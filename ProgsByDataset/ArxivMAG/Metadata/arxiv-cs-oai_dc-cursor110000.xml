<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2018-01-29T03:14:45Z</responseDate>
<request verb="ListRecords" resumptionToken="2369777|110001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04822</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SimDoc: Topic Sequence Alignment based Document Similarity Framework</dc:title>
 <dc:creator>Maheshwari, Gaurav</dc:creator>
 <dc:creator>Trivedi, Priyansh</dc:creator>
 <dc:creator>Sahijwani, Harshita</dc:creator>
 <dc:creator>Jha, Kunal</dc:creator>
 <dc:creator>Dasgupta, Sourish</dc:creator>
 <dc:creator>Lehmann, Jens</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Document similarity is the problem of estimating the degree to which a given
pair of documents has similar semantic content. An accurate document similarity
measure can improve several enterprise relevant tasks such as document
clustering, text mining, and question-answering. In this paper, we show that a
document's thematic flow, which is often disregarded by bag-of-word techniques,
is pivotal in estimating their similarity. To this end, we propose a novel
semantic document similarity framework, called SimDoc. We model documents as
topic-sequences, where topics represent latent generative clusters of related
words. Then, we use a sequence alignment algorithm to estimate their semantic
similarity. We further conceptualize a novel mechanism to compute topic-topic
similarity to fine tune our system. In our experiments, we show that SimDoc
outperforms many contemporary bag-of-words techniques in accurately computing
document similarity, and on practical applications such as document clustering.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04825</identifier>
 <datestamp>2017-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Heavy-Hitter Detection Entirely in the Data Plane</dc:title>
 <dc:creator>Sivaraman, Vibhaalakshmi</dc:creator>
 <dc:creator>Narayana, Srinivas</dc:creator>
 <dc:creator>Rottenstreich, Ori</dc:creator>
 <dc:creator>Muthukrishnan, S.</dc:creator>
 <dc:creator>Rexford, Jennifer</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Identifying the &quot;heavy hitter&quot; flows or flows with large traffic volumes in
the data plane is important for several applications e.g., flow-size aware
routing, DoS detection, and traffic engineering. However, measurement in the
data plane is constrained by the need for line-rate processing (at 10-100Gb/s)
and limited memory in switching hardware. We propose HashPipe, a heavy hitter
detection algorithm using emerging programmable data planes. HashPipe
implements a pipeline of hash tables which retain counters for heavy flows
while evicting lighter flows over time. We prototype HashPipe in P4 and
evaluate it with packet traces from an ISP backbone link and a data center. On
the ISP trace (which contains over 400,000 flows), we find that HashPipe
identifies 95% of the 300 heaviest flows with less than 80KB of memory.
</dc:description>
 <dc:description>Comment: SOSR 2017, Santa Clara, CA</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04825</dc:identifier>
 <dc:identifier>doi:10.1145/3050220.3050239</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04831</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Power of Normalization: Faster Evasion of Saddle Points</dc:title>
 <dc:creator>Levy, Kfir Y.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A commonly used heuristic in non-convex optimization is Normalized Gradient
Descent (NGD) - a variant of gradient descent in which only the direction of
the gradient is taken into account and its magnitude ignored. We analyze this
heuristic and show that with carefully chosen parameters and noise injection,
this method can provably evade saddle points. We establish the convergence of
NGD to a local minimum, and demonstrate rates which improve upon the fastest
known first order algorithm due to Ge e al. (2015).
  The effectiveness of our method is demonstrated via an application to the
problem of online tensor decomposition; a task for which saddle point evasion
is known to result in convergence to global minima.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04831</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04833</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Steady State Visually Evoked Potentials detection using a single
  electrode consumer-grade EEG device for BCI applications</dc:title>
 <dc:creator>Calore, Enrico</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Brain-Computer Interfaces (BCIs) implement a direct communication pathway
between the brain of an user and an external device, as a computer or a machine
in general. One of the most used brain responses to implement non-invasive BCIs
is the so called steady-state visually evoked potential (SSVEP). This periodic
response is generated when an user gazes to a light flickering at a constant
frequency. The SSVEP response can be detected in the user's
electroencephalogram (EEG) at the corresponding frequency of the attended
flickering stimulus. In SSVEP based BCIs, multiple stimuli, flickering at
different frequencies, are commonly presented to the user, where to each
stimulus is associated a command for an actuator. One of the limitations to a
wider adoption of BCIs is given by the need of EEG acquisition devices and
software tools which are commonly not meant for end-user usage. In this work,
exploiting state-of-the-art software tools, the use of a low cost easy to wear
single electrode EEG device is demonstrated to be exploitable to implement
simple SSVEP based BCIs. The obtained results, although less impressive than
the ones obtainable with professional EEG equipment, are interesting in view of
practical low cost BCI applications meant for end-users.
</dc:description>
 <dc:description>Comment: Work conducted between 2013 and 2014</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04833</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04834</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stall Pattern Avoidance in Polynomial Product Codes</dc:title>
 <dc:creator>Condo, Carlo</dc:creator>
 <dc:creator>Leduc-Primeau, Francois</dc:creator>
 <dc:creator>Sarkis, Gabi</dc:creator>
 <dc:creator>Giard, Pascal</dc:creator>
 <dc:creator>Gross, Warren</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>94B35</dc:subject>
 <dc:description>  Product codes are a concatenated error-correction scheme that has been often
considered for applications requiring very low bit-error rates, which demand
that the error floor be decreased as much as possible. In this work, we
consider product codes constructed from polynomial algebraic codes, and propose
a novel low-complexity post-processing technique that is able to improve the
error-correction performance by orders of magnitude. We provide lower bounds
for the error rate achievable under post processing, and present simulation
results indicating that these bounds are tight.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures, GlobalSiP 2016</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04834</dc:identifier>
 <dc:identifier>doi:10.1109/GlobalSIP.2016.7905932</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04835</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilinear Low-Rank Tensors on Graphs &amp; Applications</dc:title>
 <dc:creator>Shahid, Nauman</dc:creator>
 <dc:creator>Grassi, Francesco</dc:creator>
 <dc:creator>Vandergheynst, Pierre</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a new framework for the analysis of low-rank tensors which lies at
the intersection of spectral graph theory and signal processing. As a first
step, we present a new graph based low-rank decomposition which approximates
the classical low-rank SVD for matrices and multi-linear SVD for tensors. Then,
building on this novel decomposition we construct a general class of convex
optimization problems for approximately solving low-rank tensor inverse
problems, such as tensor Robust PCA. The whole framework is named as
'Multilinear Low-rank tensors on Graphs (MLRTG)'. Our theoretical analysis
shows: 1) MLRTG stands on the notion of approximate stationarity of
multi-dimensional signals on graphs and 2) the approximation error depends on
the eigen gaps of the graphs. We demonstrate applications for a wide variety of
4 artificial and 12 real tensor datasets, such as EEG, FMRI, BCI, surveillance
videos and hyperspectral images. Generalization of the tensor concepts to
non-euclidean domain, orders of magnitude speed-up, low-memory requirement and
significantly enhanced performance at low SNR are the key aspects of our
framework.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04837</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lost in Space: Geolocation in Event Data</dc:title>
 <dc:creator>Lee, Sophie J.</dc:creator>
 <dc:creator>Liu, Howard</dc:creator>
 <dc:creator>Ward, Michael D.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Extracting the &quot;correct&quot; location information from text data, i.e.,
determining the place of event, has long been a goal for automated text
processing. To approximate human-like coding schema, we introduce a supervised
machine learning algorithm that classifies each location word to be either
correct or incorrect. We use news articles collected from around the world
(Integrated Crisis Early Warning System [ICEWS] data and Open Event Data
Alliance [OEDA] data) to test our algorithm that consists of two stages. In the
feature selection stage, we extract contextual information from texts, namely,
the N-gram patterns for location words, the frequency of mention, and the
context of the sentences containing location words. In the classification
stage, we use three classifiers to estimate the model parameters in the
training set and then to predict whether a location word in the test set news
articles is the place of the event. The validation results show that our
algorithm improves the accuracy rate of the current geolocation methods of
dictionary approach by as much as 25%.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04838</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Verifying Proofs of Propositional Unsatisfiability via Window
  Shifting</dc:title>
 <dc:creator>Chen, Jingchao</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  The robustness and correctness of SAT solvers are receiving more and more
attention. In recent SAT competitions, a proof of unsatisfiability emitted by
SAT solvers must be checked. So far, no proof checker has been efficient for
every case. In the SAT competition 2016, some proofs were not verified within
20000 seconds. For this reason, we decided to develop a more efficient proof
checker called TreeRat. This new checker uses a window shifting technique to
improve the level of efficiency at which it verifies proofs of
unsatisfiability. At the same time, we suggest that tree-search-based SAT
solvers should use an equivalent relation encoding to emit proofs of
subproblems. In our experiments, TreeRat was able to verify almost all proofs
within 20000 seconds. On this point, TreeRat is shown to be superior to the
existing proof checker called DRAT-trim. Also, in most cases, TreeRat is faster
than DRAT-trim. Like DRAT-trim, TreeRat can output also TraceCheck dependency
graphs.
</dc:description>
 <dc:description>Comment: 12 pages, 3 figures</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04841</identifier>
 <datestamp>2017-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantitative Entropy Study of Language Complexity</dc:title>
 <dc:creator>Xie, R. R.</dc:creator>
 <dc:creator>Deng, W. B.</dc:creator>
 <dc:creator>Wang, D. J.</dc:creator>
 <dc:creator>Csernai, L. P.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We study the entropy of Chinese and English texts, based on characters in
case of Chinese texts and based on words for both languages. Significant
differences are found between the languages and between different personal
styles of debating partners. The entropy analysis points in the direction of
lower entropy, that is of higher complexity. Such a text analysis would be
applied for individuals of different styles, a single individual at different
age, as well as different groups of the population.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04841</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04842</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Role of Word Length in Semantic Topology</dc:title>
 <dc:creator>Fumarola, Francesco</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>91E10</dc:subject>
 <dc:description>  A topological argument is presented concering the structure of semantic
space, based on the negative correlation between polysemy and word length. The
resulting graph structure is applied to the modeling of free-recall
experiments, resulting in predictions on the comparative values of recall
probabilities. Associative recall is found to favor longer words whereas
sequential recall is found to favor shorter words. Data from the PEERS
experiments of Lohnas et al. (2015) and Healey and Kahana (2016) confirm both
predictons, with correlation coefficients $r_{seq}= -0.17$ and $r_{ass}=
+0.17$. The argument is then applied to predicting global properties of list
recall, which leads to a novel explanation for the word-length effect based on
the optimization of retrieval strategies.
</dc:description>
 <dc:description>Comment: 17 pages, 10 figures</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04843</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite Bases with Respect to the Superposition in Classes of Elementary
  Recursive Functions, dissertation</dc:title>
 <dc:creator>Volkov, Sergey</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  This is a thesis that was defended in 2009 at Lomonosov Moscow State
University.
  In Chapter 1:
  1. It is proved that that the class of lower (Skolem) elementary functions is
the set of all polynomial-bounded functions that can be obtained by a
composition of $x+1$, $xy$, $\max(x-y,0)$, $x\wedge y$, $\lfloor x/y \rfloor$,
and one exponential function ($2^x$ or $x^y$) using formulas that have no more
than 2 floors with respect to an exponent (for example, $(x+y)^{xy+z}+1$ has 2
floors, $2^{2^x}$ has 3 floors). Here $x\wedge y$ is a bitwise AND of $x$ and
$y$.
  2. It is proved that $\{x+y,\ \max(x-y,0),\ x\wedge y,\ \lfloor x/y \rfloor,\
2^{\lfloor \log_2 x \rfloor^2}\}$ and $\{x+y,\ \max(x-y,0),\ x\wedge y,\
\lfloor x/y \rfloor,\ x^{\lfloor \log_2 y \rfloor}\}$ are composition bases in
the functional version of the uniform $\mathrm{TC}^0$ (also known as
$\mathrm{FOM}$).
  3. The hierarchy of classes exhausting the class of elementary functions is
described in terms of compositions with restrictions on a number of floors in a
formula.
  The results of Chapter 1 are published in:
  1) Volkov S.A. An exponential expansion of the Skolem-elementary functions,
and bounded superpositions of simple arithmetic functions (in Russian),
Mathematical Problems of Cybernetics, Moscow, Fizmatlit, 2007, vol. 16, pp.
163-190
  2) doi:10.1134/S1064562407040217
  In Chapter 2 a simple composition basis in the class ${\cal E}^2$ of
Grzegorczyk hierarchy is described. This result is published in DOI:
10.1515/156939206779238436
  In Chapter 3 it is proved that the group of permutations
$\mathrm{Gr}(Q)=\{f:\ f,f^{-1}\in Q\}$ is generated by two permutations for
many classes $Q$. For example, this is proved for $Q=\mathrm{FP}$, where
$\mathrm{FP}$ is the class of all polynomial-time computable functions (of the
length of input). The results of chapter 3 are published in DOI:
10.1515/DMA.2008.046
</dc:description>
 <dc:description>Comment: translated from Russian by Dina Kunets</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04843</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04845</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Evaluation of Information Sharing Parking Guidance Policies Using a
  Bayesian Approach</dc:title>
 <dc:creator>Wu, Xinyi</dc:creator>
 <dc:creator>Balkumar, Kartik</dc:creator>
 <dc:creator>Luo, Qi</dc:creator>
 <dc:creator>Hampshire, Robert</dc:creator>
 <dc:creator>Saigal, Romesh</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Real-time parking occupancy information is critical for a parking management
system to facilitate drivers to park more efficiently. Recent advances in
connected and automated vehicle technologies enable sensor-equipped cars (probe
cars) to detect and broadcast available parking spaces when driving through
parking lots. In this paper, we evaluate the impact of market penetration of
probe cars on the system performance, and investigate different parking
guidance policies to improve the data acquisition process. We adopt a
simulation-based approach to impose four policies on an off- street parking lot
influencing the behavior of probe cars to park in assigned parking spaces. This
in turn effects the scanning route and the parking space occupancy estimations.
The last policy we propose is a near-optimal guidance strategy that maximizes
the information gain of posteriors. The results suggest that an efficient
information gathering policy can compensate for low penetration of connected
and automated vehicles. We also highlight the policy trade-off that occur while
attempting to maximize information gain through explorations and improve
assignment accuracy through exploitations. Our results can assist urban policy
makers in designing and managing smart parking systems.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04846</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Theoretic Performance of Periodogram-based CFO Estimation in
  Massive MU-MIMO Systems</dc:title>
 <dc:creator>Mukherjee, Sudarshan</dc:creator>
 <dc:creator>Mohammed, Saif Khan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study the information theoretic performance of the modified
time-reversal maximum ratio combining (TR-MRC) receiver (presented in [9]) with
the spatially averaged periodogram-based carrier frequency offset (CFO)
estimator (proposed in [7]) in multi-user massive MIMO systems. Our analysis
shows that an $\mathcal{O}(\sqrt{M})$ array gain is achieved with this
periodogram-based CFO estimator, which is same as the array gain achieved in
the ideal/zero CFO scenario ($M$ is the number of base station antennas).
Information theoretic performance comparison with the correlation-based CFO
estimator for massive MIMO systems (proposed in [6]) reveals that this
periodogram-based CFO estimator is more energy efficient in slowly time-varying
channels.
</dc:description>
 <dc:description>Comment: Submitted to IEEE ICC 2017. arXiv admin note: text overlap with
  arXiv:1605.06275</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04846</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04847</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Power of Side-information in Subgraph Detection</dc:title>
 <dc:creator>Kadavankandy, Arun</dc:creator>
 <dc:creator>Avrachenkov, Konstantin</dc:creator>
 <dc:creator>Cottatellucci, Laura</dc:creator>
 <dc:creator>Sundaresan, Rajesh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this work, we tackle the problem of hidden community detection. We
consider Belief Propagation (BP) applied to the problem of detecting a hidden
Erd\H{o}s-R\'enyi (ER) graph embedded in a larger and sparser ER graph, in the
presence of side-information. We derive two related algorithms based on BP to
perform subgraph detection in the presence of two kinds of side-information.
The first variant of side-information consists of a set of nodes, called cues,
known to be from the subgraph. The second variant of side-information consists
of a set of nodes that are cues with a given probability. It was shown in past
works that BP without side-information fails to detect the subgraph correctly
when an effective signal-to-noise ratio (SNR) parameter falls below a
threshold. In contrast, in the presence of non-trivial side-information, we
show that the BP algorithm achieves asymptotically zero error for any value of
the SNR parameter. We validate our results through simulations on synthetic
datasets as well as on a few real world networks.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2017-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04847</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04849</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deeply supervised salient object detection with short connections</dc:title>
 <dc:creator>Hou, Qibin</dc:creator>
 <dc:creator>Cheng, Ming-Ming</dc:creator>
 <dc:creator>Hu, Xiao-Wei</dc:creator>
 <dc:creator>Borji, Ali</dc:creator>
 <dc:creator>Tu, Zhuowen</dc:creator>
 <dc:creator>Torr, Philip</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent progress on saliency detection is substantial, benefiting mostly from
the explosive development of Convolutional Neural Networks (CNNs). Semantic
segmentation and saliency detection algorithms developed lately have been
mostly based on Fully Convolutional Neural Networks (FCNs). There is still a
large room for improvement over the generic FCN models that do not explicitly
deal with the scale-space problem. Holistically-Nested Edge Detector (HED)
provides a skip-layer structure with deep supervision for edge and boundary
detection, but the performance gain of HED on salience detection is not
obvious. In this paper, we propose a new method for saliency detection by
introducing short connections to the skip-layer structures within the HED
architecture. Our framework provides rich multi-scale feature maps at each
layer, a property that is critically needed to perform segment detection. Our
method produces state-of-the-art results on 5 widely tested salient object
detection benchmarks, with advantages in terms of efficiency (0.15 seconds per
image), effectiveness, and simplicity over the existing algorithms.
</dc:description>
 <dc:description>Comment: IEEE CVPR 2017</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04849</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04850</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scale-constrained Unsupervised Evaluation Method for Multi-scale Image
  Segmentation</dc:title>
 <dc:creator>Lu, Yuhang</dc:creator>
 <dc:creator>Wan, Youchuan</dc:creator>
 <dc:creator>Li, Gang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Unsupervised evaluation of segmentation quality is a crucial step in image
segmentation applications. Previous unsupervised evaluation methods usually
lacked the adaptability to multi-scale segmentation. A scale-constrained
evaluation method that evaluates segmentation quality according to the
specified target scale is proposed in this paper. First, regional saliency and
merging cost are employed to describe intra-region homogeneity and inter-region
heterogeneity, respectively. Subsequently, both of them are standardized into
equivalent spectral distances of a predefined region. Finally, by analyzing the
relationship between image characteristics and segmentation quality, we
establish the evaluation model. Experimental results show that the proposed
method outperforms four commonly used unsupervised methods in multi-scale
evaluation tasks.
</dc:description>
 <dc:description>Comment: 5 pages, 2016 IEEE International Conference on Image Processing</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04850</dc:identifier>
 <dc:identifier>doi:10.1109/ICIP.2016.7532821</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04853</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Coded Caching Delivery Design over Wireless Networks</dc:title>
 <dc:creator>Zheng, Lei</dc:creator>
 <dc:creator>Yan, Qifa</dc:creator>
 <dc:creator>Chen, Qingchun</dc:creator>
 <dc:creator>Tang, Xiaohu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Coded caching scheme is a promising technique to migrate the network burden
in peak hours, which attains more prominent gains than the uncoded caching. The
coded caching scheme can be classified into two types, namely, the centralized
and the decentralized scheme, according to whether the placement procedures are
carefully designed or operated at random. However, most of the previous
analysis assumes that the connected links between server and users are
error-free. In this paper, we explore the coded caching based delivery design
in wireless networks, where all the connected wireless links are different. For
both centralized and decentralized cases, we proposed two delivery schemes,
namely, the orthogonal delivery scheme and the concurrent delivery scheme. We
focus on the transmission time slots spent on satisfying the system requests,
and prove that for both the centralized and the decentralized cases, the
concurrent delivery always outperforms orthogonal delivery scheme. Furthermore,
for the orthogonal delivery scheme, we derive the gap in terms of transmission
time between the decentralized and centralized case, which is essentially no
more than 1.5.
</dc:description>
 <dc:description>Comment: 18 pages, 7 figures</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04861</identifier>
 <datestamp>2017-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inferring Network Structure from Cascades</dc:title>
 <dc:creator>Ghonge, Sushrut</dc:creator>
 <dc:creator>Vural, Dervis Can</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Many physical, biological, and social phenomena can be described by cascades
taking place on a network. Often, the activity can be empirically observed, but
not the underlying network of interactions. In this paper we offer three
topological methods to infer the structure of any directed network given a set
of cascade arrival times. Our formulas hold for a very general class of models
where the activation probability of a node is a generic function of its degree
and the number of its active neighbors. We report high success rates for
synthetic and real networks, for several different cascade models.
</dc:description>
 <dc:description>Comment: Published in Physical Review E</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04861</dc:identifier>
 <dc:identifier>Phys. Rev. E 96, 012319 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.96.012319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04870</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constrained Low-Rank Learning Using Least Squares-Based Regularization</dc:title>
 <dc:creator>Li, Ping</dc:creator>
 <dc:creator>Yu, Jun</dc:creator>
 <dc:creator>Wang, Meng</dc:creator>
 <dc:creator>Zhang, Luming</dc:creator>
 <dc:creator>Cai, Deng</dc:creator>
 <dc:creator>Li, Xuelong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Low-rank learning has attracted much attention recently due to its efficacy
in a rich variety of real-world tasks, e.g., subspace segmentation and image
categorization. Most low-rank methods are incapable of capturing
low-dimensional subspace for supervised learning tasks, e.g., classification
and regression. This paper aims to learn both the discriminant low-rank
representation (LRR) and the robust projecting subspace in a supervised manner.
To achieve this goal, we cast the problem into a constrained rank minimization
framework by adopting the least squares regularization. Naturally, the data
label structure tends to resemble that of the corresponding low-dimensional
representation, which is derived from the robust subspace projection of clean
data by low-rank learning. Moreover, the low-dimensional representation of
original data can be paired with some informative structure by imposing an
appropriate constraint, e.g., Laplacian regularizer. Therefore, we propose a
novel constrained LRR method. The objective function is formulated as a
constrained nuclear norm minimization problem, which can be solved by the
inexact augmented Lagrange multiplier algorithm. Extensive experiments on image
classification, human pose estimation, and robust face recovery have confirmed
the superiority of our method.
</dc:description>
 <dc:description>Comment: 14 pages, 7 figures, accepted to appear in IEEE Transactions on
  Cybernetics</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04870</dc:identifier>
 <dc:identifier>IEEE Transactions on Cybernetics, 2016</dc:identifier>
 <dc:identifier>doi:10.1109/TCYB.2016.2623638</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04871</identifier>
 <datestamp>2017-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Audio Event and Scene Recognition: A Unified Approach using Strongly and
  Weakly Labeled Data</dc:title>
 <dc:creator>Kumar, Anurag</dc:creator>
 <dc:creator>Raj, Bhiksha</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  In this paper we propose a novel learning framework called Supervised and
Weakly Supervised Learning where the goal is to learn simultaneously from
weakly and strongly labeled data. Strongly labeled data can be simply
understood as fully supervised data where all labeled instances are available.
In weakly supervised learning only data is weakly labeled which prevents one
from directly applying supervised learning methods. Our proposed framework is
motivated by the fact that a small amount of strongly labeled data can give
considerable improvement over only weakly supervised learning. The primary
problem domain focus of this paper is acoustic event and scene detection in
audio recordings. We first propose a naive formulation for leveraging labeled
data in both forms. We then propose a more general framework for Supervised and
Weakly Supervised Learning (SWSL). Based on this general framework, we propose
a graph based approach for SWSL. Our main method is based on manifold
regularization on graphs in which we show that the unified learning can be
formulated as a constraint optimization problem which can be solved by
iterative concave-convex procedure (CCCP). Our experiments show that our
proposed framework can address several concerns of audio content analysis using
weakly labeled data.
</dc:description>
 <dc:description>Comment: IJCNN 2017, 8 pages</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:date>2017-02-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04871</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04872</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topological classifier for detecting the emergence of epileptic seizures</dc:title>
 <dc:creator>Piangerelli, Marco</dc:creator>
 <dc:creator>Rucco, Matteo</dc:creator>
 <dc:creator>Merelli, Emanuela</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>I.5.2</dc:subject>
 <dc:description>  In this work we study how to apply topological data analysis to create a
method suitable to classify EEGs of patients affected by epilepsy. The
topological space constructed from the collection of EEGs signals is analyzed
by Persistent Entropy acting as a global topological feature for discriminating
between healthy and epileptic signals. The Physionet data-set has been used for
testing the classifier.
</dc:description>
 <dc:description>Comment: Open data: Physionet data-set</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04878</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Data Quality Metric (DQM): How to Estimate The Number of Undetected
  Errors in Data Sets</dc:title>
 <dc:creator>Chung, Yeounoh</dc:creator>
 <dc:creator>Krishnan, Sanjay</dc:creator>
 <dc:creator>Kraska, Tim</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Data cleaning, whether manual or algorithmic, is rarely perfect leaving a
dataset with an unknown number of false positives and false negatives after
cleaning. In many scenarios, quantifying the number of remaining errors is
challenging because our data integrity rules themselves may be incomplete, or
the available gold-standard datasets may be too small to extrapolate. As the
use of inherently fallible crowds becomes more prevalent in data cleaning
problems, it is important to have estimators to quantify the extent of such
errors. We propose novel species estimators to estimate the number of distinct
remaining errors in a dataset after it has been cleaned by a set of crowd
workers -- essentially, quantifying the utility of hiring additional workers to
clean the dataset. This problem requires new estimators that are robust to
false positives and false negatives, and we empirically show on three
real-world datasets that existing species estimators are unstable for this
problem, while our proposed techniques quickly converge.
</dc:description>
 <dc:description>Comment: To appear in VLDB 2017</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04878</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04880</identifier>
 <datestamp>2016-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IoT Sentinel: Automated Device-Type Identification for Security
  Enforcement in IoT</dc:title>
 <dc:creator>Miettinen, Markus</dc:creator>
 <dc:creator>Marchal, Samuel</dc:creator>
 <dc:creator>Hafeez, Ibbad</dc:creator>
 <dc:creator>Asokan, N.</dc:creator>
 <dc:creator>Sadeghi, Ahmad-Reza</dc:creator>
 <dc:creator>Tarkoma, Sasu</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  With the rapid growth of the Internet-of-Things (IoT), concerns about the
security of IoT devices have become prominent. Several vendors are producing
IP-connected devices for home and small office networks that often suffer from
flawed security designs and implementations. They also tend to lack mechanisms
for firmware updates or patches that can help eliminate security
vulnerabilities. Securing networks where the presence of such vulnerable
devices is given, requires a brownfield approach: applying necessary protection
measures within the network so that potentially vulnerable devices can coexist
without endangering the security of other devices in the same network. In this
paper, we present IOT SENTINEL, a system capable of automatically identifying
the types of devices being connected to an IoT network and enabling enforcement
of rules for constraining the communications of vulnerable devices so as to
minimize damage resulting from their compromise. We show that IOT SENTINEL is
effective in identifying device types and has minimal performance overhead.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2016-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04880</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04887</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpreting the Syntactic and Social Elements of the Tweet
  Representations via Elementary Property Prediction Tasks</dc:title>
 <dc:creator>Ganesh, J</dc:creator>
 <dc:creator>Gupta, Manish</dc:creator>
 <dc:creator>Varma, Vasudeva</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Research in social media analysis is experiencing a recent surge with a large
number of works applying representation learning models to solve high-level
syntactico-semantic tasks such as sentiment analysis, semantic textual
similarity computation, hashtag prediction and so on. Although the performance
of the representation learning models are better than the traditional baselines
for the tasks, little is known about the core properties of a tweet encoded
within the representations. Understanding these core properties would empower
us in making generalizable conclusions about the quality of representations.
Our work presented here constitutes the first step in opening the black-box of
vector embedding for social media posts, with emphasis on tweets in particular.
  In order to understand the core properties encoded in a tweet representation,
we evaluate the representations to estimate the extent to which it can model
each of those properties such as tweet length, presence of words, hashtags,
mentions, capitalization, and so on. This is done with the help of multiple
classifiers which take the representation as input. Essentially, each
classifier evaluates one of the syntactic or social properties which are
arguably salient for a tweet. This is also the first holistic study on
extensively analysing the ability to encode these properties for a wide variety
of tweet representation models including the traditional unsupervised methods
(BOW, LDA), unsupervised representation learning methods (Siamese CBOW,
Tweet2Vec) as well as supervised methods (CNN, BLSTM).
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04899</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diversity encouraged learning of unsupervised LSTM ensemble for neural
  activity video prediction</dc:title>
 <dc:creator>Song, Yilin</dc:creator>
 <dc:creator>Viventi, Jonathan</dc:creator>
 <dc:creator>Wang, Yao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Being able to predict the neural signal in the near future from the current
and previous observations has the potential to enable real-time responsive
brain stimulation to suppress seizures. We have investigated how to use an
auto-encoder model consisting of LSTM cells for such prediction. Recog- nizing
that there exist multiple activity pattern clusters, we have further explored
to train an ensemble of LSTM mod- els so that each model can specialize in
modeling certain neural activities, without explicitly clustering the training
data. We train the ensemble using an ensemble-awareness loss, which jointly
solves the model assignment problem and the error minimization problem. During
training, for each training sequence, only the model that has the lowest recon-
struction and prediction error is updated. Intrinsically such a loss function
enables each LTSM model to be adapted to a subset of the training sequences
that share similar dynamic behavior. We demonstrate this can be trained in an
end- to-end manner and achieve significant accuracy in neural activity
prediction.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04899</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04905</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CIFAR-10: KNN-based Ensemble of Classifiers</dc:title>
 <dc:creator>Abouelnaga, Yehya</dc:creator>
 <dc:creator>Ali, Ola S.</dc:creator>
 <dc:creator>Rady, Hager</dc:creator>
 <dc:creator>Moustafa, Mohamed</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we study the performance of different classifiers on the
CIFAR-10 dataset, and build an ensemble of classifiers to reach a better
performance. We show that, on CIFAR-10, K-Nearest Neighbors (KNN) and
Convolutional Neural Network (CNN), on some classes, are mutually exclusive,
thus yield in higher accuracy when combined. We reduce KNN overfitting using
Principal Component Analysis (PCA), and ensemble it with a CNN to increase its
accuracy. Our approach improves our best CNN model from 93.33% to 94.03%.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04920</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Learning with Truncated Gaussian Graphical Models</dc:title>
 <dc:creator>Su, Qinliang</dc:creator>
 <dc:creator>Liao, Xuejun</dc:creator>
 <dc:creator>Li, Chunyuan</dc:creator>
 <dc:creator>Gan, Zhe</dc:creator>
 <dc:creator>Carin, Lawrence</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Gaussian graphical models (GGMs) are widely used for statistical modeling,
because of ease of inference and the ubiquitous use of the normal distribution
in practical approximations. However, they are also known for their limited
modeling abilities, due to the Gaussian assumption. In this paper, we introduce
a novel variant of GGMs, which relaxes the Gaussian restriction and yet admits
efficient inference. Specifically, we impose a bipartite structure on the GGM
and govern the hidden variables by truncated normal distributions. The
nonlinearity of the model is revealed by its connection to rectified linear
unit (ReLU) neural networks. Meanwhile, thanks to the bipartite structure and
appealing properties of truncated normals, we are able to train the models
efficiently using contrastive divergence. We consider three output constructs,
accounting for real-valued, binary and count data. We further extend the model
to deep constructions and show that deep models can be used for unsupervised
pre-training of rectifier neural networks. Extensive experimental results are
provided to validate the proposed models and demonstrate their superiority over
competing models.
</dc:description>
 <dc:description>Comment: To appear in AAAI 2017</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04921</identifier>
 <datestamp>2017-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaussian mixtures: entropy and geometric inequalities</dc:title>
 <dc:creator>Eskenazis, Alexandros</dc:creator>
 <dc:creator>Nayar, Piotr</dc:creator>
 <dc:creator>Tkocz, Tomasz</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:description>  A symmetric random variable is called a Gaussian mixture if it has the same
distribution as the product of two independent random variables, one being
positive and the other a standard Gaussian random variable. Examples of
Gaussian mixtures include random variables with densities proportional to
$e^{-|t|^p}$ and symmetric $p$-stable random variables, where $p\in(0,2]$. We
obtain various sharp moment and entropy comparison estimates for weighted sums
of independent Gaussian mixtures and investigate extensions of the B-inequality
and the Gaussian correlation inequality in the context of Gaussian mixtures. We
also obtain a correlation inequality for symmetric geodesically convex sets in
the unit sphere equipped with the normalized surface area measure. We then
apply these results to derive sharp constants in Khintchine inequalities for
vectors uniformly distributed on the unit balls with respect to $p$-norms and
provide short proofs to new and old comparison estimates for geometric
parameters of sections and projections of such balls.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04924</identifier>
 <datestamp>2017-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Semi-Supervised Graph Classifier Learning with Negative Edge
  Weights</dc:title>
 <dc:creator>Cheung, Gene</dc:creator>
 <dc:creator>Su, Weng-Tai</dc:creator>
 <dc:creator>Mao, Yu</dc:creator>
 <dc:creator>Lin, Chia-Wen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In a semi-supervised learning scenario, (possibly noisy) partially observed
labels are used as input to train a classifier, in order to assign labels to
unclassified samples. In this paper, we study this classifier learning problem
from a graph signal processing (GSP) perspective. Specifically, by viewing a
binary classifier as a piecewise constant graph-signal in a high-dimensional
feature space, we cast classifier learning as a signal restoration problem via
a classical maximum a posteriori (MAP) formulation. Unlike previous
graph-signal restoration works, we consider in addition edges with negative
weights that signify anti-correlation between samples. One unfortunate
consequence is that the graph Laplacian matrix $\mathbf{L}$ can be indefinite,
and previously proposed graph-signal smoothness prior $\mathbf{x}^T \mathbf{L}
\mathbf{x}$ for candidate signal $\mathbf{x}$ can lead to pathological
solutions. In response, we derive an optimal perturbation matrix
$\boldsymbol{\Delta}$ - based on a fast lower-bound computation of the minimum
eigenvalue of $\mathbf{L}$ via a novel application of the Haynsworth inertia
additivity formula---so that $\mathbf{L} + \boldsymbol{\Delta}$ is positive
semi-definite, resulting in a stable signal prior. Further, instead of forcing
a hard binary decision for each sample, we define the notion of generalized
smoothness on graph that promotes ambiguity in the classifier signal. Finally,
we propose an algorithm based on iterative reweighted least squares (IRLS) that
solves the posed MAP problem efficiently. Extensive simulation results show
that our proposed algorithm outperforms both SVM variants and graph-based
classifiers using positive-edge graphs noticeably.
</dc:description>
 <dc:description>Comment: 15 pages, revised for IEEE Transactions on Signal and Information
  Processing over Network</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-07-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04924</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04928</identifier>
 <datestamp>2017-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Machine Translation with Pivot Languages</dc:title>
 <dc:creator>Cheng, Yong</dc:creator>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:creator>Yang, Qian</dc:creator>
 <dc:creator>Sun, Maosong</dc:creator>
 <dc:creator>Xu, Wei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  While recent neural machine translation approaches have delivered
state-of-the-art performance for resource-rich language pairs, they suffer from
the data scarcity problem for resource-scarce language pairs. Although this
problem can be alleviated by exploiting a pivot language to bridge the source
and target languages, the source-to-pivot and pivot-to-target translation
models are usually independently trained. In this work, we introduce a joint
training algorithm for pivot-based neural machine translation. We propose three
methods to connect the two models and enable them to interact with each other
during training. Experiments on Europarl and WMT corpora show that joint
training of source-to-pivot and pivot-to-target models leads to significant
improvements over independent training across various languages.
</dc:description>
 <dc:description>Comment: fix experiments and revise the paper</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-02-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04931</identifier>
 <datestamp>2017-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Approach for Learning How to Automatically Match Job Offers and
  Candidate Profiles</dc:title>
 <dc:creator>Martinez-Gil, Jorge</dc:creator>
 <dc:creator>Paoletti, Alejandra Lorena</dc:creator>
 <dc:creator>Pichler, Mario</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Automatic matching of job offers and job candidates is a major problem for a
number of organizations and job applicants that if it were successfully
addressed could have a positive impact in many countries around the world. In
this context, it is widely accepted that semi-automatic matching algorithms
between job and candidate profiles would provide a vital technology for making
the recruitment processes faster, more accurate and transparent. In this work,
we present our research towards achieving a realistic matching approach for
satisfactorily addressing this challenge. This novel approach relies on a
matching learning solution aiming to learn from past solved cases in order to
accurately predict the results in new situations. An empirical study shows us
that our approach is able to beat solutions with no learning capabilities by a
wide margin.
</dc:description>
 <dc:description>Comment: 15 pages, 6 figures</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-09-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04931</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04934</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HPAT: High Performance Analytics with Scripting Ease-of-Use</dc:title>
 <dc:creator>Totoni, Ehsan</dc:creator>
 <dc:creator>Anderson, Todd A.</dc:creator>
 <dc:creator>Shpeisman, Tatiana</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Big data analytics requires high programmer productivity and high performance
simultaneously on large-scale clusters. However, current big data analytics
frameworks (e.g. Apache Spark) have prohibitive runtime overheads since they
are library-based. We introduce a novel auto-parallelizing compiler approach
that exploits the characteristics of the data analytics domain such as the
map/reduce parallel pattern and is robust, unlike previous auto-parallelization
methods. Using this approach, we build High Performance Analytics Toolkit
(HPAT), which parallelizes high-level scripting (Julia) programs automatically,
generates efficient MPI/C++ code, and provides resiliency. Furthermore, it
provides automatic optimizations for scripting programs, such as fusion of
array operations. Thus, HPAT is 369x to 2033x faster than Spark on the Cori
supercomputer and 20x to 256x times on Amazon AWS.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04942</identifier>
 <datestamp>2017-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast and Accurate Mining of Correlated Heavy Hitters</dc:title>
 <dc:creator>Epicoco, Italo</dc:creator>
 <dc:creator>Cafaro, Massimo</dc:creator>
 <dc:creator>Pulimeno, Marco</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The problem of mining Correlated Heavy Hitters (CHH) from a two-dimensional
data stream has been introduced recently, and a deterministic algorithm based
on the use of the Misra--Gries algorithm has been proposed by Lahiri et al. to
solve it. In this paper we present a new counter-based algorithm for tracking
CHHs, formally prove its error bounds and correctness and show, through
extensive experimental results, that our algorithm outperforms the Misra--Gries
based algorithm with regard to accuracy and speed whilst requiring
asymptotically much less space.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04942</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04946</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Safety Model Checking with Complementary Approximations</dc:title>
 <dc:creator>Li, Jianwen</dc:creator>
 <dc:creator>Zhu, Shufang</dc:creator>
 <dc:creator>Zhang, Yueling</dc:creator>
 <dc:creator>Pu, Geguang</dc:creator>
 <dc:creator>Vardi, Moshe</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Formal verification techniques such as model checking, are becoming popular
in hardware design. SAT-based model checking techniques such as IC3/PDR, have
gained a significant success in hardware industry. In this paper, we present a
new framework for SAT-based safety model checking, named Complementary
Approximate Reachability (CAR). CAR is based on standard reachability analysis,
but instead of maintaining a single sequence of reachable- state sets, CAR
maintains two sequences of over- and under- approximate reachable-state sets,
checking safety and unsafety at the same time. To construct the two sequences,
CAR uses standard Boolean-reasoning algorithms, based on satisfiability
solving, one to find a satisfying cube of a satisfiable Boolean formula, and
one to provide a minimal unsatisfiable core of an unsatisfiable Boolean
formula. We applied CAR to 548 hardware model-checking instances, and compared
its performance with IC3/PDR. Our results show that CAR is able to solve 42
instances that cannot be solved by IC3/PDR. When evaluated against a portfolio
that includes IC3/PDR and other approaches, CAR is able to solve 21 instances
that the other approaches cannot solve. We conclude that CAR should be
considered as a valuable member of any algorithmic portfolio for safety model
checking.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04947</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection of north atlantic right whale upcalls using local binary
  patterns in a two-stage strategy</dc:title>
 <dc:creator>Esfahanian, Mahdi</dc:creator>
 <dc:creator>Zhuang, Hanqi</dc:creator>
 <dc:creator>Erdol, Nurgun</dc:creator>
 <dc:creator>Gerstein, Edmund</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  In this paper, we investigate the effectiveness of two-stage classification
strategies in detecting north Atlantic right whale upcalls. Time-frequency
measurements of data from passive acoustic monitoring devices are evaluated as
images. Vocalization spectrograms are preprocessed for noise reduction and tone
removal. First stage of the algorithm eliminates non-upcalls by an energy
detection algorithm. In the second stage, two sets of features are extracted
from the remaining signals using contour-based and texture based methods. The
former is based on extraction of time-frequency features from upcall contours,
and the latter employs a Local Binary Pattern operator to extract
distinguishing texture features of the upcalls. Subsequently evaluation phase
is carried out by using several classifiers to assess the effectiveness of both
the contour-based and texture-based features for upcall detection. Experimental
results with the data set provided by the Cornell University Bioacoustics
Research Program reveal that classifiers show accuracy improvements of 3% to 4%
when using LBP features over time-frequency features. Classifiers such as the
Linear Discriminant Analysis, Support Vector Machine, and TreeBagger achieve
high upcall detection rates with LBP features.
</dc:description>
 <dc:description>Comment: 32 pages, 11 figures, 4 tables</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04953</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-End Neural Sentence Ordering Using Pointer Network</dc:title>
 <dc:creator>Gong, Jingjing</dc:creator>
 <dc:creator>Chen, Xinchi</dc:creator>
 <dc:creator>Qiu, Xipeng</dc:creator>
 <dc:creator>Huang, Xuanjing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Sentence ordering is one of important tasks in NLP. Previous works mainly
focused on improving its performance by using pair-wise strategy. However, it
is nontrivial for pair-wise models to incorporate the contextual sentence
information. In addition, error prorogation could be introduced by using the
pipeline strategy in pair-wise models. In this paper, we propose an end-to-end
neural approach to address the sentence ordering problem, which uses the
pointer network (Ptr-Net) to alleviate the error propagation problem and
utilize the whole contextual information. Experimental results show the
effectiveness of the proposed model. Source codes and dataset of this paper are
available.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04953</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04967</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Iterative Orthogonal Feature Projection for Diagnosing Bias in Black-Box
  Models</dc:title>
 <dc:creator>Adebayo, Julius</dc:creator>
 <dc:creator>Kagal, Lalana</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Predictive models are increasingly deployed for the purpose of determining
access to services such as credit, insurance, and employment. Despite potential
gains in productivity and efficiency, several potential problems have yet to be
addressed, particularly the potential for unintentional discrimination. We
present an iterative procedure, based on orthogonal projection of input
attributes, for enabling interpretability of black-box predictive models.
Through our iterative procedure, one can quantify the relative dependence of a
black-box model on its input attributes.The relative significance of the inputs
to a predictive model can then be used to assess the fairness (or
discriminatory extent) of such a model.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04967</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04969</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An integrated Graphical User Interface for Debugging Answer Set Programs</dc:title>
 <dc:creator>Gasteiger, Philip</dc:creator>
 <dc:creator>Dodaro, Carmine</dc:creator>
 <dc:creator>Musitsch, Benjamin</dc:creator>
 <dc:creator>Reale, Kristian</dc:creator>
 <dc:creator>Ricca, Francesco</dc:creator>
 <dc:creator>Schekotihin, Konstantin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  Answer Set Programming (ASP) is an expressive knowledge representation and
reasoning framework. Due to its rather simple syntax paired with
high-performance solvers, ASP is interesting for industrial applications.
However, to err is human and thus debugging is an important activity during the
development process. Therefore, tools for debugging non-ground answer set
programs are needed. In this paper, we present a new graphical debugging
interface for non-ground answer set programs. The tool is based on the
recently-introduced DWASP approach for debugging and it simplifies the
interaction with the debugger. Furthermore, the debugging interface is
integrated in ASPIDE, a rich IDE for answer set programs. With our extension
ASPIDE turns into a full-fledged IDE by offering debugging support.
</dc:description>
 <dc:description>Comment: Paper presented at the 1st Workshop on Trends and Applications of
  Answer Set Programming (TAASP 2016), Klagenfurt, Austria, 26 September 2016,
  15 pages, LaTeX, 5 figures</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04976</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Naming the Pain in Requirements Engineering: Design of a Global Family
  of Surveys and First Results from Germany</dc:title>
 <dc:creator>Fern&#xe1;ndez, Daniel M&#xe9;ndez</dc:creator>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.1</dc:subject>
 <dc:description>  Context: For many years, we have observed industry struggling in defining a
high quality requirements engineering (RE) and researchers trying to understand
industrial expectations and problems. Although we are investigating the
discipline with a plethora of empirical studies, those studies either
concentrate on validating specific methods or on single companies or countries.
Therefore, they allow only for limited empirical generalisations. Objective: To
lay an empirical and generalisable foundation about the state of the practice
in RE, we aim at a series of open and reproducible surveys that allow us to
steer future research in a problem-driven manner. Method: We designed a
globally distributed family of surveys in joint collaborations with different
researchers from different countries. The instrument is based on an initial
theory inferred from available studies. As a long-term goal, the survey will be
regularly replicated to manifest a clear understanding on the status quo and
practical needs in RE. In this paper, we present the design of the family of
surveys and first results of its start in Germany. Results: Our first results
contain responses from 30 German companies. The results are not yet
generalisable, but already indicate several trends and problems. For instance,
a commonly stated problem respondents see in their company standards are
artefacts being underrepresented, and important problems they experience in
their projects are incomplete and inconsistent requirements. Conclusion: The
results suggest that the survey design and instrument are well-suited to be
replicated and, thereby, to create a generalisable empirical basis of RE in
practice.
</dc:description>
 <dc:description>Comment: 11 pages, 1 figure</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04976</dc:identifier>
 <dc:identifier>Proc. 17th International Conference on Evaluation and Assessment
  in Software Engineering (EASE'13). ACM, 2013</dc:identifier>
 <dc:identifier>doi:10.1145/2460999.2461027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04977</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Query Data With Fuzzy Information In Object-Oriented Databases An
  Approach Interval Values</dc:title>
 <dc:creator>Van Thang, Doan</dc:creator>
 <dc:creator>Van Ban, Doan</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  In this paper, we propose methods of handling attributive values of object
classes in object oriented database with fuzzy information and uncertainty
based on quantitatively semantics based hedge algebraic. In this approach we
consider to attributive values (as well as methods) object class is interval
values and the interval values are converted into sub interval in [0, 1]
respectively. That its the fuzziness of the elements in the hedge algebra is
also sub interval in [0,1]. So, we present an algorithm allows the comparison
of two sub interval [0,1] helping the requirements of the query data
</dc:description>
 <dc:date>2016-10-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04977</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04981</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Logic Gates with Ion Transistors</dc:title>
 <dc:creator>Grebel, Haim</dc:creator>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:subject>Condensed Matter - Mesoscale and Nanoscale Physics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Electronic logic gates are the basic building blocks of every computing and
micro controlling system. Logic gates are made of switches, such as diodes and
transistors. Ion-selective, ionic switches may emulate electronic switches
[1-8]. If we ever want to create artificial bio-chemical circuitry, then we
need to move a step further towards ion-logic circuitry. Here we demonstrate
ion XOR and OR gates with electrochemical cells, and specifically, with two
wet-cell batteries. In parallel to vacuum tubes, the batteries were modified to
include a third, permeable and conductive mid electrode (the gate), which was
placed between the anode and cathode in order to affect the ion flow through
it. The key is to control the cell output with a much smaller biasing power, as
demonstrated here. A successful demonstration points to self-powered ion logic
gates.
</dc:description>
 <dc:description>Comment: 13 pages; 6 figures</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04981</dc:identifier>
 <dc:identifier>doi:10.1016/j.tsf.2017.07.044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04982</identifier>
 <datestamp>2017-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Oracle Complexity of Second-Order Methods for Finite-Sum Problems</dc:title>
 <dc:creator>Arjevani, Yossi</dc:creator>
 <dc:creator>Shamir, Ohad</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Finite-sum optimization problems are ubiquitous in machine learning, and are
commonly solved using first-order methods which rely on gradient computations.
Recently, there has been growing interest in \emph{second-order} methods, which
rely on both gradients and Hessians. In principle, second-order methods can
require much fewer iterations than first-order methods, and hold the promise
for more efficient algorithms. Although computing and manipulating Hessians is
prohibitive for high-dimensional problems in general, the Hessians of
individual functions in finite-sum problems can often be efficiently computed,
e.g. because they possess a low-rank structure. Can second-order information
indeed be used to solve such problems more efficiently? In this paper, we
provide evidence that the answer -- perhaps surprisingly -- is negative, at
least in terms of worst-case guarantees. However, we also discuss what
additional assumptions and algorithmic approaches might potentially circumvent
this negative result.
</dc:description>
 <dc:description>Comment: 30 pages</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04982</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04988</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuity Assumptions in Cake-Cutting</dc:title>
 <dc:creator>Schilling, Ren&#xe9; L.</dc:creator>
 <dc:creator>Stoyan, Dietrich</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>28A12, 91B32</dc:subject>
 <dc:description>  In important papers on cake-cutting -- one of the key areas in fair division
and resource allocation -- the measure-theoretical fundamentals are not fully
correctly given. It is not clear (i) which family of sets should be taken for
the pieces of cake, (ii) which set-functions should be used for evaluating the
pieces, and (iii) which is the relationship between various continuity
properties appearing in cake-cutting.
  We show that probably the best choice for the familiy of subsets of $[0,1]$
is the Borel $\sigma$-algebra and for the set-function any `sliceable' Borel
measure. At least in dimension one it does not make sense to work with only
finitely additive contents on finite unions of intervals. For the continuity
property we see two possibilities. The weaker is the traditional divisibility
property, which is equivalent to being atom-free. The stronger is simply
absolute continuity with respect to Lebesgue measure. We also consider the case
of a base set (cake or pie) more general than $[0,1]$.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04989</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Neural Network based Part-of-Speech Tagger for Code-Mixed
  Social Media Text</dc:title>
 <dc:creator>Patel, Raj Nath</dc:creator>
 <dc:creator>Pimpale, Prakash B.</dc:creator>
 <dc:creator>Sasikumar, M</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper describes Centre for Development of Advanced Computing's (CDACM)
submission to the shared task-'Tool Contest on POS tagging for Code-Mixed
Indian Social Media (Facebook, Twitter, and Whatsapp) Text', collocated with
ICON-2016. The shared task was to predict Part of Speech (POS) tag at word
level for a given text. The code-mixed text is generated mostly on social media
by multilingual users. The presence of the multilingual words,
transliterations, and spelling variations make such content linguistically
complex. In this paper, we propose an approach to POS tag code-mixed social
media text using Recurrent Neural Network Language Model (RNN-LM) architecture.
We submitted the results for Hindi-English (hi-en), Bengali-English (bn-en),
and Telugu-English (te-en) code-mixed data.
</dc:description>
 <dc:description>Comment: 7 pages, Published at the Tool Contest on POS tagging for Indian
  Social Media Text, ICON 2016</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04989</dc:identifier>
 <dc:identifier>In Proceedings of the Tool Contest on POS tagging for Indian
  Social Media Text, ICON 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04994</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One-to-Many Network for Visually Pleasing Compression Artifacts
  Reduction</dc:title>
 <dc:creator>Guo, Jun</dc:creator>
 <dc:creator>Chao, Hongyang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We consider the compression artifacts reduction problem, where a compressed
image is transformed into an artifact-free image. Recent approaches for this
problem typically train a one-to-one mapping using a per-pixel $L_2$ loss
between the outputs and the ground-truths. We point out that these approaches
used to produce overly smooth results, and PSNR doesn't reflect their real
performance. In this paper, we propose a one-to-many network, which measures
output quality using a perceptual loss, a naturalness loss, and a JPEG loss. We
also avoid grid-like artifacts during deconvolution using a &quot;shift-and-average&quot;
strategy. Extensive experimental results demonstrate the dramatic visual
improvement of our approach over the state of the arts.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04994</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.04999</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Massively-Parallel Similarity Join, Edge-Isoperimetry, and Distance
  Correlations on the Hypercube</dc:title>
 <dc:creator>Beame, Paul</dc:creator>
 <dc:creator>Rashtchian, Cyrus</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We study distributed protocols for finding all pairs of similar vectors in a
large dataset. Our results pertain to a variety of discrete metrics, and we
give concrete instantiations for Hamming distance. In particular, we give
improved upper bounds on the overhead required for similarity defined by
Hamming distance $r&gt;1$ and prove a lower bound showing qualitative optimality
of the overhead required for similarity over any Hamming distance $r$. Our main
conceptual contribution is a connection between similarity search algorithms
and certain graph-theoretic quantities. For our upper bounds, we exhibit a
general method for designing one-round protocols using edge-isoperimetric
shapes in similarity graphs. For our lower bounds, we define a new
combinatorial optimization problem, which can be stated in purely
graph-theoretic terms yet also captures the core of the analysis in previous
theoretical work on distributed similarity joins. As one of our main technical
results, we prove new bounds on distance correlations in subsets of the Hamming
cube.
</dc:description>
 <dc:description>Comment: 23 pages, plus references and appendix. To appear in SODA 2017</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.04999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05002</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of Partial Interference Cancellation in
  Multi-Antenna UDNs</dc:title>
 <dc:creator>Atzeni, Italo</dc:creator>
 <dc:creator>Kountouris, Marios</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The employment of partial zero-forcing (PZF) receivers at the base stations
represents an efficient and low-complexity technique for uplink interference
management in cellular networks. In this paper, we focus on the performance
analysis of ultra-dense networks (UDNs) in which the multi-antenna receivers
adopt PZF. We provide both integral expressions and tight closed-form
approximations for the probability of successful transmission, which can be
used to accurately evaluate the optimal tradeoff between interference
cancellation and array gain. Numerical results show that no more than half of
the available degrees of freedom should be used for interference cancellation.
</dc:description>
 <dc:description>Comment: Paper presented at Asilomar Conference on Signals, Systems and
  Computers, 2016</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05003</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Light Field Stitching for Extended Synthetic Aperture</dc:title>
 <dc:creator>Mukati, M. Umair</dc:creator>
 <dc:creator>Gunturk, Bahadir K.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Through capturing spatial and angular radiance distribution, light field
cameras introduce new capabilities that are not possible with conventional
cameras. So far in the light field imaging literature, the focus has been on
the theory and applications of single light field capture. By combining
multiple light fields, it is possible to obtain new capabilities and
enhancements, and even exceed physical limitations, such as spatial resolution
and aperture size of the imaging device. In this paper, we present an algorithm
to register and stitch multiple light fields. We utilize the regularity of the
spatial and angular sampling in light field data, and extend some techniques
developed for stereo vision systems to light field data. Such an extension is
not straightforward for a micro-lens array (MLA) based light field camera due
to extremely small baseline and low spatial resolution. By merging multiple
light fields captured by an MLA based camera, we obtain larger synthetic
aperture, which results in improvements in light field capabilities, such as
increased depth estimation range/accuracy and wider perspective shift range.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05008</identifier>
 <datestamp>2017-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Light Field Imaging for Improved Spatial Resolution and Depth
  Range</dc:title>
 <dc:creator>Alam, M. Zeshan</dc:creator>
 <dc:creator>Gunturk, Bahadir K.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Light field imaging involves capturing both angular and spatial distribution
of light; it enables new capabilities, such as post-capture digital refocusing,
camera aperture adjustment, perspective shift, and depth estimation. Micro-lens
array (MLA) based light field cameras provide a cost-effective approach to
light field imaging. There are two main limitations of MLA-based light field
cameras: low spatial resolution and narrow baseline. While low spatial
resolution limits the general purpose use and applicability of light field
cameras, narrow baseline limits the depth estimation range and accuracy. In
this paper, we present a hybrid stereo imaging system that includes a light
field camera and a regular camera. The hybrid system addresses both spatial
resolution and narrow baseline issues of the MLA-based light field cameras
while preserving light field imaging capabilities.
</dc:description>
 <dc:description>Comment: Machine Vision and Applications</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05008</dc:identifier>
 <dc:identifier>doi:10.1007/s00138-017-0862-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05009</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OctNet: Learning Deep 3D Representations at High Resolutions</dc:title>
 <dc:creator>Riegler, Gernot</dc:creator>
 <dc:creator>Ulusoy, Ali Osman</dc:creator>
 <dc:creator>Geiger, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present OctNet, a representation for deep learning with sparse 3D data. In
contrast to existing models, our representation enables 3D convolutional
networks which are both deep and high resolution. Towards this goal, we exploit
the sparsity in the input data to hierarchically partition the space using a
set of unbalanced octrees where each leaf node stores a pooled feature
representation. This allows to focus memory allocation and computation to the
relevant dense regions and enables deeper networks without compromising
resolution. We demonstrate the utility of our OctNet representation by
analyzing the impact of resolution on several 3D tasks including 3D object
classification, orientation estimation and point cloud labeling.
</dc:description>
 <dc:description>Comment: CVPR 2017 camera ready</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05010</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anchor-Free Correlated Topic Modeling: Identifiability and Algorithm</dc:title>
 <dc:creator>Huang, Kejun</dc:creator>
 <dc:creator>Fu, Xiao</dc:creator>
 <dc:creator>Sidiropoulos, Nicholas D.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In topic modeling, many algorithms that guarantee identifiability of the
topics have been developed under the premise that there exist anchor words --
i.e., words that only appear (with positive probability) in one topic.
Follow-up work has resorted to three or higher-order statistics of the data
corpus to relax the anchor word assumption. Reliable estimates of higher-order
statistics are hard to obtain, however, and the identification of topics under
those models hinges on uncorrelatedness of the topics, which can be
unrealistic. This paper revisits topic modeling based on second-order moments,
and proposes an anchor-free topic mining framework. The proposed approach
guarantees the identification of the topics under a much milder condition
compared to the anchor-word assumption, thereby exhibiting much better
robustness in practice. The associated algorithm only involves one
eigen-decomposition and a few small linear programs. This makes it easy to
implement and scale up to very large problem instances. Experiments using the
TDT2 and Reuters-21578 corpus demonstrate that the proposed anchor-free
approach exhibits very favorable performance (measured using coherence,
similarity count, and clustering accuracy metrics) compared to the prior art.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05011</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extensive-Form Perfect Equilibrium Computation in Two-Player Games</dc:title>
 <dc:creator>Farina, Gabriele</dc:creator>
 <dc:creator>Gatti, Nicola</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We study the problem of computing an Extensive-Form Perfect Equilibrium
(EFPE) in 2-player games. This equilibrium concept refines the Nash equilibrium
requiring resilience w.r.t. a specific vanishing perturbation (representing
mistakes of the players at each decision node). The scientific challenge is
intrinsic to the EFPE definition: it requires a perturbation over the agent
form, but the agent form is computationally inefficient, due to the presence of
highly nonlinear constraints. We show that the sequence form can be exploited
in a non-trivial way and that, for general-sum games, finding an EFPE is
equivalent to solving a suitably perturbed linear complementarity problem. We
prove that Lemke's algorithm can be applied, showing that computing an EFPE is
$\textsf{PPAD}$-complete. In the notable case of zero-sum games, the problem is
in $\textsf{FP}$ and can be solved by linear programming. Our algorithms also
allow one to find a Nash equilibrium when players cannot perfectly control
their moves, being subject to a given execution uncertainty, as is the case in
most realistic physical settings.
</dc:description>
 <dc:description>Comment: To appear in AAAI 17</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05013</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PixelVAE: A Latent Variable Model for Natural Images</dc:title>
 <dc:creator>Gulrajani, Ishaan</dc:creator>
 <dc:creator>Kumar, Kundan</dc:creator>
 <dc:creator>Ahmed, Faruk</dc:creator>
 <dc:creator>Taiga, Adrien Ali</dc:creator>
 <dc:creator>Visin, Francesco</dc:creator>
 <dc:creator>Vazquez, David</dc:creator>
 <dc:creator>Courville, Aaron</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Natural image modeling is a landmark challenge of unsupervised learning.
Variational Autoencoders (VAEs) learn a useful latent representation and model
global structure well but have difficulty capturing small details. PixelCNN
models details very well, but lacks a latent code and is difficult to scale for
capturing large structures. We present PixelVAE, a VAE model with an
autoregressive decoder based on PixelCNN. Our model requires very few expensive
autoregressive layers compared to PixelCNN and learns latent codes that are
more compressed than a standard VAE while still capturing most non-trivial
structure. Finally, we extend our model to a hierarchy of latent variables at
different scales. Our model achieves state-of-the-art performance on binarized
MNIST, competitive performance on 64x64 ImageNet, and high-quality samples on
the LSUN bedrooms dataset.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05014</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Threshold Routing in a Service System with Highest-Bidder-First and
  FIFO Services</dc:title>
 <dc:creator>Bodas, Tejas</dc:creator>
 <dc:creator>Manjunath, D.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In this paper, we consider a two server system serving heterogeneous
customers. One of the server has a FIFO scheduling policy and charges a fixed
admission price to each customer. The second queue follows the
highest-bidder-first (HBF) policy where an arriving customer bids for its
position in the queue. Customers make an individually optimal choice of the
server and for such system, we characterize the equilibrium routing of
customers. We specifically show that this routing is characterized by two
thresholds.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05015</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Precoder Design for a MIMO Gaussian Wiretap Channel with
  Full-Duplex Source and Destination Nodes</dc:title>
 <dc:creator>Li, Lingxiang</dc:creator>
 <dc:creator>Chen, Zhi</dc:creator>
 <dc:creator>Petropulu, A. P.</dc:creator>
 <dc:creator>Fang, Jun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider linear precoder design for a multiple-input multiple-output
(MIMO) Gaussian wiretap channel, which comprises two legitimate nodes, i.e.,
Alice and Bob, operating in Full-Duplex (FD) mode and exchanging confidential
messages in the presence of a passive eavesdropper. Using the sum secrecy
degrees of freedoms (sum S.D.o.F.) as reliability measure, we formulate an
optimization problem with respect to the precoding matrices. In order to solve
this problem, we first propose a cooperative secrecy transmission scheme, and
prove that its feasible set is sufficient to achieve the maximum sum S.D.o.F..
Based on that feasible set, we then determine the maximum achievable sum
S.D.o.F. in closed form, and provide a method for constructing the precoding
matrix pair which achieves the maximum sum S.D.o.F.. Results show that, the FD
based network provides an attractive secrecy transmission rate performance.
</dc:description>
 <dc:description>Comment: 14 pages, 9 figures</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05026</identifier>
 <datestamp>2017-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Undecidability of Asynchronous Session Subtyping</dc:title>
 <dc:creator>Bravetti, Mario</dc:creator>
 <dc:creator>Carbone, Marco</dc:creator>
 <dc:creator>Zavattaro, Gianluigi</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Session types are used to describe communication protocols in distributed
systems and, as usual in type theories, session subtyping characterizes
substitutability of the communicating processes. We investigate the
(un)decidability of subtyping for session types in asynchronously communicating
systems. We first devise a core undecidable subtyping relation that is obtained
by imposing limitations on the structure of types. Then, as a consequence of
this initial undecidability result, we show that (differently from what stated
or conjectured in the literature) the three notions of asynchronous subtyping
defined so far for session types are all undecidable. Namely, we consider the
asynchronous session subtyping by Mostrous and Yoshida for binary sessions, the
relation by Chen et al. for binary sessions under the assumption that every
message emitted is eventually consumed, and the one by Mostrous et al. for
multiparty session types. Finally, by showing that two fragments of the core
subtyping relation are decidable, we evince that further restrictions on the
structure of types make our core subtyping relation decidable.
</dc:description>
 <dc:description>Comment: 36 pages</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05053</identifier>
 <datestamp>2017-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Detailed Face Reconstruction from a Single Image</dc:title>
 <dc:creator>Richardson, Elad</dc:creator>
 <dc:creator>Sela, Matan</dc:creator>
 <dc:creator>Or-El, Roy</dc:creator>
 <dc:creator>Kimmel, Ron</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Reconstructing the detailed geometric structure of a face from a given image
is a key to many computer vision and graphics applications, such as motion
capture and reenactment. The reconstruction task is challenging as human faces
vary extensively when considering expressions, poses, textures, and intrinsic
geometries. While many approaches tackle this complexity by using additional
data to reconstruct the face of a single subject, extracting facial surface
from a single image remains a difficult problem. As a result, single-image
based methods can usually provide only a rough estimate of the facial geometry.
In contrast, we propose to leverage the power of convolutional neural networks
to produce a highly detailed face reconstruction from a single image. For this
purpose, we introduce an end-to-end CNN framework which derives the shape in a
coarse-to-fine fashion. The proposed architecture is composed of two main
blocks, a network that recovers the coarse facial geometry (CoarseNet),
followed by a CNN that refines the facial features of that geometry (FineNet).
The proposed networks are connected by a novel layer which renders a depth
image given a mesh in 3D. Unlike object recognition and detection problems,
there are no suitable datasets for training CNNs to perform face geometry
reconstruction. Therefore, our training regime begins with a supervised phase,
based on synthetic images, followed by an unsupervised phase that uses only
unconstrained facial images. The accuracy and robustness of the proposed model
is demonstrated by both qualitative and quantitative evaluation tests.
</dc:description>
 <dc:description>Comment: 15 pages, supplementary material included</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05063</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Fluctuating Two-Ray Fading Model: Statistical Characterization and
  Performance Analysis</dc:title>
 <dc:creator>Romero-Jerez, Juan M.</dc:creator>
 <dc:creator>Lopez-Martinez, F. Javier</dc:creator>
 <dc:creator>Paris, Jos&#xe9; F.</dc:creator>
 <dc:creator>Goldsmith, Andrea J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We introduce the Fluctuating Two-Ray (FTR) fading model, a new statistical
channel model that consists of two fluctuating specular components with random
phases plus a diffuse component. The FTR model arises as the natural
generalization of the two-wave with diffuse power (TWDP) fading model; this
generalization allows its two specular components to exhibit a random amplitude
fluctuation. Unlike the TWDP model, all the chief probability functions of the
FTR fading model (PDF, CDF and MGF) are expressed in closed-form, having a
functional form similar to other state-of-the-art fading models. We also
provide approximate closed-form expressions for the PDF and CDF in terms of a
finite number of elementary functions, which allow for a simple evaluation of
these statistics to an arbitrary level of precision. We show that the FTR
fading model provides a much better fit than Rician fading for recent
small-scale fading measurements in 28 GHz outdoor millimeter-wave channels.
Finally, the performance of wireless communication systems over FTR fading is
evaluated in terms of the bit error rate and the outage capacity, and the
interplay between the FTR fading model parameters and the system performance is
discussed. Monte Carlo simulations have been carried out in order to validate
the obtained theoretical expressions.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE for publication. Copyright
  may be transferred without notice, after which this version may no longer be
  accesible</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-05-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05066</identifier>
 <datestamp>2016-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Control for Dynamic Movement Primitives</dc:title>
 <dc:creator>Wensing, Patrick M.</dc:creator>
 <dc:creator>Slotine, Jean-Jacques</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper describes the use of spatially-sparse inputs to influence global
changes in the behavior of Dynamic Movement Primitives (DMPs). The dynamics of
DMPs are analyzed through the framework of contraction theory as networked
hierarchies of contracting or transversely contracting systems. Within this
framework, sparsely-inhibited rhythmic DMPs (SI-RDMPs) are introduced to both
inhibit or enable rhythmic primitives through spatially-sparse modification of
the DMP dynamics. SI-RDMPs are demonstrated in experiments to manage start-stop
transitions for walking experiments with the MIT Cheetah. New analytical
results on the coupling of oscillators with diverse natural frequencies are
also discussed.
</dc:description>
 <dc:description>Comment: extended conference version. added new proofs in the appendix, a few
  remarks in the main body</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2016-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05070</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scaling Laws for Maximum Coloring of Random Geometric Graphs</dc:title>
 <dc:creator>Borst, Sem</dc:creator>
 <dc:creator>Bradonji&#x107;, Milan</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>60C05, 60D05, 60G55, 05C15, 05C80, 68R05, 68R10</dc:subject>
 <dc:description>  We examine maximum vertex coloring of random geometric graphs, in an
arbitrary but fixed dimension, with a constant number of colors. Since this
problem is neither scale-invariant nor smooth, the usual methodology to obtain
limit laws cannot be applied. We therefore leverage different concepts based on
subadditivity to establish convergence laws for the maximum number of vertices
that can be colored. For the constants that appear in these results, we provide
the exact value in dimension one, and upper and lower bounds in higher
dimensions.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05070</dc:identifier>
 <dc:identifier>doi:10.1016/j.dam.2016.10.009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05072</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-ideal memristors for a non-ideal world</dc:title>
 <dc:creator>Gale, Ella</dc:creator>
 <dc:subject>Condensed Matter - Mesoscale and Nanoscale Physics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>68Mxx, 92Exx, 92Fxx, 94Cxx</dc:subject>
 <dc:subject>B.3.1</dc:subject>
 <dc:subject>B.6.1</dc:subject>
 <dc:subject>C.1.3</dc:subject>
 <dc:description>  Memristors have pinched hysteresis loops in the $V-I$ plane. Ideal memristors
are everywhere non-linear, cross at zero and are rotationally symmetric. In
this paper we extend memristor theory to produce different types of
non-ideality and find that: including a background current (such as an ionic
current) moves the crossing point away from zero; including a degradation
resistance (that increases with experimental time) leads to an asymmetry;
modelling a low resistance filament in parallel describes triangular $V-I$
curves with a straight-line low resistance state. A novel measurement of
hysteresis asymmetry was introduced based on hysteresis and it was found that
which lobe was bigger depended on the size of the breaking current relative to
the memristance. The hysteresis varied differently with each type of
non-ideality, suggesting that measurements of several device I-V curves and
calculation of these parameters could give an indication of the underlying
mechanism.
</dc:description>
 <dc:description>Comment: 18 pages, 12 figures, journal paper</dc:description>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05072</dc:identifier>
 <dc:identifier>Phys. Status Solidi A, 212, 2, 229--238 (2015)</dc:identifier>
 <dc:identifier>doi:10.1002/pssa.201400169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05076</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fame and Obsolescence: Disentangling growth and ageing dynamics of
  patent citations</dc:title>
 <dc:creator>Higham, K. W.</dc:creator>
 <dc:creator>Governale, M.</dc:creator>
 <dc:creator>Jaffe, A. B.</dc:creator>
 <dc:creator>Z&#xfc;licke, U.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  We present an analysis of citations accrued over time by patents granted by
the United States Patent and Trademark Office in 1998. In contrast to previous
studies, a disaggregation by technology category is performed, and exogenously
caused citation-number growth is controlled for. Our approach reveals an
intrinsic citation rate that clearly separates into an -- in the long run,
exponentially time-dependent -- ageing function and a completely
time-independent preferential-attachment-type growth kernel. For the general
case of such a separable citation rate, we obtain the time-dependent citation
distribution analytically in a form that is valid for any functional form of
its ageing and growth parts. Good agreement between theory and long-time
characteristics of patent-citation data establishes our work as a useful
framework for addressing still open questions about knowledge-propagation
dynamics, such as the observed excess of citations at short times.
</dc:description>
 <dc:description>Comment: 8 pages, 5 Figures, RevTex4.1, to appear in Phys. Rev. E. v2:
  additional results and more detailed discussion</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05076</dc:identifier>
 <dc:identifier>Phys. Rev. E 95, 042309 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.95.042309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05080</identifier>
 <datestamp>2017-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural stochastic codes, encoding and decoding</dc:title>
 <dc:creator>Eyherabide, Hugo Gabriel</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Understanding brain function, constructing computational models and
engineering neural prosthetics require assessing two problems, namely encoding
and decoding, but their relation remains controversial. For decades, the
encoding problem has been shown to provide insight into the decoding problem,
for example, by upper bounding the decoded information. However, here we show
that this need not be the case when studying response aspects beyond noise
correlations, and trace back the actual causes of this major departure from
traditional views. To that end, we reformulate the encoding and decoding
problems from the observer or organism perspective. In addition, we study the
role of spike-time precision and response discrimination, among other response
aspects, using stochastic transformations of the neural responses, here called
stochastic codes. Our results show that stochastic codes may cause different
information losses when used to describe neural responses and when employed to
train optimal decoders. Therefore, we conclude that response aspects beyond
noise correlations may play different roles in encoding and decoding. In
practice, our results show for the first time that decoders constructed
low-quality descriptions of response aspects may operate optimally on
high-quality descriptions and vice versa, thereby potentially yielding
experimental and computational savings, as well as new opportunities for
simplifying the design of computational brain models and neural prosthetics.
</dc:description>
 <dc:description>Comment: The additional material and some of the theorems have been integrated
  within the main results of the manuscript, and few typos have been corrected</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05083</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Failure Analysis in Model Validation &amp; Verification</dc:title>
 <dc:creator>Ge, Ning</dc:creator>
 <dc:creator>Pantel, Marc</dc:creator>
 <dc:creator>Cr&#xe9;gut, Xavier</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Automated fault localization is an important issue in model validation and
verification. It helps the end users in analyzing the origin of failure. In
this work, we show the early experiments with probabilistic analysis approaches
in fault localization. Inspired by the Kullback-Leibler Divergence from
Bayesian probabilistic theory, we propose a suspiciousness factor to compute
the fault contribution for the transitions in the reachability graph of model
checking, using which to rank the potential faulty transitions. To
automatically locate design faults in the simulation model of detailed design,
we propose to use the statistical model Hidden Markov Model (HMM), which
provides statistically identical information to component's real behavior. The
core of this method is a fault localization algorithm that gives out the set of
suspicious ranked faulty components and a backward algorithm that computes the
matching degree between the HMM and the simulation model to evaluate the
confidence degree of the localization conclusion.
</dc:description>
 <dc:description>Comment: In International Conference on Embedded Real Time Software and
  Systems (ERTS 2014)</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05086</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diploid Alignment is NP-hard</dc:title>
 <dc:creator>Rizzi, Romeo</dc:creator>
 <dc:creator>Cairo, Massimo</dc:creator>
 <dc:creator>M&#xe4;kinen, Veli</dc:creator>
 <dc:creator>Valenzuela, Daniel</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Human genomes consist of pairs of homologous chromosomes, one of which is
inherited from the mother and the other from the father. Species, such as
human, with pairs of homologous chromosomes are called \textit{diploid}.
Sequence analysis literature is, however, almost solely built under the model
of a single \emph{haplotype sequence} representing a species. This fundamental
choice is apparently due to the huge conceptual simplification of carrying out
analyses over sequences rather than over pairs of related sequences. In this
paper, we show that not only raising the abstraction level creates conceptual
difficulties, but also the computational complexity will change for a natural
non-trivial extension of optimal alignment to diploids. As of independent
interest, our approach can also be seen as an extension of sequence alignment
to labelled directed acyclic graphs (labeled DAGs). Namely, we show that a
\emph{covering alignment} of two labeled DAGs is NP-hard. A covering alignment
is to find two paths $P_1(A)$ and $P_2(A)$ in DAG $A$ and two paths $P_1(B)$
and $P_2(B)$ in DAG $B$ that cover the nodes of the graphs and maximize sum of
the global alignment scores: $S(\ell(P_1(A)), \ell(P_1(B))) + S(\ell(P_2(A)),
\ell(P_2(B)))$, where $\ell(P)$ is the concatenation of labels on the path $P$.
Pair-wise alignment of haplotype sequences forming a diploid chromosome can be
converted to a two-path coverable labelled DAG, and then the covering alignment
models the similarity of two diploids over arbitrary recombination.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05087</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Software-defined and Virtualized Cellular Networks with M2M
  Communications</dc:title>
 <dc:creator>Li, Meng</dc:creator>
 <dc:creator>RichardYu, F.</dc:creator>
 <dc:creator>Si, Pengbo</dc:creator>
 <dc:creator>Sun, Enchang</dc:creator>
 <dc:creator>Zhang, Yanhua</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Machine-to-machine (M2M) communications have attracted great attention from
both academia and industry. In this paper, with recent advances in wireless
network virtualization and software-defined networking (SDN), we propose a
novel framework for M2M communications in software-defined cellular networks
with wireless network virtualization. In the proposed framework, according to
different functions and quality of service (QoS) requirements of machine-type
communication devices (MTCDs), a hypervisor enables the virtualization of the
physical M2M network, which is abstracted and sliced into multiple virtual M2M
networks. Moreover, we formulate a decision-theoretic approach to optimize the
random access process of M2M communications. In addition, we develop a feedback
and control loop to dynamically adjust the number of resource blocks (RBs) that
are used in the random access phase in a virtual M2M network by the SDN
controller. Extensive simulation results with different system parameters are
presented to show the performance of the proposed scheme.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1611.04017</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05087</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05088</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning a Deep Embedding Model for Zero-Shot Learning</dc:title>
 <dc:creator>Zhang, Li</dc:creator>
 <dc:creator>Xiang, Tao</dc:creator>
 <dc:creator>Gong, Shaogang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Zero-shot learning (ZSL) models rely on learning a joint embedding space
where both textual/semantic description of object classes and visual
representation of object images can be projected to for nearest neighbour
search. Despite the success of deep neural networks that learn an end-to-end
model between text and images in other vision problems such as image
captioning, very few deep ZSL model exists and they show little advantage over
ZSL models that utilise deep feature representations but do not learn an
end-to-end embedding. In this paper we argue that the key to make deep ZSL
models succeed is to choose the right embedding space. Instead of embedding
into a semantic space or an intermediate space, we propose to use the visual
space as the embedding space. This is because that in this space, the
subsequent nearest neighbour search would suffer much less from the hubness
problem and thus become more effective. This model design also provides a
natural mechanism for multiple semantic modalities (e.g., attributes and
sentence descriptions) to be fused and optimised jointly in an end-to-end
manner. Extensive experiments on four benchmarks show that our model
significantly outperforms the existing models.
</dc:description>
 <dc:description>Comment: To appear in CVPR 2017</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05088</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05092</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Partitioning Strategies and Task Allocation for Target-tracking with
  Multiple Guards in Polygonal Environments</dc:title>
 <dc:creator>Emadi, Hamid</dc:creator>
 <dc:creator>Gao, Tianshuang</dc:creator>
 <dc:creator>Bhattacharya, Sourabh</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents an algorithm to deploy a team of {\it free} guards
equipped with omni-directional cameras for tracking a bounded speed intruder
inside a simply-connected polygonal environment. The proposed algorithm
partitions the environment into smaller polygons, and assigns a guard to each
partition so that the intruder is visible to at least one guard at all times.
Based on the concept of {\it dynamic zones} introduced in this paper, we
propose event-triggered strategies for the guards to track the intruder. We
show that the number of guards deployed by the algorithm for tracking is
strictly less than $\lfloor {\frac{n}{3}} \rfloor$ which is sufficient and
sometimes necessary for coverage. We derive an upper bound on the speed of the
mobile guard required for successful tracking which depends on the intruder's
speed, the road map of the mobile guards, and geometry of the environment.
Finally, we extend the aforementioned analysis to orthogonal polygons, and show
that the upper bound on the number of guards deployed for tracking is strictly
less than $\lfloor {\frac{n}{4}} \rfloor$ which is sufficient and sometimes
necessary for the coverage problem.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05095</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Dexterous Manipulation Policies from Experience and Imitation</dc:title>
 <dc:creator>Kumar, Vikash</dc:creator>
 <dc:creator>Gupta, Abhishek</dc:creator>
 <dc:creator>Todorov, Emanuel</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We explore learning-based approaches for feedback control of a dexterous
five-finger hand performing non-prehensile manipulation. First, we learn local
controllers that are able to perform the task starting at a predefined initial
state. These controllers are constructed using trajectory optimization with
respect to locally-linear time-varying models learned directly from sensor
data. In some cases, we initialize the optimizer with human demonstrations
collected via teleoperation in a virtual environment. We demonstrate that such
controllers can perform the task robustly, both in simulation and on the
physical platform, for a limited range of initial conditions around the trained
starting state. We then consider two interpolation methods for generalizing to
a wider range of initial conditions: deep learning, and nearest neighbors. We
find that nearest neighbors achieve higher performance. Nevertheless, the
neural network has its advantages: it uses only tactile and proprioceptive
feedback but no visual feedback about the object (i.e. it performs the task
blind) and learns a time-invariant policy. In contrast, the nearest neighbors
method switches between time-varying local controllers based on the proximity
of initial object states sensed via motion capture. While both generalization
methods leave room for improvement, our work shows that (i) local
trajectory-based controllers for complex non-prehensile manipulation tasks can
be constructed from surprisingly small amounts of training data, and (ii)
collections of such controllers can be interpolated to form more global
controllers. Results are summarized in the supplementary video:
https://youtu.be/E0wmO6deqjo
</dc:description>
 <dc:description>Comment: Initial draft for a journal submission</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05101</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Parallel Verification of Galois Field Multipliers</dc:title>
 <dc:creator>Yu, Cunxi</dc:creator>
 <dc:creator>Ciesielski, Maciej</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Galois field (GF) arithmetic is used to implement critical arithmetic
components in communication and security-related hardware, and verification of
such components is of prime importance. Current techniques for formally
verifying such components are based on computer algebra methods that proved
successful in verification of integer arithmetic circuits. However, these
methods are sequential in nature and do not offer any parallelism. This paper
presents an algebraic functional verification technique of gate-level GF (2m )
multipliers, in which verification is performed in bit-parallel fashion. The
method is based on extracting a unique polynomial in Galois field of each
output bit independently. We demonstrate that this method is able to verify an
n-bit GF multiplier in n threads. Experiments performed on pre- and
post-synthesized Mastrovito and Montgomery multipliers show high efficiency up
to 571 bits.
</dc:description>
 <dc:description>Comment: 6 pages, 22nd Asia and South Pacific Design Automation Conference
  (ASP-DAC 2017), Japan</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05104</identifier>
 <datestamp>2016-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Way out of the Odyssey: Analyzing and Combining Recent Insights for
  LSTMs</dc:title>
 <dc:creator>Longpre, Shayne</dc:creator>
 <dc:creator>Pradhan, Sabeek</dc:creator>
 <dc:creator>Xiong, Caiming</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  LSTMs have become a basic building block for many deep NLP models. In recent
years, many improvements and variations have been proposed for deep sequence
models in general, and LSTMs in particular. We propose and analyze a series of
augmentations and modifications to LSTM networks resulting in improved
performance for text classification datasets. We observe compounding
improvements on traditional LSTMs using Monte Carlo test-time model averaging,
average pooling, and residual connections, along with four other suggested
modifications. Our analysis provides a simple, reliable, and high quality
baseline model.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2016-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05105</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Well-Typed Languages are Sound</dc:title>
 <dc:creator>Cimini, Matteo</dc:creator>
 <dc:creator>Miller, Dale</dc:creator>
 <dc:creator>Siek, Jeremy G.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:description>  Type soundness is an important property of modern programming languages. In
this paper we explore the idea that &quot;well-typed languages are sound&quot;: the idea
that the appropriate typing discipline over language specifications guarantees
that the language is type sound. We instantiate this idea for a certain class
of languages defined using small step operational semantics by ensuring the
progress and preservation theorems. Our first contribution is a syntactic
discipline for organizing and restricting language specifications so that they
automatically satisfy the progress theorem. This discipline is not novel but
makes explicit the way expert language designers have been organizing a certain
class of languages for long time. We give a formal account of this discipline
by representing language specifications as (higher-order) logic programs and by
giving a meta type system over that collection of formulas. Our second
contribution is a methodology and meta type system for guaranteeing that
languages satisfy the preservation theorem. Ultimately, we proved that language
specifications that conform to our meta type systems are guaranteed to be type
sound. We have implemented these ideas in the TypeSoundnessCertifier, a tool
that takes language specifications in the form of logic programs and type
checks them according to our meta type systems. For those languages that pass
our type checker, our tool automatically produces a proof of type soundness
that can be machine-checked by the Abella proof assistant. For those languages
that fail our type checker, the tool pinpoints the design mistakes that hinder
type soundness. We have applied the TypeSoundnessCertifier to a large number of
programming languages, including those with recursive types, polymorphism,
letrec, exceptions, lists and other common types and operators.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05109</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-rank Bilinear Pooling for Fine-Grained Classification</dc:title>
 <dc:creator>Kong, Shu</dc:creator>
 <dc:creator>Fowlkes, Charless</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Pooling second-order local feature statistics to form a high-dimensional
bilinear feature has been shown to achieve state-of-the-art performance on a
variety of fine-grained classification tasks. To address the computational
demands of high feature dimensionality, we propose to represent the covariance
features as a matrix and apply a low-rank bilinear classifier. The resulting
classifier can be evaluated without explicitly computing the bilinear feature
map which allows for a large reduction in the compute time as well as
decreasing the effective number of parameters to be learned.
  To further compress the model, we propose classifier co-decomposition that
factorizes the collection of bilinear classifiers into a common factor and
compact per-class terms. The co-decomposition idea can be deployed through two
convolutional layers and trained in an end-to-end architecture. We suggest a
simple yet effective initialization that avoids explicitly first training and
factorizing the larger bilinear classifiers. Through extensive experiments, we
show that our model achieves state-of-the-art performance on several public
datasets for fine-grained classification trained with only category labels.
Importantly, our final model is an order of magnitude smaller than the recently
proposed compact bilinear model, and three orders smaller than the standard
bilinear CNN model.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05113</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Diffusion on Region Manifolds: Recovering Small Objects with
  Compact CNN Representations</dc:title>
 <dc:creator>Iscen, Ahmet</dc:creator>
 <dc:creator>Tolias, Giorgos</dc:creator>
 <dc:creator>Avrithis, Yannis</dc:creator>
 <dc:creator>Furon, Teddy</dc:creator>
 <dc:creator>Chum, Ondrej</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Query expansion is a popular method to improve the quality of image retrieval
with both conventional and CNN representations. It has been so far limited to
global image similarity. This work focuses on diffusion, a mechanism that
captures the image manifold in the feature space. The diffusion is carried out
on descriptors of overlapping image regions rather than on a global image
descriptor like in previous approaches. An efficient off-line stage allows
optional reduction in the number of stored regions. In the on-line stage, the
proposed handling of unseen queries in the indexing stage removes additional
computation to adjust the precomputed data. We perform diffusion through a
sparse linear system solver, yielding practical query times well below one
second. Experimentally, we observe a significant boost in performance of image
retrieval with compact CNN descriptors on standard benchmarks, especially when
the query object covers only a small part of the image. Small objects have been
a common failure case of CNN-based retrieval.
</dc:description>
 <dc:description>Comment: CVPR 2017</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05113</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05117</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimation Theory Based Robust Phase Offset Estimation in the Presence
  of Delay Attacks</dc:title>
 <dc:creator>Karthik, Anantha K.</dc:creator>
 <dc:creator>Blum, Rick S.</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper addresses the problem of robust clock phase offset estimation for
the IEEE 1588 precision time protocol (PTP) in the presence of delay attacks.
Delay attacks are one of the most effective cyber attacks in PTP, as they
cannot be mitigated using typical security measures. In this paper, we consider
the case where the slave node can exchange synchronization messages with
multiple master nodes synchronized to the same clock. We first provide lower
bounds on the best achievable performance for any phase offset estimation
scheme in the presence of delay attacks. We then present a novel phase offset
estimation scheme that employs the Expectation-Maximization algorithm for
detecting which of the master-slave communication links have been subject to
delay attacks. After discarding information from the links identified as
attacked, which we show to be optimal, the optimal vector location parameter
estimator is employed to estimate the phase offset of the slave node.
Simulation results are presented to show that the proposed phase offset
estimation scheme exhibits performance close to the lower bounds in a wide
variety of scenarios.
</dc:description>
 <dc:description>Comment: 30 pages, 4 figures, Journal paper</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05118</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Amazing Mysteries of the Gutter: Drawing Inferences Between Panels
  in Comic Book Narratives</dc:title>
 <dc:creator>Iyyer, Mohit</dc:creator>
 <dc:creator>Manjunatha, Varun</dc:creator>
 <dc:creator>Guha, Anupam</dc:creator>
 <dc:creator>Vyas, Yogarshi</dc:creator>
 <dc:creator>Boyd-Graber, Jordan</dc:creator>
 <dc:creator>Daum&#xe9; III, Hal</dc:creator>
 <dc:creator>Davis, Larry</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Visual narrative is often a combination of explicit information and judicious
omissions, relying on the viewer to supply missing details. In comics, most
movements in time and space are hidden in the &quot;gutters&quot; between panels. To
follow the story, readers logically connect panels together by inferring unseen
actions through a process called &quot;closure&quot;. While computers can now describe
what is explicitly depicted in natural images, in this paper we examine whether
they can understand the closure-driven narratives conveyed by stylized artwork
and dialogue in comic book panels. We construct a dataset, COMICS, that
consists of over 1.2 million panels (120 GB) paired with automatic textbox
transcriptions. An in-depth analysis of COMICS demonstrates that neither text
nor image alone can tell a comic book story, so a computer must understand both
modalities to keep up with the plot. We introduce three cloze-style tasks that
ask models to predict narrative and character-centric aspects of a panel given
n preceding panels as context. Various deep neural architectures underperform
human baselines on these tasks, suggesting that COMICS contains fundamental
challenges for both vision and language.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-05-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05122</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrated Resource Management in Software Defined Networking, Caching
  and Computing</dc:title>
 <dc:creator>Chen, Qingxia</dc:creator>
 <dc:creator>Yu, F. Richard</dc:creator>
 <dc:creator>Huang, Tao</dc:creator>
 <dc:creator>Xie, Renchao</dc:creator>
 <dc:creator>Liu, Jiang</dc:creator>
 <dc:creator>Liu, Yunjie</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Recently, there are significant advances in the areas of networking, caching
and computing. Nevertheless, these three important areas have traditionally
been addressed separately in the existing research. In this paper, we present a
novel framework that integrates networking, caching and computing in a
systematic way and enables dynamic orchestration of these three resources to
improve the end-to-end system performance and meet the requirements of
different applications. Then, we consider the bandwidth, caching and computing
resource allocation issue and formulate it as a joint caching/computing
strategy and servers selection problem to minimize the combination cost of
network usage and energy consumption in the framework. To minimize the
combination cost of network usage and energy consumption in the framework, we
formulate it as a joint caching/computing strategy and servers selection
problem. In addition, we solve the joint caching/computing strategy and servers
selection problem using an exhaustive-search algorithm. Simulation results show
that our proposed framework significantly outperforms the traditional network
without in-network caching/computing in terms of network usage and energy
consumption.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05125</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning To Score Olympic Events</dc:title>
 <dc:creator>Parmar, Paritosh</dc:creator>
 <dc:creator>Morris, Brendan Tran</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Estimating action quality, the process of assigning a &quot;score&quot; to the
execution of an action, is crucial in areas such as sports and health care.
Unlike action recognition, which has millions of examples to learn from, the
action quality datasets that are currently available are small -- typically
comprised of only a few hundred samples. This work presents three frameworks
for evaluating Olympic sports which utilize spatiotemporal features learned
using 3D convolutional neural networks (C3D) and perform score regression with
i) SVR, ii) LSTM, and iii) LSTM followed by SVR. An efficient training
mechanism for the limited data scenarios is presented for clip-based training
with LSTM. The proposed systems show significant improvement over existing
quality assessment approaches on the task of predicting scores of Olympic
events {diving, vault, figure skating}. While the SVR-based frameworks yield
better results, LSTM-based frameworks are more natural for describing an action
and can be used for improvement feedback.
</dc:description>
 <dc:description>Comment: CVPR 2017 - CVSports Workshop</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05128</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing Energy-Efficient Convolutional Neural Networks using
  Energy-Aware Pruning</dc:title>
 <dc:creator>Yang, Tien-Ju</dc:creator>
 <dc:creator>Chen, Yu-Hsin</dc:creator>
 <dc:creator>Sze, Vivienne</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep convolutional neural networks (CNNs) are indispensable to
state-of-the-art computer vision algorithms. However, they are still rarely
deployed on battery-powered mobile devices, such as smartphones and wearable
gadgets, where vision algorithms can enable many revolutionary real-world
applications. The key limiting factor is the high energy consumption of CNN
processing due to its high computational complexity. While there are many
previous efforts that try to reduce the CNN model size or amount of
computation, we find that they do not necessarily result in lower energy
consumption, and therefore do not serve as a good metric for energy cost
estimation.
  To close the gap between CNN design and energy consumption optimization, we
propose an energy-aware pruning algorithm for CNNs that directly uses energy
consumption estimation of a CNN to guide the pruning process. The energy
estimation methodology uses parameters extrapolated from actual hardware
measurements that target realistic battery-powered system setups. The proposed
layer-by-layer pruning algorithm also prunes more aggressively than previously
proposed pruning methods by minimizing the error in output feature maps instead
of filter weights. For each layer, the weights are first pruned and then
locally fine-tuned with a closed-form least-square solution to quickly restore
the accuracy. After all layers are pruned, the entire network is further
globally fine-tuned using back-propagation. With the proposed pruning method,
the energy consumption of AlexNet and GoogLeNet are reduced by 3.7x and 1.6x,
respectively, with less than 1% top-5 accuracy loss. Finally, we show that
pruning the AlexNet with a reduced number of target classes can greatly
decrease the number of weights but the energy reduction is limited.
  Energy modeling tool and energy-aware pruned models available at
http://eyeriss.mit.edu/energy.html
</dc:description>
 <dc:description>Comment: Published as a conference paper at CVPR 2017</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05132</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence rate of stochastic k-means</dc:title>
 <dc:creator>Tang, Cheng</dc:creator>
 <dc:creator>Monteleoni, Claire</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We analyze online \cite{BottouBengio} and mini-batch \cite{Sculley} $k$-means
variants. Both scale up the widely used $k$-means algorithm via stochastic
approximation, and have become popular for large-scale clustering and
unsupervised feature learning. We show, for the first time, that starting with
any initial solution, they converge to a &quot;local optimum&quot; at rate
$O(\frac{1}{t})$ (in terms of the $k$-means objective) under general
conditions. In addition, we show if the dataset is clusterable, when
initialized with a simple and scalable seeding algorithm, mini-batch $k$-means
converges to an optimal $k$-means solution at rate $O(\frac{1}{t})$ with high
probability. The $k$-means objective is non-convex and non-differentiable: we
exploit ideas from recent work on stochastic gradient descent for non-convex
problems \cite{ge:sgd_tensor, balsubramani13} by providing a novel
characterization of the trajectory of $k$-means algorithm on its solution
space, and circumvent the non-differentiability problem via geometric insights
about $k$-means update.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1610.04900</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05134</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cost-Sensitive Deep Learning with Layer-Wise Cost Estimation</dc:title>
 <dc:creator>Chung, Yu-An</dc:creator>
 <dc:creator>Lin, Hsuan-Tien</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While deep neural networks have succeeded in several visual applications,
such as object recognition, detection, and localization, by reaching very high
classification accuracies, it is important to note that many real-world
applications demand vary- ing costs for different types of misclassification
errors, thus requiring cost-sensitive classification algorithms. Current models
of deep neural networks for cost-sensitive classification are restricted to
some specific network structures and limited depth. In this paper, we propose a
novel framework that can be applied to deep neural networks with any structure
to facilitate their learning of meaningful representations for cost-sensitive
classification problems. Furthermore, the framework allows end- to-end training
of deeper networks directly. The framework is designed by augmenting auxiliary
neurons to the output of each hidden layer for layer-wise cost estimation, and
including the total estimation loss within the optimization objective.
Experimental results on public benchmark visual data sets with two cost
information settings demonstrate that the proposed frame- work outperforms
state-of-the-art cost-sensitive deep learning models.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05136</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Learning Approach for Skill Evaluation in Robotic-Assisted
  Surgery</dc:title>
 <dc:creator>Fard, Mahtab J.</dc:creator>
 <dc:creator>Ameri, Sattar</dc:creator>
 <dc:creator>Chinnam, Ratna B.</dc:creator>
 <dc:creator>Pandya, Abhilash K.</dc:creator>
 <dc:creator>Klein, Michael D.</dc:creator>
 <dc:creator>Ellis, R. Darin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Evaluating surgeon skill has predominantly been a subjective task.
Development of objective methods for surgical skill assessment are of increased
interest. Recently, with technological advances such as robotic-assisted
minimally invasive surgery (RMIS), new opportunities for objective and
automated assessment frameworks have arisen. In this paper, we applied machine
learning methods to automatically evaluate performance of the surgeon in RMIS.
Six important movement features were used in the evaluation including
completion time, path length, depth perception, speed, smoothness and
curvature. Different classification methods applied to discriminate expert and
novice surgeons. We test our method on real surgical data for suturing task and
compare the classification result with the ground truth data (obtained by
manual labeling). The experimental results show that the proposed framework can
classify surgical skill level with relatively high accuracy of 85.7%. This
study demonstrates the ability of machine learning methods to automatically
classify expert and novice surgeons using movement features for different RMIS
tasks. Due to the simplicity and generalizability of the introduced
classification method, it is easy to implement in existing trainers.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05136</dc:identifier>
 <dc:identifier>Lecture Notes in Engineering and Computer Science: Proceedings of
  The World Congress on Engineering and Computer Science 2016, 19-21 October,
  2016, San Francisco, USA</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05138</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>S3Pool: Pooling with Stochastic Spatial Sampling</dc:title>
 <dc:creator>Zhai, Shuangfei</dc:creator>
 <dc:creator>Wu, Hui</dc:creator>
 <dc:creator>Kumar, Abhishek</dc:creator>
 <dc:creator>Cheng, Yu</dc:creator>
 <dc:creator>Lu, Yongxi</dc:creator>
 <dc:creator>Zhang, Zhongfei</dc:creator>
 <dc:creator>Feris, Rogerio</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Feature pooling layers (e.g., max pooling) in convolutional neural networks
(CNNs) serve the dual purpose of providing increasingly abstract
representations as well as yielding computational savings in subsequent
convolutional layers. We view the pooling operation in CNNs as a two-step
procedure: first, a pooling window (e.g., $2\times 2$) slides over the feature
map with stride one which leaves the spatial resolution intact, and second,
downsampling is performed by selecting one pixel from each non-overlapping
pooling window in an often uniform and deterministic (e.g., top-left) manner.
Our starting point in this work is the observation that this regularly spaced
downsampling arising from non-overlapping windows, although intuitive from a
signal processing perspective (which has the goal of signal reconstruction), is
not necessarily optimal for \emph{learning} (where the goal is to generalize).
We study this aspect and propose a novel pooling strategy with stochastic
spatial sampling (S3Pool), where the regular downsampling is replaced by a more
general stochastic version. We observe that this general stochasticity acts as
a strong regularizer, and can also be seen as doing implicit data augmentation
by introducing distortions in the feature maps. We further introduce a
mechanism to control the amount of distortion to suit different datasets and
architectures. To demonstrate the effectiveness of the proposed approach, we
perform extensive experiments on several popular image classification
benchmarks, observing excellent improvements over baseline models. Experimental
code is available at https://github.com/Shuangfei/s3pool.
</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05138</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05141</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training Spiking Deep Networks for Neuromorphic Hardware</dc:title>
 <dc:creator>Hunsberger, Eric</dc:creator>
 <dc:creator>Eliasmith, Chris</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We describe a method to train spiking deep networks that can be run using
leaky integrate-and-fire (LIF) neurons, achieving state-of-the-art results for
spiking LIF networks on five datasets, including the large ImageNet ILSVRC-2012
benchmark. Our method for transforming deep artificial neural networks into
spiking networks is scalable and works with a wide range of neural
nonlinearities. We achieve these results by softening the neural response
function, such that its derivative remains bounded, and by training the network
with noise to provide robustness against the variability introduced by spikes.
Our analysis shows that implementations of these networks on neuromorphic
hardware will be many times more power-efficient than the equivalent
non-spiking networks on traditional hardware.
</dc:description>
 <dc:description>Comment: 10 pages, 3 figures, 4 tables; the &quot;methods&quot; section of this article
  draws heavily on arXiv:1510.08829</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05141</dc:identifier>
 <dc:identifier>doi:10.13140/RG.2.2.10967.06566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05146</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Semi-Markov Switching Linear Gaussian Model for Censored Physiological
  Data</dc:title>
 <dc:creator>Alaa, Ahmed M.</dc:creator>
 <dc:creator>Yoon, Jinsung</dc:creator>
 <dc:creator>Hu, Scott</dc:creator>
 <dc:creator>van der Schaar, Mihaela</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Critically ill patients in regular wards are vulnerable to unanticipated
clinical dete- rioration which requires timely transfer to the intensive care
unit (ICU). To allow for risk scoring and patient monitoring in such a setting,
we develop a novel Semi- Markov Switching Linear Gaussian Model (SSLGM) for the
inpatients' physiol- ogy. The model captures the patients' latent clinical
states and their corresponding observable lab tests and vital signs. We present
an efficient unsupervised learn- ing algorithm that capitalizes on the
informatively censored data in the electronic health records (EHR) to learn the
parameters of the SSLGM; the learned model is then used to assess the new
inpatients' risk for clinical deterioration in an online fashion, allowing for
timely ICU admission. Experiments conducted on a het- erogeneous cohort of
6,094 patients admitted to a large academic medical center show that the
proposed model significantly outperforms the currently deployed risk scores
such as Rothman index, MEWS, SOFA and APACHE.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05148</identifier>
 <datestamp>2017-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Deep Embedding: An Unsupervised and Generative Approach to
  Clustering</dc:title>
 <dc:creator>Jiang, Zhuxi</dc:creator>
 <dc:creator>Zheng, Yin</dc:creator>
 <dc:creator>Tan, Huachun</dc:creator>
 <dc:creator>Tang, Bangsheng</dc:creator>
 <dc:creator>Zhou, Hanning</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Clustering is among the most fundamental tasks in computer vision and machine
learning. In this paper, we propose Variational Deep Embedding (VaDE), a novel
unsupervised generative clustering approach within the framework of Variational
Auto-Encoder (VAE). Specifically, VaDE models the data generative procedure
with a Gaussian Mixture Model (GMM) and a deep neural network (DNN): 1) the GMM
picks a cluster; 2) from which a latent embedding is generated; 3) then the DNN
decodes the latent embedding into observables. Inference in VaDE is done in a
variational way: a different DNN is used to encode observables to latent
embeddings, so that the evidence lower bound (ELBO) can be optimized using
Stochastic Gradient Variational Bayes (SGVB) estimator and the
reparameterization trick. Quantitative comparisons with strong baselines are
included in this paper, and experimental results show that VaDE significantly
outperforms the state-of-the-art clustering methods on 4 benchmarks from
various modalities. Moreover, by VaDE's generative nature, we show its
capability of generating highly realistic samples for any specified cluster,
without using supervised information during training. Lastly, VaDE is a
flexible and extensible framework for unsupervised generative clustering, more
general mixture models than GMM can be easily plugged in.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures, accepted by IJCAI2017</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-06-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05152</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable and Robust Local Community Detection via Adaptive Subgraph
  Extraction and Diffusions</dc:title>
 <dc:creator>Kloster, Kyle</dc:creator>
 <dc:creator>Li, Yixuan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>91D30</dc:subject>
 <dc:subject>I.5.3</dc:subject>
 <dc:description>  Local community detection, the problem of identifying a set of relevant nodes
nearby a small set of input seed nodes, is an important graph primitive with a
wealth of applications and research activity. Recent approaches include using
local spectral information, graph diffusions, and random walks to determine a
community from input seeds. As networks grow to billions of nodes and exhibit
diverse structures, it is important that community detection algorithms are not
only efficient, but also robust to different structural features.
  Toward this goal, we explore pre-processing techniques and modifications to
existing local methods aimed at improving the scalability and robustness of
algorithms related to community detection. Experiments show that our
modifications improve both speed and quality of existing methods for locating
ground truth communities, and are more robust across graphs and communities of
varying sizes, densities, and diameters. Our subgraph extraction method uses
adaptively selected PageRank parameters to improve on the recall and runtime of
a walk-based pre-processing technique of Li et al. for extracting subgraphs
before searching for a community. We then use this technique to enable the
first scalable implementation of the recent Local Fiedler method of Mahoney et
al. Our experimental evaluation shows our pre-processed version of Local
Fiedler, as well as our novel simplification of the LEMON community detection
framework of Li et al., offer significant speedups over their predecessors and
obtain cluster quality competitive with the state of the art.
</dc:description>
 <dc:description>Comment: 11 Pages, 6 figures, contains link to all software</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05154</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Locomotion of the generalized Purcell's swimmer : Modelling,
  controllability and motion primitives</dc:title>
 <dc:creator>Kadam, Sudin</dc:creator>
 <dc:creator>Banavar, Ravi</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Micro-robotics at low Reynolds number has been a growing area of research
over the past decade. We propose and study a generalized 3-link robotic swimmer
inspired by the planar Purcell's swimmer. By incorporating out-of-plane motion
of the outer limbs, this mechanism generalizes the planar Purcell's swimmer,
which has been widely studied in the literature. Such an evolution of the
limbs' motion results in the swimmer's base link evolving in a 3-dimensional
space. The swimmer's configuration space admits a trivial principal fiber
bundle structure, which along with the slender body theory at the low Reynolds
number regime, facilitates in obtaining a principal kinematic form of the
equations. We derive a coordinate-free expression for the local form of the
kinematic connection. A novel approach for local controllability analysis of
this 3-dimensional swimmer in the low Reynolds number regime is presented by
employing the controllability results of the planar Purcell's swimmer. This is
followed by control synthesis using the motion primitives approach. We prove
the existence of motion primitives based control sequence for maneuvering the
swimmer's base link whose motion evolves on a Lie group. Using the principal
fiber bundle structure, an algorithm for point to point reconfiguration of the
swimmer is presented. A set of control sequences for translational and
rotational maneuvers is then provided along with numerical simulations.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05161</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Possibility and Impossibility of Reliable Broadcast in the Bounded Model</dc:title>
 <dc:creator>Dolev, Danny</dc:creator>
 <dc:creator>Spielrien, Meir</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>D.4.7</dc:subject>
 <dc:subject>F.2.0</dc:subject>
 <dc:description>  The Reliable Broadcast concept allows an honest party to send a message to
all other parties and to make sure that all honest parties receive this
message. In addition, it allows an honest party that received a message to know
that all other honest parties would also receive the same message. This
technique is important to ensure distributed consistency when facing failures.
  In the current paper, we study the ability to use \RR to consistently
transmit a sequence of input values in an asynchronous environment with a
designated sender. The task can be easily achieved using counters, but cannot
be achieved with a bounded memory facing failures. We weaken the problem and
ask whether the receivers can at least share a common suffix. We prove that in
a standard (lossless) asynchronous system no bounded memory protocol can
guarantee a common suffix at all receivers for every input sequence if a single
party might crash.
  We further study the problem facing transient faults and prove that when
limiting the problem to transmitting a stream of a single value being sent
repeatedly we show a bounded memory self-stabilizing protocol that can ensure a
common suffix even in the presence of transient faults and an arbitrary number
of crash faults. We further prove that this last problem is not solvable in the
presence of a single Byzantine fault. Thus, this problem {\bf separates}
Byzantine behavior from crash faults in an asynchronous environment.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05162</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Net-Trim: Convex Pruning of Deep Neural Networks with Performance
  Guarantee</dc:title>
 <dc:creator>Aghasi, Alireza</dc:creator>
 <dc:creator>Abdi, Afshin</dc:creator>
 <dc:creator>Nguyen, Nam</dc:creator>
 <dc:creator>Romberg, Justin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce and analyze a new technique for model reduction for deep neural
networks. While large networks are theoretically capable of learning
arbitrarily complex models, overfitting and model redundancy negatively affects
the prediction accuracy and model variance. Our Net-Trim algorithm prunes
(sparsifies) a trained network layer-wise, removing connections at each layer
by solving a convex optimization program. This program seeks a sparse set of
weights at each layer that keeps the layer inputs and outputs consistent with
the originally trained model. The algorithms and associated analysis are
applicable to neural networks operating with the rectified linear unit (ReLU)
as the nonlinear activation. We present both parallel and cascade versions of
the algorithm. While the latter can achieve slightly simpler models with the
same generalization performance, the former can be computed in a distributed
manner. In both cases, Net-Trim significantly reduces the number of connections
in the network, while also providing enough regularization to slightly reduce
the generalization error. We also provide a mathematical analysis of the
consistency between the initial network and the retrained model. To analyze the
model sample complexity, we derive the general sufficient conditions for the
recovery of a sparse transform matrix. For a single layer taking independent
Gaussian random vectors of length $N$ as inputs, we show that if the network
response can be described using a maximum number of $s$ non-zero weights per
node, these weights can be learned from $\mathcal{O}(s\log N)$ samples.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05164</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Single Chip Self-Tunable N-Input N-Output PID Control System with
  Integrated Analog Front-end for Miniature Robotics</dc:title>
 <dc:creator>Bhandari, Anindya Shankar</dc:creator>
 <dc:creator>Chaudhuri, Arjun</dc:creator>
 <dc:creator>Sharad, Mrigank</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this work, we explore the design of an integrated, low power single chip
multi-channel Proportional-Integral-Derivative (PID) controller for emerging
miniature robotics, that includes N inputs and N corresponding outputs thereby
resulting in N parallel channels in the control system. It includes analog
front-end (AFE) and analog PID controllers for PID parameter tuning based on
PSO algorithm. The AFE incorporates adaptive biasing to ensure low power. The
PSO is optimized with respect to tuning precision, power and area. This makes
it attractive for real-time tuning of multiple miniaturized robotic devices
with a single PSO tuning algorithm block assigned for the task. For simulation
and testing purposes, we take N as 3 with the channels being defined by their
application-ends or plants, namely: dc motor, temperature sensor and gyroscope.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05170</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Effects of Relative Importance of User Constraints in Cloud of
  Things Resource Discovery: A Case Study</dc:title>
 <dc:creator>Nunes, Luiz H.</dc:creator>
 <dc:creator>Estrella, Julio C.</dc:creator>
 <dc:creator>Delbem, Alexandre C. B.</dc:creator>
 <dc:creator>Perera, Charith</dc:creator>
 <dc:creator>Reiff-Marganiec, Stephan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Over the last few years, the number of smart objects connected to the
Internet has grown exponentially in comparison to the number of services and
applications. The integration between Cloud Computing and Internet of Things,
named as Cloud of Things, plays a key role in managing the connected things,
their data and services. One of the main challenges in Cloud of Things is the
resource discovery of the smart objects and their reuse in different contexts.
Most of the existent work uses some kind of multi-criteria decision analysis
algorithm to perform the resource discovery, but do not evaluate the impact
that the user constraints has in the final solution. In this paper, we analyse
the behaviour of the SAW, TOPSIS and VIKOR multi-objective decision analyses
algorithms and the impact of user constraints on them. We evaluated the quality
of the proposed solutions using the Pareto-optimality concept.
</dc:description>
 <dc:description>Comment: Proceedings of the 9th IEEE/ACM International Conference on Utility
  and Cloud Computing (UCC 2016) Shaghai, China, December, 2016</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05170</dc:identifier>
 <dc:identifier>Proceedings of the 9th IEEE/ACM International Conference on
  Utility and Cloud Computing (UCC 2016) Shaghai, China, December, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05172</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-criteria IoT Resource Discovery: A Comparative Analysis</dc:title>
 <dc:creator>Nunes, Luiz H.</dc:creator>
 <dc:creator>Estrella, Julio C.</dc:creator>
 <dc:creator>Perera, Charith</dc:creator>
 <dc:creator>Reiff-Marganiec, Stephan</dc:creator>
 <dc:creator>Delbem, Alexandre N.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The growth of real world objects with embedded and globally networked sensors
allows to consolidate the Internet of Things paradigm and increase the number
of applications in the domains of ubiquitous and context-aware computing. The
merging between Cloud Computing and Internet of Things named Cloud of Things
will be the key to handle thousands of sensors and their data. One of the main
challenges in the Cloud of Things is context-aware sensor search and selection.
Typically, sensors require to be searched using two or more conflicting context
properties. Most of the existing work uses some kind of multi-criteria decision
analysis to perform the sensor search and selection, but does not show any
concern for the quality of the selection presented by these methods. In this
paper, we analyse the behaviour of the SAW, TOPSIS and VIKOR multi-objective
decision methods and their quality of selection comparing them with the
Pareto-optimality solutions. The gathered results allow to analyse and compare
these algorithms regarding their behaviour, the number of optimal solutions and
redundancy.
</dc:description>
 <dc:description>Comment: Software: Practice and Experience</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05172</dc:identifier>
 <dc:identifier>Software: Practice and Experience 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05176</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The strength of the SCT criterion</dc:title>
 <dc:creator>Frittaion, Emanuele</dc:creator>
 <dc:creator>Steila, Silvia</dc:creator>
 <dc:creator>Yokoyama, Keita</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Primary: 03B30, Secondary: 03F35, 03B70</dc:subject>
 <dc:description>  We undertake the study of size-change analysis in the context of Reverse
Mathematics. In particular, we prove that the SCT criterion is equivalent to
$\Sigma^0_2$-induction over RCA$_0$.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05177</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Decoupling in Enabling Energy Aware D2D Communications</dc:title>
 <dc:creator>Giluka, Mukesh Kumar</dc:creator>
 <dc:creator>Khan, M Sigbath Ali</dc:creator>
 <dc:creator>Sathya, Vanlin</dc:creator>
 <dc:creator>Franklin, Antony A</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Downlink/Uplink decoupling (DUDe) in LTE net- works has caught the attention
of researchers as it provides better uplink SINR and reduced power consumption
per device due to decoupled connection of a device with the Macro (in downlink)
and a small cell (in uplink). These characteristics of DUDe can be exploited to
encourage more D2D communications in the network. This paper first proposes a
model to estimate decoupling region within which a device is allowed to perform
DUDe. Then, it formulates an equation to calculate the total power saved by
devices due to decoupling. Finally, the extra area due to decoupling which can
be used to enable D2D pairs is calculated. Simulation results are shown based
on different simulation scenarios for different objectives for better
understanding the idea proposed.
</dc:description>
 <dc:description>Comment: 6 pages, 10 figures, Accepted for the proceedings in IEEE ANTS 2016</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05177</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05181</identifier>
 <datestamp>2017-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Learning from Data under Structural and Laplacian Constraints</dc:title>
 <dc:creator>Egilmez, Hilmi E.</dc:creator>
 <dc:creator>Pavez, Eduardo</dc:creator>
 <dc:creator>Ortega, Antonio</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Graphs are fundamental mathematical structures used in various fields to
represent data, signals and processes. In this paper, we propose a novel
framework for learning/estimating graphs from data. The proposed framework
includes (i) formulation of various graph learning problems, (ii) their
probabilistic interpretations and (iii) associated algorithms. Specifically,
graph learning problems are posed as estimation of graph Laplacian matrices
from some observed data under given structural constraints (e.g., graph
connectivity and sparsity level). From a probabilistic perspective, the
problems of interest correspond to maximum a posteriori (MAP) parameter
estimation of Gaussian-Markov random field (GMRF) models, whose precision
(inverse covariance) is a graph Laplacian matrix. For the proposed graph
learning problems, specialized algorithms are developed by incorporating the
graph Laplacian and structural constraints. The experimental results
demonstrate that the proposed algorithms outperform the current
state-of-the-art methods in terms of accuracy and computational efficiency.
</dc:description>
 <dc:description>Comment: To appear in IEEE Journal of Selected Topics in Signal Processing.
  The implementations of the algorithms proposed in this paper are available
  at: https://github.com/STAC-USC/Graph_Learning</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05181</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05182</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting tala Computationally in Polyphonic Context - A Novel Approach</dc:title>
 <dc:creator>Bhaduri, Susmita</dc:creator>
 <dc:creator>Ghosh, Dipak</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>68T10</dc:subject>
 <dc:subject>I.5.2</dc:subject>
 <dc:description>  In North-Indian-Music-System(NIMS),tabla is mostly used as percussive
accompaniment for vocal-music in polyphonic-compositions. The human auditory
system uses perceptual grouping of musical-elements and easily filters the
tabla component, thereby decoding prominent rhythmic features like tala, tempo
from a polyphonic composition. For Western music, lots of work have been
reported for automated drum analysis of polyphonic composition. However,
attempts at computational analysis of tala by separating the tabla-signal from
mixed signal in NIMS have not been successful. Tabla is played with two
components - right and left. The right-hand component has frequency overlap
with voice and other instruments. So, tala analysis of polyphonic-composition,
by accurately separating the tabla-signal from the mixture is a baffling task,
therefore an area of challenge. In this work we propose a novel technique for
successfully detecting tala using left-tabla signal, producing meaningful
results because the left-tabla normally doesn't have frequency overlap with
voice and other instruments. North-Indian-rhythm follows complex cyclic
pattern, against linear approach of Western-rhythm. We have exploited this
cyclic property along with stressed and non-stressed methods of playing
tabla-strokes to extract a characteristic pattern from the left-tabla strokes,
which, after matching with the grammar of tala-system, determines the tala and
tempo of the composition. A large number of
polyphonic(vocal+tabla+other-instruments) compositions has been analyzed with
the methodology and the result clearly reveals the effectiveness of proposed
techniques.
</dc:description>
 <dc:description>Comment: It is a 20 page document with 8 figures, essentially portrays a
  pattern recognition novel approach to detect tala from a polyphonic song
  having table content and of North-Indian-Music-System(NIMS) genre</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05182</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05183</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coalgebraic trace semantics via forgetful logics</dc:title>
 <dc:creator>Klin, Bartek</dc:creator>
 <dc:creator>Rot, Jurriaan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  We use modal logic as a framework for coalgebraic trace semantics, and show
the flexibility of the approach with concrete examples such as the language
semantics of weighted, alternating and tree automata, and the trace semantics
of generative probabilistic systems. We provide a sufficient condition under
which a logical semantics coincides with the trace semantics obtained via a
given determinization construction. Finally, we consider a condition that
guarantees the existence of a canonical determinization procedure that is
correct with respect to a given logical semantics. That procedure is closely
related to Brzozowski's minimization algorithm.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2016-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05183</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 12, Issue 4 (December
  28, 2016) lmcs:2622</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05186</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Agent Motion Planning and Object Transportation under High Level
  Goals</dc:title>
 <dc:creator>Verginis, Christos</dc:creator>
 <dc:creator>Dimarogonas, Dimos</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a hybrid control framework for the motion planning of a
multi-agent system including N robotic agents and M objects, under high level
goals. In particular, we design control protocols that allow the transition of
the agents as well as the transportation of the objects by the agents, among
predefined regions of interest in the workspace. This allows us to abstract the
coupled behavior of the agents and the objects as a finite transition system
and to design a high-level multi-agent plan that satisfies the agents' and the
objects' specifications, given as temporal logic formulas. Simulation results
verify the proposed framework.
</dc:description>
 <dc:description>Comment: To appear in the World Congress of the International Federation of
  Automatic Control (IFAC), Toulouse, France, July 2017</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05187</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variable Neighborhood Search Algorithms for the multi-depot dial-a-ride
  problem with heterogeneous vehicles and users</dc:title>
 <dc:creator>Detti, Paolo</dc:creator>
 <dc:creator>de Lara, Garazi Zabalo Manrique</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this work, a study on Variable Neighborhood Search algorithms for
multi-depot dial-a-ride problems is presented. In dial-a-ride problems patients
need to be transported from pre-specified pickup locations to pre-specified
delivery locations, under different considerations. The addressed problem
presents several constraints and features, such as heterogeneous vehicles,
distributed in different depots, and heterogeneous patients. The aim is of
minimizing the total routing cost, while respecting time-window, ride-time,
capacity and route duration constraints. The objective of the study is of
determining the best algorithm configuration in terms of initial solution,
neighborhood and local search procedures. At this aim, two different procedures
for the computation of an initial solution, six different type of neighborhoods
and five local search procedures, where only intra-route changes are made, have
been considered and compared.
  We have also evaluated an &quot;adjusting procedure&quot; that aims to produce feasible
solutions from infeasible solutions with small constraints violations. The
different VNS algorithms have been tested on instances from literature as well
as on random instances arising from a real-world healthcare application.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05187</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05190</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Driving CDCL Search</dc:title>
 <dc:creator>Dodaro, Carmine</dc:creator>
 <dc:creator>Gasteiger, Philip</dc:creator>
 <dc:creator>Leone, Nicola</dc:creator>
 <dc:creator>Musitsch, Benjamin</dc:creator>
 <dc:creator>Ricca, Francesco</dc:creator>
 <dc:creator>Schekotihin, Konstantin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The CDCL algorithm is the leading solution adopted by state-of-the-art
solvers for SAT, SMT, ASP, and others. Experiments show that the performance of
CDCL solvers can be significantly boosted by embedding domain-specific
heuristics, especially on large real-world problems. However, a proper
integration of such criteria in off-the-shelf CDCL implementations is not
obvious. In this paper, we distill the key ingredients that drive the search of
CDCL solvers, and propose a general framework for designing and implementing
new heuristics. We implemented our strategy in an ASP solver, and we
experimented on two industrial domains. On hard problem instances,
state-of-the-art implementations fail to find any solution in acceptable time,
whereas our implementation is very successful and finds all solutions.
</dc:description>
 <dc:description>Comment: Paper presented at the 1st Workshop on Trends and Applications of
  Answer Set Programming (TAASP 2016), Klagenfurt, Austria, 26 September 2016,
  15 pages, LaTeX, 5 figures</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05193</identifier>
 <datestamp>2017-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian optimization of hyper-parameters in reservoir computing</dc:title>
 <dc:creator>Yperman, Jan</dc:creator>
 <dc:creator>Becker, Thijs</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We describe a method for searching the optimal hyper-parameters in reservoir
computing, which consists of a Gaussian process with Bayesian optimization. It
provides an alternative to other frequently used optimization methods such as
grid, random, or manual search. In addition to a set of optimal
hyper-parameters, the method also provides a probability distribution of the
cost function as a function of the hyper-parameters. We apply this method to
two types of reservoirs: nonlinear delay nodes and echo state networks. It
shows excellent performance on all considered benchmarks, either matching or
significantly surpassing results found in the literature. In general, the
algorithm achieves optimal results in fewer iterations when compared to other
optimization methods. We have optimized up to six hyper-parameters
simultaneously, which would have been infeasible using, e.g., grid search. Due
to its automated nature, this method significantly reduces the need for expert
knowledge when optimizing the hyper-parameters in reservoir computing. Existing
software libraries for Bayesian optimization, such as Spearmint, make the
implementation of the algorithm straightforward. A fork of the Spearmint
framework along with a tutorial on how to use it in practice is available at
https://bitbucket.org/uhasseltmachinelearning/spearmint/
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-06-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05193</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05196</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cooperative Aerial Coverage Path Planning for Visual Inspection of
  Complex Infrastructures</dc:title>
 <dc:creator>Mansouri, Sina Sharif</dc:creator>
 <dc:creator>Kanellakis, Christoforos</dc:creator>
 <dc:creator>Wuthier, David</dc:creator>
 <dc:creator>Fresk, Emil</dc:creator>
 <dc:creator>Nikolakopoulos, George</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This article addresses the problem of Cooperative Coverage Path Planning
(C-CPP) for the inspection of complex infrastructures (offline 3D
reconstruction) by utilizing multiple Unmanned Autonomous Vehicles (UAVs). The
proposed scheme, based on a priori 3D model of the infrastructure under
inspection, is able to generate multiple paths for UAVs in order to achieve a
complete cooperative coverage in a short time. Initially the infrastructure
under inspection is being sliced by horizontal planes, which has the capability
of recognizing the branches of the structure and these branches will be handled
as breaking points for the path planning of the UAVs to collaboratively execute
the coverage task in less time and more realistically, based on the current
flying times of the UAVs. The multiple data sets collected from the coverage
are merged for the offline sparse and dense 3D reconstruction of the
infrastructure by utilizing SLAM and Structure from Motion approaches, with
either monocular or stereo sensors. The performance of the proposed C-CPP has
been experimentally evaluated in multiple indoor and realistic outdoor
infrastructure inspection experiments.
</dc:description>
 <dc:description>Comment: submitted to IEEE International Conference on Robotics and Automation
  2017</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05198</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One-Shot Video Object Segmentation</dc:title>
 <dc:creator>Caelles, Sergi</dc:creator>
 <dc:creator>Maninis, Kevis-Kokitsi</dc:creator>
 <dc:creator>Pont-Tuset, Jordi</dc:creator>
 <dc:creator>Leal-Taix&#xe9;, Laura</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper tackles the task of semi-supervised video object segmentation,
i.e., the separation of an object from the background in a video, given the
mask of the first frame. We present One-Shot Video Object Segmentation (OSVOS),
based on a fully-convolutional neural network architecture that is able to
successively transfer generic semantic information, learned on ImageNet, to the
task of foreground segmentation, and finally to learning the appearance of a
single annotated object of the test sequence (hence one-shot). Although all
frames are processed independently, the results are temporally coherent and
stable. We perform experiments on two annotated video segmentation databases,
which show that OSVOS is fast and improves the state of the art by a
significant margin (79.8% vs 68.0%).
</dc:description>
 <dc:description>Comment: CVPR 2017 camera ready. Code:
  http://www.vision.ee.ethz.ch/~cvlsegmentation/osvos/</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05203</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Will People Like Your Image? Learning the Aesthetic Space</dc:title>
 <dc:creator>Schwarz, Katharina</dc:creator>
 <dc:creator>Wieschollek, Patrick</dc:creator>
 <dc:creator>Lensch, Hendrik P. A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Rating how aesthetically pleasing an image appears is a highly complex matter
and depends on a large number of different visual factors. Previous work has
tackled the aesthetic rating problem by ranking on a 1-dimensional rating
scale, e.g., incorporating handcrafted attributes. In this paper, we propose a
rather general approach to automatically map aesthetic pleasingness with all
its complexity into an &quot;aesthetic space&quot; to allow for a highly fine-grained
resolution. In detail, making use of deep learning, our method directly learns
an encoding of a given image into this high-dimensional feature space
resembling visual aesthetics. Additionally to the mentioned visual factors,
differences in personal judgments have a large impact on the likeableness of a
photograph. Nowadays, online platforms allow users to &quot;like&quot; or favor certain
content with a single click. To incorporate a huge diversity of people, we make
use of such multi-user agreements and assemble a large data set of 380K images
(AROD) with associated meta information and derive a score to rate how visually
pleasing a given photo is. We validate our derived model of aesthetics in a
user study. Further, without any extra data labeling or handcrafted features,
we achieve state-of-the art accuracy on the AVA benchmark data set. Finally, as
our approach is able to predict the aesthetic quality of any arbitrary image or
video, we demonstrate our results on applications for resorting photo
collections, capturing the best shot on mobile devices and aesthetic key-frame
extraction from videos.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05204</identifier>
 <datestamp>2017-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The emergence and evolution of the research fronts in HIV/AIDS research</dc:title>
 <dc:creator>Fajardo-Ortiz, David</dc:creator>
 <dc:creator>Lopez-Cervantes, Malaquias</dc:creator>
 <dc:creator>Duran, Luis</dc:creator>
 <dc:creator>Dumontier, Michel</dc:creator>
 <dc:creator>Lara, Miguel</dc:creator>
 <dc:creator>Ochoa, Hector</dc:creator>
 <dc:creator>Castano, Victor M</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Quantitative Biology - Other Quantitative Biology</dc:subject>
 <dc:description>  In this paper, we have identified and analyzed the emergence, structure and
dynamics of the paradigmatic research fronts that established the fundamentals
of the biomedical knowledge on HIV/AIDS. A search of papers with the
identifiers &quot;HIV/AIDS&quot;, &quot;Human Immunodeficiency Virus&quot;, &quot;HIV-1&quot; and &quot;Acquired
Immunodeficiency Syndrome&quot; in the Web of Science (Thomson Reuters), was carried
out. A citation network of those papers was constructed. Then, a sub-network of
the papers with the highest number of inter-citations (with a minimal in-degree
of 28) was selected to perform a combination of network clustering and text
mining to identify the paradigmatic research fronts and analyze their dynamics.
Thirteen research fronts were identified in this sub-network. The biggest and
oldest front is related to the clinical knowledge on the disease in the
patient. Nine of the fronts are related to the study of specific molecular
structures and mechanisms and two of these fronts are related to the
development of drugs. The rest of the fronts are related to the study of the
disease at the cellular level. Interestingly, the emergence of these fronts
occurred in successive &quot;waves&quot; over the time which suggest a transition in the
paradigmatic focus. The emergence and evolution of the biomedical fronts in
HIV/AIDS research is explained not just by the partition of the problem in
elements and interactions leading to increasingly specialized communities, but
also by changes in the technological context of this health problem and the
dramatic changes in the epidemiological reality of HIV/AIDS that occurred
between 1993 and 1995.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05204</dc:identifier>
 <dc:identifier>PLoS ONE, 2017 12(5): e0178293</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0178293</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05205</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Search-and-Rescue Rendezvous</dc:title>
 <dc:creator>Leone, Pierre</dc:creator>
 <dc:creator>Alpern, Steve</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We consider a new type of asymmetric rendezvous search problem in which Agent
II needs to give Agent I a `gift' which can be in the form of information or
material. The gift can either be transfered upon meeting, as in traditional
rendezvous, or it can be dropped o? by II at a location he passes, in the hope
it will be found by I. The gift might be a water bottle for a traveller lost in
the desert; a supply cache for Lieutenant Scott in the Antarctic; or important
information (left as a gift). The common aim of the two agents is to minimize
the time taken for I to either meet II or find the gift. We find optimal agent
paths and droppo? times when the search region is a line, the initial distance
between the players is known and one or both of the players can leave gifts.
When there are no gifts this is the classical asymmetric rendezvous problem
solved by Alpern and Gal in 1995 [10]. We exhibit strategies solving these
various problems and use a `rendezvous algorithm' to establish their
optimality.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05206</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Expected values in percentile indicators</dc:title>
 <dc:creator>Bornmann, Lutz</dc:creator>
 <dc:creator>Haunschild, Robin</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  PP(top x%) is the proportion of papers of a unit (e.g. an institution or a
group of researchers), which belongs to the x% most frequently cited papers in
the corresponding fields and publication years. It has been proposed that x% of
papers can be expected which belongs to the x% most frequently cited papers. In
this Letter to the Editor we will present the results of an empirical test
whether we can really have this expectation and how strong the deviations from
the expected values are when many random samples are drawn from the database.
</dc:description>
 <dc:description>Comment: 6 pages with 1 table</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05209</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Variational Inference Without Pixel-Wise Reconstruction</dc:title>
 <dc:creator>Agrawal, Siddharth</dc:creator>
 <dc:creator>Dukkipati, Ambedkar</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Variational autoencoders (VAEs), that are built upon deep neural networks
have emerged as popular generative models in computer vision. Most of the work
towards improving variational autoencoders has focused mainly on making the
approximations to the posterior flexible and accurate, leading to tremendous
progress. However, there have been limited efforts to replace pixel-wise
reconstruction, which have known shortcomings. In this work, we use real-valued
non-volume preserving transformations (real NVP) to exactly compute the
conditional likelihood of the data given the latent distribution. We show that
a simple VAE with this form of reconstruction is competitive with complicated
VAE structures, on image modeling tasks. As part of our model, we develop
powerful conditional coupling layers that enable real NVP to learn with fewer
intermediate layers.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05209</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05215</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Network based Attention for Action Recognition</dc:title>
 <dc:creator>Shi, Yemin</dc:creator>
 <dc:creator>Tian, Yonghong</dc:creator>
 <dc:creator>Wang, Yaowei</dc:creator>
 <dc:creator>Huang, Tiejun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  By extracting spatial and temporal characteristics in one network, the
two-stream ConvNets can achieve the state-of-the-art performance in action
recognition. However, such a framework typically suffers from the separately
processing of spatial and temporal information between the two standalone
streams and is hard to capture long-term temporal dependence of an action. More
importantly, it is incapable of finding the salient portions of an action, say,
the frames that are the most discriminative to identify the action. To address
these problems, a \textbf{j}oint \textbf{n}etwork based \textbf{a}ttention
(JNA) is proposed in this study. We find that the fully-connected fusion,
branch selection and spatial attention mechanism are totally infeasible for
action recognition. Thus in our joint network, the spatial and temporal
branches share some information during the training stage. We also introduce an
attention mechanism on the temporal domain to capture the long-term dependence
meanwhile finding the salient portions. Extensive experiments are conducted on
two benchmark datasets, UCF101 and HMDB51. Experimental results show that our
method can improve the action recognition performance significantly and
achieves the state-of-the-art results on both datasets.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, JNA</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05216</identifier>
 <datestamp>2017-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning long-term dependencies for action recognition with a
  biologically-inspired deep network</dc:title>
 <dc:creator>Shi, Yemin</dc:creator>
 <dc:creator>Tian, Yonghong</dc:creator>
 <dc:creator>Wang, Yaowei</dc:creator>
 <dc:creator>Huang, Tiejun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Despite a lot of research efforts devoted in recent years, how to efficiently
learn long-term dependencies from sequences still remains a pretty challenging
task. As one of the key models for sequence learning, recurrent neural network
(RNN) and its variants such as long short term memory (LSTM) and gated
recurrent unit (GRU) are still not powerful enough in practice. One possible
reason is that they have only feedforward connections, which is different from
the biological neural system that is typically composed of both feedforward and
feedback connections. To address this problem, this paper proposes a
biologically-inspired deep network, called shuttleNet\footnote{Our code is
available at \url{https://github.com/shiyemin/shuttlenet}}. Technologically,
the shuttleNet consists of several processors, each of which is a GRU while
associated with multiple groups of cells and states. Unlike traditional RNNs,
all processors inside shuttleNet are loop connected to mimic the brain's
feedforward and feedback connections, in which they are shared across multiple
pathways in the loop connection. Attention mechanism is then employed to select
the best information flow pathway. Extensive experiments conducted on two
benchmark datasets (i.e UCF101 and HMDB51) show that we can beat
state-of-the-art methods by simply embedding shuttleNet into a CNN-RNN
framework.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05222</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple Yet Effective Methods for Large-Scale Scholarly Publication
  Ranking</dc:title>
 <dc:creator>Herrmannova, Drahomira</dc:creator>
 <dc:creator>Knoth, Petr</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  With the growing amount of published research, automatic evaluation of
scholarly publications is becoming an important task. In this paper we address
this problem and present a simple and transparent approach for evaluating the
importance of scholarly publications. Our method has been ranked among the top
performers in the WSDM Cup 2016 Challenge. The first part of this paper
describes our method. In the second part we present potential improvements to
the method and analyse the evaluation setup which was provided during the
challenge. Finally, we discuss future challenges in automatic evaluation of
papers including the use of full-texts based evaluation methods.
</dc:description>
 <dc:description>Comment: WSDM Cup 2016 - Entity Ranking Challenge. The 9th ACM International
  Conference on Web Search and Data Mining, San Francisco, CA, USA. February
  22-25, 2016</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05225</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Energy-Bandwidth Allocation for Multi-User Channels with
  Cooperating Hybrid Energy Nodes</dc:title>
 <dc:creator>Aggarwal, Vaneet</dc:creator>
 <dc:creator>Bell, Mark R.</dc:creator>
 <dc:creator>Elgabli, Anis</dc:creator>
 <dc:creator>Wang, Xiaodong</dc:creator>
 <dc:creator>Zhong, Shan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider the energy-bandwidth allocation for a network of
multiple users, where the transmitters each powered by both an energy harvester
and conventional grid, access the network orthogonally on the assigned
frequency band. We assume that the energy harvesting state and channel gain of
each transmitter can be predicted for $K$ time slots a priori. The different
transmitters can cooperate by donating energy to each other. The tradeoff among
the weighted sum throughput, the use of grid energy, and the amount of energy
cooperation is studied through an optimization objective which is a linear
combination of these quantities. This leads to an optimization problem with
O($N^2K$) constraints, where $N$ is the total number of transmitter-receiver
pairs, and the optimization is over seven sets of variables that denote energy
and bandwidth allocation, grid energy utilization, and energy cooperation. To
solve the problem efficiently, an iterative algorithm is proposed using the
Proximal Jacobian ADMM. The optimization sub-problems corresponding to Proximal
Jacobian ADMM steps are solved in closed form. We show that this algorithm
converges to the optimal solution with an overall complexity of O($N^2K^2$).
Numerical results show that the proposed algorithms can make efficient use of
the harvested energy, grid energy, energy cooperation, and the available
bandwidth.
</dc:description>
 <dc:description>Comment: Accepted to IEEE Transactions on Vehicular Technology, 11 pages</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-06-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05225</dc:identifier>
 <dc:identifier>doi:10.1109/TVT.2017.2731359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05239</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to do lexical quality estimation of a large OCRed historical Finnish
  newspaper collection with scarce resources</dc:title>
 <dc:creator>Kettunen, Kimmo</dc:creator>
 <dc:creator>P&#xe4;&#xe4;kk&#xf6;nen, Tuula</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The National Library of Finland has digitized the historical newspapers
published in Finland between 1771 and 1910. This collection contains
approximately 1.95 million pages in Finnish and Swedish. Finnish part of the
collection consists of about 2.40 billion words. The National Library's Digital
Collections are offered via the digi.kansalliskirjasto.fi web service, also
known as Digi. Part of the newspaper material (from 1771 to 1874) is also
available freely downloadable in The Language Bank of Finland provided by the
FINCLARIN consortium. The collection can also be accessed through the Korp
environment that has been developed by Spr{\aa}kbanken at the University of
Gothenburg and extended by FINCLARIN team at the University of Helsinki to
provide concordances of text resources. A Cranfield style information retrieval
test collection has also been produced out of a small part of the Digi
newspaper material at the University of Tampere.
  Quality of OCRed collections is an important topic in digital humanities, as
it affects general usability and searchability of collections. There is no
single available method to assess quality of large collections, but different
methods can be used to approximate quality. This paper discusses different
corpus analysis style methods to approximate overall lexical quality of the
Finnish part of the Digi collection. Methods include usage of parallel samples
and word error rates, usage of morphological analyzers, frequency analysis of
words and comparisons to comparable edited lexical data. Our aim in the quality
analysis is twofold: firstly to analyze the present state of the lexical data
and secondly, to establish a set of assessment methods that build up a compact
procedure for quality assessment after e.g. new OCRing or post correction of
the material. In the discussion part of the paper we shall synthesize results
of our different analyses.
</dc:description>
 <dc:description>Comment: 24 pages, 6 tables, 6 figures</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05239</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05241</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Combinatorial Solution to Non-Rigid 3D Shape-to-Image Matching</dc:title>
 <dc:creator>Bernard, Florian</dc:creator>
 <dc:creator>Schmidt, Frank R.</dc:creator>
 <dc:creator>Thunberg, Johan</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We propose a combinatorial solution for the problem of non-rigidly matching a
3D shape to 3D image data. To this end, we model the shape as a triangular mesh
and allow each triangle of this mesh to be rigidly transformed to achieve a
suitable matching to the image. By penalising the distance and the relative
rotation between neighbouring triangles our matching compromises between image
and shape information. In this paper, we resolve two major challenges: Firstly,
we address the resulting large and NP-hard combinatorial problem with a
suitable graph-theoretic approach. Secondly, we propose an efficient
discretisation of the unbounded 6-dimensional Lie group SE(3). To our knowledge
this is the first combinatorial formulation for non-rigid 3D shape-to-image
matching. In contrast to existing local (gradient descent) optimisation
methods, we obtain solutions that do not require a good initialisation and that
are within a bound of the optimal solution. We evaluate the proposed method on
the two problems of non-rigid 3D shape-to-shape and non-rigid 3D shape-to-image
registration and demonstrate that it provides promising results.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05241</dc:identifier>
 <dc:identifier>CVPR 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05244</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Transfer Learning for Person Re-identification</dc:title>
 <dc:creator>Geng, Mengyue</dc:creator>
 <dc:creator>Wang, Yaowei</dc:creator>
 <dc:creator>Xiang, Tao</dc:creator>
 <dc:creator>Tian, Yonghong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Person re-identification (Re-ID) poses a unique challenge to deep learning:
how to learn a deep model with millions of parameters on a small training set
of few or no labels. In this paper, a number of deep transfer learning models
are proposed to address the data sparsity problem. First, a deep network
architecture is designed which differs from existing deep Re-ID models in that
(a) it is more suitable for transferring representations learned from large
image classification datasets, and (b) classification loss and verification
loss are combined, each of which adopts a different dropout strategy. Second, a
two-stepped fine-tuning strategy is developed to transfer knowledge from
auxiliary datasets. Third, given an unlabelled Re-ID dataset, a novel
unsupervised deep transfer learning model is developed based on co-training.
The proposed models outperform the state-of-the-art deep Re-ID models by large
margins: we achieve Rank-1 accuracy of 85.4\%, 83.7\% and 56.3\% on CUHK03,
Market1501, and VIPeR respectively, whilst on VIPeR, our unsupervised model
(45.1\%) beats most supervised models.
</dc:description>
 <dc:description>Comment: 12 pages, 2 figures</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05247</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A new method to index and store spatio-temporal data</dc:title>
 <dc:creator>de Bernardo, Guillermo</dc:creator>
 <dc:creator>Casares, Ram&#xf3;n</dc:creator>
 <dc:creator>G&#xf3;mez-Brand&#xf3;n, Adri&#xe1;n</dc:creator>
 <dc:creator>Param&#xe1;, Jos&#xe9; R.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We propose a data structure that stores, in a compressed way, object
trajectories, which at the same time, allow to efficiently response queries
without the need to decompress the data. We use a data structure, called
$k^{2}$-tree, to store the full position of all objects at regular time
intervals. For storing the positions of objects between two time instants
represented with $k^{2}$-trees, we only encode the relative movements. In order
to save space, those relative moments are encoded with only one integer,
instead of two (x,y)-coordinates. Moreover, the resulting integers are further
compressed with a technique that allows us to manipulate those movements
directly in compressed form. In this paper, we show an experimental evaluation
of this structure, which shows important savings in space and good response
times.
</dc:description>
 <dc:description>Comment: This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05247</dc:identifier>
 <dc:identifier>Proceeding of the 20th Pacific Asia Conference on Information
  Systems (PACIS 2016). Association for Information Systems. AIS Electronic
  Library (AISeL). Paper 93. ISBN: 9789860491029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05248</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental and Fully Dynamic Subgraph Connectivity For Emergency
  Planning</dc:title>
 <dc:creator>Henzinger, Monika</dc:creator>
 <dc:creator>Neumann, Stefan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  During the last 10 years it has become popular to study dynamic graph
problems in a emergency planning or sensitivity setting: Instead of considering
the general fully dynamic problem, we only have to process a single batch
update of size $d$; after the update we have to answer queries.
  In this paper, we consider the dynamic subgraph connectivity problem with
sensitivity $d$: We are given a graph of which some vertices are activated and
some are deactivated. After that we get a single update in which the states of
up to d vertices are changed. Then we get a sequence of connectivity queries in
the subgraph of activated vertices.
  We present the first fully dynamic algorithm for this problem which has an
update and query time only slightly worse than the best decremental algorithm.
In addition, we present the first incremental algorithm which is tight with
respect to the best known conditional lower bound; moreover, the algorithm is
simple and we believe it is implementable and efficient in practice.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05250</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-Time Video Super-Resolution with Spatio-Temporal Networks and
  Motion Compensation</dc:title>
 <dc:creator>Caballero, Jose</dc:creator>
 <dc:creator>Ledig, Christian</dc:creator>
 <dc:creator>Aitken, Andrew</dc:creator>
 <dc:creator>Acosta, Alejandro</dc:creator>
 <dc:creator>Totz, Johannes</dc:creator>
 <dc:creator>Wang, Zehan</dc:creator>
 <dc:creator>Shi, Wenzhe</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural networks have enabled accurate image super-resolution in
real-time. However, recent attempts to benefit from temporal correlations in
video super-resolution have been limited to naive or inefficient architectures.
In this paper, we introduce spatio-temporal sub-pixel convolution networks that
effectively exploit temporal redundancies and improve reconstruction accuracy
while maintaining real-time speed. Specifically, we discuss the use of early
fusion, slow fusion and 3D convolutions for the joint processing of multiple
consecutive video frames. We also propose a novel joint motion compensation and
video super-resolution algorithm that is orders of magnitude more efficient
than competing methods, relying on a fast multi-resolution spatial transformer
module that is end-to-end trainable. These contributions provide both higher
accuracy and temporally more consistent videos, which we confirm qualitatively
and quantitatively. Relative to single-frame models, spatio-temporal networks
can either reduce the computational cost by 30% whilst maintaining the same
quality or provide a 0.2dB gain for a similar computational cost. Results on
publicly available datasets demonstrate that the proposed algorithms surpass
current state-of-the-art performance in both accuracy and efficiency.
</dc:description>
 <dc:description>Comment: Changes: * Uploaded Vid4 results (footnote 1). * Added references
  [14, 29] as spatial-transformer prior art. * Fixed typos</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05250</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05253</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strict upper and lower bounds for quantities of interest in static
  response sensitivity analysis</dc:title>
 <dc:creator>Guo, Mengwu</dc:creator>
 <dc:creator>Zhong, Hongzhi</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  In this paper, a goal-oriented error estimation technique for static response
sensitivity analysis is proposed based on the constitutive relation error (CRE)
estimation for finite element analysis (FEA). Strict upper and lower bounds of
various quantities of interest (QoI) that are associated with the response
sensitivity derivative fields are acquired. Numerical results are presented to
assess the strict bounding properties of the proposed technique.
</dc:description>
 <dc:description>Comment: 20 pages, 14 figures</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05253</dc:identifier>
 <dc:identifier>Applied Mathematical Modelling, 2017, 49: 17-34</dc:identifier>
 <dc:identifier>doi:10.1016/j.apm.2017.04.029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05267</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Convolutional Networks for Action Segmentation and Detection</dc:title>
 <dc:creator>Lea, Colin</dc:creator>
 <dc:creator>Flynn, Michael D.</dc:creator>
 <dc:creator>Vidal, Rene</dc:creator>
 <dc:creator>Reiter, Austin</dc:creator>
 <dc:creator>Hager, Gregory D.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The ability to identify and temporally segment fine-grained human actions
throughout a video is crucial for robotics, surveillance, education, and
beyond. Typical approaches decouple this problem by first extracting local
spatiotemporal features from video frames and then feeding them into a temporal
classifier that captures high-level temporal patterns. We introduce a new class
of temporal models, which we call Temporal Convolutional Networks (TCNs), that
use a hierarchy of temporal convolutions to perform fine-grained action
segmentation or detection. Our Encoder-Decoder TCN uses pooling and upsampling
to efficiently capture long-range temporal patterns whereas our Dilated TCN
uses dilated convolutions. We show that TCNs are capable of capturing action
compositions, segment durations, and long-range dependencies, and are over a
magnitude faster to train than competing LSTM-based Recurrent Neural Networks.
We apply these models to three challenging fine-grained datasets and show large
improvements over the state of the art.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05269</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hilbert Transform, Analytic Signal, and Modulation Analysis for Graph
  Signal Processing</dc:title>
 <dc:creator>Venkitaraman, Arun</dc:creator>
 <dc:creator>Chatterjee, Saikat</dc:creator>
 <dc:creator>H&#xe4;ndel, Peter</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We propose Hilbert transform (HT) and analytic signal (AS) construction for
signals over graphs. This is motivated by the popularity of HT, AS, and
modulation analysis in conventional signal processing, and the observation that
complementary insight is often obtained by viewing conventional signals in the
graph setting. Our definitions of HT and AS use a conjugate-symmetry-like
property exhibited by the graph Fourier transform (GFT). We show that a real
graph signal (GS) can be represented using smaller number of GFT coefficients
than the signal length. We show that the graph HT (GHT) and graph AS (GAS)
operations are linear and shift-invariant over graphs. Using the GAS, we define
the amplitude, phase, and frequency modulations for a graph signal (GS).
Further, we use convex optimization to develop an alternative definition of
envelope for a GS. We illustrate the proposed concepts by showing applications
to synthesized and real-world signals. For example, we show that the GHT is
suitable for anomaly detection/analysis over networks and that GAS reveals
complementary information in speech signals.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-05-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05269</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05271</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeMeshNet: Blind Face Inpainting for Deep MeshFace Verification</dc:title>
 <dc:creator>Zhang, Shu</dc:creator>
 <dc:creator>He, Ran</dc:creator>
 <dc:creator>Tan, Tieniu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  MeshFace photos have been widely used in many Chinese business organizations
to protect ID face photos from being misused. The occlusions incurred by random
meshes severely degenerate the performance of face verification systems, which
raises the MeshFace verification problem between MeshFace and daily photos.
Previous methods cast this problem as a typical low-level vision problem, i.e.
blind inpainting. They recover perceptually pleasing clear ID photos from
MeshFaces by enforcing pixel level similarity between the recovered ID images
and the ground-truth clear ID images and then perform face verification on
them. Essentially, face verification is conducted on a compact feature space
rather than the image pixel space. Therefore, this paper argues that pixel
level similarity and feature level similarity jointly offer the key to improve
the verification performance. Based on this insight, we offer a novel feature
oriented blind face inpainting framework. Specifically, we implement this by
establishing a novel DeMeshNet, which consists of three parts. The first part
addresses blind inpainting of the MeshFaces by implicitly exploiting extra
supervision from the occlusion position to enforce pixel level similarity. The
second part explicitly enforces a feature level similarity in the compact
feature space, which can explore informative supervision from the feature space
to produce better inpainting results for verification. The last part copes with
face alignment within the net via a customized spatial transformer module when
extracting deep facial features. All the three parts are implemented within an
end-to-end network that facilitates efficient optimization. Extensive
experiments on two MeshFace datasets demonstrate the effectiveness of the
proposed DeMeshNet as well as the insight of this paper.
</dc:description>
 <dc:description>Comment: 10pages, submitted to CVPR 17</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05301</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalisation and Sharing in Triplet Convnets for Sketch based Visual
  Search</dc:title>
 <dc:creator>Bui, Tu</dc:creator>
 <dc:creator>Ribeiro, Leonardo</dc:creator>
 <dc:creator>Ponti, Moacir</dc:creator>
 <dc:creator>Collomosse, John</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose and evaluate several triplet CNN architectures for measuring the
similarity between sketches and photographs, within the context of the sketch
based image retrieval (SBIR) task. In contrast to recent fine-grained SBIR
work, we study the ability of our networks to generalise across diverse object
categories from limited training data, and explore in detail strategies for
weight sharing, pre-processing, data augmentation and dimensionality reduction.
We exceed the performance of pre-existing techniques on both the Flickr15k
category level SBIR benchmark by $18\%$, and the TU-Berlin SBIR benchmark by
$\sim10 \mathcal{T}_b$, when trained on the 250 category TU-Berlin
classification dataset augmented with 25k corresponding photographs harvested
from the Internet.
</dc:description>
 <dc:description>Comment: submitted to CVPR2017 on 15Nov16</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05317</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Learning Scheme for Microgrid Islanding and Reconnection</dc:title>
 <dc:creator>Lassetter, Carter</dc:creator>
 <dc:creator>Cotilla-Sanchez, Eduardo</dc:creator>
 <dc:creator>Kim, Jinsub</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper introduces a potential learning scheme that can dynamically
predict the stability of the reconnection of sub-networks to a main grid. As
the future electrical power systems tend towards smarter and greener
technology, the deployment of self sufficient networks, or microgrids, becomes
more likely. Microgrids may operate on their own or synchronized with the main
grid, thus control methods need to take into account islanding and reconnecting
of said networks. The ability to optimally and safely reconnect a portion of
the grid is not well understood and, as of now, limited to raw synchronization
between interconnection points. A support vector machine (SVM) leveraging
real-time data from phasor measurement units (PMUs) is proposed to predict in
real time whether the reconnection of a sub-network to the main grid would lead
to stability or instability. A dynamics simulator fed with pre-acquired system
parameters is used to create training data for the SVM in various operating
states. The classifier was tested on a variety of cases and operating points to
ensure diversity. Accuracies of approximately 85% were observed throughout most
conditions when making dynamic predictions of a given network.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05319</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guidefill: GPU Accelerated, Artist Guided Geometric Inpainting for 3D
  Conversion</dc:title>
 <dc:creator>Hocking, L. Robert</dc:creator>
 <dc:creator>MacKenzie, Russell</dc:creator>
 <dc:creator>Schoenlieb, Carola-Bibiane</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>68U10, 68W10, 65M15</dc:subject>
 <dc:description>  The conversion of traditional film into stereo 3D has become an important
problem in the past decade. One of the main bottlenecks is a disocclusion step,
which in commercial 3D conversion is usually done by teams of artists armed
with a toolbox of inpainting algorithms. A current difficulty in this is that
most available algorithms are either too slow for interactive use, or provide
no intuitive means for users to tweak the output. In this paper we present a
new fast inpainting algorithm based on transporting along automatically
detected splines, which the user may edit. Our algorithm is implemented on the
GPU and fills the inpainting domain in successive shells that adapt their shape
on the fly. In order to allocate GPU resources as efficiently as possible, we
propose a parallel algorithm to track the inpainting interface as it evolves,
ensuring that no resources are wasted on pixels that are not currently being
worked on. Theoretical analysis of the time and processor complexiy of our
algorithm without and with tracking (as well as numerous numerical experiments)
demonstrate the merits of the latter. Our transport mechanism is similar to the
one used in coherence transport, but improves upon it by corrected a &quot;kinking&quot;
phenomena whereby extrapolated isophotes may bend at the boundary of the
inpainting domain. Theoretical results explaining this phenomena and its
resolution are presented. Although our method ignores texture, in many cases
this is not a problem due to the thin inpainting domains in 3D conversion.
Experimental results show that our method can achieve a visual quality that is
competitive with the state-of-the-art while maintaining interactive speeds and
providing the user with an intuitive interface to tweak the results.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05321</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Semi-supervised Framework for Image Captioning</dc:title>
 <dc:creator>Chen, Wenhu</dc:creator>
 <dc:creator>Lucchi, Aurelien</dc:creator>
 <dc:creator>Hofmann, Thomas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  State-of-the-art approaches for image captioning require supervised training
data consisting of captions with paired image data. These methods are typically
unable to use unsupervised data such as textual data with no corresponding
images, which is a much more abundant commodity. We here propose a novel way of
using such textual data by artificially generating missing visual information.
We evaluate this learning approach on a newly designed model that detects
visual concepts present in an image and feed them to a reviewer-decoder
architecture with an attention mechanism. Unlike previous approaches that
encode visual concepts using word embeddings, we instead suggest using regional
image features which capture more intrinsic information. The main benefit of
this architecture is that it synthesizes meaningful thought vectors that
capture salient image properties and then applies a soft attentive decoder to
decode the thought vectors and generate image captions. We evaluate our model
on both Microsoft COCO and Flickr30K datasets and demonstrate that this model
combined with our semi-supervised learning method can largely improve
performance and help the model to generate more accurate and diverse captions.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-06-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05322</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Capacity Region of the Two-User Gaussian Interference
  Channel with Noisy Channel-Output Feedback</dc:title>
 <dc:creator>Quintero, Victor</dc:creator>
 <dc:creator>Perlaza, Samir M.</dc:creator>
 <dc:creator>Esnaola, I&#xf1;aki</dc:creator>
 <dc:creator>Gorce, Jean-Marie</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, the capacity region of the linear deterministic interference
channel with noisy channel-output feedback (LD-IC-NOF) is fully characterized.
A capacity-achieving scheme is obtained using a random coding argument and
three well-known techniques: rate splitting, superposition coding and backward
decoding. The converse region is obtained using some of the existing outer
bounds as well as a set of new outer bounds that are obtained by using
genie-aided models of the original LD-IC-NOF. Using the insights gained from
the analysis of the LD-IC-NOF, an achievability region and a converse region
for the two-user Gaussian interference channel with noisy channel-output
feedback (G-IC-NOF) are presented. Finally, the achievability region and the
converse region approximate the capacity region of the G-IC-NOF to within 4.4
bits.
</dc:description>
 <dc:description>Comment: This work was submitted to the IEEE Transactions on Information
  Theory in November 10 2016. Part of this work was presented at the IEEE
  International Workshop on Information Theory (ITW), Cambridge, United
  Kingdom, September, 2016 (arXiv:1603.07554), and IEEE International Workshop
  on Information Theory (ITW), Jeju Island, Korea, October, 2015
  (arXiv:1502.04649). Parts of this work appear in INRIA Research Reports 0456
  (arXiv:1608.08920) and 8861 (arXiv:1608.08907)</dc:description>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05328</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Credibility Analysis with Effective Domain Transferred Deep
  Networks</dc:title>
 <dc:creator>Jin, Zhiwei</dc:creator>
 <dc:creator>Cao, Juan</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:creator>Zhang, Yongdong</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Numerous fake images spread on social media today and can severely jeopardize
the credibility of online content to public. In this paper, we employ deep
networks to learn distinct fake image related features. In contrast to
authentic images, fake images tend to be eye-catching and visually striking.
Compared with traditional visual recognition tasks, it is extremely challenging
to understand these psychologically triggered visual patterns in fake images.
Traditional general image classification datasets, such as ImageNet set, are
designed for feature learning at the object level but are not suitable for
learning the hyper-features that would be required by image credibility
analysis. In order to overcome the scarcity of training samples of fake images,
we first construct a large-scale auxiliary dataset indirectly related to this
task. This auxiliary dataset contains 0.6 million weakly-labeled fake and real
images collected automatically from social media. Through an AdaBoost-like
transfer learning algorithm, we train a CNN model with a few instances in the
target training set and 0.6 million images in the collected auxiliary set. This
learning algorithm is able to leverage knowledge from the auxiliary set and
gradually transfer it to the target task. Experiments on a real-world testing
set show that our proposed domain transferred CNN model outperforms several
competing baselines. It obtains superiror results over transfer learning
methods based on the general ImageNet set. Moreover, case studies show that our
proposed method reveals some interesting patterns for distinguishing fake and
authentic images.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05335</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Learning of Important Objects from First-Person Videos</dc:title>
 <dc:creator>Bertasius, Gedas</dc:creator>
 <dc:creator>Park, Hyun Soo</dc:creator>
 <dc:creator>Yu, Stella X.</dc:creator>
 <dc:creator>Shi, Jianbo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A first-person camera, placed at a person's head, captures, which objects are
important to the camera wearer. Most prior methods for this task learn to
detect such important objects from the manually labeled first-person data in a
supervised fashion. However, important objects are strongly related to the
camera wearer's internal state such as his intentions and attention, and thus,
only the person wearing the camera can provide the importance labels. Such a
constraint makes the annotation process costly and limited in scalability.
  In this work, we show that we can detect important objects in first-person
images without the supervision by the camera wearer or even third-person
labelers. We formulate an important detection problem as an interplay between
the 1) segmentation and 2) recognition agents. The segmentation agent first
proposes a possible important object segmentation mask for each image, and then
feeds it to the recognition agent, which learns to predict an important object
mask using visual semantics and spatial features.
  We implement such an interplay between both agents via an alternating
cross-pathway supervision scheme inside our proposed Visual-Spatial Network
(VSN). Our VSN consists of spatial (&quot;where&quot;) and visual (&quot;what&quot;) pathways, one
of which learns common visual semantics while the other focuses on the spatial
location cues. Our unsupervised learning is accomplished via a cross-pathway
supervision, where one pathway feeds its predictions to a segmentation agent,
which proposes a candidate important object segmentation mask that is then used
by the other pathway as a supervisory signal. We show our method's success on
two different important object datasets, where our method achieves similar or
better results as the supervised methods.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05339</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CareerMapper: An Automated Resume Evaluation Tool</dc:title>
 <dc:creator>Lai, Vivian</dc:creator>
 <dc:creator>Shim, Kyong Jin</dc:creator>
 <dc:creator>Oentaryo, Richard J.</dc:creator>
 <dc:creator>Prasetyo, Philips K.</dc:creator>
 <dc:creator>Vu, Casey</dc:creator>
 <dc:creator>Lim, Ee-Peng</dc:creator>
 <dc:creator>Lo, David</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The advent of the Web brought about major changes in the way people search
for jobs and companies look for suitable candidates. As more employers and
recruitment firms turn to the Web for job candidate search, an increasing
number of people turn to the Web for uploading and creating their online
resumes. Resumes are often the first source of information about candidates and
also the first item of evaluation in candidate selection. Thus, it is
imperative that resumes are complete, free of errors and well-organized. We
present an automated resume evaluation tool called &quot;CareerMapper&quot;. Our tool is
designed to conduct a thorough review of a user's LinkedIn profile and provide
best recommendations for improved online resumes by analyzing a large number of
online user profiles.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05339</dc:identifier>
 <dc:identifier>Proceedings of the IEEE International Conference on Big Data (IEEE
  BigData 2016)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05340</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximating Wisdom of Crowds using K-RBMs</dc:title>
 <dc:creator>Gupta, Abhay</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  An important way to make large training sets is to gather noisy labels from
crowds of non experts. We propose a method to aggregate noisy labels collected
from a crowd of workers or annotators. Eliciting labels is important in tasks
such as judging web search quality and rating products. Our method assumes that
labels are generated by a probability distribution over items and labels. We
formulate the method by drawing parallels between Gaussian Mixture Models
(GMMs) and Restricted Boltzmann Machines (RBMs) and show that the problem of
vote aggregation can be viewed as one of clustering. We use K-RBMs to perform
clustering. We finally show some empirical evaluations over real datasets.
</dc:description>
 <dc:description>Comment: 8 pages, 1 figure</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05342</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximately Efficient Two-Sided Combinatorial Auctions</dc:title>
 <dc:creator>Colini-Baldeschi, Riccardo</dc:creator>
 <dc:creator>Goldberg, Paul</dc:creator>
 <dc:creator>de Keijzer, Bart</dc:creator>
 <dc:creator>Leonardi, Stefano</dc:creator>
 <dc:creator>Roughgarden, Tim</dc:creator>
 <dc:creator>Turchetta, Stefano</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Mechanism design for one-sided markets has been investigated for several
decades in economics and in computer science. More recently, there has been an
increased attention on mechanisms for two-sided markets, in which buyers and
sellers act strategically. For two-sided markets, an impossibility result of
Myerson and Satterthwaite states that no mechanism can simultaneously satisfy
individual rationality (IR), incentive compatibility (IC), strong
budget-balance (SBB), and be efficient. On the other hand, important
applications to web advertisement, stock exchange, and frequency spectrum
allocation, require us to consider two-sided combinatorial auctions in which
buyers have preferences on subsets of items, and sellers may offer multiple
heterogeneous items. No efficient mechanism was known so far for such two-sided
combinatorial markets. This work provides the first IR, IC and SBB mechanisms
that provides an O(1)-approximation to the optimal social welfare for two-sided
markets. An initial construction yields such a mechanism, but exposes a
conceptual problem in the traditional SBB notion. This leads us to define the
stronger notion of direct trade strong budget balance (DSBB). We then proceed
to design mechanisms that are IR, IC, DSBB, and again provide an
O(1)-approximation to the optimal social welfare. Our mechanisms work for any
number of buyers with XOS valuations - a class in between submodular and
subadditive functions - and any number of sellers. We provide a mechanism that
is dominant strategy incentive compatible (DSIC) if the sellers each have one
item for sale, and one that is bayesian incentive compatible (BIC) if sellers
hold multiple items and have additive valuations over them. Finally, we present
a DSIC mechanism for the case that the valuation functions of all buyers and
sellers are additive.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05345</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly Supervised Top-down Salient Object Detection</dc:title>
 <dc:creator>Cholakkal, Hisham</dc:creator>
 <dc:creator>Johnson, Jubin</dc:creator>
 <dc:creator>Rajan, Deepu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Top-down saliency models produce a probability map that peaks at target
locations specified by a task/goal such as object detection. They are usually
trained in a fully supervised setting involving pixel-level annotations of
objects. We propose a weakly supervised top-down saliency framework using only
binary labels that indicate the presence/absence of an object in an image.
First, the probabilistic contribution of each image region to the confidence of
a CNN-based image classifier is computed through a backtracking strategy to
produce top-down saliency. From a set of saliency maps of an image produced by
fast bottom-up saliency approaches, we select the best saliency map suitable
for the top-down task. The selected bottom-up saliency map is combined with the
top-down saliency map. Features having high combined saliency are used to train
a linear SVM classifier to estimate feature saliency. This is integrated with
combined saliency and further refined through a multi-scale
superpixel-averaging of saliency map. We evaluate the performance of the
proposed weakly supervised top-down saliency against fully supervised
approaches and achieve state-of-the-art performance. Experiments are carried
out on seven challenging datasets and quantitative results are compared with 36
closely related approaches across 4 different applications.
</dc:description>
 <dc:description>Comment: 14 pages, 12 figures</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05346</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>File Synchronization Systems Survey</dc:title>
 <dc:creator>Mehdi, Zulqarnain</dc:creator>
 <dc:creator>Ragab-Hassen, Hani</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Several solutions exist for file storage, sharing, and synchronization. Many
of them involve a central server, or a collection of servers, that either store
the files, or act as a gateway for them to be shared. Some systems take a
decentralized approach, wherein interconnected users form a peer-to-peer (P2P)
network, and partake in the sharing process: they share the files they possess
with others, and can obtain the files owned by other peers. In this paper, we
survey various technologies, both cloud-based and P2P-based, that users use to
synchronize their files across the network, and discuss their strengths and
weaknesses.
</dc:description>
 <dc:description>Comment: The Sixth International Conference on Computer Science, Engineering &amp;
  Applications (ICCSEA 2016)</dc:description>
 <dc:date>2016-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05346</dc:identifier>
 <dc:identifier>ICCSEA 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05352</identifier>
 <datestamp>2017-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing DF Cognitive Radio Networks with Full-Duplex-Enabled Energy
  Access Points</dc:title>
 <dc:creator>Xing, Hong</dc:creator>
 <dc:creator>Kang, Xin</dc:creator>
 <dc:creator>Wong, Kai-Kit</dc:creator>
 <dc:creator>Nallanathan, Arumugam</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  With the recent advances in radio frequency (RF) energy harvesting (EH)
technologies, wireless powered cooperative cognitive radio network (CCRN) has
drawn an upsurge of interest for improving the spectrum utilization with
incentive to motivate joint information and energy cooperation between the
primary and secondary systems. Dedicated energy beamforming (EB) is aimed for
remedying the low efficiency of wireless power transfer (WPT), which
nevertheless arouses out-of-band EH phases and thus low cooperation efficiency.
To address this issue, in this paper, we consider a novel RF EH CCRN aided by
full-duplex (FD)-enabled energy access points (EAPs) that can cooperate to
wireless charge the secondary transmitter (ST) while concurrently receiving
primary transmitter (PT)'s signal in the first transmission phase, and to
perform decode-and-forward (DF) relaying in the second transmission phase. We
investigate a weighted sum-rate maximization problem subject to the
transmitting power constraints as well as a total cost constraint using
successive convex approximation (SCA) techniques. A zero-forcing (ZF) based
suboptimal scheme that requires only local CSIs for the EAPs to obtain their
optimum receive beamforming is also derived. Various tradeoffs between the
weighted sum-rate and other system parameters are provided in numerical results
to corroborate the effectiveness of the proposed solutions against the
benchmark ones.
</dc:description>
 <dc:description>Comment: 30 pages, 10 figures, submitted for possible journal publication</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05352</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05353</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context Awareness in Next Generation of Mobile Core Networks</dc:title>
 <dc:creator>Marquezan, Clarissa Cassales</dc:creator>
 <dc:creator>Mahmood, Kashif</dc:creator>
 <dc:creator>Zafeiropoulos, Anastasios</dc:creator>
 <dc:creator>Krishna, Renan</dc:creator>
 <dc:creator>Huang, Xiaofeng</dc:creator>
 <dc:creator>An, Xueli</dc:creator>
 <dc:creator>Corujo, Daniel</dc:creator>
 <dc:creator>Leit&#xe3;o, Filipe</dc:creator>
 <dc:creator>Rosas, Maria Lema</dc:creator>
 <dc:creator>Einsiedler, Hans</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>68M10</dc:subject>
 <dc:description>  Context awareness is an important enabler for next generation of Mobile Core
Networks (MCN). However there exist a number of challenges in this regard. For
example how to develop a framework which 1) is able to generate context richer
than what is available today; 2) allows reusability of context across the
network; 3) provides a mechanism for exposing context to third parties; and 4)
can bring together &quot;big data&quot; for mobile core network optimization. In this
work, we introduce a context awareness framework addressing the aforementioned
challenges but also taking into account the 3GPP standardization activities
related to context awareness in MCN. Within this framework we propose Context
Generation and Handling Function (CGHF) which generates rich context by
processing information from various sources and then handles its distribution
through an efficient publish subscribe mechanism. In addition we provide
examples where context can be used to optimize control plane decision making.
While the focus of this work is on the use of context for MCN, we still believe
such context can be also used by applications (at the edge as well as in data
centers) and third party services to improve their operations and providing new
unforeseen services.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05353</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05356</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Interconnected Virtual Reality: Opportunities, Challenges and
  Enablers</dc:title>
 <dc:creator>Ba&#x15f;tu&#x11f;, Ejder</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:creator>M&#xe9;dard, Muriel</dc:creator>
 <dc:creator>Debbah, M&#xe9;rouane</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Just recently, the concept of augmented and virtual reality (AR/VR) over
wireless has taken the entire 5G ecosystem by storm spurring an unprecedented
interest from both academia, industry and others. Yet, the success of an
immersive VR experience hinges on solving a plethora of grand challenges
cutting across multiple disciplines. This article underscores the importance of
VR technology as a disruptive use case of 5G (and beyond) harnessing the latest
development of storage/memory, fog/edge computing, computer vision, artificial
intelligence and others. In particular, the main requirements of wireless
interconnected VR are described followed by a selection of key enablers, then,
research avenues and their underlying grand challenges are presented.
Furthermore, we examine three VR case studies and provide numerical results
under various storage, computing and network configurations. Finally, this
article exposes the limitations of current networks and makes the case for more
theory, and innovations to spearhead VR for the masses.
</dc:description>
 <dc:description>Comment: a version of this paper has been accepted to IEEE Communications
  Magazine, Special Issue on Agile Radio Resource Management Techniques for 5G
  New Radio. 7 pages, 6 figures</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05358</identifier>
 <datestamp>2017-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lip Reading Sentences in the Wild</dc:title>
 <dc:creator>Chung, Joon Son</dc:creator>
 <dc:creator>Senior, Andrew</dc:creator>
 <dc:creator>Vinyals, Oriol</dc:creator>
 <dc:creator>Zisserman, Andrew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The goal of this work is to recognise phrases and sentences being spoken by a
talking face, with or without the audio. Unlike previous works that have
focussed on recognising a limited number of words or phrases, we tackle lip
reading as an open-world problem - unconstrained natural language sentences,
and in the wild videos.
  Our key contributions are: (1) a 'Watch, Listen, Attend and Spell' (WLAS)
network that learns to transcribe videos of mouth motion to characters; (2) a
curriculum learning strategy to accelerate training and to reduce overfitting;
(3) a 'Lip Reading Sentences' (LRS) dataset for visual speech recognition,
consisting of over 100,000 natural sentences from British television.
  The WLAS model trained on the LRS dataset surpasses the performance of all
previous work on standard lip reading benchmark datasets, often by a
significant margin. This lip reading performance beats a professional lip
reader on videos from BBC television, and we also demonstrate that visual
information helps to improve speech recognition performance even when the audio
is available.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05359</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Longest Common Extensions with Recompression</dc:title>
 <dc:creator>I, Tomohiro</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Given two positions $i$ and $j$ in a string $T$ of length $N$, a longest
common extension (LCE) query asks for the length of the longest common prefix
between suffixes beginning at $i$ and $j$. A compressed LCE data structure is a
data structure that stores $T$ in a compressed form while supporting fast LCE
queries. In this article we show that the recompression technique is a powerful
tool for compressed LCE data structures. We present a new compressed LCE data
structure of size $O(z \lg (N/z))$ that supports LCE queries in $O(\lg N)$
time, where $z$ is the size of Lempel-Ziv 77 factorization without
self-reference of $T$. Given $T$ as an uncompressed form, we show how to build
our data structure in $O(N)$ time and space. Given $T$ as a grammar compressed
form, i.e., an straight-line program of size n generating $T$, we show how to
build our data structure in $O(n \lg (N/n))$ time and $O(n + z \lg (N/z))$
space. Our algorithms are deterministic and always return correct answers.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05360</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Life of Lazarillo de Tormes and of His Machine Learning Adversities</dc:title>
 <dc:creator>de la Rosa, Javier</dc:creator>
 <dc:creator>Su&#xe1;rez, Juan-Luis</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Summit work of the Spanish Golden Age and forefather of the so-called
picaresque novel, The Life of Lazarillo de Tormes and of His Fortunes and
Adversities still remains an anonymous text. Although distinguished scholars
have tried to attribute it to different authors based on a variety of criteria,
a consensus has yet to be reached. The list of candidates is long and not all
of them enjoy the same support within the scholarly community. Analyzing their
works from a data-driven perspective and applying machine learning techniques
for style and text fingerprinting, we shed light on the authorship of the
Lazarillo. As in a state-of-the-art survey, we discuss the methods used and how
they perform in our specific case. According to our methodology, the most
likely author seems to be Juan Arce de Ot\'alora, closely followed by Alfonso
de Vald\'es. The method states that not certain attribution can be made with
the given corpus.
</dc:description>
 <dc:description>Comment: 66 pages, 11 figures</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05360</dc:identifier>
 <dc:identifier>Lemir: Revista de Literatura Espa\~nola Medieval y del
  Renacimiento, 20 (2016)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05362</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Outsmarting Network Security with SDN Teleportation</dc:title>
 <dc:creator>Thimmaraju, Kashyap</dc:creator>
 <dc:creator>Schiff, Liron</dc:creator>
 <dc:creator>Schmid, Stefan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Software-defined networking is considered a promising new paradigm, enabling
more reliable and formally verifiable communication networks. However, this
paper shows that the separation of the control plane from the data plane, which
lies at the heart of Software-Defined Networks (SDNs), introduces a new
vulnerability which we call \emph{teleportation}. An attacker (e.g., a
malicious switch in the data plane or a host connected to the network) can use
teleportation to transmit information via the control plane and bypass critical
network functions in the data plane (e.g., a firewall), and to violate security
policies as well as logical and even physical separations. This paper
characterizes the design space for teleportation attacks theoretically, and
then identifies four different teleportation techniques. We demonstrate and
discuss how these techniques can be exploited for different attacks (e.g.,
exfiltrating confidential data at high rates), and also initiate the discussion
of possible countermeasures. Generally, and given today's trend toward more
intent-based networking, we believe that our findings are relevant beyond the
use cases considered in this paper.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05362</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05365</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Am I a Baller? Basketball Performance Assessment from First-Person
  Videos</dc:title>
 <dc:creator>Bertasius, Gedas</dc:creator>
 <dc:creator>Park, Hyun Soo</dc:creator>
 <dc:creator>Yu, Stella X.</dc:creator>
 <dc:creator>Shi, Jianbo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a method to assess a basketball player's performance from
his/her first-person video. A key challenge lies in the fact that the
evaluation metric is highly subjective and specific to a particular evaluator.
We leverage the first-person camera to address this challenge. The
spatiotemporal visual semantics provided by a first-person view allows us to
reason about the camera wearer's actions while he/she is participating in an
unscripted basketball game. Our method takes a player's first-person video and
provides a player's performance measure that is specific to an evaluator's
preference.
  To achieve this goal, we first use a convolutional LSTM network to detect
atomic basketball events from first-person videos. Our network's ability to
zoom-in to the salient regions addresses the issue of a severe camera wearer's
head movement in first-person videos. The detected atomic events are then
passed through the Gaussian mixtures to construct a highly non-linear visual
spatiotemporal basketball assessment feature. Finally, we use this feature to
learn a basketball assessment model from pairs of labeled first-person
basketball videos, for which a basketball expert indicates, which of the two
players is better.
  We demonstrate that despite not knowing the basketball evaluator's criterion,
our model learns to accurately assess the players in real-world games.
Furthermore, our model can also discover basketball events that contribute
positively and negatively to a player's performance.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05368</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Style Representations and the Large-Scale Classification of
  Artistic Style</dc:title>
 <dc:creator>Johnson, Jeremiah</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The artistic style of a painting is a subtle aesthetic judgment used by art
historians for grouping and classifying artwork. The recently introduced
`neural-style' algorithm substantially succeeds in merging the perceived
artistic style of one image or set of images with the perceived content of
another. In light of this and other recent developments in image analysis via
convolutional neural networks, we investigate the effectiveness of a
`neural-style' representation for classifying the artistic style of paintings.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures, 2 tables</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05369</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast On-Line Kernel Density Estimation for Active Object Localization</dc:title>
 <dc:creator>Rhodes, Anthony D.</dc:creator>
 <dc:creator>Quinn, Max H.</dc:creator>
 <dc:creator>Mitchell, Melanie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A major goal of computer vision is to enable computers to interpret visual
situations---abstract concepts (e.g., &quot;a person walking a dog,&quot; &quot;a crowd
waiting for a bus,&quot; &quot;a picnic&quot;) whose image instantiations are linked more by
their common spatial and semantic structure than by low-level visual
similarity. In this paper, we propose a novel method for prior learning and
active object localization for this kind of knowledge-driven search in static
images. In our system, prior situation knowledge is captured by a set of
flexible, kernel-based density estimations---a situation model---that represent
the expected spatial structure of the given situation. These estimations are
efficiently updated by information gained as the system searches for relevant
objects, allowing the system to use context as it is discovered to narrow the
search.
  More specifically, at any given time in a run on a test image, our system
uses image features plus contextual information it has discovered to identify a
small subset of training images---an importance cluster---that is deemed most
similar to the given test image, given the context. This subset is used to
generate an updated situation model in an on-line fashion, using an efficient
multipole expansion technique.
  As a proof of concept, we apply our algorithm to a highly varied and
challenging dataset consisting of instances of a &quot;dog-walking&quot; situation. Our
results support the hypothesis that dynamically-rendered, context-based
probability models can support efficient object localization in visual
situations. Moreover, our approach is general enough to be applied to diverse
machine learning paradigms requiring interpretable, probabilistic
representations generated from partially observed data.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1607.00548</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05369</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05372</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sensitivity Analysis for Convex Separable Optimization over Integral
  Polymatroids</dc:title>
 <dc:creator>Harks, Tobias</dc:creator>
 <dc:creator>Klimm, Max</dc:creator>
 <dc:creator>Peis, Britta</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We study the sensitivity of optimal solutions of convex separable
optimization problems over an integral polymatroid base polytope with respect
to parameters determining both the cost of each element and the polytope. Under
convexity and a regularity assumption on the functional dependency of the cost
function with respect to the parameters, we show that reoptimization after a
change in parameters can be done by elementary local operations. Applying this
result, we derive that starting from any optimal solution there is a new
optimal solution to new parameters such that the L1-norm of the difference of
the two solutions is at most two times the L1 norm of the difference of the
parameters. We apply these sensitivity results to a class of non-cooperative
polymatroid games and derive the existence of pure Nash equilibria. We
complement our results by showing that polymatroids are the maximal
combinatorial structure enabling these results. For any non-polymatroid region,
there is a corresponding optimization problem for which the sensitivity results
do not hold. In addition, there is a game where the players strategies are
isomorphic to the non-polymatroid region and that does not admit a pure Nash
equilibrium.
</dc:description>
 <dc:description>Comment: Succeeds arXiv paper 1407.7650. arXiv admin note: text overlap with
  arXiv:1407.7650</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05373</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepCas: an End-to-end Predictor of Information Cascades</dc:title>
 <dc:creator>Li, Cheng</dc:creator>
 <dc:creator>Ma, Jiaqi</dc:creator>
 <dc:creator>Guo, Xiaoxiao</dc:creator>
 <dc:creator>Mei, Qiaozhu</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Information cascades, effectively facilitated by most social network
platforms, are recognized as a major factor in almost every social success and
disaster in these networks. Can cascades be predicted? While many believe that
they are inherently unpredictable, recent work has shown that some key
properties of information cascades, such as size, growth, and shape, can be
predicted by a machine learning algorithm that combines many features. These
predictors all depend on a bag of hand-crafting features to represent the
cascade network and the global network structure. Such features, always
carefully and sometimes mysteriously designed, are not easy to extend or to
generalize to a different platform or domain.
  Inspired by the recent successes of deep learning in multiple data mining
tasks, we investigate whether an end-to-end deep learning approach could
effectively predict the future size of cascades. Such a method automatically
learns the representation of individual cascade graphs in the context of the
global network structure, without hand-crafted features and heuristics. We find
that node embeddings fall short of predictive power, and it is critical to
learn the representation of a cascade graph as a whole. We present algorithms
that learn the representation of cascade graphs in an end-to-end manner, which
significantly improve the performance of cascade prediction over strong
baselines that include feature based methods, node embedding methods, and graph
kernel methods. Our results also provide interesting implications for cascade
prediction in general.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05373</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05374</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Automated Attendance System based on NFC &amp; X-Bee Technologies with a
  Remote Database</dc:title>
 <dc:creator>Yeboah-Boateng, Ezer Osei</dc:creator>
 <dc:creator>Asamoah, Emmanuel Owusu</dc:creator>
 <dc:creator>Segbedzi, Vera Dzidedi</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The main aim of this research was to automate attendance registration,
thereby reducing human involvement in the whole process. Typically, the system
works by storing vital staff personable information, such as Name, Job
specification, etc. into a MySQL database upon engagement. The staff is
identified with a unique key associated with an NFC based ID card within the
database. So on typical work day, an employee scans his/her ID card on the
PN532 reader in close proximity. The exact time and date, together with the
unique identifier of the scanned card are stored locally on a storage media,
before the data is relayed via the XBee to the remote database. The captured
data is then authenticated by comparing with the pre-entered data to give
access or authorization to the corporate resources, as well as recorded for
attendance purposes. Our experiment shows that the automated attendance system
is more effective, efficient and reliable, due to its real time capability,
remote monitoring and attendance reports that it provides to the institution.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05376</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>hMAC: Enabling Hybrid TDMA/CSMA on IEEE 802.11 Hardware</dc:title>
 <dc:creator>Zehl, Sven</dc:creator>
 <dc:creator>Zubow, Anatolij</dc:creator>
 <dc:creator>Wolisz, Adam</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We present our current work-in-progress on the design and implementation of a
hybrid TDMA/CSMA medium access architecture, hereafter referred to as hMAC,
which can be used on top of commercial IEEE 802.11 off-the-shelf hardware. The
software only solution is based on the popular Linux ATH9K softMAC driver and
hence can be used with standard Linux systems using Atheros based wireless
network devices. The proposed hMAC exploits the standard 802.11 power saving
functionality present in the ATH9K device driver to enable control of the
software packet queues. This allows the assignment of TDMA time slots on
wireless link and traffic class basis. While the solution is placed only in the
device driver, the CSMA/CA functionality on hardware level is still active.
This enables inter-working with standard unmodified 802.11 devices. We tested
our prototypical hMAC implementation in a small test-bed. Therefore, we
implemented a centralized interference management scheme in which pairs of
links suffering from a hidden node problem are assigned to TDMA time slots on a
per-link basis. To show the benefits of the proposed hMAC approach we compared
the results with standard 802.11 DCF and classical, i.e. per-node, TDMA.
Finally, to enable collaboration with the research community, the hMAC source
code is provided as open-source.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05377</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully-adaptive Feature Sharing in Multi-Task Networks with Applications
  in Person Attribute Classification</dc:title>
 <dc:creator>Lu, Yongxi</dc:creator>
 <dc:creator>Kumar, Abhishek</dc:creator>
 <dc:creator>Zhai, Shuangfei</dc:creator>
 <dc:creator>Cheng, Yu</dc:creator>
 <dc:creator>Javidi, Tara</dc:creator>
 <dc:creator>Feris, Rogerio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Multi-task learning aims to improve generalization performance of multiple
prediction tasks by appropriately sharing relevant information across them. In
the context of deep neural networks, this idea is often realized by
hand-designed network architectures with layers that are shared across tasks
and branches that encode task-specific features. However, the space of possible
multi-task deep architectures is combinatorially large and often the final
architecture is arrived at by manual exploration of this space subject to
designer's bias, which can be both error-prone and tedious. In this work, we
propose a principled approach for designing compact multi-task deep learning
architectures. Our approach starts with a thin network and dynamically widens
it in a greedy manner during training using a novel criterion that promotes
grouping of similar tasks together. Our Extensive evaluation on person
attributes classification tasks involving facial and clothing attributes
suggests that the models produced by the proposed method are fast, compact and
can closely match or exceed the state-of-the-art accuracy from strong baselines
by much more expensive models.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05378</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral Convolution Networks</dc:title>
 <dc:creator>Francesca, Maria</dc:creator>
 <dc:creator>Hughes, Arthur</dc:creator>
 <dc:creator>Gregg, David</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Previous research has shown that computation of convolution in the frequency
domain provides a significant speedup versus traditional convolution network
implementations. However, this performance increase comes at the expense of
repeatedly computing the transform and its inverse in order to apply other
network operations such as activation, pooling, and dropout. We show,
mathematically, how convolution and activation can both be implemented in the
frequency domain using either the Fourier or Laplace transformation. The main
contributions are a description of spectral activation under the Fourier
transform and a further description of an efficient algorithm for computing
both convolution and activation under the Laplace transform. By computing both
the convolution and activation functions in the frequency domain, we can reduce
the number of transforms required, as well as reducing overall complexity. Our
description of a spectral activation function, together with existing spectral
analogs of other network functions may then be used to compose a fully spectral
implementation of a convolution network.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05378</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05379</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PCT and Beyond: Towards a Computational Framework for `Intelligent'
  Communicative Systems</dc:title>
 <dc:creator>Moore, Prof. Roger K.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Recent years have witnessed increasing interest in the potential benefits of
`intelligent' autonomous machines such as robots. Honda's Asimo humanoid robot,
iRobot's Roomba robot vacuum cleaner and Google's driverless cars have fired
the imagination of the general public, and social media buzz with speculation
about a utopian world of helpful robot assistants or the coming robot
apocalypse! However, there is a long way to go before autonomous systems reach
the level of capabilities required for even the simplest of tasks involving
human-robot interaction - especially if it involves communicative behaviour
such as speech and language. Of course the field of Artificial Intelligence
(AI) has made great strides in these areas, and has moved on from abstract
high-level rule-based paradigms to embodied architectures whose operations are
grounded in real physical environments. What is still missing, however, is an
overarching theory of intelligent communicative behaviour that informs
system-level design decisions in order to provide a more coherent approach to
system integration. This chapter introduces the beginnings of such a framework
inspired by the principles of Perceptual Control Theory (PCT). In particular,
it is observed that PCT has hitherto tended to view perceptual processes as a
relatively straightforward series of transformations from sensation to
perception, and has overlooked the potential of powerful generative model-based
solutions that have emerged in practical fields such as visual or auditory
scene analysis. Starting from first principles, a sequence of arguments is
presented which not only shows how these ideas might be integrated into PCT,
but which also extend PCT towards a remarkably symmetric architecture for a
needs-driven communicative agent. It is concluded that, if behaviour is the
control of perception, then perception is the simulation of behaviour.
</dc:description>
 <dc:description>Comment: To appear in A. McElhone &amp; W. Mansell (Eds.), Living Control Systems
  IV: Perceptual Control Theory and the Future of the Life and Social Sciences,
  Benchmark Publications Inc</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05380</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Market Segmentation for Privacy Differentiated &quot;Free&quot; Services</dc:title>
 <dc:creator>Huang, Chong</dc:creator>
 <dc:creator>Sankar, Lalitha</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The emerging marketplace for online free services in which service providers
earn revenue from using consumer data in direct and indirect ways has lead to
significant privacy concerns. This leads to the following question: can the
online marketplace sustain multiple service providers (SPs) that offer
privacy-differentiated free services? This paper studies the problem of market
segmentation for the free online services market by augmenting the classical
Hotelling model for market segmentation analysis to include the fact that for
the free services market, a consumer values service not in monetized terms but
by its quality of service (QoS) and that the differentiator of services is not
product price but the privacy risk advertised by a SP. Building upon the
Hotelling model, this paper presents a parametrized model for SP profit and
consumer valuation of service for both the two- and multi-SP problems to show
that: (i) when consumers place a high value on privacy, it leads to a lower use
of private data by SPs (i.e., their advertised privacy risk reduces), and thus,
SPs compete on the QoS; (ii) SPs that are capable of differentiating on
services that do not directly target consumers gain larger market share; and
(iii) a higher valuation of privacy by consumers forces SPs with smaller
untargeted revenue to offer lower privacy risk to attract more consumers. The
work also illustrates the market segmentation problem for more than two SPs and
highlights the instability of such markets.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05380</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05384</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Feature-Enriched Neural Model for Joint Chinese Word Segmentation and
  Part-of-Speech Tagging</dc:title>
 <dc:creator>Chen, Xinchi</dc:creator>
 <dc:creator>Qiu, Xipeng</dc:creator>
 <dc:creator>Huang, Xuanjing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recently, neural network models for natural language processing tasks have
been increasingly focused on for their ability of alleviating the burden of
manual feature engineering. However, the previous neural models cannot extract
the complicated feature compositions as the traditional methods with discrete
features. In this work, we propose a feature-enriched neural model for joint
Chinese word segmentation and part-of-speech tagging task. Specifically, to
simulate the feature templates of traditional discrete feature based models, we
use different filters to model the complex compositional features with
convolutional and pooling layer, and then utilize long distance dependency
information with recurrent layer. Experimental results on five different
datasets show the effectiveness of our proposed model.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05384</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05396</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Attention-controlled Cascaded Shape Regression Exploiting
  Training Data Augmentation and Fuzzy-set Sample Weighting</dc:title>
 <dc:creator>Feng, Zhen-Hua</dc:creator>
 <dc:creator>Kittler, Josef</dc:creator>
 <dc:creator>Christmas, William</dc:creator>
 <dc:creator>Huber, Patrik</dc:creator>
 <dc:creator>Wu, Xiao-Jun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a new Cascaded Shape Regression (CSR) architecture, namely Dynamic
Attention-Controlled CSR (DAC-CSR), for robust facial landmark detection on
unconstrained faces. Our DAC-CSR divides facial landmark detection into three
cascaded sub-tasks: face bounding box refinement, general CSR and
attention-controlled CSR. The first two stages refine initial face bounding
boxes and output intermediate facial landmarks. Then, an online dynamic model
selection method is used to choose appropriate domain-specific CSRs for further
landmark refinement. The key innovation of our DAC-CSR is the fault-tolerant
mechanism, using fuzzy set sample weighting for attention-controlled
domain-specific model training. Moreover, we advocate data augmentation with a
simple but effective 2D profile face generator, and context-aware feature
extraction for better facial feature representation. Experimental results
obtained on challenging datasets demonstrate the merits of our DAC-CSR over the
state-of-the-art.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05396</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05397</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning with Unsupervised Auxiliary Tasks</dc:title>
 <dc:creator>Jaderberg, Max</dc:creator>
 <dc:creator>Mnih, Volodymyr</dc:creator>
 <dc:creator>Czarnecki, Wojciech Marian</dc:creator>
 <dc:creator>Schaul, Tom</dc:creator>
 <dc:creator>Leibo, Joel Z</dc:creator>
 <dc:creator>Silver, David</dc:creator>
 <dc:creator>Kavukcuoglu, Koray</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deep reinforcement learning agents have achieved state-of-the-art results by
directly maximising cumulative reward. However, environments contain a much
wider variety of possible training signals. In this paper, we introduce an
agent that also maximises many other pseudo-reward functions simultaneously by
reinforcement learning. All of these tasks share a common representation that,
like unsupervised learning, continues to develop in the absence of extrinsic
rewards. We also introduce a novel mechanism for focusing this representation
upon extrinsic rewards, so that learning can rapidly adapt to the most relevant
aspects of the actual task. Our agent significantly outperforms the previous
state-of-the-art on Atari, averaging 880\% expert human performance, and a
challenging suite of first-person, three-dimensional \emph{Labyrinth} tasks
leading to a mean speedup in learning of 10$\times$ and averaging 87\% expert
human performance on Labyrinth.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05402</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The ZipML Framework for Training Models with End-to-End Low Precision:
  The Cans, the Cannots, and a Little Bit of Deep Learning</dc:title>
 <dc:creator>Zhang, Hantian</dc:creator>
 <dc:creator>Li, Jerry</dc:creator>
 <dc:creator>Kara, Kaan</dc:creator>
 <dc:creator>Alistarh, Dan</dc:creator>
 <dc:creator>Liu, Ji</dc:creator>
 <dc:creator>Zhang, Ce</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recently there has been significant interest in training machine-learning
models at low precision: by reducing precision, one can reduce computation and
communication by one order of magnitude. We examine training at reduced
precision, both from a theoretical and practical perspective, and ask: is it
possible to train models at end-to-end low precision with provable guarantees?
Can this lead to consistent order-of-magnitude speedups? We present a framework
called ZipML to answer these questions. For linear models, the answer is yes.
We develop a simple framework based on one simple but novel strategy called
double sampling. Our framework is able to execute training at low precision
with no bias, guaranteeing convergence, whereas naive quantization would
introduce significant bias. We validate our framework across a range of
applications, and show that it enables an FPGA prototype that is up to 6.5x
faster than an implementation using full 32-bit precision. We further develop a
variance-optimal stochastic quantization strategy and show that it can make a
significant difference in a variety of settings. When applied to linear models
together with double sampling, we save up to another 1.7x in data movement
compared with uniform quantization. When training deep networks with quantized
models, we achieve higher accuracy than the state-of-the-art XNOR-Net. Finally,
we extend our framework through approximation to non-linear models, such as
SVM. We show that, although using low-precision data induces bias, we can
appropriately bound and control the bias. We find in practice 8-bit precision
is often sufficient to converge to the correct solution. Interestingly,
however, in practice we notice that our framework does not always outperform
the naive rounding approach. We discuss this negative result in detail.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-06-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05413</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Spectral Efficiency and Security Enhancements of NOMA Assisted
  Multicast-Unicast Streaming</dc:title>
 <dc:creator>Ding, Zhiguo</dc:creator>
 <dc:creator>Zhao, Zhongyuan</dc:creator>
 <dc:creator>Peng, Mugen</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers the application of non-orthogonal multiple access (NOMA)
to a multi-user network with mixed multicasting and unicasting traffic. The
proposed design of beamforming and power allocation ensures that the unicasting
performance is improved while maintaining the reception reliability of
multicasting. Both analytical and simulation results are provided to
demonstrate that the use of the NOMA assisted multicast-unicast scheme yields a
significant improvement in spectral efficiency compared to orthogonal multiple
access (OMA) schemes which realize multicasting and unicasting services
separately. Since unicasting messages are broadcasted to all the users, how the
use of NOMA can prevent those multicasting receivers intercepting the
unicasting messages is also investigated, where it is shown that the secrecy
unicasting rate achieved by NOMA is always larger than or equal to that of OMA.
This security gain is mainly due to the fact that the multicasting messages can
be used as jamming signals to prevent potential eavesdropping when the
multicasting and unicasting messages are superimposed together following the
NOMA principle.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05415</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multipliers: comparison of Fourier transformation based method and
  Synopsys design technique for up to 32 bits inputs in regular and saturation
  arithmetics</dc:title>
 <dc:creator>Gorodecky, Danila</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  The technique for hardware multiplication based upon Fourier transformation
has been introduced. The technique has the highest efficiency on multiplication
units with up to 8 bit range. Each multiplication unit is realized on base of
the minimized Boolean functions. Experimental data showed that this technique
the multiplication process speed up to 20% higher for 2-8 bit range of input
operands and up to 3% higher for 8-32 bit range of input operands than
analogues designed by Synopsys technique.
</dc:description>
 <dc:description>Comment: Proceedings of the 12th International Workshop on Boolean Problems,
  Freiberg, Germany, Sept. 22-23, 2016. Edited by B. Steinbach. Freiberg
  University of Mining and Technology. P. 145-150. Changed title from
  &quot;Multipliers design technique based disjunctive normal form minimizationa and
  Fourier transformation&quot;; fixed some inaccuracies</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05415</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05416</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Composing Music with Grammar Argumented Neural Networks and Note-Level
  Encoding</dc:title>
 <dc:creator>Sun, Zheng</dc:creator>
 <dc:creator>Liu, Jiaqi</dc:creator>
 <dc:creator>Zhang, Zewang</dc:creator>
 <dc:creator>Chen, Jingwen</dc:creator>
 <dc:creator>Huo, Zhao</dc:creator>
 <dc:creator>Lee, Ching Hua</dc:creator>
 <dc:creator>Zhang, Xiao</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Creating aesthetically pleasing pieces of art, including music, has been a
long-term goal for artificial intelligence research. Despite recent successes
of long-short term memory (LSTM) recurrent neural networks (RNNs) in sequential
learning, LSTM neural networks have not, by themselves, been able to generate
natural-sounding music conforming to music theory. To transcend this
inadequacy, we put forward a novel method for music composition that combines
the LSTM with Grammars motivated by music theory. The main tenets of music
theory are encoded as grammar argumented (GA) filters on the training data,
such that the machine can be trained to generate music inheriting the
naturalness of human-composed pieces from the original dataset while adhering
to the rules of music theory. Unlike previous approaches, pitches and durations
are encoded as one semantic entity, which we refer to as note-level encoding.
This allows easy implementation of music theory grammars, as well as closer
emulation of the thinking pattern of a musician. Although the GA rules are
applied to the training data and never directly to the LSTM music generation,
our machine still composes music that possess high incidences of diatonic scale
notes, small pitch intervals and chords, in deference to music theory.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05418</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VisualBackProp: efficient visualization of CNNs</dc:title>
 <dc:creator>Bojarski, Mariusz</dc:creator>
 <dc:creator>Choromanska, Anna</dc:creator>
 <dc:creator>Choromanski, Krzysztof</dc:creator>
 <dc:creator>Firner, Bernhard</dc:creator>
 <dc:creator>Jackel, Larry</dc:creator>
 <dc:creator>Muller, Urs</dc:creator>
 <dc:creator>Zieba, Karol</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a new method, that we call VisualBackProp, for
visualizing which sets of pixels of the input image contribute most to the
predictions made by the convolutional neural network (CNN). The method heavily
hinges on exploring the intuition that the feature maps contain less and less
irrelevant information to the prediction decision when moving deeper into the
network. The technique we propose was developed as a debugging tool for
CNN-based systems for steering self-driving cars and is therefore required to
run in real-time, i.e. it was designed to require less computations than a
forward propagation. This makes the presented visualization method a valuable
debugging tool which can be easily used during both training and inference. We
furthermore justify our approach with theoretical arguments and theoretically
confirm that the proposed method identifies sets of input pixels, rather than
individual pixels, that collaboratively contribute to the prediction. Our
theoretical findings stand in agreement with the experimental results. The
empirical evaluation shows the plausibility of the proposed approach on the
road video data as well as in other applications and reveals that it compares
favorably to the layer-wise relevance propagation approach, i.e. it obtains
similar visualization results and simultaneously achieves order of magnitude
speed-ups.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05418</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05419</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigating Factors Influencing the Latency of Cyberbullying Detection</dc:title>
 <dc:creator>Rafiq, Rahat Ibn</dc:creator>
 <dc:creator>Hosseinmardi, Homa</dc:creator>
 <dc:creator>Han, Richard</dc:creator>
 <dc:creator>Lv, Qin</dc:creator>
 <dc:creator>Mishra, Shivakant</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Cyberbullying in online social networks has become a critical problem,
especially among teenagers who are social networks' prolific users. As a
result, researchers have focused on identifying distinguishing features of
cyberbullying and developing techniques to automatically detect cyberbullying
incidents. While this research has resulted in developing highly accurate
classifiers, two key practical issues related to identifying cyberbullying have
largely been ignored, namely scalability of cyberbullying detection services
and timeliness of raising alerts whenever a cyberbullying incident is
suspected.
  These two issues are the subject of this paper. We propose a multi-stage
cyberbullying detection solution that drastically reduces the classification
time and the time to raise cyberbullying alerts. The proposed solution is
highly scalable, does not sacrifice accuracy for scalability, and is highly
responsive in raising alerts. The solution is comprised of three novel
components, an initial predictor, a multilevel priority scheduler, and an
incremental classification mechanism. We have implemented this solution and
utilized data obtained from the Vine online social network to demonstrate the
utility of each of these components via a detailed performance evaluation. We
show that our complete solution is significantly more scalable and responsive
than the current state-of-the-art.
</dc:description>
 <dc:description>Comment: 9 pages, 6 figures, 3 tables</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05424</identifier>
 <datestamp>2017-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Associative Embedding: End-to-End Learning for Joint Detection and
  Grouping</dc:title>
 <dc:creator>Newell, Alejandro</dc:creator>
 <dc:creator>Huang, Zhiao</dc:creator>
 <dc:creator>Deng, Jia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce associative embedding, a novel method for supervising
convolutional neural networks for the task of detection and grouping. A number
of computer vision problems can be framed in this manner including multi-person
pose estimation, instance segmentation, and multi-object tracking. Usually the
grouping of detections is achieved with multi-stage pipelines, instead we
propose an approach that teaches a network to simultaneously output detections
and group assignments. This technique can be easily integrated into any
state-of-the-art network architecture that produces pixel-wise predictions. We
show how to apply this method to both multi-person pose estimation and instance
segmentation and report state-of-the-art performance for multi-person pose on
the MPII and MS-COCO datasets.
</dc:description>
 <dc:description>Comment: Added results on MS-COCO and updated results on MPII</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05425</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ProjE: Embedding Projection for Knowledge Graph Completion</dc:title>
 <dc:creator>Shi, Baoxu</dc:creator>
 <dc:creator>Weninger, Tim</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  With the large volume of new information created every day, determining the
validity of information in a knowledge graph and filling in its missing parts
are crucial tasks for many researchers and practitioners. To address this
challenge, a number of knowledge graph completion methods have been developed
using low-dimensional graph embeddings. Although researchers continue to
improve these models using an increasingly complex feature space, we show that
simple changes in the architecture of the underlying model can outperform
state-of-the-art models without the need for complex feature engineering. In
this work, we present a shared variable neural network model called ProjE that
fills-in missing information in a knowledge graph by learning joint embeddings
of the knowledge graph's entities and edges, and through subtle, but important,
changes to the standard loss function. In doing so, ProjE has a parameter size
that is smaller than 11 out of 15 existing methods while performing $37\%$
better than the current-best method on standard datasets. We also show, via a
new fact checking task, that ProjE is capable of accurately determining the
veracity of many declarative statements.
</dc:description>
 <dc:description>Comment: 14 pages, Accepted to AAAI 2017</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05428</identifier>
 <datestamp>2017-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Upscaledb: Efficient Integer-Key Compression in a Key-Value Store using
  SIMD Instructions</dc:title>
 <dc:creator>Lemire, Daniel</dc:creator>
 <dc:creator>Rupp, Christoph</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Compression can sometimes improve performance by making more of the data
available to the processors faster. We consider the compression of integer keys
in a B+-tree index. For this purpose, systems such as IBM DB2 use variable-byte
compression over differentially coded keys. We revisit this problem with
various compression alternatives such as Google's VarIntGB, Binary Packing and
Frame-of-Reference. In all cases, we describe algorithms that can operate
directly on compressed data. Many of our alternatives exploit the
single-instruction-multiple-data (SIMD) instructions supported by modern CPUs.
We evaluate our techniques in a database environment provided by Upscaledb, a
production-quality key-value database. Our best techniques are SIMD
accelerated: they simultaneously reduce memory usage while improving
single-threaded speeds. In particular, a differentially coded SIMD
binary-packing techniques (BP128) can offer a superior query speed (e.g., 40%
better than an uncompressed database) while providing the best compression
(e.g., by a factor of ten). For analytic workloads, our fast compression
techniques offer compelling benefits. Our software is available as open source.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05428</dc:identifier>
 <dc:identifier>Information Systems Volume 66, June 2017, Pages 13-23</dc:identifier>
 <dc:identifier>doi:10.1016/j.is.2017.01.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05429</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Hardness Results for Routing on Disjoint Paths</dc:title>
 <dc:creator>Chuzhoy, Julia</dc:creator>
 <dc:creator>Kim, David H. K.</dc:creator>
 <dc:creator>Nimavat, Rachit</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In the classical Node-Disjoint Paths (NDP) problem, the input consists of an
undirected $n$-vertex graph $G$, and a collection
$\mathcal{M}=\{(s_1,t_1),\ldots,(s_k,t_k)\}$ of pairs of its vertices, called
source-destination, or demand, pairs. The goal is to route the largest possible
number of the demand pairs via node-disjoint paths. The best current
approximation for the problem is achieved by a simple greedy algorithm, whose
approximation factor is $O(\sqrt n)$, while the best current negative result is
an $\Omega(\log^{1/2-\delta}n)$-hardness of approximation for any constant
$\delta$, under standard complexity assumptions. Even seemingly simple special
cases of the problem are still poorly understood: when the input graph is a
grid, the best current algorithm achieves an $\tilde O(n^{1/4})$-approximation,
and when it is a general planar graph, the best current approximation ratio of
an efficient algorithm is $\tilde O(n^{9/19})$. The best currently known lower
bound on the approximability of both these versions of the problem is
APX-hardness.
  In this paper we prove that NDP is $2^{\Omega(\sqrt{\log n})}$-hard to
approximate, unless all problems in NP have algorithms with running time
$n^{O(\log n)}$. Our result holds even when the underlying graph is a planar
graph with maximum vertex degree $3$, and all source vertices lie on the
boundary of a single face (but the destination vertices may lie anywhere in the
graph). We extend this result to the closely related Edge-Disjoint Paths
problem, showing the same hardness of approximation ratio even for sub-cubic
planar graphs with all sources lying on the boundary of a single face.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05429</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05431</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aggregated Residual Transformations for Deep Neural Networks</dc:title>
 <dc:creator>Xie, Saining</dc:creator>
 <dc:creator>Girshick, Ross</dc:creator>
 <dc:creator>Doll&#xe1;r, Piotr</dc:creator>
 <dc:creator>Tu, Zhuowen</dc:creator>
 <dc:creator>He, Kaiming</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a simple, highly modularized network architecture for image
classification. Our network is constructed by repeating a building block that
aggregates a set of transformations with the same topology. Our simple design
results in a homogeneous, multi-branch architecture that has only a few
hyper-parameters to set. This strategy exposes a new dimension, which we call
&quot;cardinality&quot; (the size of the set of transformations), as an essential factor
in addition to the dimensions of depth and width. On the ImageNet-1K dataset,
we empirically show that even under the restricted condition of maintaining
complexity, increasing cardinality is able to improve classification accuracy.
Moreover, increasing cardinality is more effective than going deeper or wider
when we increase the capacity. Our models, named ResNeXt, are the foundations
of our entry to the ILSVRC 2016 classification task in which we secured 2nd
place. We further investigate ResNeXt on an ImageNet-5K set and the COCO
detection set, also showing better results than its ResNet counterpart. The
code and models are publicly available online.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2017. Code and models:
  https://github.com/facebookresearch/ResNeXt</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05435</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Gated Recurrent Networks for Video Segmentation</dc:title>
 <dc:creator>Siam, Mennatullah</dc:creator>
 <dc:creator>Valipour, Sepehr</dc:creator>
 <dc:creator>Jagersand, Martin</dc:creator>
 <dc:creator>Ray, Nilanjan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Semantic segmentation has recently witnessed major progress, where fully
convolutional neural networks have shown to perform well. However, most of the
previous work focused on improving single image segmentation. To our knowledge,
no prior work has made use of temporal video information in a recurrent
network. In this paper, we introduce a novel approach to implicitly utilize
temporal data in videos for online semantic segmentation. The method relies on
a fully convolutional network that is embedded into a gated recurrent
architecture. This design receives a sequence of consecutive video frames and
outputs the segmentation of the last frame. Convolutional gated recurrent
networks are used for the recurrent part to preserve spatial connectivities in
the image. Our proposed method can be applied in both online and batch
segmentation. This architecture is tested for both binary and semantic video
segmentation tasks. Experiments are conducted on the recent benchmarks in
SegTrack V2, Davis, CityScapes, and Synthia. Using recurrent fully
convolutional networks improved the baseline network performance in all of our
experiments. Namely, 5% and 3% improvement of F-measure in SegTrack2 and Davis
respectively, 5.7% improvement in mean IoU in Synthia and 3.5% improvement in
categorical mean IoU in CityScapes. The performance of the RFCN network depends
on its baseline fully convolutional network. Thus RFCN architecture can be seen
as a method to improve its baseline segmentation network by exploiting
spatiotemporal information in videos.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1606.00487</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05435</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05438</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Framework for Floor-plan Prediction of Dynamic Runtime
  Reconfigurable Systems</dc:title>
 <dc:creator>Al-Wattar, A.</dc:creator>
 <dc:creator>Areibi, S.</dc:creator>
 <dc:creator>Grewal, G.</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Several embedded application domains for reconfigurable systems tend to
combine frequent changes with high performance demands of their workloads such
as image processing, wearable computing and network processors. Time
multiplexing of reconfigurable hardware resources raises a number of new
issues, ranging from run-time systems to complex programming models that
usually form a Reconfigurable hardware Operating System (ROS). The Operating
System performs online task scheduling and handles resource management. There
are many challenges in adaptive computing and dynamic reconfigurable systems.
One of the major understudied challenges is estimating the required resources
in terms of soft cores, Programmable Reconfigurable Regions (PRRs), the
appropriate communication infrastructure, and to predict a near optimal layout
and floorplan of the reconfigurable logic fabric. Some of these issues are
specific to the application being designed, while others are more general and
relate to the underlying run-time environment. Static resource allocation for
Run- Time Reconfiguration (RTR) often leads to inferior and unacceptable
results. In this paper, we present a novel adaptive and dynamic methodology,
based on a Machine Learning approach, for predicting and estimating the
necessary resources for an application based on past historical information. An
important feature of the proposed methodology is that the system is able to
learn and generalize and, therefore, is expected to improve its accuracy over
time. The goal of the entire process is to extract useful hidden knowledge from
the data. This knowledge is the prediction and estimation of the necessary
resources for an unknown or not previously seen application.
</dc:description>
 <dc:description>Comment: 23 pages, 12 figures</dc:description>
 <dc:date>2016-09-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05438</dc:identifier>
 <dc:identifier>International Journal of Reconfigurable and Embedded Systems
  (IJRES) Vol. 4, No. 2, July 2015, pp. 99~121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05467</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Common Reconstructions in the Successive Refinement Problem with
  Receiver Side Information</dc:title>
 <dc:creator>Vellambi, Badri N.</dc:creator>
 <dc:creator>Timo, Roy</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study a variant of the successive refinement problem with receiver side
information where the receivers require identical reconstructions. We present
general inner and outer bounds for the rate region for this variant and present
a single-letter characterization of the admissible rate region for several
classes of the joint distribution of the source and the side information. The
characterization indicates that the side information can be fully used to
reduce the communication rates via binning; however, the reconstruction
functions can depend only on the G\'acs-K\&quot;orner common randomness shared by
the two receivers. Unlike existing (inner and outer) bounds to the rate region
of the general successive refinement problem, the characterization of the
admissible rate region derived for several settings of the variant studied
requires only one auxiliary random variable. Using the derived
characterization, we establish that the admissible rate region is not
continuous in the underlying source source distribution even though the problem
formulation does not involve zero-error or functional reconstruction
constraints.
</dc:description>
 <dc:description>Comment: 37 pages, 8 figures. Some of the material in this paper was presented
  at the 2013 IEEE Information Theory Workshop in Seville, Spain, and the 2014
  IEEEInternational Symposium on Information Theory in Honolulu, USA, 2014.
  This work was supported by the Australian Research Council Discovery Project
  DP120102123</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05467</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05469</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Embedding Projector: Interactive Visualization and Interpretation of
  Embeddings</dc:title>
 <dc:creator>Smilkov, Daniel</dc:creator>
 <dc:creator>Thorat, Nikhil</dc:creator>
 <dc:creator>Nicholson, Charles</dc:creator>
 <dc:creator>Reif, Emily</dc:creator>
 <dc:creator>Vi&#xe9;gas, Fernanda B.</dc:creator>
 <dc:creator>Wattenberg, Martin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Embeddings are ubiquitous in machine learning, appearing in recommender
systems, NLP, and many other applications. Researchers and developers often
need to explore the properties of a specific embedding, and one way to analyze
embeddings is to visualize them. We present the Embedding Projector, a tool for
interactive visualization and interpretation of embeddings.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05469</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05476</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-calibration-based Approach to Critical Motion Sequences of
  Rolling-shutter Structure from Motion</dc:title>
 <dc:creator>Ito, Eisuke</dc:creator>
 <dc:creator>Okatani, Takayuki</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we consider critical motion sequences (CMSs) of rolling-shutter
(RS) SfM. Employing an RS camera model with linearized pure rotation, we show
that the RS distortion can be approximately expressed by two internal
parameters of an &quot;imaginary&quot; camera plus one-parameter nonlinear transformation
similar to lens distortion. We then reformulate the problem as self-calibration
of the imaginary camera, in which its skew and aspect ratio are unknown and
varying in the image sequence. In the formulation, we derive a general
representation of CMSs. We also show that our method can explain the CMS that
was recently reported in the literature, and then present a new remedy to deal
with the degeneracy. Our theoretical results agree well with experimental
results; it explains degeneracies observed when we employ naive bundle
adjustment, and how they are resolved by our method.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05479</identifier>
 <datestamp>2017-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Fluorescence-Based Synapse Detection</dc:title>
 <dc:creator>Simhal, Anish K.</dc:creator>
 <dc:creator>Aguerrebere, Cecilia</dc:creator>
 <dc:creator>Collman, Forrest</dc:creator>
 <dc:creator>Vogelstein, Joshua T.</dc:creator>
 <dc:creator>Micheva, Kristina D.</dc:creator>
 <dc:creator>Weinberg, Richard J.</dc:creator>
 <dc:creator>Smith, Stephen J.</dc:creator>
 <dc:creator>Sapiro, Guillermo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Brain function results from communication between neurons connected by
complex synaptic networks. Synapses are themselves highly complex and diverse
signaling machines, containing protein products of hundreds of different genes,
some in hundreds of copies, arranged in precise lattice at each individual
synapse. Synapses are fundamental not only to synaptic network function but
also to network development, adaptation, and memory. In addition, abnormalities
of synapse numbers or molecular components are implicated in most mental and
neurological disorders. Despite their obvious importance, mammalian synapse
populations have so far resisted detailed quantitative study. In human brains
and most animal nervous systems, synapses are very small and very densely
packed: there are approximately 1 billion synapses per cubic millimeter of
human cortex. This volumetric density poses very substantial challenges to
proteometric analysis at the critical level of the individual synapse. The
present work describes new probabilistic image analysis methods for
single-synapse analysis of synapse populations in both animal and human brains.
</dc:description>
 <dc:description>Comment: Current awaiting peer review</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05479</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pcbi.1005493</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05480</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving Cold-Start Problem in Large-scale Recommendation Engines: A Deep
  Learning Approach</dc:title>
 <dc:creator>Yuan, Jianbo</dc:creator>
 <dc:creator>Shalaby, Walid</dc:creator>
 <dc:creator>Korayem, Mohammed</dc:creator>
 <dc:creator>Lin, David</dc:creator>
 <dc:creator>AlJadda, Khalifeh</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Collaborative Filtering (CF) is widely used in large-scale recommendation
engines because of its efficiency, accuracy and scalability. However, in
practice, the fact that recommendation engines based on CF require interactions
between users and items before making recommendations, make it inappropriate
for new items which haven't been exposed to the end users to interact with.
This is known as the cold-start problem. In this paper we introduce a novel
approach which employs deep learning to tackle this problem in any CF based
recommendation engine. One of the most important features of the proposed
technique is the fact that it can be applied on top of any existing CF based
recommendation engine without changing the CF core. We successfully applied
this technique to overcome the item cold-start problem in Careerbuilder's CF
based recommendation engine. Our experiments show that the proposed technique
is very efficient to resolve the cold-start problem while maintaining high
accuracy of the CF recommendations.
</dc:description>
 <dc:description>Comment: in Big Data, IEEE International Conference on, 2016</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05480</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05487</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algebraic multigrid support vector machines</dc:title>
 <dc:creator>Sadrfaridpour, Ehsan</dc:creator>
 <dc:creator>Jeereddy, Sandeep</dc:creator>
 <dc:creator>Kennedy, Ken</dc:creator>
 <dc:creator>Luckow, Andre</dc:creator>
 <dc:creator>Razzaghi, Talayeh</dc:creator>
 <dc:creator>Safro, Ilya</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  The support vector machine is a flexible optimization-based technique widely
used for classification problems. In practice, its training part becomes
computationally expensive on large-scale data sets because of such reasons as
the complexity and number of iterations in parameter fitting methods,
underlying optimization solvers, and nonlinearity of kernels. We introduce a
fast multilevel framework for solving support vector machine models that is
inspired by the algebraic multigrid. Significant improvement in the running has
been achieved without any loss in the quality. The proposed technique is highly
beneficial on imbalanced sets. We demonstrate computational results on publicly
available and industrial data sets.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05487</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05490</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Regularisation for Recurrent Image Annotation</dc:title>
 <dc:creator>Liu, Feng</dc:creator>
 <dc:creator>Xiang, Tao</dc:creator>
 <dc:creator>Hospedales, Timothy M.</dc:creator>
 <dc:creator>Yang, Wankou</dc:creator>
 <dc:creator>Sun, Changyin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The &quot;CNN-RNN&quot; design pattern is increasingly widely applied in a variety of
image annotation tasks including multi-label classification and captioning.
Existing models use the weakly semantic CNN hidden layer or its transform as
the image embedding that provides the interface between the CNN and RNN. This
leaves the RNN overstretched with two jobs: predicting the visual concepts and
modelling their correlations for generating structured annotation output.
Importantly this makes the end-to-end training of the CNN and RNN slow and
ineffective due to the difficulty of back propagating gradients through the RNN
to train the CNN. We propose a simple modification to the design pattern that
makes learning more effective and efficient. Specifically, we propose to use a
semantically regularised embedding layer as the interface between the CNN and
RNN. Regularising the interface can partially or completely decouple the
learning problems, allowing each to be more effectively trained and jointly
training much more efficient. Extensive experiments show that state-of-the art
performance is achieved on multi-label classification as well as image
captioning.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05497</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Explicablility as Minimizing Distance from Expected Behavior</dc:title>
 <dc:creator>Kulkarni, Anagha</dc:creator>
 <dc:creator>Zha, Yantian</dc:creator>
 <dc:creator>Chakraborti, Tathagata</dc:creator>
 <dc:creator>Vadlamudi, Satya Gautam</dc:creator>
 <dc:creator>Zhang, Yu</dc:creator>
 <dc:creator>Kambhampati, Subbarao</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In order to have effective human AI collaboration, it is not simply enough to
address the question of autonomy; an equally important question is, how the
AI's behavior is being perceived by their human counterparts. When AI agent's
task plans are generated without such considerations, they may often
demonstrate inexplicable behavior from the human's point of view. This problem
arises due to the human's partial or inaccurate understanding of the agent's
planning process and/or the model. This may have serious implications on
human-AI collaboration, from increased cognitive load and reduced trust in the
agent, to more serious concerns of safety in interactions with physical agent.
In this paper, we address this issue by modeling the notion of plan
explicability as a function of the distance between a plan that agent makes and
the plan that human expects it to make. To this end, we learn a distance
function based on different plan distance measures that can accurately model
this notion of plan explicability, and develop an anytime search algorithm that
can use this distance as a heuristic to come up with progressively explicable
plans. We evaluate the effectiveness of our approach in a simulated autonomous
car domain and a physical service robot domain. We provide empirical
evaluations that demonstrate the usefulness of our approach in making the
planning process of an autonomous agent conform to human expectations.
</dc:description>
 <dc:description>Comment: 10 pages, 10 figures</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05503</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Exploration of Convolutional Fusion Networks for Visual
  Recognition</dc:title>
 <dc:creator>Liu, Yu</dc:creator>
 <dc:creator>Guo, Yanming</dc:creator>
 <dc:creator>Lew, Michael S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Despite recent advances in multi-scale deep representations, their
limitations are attributed to expensive parameters and weak fusion modules.
Hence, we propose an efficient approach to fuse multi-scale deep
representations, called convolutional fusion networks (CFN). Owing to using
1$\times$1 convolution and global average pooling, CFN can efficiently generate
the side branches while adding few parameters. In addition, we present a
locally-connected fusion module, which can learn adaptive weights for the side
branches and form a discriminatively fused feature. CFN models trained on the
CIFAR and ImageNet datasets demonstrate remarkable improvements over the plain
CNNs. Furthermore, we generalize CFN to three new tasks, including scene
recognition, fine-grained recognition and image retrieval. Our experiments show
that it can obtain consistent improvements towards the transferring tasks.
</dc:description>
 <dc:description>Comment: 23rd International Conference on MultiMedia Modeling (MMM 2017)</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05507</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Feature Interpolation for Image Content Changes</dc:title>
 <dc:creator>Upchurch, Paul</dc:creator>
 <dc:creator>Gardner, Jacob</dc:creator>
 <dc:creator>Pleiss, Geoff</dc:creator>
 <dc:creator>Pless, Robert</dc:creator>
 <dc:creator>Snavely, Noah</dc:creator>
 <dc:creator>Bala, Kavita</dc:creator>
 <dc:creator>Weinberger, Kilian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose Deep Feature Interpolation (DFI), a new data-driven baseline for
automatic high-resolution image transformation. As the name suggests, it relies
only on simple linear interpolation of deep convolutional features from
pre-trained convnets. We show that despite its simplicity, DFI can perform
high-level semantic transformations like &quot;make older/younger&quot;, &quot;make
bespectacled&quot;, &quot;add smile&quot;, among others, surprisingly well - sometimes even
matching or outperforming the state-of-the-art. This is particularly unexpected
as DFI requires no specialized network architecture or even any deep network to
be trained for these tasks. DFI therefore can be used as a new baseline to
evaluate more complex algorithms and provides a practical answer to the
question of which image transformation tasks are still challenging in the rise
of deep learning.
</dc:description>
 <dc:description>Comment: First two authors contributed equally. Accepted by CVPR 2017. Code at
  https://github.com/paulu/deepfeatinterp</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-06-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05507</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05512</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unmatched Perturbation Accommodation for an Aerospace Launch Vehicle
  Autopilot Using Dynamic Sliding Manifolds</dc:title>
 <dc:creator>Saniee, Mohammad Reza</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Sliding mode control of a launch vehicle during its atmospheric flight phase
is studied in the presence of unmatched disturbances. Linear time-varying
dynamics of the aerospace vehicle is converted into a systematic formula and
then dynamic sliding manifold as an advanced method is used in order to
overcome the limited capability of conventional sliding manifolds in minimizing
the undesired effects of unmatched perturbations on the control system. At the
end, simulation results are evaluated and the performance of two approaches are
compared in terms of stability and robustness of the autopilot.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05512</dc:identifier>
 <dc:identifier>International Journal on Technical and Physical Problems of
  Engineering (IJTPE), September 2016, Issue 28, Volume 8, Number 3, Pages
  27-31</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05513</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dilated Floor Functions That Commute</dc:title>
 <dc:creator>Lagarias, Jeffrey C.</dc:creator>
 <dc:creator>Murayama, Takumi</dc:creator>
 <dc:creator>Richman, D. Harry</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>39B12 (Primary), 11J54, 68U05 (Secondary)</dc:subject>
 <dc:description>  We determine all pairs of real numbers $(\alpha, \beta)$ such that the
dilated floor functions $\lfloor \alpha x\rfloor$ and $\lfloor \beta x\rfloor$
commute under composition, i.e., such that $\lfloor \alpha \lfloor \beta
x\rfloor\rfloor = \lfloor \beta \lfloor \alpha x\rfloor\rfloor$ holds for all
real $x$.
</dc:description>
 <dc:description>Comment: 6 pages, to appear in Amer. Math. Monthly</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05513</dc:identifier>
 <dc:identifier>Amer. Math. Monthly 123, no. 10 (2016) 1033-1038</dc:identifier>
 <dc:identifier>doi:10.4169/amer.math.monthly.123.10.1033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05520</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Action- and Context-Aware Sequence Learning for Activity
  Recognition and Anticipation</dc:title>
 <dc:creator>Aliakbarian, Mohammad Sadegh</dc:creator>
 <dc:creator>Saleh, Fatemehsadat</dc:creator>
 <dc:creator>Fernando, Basura</dc:creator>
 <dc:creator>Salzmann, Mathieu</dc:creator>
 <dc:creator>Petersson, Lars</dc:creator>
 <dc:creator>Andersson, Lars</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Action recognition and anticipation are key to the success of many computer
vision applications. Existing methods can roughly be grouped into those that
extract global, context-aware representations of the entire image or sequence,
and those that aim at focusing on the regions where the action occurs. While
the former may suffer from the fact that context is not always reliable, the
latter completely ignore this source of information, which can nonetheless be
helpful in many situations. In this paper, we aim at making the best of both
worlds by developing an approach that leverages both context-aware and
action-aware features. At the core of our method lies a novel multi-stage
recurrent architecture that allows us to effectively combine these two sources
of information throughout a video. This architecture first exploits the global,
context-aware features, and merges the resulting representation with the
localized, action-aware ones. Our experiments on standard datasets evidence the
benefits of our approach over methods that use each information type
separately. We outperform the state-of-the-art methods that, as us, rely only
on RGB frames as input for both action recognition and anticipation.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures, 7 tables</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05521</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Hashing for Multi-View Data: Jointly Learning Low-Rank Kernelized
  Similarity Consensus and Hash Functions</dc:title>
 <dc:creator>Wu, Lin</dc:creator>
 <dc:creator>Wang, Yang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Learning hash functions/codes for similarity search over multi-view data is
attracting increasing attention, where similar hash codes are assigned to the
data objects characterizing consistently neighborhood relationship across
views. Traditional methods in this category inherently suffer three
limitations: 1) they commonly adopt a two-stage scheme where similarity matrix
is first constructed, followed by a subsequent hash function learning; 2) these
methods are commonly developed on the assumption that data samples with
multiple representations are noise-free,which is not practical in real-life
applications; 3) they often incur cumbersome training model caused by the
neighborhood graph construction using all $N$ points in the database ($O(N)$).
In this paper, we motivate the problem of jointly and efficiently training the
robust hash functions over data objects with multi-feature representations
which may be noise corrupted. To achieve both the robustness and training
efficiency, we propose an approach to effectively and efficiently learning
low-rank kernelized \footnote{We use kernelized similarity rather than kernel,
as it is not a squared symmetric matrix for data-landmark affinity matrix.}
hash functions shared across views. Specifically, we utilize landmark graphs to
construct tractable similarity matrices in multi-views to automatically
discover neighborhood structure in the data. To learn robust hash functions, a
latent low-rank kernel function is used to construct hash functions in order to
accommodate linearly inseparable data. In particular, a latent kernelized
similarity matrix is recovered by rank minimization on multiple kernel-based
similarity matrices. Extensive experiments on real-world multi-view datasets
validate the efficacy of our method in the presence of error corruptions.
</dc:description>
 <dc:description>Comment: Accepted to appear in Image and Vision Computing</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05527</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Node Selection for Deep Neural Networks using Group Lasso
  Regularization</dc:title>
 <dc:creator>Ochiai, Tsubasa</dc:creator>
 <dc:creator>Matsuda, Shigeki</dc:creator>
 <dc:creator>Watanabe, Hideyuki</dc:creator>
 <dc:creator>Katagiri, Shigeru</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We examine the effect of the Group Lasso (gLasso) regularizer in selecting
the salient nodes of Deep Neural Network (DNN) hidden layers by applying a
DNN-HMM hybrid speech recognizer to TED Talks speech data. We test two types of
gLasso regularization, one for outgoing weight vectors and another for incoming
weight vectors, as well as two sizes of DNNs: 2048 hidden layer nodes and 4096
nodes. Furthermore, we compare gLasso and L2 regularizers. Our experiment
results demonstrate that our DNN training, in which the gLasso regularizer was
embedded, successfully selected the hidden layer nodes that are necessary and
sufficient for achieving high classification power.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2017</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05527</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05530</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Improved Integrality Gap for the Calinescu-Karloff-Rabani Relaxation
  for Multiway Cut</dc:title>
 <dc:creator>Angelidakis, Haris</dc:creator>
 <dc:creator>Makarychev, Yury</dc:creator>
 <dc:creator>Manurangsi, Pasin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We construct an improved integrality gap instance for the
Calinescu-Karloff-Rabani LP relaxation of the Multiway Cut problem. In
particular, for $k \geqslant 3$ terminals, our instance has an integrality
ratio of $6 / (5 + \frac{1}{k - 1}) - \varepsilon$, for every constant
$\varepsilon &gt; 0$. For every $k \geqslant 4$, our result improves upon a
long-standing lower bound of $8 / (7 + \frac{1}{k - 1})$ by Freund and Karloff
(2000). Due to Manokaran et al.'s result (2008), our integrality gap also
implies Unique Games hardness of approximating Multiway Cut of the same ratio.
</dc:description>
 <dc:description>Comment: 18 pages, 6 figures</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05537</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Duplication Distance to the Root for Binary Sequences</dc:title>
 <dc:creator>Alon, Noga</dc:creator>
 <dc:creator>Bruck, Jehoshua</dc:creator>
 <dc:creator>Farnoud, Farzad</dc:creator>
 <dc:creator>Jain, Siddharth</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:description>  We study the tandem duplication distance between binary sequences and their
roots. In other words, the quantity of interest is the number of tandem
duplication operations of the form $\seq x = \seq a \seq b \seq c \to \seq y =
\seq a \seq b \seq b \seq c$, where $\seq x$ and $\seq y$ are sequences and
$\seq a$, $\seq b$, and $\seq c$ are their substrings, needed to generate a
binary sequence of length $n$ starting from a square-free sequence from the set
$\{0,1,01,10,010,101\}$. This problem is a restricted case of finding the
duplication/deduplication distance between two sequences, defined as the
minimum number of duplication and deduplication operations required to
transform one sequence to the other. We consider both exact and approximate
tandem duplications. For exact duplication, denoting the maximum distance to
the root of a sequence of length $n$ by $f(n)$, we prove that $f(n)=\Theta(n)$.
For the case of approximate duplication, where a $\beta$-fraction of symbols
may be duplicated incorrectly, we show that the maximum distance has a sharp
transition from linear in $n$ to logarithmic at $\beta=1/2$. We also study the
duplication distance to the root for sequences with a given root and for
special classes of sequences, namely, the de Bruijn sequences, the Thue-Morse
sequence, and the Fibbonaci words. The problem is motivated by genomic tandem
duplication mutations and the smallest number of tandem duplication events
required to generate a given biological sequence.
</dc:description>
 <dc:description>Comment: submitted to IEEE Transactions on Information Theory</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05539</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fog Computing: A Taxonomy, Survey and Future Directions</dc:title>
 <dc:creator>Mahmud, Redowan</dc:creator>
 <dc:creator>Kotagiri, Ramamohanarao</dc:creator>
 <dc:creator>Buyya, Rajkumar</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In recent years, the number of Internet of Things (IoT) devices/sensors has
increased to a great extent. To support the computational demand of real-time
latency-sensitive applications of largely geo-distributed IoT devices/sensors,
a new computing paradigm named &quot;Fog computing&quot; has been introduced. Generally,
Fog computing resides closer to the IoT devices/sensors and extends the
Cloud-based computing, storage and networking facilities. In this chapter, we
comprehensively analyse the challenges in Fogs acting as an intermediate layer
between IoT devices/ sensors and Cloud datacentres and review the current
developments in this field. We present a taxonomy of Fog computing according to
the identified challenges and its key features.We also map the existing works
to the taxonomy in order to identify current research gaps in the area of Fog
computing. Moreover, based on the observations, we propose future directions
for research.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-10-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05539</dc:identifier>
 <dc:identifier>Internet of Everything. Internet of Things (Technology,
  Communications and Computing), Springer 2017 103-130</dc:identifier>
 <dc:identifier>doi:10.1007/978-981-10-5861-5_5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05546</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zero-Shot Visual Question Answering</dc:title>
 <dc:creator>Teney, Damien</dc:creator>
 <dc:creator>Hengel, Anton van den</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Part of the appeal of Visual Question Answering (VQA) is its promise to
answer new questions about previously unseen images. Most current methods
demand training questions that illustrate every possible concept, and will
therefore never achieve this capability, since the volume of required training
data would be prohibitive. Answering general questions about images requires
methods capable of Zero-Shot VQA, that is, methods able to answer questions
beyond the scope of the training questions. We propose a new evaluation
protocol for VQA methods which measures their ability to perform Zero-Shot VQA,
and in doing so highlights significant practical deficiencies of current
approaches, some of which are masked by the biases in current datasets. We
propose and evaluate several strategies for achieving Zero-Shot VQA, including
methods based on pretrained word embeddings, object classifiers with semantic
embeddings, and test-time retrieval of example images. Our extensive
experiments are intended to serve as baselines for Zero-Shot VQA, and they also
achieve state-of-the-art performance in the standard VQA evaluation setting.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05546</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05548</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple Access Technologies for cellular M2M Communications: An
  Overview</dc:title>
 <dc:creator>Shirvanimoghaddam, Mahyar</dc:creator>
 <dc:creator>Johnson, Sarah</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper reviews the multiple access techniques for machine-to-machine
(M2M) communications in future wireless cellular networks. M2M communications
aims at providing te communication infrastructure for the emerging Internet of
Things (IoT), which will revolutionize the way we interact with our surrounding
physical environment. We provide an overview of the multiple access strategies
and explain their limitations when used for M2M communications. We show the
throughput efficiency of different multiple access techniques when used in
coordinated and uncoordinated scenarios. Non-orthogonal multiple access is also
shown to support a larger number of devices compared to orthogonal multiple
access techniques, especially in uncoordinated scenarios. We also detail the
issues and challenges of different multiple access techniques to be used for
M2M applications in cellular networks.
</dc:description>
 <dc:description>Comment: Submitted to ZTE Communications</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05549</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel multiple selection by regular sampling</dc:title>
 <dc:creator>Nowicki, Krzysztof</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this paper we present a deterministic parallel algorithm solving the
multiple selection problem in congested clique model. In this problem for given
set of elements S and a set of ranks $K = \{k_1 , k_2 , ..., k_r \}$ we are
asking for the $k_i$-th smallest element of $S$ for $1 \leq i \leq r$. The
presented algorithm is deterministic, time optimal , and needs $O(\log^*_{r+1}
(n))$ communication rounds, where $n$ is the size of the input set, and $r$ is
the size of the rank set. This algorithm may be of theoretical interest, as for
$r = 1$ (classic selection problem) it gives an improvement in the asymptotic
synchronization cost over previous $O(\log \log p)$ communication rounds
solution, where $p$ is size of clique.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05552</identifier>
 <datestamp>2017-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DelugeNets: Deep Networks with Efficient and Flexible Cross-layer
  Information Inflows</dc:title>
 <dc:creator>Kuen, Jason</dc:creator>
 <dc:creator>Kong, Xiangfei</dc:creator>
 <dc:creator>Wang, Gang</dc:creator>
 <dc:creator>Tan, Yap-Peng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deluge Networks (DelugeNets) are deep neural networks which efficiently
facilitate massive cross-layer information inflows from preceding layers to
succeeding layers. The connections between layers in DelugeNets are established
through cross-layer depthwise convolutional layers with learnable filters,
acting as a flexible yet efficient selection mechanism. DelugeNets can
propagate information across many layers with greater flexibility and utilize
network parameters more effectively compared to ResNets, whilst being more
efficient than DenseNets. Remarkably, a DelugeNet model with just model
complexity of 4.31 GigaFLOPs and 20.2M network parameters, achieve
classification errors of 3.76% and 19.02% on CIFAR-10 and CIFAR-100 dataset
respectively. Moreover, DelugeNet-122 performs competitively to ResNet-200 on
ImageNet dataset, despite costing merely half of the computations needed by the
latter.
</dc:description>
 <dc:description>Comment: Code: https://github.com/xternalz/DelugeNets</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05556</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Throughput of TCP over Cognitive Radio Channels</dc:title>
 <dc:creator>Poojary, Sudheer</dc:creator>
 <dc:creator>Agrawal, Akash</dc:creator>
 <dc:creator>Gupta, Bhoomika</dc:creator>
 <dc:creator>Bura, Archana</dc:creator>
 <dc:creator>Sharma, Vinod</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, we study the performance of a TCP connection over cognitive
radio networks. In these networks, the network may not always be available for
transmission. Also, the packets can be lost due to wireless channel
impairments. We evaluate the throughput and packet retransmission timeout
probability of a secondary TCP connection over an ON/OFF channel. We first
assume that the ON and OFF time durations are exponential and later extend it
to more general distributions. We then consider multiple TCP connections over
the ON/OFF channel. We validate our theoretical models and the approximations
made therein via ns2 simulations.
</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05556</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05557</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Prudent-Precedence Concurrency Control Protocol for High Data
  Contention Database Enviornments</dc:title>
 <dc:creator>Xiong, Weidong</dc:creator>
 <dc:creator>Yu, Feng</dc:creator>
 <dc:creator>Hamdi, Mohammed</dc:creator>
 <dc:creator>Hou, Wen-Chi</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  In this paper, we propose a concurrency control protocol, called the
Prudent-Precedence Concurrency Control (PPCC) protocol, for high data
contention database environments. PPCC is prudently more aggressive in
permitting more serializable schedules than two-phase locking. It maintains a
restricted precedence among conflicting transactions and commits the
transactions according to the serialization order established in the
executions. A detailed simulation model has been constructed and extensive
experiments have been conducted to evaluate the performance of the proposed
approach. The results demonstrate that the proposed algorithm outperforms the
two-phase locking and optimistic concurrency control in all ranges of system
workload.
</dc:description>
 <dc:description>Comment: 14 pages, 16 figures, 1 table</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05557</dc:identifier>
 <dc:identifier>International Journal of Database Management Systems (IJDMS),
  8(5), 1-14 (2016)</dc:identifier>
 <dc:identifier>doi:10.5121/ijdms.2016.8501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05558</identifier>
 <datestamp>2017-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Rank and Matrix Rigidity</dc:title>
 <dc:creator>Alman, Josh</dc:creator>
 <dc:creator>Williams, Ryan</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We consider a notion of probabilistic rank and probabilistic sign-rank of a
matrix, which measures the extent to which a matrix can be probabilistically
represented by low-rank matrices. We demonstrate several connections with
matrix rigidity, communication complexity, and circuit lower bounds, including:
  The Walsh-Hadamard Transform is Not Very Rigid. We give surprising upper
bounds on the rigidity of a family of matrices whose rigidity has been
extensively studied, and was conjectured to be highly rigid. For the $2^n
\times 2^n$ Walsh-Hadamard transform $H_n$ (a.k.a. Sylvester matrices, or the
communication matrix of Inner Product mod 2), we show how to modify only
$2^{\epsilon n}$ entries in each row and make the rank drop below
$2^{n(1-\Omega(\epsilon^2/\log(1/\epsilon)))}$, for all $\epsilon &gt; 0$, over
any field. That is, it is not possible to prove arithmetic circuit lower bounds
on Hadamard matrices, via L. Valiant's matrix rigidity approach. We also show
non-trivial rigidity upper bounds for $H_n$ with smaller target rank.
  Matrix Rigidity and Threshold Circuit Lower Bounds. We give new consequences
of rigid matrices for Boolean circuit complexity. We show that explicit $n
\times n$ Boolean matrices which maintain rank at least $2^{(\log
n)^{1-\delta}}$ after $n^2/2^{(\log n)^{\delta/2}}$ modified entries would
yield a function lacking sub-quadratic-size $AC^0$ circuits with two layers of
arbitrary linear threshold gates. We also prove that explicit 0/1 matrices over
$\mathbb{R}$ which are modestly more rigid than the best known rigidity lower
bounds for sign-rank would imply strong lower bounds for the infamously
difficult class $THR\circ THR$.
</dc:description>
 <dc:description>Comment: 21 pages</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05559</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boosting Variational Inference</dc:title>
 <dc:creator>Guo, Fangjian</dc:creator>
 <dc:creator>Wang, Xiangyu</dc:creator>
 <dc:creator>Fan, Kai</dc:creator>
 <dc:creator>Broderick, Tamara</dc:creator>
 <dc:creator>Dunson, David B.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Variational inference (VI) provides fast approximations of a Bayesian
posterior in part because it formulates posterior approximation as an
optimization problem: to find the closest distribution to the exact posterior
over some family of distributions. For practical reasons, the family of
distributions in VI is usually constrained so that it does not include the
exact posterior, even as a limit point. Thus, no matter how long VI is run, the
resulting approximation will not approach the exact posterior. We propose to
instead consider a more flexible approximating family consisting of all
possible finite mixtures of a parametric base distribution (e.g., Gaussian).
For efficient inference, we borrow ideas from gradient boosting to develop an
algorithm we call boosting variational inference (BVI). BVI iteratively
improves the current approximation by mixing it with a new component from the
base distribution family and thereby yields progressively more accurate
posterior approximations as more computing time is spent. Unlike a number of
common VI variants including mean-field VI, BVI is able to capture
multimodality, general posterior covariance, and nonstandard posterior shapes.
</dc:description>
 <dc:description>Comment: 17 pages, 7 figures</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05561</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fast and Provable Method for Estimating Clique Counts Using Tur\'an's
  Theorem</dc:title>
 <dc:creator>Jain, Shweta</dc:creator>
 <dc:creator>Seshadhri, C.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Clique counts reveal important properties about the structure of massive
graphs, especially social networks. The simple setting of just 3-cliques
(triangles) has received much attention from the research community. For larger
cliques (even, say 6-cliques) the problem quickly becomes intractable because
of combinatorial explosion. Most methods used for triangle counting do not
scale for large cliques, and existing algorithms require massive parallelism to
be feasible.
  We present a new randomized algorithm that provably approximates the number
of k-cliques, for any constant k. The key insight is the use of (strengthenings
of) the classic Tur\'an's theorem: this claims that if the edge density of a
graph is sufficiently high, the k-clique density must be non-trivial. We define
a combinatorial structure called a Tur\'an shadow, the construction of which
leads to fast algorithms for clique counting.
  We design a practical heuristic, called TUR\'AN-SHADOW, based on this
theoretical algorithm, and test it on a large class of test graphs. In all
cases,TUR\'AN-SHADOW has less than 2% error, in a fraction of the time used by
well-tuned exact algorithms. We do detailed comparisons with a range of other
sampling algorithms, and find that TUR\'AN-SHADOW is generally much faster and
more accurate. For example, TUR\'AN-SHADOW estimates all cliques numbers up to
size 10 in social network with over a hundred million edges. This is done in
less than three hours on a single commodity machine.
</dc:description>
 <dc:description>Comment: Added a link to the code</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05564</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on Quantum-Secure PRPs</dc:title>
 <dc:creator>Zhandry, Mark</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  We show how to construct pseudorandom permutations (PRPs) that remain secure
even if the adversary can query the permutation on a quantum superposition of
inputs. Such PRPs are called \emph{quantum-secure}. Our construction combines a
quantum-secure pseudorandom \emph{function} together with constructions of
\emph{classical} format preserving encryption. By combining known results, we
obtain the first quantum-secure PRP in this model whose security relies only on
the existence of one-way functions. Previously, to the best of the author's
knowledge, quantum security of PRPs had to be assumed, and there were no prior
security reductions to simpler primitives, let alone one-way functions.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05569</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Analytical Model for S-ALOHA Performance Evaluation in M2M Networks</dc:title>
 <dc:creator>Song, Qipeng</dc:creator>
 <dc:creator>Lagrange, Xavier</dc:creator>
 <dc:creator>Nuaymi, Loutfi</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The S-ALOHA (i.e. slotted-ALOHA) protocol is recently regaining interest in
Lower Power Wide Area Networks (LPWAN) handling M2M traffic. Despite intensive
studies since the birth of S-ALOHA, the special features of M2M traffic and
requirements highlight the importance of analytical models taking into account
performance-affecting factors and giving a thorough performance evaluation.
Fulfilling this necessity is the main focus of this paper: we jointly consider
the impact of capture effect, diversity of transmit power levels with imperfect
power control. We propose a low-complexity but still accurate analytical model
capable of evaluating S-ALOHA in terms of packet loss rate, throughput,
energy-efficiency and average number of transmissions. The proposed model is
able to facilitate dimensioning and design of S-ALOHA based LPWAN. The
comparison between simulation and analytical results confirms the accuracy of
our proposed model. The design guides about S-ALOHA based LPWAN deduced from
our model are: the imperfect power control can be positive with capture effect
and and appropriate transmit power diversity strategy. The transmit power
diversity strategy should be determined by jointly considering network charges
level, power control precision and capture ratio to achieve optimal performance
of S-ALOHA.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figurs, submmited to ICC2017</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05579</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bus Stops Location and Bus Route Planning Using Mean Shift Clustering
  and Ant Colony in West Jakarta</dc:title>
 <dc:creator>Supangat, Kenny</dc:creator>
 <dc:creator>Soelistio, Yustinus Eko</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Traffic Jam has been a daily problem for people in Jakarta which is one of
the busiest city in Indonesia up until now. Even though the official government
has tried to reduce the impact of traffic issues by developing a new public
transportation which takes up a lot of resources and time, it failed to
diminish the problem. The actual concern to this problem actually lies in how
people move between places in Jakarta where they always using their own vehicle
like cars, and motorcycles that fill most of the street in Jakarta. Among much
other public transportations that roams the street of Jakarta, Buses is
believed to be an efficient transportation that can move many people at once.
However, the location of the bus stop is now have moved to the middle of the
main road, and it is too far for the nearby residence to access to it. This
paper proposes an optimal location of optimal bus stops in West Jakarta that is
experimentally proven to have a maximal distance of 350 m. The optimal location
is estimated by means of mean shift clustering method while the optimal routes
are calculated using Ant Colony algorithm. The bus stops locations rate of
error is 0.07% with overall route area of 32 km. Based on our experiments, we
believe our proposed bus stop plan can be an interesting alternative to reduce
traffic congestion in West Jakarta.
</dc:description>
 <dc:description>Comment: Original publication in the ICITDA 2016 Conference (14-16 Nov. 2016),
  icitda.uii.ac.id</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05579</dc:identifier>
 <dc:identifier>doi:10.1088/1757-899X/185/1/012022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05588</identifier>
 <datestamp>2017-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Instance-aware Image and Sentence Matching with Selective Multimodal
  LSTM</dc:title>
 <dc:creator>Huang, Yan</dc:creator>
 <dc:creator>Wang, Wei</dc:creator>
 <dc:creator>Wang, Liang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Effective image and sentence matching depends on how to well measure their
global visual-semantic similarity. Based on the observation that such a global
similarity arises from a complex aggregation of multiple local similarities
between pairwise instances of image (objects) and sentence (words), we propose
a selective multimodal Long Short-Term Memory network (sm-LSTM) for
instance-aware image and sentence matching. The sm-LSTM includes a multimodal
context-modulated attention scheme at each timestep that can selectively attend
to a pair of instances of image and sentence, by predicting pairwise
instance-aware saliency maps for image and sentence. For selected pairwise
instances, their representations are obtained based on the predicted saliency
maps, and then compared to measure their local similarity. By similarly
measuring multiple local similarities within a few timesteps, the sm-LSTM
sequentially aggregates them with hidden states to obtain a final matching
score as the desired global similarity. Extensive experiments show that our
model can well match image and sentence with complex content, and achieve the
state-of-the-art results on two public benchmark datasets.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05588</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05590</identifier>
 <datestamp>2017-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convex Optimization of Distributed Cooperative Detection in
  Multi-Receiver Molecular Communication</dc:title>
 <dc:creator>Fang, Yuting</dc:creator>
 <dc:creator>Noel, Adam</dc:creator>
 <dc:creator>Yang, Nan</dc:creator>
 <dc:creator>Eckford, Andrew W.</dc:creator>
 <dc:creator>Kennedy, Rodney A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, the error performance achieved by cooperative detection among
K distributed receivers in a diffusion-based molecular communication (MC)
system is analyzed and optimized. In this system, the receivers first make
local hard decisions on the transmitted symbol and then report these decisions
to a fusion center (FC). The FC combines the local hard decisions to make a
global decision using an N-out-of-K fusion rule. Two reporting scenarios,
namely, perfect reporting and noisy reporting, are considered. Closed-form
expressions are derived for the expected global error probability of the system
for both reporting scenarios. New approximated expressions are also derived for
the expected error probability. Convex constraints are then found to make the
approximated expressions jointly convex with respect to the decision thresholds
at the receivers and the FC. Based on such constraints, suboptimal convex
optimization problems are formulated and solved to determine the optimal
decision thresholds which minimize the expected error probability of the
system. Numerical and simulation results reveal that the system error
performance is greatly improved by combining the detection information of
distributed receivers. They also reveal that the solutions to the formulated
suboptimal convex optimization problems achieve near-optimal global error
performance.
</dc:description>
 <dc:description>Comment: 14 page, 8 figures, submitted to IEEE Transactions on Molecular,
  Biological and Multi-Scale Communications. Copyright may be transferred
  without notice, after which this version may no longer be accessible</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05590</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05592</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multimodal Memory Modelling for Video Captioning</dc:title>
 <dc:creator>Wang, Junbo</dc:creator>
 <dc:creator>Wang, Wei</dc:creator>
 <dc:creator>Huang, Yan</dc:creator>
 <dc:creator>Wang, Liang</dc:creator>
 <dc:creator>Tan, Tieniu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Video captioning which automatically translates video clips into natural
language sentences is a very important task in computer vision. By virtue of
recent deep learning technologies, e.g., convolutional neural networks (CNNs)
and recurrent neural networks (RNNs), video captioning has made great progress.
However, learning an effective mapping from visual sequence space to language
space is still a challenging problem. In this paper, we propose a Multimodal
Memory Model (M3) to describe videos, which builds a visual and textual shared
memory to model the long-term visual-textual dependency and further guide
global visual attention on described targets. Specifically, the proposed M3
attaches an external memory to store and retrieve both visual and textual
contents by interacting with video and sentence with multiple read and write
operations. First, text representation in the Long Short-Term Memory (LSTM)
based text decoder is written into the memory, and the memory contents will be
read out to guide an attention to select related visual targets. Then, the
selected visual information is written into the memory, which will be further
read out to the text decoder. To evaluate the proposed model, we perform
experiments on two publicly benchmark datasets: MSVD and MSR-VTT. The
experimental results demonstrate that our method outperforms the
state-of-theart methods in terms of BLEU and METEOR.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05592</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05594</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SCA-CNN: Spatial and Channel-wise Attention in Convolutional Networks
  for Image Captioning</dc:title>
 <dc:creator>Chen, Long</dc:creator>
 <dc:creator>Zhang, Hanwang</dc:creator>
 <dc:creator>Xiao, Jun</dc:creator>
 <dc:creator>Nie, Liqiang</dc:creator>
 <dc:creator>Shao, Jian</dc:creator>
 <dc:creator>Liu, Wei</dc:creator>
 <dc:creator>Chua, Tat-Seng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual attention has been successfully applied in structural prediction tasks
such as visual captioning and question answering. Existing visual attention
models are generally spatial, i.e., the attention is modeled as spatial
probabilities that re-weight the last conv-layer feature map of a CNN encoding
an input image. However, we argue that such spatial attention does not
necessarily conform to the attention mechanism --- a dynamic feature extractor
that combines contextual fixations over time, as CNN features are naturally
spatial, channel-wise and multi-layer. In this paper, we introduce a novel
convolutional neural network dubbed SCA-CNN that incorporates Spatial and
Channel-wise Attentions in a CNN. In the task of image captioning, SCA-CNN
dynamically modulates the sentence generation context in multi-layer feature
maps, encoding where (i.e., attentive spatial locations at multiple layers) and
what (i.e., attentive channels) the visual attention is. We evaluate the
proposed SCA-CNN architecture on three benchmark image captioning datasets:
Flickr8K, Flickr30K, and MSCOCO. It is consistently observed that SCA-CNN
significantly outperforms state-of-the-art visual attention-based image
captioning methods.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05594</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05597</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decoupled Signal Detection for the Uplink of Large-Scale MIMO Systems in
  Heterogeneous Networks</dc:title>
 <dc:creator>Arevalo, L.</dc:creator>
 <dc:creator>de Lamare, R. C.</dc:creator>
 <dc:creator>Haardt, M.</dc:creator>
 <dc:creator>Sampaio-Neto, R.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Massive multiple-input multiple-output (MIMO) systems are strong candidates
for future fifth generation (5G) heterogeneous cellular networks. For 5G, a
network densification with a high number of different classes of users and data
service requirements is expected. Such a large number of connected devices
needs to be separated in order to allow the detection of the transmitted
signals according to different data requirements. In this paper, a decoupled
signal detection (DSD) technique which allows the separation of the uplink
signals, for each user class, at the base station (BS) is proposed for massive
MIMO systems. A mathematical signal model for massive MIMO systems with
centralized and distributed antennas in heterogeneous networks is also
developed. The performance of the proposed DSD algorithm is evaluated and
compared with existing detection schemes in a realistic scenario with
distributed antennas. A sum-rate analysis and a computational cost study for
DSD are also presented. Simulation results show an excellent performance of the
proposed DSD algorithm when combined with linear and successive interference
cancellation detection techniques.
</dc:description>
 <dc:description>Comment: 10 figures</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05597</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05603</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly-supervised Learning of Mid-level Features for Pedestrian
  Attribute Recognition and Localization</dc:title>
 <dc:creator>Yu, Kai</dc:creator>
 <dc:creator>Leng, Biao</dc:creator>
 <dc:creator>Zhang, Zhang</dc:creator>
 <dc:creator>Li, Dangwei</dc:creator>
 <dc:creator>Huang, Kaiqi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  State-of-the-art methods treat pedestrian attribute recognition as a
multi-label image classification problem. The location information of person
attributes is usually eliminated or simply encoded in the rigid splitting of
whole body in previous work. In this paper, we formulate the task in a
weakly-supervised attribute localization framework. Based on GoogLeNet,
firstly, a set of mid-level attribute features are discovered by novelly
designed detection layers, where a max-pooling based weakly-supervised object
detection technique is used to train these layers with only image-level labels
without the need of bounding box annotations of pedestrian attributes.
Secondly, attribute labels are predicted by regression of the detection
response magnitudes. Finally, the locations and rough shapes of pedestrian
attributes can be inferred by performing clustering on a fusion of activation
maps of the detection layers, where the fusion weights are estimated as the
correlation strengths between each attribute and its relevant mid-level
features. Extensive experiments are performed on the two currently largest
pedestrian attribute datasets, i.e. the PETA dataset and the RAP dataset.
Results show that the proposed method has achieved competitive performance on
attribute recognition, compared to other state-of-the-art methods. Moreover,
the results of attribute localization are visualized to understand the
characteristics of the proposed method.
</dc:description>
 <dc:description>Comment: Containing 9 pages and 5 figures. Codes open-sourced on
  https://github.com/kyu-sz/WPAL-network</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05604</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consecutive partitions of social networks between rivaling leaders</dc:title>
 <dc:creator>Krawczyk, Malgorzata J.</dc:creator>
 <dc:creator>Kulakowski, Krzysztof</dc:creator>
 <dc:creator>Holyst, Janusz A.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  A model algorithm is proposed to study subsequent partitions of complex
networks describing social structures. The partitions are supposed to appear as
actions of rivaling leaders corresponding to nodes with large degrees. The
condition of a partition is that the distance between two leaders is at least
three links. This ensures that the layer of nearest neighbours of each leader
remains attached to him. As a rule, numerically calculated size distribution of
fragments of scale-free Albert-Barabasi networks reveals one large fragment
which contains the original leader (hub of the network), and a number of small
fragments with opponents that are described by two Weibull distributions.
Numerical simulations and mean-field theory reveal that size of the larger
fragment scales as the square root of the initial network size. The algorithm
is applied to the data on political blogs in U.S. (L. Adamic and N. Glance,
Proc. WWW-2005). The obtained fragments are clearly polarized; either they
belong to Democrats, or to the GOP.
</dc:description>
 <dc:description>Comment: 15 pages, 7 figures</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05607</identifier>
 <datestamp>2017-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optical Flow Requires Multiple Strategies (but only one network)</dc:title>
 <dc:creator>Schuster, Tal</dc:creator>
 <dc:creator>Wolf, Lior</dc:creator>
 <dc:creator>Gadot, David</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We show that the matching problem that underlies optical flow requires
multiple strategies, depending on the amount of image motion and other factors.
We then study the implications of this observation on training a deep neural
network for representing image patches in the context of descriptor based
optical flow. We propose a metric learning method, which selects suitable
negative samples based on the nature of the true match. This type of training
produces a network that displays multiple strategies depending on the input and
leads to state of the art results on the KITTI 2012 and KITTI 2015 optical flow
benchmarks.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05616</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Stabilizing Maximal Matching and Anonymous Networks</dc:title>
 <dc:creator>Cohen, Johanne</dc:creator>
 <dc:creator>Lef&#xe8;vre, Jonas</dc:creator>
 <dc:creator>Ma&#xe2;mra, Khaled</dc:creator>
 <dc:creator>Pilard, Laurence</dc:creator>
 <dc:creator>Sohier, Devan</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We propose a self-stabilizing algorithm for computing a maximal matching in
an anonymous network. The complexity is $O(n^3)$ moves with high probability,
under the adversarial distributed daemon. In this algorithm, each node can
determine whether one of its neighbors points to it or to another node, leading
to a contradiction with the anonymous assumption. To solve this problem, we
provide under the classical link-register model, a self-stabilizing algorithm
that gives a unique name to a link such that this name is shared by both
extremities of the link.
</dc:description>
 <dc:description>Comment: 17 pages, 4 figures</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05616</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05619</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Backpressure on the Backbone: A Lightweight, Non-intrusive Traffic
  Engineering Approach</dc:title>
 <dc:creator>Liaskos, Christos</dc:creator>
 <dc:creator>Dimitropoulos, Xenofontas</dc:creator>
 <dc:creator>Tassiulas, Leandros</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The present study proposes a novel collaborative traffic engineering scheme
for networks of autonomous systems. Backpressure routing principles are used
for deriving priority routing rules that optimally stabilize a network, while
maximizing its throughput under latency considerations. The routing rules are
deployed to the network following simple SDN principles. The proposed scheme
requires minimal, infrequent interaction with a central controller, limiting
its imposed workload. Furthermore, it respects the internal structure of the
autonomous systems and their existing peering relations. In addition, it
co-exists smoothly with underlying distance vector-based routing schemes. The
proposed scheme combines simplicity with substantial gains in served transit
traffic volume, as shown by simulations in realistic setups and proven via
mathematical analysis.
</dc:description>
 <dc:description>Comment: Accepted for publication at IEEE Transactions on Network and Service
  Management (IEEE TNSM), October 2016</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05626</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Adaptive Compliance</dc:title>
 <dc:creator>Garc&#xed;a-Gal&#xe1;n, Jes&#xfa;s</dc:creator>
 <dc:creator>Pasquale, Liliana</dc:creator>
 <dc:creator>Grispos, George</dc:creator>
 <dc:creator>Nuseibeh, Bashar</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Mission critical software is often required to comply with multiple
regulations, standards or policies. Recent paradigms, such as cloud computing,
also require software to operate in heterogeneous, highly distributed, and
changing environments. In these environments, compliance requirements can vary
at runtime and traditional compliance management techniques, which are normally
applied at design time, may no longer be sufficient. In this paper, we motivate
the need for adaptive compliance by illustrating possible compliance concerns
determined by runtime variability. We further motivate our work by means of a
cloud computing scenario, and present two main contributions. First, we propose
and justify a process to support adaptive compliance that ex- tends the
traditional compliance management lifecycle with the activities of the
Monitor-Analyse-Plan-Execute (MAPE) loop, and enacts adaptation through
re-configuration. Second, we explore the literature on software compliance and
classify existing work in terms of the activities and concerns of adaptive
compliance. In this way, we determine how the literature can support our
proposal and what are the open research challenges that need to be addressed in
order to fully support adaptive compliance.
</dc:description>
 <dc:description>Comment: Position paper at SEAMS'16</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05626</dc:identifier>
 <dc:identifier>doi:10.1145/2897053.2897070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05633</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minor complexities of finite operations</dc:title>
 <dc:creator>Shtrakov, Slavcho</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Primary: 94C10, Secondary: 06E30, 68Q25, 68Q15</dc:subject>
 <dc:description>  In this paper we present a new class of complexity measures, induced by a new
data structure for representing $k$-valued functions (operations), called minor
decision diagram. The results are presented in terms of Multi-Valued Logic
circuits (MVL-circuits), ordered decision diagrams, formulas and minor
decomposition trees.
  When assigning values to some variables in a function $f$ the resulting
function is a subfunction of $f$, and when identifying some variables the
resulting function is a minor of $f$. A set $M$ of essential variables in $f$
is separable if there is a subfunction of $f$, whose set of essential variables
is $M$. The essential arity gap $gap(f)$ of the function $f$ is the minimum
number of essential variables in $f$ which become fictive when identifying
distinct essential variables in $f$. We prove that, if a function $f$ has
non-trivial arity gap ($gap(f)\ge 2$), then all sets of essential variables in
$f$ are separable. We define equivalence relations which classify the functions
of $k$-valued logic into classes with the same minor complexities. These
relations induce transformation groups which are compared with the subgroups of
the restricted affine group (RAG) and the groups determined by the equivalence
relations with respect to the subfunctions, implementations and separable sets
in functions. These methods provide a detailed classification of $n$-ary
$k$-valued functions for small values of $n$ and $k$.
</dc:description>
 <dc:description>Comment: 24 pages, 14 figures</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05633</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05638</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fictitious play for cooperative action selection in robot teams</dc:title>
 <dc:creator>Smyrnakis, Michalis</dc:creator>
 <dc:creator>Veres, Sandor M.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  A game theoretic distributed decision making approach is presented for the
problem of control effort allocation in a robotic team based on a novel variant
of fictitious play. The proposed learning process allows the robots to
accomplish their objectives by coordinating their actions in order to
efficiently complete their tasks. In particular, each robot of the team
predicts the other robots' planned actions while making decisions to maximise
their own expected reward that depends on the reward for joint successful
completion of the task. Action selection is interpreted as an $n$-player
cooperative game. The approach presented can be seen as part of the
\emph{Belief Desire Intention} (BDI) framework, also can address the problem of
cooperative, legal, safe, considerate and emphatic decisions by robots if their
individual and group rewards are suitably defined. After theoretical analysis
the performance of the proposed algorithm is tested on four simulation
scenarios. The first one is a coordination game between two material handling
robots, the second one is a warehouse patrolling task by a team of robots, the
third one presents a coordination mechanism between two robots that carry a
heavy object on a corridor and the fourth one is an example of coordination on
a sensors network.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1301.3347</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05638</dc:identifier>
 <dc:identifier>Engineering Applications of Artificial Intelligence, Volume 56,
  November 2016, Pages 14-29</dc:identifier>
 <dc:identifier>doi:10.1016/j.engappai.2016.08.008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05640</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stream Packing for Asynchronous Multi-Context Systems using ASP</dc:title>
 <dc:creator>Ellmauthaler, Stefan</dc:creator>
 <dc:creator>P&#xfc;hrer, J&#xf6;rg</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  When a processing unit relies on data from external streams, we may face the
problem that the stream data needs to be rearranged in a way that allows the
unit to perform its task(s). On arrival of new data, we must decide whether
there is sufficient information available to start processing or whether to
wait for more data. Furthermore, we need to ensure that the data meets the
input specification of the processing step. In the case of multiple input
streams it is also necessary to coordinate which data from which incoming
stream should form the input of the next process instantiation. In this work,
we propose a declarative approach as an interface between multiple streams and
a processing unit. The idea is to specify via answer-set programming how to
arrange incoming data in packages that are suitable as input for subsequent
processing. Our approach is intended for use in asynchronous multi-context
systems (aMCSs), a recently proposed framework for loose coupling of knowledge
representation formalisms that allows for online reasoning in a dynamic
environment. Contexts in aMCSs process data streams from external sources and
other contexts.
</dc:description>
 <dc:description>Comment: Workshop on Trends and Applications of Answer Set Programming (TAASP
  2016)</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05640</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05641</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational tameness of classical non-causal models</dc:title>
 <dc:creator>Baumeler, &#xc4;min</dc:creator>
 <dc:creator>Wolf, Stefan</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We show that the computational power of the non-causal circuit model, i.e.,
the circuit model where the assumption of a global causal order is replaced by
the assumption of logical consistency, is completely characterized by the
complexity class~$\operatorname{\mathsf{UP}}\cap\operatorname{\mathsf{coUP}}$.
An example of a problem in that class is factorization. Our result implies that
classical deterministic closed timelike curves (CTCs) cannot efficiently solve
problems that lie outside of that class. Thus, in stark contrast to other CTC
models, these CTCs cannot efficiently
solve~$\operatorname{\mathsf{NP-complete}}$ problems,
unless~$\operatorname{\mathsf{NP}}=\operatorname{\mathsf{UP}}\cap\operatorname{\mathsf{coUP}}=\operatorname{\mathsf{coNP}}$,
which lets their existence in nature appear less implausible. This result gives
a new characterization
of~$\operatorname{\mathsf{UP}}\cap\operatorname{\mathsf{coUP}}$ in terms of
fixed points.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures, 1 algorithm, revised</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05641</dc:identifier>
 <dc:identifier>Proceedings of the Royal Society A 474, 20170698, 2018</dc:identifier>
 <dc:identifier>doi:10.1098/rspa.2017.0698</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05642</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Minimisation: a Language-Based Approach (Long Version)</dc:title>
 <dc:creator>Antignac, Thibaud</dc:creator>
 <dc:creator>Sands, David</dc:creator>
 <dc:creator>Schneider, Gerardo</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Data minimisation is a privacy-enhancing principle considered as one of the
pillars of personal data regulations. This principle dictates that personal
data collected should be no more than necessary for the specific purpose
consented by the user. In this paper we study data minimisation from a
programming language perspective. We assume that a given program embodies the
purpose of data collection, and define a data minimiser as a pre-processor for
the input which reduces the amount of information available to the program
without compromising its functionality. In this context we study formal
definitions of data minimisation, present different mechanisms and
architectures to ensure data minimisation, and provide a procedure to
synthesise a correct data minimiser for a given program.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05644</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inverting The Generator Of A Generative Adversarial Network</dc:title>
 <dc:creator>Creswell, Antonia</dc:creator>
 <dc:creator>Bharath, Anil Anthony</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Generative adversarial networks (GANs) learn to synthesise new samples from a
high-dimensional distribution by passing samples drawn from a latent space
through a generative network. When the high-dimensional distribution describes
images of a particular data set, the network should learn to generate visually
similar image samples for latent variables that are close to each other in the
latent space. For tasks such as image retrieval and image classification, it
may be useful to exploit the arrangement of the latent space by projecting
images into it, and using this as a representation for discriminative tasks.
GANs often consist of multiple layers of non-linear computations, making them
very difficult to invert. This paper introduces techniques for projecting image
samples into the latent space using any pre-trained GAN, provided that the
computational graph is available. We evaluate these techniques on both MNIST
digits and Omniglot handwritten characters. In the case of MNIST digits, we
show that projections into the latent space maintain information about the
style and the identity of the digit. In the case of Omniglot characters, we
show that even characters from alphabets that have not been seen during
training may be projected well into the latent space; this suggests that this
approach may have applications in one-shot learning.
</dc:description>
 <dc:description>Comment: Accepted at NIPS 2016 Workshop on Adversarial Training</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05644</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05646</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online and Dynamic Algorithms for Set Cover</dc:title>
 <dc:creator>Gupta, Anupam</dc:creator>
 <dc:creator>Krishnaswamy, Ravishankar</dc:creator>
 <dc:creator>Kumar, Amit</dc:creator>
 <dc:creator>Panigrahi, Debmalya</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we study the set cover problem in the fully dynamic model. In
this model, the set of active elements, i.e., those that must be covered at any
given time, can change due to element arrivals and departures. The goal is to
maintain an algorithmic solution that is competitive with respect to the
current optimal solution. This model is popular in both the dynamic algorithms
and online algorithms communities. The difference is in the restriction placed
on the algorithm: in dynamic algorithms, the running time of the algorithm
making updates (called update time) is bounded, while in online algorithms, the
number of updates made to the solution (called recourse) is limited.
  In this paper we show the following results: In the update time setting, we
obtain O(log n)-competitiveness with O(f log n) amortized update time, and
O(f^3)-competitiveness with O(f^2) update time. The O(log n)-competitive
algorithm is the first one to achieve a competitive ratio independent of f in
this setting. In the recourse setting, we show a competitive ratio of O(min{log
n,f}) with constant amortized recourse. Note that this matches the best offline
bounds with just constant recourse, something that is impossible in the
classical online model.
  Our results are based on two algorithmic frameworks in the fully-dynamic
model that are inspired by the classic greedy and primal-dual algorithms for
offline set cover. We show that both frameworks can be used for obtaining both
recourse and update time bounds, thereby demonstrating algorithmic techniques
common to these strands of research.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05646</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05651</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Theory of Available-by-Design Communicating Systems</dc:title>
 <dc:creator>L&#xf3;pez, Hugo A.</dc:creator>
 <dc:creator>Nielson, Flemming</dc:creator>
 <dc:creator>Nielson, Hanne Riis</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>68Q55, 68Q60, 68Q85</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>B.8.1</dc:subject>
 <dc:description>  Choreographic programming is a programming-language design approach that
drives error-safe protocol development in distributed systems. Starting from a
global specification (choreography) one can generate distributed
implementations. The advantages of this top-down approach lie in the
correctness-by-design principle, where implementations (endpoints) generated
from a choreography behave according to the strict control flow described in
the choreography, and do not deadlock. Motivated by challenging scenarios in
Cyber-Physical Systems (CPS), we study how choreographic programming can cater
for dynamic infrastructures where not all endpoints are always available. We
introduce the Global Quality Calculus ($GC_q$), a variant of choreographic
programming for the description of communication systems where some of the
components involved in a communication might fail. GCq features novel operators
for multiparty, partial and collective communications. This paper studies the
nature of failure-aware communication: First, we introduce $GC_q$ syntax,
semantics and examples of its use. The interplay between failures and
collective communications in a choreography can lead to choreographies that
cannot progress due to absence of resources. In our second contribution, we
provide a type system that ensures that choreographies can be realized despite
changing availability conditions. A specification in $GC_q$ guides the
implementation of distributed endpoints when paired with global (session)
types. Our third contribution provides an endpoint-projection based methodology
for the generation of failure-aware distributed processes. We show the
correctness of the projection, and that well-typed choreographies with
availability considerations enjoy progress.
</dc:description>
 <dc:description>Comment: Extended version of paper entitled &quot;Enforcing Availability in
  Failure-Aware Communicating Systems&quot;, presented at FORTE 2016. 30 pages
  (original paper) + 19 pages of appendixes</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05653</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Iterative Channel Estimation Using LSE and Sparse Message Passing for
  MmWave MIMO Systems</dc:title>
 <dc:creator>Huang, Chongwen</dc:creator>
 <dc:creator>Liu, Lei</dc:creator>
 <dc:creator>Yuen, Chau</dc:creator>
 <dc:creator>Sun, Sumei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose an iterative channel estimation algorithm based on the Least
Square Estimation (LSE) and Sparse Message Passing (SMP) algorithm for the
Millimeter Wave (mmWave) MIMO systems. The channel coefficients of the mmWave
MIMO are approximately modeled as a Bernoulli-Gaussian distribution since there
are relatively fewer paths in the mmWave channel, i.e., the channel matrix is
sparse and only has a few non-zero entries. By leveraging the advantage of
sparseness, we proposed an algorithm that iteratively detects the exact
location and value of non-zero entries of the sparse channel matrix. The SMP is
used to detect the exact location of non-zero entries of the channel matrix,
while the LSE is used for estimating its value at each iteration. We also
analyze the Cramer-Rao Lower Bound (CLRB), and show that the proposed algorithm
is a minimum variance unbiased estimator. Furthermore, we employ the Gaussian
approximation for message densities under density evolution to simplify the
analysis of the algorithm, which provides a simple method to predict the
performance of the proposed algorithm. Numerical experiments show that the
proposed algorithm has much better performance than the existing sparse
estimators, especially when the channel is sparse. In addition, our proposed
algorithm converges to the CRLB of the genie-aided estimation of sparse
channels in just 5 turbo iterations.
</dc:description>
 <dc:description>Comment: 31 pages, 10 figures, submitted to IEEE JSAC Special Issue on
  Millimeter Wave Communications for Future Mobile Networks</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05653</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05656</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Swap Equilibria under Link and Vertex Destruction</dc:title>
 <dc:creator>Kliemann, Lasse</dc:creator>
 <dc:creator>Sheykhdarabadi, Elmira Shirazi</dc:creator>
 <dc:creator>Srivastav, Anand</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We initiate the study of the \emph{destruction model} (\aka \emph{adversary
model}) introduced by Kliemann (2010), using the stability concept of
\emph{swap equilibrium} introduced by Alon et. al (2010). The destruction model
is a network formation game incorporating the robustness of a network under a
more or less targeted attack. In addition to bringing in the swap equilibrium
(SE) concept, we extend the model from an attack on the edges of the network to
an attack on its vertices. Vertex destruction can generally cause more harm and
tends to be more difficult to analyze.
  We prove structural results and linear upper bounds or super-linear lower
bounds on the social cost of SE under different attack scenarios. The most
complex case is when the vertex to be destroyed is chosen uniformly at random
from the set of those vertices where each causes a maximum number of player
pairs to be separated (called a max-sep vertex). We prove a lower bound on the
social cost of $\Omega(n^{3/2})$ for this case and initiate an understanding of
the structural properties of SE in this scenario. Namely, we prove that there
is no SE that is a tree and has only one max-sep vertex. We conjecture that
this result can be generalized, in particular we conjecture that there is no SE
that is a tree. On the other hand, we prove that if the vertex to be destroyed
is chosen uniformly at random from the set of \emph{all} vertices, then each SE
is a tree (unless it is two-connected). Our conjecture would imply that moving
from the uniform probability measure to a measure concentrated on the max-sep
vertices, means moving from no SE having a cycle (unless two-connected) to each
SE having a cycle. This would ask for a more detailed study of this transition
in future work.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05656</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05660</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Matrix Chain Algorithm to Compile Linear Algebra Expressions</dc:title>
 <dc:creator>Barthels, Henrik</dc:creator>
 <dc:creator>Bientinesi, Paolo</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The matrix chain problem consists in finding the parenthesization of a matrix
product $M := A_1 A_2 \cdots A_n$ that minimizes the number of scalar
operations. In practical applications, however, one frequently encounters more
complicated scenarios, where expressions involve transposition, inversion,
matrices with given properties, and sequences. The computation of such
expressions makes use of a set of computational kernels that offer
functionality well beyond the simple matrix product. The challenge then shifts
from finding an optimal parenthesization to finding an optimal mapping of the
input expression to the available kernels. Furthermore, it is often the case
that a solution based on the minimization of scalar operations does not result
in the optimal solution in terms of execution time, and/or might be numerically
unstable. In this paper, we introduce a number of generalizations of the matrix
chain problem--including kernels, properties, sequences, and cost
functions--and present corresponding algorithmic solutions.
  The motivation for this work comes from the fact that--despite great advances
in the development of compilers--the task of mapping linear algebra problems to
optimized kernels is still to be done manually. In order to relieve the user
from this complex task, new techniques for the compilation of linear algebra
expressions have to be developed.
</dc:description>
 <dc:description>Comment: DSLDI 2016</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05664</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to detect and localize many objects from few examples</dc:title>
 <dc:creator>Moysset, Bastien</dc:creator>
 <dc:creator>Kermorvant, Christoper</dc:creator>
 <dc:creator>Wolf, Christian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The current trend in object detection and localization is to learn
predictions with high capacity deep neural networks trained on a very large
amount of annotated data and using a high amount of processing power. In this
work, we propose a new neural model which directly predicts bounding box
coordinates. The particularity of our contribution lies in the local
computations of predictions with a new form of local parameter sharing which
keeps the overall amount of trainable parameters low. Key components of the
model are spatial 2D-LSTM recurrent layers which convey contextual information
between the regions of the image. We show that this model is more powerful than
the state of the art in applications where training data is not as abundant as
in the classical configuration of natural images and Imagenet/Pascal VOC tasks.
We particularly target the detection of text in document images, but our method
is not limited to this setting. The proposed model also facilitates the
detection of many objects in a single image and can deal with inputs of
variable sizes without resizing.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05666</identifier>
 <datestamp>2017-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Discriminatively Learned CNN Embedding for Person Re-identification</dc:title>
 <dc:creator>Zheng, Zhedong</dc:creator>
 <dc:creator>Zheng, Liang</dc:creator>
 <dc:creator>Yang, Yi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We revisit two popular convolutional neural networks (CNN) in person
re-identification (re-ID), i.e, verification and classification models. The two
models have their respective advantages and limitations due to different loss
functions. In this paper, we shed light on how to combine the two models to
learn more discriminative pedestrian descriptors. Specifically, we propose a
new siamese network that simultaneously computes identification loss and
verification loss. Given a pair of training images, the network predicts the
identities of the two images and whether they belong to the same identity. Our
network learns a discriminative embedding and a similarity measurement at the
same time, thus making full usage of the annotations. Albeit simple, the
learned embedding improves the state-of-the-art performance on two public
person re-ID benchmarks. Further, we show our architecture can also be applied
in image retrieval.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05672</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Algebraic Intersection Type Unification Problem</dc:title>
 <dc:creator>Dudenhefner, Andrej</dc:creator>
 <dc:creator>Martens, Moritz</dc:creator>
 <dc:creator>Rehof, Jakob</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  The algebraic intersection type unification problem is an important component
in proof search related to several natural decision problems in intersection
type systems. It is unknown and remains open whether the algebraic intersection
type unification problem is decidable. We give the first nontrivial lower bound
for the problem by showing (our main result) that it is exponential time hard.
Furthermore, we show that this holds even under rank 1 solutions (substitutions
whose codomains are restricted to contain rank 1 types). In addition, we
provide a fixed-parameter intractability result for intersection type matching
(one-sided unification), which is known to be NP-complete.
  We place the algebraic intersection type unification problem in the context
of unification theory. The equational theory of intersection types can be
presented as an algebraic theory with an ACI (associative, commutative, and
idempotent) operator (intersection type) combined with distributivity
properties with respect to a second operator (function type). Although the
problem is algebraically natural and interesting, it appears to occupy a
hitherto unstudied place in the theory of unification, and our investigation of
the problem suggests that new methods are required to understand the problem.
Thus, for the lower bound proof, we were not able to reduce from known results
in ACI-unification theory and use game-theoretic methods for two-player tiling
games.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05672</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 3 (August
  15, 2017) lmcs:3858</dc:identifier>
 <dc:identifier>doi:10.23638/LMCS-13(3:9)2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05675</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Study on Feature Subspace of Archetypal Emotions for Speech Emotion
  Recognition</dc:title>
 <dc:creator>Ma, Xi</dc:creator>
 <dc:creator>Wu, Zhiyong</dc:creator>
 <dc:creator>Jia, Jia</dc:creator>
 <dc:creator>Xu, Mingxing</dc:creator>
 <dc:creator>Meng, Helen</dc:creator>
 <dc:creator>Cai, Lianhong</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Feature subspace selection is an important part in speech emotion
recognition. Most of the studies are devoted to finding a feature subspace for
representing all emotions. However, some studies have indicated that the
features associated with different emotions are not exactly the same. Hence,
traditional methods may fail to distinguish some of the emotions with just one
global feature subspace. In this work, we propose a new divide and conquer idea
to solve the problem. First, the feature subspaces are constructed for all the
combinations of every two different emotions (emotion-pair). Bi-classifiers are
then trained on these feature subspaces respectively. The final emotion
recognition result is derived by the voting and competition method.
Experimental results demonstrate that the proposed method can get better
results than the traditional multi-classification method.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures, ICASSP-2017</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05689</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end Learning of Cost-Volume Aggregation for Real-time Dense
  Stereo</dc:title>
 <dc:creator>Kuzmin, Andrey</dc:creator>
 <dc:creator>Mikushin, Dmitry</dc:creator>
 <dc:creator>Lempitsky, Victor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a new deep learning-based approach for dense stereo matching.
Compared to previous works, our approach does not use deep learning of pixel
appearance descriptors, employing very fast classical matching scores instead.
At the same time, our approach uses a deep convolutional network to predict the
local parameters of cost volume aggregation process, which in this paper we
implement using differentiable domain transform. By treating such transform as
a recurrent neural network, we are able to train our whole system that includes
cost volume computation, cost-volume aggregation (smoothing), and
winner-takes-all disparity selection end-to-end. The resulting method is highly
efficient at test time, while achieving good matching accuracy. On the KITTI
2015 benchmark, it achieves a result of 6.34\% error rate while running at 29
frames per second rate on a modern GPU.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05689</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05705</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DSAC - Differentiable RANSAC for Camera Localization</dc:title>
 <dc:creator>Brachmann, Eric</dc:creator>
 <dc:creator>Krull, Alexander</dc:creator>
 <dc:creator>Nowozin, Sebastian</dc:creator>
 <dc:creator>Shotton, Jamie</dc:creator>
 <dc:creator>Michel, Frank</dc:creator>
 <dc:creator>Gumhold, Stefan</dc:creator>
 <dc:creator>Rother, Carsten</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  RANSAC is an important algorithm in robust optimization and a central
building block for many computer vision applications. In recent years,
traditionally hand-crafted pipelines have been replaced by deep learning
pipelines, which can be trained in an end-to-end fashion. However, RANSAC has
so far not been used as part of such deep learning pipelines, because its
hypothesis selection procedure is non-differentiable. In this work, we present
two different ways to overcome this limitation. The most promising approach is
inspired by reinforcement learning, namely to replace the deterministic
hypothesis selection by a probabilistic selection for which we can derive the
expected loss w.r.t. to all learnable parameters. We call this approach DSAC,
the differentiable counterpart of RANSAC. We apply DSAC to the problem of
camera localization, where deep learning has so far failed to improve on
traditional approaches. We demonstrate that by directly minimizing the expected
loss of the output camera poses, robustly estimated by RANSAC, we achieve an
increase in accuracy. In the future, any deep learning pipeline can use DSAC as
a robust optimization component.
</dc:description>
 <dc:description>Comment: CVPR 2017</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05708</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Fuse 2D and 3D Image Cues for Monocular Body Pose Estimation</dc:title>
 <dc:creator>Tekin, Bugra</dc:creator>
 <dc:creator>M&#xe1;rquez-Neila, Pablo</dc:creator>
 <dc:creator>Salzmann, Mathieu</dc:creator>
 <dc:creator>Fua, Pascal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Most recent approaches to monocular 3D human pose estimation rely on Deep
Learning. They typically involve regressing from an image to either 3D joint
coordinates directly or 2D joint locations from which 3D coordinates are
inferred. Both approaches have their strengths and weaknesses and we therefore
propose a novel architecture designed to deliver the best of both worlds by
performing both simultaneously and fusing the information along the way. At the
heart of our framework is a trainable fusion scheme that learns how to fuse the
information optimally instead of being hand-designed. This yields significant
improvements upon the state-of-the-art on standard 3D human pose estimation
benchmarks.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05708</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05709</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Factorized Bilinear Models for Image Recognition</dc:title>
 <dc:creator>Li, Yanghao</dc:creator>
 <dc:creator>Wang, Naiyan</dc:creator>
 <dc:creator>Liu, Jiaying</dc:creator>
 <dc:creator>Hou, Xiaodi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Although Deep Convolutional Neural Networks (CNNs) have liberated their power
in various computer vision tasks, the most important components of CNN,
convolutional layers and fully connected layers, are still limited to linear
transformations. In this paper, we propose a novel Factorized Bilinear (FB)
layer to model the pairwise feature interactions by considering the quadratic
terms in the transformations. Compared with existing methods that tried to
incorporate complex non-linearity structures into CNNs, the factorized
parameterization makes our FB layer only require a linear increase of
parameters and affordable computational cost. To further reduce the risk of
overfitting of the FB layer, a specific remedy called DropFactor is devised
during the training process. We also analyze the connection between FB layer
and some existing models, and show FB layer is a generalization to them.
Finally, we validate the effectiveness of FB layer on several widely adopted
datasets including CIFAR-10, CIFAR-100 and ImageNet, and demonstrate superior
results compared with various state-of-the-art deep models.
</dc:description>
 <dc:description>Comment: Accepted by ICCV 2017</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05720</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hard-Aware Deeply Cascaded Embedding</dc:title>
 <dc:creator>Yuan, Yuhui</dc:creator>
 <dc:creator>Yang, Kuiyuan</dc:creator>
 <dc:creator>Zhang, Chao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Riding on the waves of deep neural networks, deep metric learning has also
achieved promising results in various tasks using triplet network or Siamese
network. Though the basic goal of making images from the same category closer
than the ones from different categories is intuitive, it is hard to directly
optimize due to the quadratic or cubic sample size. To solve the problem, hard
example mining which only focuses on a subset of samples that are considered
hard is widely used. However, hard is defined relative to a model, where
complex models treat most samples as easy ones and vice versa for simple
models, and both are not good for training. Samples are also with different
hard levels, it is hard to define a model with the just right complexity and
choose hard examples adequately. This motivates us to ensemble a set of models
with different complexities in cascaded manner and mine hard examples
adaptively, a sample is judged by a series of models with increasing
complexities and only updates models that consider the sample as a hard case.
We evaluate our method on CARS196, CUB-200-2011, Stanford Online Products,
VehicleID and DeepFashion datasets. Our method outperforms state-of-the-art
methods by a large margin.
</dc:description>
 <dc:description>Comment: accepted by ICCV 2017</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05720</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05722</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GENESIM: genetic extraction of a single, interpretable model</dc:title>
 <dc:creator>Vandewiele, Gilles</dc:creator>
 <dc:creator>Janssens, Olivier</dc:creator>
 <dc:creator>Ongenae, Femke</dc:creator>
 <dc:creator>De Turck, Filip</dc:creator>
 <dc:creator>Van Hoecke, Sofie</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Models obtained by decision tree induction techniques excel in being
interpretable.However, they can be prone to overfitting, which results in a low
predictive performance. Ensemble techniques are able to achieve a higher
accuracy. However, this comes at a cost of losing interpretability of the
resulting model. This makes ensemble techniques impractical in applications
where decision support, instead of decision making, is crucial.
  To bridge this gap, we present the GENESIM algorithm that transforms an
ensemble of decision trees to a single decision tree with an enhanced
predictive performance by using a genetic algorithm. We compared GENESIM to
prevalent decision tree induction and ensemble techniques using twelve publicly
available data sets. The results show that GENESIM achieves a better predictive
performance on most of these data sets than decision tree induction techniques
and a predictive performance in the same order of magnitude as the ensemble
techniques. Moreover, the resulting model of GENESIM has a very low complexity,
making it very interpretable, in contrast to ensemble techniques.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05722</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05723</identifier>
 <datestamp>2017-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Achievable Uplink Rates for Massive MIMO with Coarse Quantization</dc:title>
 <dc:creator>Moll&#xe9;n, Christopher</dc:creator>
 <dc:creator>Choi, Junil</dc:creator>
 <dc:creator>Larsson, Erik G.</dc:creator>
 <dc:creator>Heath Jr, Robert W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The high hardware complexity of a massive MIMO base station, which requires
hundreds of radio chains, makes it challenging to build commercially. One way
to reduce the hardware complexity and power consumption of the receiver is to
lower the resolution of the analog-to-digital converters (ADCs). We derive an
achievable rate for a massive MIMO system with arbitrary quantization and use
this rate to show that ADCs with as low as 3 bits can be used without
significant performance loss at spectral efficiencies around 3.5 bpcu per user,
also under interference from stronger transmitters and with some imperfections
in the automatic gain control.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05723</dc:identifier>
 <dc:identifier>IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP), New Orleans, Mar. 2017, pp. 6488-6492</dc:identifier>
 <dc:identifier>doi:10.1109/ICASSP.2017.7953406</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05724</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unimodal Thompson Sampling for Graph-Structured Arms</dc:title>
 <dc:creator>Paladino, Stefano</dc:creator>
 <dc:creator>Trov&#xf2;, Francesco</dc:creator>
 <dc:creator>Restelli, Marcello</dc:creator>
 <dc:creator>Gatti, Nicola</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study, to the best of our knowledge, the first Bayesian algorithm for
unimodal Multi-Armed Bandit (MAB) problems with graph structure. In this
setting, each arm corresponds to a node of a graph and each edge provides a
relationship, unknown to the learner, between two nodes in terms of expected
reward. Furthermore, for any node of the graph there is a path leading to the
unique node providing the maximum expected reward, along which the expected
reward is monotonically increasing. Previous results on this setting describe
the behavior of frequentist MAB algorithms. In our paper, we design a Thompson
Sampling-based algorithm whose asymptotic pseudo-regret matches the lower bound
for the considered setting. We show that -as it happens in a wide number of
scenarios- Bayesian MAB algorithms dramatically outperform frequentist ones. In
particular, we provide a thorough experimental evaluation of the performance of
our and state-of-the-art algorithms as the properties of the graph vary.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05725</identifier>
 <datestamp>2017-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PolyNet: A Pursuit of Structural Diversity in Very Deep Networks</dc:title>
 <dc:creator>Zhang, Xingcheng</dc:creator>
 <dc:creator>Li, Zhizhong</dc:creator>
 <dc:creator>Loy, Chen Change</dc:creator>
 <dc:creator>Lin, Dahua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A number of studies have shown that increasing the depth or width of
convolutional networks is a rewarding approach to improve the performance of
image recognition. In our study, however, we observed difficulties along both
directions. On one hand, the pursuit for very deep networks is met with a
diminishing return and increased training difficulty; on the other hand,
widening a network would result in a quadratic growth in both computational
cost and memory demand. These difficulties motivate us to explore structural
diversity in designing deep networks, a new dimension beyond just depth and
width. Specifically, we present a new family of modules, namely the
PolyInception, which can be flexibly inserted in isolation or in a composition
as replacements of different parts of a network. Choosing PolyInception modules
with the guidance of architectural efficiency can improve the expressive power
while preserving comparable computational cost. The Very Deep PolyNet, designed
following this direction, demonstrates substantial improvements over the
state-of-the-art on the ILSVRC 2012 benchmark. Compared to Inception-ResNet-v2,
it reduces the top-5 validation error on single crops from 4.9% to 4.25%, and
that on multi-crops from 3.7% to 3.45%.
</dc:description>
 <dc:description>Comment: Tech report</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05735</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Dynamic Coverage Infrastructure for Large-Scale Fleets of
  Reconnaissance UAVs</dc:title>
 <dc:creator>Altshuler, Yaniv</dc:creator>
 <dc:creator>Pentland, Alex</dc:creator>
 <dc:creator>Bekhor, Shlomo</dc:creator>
 <dc:creator>Shiftan, Yoram</dc:creator>
 <dc:creator>Bruckstein, Alfred</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Current state of the art in the field of UAV activation relies solely on
human operators for the design and adaptation of the drones' flying routes.
Furthermore, this is being done today on an individual level (one vehicle per
operators), with some exceptions of a handful of new systems, that are
comprised of a small number of self-organizing swarms, manually guided by a
human operator.
  Drones-based monitoring is of great importance in variety of civilian
domains, such as road safety, homeland security, and even environmental
control. In its military aspect, efficiently detecting evading targets by a
fleet of unmanned drones has an ever increasing impact on the ability of modern
armies to engage in warfare. The latter is true both traditional symmetric
conflicts among armies as well as asymmetric ones. Be it a speeding driver, a
polluting trailer or a covert convoy, the basic challenge remains the same --
how can its detection probability be maximized using as little number of drones
as possible.
  In this work we propose a novel approach for the optimization of large scale
swarms of reconnaissance drones -- capable of producing on-demand optimal
coverage strategies for any given search scenario. Given an estimation cost of
the threat's potential damages, as well as types of monitoring drones available
and their comparative performance, our proposed method generates an
analytically provable strategy, stating the optimal number and types of drones
to be deployed, in order to cost-efficiently monitor a pre-defined region for
targets maneuvering using a given roads networks.
  We demonstrate our model using a unique dataset of the Israeli transportation
network, on which different deployment schemes for drones deployment are
evaluated.
</dc:description>
 <dc:description>Comment: 35 pages, 19 figures</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05735</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05740</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Non-Parametric Tests of Relative Dependency and Similarity</dc:title>
 <dc:creator>Bounliphone, Wacha</dc:creator>
 <dc:creator>Belilovsky, Eugene</dc:creator>
 <dc:creator>Tenenhaus, Arthur</dc:creator>
 <dc:creator>Antonoglou, Ioannis</dc:creator>
 <dc:creator>Gretton, Arthur</dc:creator>
 <dc:creator>Blashcko, Matthew B.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We introduce two novel non-parametric statistical hypothesis tests. The first
test, called the relative test of dependency, enables us to determine whether
one source variable is significantly more dependent on a first target variable
or a second. Dependence is measured via the Hilbert-Schmidt Independence
Criterion (HSIC). The second test, called the relative test of similarity, is
use to determine which of the two samples from arbitrary distributions is
significantly closer to a reference sample of interest and the relative measure
of similarity is based on the Maximum Mean Discrepancy (MMD). To construct
these tests, we have used as our test statistics the difference of HSIC
statistics and of MMD statistics, respectively. The resulting tests are
consistent and unbiased, and have favorable convergence properties. The
effectiveness of the relative dependency test is demonstrated on several
real-world problems: we identify languages groups from a multilingual parallel
corpus, and we show that tumor location is more dependent on gene expression
than chromosome imbalance. We also demonstrate the performance of the relative
test of similarity over a broad selection of model comparisons problems in deep
generative models.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05742</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building Deep Networks on Grassmann Manifolds</dc:title>
 <dc:creator>Huang, Zhiwu</dc:creator>
 <dc:creator>Wu, Jiqing</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learning representations on Grassmann manifolds is popular in quite a few
visual recognition tasks. In order to enable deep learning on Grassmann
manifolds, this paper proposes a deep network architecture by generalizing the
Euclidean network paradigm to Grassmann manifolds. In particular, we design
full rank mapping layers to transform input Grassmannian data to more desirable
ones, exploit re-orthonormalization layers to normalize the resulting matrices,
study projection pooling layers to reduce the model complexity in the
Grassmannian context, and devise projection mapping layers to respect
Grassmannian geometry and meanwhile achieve Euclidean forms for regular output
layers. To train the Grassmann networks, we exploit a stochastic gradient
descent setting on manifolds of the connection weights, and study a matrix
generalization of backpropagation to update the structured data. The
evaluations on three visual recognition tasks show that our Grassmann networks
have clear advantages over existing Grassmann learning methods, and achieve
results comparable with state-of-the-art approaches.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05743</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relational Multi-Manifold Co-Clustering</dc:title>
 <dc:creator>Li, Ping</dc:creator>
 <dc:creator>Bu, Jiajun</dc:creator>
 <dc:creator>Chen, Chun</dc:creator>
 <dc:creator>He, Zhanying</dc:creator>
 <dc:creator>Cai, Deng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Co-clustering targets on grouping the samples (e.g., documents, users) and
the features (e.g., words, ratings) simultaneously. It employs the dual
relation and the bilateral information between the samples and features. In
many realworld applications, data usually reside on a submanifold of the
ambient Euclidean space, but it is nontrivial to estimate the intrinsic
manifold of the data space in a principled way. In this study, we focus on
improving the co-clustering performance via manifold ensemble learning, which
is able to maximally approximate the intrinsic manifolds of both the sample and
feature spaces. To achieve this, we develop a novel co-clustering algorithm
called Relational Multi-manifold Co-clustering (RMC) based on symmetric
nonnegative matrix tri-factorization, which decomposes the relational data
matrix into three submatrices. This method considers the intertype relationship
revealed by the relational data matrix, and also the intra-type information
reflected by the affinity matrices encoded on the sample and feature data
distributions. Specifically, we assume the intrinsic manifold of the sample or
feature space lies in a convex hull of some pre-defined candidate manifolds. We
want to learn a convex combination of them to maximally approach the desired
intrinsic manifold. To optimize the objective function, the multiplicative
rules are utilized to update the submatrices alternatively. Besides, both the
entropic mirror descent algorithm and the coordinate descent algorithm are
exploited to learn the manifold coefficient vector. Extensive experiments on
documents, images and gene expression data sets have demonstrated the
superiority of the proposed algorithm compared to other well-established
methods.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures, published in IEEE Transactions on Cybernetics
  (TCYB)</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05743</dc:identifier>
 <dc:identifier>IEEE Transactions on Cybernetics, 43(6): 1871-1881, 2013</dc:identifier>
 <dc:identifier>doi:10.1109/TSMCB.2012.2234108</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05744</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compensating for Large In-Plane Rotations in Natural Images</dc:title>
 <dc:creator>Boominathan, Lokesh</dc:creator>
 <dc:creator>Srinivas, Suraj</dc:creator>
 <dc:creator>Babu, R. Venkatesh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Rotation invariance has been studied in the computer vision community
primarily in the context of small in-plane rotations. This is usually achieved
by building invariant image features. However, the problem of achieving
invariance for large rotation angles remains largely unexplored. In this work,
we tackle this problem by directly compensating for large rotations, as opposed
to building invariant features. This is inspired by the neuro-scientific
concept of mental rotation, which humans use to compare pairs of rotated
objects. Our contributions here are three-fold. First, we train a Convolutional
Neural Network (CNN) to detect image rotations. We find that generic CNN
architectures are not suitable for this purpose. To this end, we introduce a
convolutional template layer, which learns representations for canonical
'unrotated' images. Second, we use Bayesian Optimization to quickly sift
through a large number of candidate images to find the canonical 'unrotated'
image. Third, we use this method to achieve robustness to large angles in an
image retrieval scenario. Our method is task-agnostic, and can be used as a
pre-processing step in any computer vision system.
</dc:description>
 <dc:description>Comment: Accepted at Indian Conference on Computer Vision, Graphics and Image
  Processing (ICVGIP) 2016</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05744</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05751</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multi-Modal Graph-Based Semi-Supervised Pipeline for Predicting Cancer
  Survival</dc:title>
 <dc:creator>Hassanzadeh, Hamid Reza</dc:creator>
 <dc:creator>Phan, John H.</dc:creator>
 <dc:creator>Wang, May D.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Cancer survival prediction is an active area of research that can help
prevent unnecessary therapies and improve patient's quality of life. Gene
expression profiling is being widely used in cancer studies to discover
informative biomarkers that aid predict different clinical endpoint prediction.
We use multiple modalities of data derived from RNA deep-sequencing (RNA-seq)
to predict survival of cancer patients. Despite the wealth of information
available in expression profiles of cancer tumors, fulfilling the
aforementioned objective remains a big challenge, for the most part, due to the
paucity of data samples compared to the high dimension of the expression
profiles. As such, analysis of transcriptomic data modalities calls for
state-of-the-art big-data analytics techniques that can maximally use all the
available data to discover the relevant information hidden within a significant
amount of noise. In this paper, we propose a pipeline that predicts cancer
patients' survival by exploiting the structure of the input (manifold learning)
and by leveraging the unlabeled samples using Laplacian support vector
machines, a graph-based semi supervised learning (GSSL) paradigm. We show that
under certain circumstances, no single modality per se will result in the best
accuracy and by fusing different models together via a stacked generalization
strategy, we may boost the accuracy synergistically. We apply our approach to
two cancer datasets and present promising results. We maintain that a similar
pipeline can be used for predictive tasks where labeled samples are expensive
to acquire.
</dc:description>
 <dc:description>Comment: in 2016 IEEE International Conference on Bioinformatics and
  Biomedicine (BIBM)</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05751</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05753</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximizing a Submodular Function with Viability Constraints</dc:title>
 <dc:creator>Dvo&#x159;&#xe1;k, Wolfgang</dc:creator>
 <dc:creator>Henzinger, Monika</dc:creator>
 <dc:creator>Williamson, David P.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the problem of maximizing a monotone submodular function with
viability constraints. This problem originates from computational biology,
where we are given a phylogenetic tree over a set of species and a directed
graph, the so-called food web, encoding viability constraints between these
species. These food webs usually have constant {depth}. The goal is to select a
subset of $k$ species that satisfies the viability constraints and has maximal
phylogenetic diversity. As this problem is known to be NP-hard, we investigate
approximation algorithms. We present the first constant factor approximation
algorithm if the depth is constant. Its approximation ratio is
$(1-\frac{1}{\sqrt{e}})$. This algorithm not only applies to phylogenetic trees
with viability constraints but for arbitrary monotone submodular set functions
with viability constraints. Second, we show that there is no
$(1-1/e+\epsilon)$-approximation algorithm for our problem setting (even for
additive functions) and that there is no approximation algorithm for a slight
extension of this setting.
</dc:description>
 <dc:description>Comment: in Algorithmica (2015)</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05753</dc:identifier>
 <dc:identifier>doi:10.1007/s00453-015-0066-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05754</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Separating quantum communication and approximate rank</dc:title>
 <dc:creator>Anshu, Anurag</dc:creator>
 <dc:creator>Ben-David, Shalev</dc:creator>
 <dc:creator>Garg, Ankit</dc:creator>
 <dc:creator>Jain, Rahul</dc:creator>
 <dc:creator>Kothari, Robin</dc:creator>
 <dc:creator>Lee, Troy</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  One of the best lower bound methods for the quantum communication complexity
of a function H (with or without shared entanglement) is the logarithm of the
approximate rank of the communication matrix of H. This measure is essentially
equivalent to the approximate gamma_2 norm and generalized discrepancy, and
subsumes several other lower bounds. All known lower bounds on quantum
communication complexity in the general unbounded-round model can be shown via
the logarithm of approximate rank, and it was an open problem to give any
separation at all between quantum communication complexity and the logarithm of
the approximate rank.
  In this work we provide the first such separation: We exhibit a total
function H with quantum communication complexity almost quadratically larger
than the logarithm of its approximate rank. We construct H using the
communication lookup function framework of Anshu et al. (FOCS 2016) based on
the cheat sheet framework of Aaronson et al. (STOC 2016). From a starting
function F, this framework defines a new function H=F_G. Our main technical
result is a lower bound on the quantum communication complexity of F_G in terms
of the discrepancy of F, which we do via quantum information theoretic
arguments. We show the upper bound on the approximate rank of F_G by relating
it to the Boolean circuit size of the starting function F.
</dc:description>
 <dc:description>Comment: 34 pages</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05754</dc:identifier>
 <dc:identifier>32nd Conference on Computational Complexity (CCC 2017), Leibniz
  International Proceedings in Informatics (LIPIcs) 79, pp. 24:1-24:33 (2017)</dc:identifier>
 <dc:identifier>doi:10.4230/LIPIcs.CCC.2017.24</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05755</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-Domain Face Verification: Matching ID Document and Self-Portrait
  Photographs</dc:title>
 <dc:creator>Folego, Guilherme</dc:creator>
 <dc:creator>Angeloni, Marcus A.</dc:creator>
 <dc:creator>Stuchi, Jos&#xe9; Augusto</dc:creator>
 <dc:creator>Godoy, Alan</dc:creator>
 <dc:creator>Rocha, Anderson</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Cross-domain biometrics has been emerging as a new necessity, which poses
several additional challenges, including harsh illumination changes, noise,
pose variation, among others. In this paper, we explore approaches to
cross-domain face verification, comparing self-portrait photographs (&quot;selfies&quot;)
to ID documents. We approach the problem with proper image photometric
adjustment and data standardization techniques, along with deep learning
methods to extract the most prominent features from the data, reducing the
effects of domain shift in this problem. We validate the methods using a novel
dataset comprising 50 individuals. The obtained results are promising and
indicate that the adopted path is worth further investigation.
</dc:description>
 <dc:description>Comment: XII WORKSHOP DE VIS\~AO COMPUTACIONAL (Campo Grande, Brazil). In XII
  Workshop de Vis\~ao Computacional (pp. 311-316) (2016)</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05755</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05760</identifier>
 <datestamp>2017-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Examining the Impact of Blur on Recognition by Convolutional Networks</dc:title>
 <dc:creator>Vasiljevic, Igor</dc:creator>
 <dc:creator>Chakrabarti, Ayan</dc:creator>
 <dc:creator>Shakhnarovich, Gregory</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  State-of-the-art algorithms for many semantic visual tasks are based on the
use of convolutional neural networks. These networks are commonly trained, and
evaluated, on large annotated datasets of artifact-free high-quality images. In
this paper, we investigate the effect of one such artifact that is quite common
in natural capture settings: optical blur. We show that standard network
models, trained only on high-quality images, suffer a significant degradation
in performance when applied to those degraded by blur due to defocus, or
subject or camera motion. We investigate the extent to which this degradation
is due to the mismatch between training and input image statistics.
Specifically, we find that fine-tuning a pre-trained model with blurred images
added to the training set allows it to regain much of the lost accuracy. We
also show that there is a fair amount of generalization between different
degrees and types of blur, which implies that a single network model can be
used robustly for recognition when the nature of the blur in the input is
unknown. We find that this robustness arises as a result of these models
learning to generate blur invariant representations in their hidden layers. Our
findings provide useful insights towards developing vision systems that can
perform reliably on real world images affected by blur.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05760</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05763</identifier>
 <datestamp>2017-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to reinforcement learn</dc:title>
 <dc:creator>Wang, Jane X</dc:creator>
 <dc:creator>Kurth-Nelson, Zeb</dc:creator>
 <dc:creator>Tirumala, Dhruva</dc:creator>
 <dc:creator>Soyer, Hubert</dc:creator>
 <dc:creator>Leibo, Joel Z</dc:creator>
 <dc:creator>Munos, Remi</dc:creator>
 <dc:creator>Blundell, Charles</dc:creator>
 <dc:creator>Kumaran, Dharshan</dc:creator>
 <dc:creator>Botvinick, Matt</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In recent years deep reinforcement learning (RL) systems have attained
superhuman performance in a number of challenging task domains. However, a
major limitation of such applications is their demand for massive amounts of
training data. A critical present objective is thus to develop deep RL methods
that can adapt rapidly to new tasks. In the present work we introduce a novel
approach to this challenge, which we refer to as deep meta-reinforcement
learning. Previous work has shown that recurrent networks can support
meta-learning in a fully supervised context. We extend this approach to the RL
setting. What emerges is a system that is trained using one RL algorithm, but
whose recurrent dynamics implement a second, quite separate RL procedure. This
second, learned RL algorithm can differ from the original one in arbitrary
ways. Importantly, because it is learned, it is configured to exploit structure
in the training domain. We unpack these points in a series of seven
proof-of-concept experiments, each of which examines a key aspect of deep
meta-RL. We consider prospects for extending and scaling up the approach, and
also point out some potentially important implications for neuroscience.
</dc:description>
 <dc:description>Comment: 17 pages, 7 figures, 1 table</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05763</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05774</identifier>
 <datestamp>2017-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Do Recurrent Neural Network Grammars Learn About Syntax?</dc:title>
 <dc:creator>Kuncoro, Adhiguna</dc:creator>
 <dc:creator>Ballesteros, Miguel</dc:creator>
 <dc:creator>Kong, Lingpeng</dc:creator>
 <dc:creator>Dyer, Chris</dc:creator>
 <dc:creator>Neubig, Graham</dc:creator>
 <dc:creator>Smith, Noah A.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recurrent neural network grammars (RNNG) are a recently proposed
probabilistic generative modeling family for natural language. They show
state-of-the-art language modeling and parsing performance. We investigate what
information they learn, from a linguistic perspective, through various
ablations to the model and the data, and by augmenting the model with an
attention mechanism (GA-RNNG) to enable closer inspection. We find that
explicit modeling of composition is crucial for achieving the best performance.
Through the attention mechanism, we find that headedness plays a central role
in phrasal representation (with the model's latent attention largely agreeing
with predictions made by hand-crafted head rules, albeit with some important
differences). By training grammars without nonterminal labels, we find that
phrasal representations depend minimally on nonterminals, providing support for
the endocentricity hypothesis.
</dc:description>
 <dc:description>Comment: 10 pages. To appear in EACL 2017, Valencia, Spain</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05774</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05777</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeeperBind: Enhancing Prediction of Sequence Specificities of DNA
  Binding Proteins</dc:title>
 <dc:creator>Hassanzadeh, Hamid Reza</dc:creator>
 <dc:creator>Wang, May D.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Transcription factors (TFs) are macromolecules that bind to
\textit{cis}-regulatory specific sub-regions of DNA promoters and initiate
transcription. Finding the exact location of these binding sites (aka motifs)
is important in a variety of domains such as drug design and development. To
address this need, several \textit{in vivo} and \textit{in vitro} techniques
have been developed so far that try to characterize and predict the binding
specificity of a protein to different DNA loci. The major problem with these
techniques is that they are not accurate enough in prediction of the binding
affinity and characterization of the corresponding motifs. As a result,
downstream analysis is required to uncover the locations where proteins of
interest bind. Here, we propose DeeperBind, a long short term recurrent
convolutional network for prediction of protein binding specificities with
respect to DNA probes. DeeperBind can model the positional dynamics of probe
sequences and hence reckons with the contributions made by individual
sub-regions in DNA sequences, in an effective way. Moreover, it can be trained
and tested on datasets containing varying-length sequences. We apply our
pipeline to the datasets derived from protein binding microarrays (PBMs), an
in-vitro high-throughput technology for quantification of protein-DNA binding
preferences, and present promising results. To the best of our knowledge, this
is the most accurate pipeline that can predict binding specificities of DNA
sequences from the data produced by high-throughput technologies through
utilization of the power of deep learning for feature generation and positional
dynamics modeling.
</dc:description>
 <dc:description>Comment: in 2016 IEEE International Conference on Bioinformatics and
  Biomedicine (BIBM)</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05777</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05778</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards the Modeling of Behavioral Trajectories of Users in Online
  Social Media</dc:title>
 <dc:creator>Bessi, Alessandro</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we introduce a methodology that allows to model behavioral
trajectories of users in online social media. First, we illustrate how to
leverage the probabilistic framework provided by Hidden Markov Models (HMMs) to
represent users by embedding the temporal sequences of actions they performed
online. We then derive a model-based distance between trained HMMs, and we use
spectral clustering to find homogeneous clusters of users showing similar
behavioral trajectories. To provide platform-agnostic results, we apply the
proposed approach to two different online social media --- i.e. Facebook and
YouTube. We conclude discussing merits and limitations of our approach as well
as future and promising research directions.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05778</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05780</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gap Safe screening rules for sparsity enforcing penalties</dc:title>
 <dc:creator>Ndiaye, Eugene</dc:creator>
 <dc:creator>Fercoq, Olivier</dc:creator>
 <dc:creator>Gramfort, Alexandre</dc:creator>
 <dc:creator>Salmon, Joseph</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  In high dimensional regression settings, sparsity enforcing penalties have
proved useful to regularize the data-fitting term. A recently introduced
technique called screening rules propose to ignore some variables in the
optimization leveraging the expected sparsity of the solutions and consequently
leading to faster solvers. When the procedure is guaranteed not to discard
variables wrongly the rules are said to be safe. In this work, we propose a
unifying framework for generalized linear models regularized with standard
sparsity enforcing penalties such as $\ell_1$ or $\ell_1/\ell_2$ norms. Our
technique allows to discard safely more variables than previously considered
safe rules, particularly for low regularization parameters. Our proposed Gap
Safe rules (so called because they rely on duality gap computation) can cope
with any iterative solver but are particularly well suited to (block)
coordinate descent methods. Applied to many standard learning tasks, Lasso,
Sparse-Group Lasso, multi-task Lasso, binary and multinomial logistic
regression, etc., we report significant speed-ups compared to previously
proposed safe rules on all tested data sets.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05780</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05787</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FPGA Implementation of a Scalable and Run-Time Adaptable Multi-Standard
  Packet Detector</dc:title>
 <dc:creator>Chacko, James</dc:creator>
 <dc:creator>Jacovic, Marko</dc:creator>
 <dc:creator>Kandasamy, Nagarajan</dc:creator>
 <dc:creator>Dandekar, Kapil R.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper describes a step by step approach for implementing a scalable and
run-time adaptable multi-standard packet detector for orthogonal frequency
divisional multiplexing (OFDM) based communication standards. The paper briefly
describes considerations and design choices in making a modular system block
with generic control supporting rapid prototyping and implementation of
preamble-based packet detectors. The results were generated through
implementation on a Xilinx Virtex-6 FPGA with a MicroBlaze processor
instantiated to provide run-time control and adaptability.
</dc:description>
 <dc:date>2016-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05788</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Science in Service of Performing Arts: Applying Machine Learning to
  Predicting Audience Preferences</dc:title>
 <dc:creator>Abernethy, Jacob</dc:creator>
 <dc:creator>Anderson, Cyrus</dc:creator>
 <dc:creator>Chojnacki, Alex</dc:creator>
 <dc:creator>Dai, Chengyu</dc:creator>
 <dc:creator>Dryden, John</dc:creator>
 <dc:creator>Schwartz, Eric</dc:creator>
 <dc:creator>Shen, Wenbo</dc:creator>
 <dc:creator>Stroud, Jonathan</dc:creator>
 <dc:creator>Wendlandt, Laura</dc:creator>
 <dc:creator>Yang, Sheng</dc:creator>
 <dc:creator>Zhang, Daniel</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Performing arts organizations aim to enrich their communities through the
arts. To do this, they strive to match their performance offerings to the taste
of those communities. Success relies on understanding audience preference and
predicting their behavior. Similar to most e-commerce or digital entertainment
firms, arts presenters need to recommend the right performance to the right
customer at the right time. As part of the Michigan Data Science Team (MDST),
we partnered with the University Musical Society (UMS), a non-profit performing
arts presenter housed in the University of Michigan, Ann Arbor. We are
providing UMS with analysis and business intelligence, utilizing historical
individual-level sales data. We built a recommendation system based on
collaborative filtering, gaining insights into the artistic preferences of
customers, along with the similarities between performances. To better
understand audience behavior, we used statistical methods from customer-base
analysis. We characterized customer heterogeneity via segmentation, and we
modeled customer cohorts to understand and predict ticket purchasing patterns.
Finally, we combined statistical modeling with natural language processing
(NLP) to explore the impact of wording in program descriptions. These ongoing
efforts provide a platform to launch targeted marketing campaigns, helping UMS
carry out its mission by allocating its resources more efficiently. Celebrating
its 138th season, UMS is a 2014 recipient of the National Medal of Arts, and it
continues to enrich communities by connecting world-renowned artists with
diverse audiences, especially students in their formative years. We aim to
contribute to that mission through data science and customer analytics.
</dc:description>
 <dc:description>Comment: Presented at the Data For Good Exchange 2016</dc:description>
 <dc:date>2016-09-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05789</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applying Software Craftsmanship Practices to a Scrum Project: an
  Experience Report</dc:title>
 <dc:creator>Lucena, Percival</dc:creator>
 <dc:creator>Tizzei, Leonardo P.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.9</dc:subject>
 <dc:description>  The Software Craftsmanship manifesto has defined values and principles that
software development teams should follow to deliver quality software that
fulfills functional and non-functional requirements without dealing with high
amounts of technical debt. Software craftsmanship approach to software
development prioritizes technical practices in order to provide a clean code
base. This work analyzes a set of practices that can be applied to a Scrum
project that aims to incorporate Software Craftsmanship values. The process
implementation described may be a useful contribution for software development
teams who also intend to implement Software Craftsmanship on their projects.
</dc:description>
 <dc:description>Comment: in Proceedings of 2016 Workshop on Social, Human and Economics
  Aspects of Software</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05789</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05793</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Lock-free Data Structures Perform in Dynamic Environments: Models
  and Analyses</dc:title>
 <dc:creator>Atalar, Aras</dc:creator>
 <dc:creator>Renaud-Goud, Paul</dc:creator>
 <dc:creator>Tsigas, Philippas</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this paper we present two analytical frameworks for calculating the
performance of lock-free data structures. Lock-free data structures are based
on retry loops and are called by application-specific routines. In contrast to
previous work, we consider in this paper lock-free data structures in dynamic
environments. The size of each of the retry loops, and the size of the
application routines invoked in between, are not constant but may change
dynamically. The new frameworks follow two different approaches. The first
framework, the simplest one, is based on queuing theory. It introduces an
average-based approach that facilitates a more coarse-grained analysis, with
the benefit of being ignorant of size distributions. Because of this
independence from the distribution nature it covers a set of complicated
designs. The second approach, instantiated with an exponential distribution for
the size of the application routines, uses Markov chains, and is tighter
because it constructs stochastically the execution, step by step.
  Both frameworks provide a performance estimate which is close to what we
observe in practice. We have validated our analysis on (i) several fundamental
lock-free data structures such as stacks, queues, deques and counters, some of
them employing helping mechanisms, and (ii) synthetic tests covering a wide
range of possible lock-free designs. We show the applicability of our results
by introducing new back-off mechanisms, tested in application contexts, and by
designing an efficient memory management scheme that typical lock-free
algorithms can utilize.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05799</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Freiburg Groceries Dataset</dc:title>
 <dc:creator>Jund, Philipp</dc:creator>
 <dc:creator>Abdo, Nichola</dc:creator>
 <dc:creator>Eitel, Andreas</dc:creator>
 <dc:creator>Burgard, Wolfram</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With the increasing performance of machine learning techniques in the last
few years, the computer vision and robotics communities have created a large
number of datasets for benchmarking object recognition tasks. These datasets
cover a large spectrum of natural images and object categories, making them not
only useful as a testbed for comparing machine learning approaches, but also a
great resource for bootstrapping different domain-specific perception and
robotic systems. One such domain is domestic environments, where an autonomous
robot has to recognize a large variety of everyday objects such as groceries.
This is a challenging task due to the large variety of objects and products,
and where there is great need for real-world training data that goes beyond
product images available online. In this paper, we address this issue and
present a dataset consisting of 5,000 images covering 25 different classes of
groceries, with at least 97 images per class. We collected all images from
real-world settings at different stores and apartments. In contrast to existing
groceries datasets, our dataset includes a large variety of perspectives,
lighting conditions, and degrees of clutter. Overall, our images contain
thousands of different object instances. It is our hope that machine learning
and robotics researchers find this dataset of use for training, testing, and
bootstrapping their approaches. As a baseline classifier to facilitate
comparison, we re-trained the CaffeNet architecture (an adaptation of the
well-known AlexNet) on our dataset and achieved a mean accuracy of 78.9%. We
release this trained model along with the code and data splits we used in our
experiments.
</dc:description>
 <dc:description>Comment: Link to dataset:
  http://www2.informatik.uni-freiburg.de/~eitel/freiburg_groceries_dataset.html
  Link to code: https://github.com/PhilJd/freiburg_groceries_dataset</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05800</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Splitting schemes for unsteady problems involving the grad-div operator</dc:title>
 <dc:creator>Minev, Peter</dc:creator>
 <dc:creator>Vabishchevich, Petr N.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>65N12, 65N15, 35Q30</dc:subject>
 <dc:description>  In this paper we consider various splitting schemes for unsteady problems
containing the grad-div operator. The fully implicit discretization of such
problems would yield at each time step a linear problem that couples all
components of the solution vector. In this paper we discuss various
possibilities to decouple the equations for the different components that
result in unconditionally stable schemes. If the spatial discretization uses
Cartesian grids, the resulting schemes are Locally One Dimensional (LOD). The
stability analysis of these schemes is based on the general stability theory of
additive operator-difference schemes developed by Samarskii and his
collaborators. The results of the theoretical analysis are illustrated on a 2D
numerical example with a smooth manufactured solution.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05803</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>COOLL: Controlled On/Off Loads Library, a Public Dataset of High-Sampled
  Electrical Signals for Appliance Identification</dc:title>
 <dc:creator>Picon, Thomas</dc:creator>
 <dc:creator>Meziane, Mohamed Nait</dc:creator>
 <dc:creator>Ravier, Philippe</dc:creator>
 <dc:creator>Lamarque, Guy</dc:creator>
 <dc:creator>Novello, Clarisse</dc:creator>
 <dc:creator>Bunetel, Jean-Charles Le</dc:creator>
 <dc:creator>Raingeaud, Yves</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  This paper gives a brief description of the Controlled On/Off Loads Library
(COOLL) dataset. This latter is a dataset of high-sampled electrical current
and voltage measurements representing individual appliances consumption. The
measurements were taken in June 2016 in the PRISME laboratory of the University
of Orl\'eans, France. The appliances are mainly controllable appliances (i.e.
we can precisely control their turn-on/off time instants). 42 appliances of 12
types were measured at a 100 kHz sampling frequency.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures, 3 tables</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05803</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05817</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nothing Else Matters: Model-Agnostic Explanations By Identifying
  Prediction Invariance</dc:title>
 <dc:creator>Ribeiro, Marco Tulio</dc:creator>
 <dc:creator>Singh, Sameer</dc:creator>
 <dc:creator>Guestrin, Carlos</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  At the core of interpretable machine learning is the question of whether
humans are able to make accurate predictions about a model's behavior. Assumed
in this question are three properties of the interpretable output: coverage,
precision, and effort. Coverage refers to how often humans think they can
predict the model's behavior, precision to how accurate humans are in those
predictions, and effort is either the up-front effort required in interpreting
the model, or the effort required to make predictions about a model's behavior.
  In this work, we propose anchor-LIME (aLIME), a model-agnostic technique that
produces high-precision rule-based explanations for which the coverage
boundaries are very clear. We compare aLIME to linear LIME with simulated
experiments, and demonstrate the flexibility of aLIME with qualitative examples
from a variety of domains and tasks.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05819</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kolmogorov complexity and generalized length functions</dc:title>
 <dc:creator>Fraize, Cameron</dc:creator>
 <dc:creator>Porter, Christopher P.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  Kolmogorov complexity measures the algorithmic complexity of a finite binary
string $\sigma$ in terms of the length of the shortest description $\sigma^*$
of $\sigma$. Traditionally, the length of a string is taken to measure the
amount of information contained in the string. However, we may also view the
length of $\sigma$ as a measure of the cost of producing $\sigma$, which
permits one to generalize the notion of length, wherein the cost of producing a
0 or a 1 can vary in some prescribed manner.
  In this article, we initiate the study of this generalization of length based
on the above information cost interpretation. We also modify the definition of
Kolmogorov complexity to use such generalized length functions instead of
standard length. We further investigate conditions under which the notion of
complexity defined in terms of a given generalized length function preserves
some essential properties of Kolmogorov complexity. We focus on a specific
class of generalized length functions that are intimately related to a specific
subcollection of Bernoulli $p$-measures, namely those corresponding to the
unique computable real $p\in(0,1)$ such that $p^k=1-p$, for integers $k\geq 1$.
We then study randomness with respect to such measures, by proving a
generalization version of the classic Levin-Schnorr theorem that involves
$k$-length functions and then proving subsequent results that involve effective
dimension and entropy.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05827</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Mathematical Understanding of the Difficulty in Learning with
  Feedforward Neural Networks</dc:title>
 <dc:creator>Shen, Hao</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Training deep neural networks for solving machine learning problems is one
great challenge in the field, mainly due to its associated optimisation problem
being highly non-convex. Recent developments have suggested that many training
algorithms do not suffer from undesired local minima under certain scenario,
and consequently led to great efforts in pursuing mathematical explanations for
such observations. This work provides an alternative mathematical understanding
of the challenge from a smooth optimisation perspective. By assuming exact
learning of finite samples, sufficient conditions are identified via a critical
point analysis to ensure any local minimum to be globally minimal as well.
Furthermore, a state of the art algorithm, known as the Generalised
Gauss-Newton (GGN) algorithm, is rigorously revisited as an approximate
Newton's algorithm, which shares the property of being locally quadratically
convergent to a global minimum under the condition of exact learning.
</dc:description>
 <dc:description>Comment: 22 pages, 1 figure, submitted for publication</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05831</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized LR parsing and the shuffle operator</dc:title>
 <dc:creator>Maraist, John</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We adapt Tomita's Generalized LR algorithm to languages generated by
context-free grammars enriched with a shuffle operator. The change involves
extensions to the underlying handle-finding finite automaton, construction of
parser tables, and the necessary optimizations in constructing a deterministic
parser. Our system is motivated by an application from artificial intelligence
plan recognition. We argue for the correctness of the system, and discuss
future extensions of this work.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05831</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05837</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AutoScaler: Scale-Attention Networks for Visual Correspondence</dc:title>
 <dc:creator>Wang, Shenlong</dc:creator>
 <dc:creator>Luo, Linjie</dc:creator>
 <dc:creator>Zhang, Ning</dc:creator>
 <dc:creator>Li, Jia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Finding visual correspondence between local features is key to many computer
vision problems. While defining features with larger contextual scales usually
implies greater discriminativeness, it could also lead to less spatial accuracy
of the features. We propose AutoScaler, a scale-attention network to explicitly
optimize this trade-off in visual correspondence tasks. Our network consists of
a weight-sharing feature network to compute multi-scale feature maps and an
attention network to combine them optimally in the scale space. This allows our
network to have adaptive receptive field sizes over different scales of the
input. The entire network is trained end-to-end in a siamese framework for
visual correspondence tasks. Our method achieves favorable results compared to
state-of-the-art methods on challenging optical flow and semantic matching
benchmarks, including Sintel, KITTI and CUB-2011. We also show that our method
can generalize to improve hand-crafted descriptors (e.g Daisy) on general
visual correspondence tasks. Finally, our attention network can generate
visually interpretable scale attention maps.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05839</identifier>
 <datestamp>2017-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximizing the minimum achievable secrecy rate of two-way relay networks
  using the null space beamforming method</dc:title>
 <dc:creator>khordad, Erfan</dc:creator>
 <dc:creator>Akhlaghi, Soroush</dc:creator>
 <dc:creator>Mirzaee, Meysam</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This paper concerns maximizing the minimum achievable secrecy rate of a
two-way relay network in the presence of an eavesdropper, in which two nodes
aim to exchange messages in two hops, using a multi-antenna relay. Throughout
the first hop, the two nodes simultaneously transmit their messages to the
relay. In the second hop, the relay broadcasts a combination of the received
information to the users such that the transmitted signal lies in the null
space of the eavesdropper's channel; this is called null space beamforming
(NSBF). The best NSBF matrix for maximizing the minimum achievable secrecy rate
is studied, showing that the problem is not convex in general. To address this
issue, the problem is divided into three sub-problems: a close-to-optimal
solution is derived by using the semi-definite relaxation (SDR) technique.
Simulation results demonstrate the superiority of the proposed method w.r.t.
the most well-known method addressed in the literature.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05839</dc:identifier>
 <dc:identifier>doi:10.1049/iet-com.2016.0470</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05842</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video Processing from Electro-optical Sensors for Object Detection and
  Tracking in Maritime Environment: A Survey</dc:title>
 <dc:creator>Prasad, D. K.</dc:creator>
 <dc:creator>Rajan, D.</dc:creator>
 <dc:creator>Rachmawati, L.</dc:creator>
 <dc:creator>Rajabaly, E.</dc:creator>
 <dc:creator>Quek, C.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a survey on maritime object detection and tracking approaches,
which are essential for the development of a navigational system for autonomous
ships. The electro-optical (EO) sensor considered here is a video camera that
operates in the visible or the infrared spectra, which conventionally
complement radar and sonar and have demonstrated effectiveness for situational
awareness at sea has demonstrated its effectiveness over the last few years.
This paper provides a comprehensive overview of various approaches of video
processing for object detection and tracking in the maritime environment. We
follow an approach-based taxonomy wherein the advantages and limitations of
each approach are compared. The object detection system consists of the
following modules: horizon detection, static background subtraction and
foreground segmentation. Each of these has been studied extensively in maritime
situations and has been shown to be challenging due to the presence of
background motion especially due to waves and wakes. The main processes
involved in object tracking include video frame registration, dynamic
background subtraction, and the object tracking algorithm itself. The
challenges for robust tracking arise due to camera motion, dynamic background
and low contrast of tracked object, possibly due to environmental degradation.
The survey also discusses multisensor approaches and commercial maritime
systems that use EO sensors. The survey also highlights methods from computer
vision research which hold promise to perform well in maritime EO data
processing. Performance of several maritime and computer vision techniques is
evaluated on newly proposed Singapore Maritime Dataset.
</dc:description>
 <dc:description>Comment: 23 pages</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05896</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Answering Image Riddles using Vision and Reasoning through Probabilistic
  Soft Logic</dc:title>
 <dc:creator>Aditya, Somak</dc:creator>
 <dc:creator>Yang, Yezhou</dc:creator>
 <dc:creator>Baral, Chitta</dc:creator>
 <dc:creator>Aloimonos, Yiannis</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this work, we explore a genre of puzzles (&quot;image riddles&quot;) which involves
a set of images and a question. Answering these puzzles require both
capabilities involving visual detection (including object, activity
recognition) and, knowledge-based or commonsense reasoning. We compile a
dataset of over 3k riddles where each riddle consists of 4 images and a
groundtruth answer. The annotations are validated using crowd-sourced
evaluation. We also define an automatic evaluation metric to track future
progress. Our task bears similarity with the commonly known IQ tasks such as
analogy solving, sequence filling that are often used to test intelligence.
  We develop a Probabilistic Reasoning-based approach that utilizes
probabilistic commonsense knowledge to answer these riddles with a reasonable
accuracy. We demonstrate the results of our approach using both automatic and
human evaluations. Our approach achieves some promising results for these
riddles and provides a strong baseline for future attempts. We make the entire
dataset and related materials publicly available to the community in
ImageRiddle Website (http://bit.ly/22f9Ala).
</dc:description>
 <dc:description>Comment: 14 pages, 10 figures</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05896</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05898</identifier>
 <datestamp>2017-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Associative Memories to Accelerate Approximate Nearest Neighbor Search</dc:title>
 <dc:creator>Gripon, Vincent</dc:creator>
 <dc:creator>L&#xf6;we, Matthias</dc:creator>
 <dc:creator>Vermet, Franck</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>82C32, 60K35 (Primary), 68T05, 92B20 (Secondary)</dc:subject>
 <dc:description>  Nearest neighbor search is a very active field in machine learning for it
appears in many application cases, including classification and object
retrieval. In its canonical version, the complexity of the search is linear
with both the dimension and the cardinal of the collection of vectors the
search is performed in. Recently many works have focused on reducing the
dimension of vectors using quantization techniques or hashing, while providing
an approximate result. In this paper we focus instead on tackling the cardinal
of the collection of vectors. Namely, we introduce a technique that partitions
the collection of vectors and stores each part in its own associative memory.
When a query vector is given to the system, associative memories are polled to
identify which one contain the closest match. Then an exhaustive search is
conducted only on the part of vectors stored in the selected associative
memory. We study the effectiveness of the system when messages to store are
generated from i.i.d. uniform $\pm$1 random variables or 0-1 sparse i.i.d.
random variables. We also conduct experiment on both synthetic data and real
data and show it is possible to achieve interesting trade-offs between
complexity and accuracy.
</dc:description>
 <dc:description>Comment: 21 pages, 12 figures</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:date>2017-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05898</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05901</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>D-finite Numbers</dc:title>
 <dc:creator>Huang, Hui</dc:creator>
 <dc:creator>Kauers, Manuel</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  D-finite functions and P-recursive sequences are defined in terms of linear
differential and recurrence equations with polynomial coefficients. In this
paper, we introduce a class of numbers closely related to D-finite functions
and P-recursive sequences. It consists of the limits of convergent P-recursive
sequences. Typically, this class contains many well-known mathematical
constants in addition to the algebraic numbers. Our definition of the class of
D-finite numbers depends on two subrings of the field of complex numbers. We
investigate how difference choices of these two subrings affect the class.
Moreover, we show that D-finite numbers over the Gaussian rational field are
essentially the same as the values of D-finite functions at non-singular
algebraic number arguments. This result makes it easier to recognize certain
numbers as D-finite.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05901</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05907</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Query Complexity of Black-Peg AB-Mastermind</dc:title>
 <dc:creator>Ouali, Mourad El</dc:creator>
 <dc:creator>Glazik, Christian</dc:creator>
 <dc:creator>Sauerland, Volkmar</dc:creator>
 <dc:creator>Srivastav, Anand</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>91A46, 68Q25</dc:subject>
 <dc:description>  Mastermind game is a two players zero sum game of imperfect information. The
first player, called codemaker, chooses a secret code and the second player,
called codebreaker, tries to break the secret code by making as few guesses as
possible, exploiting information that is given by the codemaker after each
guess. In this paper, we consider the so called Black-Peg variant of
Mastermind, where the only information concerning a guess is the number of
positions in which the guess coincides with the secret code. More precisely, we
deal with a special version of the Black-Peg game with n holes and k&lt;=n colors
where no repetition of colors is allowed. We present upper and lower bounds on
the number of guesses necessary to break the secret code. We first come back to
the upper bound results introduced by El Ouali and Sauerland (2013). For the
case k=n the secret code can be algorithmically identified within less than
(n-3)*ld(n)+5n/2 queries. That result improves the result of Ker-I Ko and
Shia-Chung Teng (1985) by almost a factor of 2. For the case k&gt;n we prove an
upper bound for the problem of (n-1)*ld(n)+k+1. Furthermore we prove a new
lower bound for (a generalization of) the case k=n that improves the recent
result of Berger et al. (2016) from n-log(log(n)) to n. We also give a lower
bound of k queries for the case k&gt;n.
</dc:description>
 <dc:description>Comment: 11 pages, 2 figures. arXiv admin note: substantial text overlap with
  arXiv:1303.5862</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05907</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05910</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wirelessly Powered Urban Crowd Sensing over Wearables: Trading Energy
  for Data</dc:title>
 <dc:creator>Galinina, Olga</dc:creator>
 <dc:creator>Mikhaylov, Konstantin</dc:creator>
 <dc:creator>Huang, Kaibin</dc:creator>
 <dc:creator>Andreev, Sergey</dc:creator>
 <dc:creator>Koucheryavy, Yevgeni</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this article, we put forward the mobile crowd sensing paradigm based on
ubiquitous wearable devices carried by human users. The key challenge for mass
user involvement into prospective urban crowd sending applications, such as
monitoring of large-scale phenomena (e.g., traffic congestion and air pollution
levels), is the appropriate sources of motivation. We thus advocate for the use
of wireless power transfer provided in exchange for sensed data to incentivize
the owners of wearables to participate in collaborative data collection. Based
on this construction, we develop the novel concept of wirelessly powered crowd
sensing and offer the corresponding network architecture considerations
together with a systematic review of wireless charging techniques to implement
it. Further, we contribute a detailed system-level feasibility study that
reports on the achievable performance levels for the envisioned setup. Finally,
the underlying energy-data trading mechanisms are discussed, and the work is
concluded with outlining open research opportunities.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05910</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05911</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing Absolutely Normal Numbers in Nearly Linear Time</dc:title>
 <dc:creator>Lutz, Jack H.</dc:creator>
 <dc:creator>Mayordomo, Elvira</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>03D32, 68W01, 11-04</dc:subject>
 <dc:description>  A real number $x$ is absolutely normal if, for every base $b\ge 2$, every two
equally long strings of digits appear with equal asymptotic frequency in the
base-$b$ expansion of $x$. This paper presents an explicit algorithm that
generates the binary expansion of an absolutely normal number $x$, with the
$n$th bit of $x$ appearing after $n$polylog$(n)$ computation steps. This speed
is achieved by simultaneously computing and diagonalizing against a martingale
that incorporates Lempel-Ziv parsing algorithms in all bases.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05915</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative One-Class Models for Text-based Person Retrieval in Forensic
  Applications</dc:title>
 <dc:creator>Ger&#xf3;nimo, David</dc:creator>
 <dc:creator>Kjellstr&#xf6;m, Hedvig</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatic forensic image analysis assists criminal investigation experts in
the search for suspicious persons, abnormal behaviors detection and identity
matching in images. In this paper we propose a person retrieval system that
uses textual queries (e.g., &quot;black trousers and green shirt&quot;) as descriptions
and a one-class generative color model with outlier filtering to represent the
images both to train the models and to perform the search. The method is
evaluated in terms of its efficiency in fulfilling the needs of a forensic
retrieval system: limited annotation, robustness, extensibility, adaptability
and computational cost. The proposed generative method is compared to a
corresponding discriminative approach. Experiments are carried out using a
range of queries in three different databases. The experiments show that the
two evaluated algorithms provide average retrieval performance and adaptable to
new datasets. The proposed generative algorithm has some advantages over the
discriminative one, specifically its capability to work with very few training
samples and its much lower computational requirements when the number of
training examples increases.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05915</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05916</identifier>
 <datestamp>2017-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Squared Earth Mover's Distance-based Loss for Training Deep Neural
  Networks</dc:title>
 <dc:creator>Hou, Le</dc:creator>
 <dc:creator>Yu, Chen-Ping</dc:creator>
 <dc:creator>Samaras, Dimitris</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In the context of single-label classification, despite the huge success of
deep learning, the commonly used cross-entropy loss function ignores the
intricate inter-class relationships that often exist in real-life tasks such as
age classification. In this work, we propose to leverage these relationships
between classes by training deep nets with the exact squared Earth Mover's
Distance (also known as Wasserstein distance) for single-label classification.
The squared EMD loss uses the predicted probabilities of all classes and
penalizes the miss-predictions according to a ground distance matrix that
quantifies the dissimilarities between classes. We demonstrate that on datasets
with strong inter-class relationships such as an ordering between classes, our
exact squared EMD losses yield new state-of-the-art results. Furthermore, we
propose a method to automatically learn this matrix using the CNN's own
features during training. We show that our method can learn a ground distance
matrix efficiently with no inter-class relationship priors and yield the same
performance gain. Finally, we show that our method can be generalized to
applications that lack strong inter-class relationships and still maintain
state-of-the-art performance. Therefore, with limited computational overhead,
one can always deploy the proposed loss function on any dataset over the
conventional cross-entropy.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05923</identifier>
 <datestamp>2017-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;Influence Sketching&quot;: Finding Influential Samples In Large-Scale
  Regressions</dc:title>
 <dc:creator>Wojnowicz, Mike</dc:creator>
 <dc:creator>Cruz, Ben</dc:creator>
 <dc:creator>Zhao, Xuan</dc:creator>
 <dc:creator>Wallace, Brian</dc:creator>
 <dc:creator>Wolff, Matt</dc:creator>
 <dc:creator>Luan, Jay</dc:creator>
 <dc:creator>Crable, Caleb</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  There is an especially strong need in modern large-scale data analysis to
prioritize samples for manual inspection. For example, the inspection could
target important mislabeled samples or key vulnerabilities exploitable by an
adversarial attack. In order to solve the &quot;needle in the haystack&quot; problem of
which samples to inspect, we develop a new scalable version of Cook's distance,
a classical statistical technique for identifying samples which unusually
strongly impact the fit of a regression model (and its downstream predictions).
In order to scale this technique up to very large and high-dimensional
datasets, we introduce a new algorithm which we call &quot;influence sketching.&quot;
Influence sketching embeds random projections within the influence computation;
in particular, the influence score is calculated using the randomly projected
pseudo-dataset from the post-convergence Generalized Linear Model (GLM). We
validate that influence sketching can reliably and successfully discover
influential samples by applying the technique to a malware detection dataset of
over 2 million executable files, each represented with almost 100,000 features.
For example, we find that randomly deleting approximately 10% of training
samples reduces predictive accuracy only slightly from 99.47% to 99.45%,
whereas deleting the same number of samples with high influence sketch scores
reduces predictive accuracy all the way down to 90.24%. Moreover, we find that
influential samples are especially likely to be mislabeled. In the case study,
we manually inspect the most influential samples, and find that influence
sketching pointed us to new, previously unidentified pieces of malware.
</dc:description>
 <dc:description>Comment: fixed additional typos</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05923</dc:identifier>
 <dc:identifier>Big Data (Big Data), 2016 IEEE International Conference on, pp.
  3601 - 3612. IEEE, 2016</dc:identifier>
 <dc:identifier>doi:10.1109/BigData.2016.7841024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05927</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized BackPropagation, \'{E}tude De Cas: Orthogonality</dc:title>
 <dc:creator>Harandi, Mehrtash</dc:creator>
 <dc:creator>Fernando, Basura</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper introduces an extension of the backpropagation algorithm that
enables us to have layers with constrained weights in a deep network. In
particular, we make use of the Riemannian geometry and optimization techniques
on matrix manifolds to step outside of normal practice in training deep
networks, equipping the network with structures such as orthogonality or
positive definiteness. Based on our development, we make another contribution
by introducing the Stiefel layer, a layer with orthogonal weights. Among
various applications, Stiefel layers can be used to design orthogonal filter
banks, perform dimensionality reduction and feature extraction. We demonstrate
the benefits of having orthogonality in deep networks through a broad set of
experiments, ranging from unsupervised feature learning to fine-grained image
classification.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05927</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05934</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Increasing the Interpretability of Recurrent Neural Networks Using
  Hidden Markov Models</dc:title>
 <dc:creator>Krakovna, Viktoriya</dc:creator>
 <dc:creator>Doshi-Velez, Finale</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  As deep neural networks continue to revolutionize various application
domains, there is increasing interest in making these powerful models more
understandable and interpretable, and narrowing down the causes of good and bad
predictions. We focus on recurrent neural networks, state of the art models in
speech recognition and translation. Our approach to increasing interpretability
is by combining a long short-term memory (LSTM) model with a hidden Markov
model (HMM), a simpler and more transparent model. We add the HMM state
probabilities to the output layer of the LSTM, and then train the HMM and LSTM
either sequentially or jointly. The LSTM can make use of the information from
the HMM, and fill in the gaps when the HMM is not performing well. A small
hybrid model usually performs better than a standalone LSTM of the same size,
especially on smaller data sets. We test the algorithms on text data and
medical time series data, and find that the LSTM and HMM learn complementary
information about the features in the text.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems. arXiv admin note: substantial text overlap with
  arXiv:1606.05320</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05939</identifier>
 <datestamp>2017-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SC-DCNN: Highly-Scalable Deep Convolutional Neural Network using
  Stochastic Computing</dc:title>
 <dc:creator>Ren, Ao</dc:creator>
 <dc:creator>Li, Ji</dc:creator>
 <dc:creator>Li, Zhe</dc:creator>
 <dc:creator>Ding, Caiwen</dc:creator>
 <dc:creator>Qian, Xuehai</dc:creator>
 <dc:creator>Qiu, Qinru</dc:creator>
 <dc:creator>Yuan, Bo</dc:creator>
 <dc:creator>Wang, Yanzhi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With recent advancing of Internet of Things (IoTs), it becomes very
attractive to implement the deep convolutional neural networks (DCNNs) onto
embedded/portable systems. Presently, executing the software-based DCNNs
requires high-performance server clusters in practice, restricting their
widespread deployment on the mobile devices. To overcome this issue,
considerable research efforts have been conducted in the context of developing
highly-parallel and specific DCNN hardware, utilizing GPGPUs, FPGAs, and ASICs.
Stochastic Computing (SC), which uses bit-stream to represent a number within
[-1, 1] by counting the number of ones in the bit-stream, has a high potential
for implementing DCNNs with high scalability and ultra-low hardware footprint.
Since multiplications and additions can be calculated using AND gates and
multiplexers in SC, significant reductions in power/energy and hardware
footprint can be achieved compared to the conventional binary arithmetic
implementations. The tremendous savings in power (energy) and hardware
resources bring about immense design space for enhancing scalability and
robustness for hardware DCNNs. This paper presents the first comprehensive
design and optimization framework of SC-based DCNNs (SC-DCNNs). We first
present the optimal designs of function blocks that perform the basic
operations, i.e., inner product, pooling, and activation function. Then we
propose the optimal design of four types of combinations of basic function
blocks, named feature extraction blocks, which are in charge of extracting
features from input feature maps. Besides, weight storage methods are
investigated to reduce the area and power/energy consumption for storing
weights. Finally, the whole SC-DCNN implementation is optimized, with feature
extraction blocks carefully selected, to minimize area and power/energy
consumption while maintaining a high network accuracy level.
</dc:description>
 <dc:description>Comment: This paper is accepted by 22nd ACM International Conference on
  Architectural Support for Programming Languages and Operating Systems, 2017</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05943</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extern Objects in P4: an ROHC Compression Case Study</dc:title>
 <dc:creator>da Silva, Jeferson Santiago</dc:creator>
 <dc:creator>Boyer, Fran&#xe7;ois-Raymond</dc:creator>
 <dc:creator>Chiquette, Laurent-Olivier</dc:creator>
 <dc:creator>Langlois, J. M. Pierre</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  P4 is an emergent packet-processing language where the user can describe how
the packets are to be processed in a switching element. This paper presents a
way to implement advanced operations that are not directly supported in P4. In
this work, two different ways to add extensions to P4 are presented: i) using
new native primitives and ii) using extern instances. As a case study, an ROHC
entity was implemented and invoked in a P4 program.
  The tests show that both methods are effective, with similar performance in
terms of average packet latency. However, extern instances utilization suggests
being more suitable for target-specific switching applications, where the
manufacturer/vendor can specify its own specific operations without changes in
the P4 semantics, exporting them to P4 as a standard vendor-specific library.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures, 2 tables, submitted for the SOSR '17 Symposium on
  SDN Research, April 3-4, 2017, Santa Clara, California, USA</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05943</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05944</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallelepipeds obtaining HBL lower bounds</dc:title>
 <dc:creator>Demmel, James</dc:creator>
 <dc:creator>Rusciano, Alex</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Classical Analysis and ODEs</dc:subject>
 <dc:description>  This work studies the application of the discrete Holder-Brascamp-Lieb (HBL)
inequalities to the design of communication optimal algorithms. In particular,
it describes optimal tiling (blocking) strategies for nested loops that lack
data dependencies and exhibit linear memory access patterns. We attain known
lower bounds for communication costs by unraveling the relationship between the
HBL linear program, its dual, and tile selection. The methods used are
constructive and algorithmic. The case when all arrays have one index is
explored in depth, as a useful example in which a particularly efficient tiling
can be determined.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05944</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05947</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimal Problems for the Calibrated Trifocal Variety</dc:title>
 <dc:creator>Kileel, Joe</dc:creator>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>14M20, 14Q15, 14N99, 15A69, 65H20, 68T45</dc:subject>
 <dc:description>  We determine the algebraic degree of minimal problems for the calibrated
trifocal variety in computer vision. We rely on numerical algebraic geometry
and the homotopy continuation software Bertini.
</dc:description>
 <dc:description>Comment: 23 pages, 1 table</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05950</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of a Design Pattern for Teaching with Features and Labels</dc:title>
 <dc:creator>Meek, Christopher</dc:creator>
 <dc:creator>Simard, Patrice</dc:creator>
 <dc:creator>Zhu, Xiaojin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the task of teaching a machine to classify objects using features
and labels. We introduce the Error-Driven-Featuring design pattern for teaching
using features and labels in which a teacher prefers to introduce features only
if they are needed. We analyze the potential risks and benefits of this
teaching pattern through the use of teaching protocols, illustrative examples,
and by providing bounds on the effort required for an optimal machine teacher
using a linear learning algorithm, the most commonly used type of learners in
interactive machine learning systems. Our analysis provides a deeper
understanding of potential trade-offs of using different learning algorithms
and between the effort required for featuring (creating new features) and
labeling (providing labels for objects).
</dc:description>
 <dc:description>Comment: Also available at
  https://www.microsoft.com/en-us/research/publication/a-design-pattern-for-teaching-with-features-and-labels/</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05950</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05955</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Characterization of Prediction Errors</dc:title>
 <dc:creator>Meek, Christopher</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Understanding prediction errors and determining how to fix them is critical
to building effective predictive systems. In this paper, we delineate four
types of prediction errors and demonstrate that these four types characterize
all prediction errors. In addition, we describe potential remedies and tools
that can be used to reduce the uncertainty when trying to determine the source
of a prediction error and when trying to take action to remove a prediction
errors.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05955</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05959</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hotelling-Downs Model with Limited Attraction</dc:title>
 <dc:creator>Shen, Weiran</dc:creator>
 <dc:creator>Wang, Zihe</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In this paper we study variations of the standard Hotelling-Downs model of
spatial competition, where each agent attracts the clients in a restricted
neighborhood, each client randomly picks one attractive agent for service.
  Two utility functions for agents are considered: support utility and winner
utility. We generalize the results by Feldman et al. to the case where the
clients are distributed arbitrarily. In the support utility setting, we show
that a pure Nash equilibrium always exists by formulating the game as a
potential game. In the winner utility setting, we show that there exists a Nash
equilibrium in two cases: when there are at most 3 agents and when the size of
attraction area is at least half of the entire space. We also consider the
price of anarchy and the fairness of equilibria and give tight bounds on these
criteria.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05959</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05961</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Recursive Inclusions in two timescales with non-additive
  iterate dependent Markov noise</dc:title>
 <dc:creator>Yaji, Vinayaka</dc:creator>
 <dc:creator>Bhatnagar, Shalabh</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper we study the asymptotic behavior of a stochastic approximation
scheme on two timescales with set-valued drift functions and in the presence of
non-additive iterate-dependent Markov noise. It is shown that the recursion on
each timescale tracks the flow of a differential inclusion obtained by
averaging the set-valued drift function in the recursion with respect to a set
of measures which take into account both the averaging with respect to the
stationary distributions of the Markov noise terms and the interdependence
between the two recursions on different timescales. The framework studied in
this paper builds on the works of \it{A. Ramaswamy et al. }\rm by allowing for
the presence of non-additive iterate-dependent Markov noise. As an application,
we consider the problem of computing the optimum in a constrained convex
optimization problem where the objective function and the constraints are
averaged with respect to the stationary distribution of an underlying Markov
chain. Further the proposed scheme neither requires the differentiability of
the objective function nor the knowledge of the averaging measure.
</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05961</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05962</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Word and Document Embeddings based on Neural Network Approaches</dc:title>
 <dc:creator>Lai, Siwei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Data representation is a fundamental task in machine learning. The
representation of data affects the performance of the whole machine learning
system. In a long history, the representation of data is done by feature
engineering, and researchers aim at designing better features for specific
tasks. Recently, the rapid development of deep learning and representation
learning has brought new inspiration to various domains.
  In natural language processing, the most widely used feature representation
is the Bag-of-Words model. This model has the data sparsity problem and cannot
keep the word order information. Other features such as part-of-speech tagging
or more complex syntax features can only fit for specific tasks in most cases.
This thesis focuses on word representation and document representation. We
compare the existing systems and present our new model.
  First, for generating word embeddings, we make comprehensive comparisons
among existing word embedding models. In terms of theory, we figure out the
relationship between the two most important models, i.e., Skip-gram and GloVe.
In our experiments, we analyze three key points in generating word embeddings,
including the model construction, the training corpus and parameter design. We
evaluate word embeddings with three types of tasks, and we argue that they
cover the existing use of word embeddings. Through theory and practical
experiments, we present some guidelines for how to generate a good word
embedding.
  Second, in Chinese character or word representation. We introduce the joint
training of Chinese character and word. ...
  Third, for document representation, we analyze the existing document
representation models, including recursive NNs, recurrent NNs and convolutional
NNs. We point out the drawbacks of these models and present our new model, the
recurrent convolutional neural networks. ...
</dc:description>
 <dc:description>Comment: PhD thesis, in Chinese, Institute of Automation, Chinese Academy of
  Sciences, 2016</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05962</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05963</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reweighted Low-Rank Tensor Decomposition based on t-SVD and its
  Applications in Video Denoising</dc:title>
 <dc:creator>Baburaj, M.</dc:creator>
 <dc:creator>George, Sudhish N.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  The t-SVD based Tensor Robust Principal Component Analysis (TRPCA) decomposes
low rank multi-linear signal corrupted by gross errors into low multi-rank and
sparse component by simultaneously minimizing tensor nuclear norm and l 1 norm.
But if the multi-rank of the signal is considerably large and/or large amount
of noise is present, the performance of TRPCA deteriorates. To overcome this
problem, this paper proposes a new efficient iterative reweighted tensor
decomposition scheme based on t-SVD which significantly improves tensor
multi-rank in TRPCA. Further, the sparse component of the tensor is also
recovered by reweighted l 1 norm which enhances the accuracy of decomposition.
The effectiveness of the proposed method is established by applying it to the
video denoising problem and the experimental results reveal that the proposed
algorithm outperforms its counterparts.
</dc:description>
 <dc:description>Comment: Algorithm 1 is inefficient since line 2 is processed n 3 times need
  to be changed There are inconsistent notations throughout the manuscript
  Unitary Tensor are not defined</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05964</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reweighted Low-Rank Tensor Completion and its Applications in Video
  Recovery</dc:title>
 <dc:creator>M., Baburaj</dc:creator>
 <dc:creator>George, Sudhish N.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper focus on recovering multi-dimensional data called tensor from
randomly corrupted incomplete observation. Inspired by reweighted $l_1$ norm
minimization for sparsity enhancement, this paper proposes a reweighted
singular value enhancement scheme to improve tensor low tubular rank in the
tensor completion process. An efficient iterative decomposition scheme based on
t-SVD is proposed which improves low-rank signal recovery significantly. The
effectiveness of the proposed method is established by applying to video
completion problem, and experimental results reveal that the algorithm
outperforms its counterparts.
</dc:description>
 <dc:description>Comment: Algorithm 1 is inefficient since line 2 is processed n 3 times need
  to be changed There are inconsistent notations throughout the manuscript
  Unitary Tensor are not defined</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05964</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05971</identifier>
 <datestamp>2017-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding Mirror Symmetry via Registration</dc:title>
 <dc:creator>Cicconet, Marcelo</dc:creator>
 <dc:creator>Hildebrand, David G. C.</dc:creator>
 <dc:creator>Elliott, Hunter</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Symmetry is prevalent in nature and a common theme in man-made designs. Both
the human visual system and computer vision algorithms can use symmetry to
facilitate object recognition and other tasks. Detecting mirror symmetry in
images and data is, therefore, useful for a number of applications. Here, we
demonstrate that the problem of fitting a plane of mirror symmetry to data in
any Euclidian space can be reduced to the problem of registering two datasets.
The exactness of the resulting solution depends entirely on the registration
accuracy. This new Mirror Symmetry via Registration (MSR) framework involves
(1) data reflection with respect to an arbitrary plane, (2) registration of
original and reflected datasets, and (3) calculation of the eigenvector of
eigenvalue -1 for the transformation matrix representing the reflection and
registration mappings. To support MSR, we also introduce a novel 2D
registration method based on random sample consensus of an ensemble of
normalized cross-correlation matches. With this as its registration back-end,
MSR achieves state-of-the-art performance for symmetry line detection in two
independent 2D testing databases. We further demonstrate the generality of MSR
by testing it on a database of 3D shapes with an iterative closest point
registration back-end. Finally, we explore its applicability to examining
symmetry in natural systems by assessing the degree of symmetry present in
myelinated axon reconstructions from a larval zebrafish.
</dc:description>
 <dc:description>Comment: Submitted to ICCV 2017</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05973</identifier>
 <datestamp>2017-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NCBO Ontology Recommender 2.0: An Enhanced Approach for Biomedical
  Ontology Recommendation</dc:title>
 <dc:creator>Martinez-Romero, Marcos</dc:creator>
 <dc:creator>Jonquet, Clement</dc:creator>
 <dc:creator>O'Connor, Martin J.</dc:creator>
 <dc:creator>Graybeal, John</dc:creator>
 <dc:creator>Pazos, Alejandro</dc:creator>
 <dc:creator>Musen, Mark A.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  Biomedical researchers use ontologies to annotate their data with ontology
terms, enabling better data integration and interoperability. However, the
number, variety and complexity of current biomedical ontologies make it
cumbersome for researchers to determine which ones to reuse for their specific
needs. To overcome this problem, in 2010 the National Center for Biomedical
Ontology (NCBO) released the Ontology Recommender, which is a service that
receives a biomedical text corpus or a list of keywords and suggests ontologies
appropriate for referencing the indicated terms. We developed a new version of
the NCBO Ontology Recommender. Called Ontology Recommender 2.0, it uses a new
recommendation approach that evaluates the relevance of an ontology to
biomedical text data according to four criteria: (1) the extent to which the
ontology covers the input data; (2) the acceptance of the ontology in the
biomedical community; (3) the level of detail of the ontology classes that
cover the input data; and (4) the specialization of the ontology to the domain
of the input data. Our evaluation shows that the enhanced recommender provides
higher quality suggestions than the original approach, providing better
coverage of the input data, more detailed information about their concepts,
increased specialization for the domain of the input data, and greater
acceptance and use in the community. In addition, it provides users with more
explanatory information, along with suggestions of not only individual
ontologies but also groups of ontologies. It also can be customized to fit the
needs of different scenarios. Ontology Recommender 2.0 combines the strengths
of its predecessor with a range of adjustments and new features that improve
its reliability and usefulness. Ontology Recommender 2.0 recommends over 500
biomedical ontologies from the NCBO BioPortal platform, where it is openly
available.
</dc:description>
 <dc:description>Comment: 29 pages, 8 figures, 11 tables</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05973</dc:identifier>
 <dc:identifier>Journal of Biomedical Semantics 8 (2017) 1-22</dc:identifier>
 <dc:identifier>doi:10.1186/s13326-017-0128-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05975</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hardware-Based Linear Program Decoding with the Alternating Direction
  Method of Multipliers</dc:title>
 <dc:creator>Wasson, Mitchell</dc:creator>
 <dc:creator>Milicevic, Mario</dc:creator>
 <dc:creator>Draper, Stark C.</dc:creator>
 <dc:creator>Gulak, Glenn</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We present a hardware-based implementation of Linear Program (LP) decoding
for binary linear codes. LP decoding frames error-correction as an optimization
problem. In contrast, variants of Belief Propagation (BP) decoding frame
error-correction as a problem of graphical inference. LP decoding has several
advantages over BP-based methods, including convergence guarantees and better
error-rate performance in high-reliability channels. The latter makes LP
decoding attractive for optical transport and storage applications. However, LP
decoding, when implemented with general solvers, does not scale to large
blocklengths and is not suitable for a parallelized implementation in hardware.
It has been recently shown that the Alternating Direction Method of Multipliers
(ADMM) can be applied to decompose the LP decoding problem. The result is a
message-passing algorithm with a structure very similar to BP. We present new
intuition for this decoding algorithm as well as for its major computational
primitive: projection onto the parity polytope. Furthermore, we present results
for a fixed-point Verilog implementation of ADMM-LP decoding. This
implementation targets a Field-Programmable Gate Array (FPGA) platform to
evaluate error-rate performance and estimate resource usage. We show that Frame
Error Rate (FER) performance well within 0.5dB of double-precision
implementations is possible with 10-bit messages. Finally, we outline a number
of research opportunities that should be explored en-route to the realization
of an Application Specific Integrated Circuit (ASIC) implementation capable of
gigabit per second throughput.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05975</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05977</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust and Scalable Column/Row Sampling from Corrupted Big Data</dc:title>
 <dc:creator>Rahmani, Mostafa</dc:creator>
 <dc:creator>Atia, George</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Conventional sampling techniques fall short of drawing descriptive sketches
of the data when the data is grossly corrupted as such corruptions break the
low rank structure required for them to perform satisfactorily. In this paper,
we present new sampling algorithms which can locate the informative columns in
presence of severe data corruptions. In addition, we develop new scalable
randomized designs of the proposed algorithms. The proposed approach is
simultaneously robust to sparse corruption and outliers and substantially
outperforms the state-of-the-art robust sampling algorithms as demonstrated by
experiments conducted using both real and synthetic data.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05977</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05980</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Precondition Inference for Peephole Optimizations in LLVM</dc:title>
 <dc:creator>Menendez, David</dc:creator>
 <dc:creator>Nagarakatte, Santosh</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Peephole optimizations are a common source of compiler bugs. Compiler
developers typically transform an incorrect peephole optimization into a valid
one by strengthening the precondition. This process is challenging and tedious.
This paper proposes ALIVE-INFER, a data-driven approach that infers
preconditions for peephole optimizations expressed in Alive. ALIVE-INFER
generates positive and negative examples for an optimization, enumerates
predicates on-demand, and learns a set of predicates that separate the positive
and negative examples. ALIVE-INFER repeats this process until it finds a
precondition that ensures the validity of the optimization. ALIVE-INFER reports
both a weakest precondition and a set of succinct partial preconditions to the
developer. Our prototype generates preconditions that are weaker than LLVM's
preconditions for 73 optimizations in the Alive suite. We also demonstrate the
applicability of this technique to generalize 54 optimization patterns
generated by Souper, an LLVM~IR--based superoptimizer.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05980</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05985</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressed Sensing from Phaseless Gaussian Measurements via Linear
  Programming in the Natural Parameter Space</dc:title>
 <dc:creator>Hand, Paul</dc:creator>
 <dc:creator>Voroninski, Vladislav</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We consider faithfully combining phase retrieval with classical compressed
sensing. Inspired by the recent novel formulation for phase retrieval called
PhaseMax, we present and analyze SparsePhaseMax, a linear program for phaseless
compressed sensing in the natural parameter space. We establish that when
provided with an initialization that correlates with an arbitrary $k$-sparse
$n$-vector, SparsePhaseMax recovers this vector up to global sign with high
probability from $O(k \log \frac{n}{k})$ magnitude measurements against i.i.d.
Gaussian random vectors. Our proof of this fact exploits a curious newfound
connection between phaseless and 1-bit compressed sensing. This is the first
result to establish bootstrapped compressed sensing from phaseless Gaussian
measurements under optimal sample complexity.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05985</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05990</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monte Carlo Connection Prover</dc:title>
 <dc:creator>F&#xe4;rber, Michael</dc:creator>
 <dc:creator>Kaliszyk, Cezary</dc:creator>
 <dc:creator>Urban, Josef</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Monte Carlo Tree Search (MCTS) is a technique to guide search in a large
decision space by taking random samples and evaluating their outcome. In this
work, we study MCTS methods in the context of the connection calculus and
implement them on top of the leanCoP prover. This includes proposing useful
proof-state evaluation heuristics that are learned from previous proofs, and
proposing and automatically improving suitable MCTS strategies in this context.
The system is trained and evaluated on a large suite of related problems coming
from the Mizar proof assistant, showing that it is capable to find new and
different proofs. To our knowledge, this is the first time MCTS has been
applied to theorem proving.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05990</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05991</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Almost-Polynomial Ratio ETH-Hardness of Approximating Densest
  $k$-Subgraph</dc:title>
 <dc:creator>Manurangsi, Pasin</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In the Densest $k$-Subgraph problem, given an undirected graph $G$ and an
integer $k$, the goal is to find a subgraph of $G$ on $k$ vertices that
contains maximum number of edges. Even though the state-of-the-art algorithm
for the problem achieves only $O(n^{1/4 + \varepsilon})$ approximation ratio
(Bhaskara et al., 2010), previous attempts at proving hardness of
approximation, including those under average case assumptions, fail to achieve
a polynomial ratio; the best ratios ruled out under any worst case assumption
and any average case assumption are only any constant (Raghavendra and Steurer,
2010) and $2^{\Omega(\log^{2/3} n)}$ (Alon et al., 2011) respectively.
  In this work, we show, assuming the exponential time hypothesis (ETH), that
there is no polynomial-time algorithm that approximates Densest $k$-Subgraph to
within $n^{1/(\log \log n)^c}$ factor of the optimum, where $c &gt; 0$ is a
universal constant independent of $n$. In addition, our result has &quot;perfect
completeness&quot;, meaning that we prove that it is ETH-hard to even distinguish
between the case in which $G$ contains a $k$-clique and the case in which every
induced $k$-subgraph of $G$ has density at most $1/n^{-1/(\log \log n)^c}$ in
polynomial time.
  Moreover, if we make a stronger assumption that there is some constant
$\varepsilon &gt; 0$ such that no subexponential-time algorithm can distinguish
between a satisfiable 3SAT formula and one which is only $(1 -
\varepsilon)$-satisfiable (also known as Gap-ETH), then the ratio above can be
improved to $n^{f(n)}$ for any function $f$ whose limit is zero as $n$ goes to
infinity (i.e. $f \in o(1)$).
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05992</identifier>
 <datestamp>2017-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure and Energy-Efficient Beamforming for Simultaneous Information and
  Energy Transfer</dc:title>
 <dc:creator>Nasir, Ali A.</dc:creator>
 <dc:creator>Tuan, Hoang D.</dc:creator>
 <dc:creator>Duong, Trung Q.</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Next-generation communication networks will likely involve the
energy-efficient transfer of information and energy over the same wireless
channel, for which the physical layer will become more vulnerable to cyber
attacks by potential multi-antenna eavesdroppers. To address this issue, this
paper considers transmit time-switching (TS) mode, in which energy and
information signals are transmitted separately in time by the BS. This protocol
is not only easy to implement but also delivers the opportunity of
multi-purpose beamforming, in which energy beamformers during wireless power
transfer are useful in jamming the eavesdropper. In the presence of imperfect
channel estimation and multi-antenna eavesdroppers, the energy and information
beamformers and the transmit TS ratio are jointly optimized to maximize the
worst-case user secrecy rate subject to UEs' harvested energy thresholds and a
BS transmit power budget. New robust path-following algorithms, which involve
one simple convex quadratic program at each iteration are proposed for
computational solutions of this difficult optimization problem and also the
problem of secure energy efficiency maximization. The latter is further complex
due to additional optimization variables appearing in the denominator of the
secrecy rate function. Numerical results confirm that the performance of the
proposed computational solutions is robust against the channel uncertainties.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05994</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Dissection of the Test-Driven Development Process: Does It Really
  Matter to Test-First or to Test-Last?</dc:title>
 <dc:creator>Fucci, Davide</dc:creator>
 <dc:creator>Erdogmus, Hakan</dc:creator>
 <dc:creator>Turhan, Burak</dc:creator>
 <dc:creator>Oivo, Markku</dc:creator>
 <dc:creator>Juristo, Natalia</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Background: Test-driven development (TDD) is a technique that repeats short
coding cycles interleaved with testing. The developer first writes a unit test
for the desired functionality, followed by the necessary production code, and
refactors the code. Many empirical studies neglect unique process
characteristics related to TDD iterative nature. Aim: We formulate four process
characteristic: sequencing, granularity, uniformity, and refactoring effort. We
investigate how these characteristics impact quality and productivity in TDD
and related variations. Method: We analyzed 82 data points collected from 39
professionals, each capturing the process used while performing a specific
development task. We built regression models to assess the impact of process
characteristics on quality and productivity. Quality was measured by functional
correctness. Result: Quality and productivity improvements were primarily
positively associated with the granularity and uniformity. Sequencing, the
order in which test and production code are written, had no important
influence. Refactoring effort was negatively associated with both outcomes. We
explain the unexpected negative correlation with quality by possible prevalence
of mixed refactoring. Conclusion: The claimed benefits of TDD may not be due to
its distinctive test-first dynamic, but rather due to the fact that TDD-like
processes encourage fine-grained, steady steps that improve focus and flow.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05994</dc:identifier>
 <dc:identifier>doi:10.1109/TSE.2016.2616877</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05995</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wireless-powered relaying with finite block-length codes</dc:title>
 <dc:creator>Haghifam, Mahdi</dc:creator>
 <dc:creator>Makki, Behrooz</dc:creator>
 <dc:creator>Nasiri-Kenari, Masoumeh</dc:creator>
 <dc:creator>Svensson, Tommy</dc:creator>
 <dc:creator>Zorzi, Michele</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies the outage probability and the throughput of
amplify-and-forward relay networks with wireless information and energy
transfer. We use some recent results on finite block-length codes to analyze
the system performance in the cases with short codewords. Specifically, the
time switching relaying and the power splitting relaying protocols are
considered for energy and information transfer. We derive tight approximations
for the outage probability/throughput. Then, we analyze the outage probability
in asymptotically high signal-to-noise ratios. Finally, we use numerical
results to confirm the accuracy of our analysis and to evaluate the system
performance in different scenarios. Our results indicate that, in
delay-constrained scenarios, the codeword length affects the outage
probability/throughput of the joint energy and information transfer systems
considerably.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05995</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.05998</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weak Decoupling, Polynomial Folds, and Approximate Optimization over the
  Sphere</dc:title>
 <dc:creator>Bhattiprolu, Vijay</dc:creator>
 <dc:creator>Ghosh, Mrinalkanti</dc:creator>
 <dc:creator>Guruswami, Venkatesan</dc:creator>
 <dc:creator>Lee, Euiwoong</dc:creator>
 <dc:creator>Tulsiani, Madhur</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the following basic problem: given an $n$-variate degree-$d$
homogeneous polynomial $f$ with real coefficients, compute a unit vector $x \in
\mathbb{R}^n$ that maximizes $|f(x)|$. Besides its fundamental nature, this
problem arises in diverse contexts ranging from tensor and operator norms to
graph expansion to quantum information theory. The homogeneous degree $2$ case
is efficiently solvable as it corresponds to computing the spectral norm of an
associated matrix, but the higher degree case is NP-hard.
  We give approximation algorithms for this problem that offer a trade-off
between the approximation ratio and running time: in $n^{O(q)}$ time, we get an
approximation within factor $O_d((n/q)^{d/2-1})$ for arbitrary polynomials,
$O_d((n/q)^{d/4-1/2})$ for polynomials with non-negative coefficients, and
$O_d(\sqrt{m/q})$ for sparse polynomials with $m$ monomials. The approximation
guarantees are with respect to the optimum of the level-$q$ sum-of-squares
(SoS) SDP relaxation of the problem. Known polynomial time algorithms for this
problem rely on &quot;decoupling lemmas.&quot; Such tools are not capable of offering a
trade-off like our results as they blow up the number of variables by a factor
equal to the degree. We develop new decoupling tools that are more efficient in
the number of variables at the expense of less structure in the output
polynomials. This enables us to harness the benefits of higher level SoS
relaxations.
  We complement our algorithmic results with some polynomially large
integrality gaps, albeit for a slightly weaker (but still very natural)
relaxation. Toward this, we give a method to lift a level-$4$ solution matrix
$M$ to a higher level solution, under a mild technical condition on $M$.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-04-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.05998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06008</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-User Millimeter Wave MIMO with Full-Dimensional Lens Antenna Array</dc:title>
 <dc:creator>Zeng, Yong</dc:creator>
 <dc:creator>Yang, Lu</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Millimeter wave (mmWave) communication by utilizing lens antenna arrays is a
promising technique for realizing cost-effective 5G wireless systems with large
MIMO (multiple-input multiple-output) but only limited radio frequency (RF)
chains. This paper studies an uplink multi-user mmWave single-sided lens MIMO
system, where only the base station (BS) is equipped with a full-dimensional
(FD) lens antenna array with both elevation and azimuth angle resolution
capabilities, and each mobile station (MS) employs the conventional uniform
planar array (UPA) without the lens. By exploiting the angle-dependent energy
focusing property of the lens antenna array at the BS as well as the multi-path
sparsity of mmWave channels, we propose a low-complexity path division multiple
access (PDMA) scheme, which enables virtually interference-free multi-user
communications when the angle of arrivals (AoAs) of all MS multi-path signals
are sufficiently separable at the BS. To this end, a new technique called path
delay compensation is proposed at the BS to effectively transform the
multi-user frequency-selective MIMO channels to parallel frequency-flat
small-size MIMO channels for different MSs, for each of which the
low-complexity single-carrier(SC) transmission is applied. For general
scenarios with insufficient AoA separations, analog beamforming at the MSs and
digital combining at the BS are jointly designed to maximize the achievable
sum-rate of the MSs based on their effective MIMO channels resulting from path
delay compensation. In addition, we propose a new and efficient channel
estimation scheme tailored for PDMA, which requires negligible training
overhead in practical mmWave systems and yet leads to comparable performance as
that based on perfect channel state information (CSI).
</dc:description>
 <dc:description>Comment: 14 pages, 9 figures, submitted for possible journal publication</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06009</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fuzzy Statistical Matrices for Cell Classification</dc:title>
 <dc:creator>Thibault, Guillaume</dc:creator>
 <dc:creator>Shafran, Izhak</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we generalize image (texture) statistical descriptors and
propose algorithms that improve their efficacy. Recently, a new method showed
how the popular Co-Occurrence Matrix (COM) can be modified into a fuzzy version
(FCOM) which is more effective and robust to noise. Here, we introduce new
fuzzy versions of two additional higher order statistical matrices: the Run
Length Matrix (RLM) and the Size Zone Matrix (SZM). We define the fuzzy zones
and propose an efficient algorithm to compute the descriptors. We demonstrate
the advantage of the proposed improvements over several state-of-the-art
methods on three tasks from quantitative cell biology: analyzing and
classifying Human Epithelial type 2 (HEp-2) cells using Indirect
Immunofluorescence protocol (IFF).
</dc:description>
 <dc:description>Comment: 21 pages, 7 figures, 5 tables</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06011</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Visual Multi-Object Tracking via Labeled Random Finite Set
  Filtering</dc:title>
 <dc:creator>Kim, Du Yong</dc:creator>
 <dc:creator>Vo, Ba-Ngu</dc:creator>
 <dc:creator>Vo, Ba-Tuong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes an online visual multi-object tracking algorithm using a
top-down Bayesian formulation that seamlessly integrates state estimation,
track management, clutter rejection, occlusion and mis-detection handling into
a single recursion. This is achieved by modeling the multi-object state as
labeled random finite set and using the Bayes recursion to propagate the
multi-object filtering density forward in time. The proposed filter updates
tracks with detections but switches to image data when mis-detection occurs,
thereby exploiting the efficiency of detection data and the accuracy of image
data. Furthermore the labeled random finite set framework enables the
incorporation of prior knowledge that mis-detections of long tracks which occur
in the middle of the scene are likely to be due to occlusions. Such prior
knowledge can be exploited to improve occlusion handling, especially long
occlusions that can lead to premature track termination in on-line multi-object
tracking. Tracking performance are compared to state-of-the-art algorithms on
well-known benchmark video datasets.
</dc:description>
 <dc:description>Comment: 13 pages, 9 figures</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06013</identifier>
 <datestamp>2017-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving training of deep neural networks via Singular Value Bounding</dc:title>
 <dc:creator>Jia, Kui</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning methods achieve great success recently on many computer vision
problems, with image classification and object detection as the prominent
examples. In spite of these practical successes, optimization of deep networks
remains an active topic in deep learning research. In this work, we focus on
investigation of the network solution properties that can potentially lead to
good performance. Our research is inspired by theoretical and empirical results
that use orthogonal matrices to initialize networks, but we are interested in
investigating how orthogonal weight matrices perform when network training
converges. To this end, we propose to constrain the solutions of weight
matrices in the orthogonal feasible set during the whole process of network
training, and achieve this by a simple yet effective method called Singular
Value Bounding (SVB). In SVB, all singular values of each weight matrix are
simply bounded in a narrow band around the value of 1. Based on the same
motivation, we also propose Bounded Batch Normalization (BBN), which improves
Batch Normalization by removing its potential risk of ill-conditioned layer
transform. We present both theoretical and empirical results to justify our
proposed methods. Experiments on benchmark image classification datasets show
the efficacy of our proposed SVB and BBN. In particular, we achieve the
state-of-the-art results of 3.06% error rate on CIFAR10 and 16.90% on CIFAR100,
using off-the-shelf network architectures (Wide ResNets). Our preliminary
results on ImageNet also show the promise in large-scale learning.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06026</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross Domain Knowledge Transfer for Person Re-identification</dc:title>
 <dc:creator>Xiao, Qiqi</dc:creator>
 <dc:creator>Cao, Kelei</dc:creator>
 <dc:creator>Chen, Haonan</dc:creator>
 <dc:creator>Peng, Fangyue</dc:creator>
 <dc:creator>Zhang, Chi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Person Re-Identification (re-id) is a challenging task in computer vision,
especially when there are limited training data from multiple camera views. In
this paper, we pro- pose a deep learning based person re-identification method
by transferring knowledge of mid-level attribute features and high-level
classification features. Building on the idea that identity classification,
attribute recognition and re- identification share the same mid-level semantic
representations, they can be trained sequentially by fine-tuning one based on
another. In our framework, we train identity classification and attribute
recognition tasks from deep Convolutional Neural Network (dCNN) to learn person
information. The information can be transferred to the person re-id task and
improves its accuracy by a large margin. Further- more, a Long Short Term
Memory(LSTM) based Recurrent Neural Network (RNN) component is extended by a
spacial gate. This component is used in the re-id model to pay attention to
certain spacial parts in each recurrent unit. Experimental results show that
our method achieves 78.3% of rank-1 recognition accuracy on the CUHK03
benchmark.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06038</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polynomial self-stabilizing algorithm and proof for a 2/3-approximation
  of a maximum matching</dc:title>
 <dc:creator>Cohen, Johanne</dc:creator>
 <dc:creator>Ma&#xe2;mra, Khaled</dc:creator>
 <dc:creator>Manoussakis, George</dc:creator>
 <dc:creator>Pilard, Laurence</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We present the first polynomial self-stabilizing algorithm for finding a
$\frac23$-approximation of a maximum matching in a general graph. The previous
best known algorithm has been presented by Manne \emph{et al.}
\cite{ManneMPT11} and has a sub-exponential time complexity under the
distributed adversarial daemon \cite{Coor}. Our new algorithm is an adaptation
of the Manne \emph{et al.} algorithm and works under the same daemon, but with
a time complexity in $O(n^3)$ moves. Moreover, our algorithm only needs one
more boolean variable than the previous one, thus as in the Manne \emph{et al.}
algorithm, it only requires a constant amount of memory space (three
identifiers and $two$ booleans per node).
</dc:description>
 <dc:description>Comment: 16 pages, 6 figures</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06049</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantifying gender preferences across humans lifespan</dc:title>
 <dc:creator>Ghosh, Asim</dc:creator>
 <dc:creator>Monsivais, Daniel</dc:creator>
 <dc:creator>Bhattacharya, Kunal</dc:creator>
 <dc:creator>Dunbar, Robin I. M.</dc:creator>
 <dc:creator>Kaski, Kimmo</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  In human relations individuals' gender and age play a key role in the
structures and dynamics of their social arrangements. In order to analyze the
gender preferences of individuals in interaction with others at different
stages of their lives we study a large mobile phone dataset. To do this we
consider four fundamental gender-related caller and callee combinations of
human interactions, namely male to male, male to female, female to male, and
female to female, which together with age, kinship, and different levels of
friendship give rise to a wide scope of human sociality. Here we analyse the
relative strength of these four types of interaction using a large dataset of
mobile phone communication records. Our analysis suggests strong age dependence
for an ego of one gender choosing to call an individual of either gender. We
observe a strong opposite sex bonding across most of their reproductive age.
However, older women show a strong tendency to connect to another female that
is one generation younger in a way that is suggestive of the
\emph{grandmothering effect}. We also find that the relative strength among the
four possible interactions depends on phone call duration. For calls of medium
and long duration, opposite gender interactions are significantly more probable
than same gender interactions during the reproductive years, suggesting
potential emotional exchange between spouses. By measuring the fraction of
calls to other generations we find that mothers tend to make calls more to
their daughters than to their sons, whereas fathers make calls more to their
sons than to their daughters. For younger people, most of their calls go to
same generation alters, while older people call the younger people more
frequently, which supports the suggestion that \emph{affection flows downward}.
</dc:description>
 <dc:description>Comment: 12 pages, 8 figures</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06067</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An End-to-End Spatio-Temporal Attention Model for Human Action
  Recognition from Skeleton Data</dc:title>
 <dc:creator>Song, Sijie</dc:creator>
 <dc:creator>Lan, Cuiling</dc:creator>
 <dc:creator>Xing, Junliang</dc:creator>
 <dc:creator>Zeng, Wenjun</dc:creator>
 <dc:creator>Liu, Jiaying</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Human action recognition is an important task in computer vision. Extracting
discriminative spatial and temporal features to model the spatial and temporal
evolutions of different actions plays a key role in accomplishing this task. In
this work, we propose an end-to-end spatial and temporal attention model for
human action recognition from skeleton data. We build our model on top of the
Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM), which
learns to selectively focus on discriminative joints of skeleton within each
frame of the inputs and pays different levels of attention to the outputs of
different frames. Furthermore, to ensure effective training of the network, we
propose a regularized cross-entropy loss to drive the model learning process
and develop a joint training strategy accordingly. Experimental results
demonstrate the effectiveness of the proposed model,both on the small human
action recognition data set of SBU and the currently largest NTU dataset.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06067</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06069</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepVO: A Deep Learning approach for Monocular Visual Odometry</dc:title>
 <dc:creator>Mohanty, Vikram</dc:creator>
 <dc:creator>Agrawal, Shubh</dc:creator>
 <dc:creator>Datta, Shaswat</dc:creator>
 <dc:creator>Ghosh, Arna</dc:creator>
 <dc:creator>Sharma, Vishnu Dutt</dc:creator>
 <dc:creator>Chakravarty, Debashish</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep Learning based techniques have been adopted with precision to solve a
lot of standard computer vision problems, some of which are image
classification, object detection and segmentation. Despite the widespread
success of these approaches, they have not yet been exploited largely for
solving the standard perception related problems encountered in autonomous
navigation such as Visual Odometry (VO), Structure from Motion (SfM) and
Simultaneous Localization and Mapping (SLAM). This paper analyzes the problem
of Monocular Visual Odometry using a Deep Learning-based framework, instead of
the regular 'feature detection and tracking' pipeline approaches. Several
experiments were performed to understand the influence of a known/unknown
environment, a conventional trackable feature and pre-trained activations tuned
for object classification on the network's ability to accurately estimate the
motion trajectory of the camera (or the vehicle). Based on these observations,
we propose a Convolutional Neural Network architecture, best suited for
estimating the object's pose under known environment conditions, and displays
promising results when it comes to inferring the actual scale using just a
single camera in real-time.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06070</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rope through Loop Insertion for Robotic Knotting: A Virtual Magnetic
  Field Formulation</dc:title>
 <dc:creator>Marzinotto, Alejandro</dc:creator>
 <dc:creator>Stork, Johannes A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Inserting an end of a rope through a loop is a common and important action
that is required for creating most types of knots. To perform this action, we
need to pass the end of the rope through an area that is enclosed by another
segment of rope. As for all knotting actions, the robot must for this exercise
control over a semi-compliant and flexible body whose complex 3d shape is
difficult to perceive and follow. Additionally, the target loop often deforms
during the insertion. We address this problem by defining a virtual magnetic
field through the loop's interior and use the Biot Savart law to guide the
robotic manipulator that holds the end of the rope. This approach directly
defines, for any manipulator position, a motion vector that results in a path
that passes through the loop. The motion vector is directly derived from the
position of the loop and changes as soon as it moves or deforms. In simulation,
we test the insertion action against dynamic loop deformation of different
intensity. We also combine insertion with grasp and release actions,
coordinated by a hybrid control system, to tie knots in simulation and with a
NAO robot.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06078</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast and reconfigurable packet classification engine in FPGA-based
  firewall</dc:title>
 <dc:creator>Wicaksana, Arief</dc:creator>
 <dc:creator>Sasongko, Arif</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In data communication via internet, security is becoming one of the most
influential aspects. One way to support it is by classifying and filtering
ethernet packets within network devices. Packet classification is a fundamental
task for network devices such as routers, firewalls, and intrusion detection
systems. In this paper we present architecture of fast and reconfigurable
Packet Classification Engine (PCE). This engine is used in FPGA-based firewall.
Our PCE inspects multi-dimensional field of packet header sequentially based on
tree-based algorithm. This algorithm simplifies overall system to a lower scale
and leads to a more secure system. The PCE works with an adaptation of single
cycle processor architecture in the system. Ethernet packet is examined with
PCE based on Source IP Address, Destination IP Address, Source Port,
Destination Port, and Protocol fields of the packet header. These are basic
fields to know whether it is a dangerous or normal packet before inspecting the
content. Using implementation of tree-based algorithm in the architecture,
firewall rules are rebuilt into 24-bit sub-rules which are read as processor
instruction in the inspection process. The inspection process is comparing one
sub-rule with input field of header every clock cycle. The proposed PCE shows
91 MHz clock frequency in Cyclone II EP2C70F896C6 with 13 clocks throughput
average from input to output generation. The use of tree-based algorithm
simplifies the multidimensional packet inspection and gives us reconfigurable
as well as scalable system. The architecture is fast, reliable, and adaptable
and also can maximize the advantages of the algorithm very well. Although the
PCE has high frequency and little amount of clock, filtering speed of a
firewall also depends on the other components, such as packet FIFO buffer. Fast
and reliable FIFO buffer is needed to support the PCE. This PCE also is not
completed with rule update mechanism yet. This proposed PCE is tested as a
component of FPGA-based firewall to filter Ethernet packet with FPGA DE2 Board
using NIOS II platform.
</dc:description>
 <dc:description>Comment: in 2011 International Conference on Electrical Engineering and
  Informatics (ICEEI), Jul 2011, Bandung, Indonesia</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06078</dc:identifier>
 <dc:identifier>doi:10.1109/ICEEI.2011.6021782</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06079</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Machine Learning Approach to Model the Received Signal in Molecular
  Communications</dc:title>
 <dc:creator>Yilmaz, H. Birkan</dc:creator>
 <dc:creator>Lee, Changmin</dc:creator>
 <dc:creator>Cho, Yae Jee</dc:creator>
 <dc:creator>Chae, Chan-Byoung</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A molecular communication channel is determined by the received signal.
Received signal models form the basis for studies focused on modulation,
receiver design, capacity, and coding depend on the received signal models.
Therefore, it is crucial to model the number of received molecules until time
$t$ analytically. Modeling the diffusion-based molecular communication channel
with the first-hitting process is an open issue for a spherical transmitter. In
this paper, we utilize the artificial neural networks technique to model the
received signal for a spherical transmitter and a perfectly absorbing receiver
(i.e., first hitting process). The proposed technique may be utilized in other
studies that assume a spherical transmitter instead of a point transmitter.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06079</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06080</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Generalized Stochastic Variational Bayesian Hyperparameter Learning
  Framework for Sparse Spectrum Gaussian Process Regression</dc:title>
 <dc:creator>Hoang, Quang Minh</dc:creator>
 <dc:creator>Hoang, Trong Nghia</dc:creator>
 <dc:creator>Low, Kian Hsiang</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  While much research effort has been dedicated to scaling up sparse Gaussian
process (GP) models based on inducing variables for big data, little attention
is afforded to the other less explored class of low-rank GP approximations that
exploit the sparse spectral representation of a GP kernel. This paper presents
such an effort to advance the state of the art of sparse spectrum GP models to
achieve competitive predictive performance for massive datasets. Our
generalized framework of stochastic variational Bayesian sparse spectrum GP
(sVBSSGP) models addresses their shortcomings by adopting a Bayesian treatment
of the spectral frequencies to avoid overfitting, modeling these frequencies
jointly in its variational distribution to enable their interaction a
posteriori, and exploiting local data for boosting the predictive performance.
However, such structural improvements result in a variational lower bound that
is intractable to be optimized. To resolve this, we exploit a variational
parameterization trick to make it amenable to stochastic optimization.
Interestingly, the resulting stochastic gradient has a linearly decomposable
structure that can be exploited to refine our stochastic optimization method to
incur constant time per iteration while preserving its property of being an
unbiased estimator of the exact gradient of the variational lower bound.
Empirical evaluation on real-world datasets shows that sVBSSGP outperforms
state-of-the-art stochastic implementations of sparse GP models.
</dc:description>
 <dc:description>Comment: 31st AAAI Conference on Artificial Intelligence (AAAI 2017), Extended
  version with proofs, 11 pages</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06086</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Swarm Intelligence for Multiobjective Optimization of Extraction Process</dc:title>
 <dc:creator>Ganesan, T.</dc:creator>
 <dc:creator>Elamvazuthi, I.</dc:creator>
 <dc:creator>Vasant, P.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Multi objective (MO) optimization is an emerging field which is increasingly
being implemented in many industries globally. In this work, the MO
optimization of the extraction process of bioactive compounds from the Gardenia
Jasminoides Ellis fruit was solved. Three swarm-based algorithms have been
applied in conjunction with normal-boundary intersection (NBI) method to solve
this MO problem. The gravitational search algorithm (GSA) and the particle
swarm optimization (PSO) technique were implemented in this work. In addition,
a novel Hopfield-enhanced particle swarm optimization was developed and applied
to the extraction problem. By measuring the levels of dominance, the optimality
of the approximate Pareto frontiers produced by all the algorithms were gauged
and compared. Besides, by measuring the levels of convergence of the frontier,
some understanding regarding the structure of the objective space in terms of
its relation to the level of frontier dominance is uncovered. Detail
comparative studies were conducted on all the algorithms employed and developed
in this work.
</dc:description>
 <dc:date>2016-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06086</dc:identifier>
 <dc:identifier>Handbook of Research on Modern Optimization Algorithms and
  Applications in Engineering and Economics, (2016), IGI Global, pp 516 - 544</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06092</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Epidemic spreading on complex networks with community structures</dc:title>
 <dc:creator>Stegehuis, Clara</dc:creator>
 <dc:creator>van der Hofstad, Remco</dc:creator>
 <dc:creator>van Leeuwaarden, Johan S. H.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Many real-world networks display a community structure. We study two random
graph models that create a network with similar community structure as a given
network. One model preserves the exact community structure of the original
network, while the other model only preserves the set of communities and the
vertex degrees. These models show that community structure is an important
determinant of the behavior of percolation processes on networks, such as
information diffusion or virus spreading: the community structure can both
\textit{enforce} as well as \textit{inhibit} diffusion processes. Our models
further show that it is the mesoscopic set of communities that matters. The
exact internal structures of communities barely influence the behavior of
percolation processes across networks. This insensitivity is likely due to the
relative denseness of the communities.
</dc:description>
 <dc:description>Comment: 19 pages</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06092</dc:identifier>
 <dc:identifier>Scientific Reports 6, Article number: 29748 (2016)</dc:identifier>
 <dc:identifier>doi:10.1038/srep29748</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06101</identifier>
 <datestamp>2017-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dependent Types for Extensive Games</dc:title>
 <dc:creator>Lescanne, Pierre</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  Extensive games are tools largely used in economics to describe decision
processes ofa community of agents. In this paper we propose a formal
presentation based on theproof assistant COQ which focuses mostly on infinite
extensive games and theircharacteristics. COQ proposes a feature called
&quot;dependent types&quot;, which meansthat the type of an object may depend on the type
of its components. For instance,the set of choices or the set of utilities of
an agent may depend on the agentherself. Using dependent types, we describe
formally a very general class of gamesand strategy profiles, which corresponds
somewhat to what game theorists are used to.We also discuss the notions of
infiniteness in game theory and how this can beprecisely described.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06108</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Navigational Rule Derivation: An algorithm to determine the effect of
  traffic signs on road networks</dc:title>
 <dc:creator>Galaktionov, Daniil</dc:creator>
 <dc:creator>Luaces, Miguel R.</dc:creator>
 <dc:creator>Places, &#xc1;ngeles S.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper we present an algorithm to build a road network map enriched
with traffic rules such as one-way streets and forbidden turns, based on the
interpretation of already detected and classified traffic signs. Such algorithm
helps to automatize the elaboration of maps for commercial navigation systems.
Our solution is based on simulating navigation along the road network,
determining at each point of interest the visibility of the signs and their
effect on the roads. We test our approach in a small urban network and discuss
various ways to generalize it to support more complex environments.
</dc:description>
 <dc:description>Comment: This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941. in PACIS 2016 Online
  Proceedings</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06108</dc:identifier>
 <dc:identifier>Proceeding of the 20th Pacific Asia Conference on Information
  Systems (PACIS 2016). Association for Information Systems. AIS Electronic
  Library (AISeL). Paper 94. ISBN: 9789860491029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06115</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast low-level pattern matching algorithm</dc:title>
 <dc:creator>Soldo, Janja Paliska</dc:creator>
 <dc:creator>Krzic, Ana Sovic</dc:creator>
 <dc:creator>Sersic, and Damir</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:description>  This paper focuses on pattern matching in the DNA sequence. It was inspired
by a previously reported method that proposes encoding both pattern and
sequence using prime numbers. Although fast, the method is limited to rather
small pattern lengths, due to computing precision problem. Our approach
successfully deals with large patterns, due to our implementation that uses
modular arithmetic. In order to get the results very fast, the code was adapted
for multithreading and parallel implementations. The method is reduced to
assembly language level instructions, thus the final result shows significant
time and memory savings compared to the reference algorithm.
</dc:description>
 <dc:description>Comment: 14 pages, 7 tables This work has been fully supported by Croatian
  Science Foundation under the project UIP-11-2013-7353 Algorithms for Genome
  Sequence Analysis</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06128</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Annex: Radon - Rapid Discovery of Topological Relations</dc:title>
 <dc:creator>Sherif, Mohamed Ahmed</dc:creator>
 <dc:creator>Dre&#xdf;ler, Kevin</dc:creator>
 <dc:creator>Smeros, Panayiotis</dc:creator>
 <dc:creator>Ngomo, Axel-Cyrille Ngonga</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Datasets containing geo-spatial resources are increasingly being represented
according to the Linked Data principles. Several time-efficient approaches for
discovering links between RDF resources have been developed over the last
years. However, the time-efficient discovery of topological relations between
geospatial resources has been paid little attention to. We address this
research gap by presenting Radon, a novel approach for the rapid computation of
topological relations between geo-spatial resources. Our approach uses a sparse
tiling index in combination with minimum bounding boxes to reduce the
computation time of topological relations. Our evaluation of Radon's runtime on
45 datasets and in more than 800 experiments shows that it outperforms the
state of the art by up to 3 orders of magnitude while maintaining an F-measure
of 100%. Moreover, our experiments suggest that Radon scales up well when
implemented in parallel.
</dc:description>
 <dc:description>Comment: 19 pages, 3 figures, i algorithm and 1 table</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06132</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster variational inducing input Gaussian process classification</dc:title>
 <dc:creator>Izmailov, Pavel</dc:creator>
 <dc:creator>Kropotov, Dmitry</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Gaussian processes (GP) provide a prior over functions and allow finding
complex regularities in data. Gaussian processes are successfully used for
classification/regression problems and dimensionality reduction. In this work
we consider the classification problem only. The complexity of standard methods
for GP-classification scales cubically with the size of the training dataset.
This complexity makes them inapplicable to big data problems. Therefore, a
variety of methods were introduced to overcome this limitation. In the paper we
focus on methods based on so called inducing inputs. This approach is based on
variational inference and proposes a particular lower bound for marginal
likelihood (evidence). This bound is then maximized w.r.t. parameters of kernel
function of the Gaussian process, thus fitting the model to data. The
computational complexity of this method is $O(nm^2)$, where $m$ is the number
of inducing inputs used by the model and is assumed to be substantially smaller
than the size of the dataset $n$. Recently, a new evidence lower bound for
GP-classification problem was introduced. It allows using stochastic
optimization, which makes it suitable for big data problems. However, the new
lower bound depends on $O(m^2)$ variational parameter, which makes optimization
challenging in case of big m. In this work we develop a new approach for
training inducing input GP models for classification problems. Here we use
quadratic approximation of several terms in the aforementioned evidence lower
bound, obtaining analytical expressions for optimal values of most of the
parameters in the optimization, thus sufficiently reducing the dimension of
optimization space. In our experiments we achieve as well or better results,
compared to the existing method. Moreover, our method doesn't require the user
to manually set the learning rate, making it more practical, than the existing
method.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06134</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Team-maxmin equilibrium: efficiency bounds and algorithms</dc:title>
 <dc:creator>Basilico, Nicola</dc:creator>
 <dc:creator>Celli, Andrea</dc:creator>
 <dc:creator>De Nittis, Giuseppe</dc:creator>
 <dc:creator>Gatti, Nicola</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The Team-maxmin equilibrium prescribes the optimal strategies for a team of
rational players sharing the same goal and without the capability of
correlating their strategies in strategic games against an adversary. This
solution concept can capture situations in which an agent controls multiple
resources-corresponding to the team members-that cannot communicate. It is
known that such equilibrium always exists and it is unique (unless degeneracy)
and these properties make it a credible solution concept to be used in
real-world applications, especially in security scenarios. Nevertheless, to the
best of our knowledge, the Team-maxmin equilibrium is almost completely
unexplored in the literature. In this paper, we investigate bounds of
(in)efficiency of the Team-maxmin equilibrium w.r.t. the Nash equilibria and
w.r.t. the Maxmin equilibrium when the team members can play correlated
strategies. Furthermore, we study a number of algorithms to find and/or
approximate an equilibrium, discussing their theoretical guarantees and
evaluating their performance by using a standard testbed of game instances.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06140</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A theory of passive linear systems with no assumptions</dc:title>
 <dc:creator>Hughes, Timothy H.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We present two linked theorems on passivity: the passive behavior theorem,
parts 1 and 2. Part 1 provides necessary and sufficient conditions for a
general linear system, described by a set of high order differential equations,
to be passive. Part 2 extends the positive-real lemma to include uncontrollable
and unobservable state-space systems.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06140</dc:identifier>
 <dc:identifier>Hughes, T.H.: A theory of passive linear systems with no
  assumptions, Automatica, 86, 87-97 (2017)</dc:identifier>
 <dc:identifier>doi:10.1016/j.automatica.2017.08.017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06145</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CoSTAR: Instructing Collaborative Robots with Behavior Trees and Vision</dc:title>
 <dc:creator>Paxton, Chris</dc:creator>
 <dc:creator>Hundt, Andrew</dc:creator>
 <dc:creator>Jonathan, Felix</dc:creator>
 <dc:creator>Guerin, Kelleher</dc:creator>
 <dc:creator>Hager, Gregory D.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  For collaborative robots to become useful, end users who are not robotics
experts must be able to instruct them to perform a variety of tasks. With this
goal in mind, we developed a system for end-user creation of robust task plans
with a broad range of capabilities. CoSTAR: the Collaborative System for Task
Automation and Recognition is our winning entry in the 2016 KUKA Innovation
Award competition at the Hannover Messe trade show, which this year focused on
Flexible Manufacturing. CoSTAR is unique in how it creates natural abstractions
that use perception to represent the world in a way users can both understand
and utilize to author capable and robust task plans. Our Behavior Tree-based
task editor integrates high-level information from known object segmentation
and pose estimation with spatial reasoning and robot actions to create robust
task plans. We describe the cross-platform design and implementation of this
system on multiple industrial robots and evaluate its suitability for a wide
variety of use cases.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06145</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06148</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compacting Neural Network Classifiers via Dropout Training</dc:title>
 <dc:creator>Kubo, Yotaro</dc:creator>
 <dc:creator>Tucker, George</dc:creator>
 <dc:creator>Wiesler, Simon</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We introduce dropout compaction, a novel method for training feed-forward
neural networks which realizes the performance gains of training a large model
with dropout regularization, yet extracts a compact neural network for run-time
efficiency. In the proposed method, we introduce a sparsity-inducing prior on
the per unit dropout retention probability so that the optimizer can
effectively prune hidden units during training. By changing the prior
hyperparameters, we can control the size of the resulting network. We performed
a systematic comparison of dropout compaction and competing methods on several
real-world speech recognition tasks and found that dropout compaction achieved
comparable accuracy with fewer than 50% of the hidden units, translating to a
2.5x speedup in run-time.
</dc:description>
 <dc:description>Comment: Submitted to AISTATS 2017 (Short-version is accepted to NIPS Workshop
  on Efficient Methods for Deep Neural Networks)</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06150</identifier>
 <datestamp>2017-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Key Consensus in Presence of Noise</dc:title>
 <dc:creator>Jin, Zhengzhong</dc:creator>
 <dc:creator>Zhao, Yunlei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this work, we abstract some key ingredients in previous LWE- and
RLWE-based key exchange protocols, by introducing and formalizing the building
tool, referred to as key consensus (KC) and its asymmetric variant AKC. KC and
AKC allow two communicating parties to reach consensus from close values
obtained by some secure information exchange. We then discover upper bounds on
parameters for any KC and AKC. KC and AKC are fundamental to lattice based
cryptography, in the sense that a list of cryptographic primitives based on
LWR, LWE and RLWE (including key exchange, public-key encryption, and more) can
be modularly constructed from them. As a conceptual contribution, this much
simplifies the design and analysis of these cryptosystems in the future.
  We then design and analyze both general and highly practical KC and AKC
schemes, which are referred to as OKCN and AKCN respectively for presentation
simplicity. Based on KC and AKC, we present generic constructions of key
exchange (KE) from LWR, LWE and RLWE. The generic construction allows versatile
instantiations with our OKCN and AKCN schemes, for which we elaborate on
evaluating and choosing the concrete parameters in order to achieve an
optimally-balanced performance among security, computational cost, bandwidth
efficiency, error rate, and operation simplicity.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-10-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06150</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06158</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AFFACT - Alignment-Free Facial Attribute Classification Technique</dc:title>
 <dc:creator>G&#xfc;nther, Manuel</dc:creator>
 <dc:creator>Rozsa, Andras</dc:creator>
 <dc:creator>Boult, Terrance E.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Facial attributes are soft-biometrics that allow limiting the search space,
e.g., by rejecting identities with non-matching facial characteristics such as
nose sizes or eyebrow shapes. In this paper, we investigate how the latest
versions of deep convolutional neural networks, ResNets, perform on the facial
attribute classification task. We test two loss functions: the sigmoid
cross-entropy loss and the Euclidean loss, and find that for classification
performance there is little difference between these two. Using an ensemble of
three ResNets, we obtain the new state-of-the-art facial attribute
classification error of 8.00% on the aligned images of the CelebA dataset. More
significantly, we introduce the Alignment-Free Facial Attribute Classification
Technique (AFFACT), a data augmentation technique that allows a network to
classify facial attributes without requiring alignment beyond detected face
bounding boxes. To our best knowledge, we are the first to report similar
accuracy when using only the detected bounding boxes -- rather than requiring
alignment based on automatically detected facial landmarks -- and who can
improve classification accuracy with rotating and scaling test images. We show
that this approach outperforms the CelebA baseline on unaligned images with a
relative improvement of 36.8%.
</dc:description>
 <dc:description>Comment: This is a pre-print of the original paper accepted for oral
  presentation at the International Joint Conference on Biometrics (IJCB) 2017</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06158</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06159</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-End Subtitle Detection and Recognition for Videos in East Asian
  Languages via CNN Ensemble with Near-Human-Level Performance</dc:title>
 <dc:creator>Xu, Yan</dc:creator>
 <dc:creator>Shan, Siyuan</dc:creator>
 <dc:creator>Qiu, Ziming</dc:creator>
 <dc:creator>Jia, Zhipeng</dc:creator>
 <dc:creator>Shen, Zhengyang</dc:creator>
 <dc:creator>Wang, Yipei</dc:creator>
 <dc:creator>Shi, Mengfei</dc:creator>
 <dc:creator>Chang, Eric I-Chao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose an innovative end-to-end subtitle detection and
recognition system for videos in East Asian languages. Our end-to-end system
consists of multiple stages. Subtitles are firstly detected by a novel image
operator based on the sequence information of consecutive video frames. Then,
an ensemble of Convolutional Neural Networks (CNNs) trained on synthetic data
is adopted for detecting and recognizing East Asian characters. Finally, a
dynamic programming approach leveraging language models is applied to
constitute results of the entire body of text lines. The proposed system
achieves average end-to-end accuracies of 98.2% and 98.3% on 40 videos in
Simplified Chinese and 40 videos in Traditional Chinese respectively, which is
a significant outperformance of other existing methods. The near-perfect
accuracy of our system dramatically narrows the gap between human cognitive
ability and state-of-the-art algorithms used for such a task.
</dc:description>
 <dc:description>Comment: 35 pages</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06159</dc:identifier>
 <dc:identifier>doi:10.1016/j.image.2017.09.013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06164</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving the Coverage and Spectral Efficiency of Millimeter-Wave
  Cellular Networks using Device-to-Device Relays</dc:title>
 <dc:creator>Wu, Shuanshuan</dc:creator>
 <dc:creator>Atat, Rachad</dc:creator>
 <dc:creator>Mastronarde, Nicholas</dc:creator>
 <dc:creator>Liu, Lingjia</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:description>  The susceptibility of millimeter waveform propagation to blockages limits the
coverage of millimeter-wave (mmWave) signals. To overcome blockages, we propose
to leverage two-hop device-to-device (D2D) relaying. Using stochastic geometry,
we derive expressions for the downlink coverage probability of relay-assisted
mmWave cellular networks when the D2D links are implemented in either uplink
mmWave or uplink microwave bands. We further investigate the spectral
efficiency (SE) improvement in the cellular downlink, and the effect of D2D
transmissions on the cellular uplink. For mmWave links, we derive the coverage
probability using dominant interferer analysis while accounting for both
blockages and beamforming gains. For microwave D2D links, we derive the
coverage probability considering both line-of-sight (LOS) and non-line-of-sight
(NLOS) propagation. Numerical results show that downlink coverage and SE can be
improved using two-hop D2D relaying. Specifically, microwave D2D relays achieve
better coverage because D2D connections can be established under NLOS
conditions. However, mmWave D2D relays achieve better coverage when the density
of interferers is large because blockages eliminate interference from NLOS
interferers. The SE on the downlink depends on the relay mode selection
strategy, and mmWave D2D relays use a significantly smaller fraction of uplink
resources than microwave D2D relays.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2018-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06164</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2017.2787990</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06172</identifier>
 <datestamp>2016-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallelizing Word2Vec in Multi-Core and Many-Core Architectures</dc:title>
 <dc:creator>Ji, Shihao</dc:creator>
 <dc:creator>Satish, Nadathur</dc:creator>
 <dc:creator>Li, Sheng</dc:creator>
 <dc:creator>Dubey, Pradeep</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Word2vec is a widely used algorithm for extracting low-dimensional vector
representations of words. State-of-the-art algorithms including those by
Mikolov et al. have been parallelized for multi-core CPU architectures, but are
based on vector-vector operations with &quot;Hogwild&quot; updates that are
memory-bandwidth intensive and do not efficiently use computational resources.
In this paper, we propose &quot;HogBatch&quot; by improving reuse of various data
structures in the algorithm through the use of minibatching and negative sample
sharing, hence allowing us to express the problem using matrix multiply
operations. We also explore different techniques to distribute word2vec
computation across nodes in a compute cluster, and demonstrate good strong
scalability up to 32 nodes. The new algorithm is particularly suitable for
modern multi-core/many-core architectures, especially Intel's latest Knights
Landing processors, and allows us to scale up the computation near linearly
across cores and nodes, and process hundreds of millions of words per second,
which is the fastest word2vec implementation to the best of our knowledge.
</dc:description>
 <dc:description>Comment: NIPS Workshop on Efficient Methods for Deep Neural Networks (2016)</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2016-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06172</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06174</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stratified Knowledge Bases as Interpretable Probabilistic Models
  (Extended Abstract)</dc:title>
 <dc:creator>Kuzelka, Ondrej</dc:creator>
 <dc:creator>Davis, Jesse</dc:creator>
 <dc:creator>Schockaert, Steven</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper, we advocate the use of stratified logical theories for
representing probabilistic models. We argue that such encodings can be more
interpretable than those obtained in existing frameworks such as Markov logic
networks. Among others, this allows for the use of domain experts to improve
learned models by directly removing, adding, or modifying logical formulas.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06175</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Interpretability for Visualizations using Adapted Cox Models
  through a User Experiment</dc:title>
 <dc:creator>Bibal, Adrien</dc:creator>
 <dc:creator>Fr&#xe9;nay, Benoit</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In order to be useful, visualizations need to be interpretable. This paper
uses a user-based approach to combine and assess quality measures in order to
better model user preferences. Results show that cluster separability measures
are outperformed by a neighborhood conservation measure, even though the former
are usually considered as intuitively representative of user motives. Moreover,
combining measures, as opposed to using a single measure, further improves
prediction performances.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06179</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LOTS about Attacking Deep Features</dc:title>
 <dc:creator>Rozsa, Andras</dc:creator>
 <dc:creator>G&#xfc;nther, Manuel</dc:creator>
 <dc:creator>Boult, Terrance E.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep neural networks provide state-of-the-art performance on various tasks
and are, therefore, widely used in real world applications. DNNs are becoming
frequently utilized in biometrics for extracting deep features, which can be
used in recognition systems for enrolling and recognizing new individuals. It
was revealed that deep neural networks suffer from a fundamental problem,
namely, they can unexpectedly misclassify examples formed by slightly
perturbing correctly recognized inputs. Various approaches have been developed
for generating these so-called adversarial examples, but they aim at attacking
end-to-end networks. For biometrics, it is natural to ask whether systems using
deep features are immune to or, at least, more resilient to attacks than
end-to-end networks. In this paper, we introduce a general technique called the
layerwise origin-target synthesis (LOTS) that can be efficiently used to form
adversarial examples that mimic the deep features of the target. We analyze and
compare the adversarial robustness of the end-to-end VGG Face network with
systems that use Euclidean or cosine distance between gallery templates and
extracted deep features. We demonstrate that iterative LOTS is very effective
and show that systems utilizing deep features are easier to attack than the
end-to-end network.
</dc:description>
 <dc:description>Comment: Accepted to the International Joint Conference on Biometrics (IJCB)
  2017</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06188</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variable Computation in Recurrent Neural Networks</dc:title>
 <dc:creator>Jernite, Yacine</dc:creator>
 <dc:creator>Grave, Edouard</dc:creator>
 <dc:creator>Joulin, Armand</dc:creator>
 <dc:creator>Mikolov, Tomas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recurrent neural networks (RNNs) have been used extensively and with
increasing success to model various types of sequential data. Much of this
progress has been achieved through devising recurrent units and architectures
with the flexibility to capture complex statistics in the data, such as long
range dependency or localized attention phenomena. However, while many
sequential data (such as video, speech or language) can have highly variable
information flow, most recurrent models still consume input features at a
constant rate and perform a constant number of computations per time step,
which can be detrimental to both speed and model capacity. In this paper, we
explore a modification to existing recurrent units which allows them to learn
to vary the amount of computation they perform at each step, without prior
knowledge of the sequence's time structure. We show experimentally that not
only do our models require fewer operations, they also lead to better
performance overall on evaluation tasks.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06189</identifier>
 <datestamp>2017-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Query Complexity of Tournament Solutions</dc:title>
 <dc:creator>Dey, Palash</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A directed graph where there is exactly one edge between every pair of
vertices is called a {\em tournament}. Finding the &quot;best&quot; set of vertices of a
tournament is a well studied problem in social choice theory. A {\em tournament
solution} takes a tournament as input and outputs a subset of vertices of the
input tournament. However, in many applications, for example, choosing the best
set of drugs from a given set of drugs, the edges of the tournament are given
only implicitly and knowing the orientation of an edge is costly. In such
scenarios, we would like to know the best set of vertices (according to some
tournament solution) by &quot;querying&quot; as few edges as possible. We, in this paper,
precisely study this problem for commonly used tournament solutions: given an
oracle access to the edges of a tournament T, find $f(T)$ by querying as few
edges as possible, for a tournament solution f. We first show that the set of
Condorcet non-losers in a tournament can be found by querying $2n-\lfloor \log
n \rfloor -2$ edges only and this is tight in the sense that every algorithm
for finding the set of Condorcet non-losers needs to query at least $2n-\lfloor
\log n \rfloor -2$ edges in the worst case, where $n$ is the number of vertices
in the input tournament. We then move on to study other popular tournament
solutions and show that any algorithm for finding the Copeland set, the Slater
set, the Markov set, the bipartisan set, the uncovered set, the Banks set, and
the top cycle must query $\Omega(n^2)$ edges in the worst case. On the positive
side, we are able to circumvent our strong query complexity lower bound results
by proving that, if the size of the top cycle of the input tournament is at
most $k$, then we can find all the tournament solutions mentioned above by
querying $O(nk + \frac{n\log n}{\log(1-\frac{1}{k})})$ edges only.
</dc:description>
 <dc:description>Comment: To appear in AAAI 2017</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06194</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Expert Gate: Lifelong Learning with a Network of Experts</dc:title>
 <dc:creator>Aljundi, Rahaf</dc:creator>
 <dc:creator>Chakravarty, Punarjay</dc:creator>
 <dc:creator>Tuytelaars, Tinne</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper we introduce a model of lifelong learning, based on a Network
of Experts. New tasks / experts are learned and added to the model
sequentially, building on what was learned before. To ensure scalability of
this process,data from previous tasks cannot be stored and hence is not
available when learning a new task. A critical issue in such context, not
addressed in the literature so far, relates to the decision which expert to
deploy at test time. We introduce a set of gating autoencoders that learn a
representation for the task at hand, and, at test time, automatically forward
the test sample to the relevant expert. This also brings memory efficiency as
only one expert network has to be loaded into memory at any given time.
Further, the autoencoders inherently capture the relatedness of one task to
another, based on which the most relevant prior model to be used for training a
new expert, with finetuning or learning without-forgetting, can be selected. We
evaluate our method on image classification and video prediction problems.
</dc:description>
 <dc:description>Comment: CVPR 2017 paper</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06197</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Study of Continuous Connectivity Degree Sequence
  Equivalents</dc:title>
 <dc:creator>Moyer, Daniel</dc:creator>
 <dc:creator>Gutman, Boris A.</dc:creator>
 <dc:creator>Faskowitz, Joshua</dc:creator>
 <dc:creator>Jahanshad, Neda</dc:creator>
 <dc:creator>Thompson, Paul M.</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In the present work we demonstrate the use of a parcellation free
connectivity model based on Poisson point processes. This model produces for
each subject a continuous bivariate intensity function that represents for
every possible pair of points the relative rate at which we observe tracts
terminating at those points. We fit this model to explore degree sequence
equivalents for spatial continuum graphs, and to investigate the local
differences between estimated intensity functions for two different
tractography methods. This is a companion paper to Moyer et al. (2016), where
the model was originally defined.
</dc:description>
 <dc:description>Comment: Presented at The MICCAI-BACON 16 Workshop
  (https://arxiv.org/abs/1611.03363)</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06203</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ear Recognition: More Than a Survey</dc:title>
 <dc:creator>Emer&#x161;i&#x10d;, &#x17d;iga</dc:creator>
 <dc:creator>&#x160;truc, Vitomir</dc:creator>
 <dc:creator>Peer, Peter</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatic identity recognition from ear images represents an active field of
research within the biometric community. The ability to capture ear images from
a distance and in a covert manner makes the technology an appealing choice for
surveillance and security applications as well as other application domains.
Significant contributions have been made in the field over recent years, but
open research problems still remain and hinder a wider (commercial) deployment
of the technology. This paper presents an overview of the field of automatic
ear recognition (from 2D images) and focuses specifically on the most recent,
descriptor-based methods proposed in this area. Open challenges are discussed
and potential research directions are outlined with the goal of providing the
reader with a point of reference for issues worth examining in the future. In
addition to a comprehensive review on ear recognition technology, the paper
also introduces a new, fully unconstrained dataset of ear images gathered from
the web and a toolbox implementing several state-of-the-art techniques for ear
recognition. The dataset and toolbox are meant to address some of the open
issues in the field and are made publicly available to the research community.
</dc:description>
 <dc:description>Comment: 17 pages, paper accepted to Neurocomputing</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06204</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visualizing and Understanding Curriculum Learning for Long Short-Term
  Memory Networks</dc:title>
 <dc:creator>Cirik, Volkan</dc:creator>
 <dc:creator>Hovy, Eduard</dc:creator>
 <dc:creator>Morency, Louis-Philippe</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Curriculum Learning emphasizes the order of training instances in a
computational learning setup. The core hypothesis is that simpler instances
should be learned early as building blocks to learn more complex ones. Despite
its usefulness, it is still unknown how exactly the internal representation of
models are affected by curriculum learning. In this paper, we study the effect
of curriculum learning on Long Short-Term Memory (LSTM) networks, which have
shown strong competency in many Natural Language Processing (NLP) problems. Our
experiments on sentiment analysis task and a synthetic task similar to sequence
prediction tasks in NLP show that curriculum learning has a positive effect on
the LSTM's internal states by biasing the model towards building constructive
representations i.e. the internal representation at the previous timesteps are
used as building blocks for the final prediction. We also find that smaller
models significantly improves when they are trained with curriculum learning.
Lastly, we show that curriculum learning helps more when the amount of training
data is limited.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06211</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NoiseOut: A Simple Way to Prune Neural Networks</dc:title>
 <dc:creator>Babaeizadeh, Mohammad</dc:creator>
 <dc:creator>Smaragdis, Paris</dc:creator>
 <dc:creator>Campbell, Roy H.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Neural networks are usually over-parameterized with significant redundancy in
the number of required neurons which results in unnecessary computation and
memory usage at inference time. One common approach to address this issue is to
prune these big networks by removing extra neurons and parameters while
maintaining the accuracy. In this paper, we propose NoiseOut, a fully automated
pruning algorithm based on the correlation between activations of neurons in
the hidden layers. We prove that adding additional output neurons with entirely
random targets results into a higher correlation between neurons which makes
pruning by NoiseOut even more efficient. Finally, we test our method on various
networks and datasets. These experiments exhibit high pruning rates while
maintaining the accuracy of the original network.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06213</identifier>
 <datestamp>2017-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GaDei: On Scale-up Training As A Service For Deep Learning</dc:title>
 <dc:creator>Zhang, Wei</dc:creator>
 <dc:creator>Feng, Minwei</dc:creator>
 <dc:creator>Zheng, Yunhui</dc:creator>
 <dc:creator>Ren, Yufei</dc:creator>
 <dc:creator>Wang, Yandong</dc:creator>
 <dc:creator>Liu, Ji</dc:creator>
 <dc:creator>Liu, Peng</dc:creator>
 <dc:creator>Xiang, Bing</dc:creator>
 <dc:creator>Zhang, Li</dc:creator>
 <dc:creator>Zhou, Bowen</dc:creator>
 <dc:creator>Wang, Fei</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>C.1.3</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:description>  Deep learning (DL) training-as-a-service (TaaS) is an important emerging
industrial workload. The unique challenge of TaaS is that it must satisfy a
wide range of customers who have no experience and resources to tune DL
hyper-parameters, and meticulous tuning for each user's dataset is
prohibitively expensive. Therefore, TaaS hyper-parameters must be fixed with
values that are applicable to all users. IBM Watson Natural Language Classifier
(NLC) service, the most popular IBM cognitive service used by thousands of
enterprise-level clients around the globe, is a typical TaaS service. By
evaluating the NLC workloads, we show that only the conservative
hyper-parameter setup (e.g., small mini-batch size and small learning rate) can
guarantee acceptable model accuracy for a wide range of customers. We further
justify theoretically why such a setup guarantees better model convergence in
general. Unfortunately, the small mini-batch size causes a high volume of
communication traffic in a parameter-server based system. We characterize the
high communication bandwidth requirement of TaaS using representative
industrial deep learning workloads and demonstrate that none of the
state-of-the-art scale-up or scale-out solutions can satisfy such a
requirement. We then present GaDei, an optimized shared-memory based scale-up
parameter server design. We prove that the designed protocol is deadlock-free
and it processes each gradient exactly once. Our implementation is evaluated on
both commercial benchmarks and public benchmarks to demonstrate that it
significantly outperforms the state-of-the-art parameter-server based
implementation while maintaining the required accuracy and our implementation
reaches near the best possible runtime performance, constrained only by the
hardware limitation. Furthermore, to the best of our knowledge, GaDei is the
only scale-up DL system that provides fault-tolerance.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-10-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06216</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Deep Neural Networks for Dialogue: A Short Review</dc:title>
 <dc:creator>Serban, Iulian Vlad</dc:creator>
 <dc:creator>Lowe, Ryan</dc:creator>
 <dc:creator>Charlin, Laurent</dc:creator>
 <dc:creator>Pineau, Joelle</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Researchers have recently started investigating deep neural networks for
dialogue applications. In particular, generative sequence-to-sequence (Seq2Seq)
models have shown promising results for unstructured tasks, such as word-level
dialogue response generation. The hope is that such models will be able to
leverage massive amounts of data to learn meaningful natural language
representations and response generation strategies, while requiring a minimum
amount of domain knowledge and hand-crafting. An important challenge is to
develop models that can effectively incorporate dialogue context and generate
meaningful and diverse responses. In support of this goal, we review recently
proposed models based on generative encoder-decoder neural network
architectures, and show that these models have better ability to incorporate
long-term dialogue history, to model uncertainty and ambiguity in dialogue, and
to generate responses with high-level compositional structure.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, 3 tables; NIPS 2016 workshop on Learning Methods
  for Dialogue</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06221</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structural Causal Models: Cycles, Marginalizations, Exogenous
  Reparametrizations and Reductions</dc:title>
 <dc:creator>Bongers, Stephan</dc:creator>
 <dc:creator>Peters, Jonas</dc:creator>
 <dc:creator>Sch&#xf6;lkopf, Bernhard</dc:creator>
 <dc:creator>Mooij, Joris M.</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Structural causal models (SCMs), also known as non-parametric structural
equation models (NP-SEMs), are widely used for causal modeling purposes. In
this paper, we give a rigorous treatment of structural causal models, dealing
with measure-theoretic complications that arise in the presence of cyclic
relations. The central question studied in this paper is: given a (possibly
cyclic) SCM defined on a large system (consisting of observable endogenous and
latent exogenous variables), can we &quot;project it down&quot; to an SCM that describes
a subsystem (consisting of a subset of the observed endogenous variables and
possibly different latent exogenous variables) in order to obtain a more
parsimonious but equivalent representation of the subsystem? We define a
marginalization operation that effectively removes a subset of the endogenous
variables from the model, and a class of mappings, exogenous
reparameterizations, that can be used to reduce the space of exogenous
variables. We show that both operations preserve the causal semantics of the
model and that under mild conditions they can lead to a significant reduction
of the model complexity, at least in terms of the number of variables in the
model. We argue that for the task of estimating an SCM from data, the existence
of &quot;smooth&quot; reductions would be desirable. We provide several conditions under
which the existence of such reductions can be shown, but also provide a
counterexample that shows that such reductions do not exist in general. The
latter result implies that existing approaches to estimate linear or Markovian
SCMs from data cannot be extended to general SCMs.
</dc:description>
 <dc:description>Comment: Will probably be submitted to The Annals of Statistics</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06221</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06222</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Near Neighbors for General Symmetric Norms</dc:title>
 <dc:creator>Andoni, Alexandr</dc:creator>
 <dc:creator>Nguyen, Huy L.</dc:creator>
 <dc:creator>Nikolov, Aleksandar</dc:creator>
 <dc:creator>Razenshteyn, Ilya</dc:creator>
 <dc:creator>Waingarten, Erik</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:description>  We show that every symmetric normed space admits an efficient nearest
neighbor search data structure with doubly-logarithmic approximation.
Specifically, for every $n$, $d = n^{o(1)}$, and every $d$-dimensional
symmetric norm $\|\cdot\|$, there exists a data structure for
$\mathrm{poly}(\log \log n)$-approximate nearest neighbor search over
$\|\cdot\|$ for $n$-point datasets achieving $n^{o(1)}$ query time and
$n^{1+o(1)}$ space. The main technical ingredient of the algorithm is a
low-distortion embedding of a symmetric norm into a low-dimensional iterated
product of top-$k$ norms.
  We also show that our techniques cannot be extended to general norms.
</dc:description>
 <dc:description>Comment: 27 pages, 1 figure</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06224</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ModelHub: Towards Unified Data and Lifecycle Management for Deep
  Learning</dc:title>
 <dc:creator>Miao, Hui</dc:creator>
 <dc:creator>Li, Ang</dc:creator>
 <dc:creator>Davis, Larry S.</dc:creator>
 <dc:creator>Deshpande, Amol</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning has improved state-of-the-art results in many important fields,
and has been the subject of much research in recent years, leading to the
development of several systems for facilitating deep learning. Current systems,
however, mainly focus on model building and training phases, while the issues
of data management, model sharing, and lifecycle management are largely
ignored. Deep learning modeling lifecycle generates a rich set of data
artifacts, such as learned parameters and training logs, and comprises of
several frequently conducted tasks, e.g., to understand the model behaviors and
to try out new models. Dealing with such artifacts and tasks is cumbersome and
largely left to the users. This paper describes our vision and implementation
of a data and lifecycle management system for deep learning. First, we
generalize model exploration and model enumeration queries from commonly
conducted tasks by deep learning modelers, and propose a high-level domain
specific language (DSL), inspired by SQL, to raise the abstraction level and
accelerate the modeling process. To manage the data artifacts, especially the
large amount of checkpointed float parameters, we design a novel model
versioning system (dlv), and a read-optimized parameter archival storage system
(PAS) that minimizes storage footprint and accelerates query workloads without
losing accuracy. PAS archives versioned models using deltas in a
multi-resolution fashion by separately storing the less significant bits, and
features a novel progressive query (inference) evaluation algorithm. Third, we
show that archiving versioned models using deltas poses a new dataset
versioning problem and we develop efficient algorithms for solving it. We
conduct extensive experiments over several real datasets from computer vision
domain to show the efficiency of the proposed techniques.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06232</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implementing Ideas for Improving Software Citation and Credit</dc:title>
 <dc:creator>Teuben, Peter</dc:creator>
 <dc:creator>Allen, Alice</dc:creator>
 <dc:creator>Berriman, G. Bruce</dc:creator>
 <dc:creator>DuPrie, Kimberly</dc:creator>
 <dc:creator>Mink, Jessica</dc:creator>
 <dc:creator>Robitaille, Thomas</dc:creator>
 <dc:creator>Shortridge, Keith</dc:creator>
 <dc:creator>Taylor, Mark</dc:creator>
 <dc:creator>Warmels, Rein</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Improving software citation and credit continues to be a topic of interest
across and within many disciplines, with numerous efforts underway. In this
Birds of a Feather (BoF) session, we started with a list of actionable ideas
from last year's BoF and other similar efforts and worked alone or in small
groups to begin implementing them. Work was captured in a common Google
document; the session organizers will disseminate or otherwise put this
information to use in or for the community in collaboration with those who
contributed.
</dc:description>
 <dc:description>Comment: 4 pages; to be published in ADASS XXVI (held Oct 16-20, 2016)
  proceedings</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06241</identifier>
 <datestamp>2017-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using LSTM recurrent neural networks for monitoring the LHC
  superconducting magnets</dc:title>
 <dc:creator>Wielgosz, Maciej</dc:creator>
 <dc:creator>Skocze&#x144;, Andrzej</dc:creator>
 <dc:creator>Mertik, Matej</dc:creator>
 <dc:subject>Physics - Instrumentation and Detectors</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Accelerator Physics</dc:subject>
 <dc:description>  The superconducting LHC magnets are coupled with an electronic monitoring
system which records and analyses voltage time series reflecting their
performance. A currently used system is based on a range of preprogrammed
triggers which launches protection procedures when a misbehavior of the magnets
is detected. All the procedures used in the protection equipment were designed
and implemented according to known working scenarios of the system and are
updated and monitored by human operators.
  This paper proposes a novel approach to monitoring and fault protection of
the Large Hadron Collider (LHC) superconducting magnets which employs
state-of-the-art Deep Learning algorithms. Consequently, the authors of the
paper decided to examine the performance of LSTM recurrent neural networks for
modeling of voltage time series of the magnets. In order to address this
challenging task different network architectures and hyper-parameters were used
to achieve the best possible performance of the solution. The regression
results were measured in terms of RMSE for different number of future steps and
history length taken into account for the prediction. The best result of
RMSE=0.00104 was obtained for a network of 128 LSTM cells within the internal
layer and 16 steps history buffer.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-06-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06241</dc:identifier>
 <dc:identifier>doi:10.1016/j.nima.2017.06.020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06245</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spikes as regularizers</dc:title>
 <dc:creator>S&#xf8;gaard, Anders</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a confidence-based single-layer feed-forward learning algorithm
SPIRAL (Spike Regularized Adaptive Learning) relying on an encoding of
activation spikes. We adaptively update a weight vector relying on confidence
estimates and activation offsets relative to previous activity. We regularize
updates proportionally to item-level confidence and weight-specific support,
loosely inspired by the observation from neurophysiology that high spike rates
are sometimes accompanied by low temporal precision. Our experiments suggest
that the new learning algorithm SPIRAL is more robust and less prone to
overfitting than both the averaged perceptron and AROW.
</dc:description>
 <dc:description>Comment: Computing with Spikes at NIPS 2016</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06245</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06249</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometric Controllability of The Purcell's Swimmer and its Symmetrized
  Cousin</dc:title>
 <dc:creator>Kadam, Sudin</dc:creator>
 <dc:creator>Banavar, Ravi</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We analyse weak and strong controllability notions for the locomotion of the
3-link Purcell's swimmer, the simplest possible swimmer at low Reynolds number
from a geometric framework. After revisiting a purely kinematic form of the
equations, we apply an extension of Chow's theorem to analyze controllability
in the strong and weak sense. Further, the connection form for the symmetric
version of the Purcell's swimmer is derived, based on which, the
controllability analysis utilizing the Abelian nature of the structure group is
presented. The novelty in our approach is the usage of geometry and the
principal fiber bundle structure of the configuration manifold of the system to
arrive at strong and weak controllability notions.
</dc:description>
 <dc:description>Comment: 6 pages, presented at IFAC symposium on Nonlinear Control Systems
  2016</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06256</identifier>
 <datestamp>2017-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning through Asynchronous Advantage Actor-Critic on a
  GPU</dc:title>
 <dc:creator>Babaeizadeh, Mohammad</dc:creator>
 <dc:creator>Frosio, Iuri</dc:creator>
 <dc:creator>Tyree, Stephen</dc:creator>
 <dc:creator>Clemons, Jason</dc:creator>
 <dc:creator>Kautz, Jan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce a hybrid CPU/GPU version of the Asynchronous Advantage
Actor-Critic (A3C) algorithm, currently the state-of-the-art method in
reinforcement learning for various gaming tasks. We analyze its computational
traits and concentrate on aspects critical to leveraging the GPU's
computational power. We introduce a system of queues and a dynamic scheduling
strategy, potentially helpful for other asynchronous algorithms as well. Our
hybrid CPU/GPU version of A3C, based on TensorFlow, achieves a significant
speed up compared to a CPU implementation; we make it publicly available to
other researchers at https://github.com/NVlabs/GA3C .
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06256</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06258</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why RLC realizations of certain impedances need many more energy storage
  elements than expected</dc:title>
 <dc:creator>Hughes, Timothy H.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  It is a significant and longstanding puzzle that the resistor, inductor,
capacitor (RLC) networks obtained by the established RLC realization procedures
appear highly non-minimal from the perspective of linear systems theory.
Specifically, each of these networks contains significantly more energy storage
elements than the McMillan degree of its impedance, and possesses a non-minimal
state-space representation whose states correspond to the inductor currents and
capacitor voltages. Despite this apparent non-minimality, there have been no
improved algorithms since the 1950s, with the concurrent discovery by Reza,
Pantell, Fialkow and Gerst of a class of networks (the RPFG networks), which
are a slight simplification of the Bott-Duffin networks. Each RPFG network
contains more than twice as many energy storage elements as the McMillan degree
of its impedance, yet it has never been established if all of these energy
storage elements are necessary. In this paper, we present some newly discovered
alternatives to the RPFG networks. We then prove that the RPFG networks, and
these newly discovered networks, contain the least possible number of energy
storage elements for realizing certain positive-real functions. In other words,
all RLC networks which realize certain impedances contain more than twice the
expected number (McMillan degree) of energy storage elements.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06258</dc:identifier>
 <dc:identifier>Hughes T.H.: Why RLC realizations of certain impedances need many
  more energy storage elements than expected. IEEE Trans. Autom. Control 62(9),
  4333-4346 (2017)</dc:identifier>
 <dc:identifier>doi:10.1109/TAC.2017.2667585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06265</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Clustering and Conventional Networks for Music Separation: Stronger
  Together</dc:title>
 <dc:creator>Luo, Yi</dc:creator>
 <dc:creator>Chen, Zhuo</dc:creator>
 <dc:creator>Hershey, John R.</dc:creator>
 <dc:creator>Roux, Jonathan Le</dc:creator>
 <dc:creator>Mesgarani, Nima</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Deep clustering is the first method to handle general audio separation
scenarios with multiple sources of the same type and an arbitrary number of
sources, performing impressively in speaker-independent speech separation
tasks. However, little is known about its effectiveness in other challenging
situations such as music source separation. Contrary to conventional networks
that directly estimate the source signals, deep clustering generates an
embedding for each time-frequency bin, and separates sources by clustering the
bins in the embedding space. We show that deep clustering outperforms
conventional networks on a singing voice separation task, in both matched and
mismatched conditions, even though conventional networks have the advantage of
end-to-end training for best signal approximation, presumably because its more
flexible objective engenders better regularization. Since the strengths of deep
clustering and conventional network architectures appear complementary, we
explore combining them in a single hybrid network trained via an approach akin
to multi-task learning. Remarkably, the combination significantly outperforms
either of its components.
</dc:description>
 <dc:description>Comment: Published in ICASSP 2017</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06265</dc:identifier>
 <dc:identifier>doi:10.1109/ICASSP.2017.7952118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06271</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Single-Source Surface Integral Method to Compute Scattering from
  Dielectric Objects</dc:title>
 <dc:creator>Patel, Utkarsh R.</dc:creator>
 <dc:creator>Triverio, Piero</dc:creator>
 <dc:creator>Hum, Sean V.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Using the traditional surface integral methods, the computation of scattering
from a dielectric object requires two equivalent current densities on the
boundary of the dielectric. In this paper, we present an approach that requires
only a single current density. Our method is based on a surface admittance
operator and is applicable to dielectric bodies of arbitrary shape. The
formulation results in four times lower memory consumption and up to eight
times lower time to solve the linear system than the traditional PMCHWT
formulation. Numerical results demonstrate that the proposed technique is as
accurate as the PMCHWT formulation.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Antennas and Wireless Propagation Letters on
  November 18, 2016</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06271</dc:identifier>
 <dc:identifier>doi:10.1109/LAWP.2017.2669183</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06276</identifier>
 <datestamp>2017-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mixing Metaphors: Actors as Channels and Channels as Actors (Extended
  Version)</dc:title>
 <dc:creator>Fowler, Simon</dc:creator>
 <dc:creator>Lindley, Sam</dc:creator>
 <dc:creator>Wadler, Philip</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:description>  Channel- and actor-based programming languages are both used in practice, but
the two are often confused. Languages such as Go provide anonymous processes
which communicate using buffers or rendezvous points---known as
channels---while languages such as Erlang provide addressable processes---known
as actors---each with a single incoming message queue. The lack of a common
representation makes it difficult to reason about translations that exist in
the folklore. We define a calculus $\lambda_{\textrm{ch}}$ for typed
asynchronous channels, and a calculus $\lambda_{\textrm{act}}$ for typed
actors. We define translations from $\lambda_{\textrm{act}}$ into
$\lambda_{\textrm{ch}}$ and $\lambda_{\textrm{ch}}$ into
$\lambda_{\textrm{act}}$ and prove that both are type- and
semantics-preserving. We show that our approach accounts for synchronisation
and selective receive in actor systems and discuss future extensions to support
guarded choice and behavioural types.
</dc:description>
 <dc:description>Comment: Extended version of paper appearing at ECOOP'17</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-05-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06284</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Anatomy Classification Through Visualization</dc:title>
 <dc:creator>Kumar, Devinder</dc:creator>
 <dc:creator>Menkovski, Vlado</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  One of the main challenges for broad adoption of deep convolutional neural
network (DCNN) models is the lack of understanding of their decision process.
In many applications a simpler less capable model that can be easily understood
is favorable to a black-box model that has superior performance. In this paper,
we present an approach for designing DCNN models based on visualization of the
internal activations of the model. We visualize the model's response using
fractional stride convolution technique and compare the results with known
imaging landmarks from the medical literature. We show that sufficiently deep
and capable models can be successfully trained to use the same medical
landmarks a human expert would use. The presented approach allows for
communicating the model decision process well, but also offers insight towards
detecting biases.
</dc:description>
 <dc:description>Comment: Accepted at 30th NIPS Machine learning for Health Workshop, 2016</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06284</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06285</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Good characterizations and linear time recognition for 2-probe block
  graphs</dc:title>
 <dc:creator>Le, Van Bang</dc:creator>
 <dc:creator>Peng, Sheng-Lung</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Block graphs are graphs in which every block (biconnected component) is a
clique. A graph $G=(V,E)$ is said to be an (unpartitioned) $k$-probe block
graph if there exist $k$ independent sets $N_i\subseteq V$, $1\le i\le k$, such
that the graph $G'$ obtained from $G$ by adding certain edges between vertices
inside the sets $N_i$, $1\le i\le k$, is a block graph; if the independent sets
$N_i$ are given, $G$ is called a partitioned $k$-probe block graph. In this
paper we give good characterizations for $2$-probe block graphs, in both
unpartitioned and partitioned cases. As an algorithmic implication, partitioned
and unpartitioned probe block graphs can be recognized in linear time,
improving a recognition algorithm of cubic time complexity previously obtained
by Chang et al. [Block-graph width, Theoretical Computer Science 412 (2011),
2496--2502].
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06285</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06292</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimizing cyber sickness in head mounted display systems: design
  guidelines and applications</dc:title>
 <dc:creator>Porcino, Thiago M.</dc:creator>
 <dc:creator>Clua, Esteban W.</dc:creator>
 <dc:creator>Vasconcelos, Cristina N.</dc:creator>
 <dc:creator>Trevisan, Daniela</dc:creator>
 <dc:creator>Valente, Luis</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  We are experiencing an upcoming trend of using head mounted display systems
in games and serious games, which is likely to become an established practice
in the near future. While these systems provide highly immersive experiences,
many users have been reporting discomfort symptoms, such as nausea, sickness,
and headaches, among others. When using VR for health applications, this is
more critical, since the discomfort may interfere a lot in treatments. In this
work we discuss possible causes of these issues, and present possible solutions
as design guidelines that may mitigate them. In this context, we go deeper
within a dynamic focus solution to reduce discomfort in immersive virtual
environments, when using first-person navigation. This solution applies an
heuristic model of visual attention that works in real time. This work also
discusses a case study (as a first-person spatial shooter demo) that applies
this solution and the proposed design guidelines.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures, 3 tables</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06296</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bayesian approach to type-specific conic fitting</dc:title>
 <dc:creator>Collett, Matthew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>I.4.8</dc:subject>
 <dc:description>  A perturbative approach is used to quantify the effect of noise in data
points on fitted parameters in a general homogeneous linear model, and the
results applied to the case of conic sections. There is an optimal choice of
normalisation that minimises bias, and iteration with the correct reweighting
significantly improves statistical reliability. By conditioning on an
appropriate prior, an unbiased type-specific fit can be obtained. Error
estimates for the conic coefficients may also be used to obtain both bias
corrections and confidence intervals for other curve parameters.
</dc:description>
 <dc:description>Comment: 27 pages, 9 figures</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06296</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06299</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Content-Centric and Software-Defined Networking with Big Data</dc:title>
 <dc:creator>Yao, Haipeng</dc:creator>
 <dc:creator>Qiu, Chao</dc:creator>
 <dc:creator>Fang, Chao</dc:creator>
 <dc:creator>Chen, Xu</dc:creator>
 <dc:creator>Yu, F. Richard</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Many communities have researched the application of novel network
architectures such as Content-Centric Networking (CCN) and Software-Defined
Networking (SDN) to build the future Internet. Another emerging technology
which is big data analysis has also won lots of attentions from academia to
industry. Many splendid researches have been done on CCN, SDN, and big data,
which all have addressed separately in the traditional literature. In this
paper, we propose a novel network paradigm to jointly consider CCN, SDN, and
big data, and provide the architecture internal data flow, big data processing
and use cases which indicate the benefits and applicability. Simulation results
are exhibited to show the potential benefits relating to the proposed network
paradigm. We refer to this novel paradigm as Data-Driven Networking (DDN).
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06301</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inferring Restaurant Styles by Mining Crowd Sourced Photos from
  User-Review Websites</dc:title>
 <dc:creator>Liao, Haofu</dc:creator>
 <dc:creator>Li, Yucheng</dc:creator>
 <dc:creator>Hu, Tianran</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  When looking for a restaurant online, user uploaded photos often give people
an immediate and tangible impression about a restaurant. Due to their
informativeness, such user contributed photos are leveraged by restaurant
review websites to provide their users an intuitive and effective search
experience. In this paper, we present a novel approach to inferring restaurant
types or styles (ambiance, dish styles, suitability for different occasions)
from user uploaded photos on user-review websites. To that end, we first
collect a novel restaurant photo dataset associating the user contributed
photos with the restaurant styles from TripAdvior. We then propose a deep
multi-instance multi-label learning (MIML) framework to deal with the unique
problem setting of the restaurant style classification task. We employ a
two-step bootstrap strategy to train a multi-label convolutional neural network
(CNN). The multi-label CNN is then used to compute the confidence scores of
restaurant styles for all the images associated with a restaurant. The computed
confidence scores are further used to train a final binary classifier for each
restaurant style tag. Upon training, the styles of a restaurant can be profiled
by analyzing restaurant photos with the trained multi-label CNN and SVM models.
Experimental evaluation has demonstrated that our crowd sourcing-based approach
can effectively infer the restaurant style when there are a sufficient number
of user uploaded photos for a given restaurant.
</dc:description>
 <dc:description>Comment: 10 pages, Accepted by IEEE BigData 2016</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06302</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Resource Allocation in Next Generation Cellular Networks with
  Full-Duplex Self-backhauls</dc:title>
 <dc:creator>Chen, Lei</dc:creator>
 <dc:creator>Yu, F. Richard</dc:creator>
 <dc:creator>Ji, Hong</dc:creator>
 <dc:creator>Rong, Bo</dc:creator>
 <dc:creator>Leung, Victor C. M.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  With the dense deployment of small cell networks, low-cost backhaul schemes
for small cell base stations (SBSs) have attracted great attentions.
Self-backhaul using cellular communication technology is considered as a
promising solution. Although some excellent works have been done on
self-backhaul in small cell networks, most of them do not consider the recent
advances of full-duplex (FD) and massive multiple-input and multiple-output
(MIMO) technologies. In this paper, we propose a self-backhaul scheme for small
cell networks by combining FD and massive MIMO technologies. In our proposed
scheme, the macro base station (MBS) is equipped with massive MIMO antennas,
and the SBSs have the FD communication ability. By treating the SBSs as
\textit{special} macro users, we can achieve the simultaneous transmissions of
the access link of users and the backhaul link of SBSs in the same frequency.
Furthermore, considering the existence of inter-tier and intra-tier
interference, we formulate the power allocation problem of the MBS and SBSs as
an optimization problem. Because the formulated power allocation problem is a
non-convex problem, we transform the original problem into a difference of
convex program (DCP) by successive convex approximation method (SCAM) and
variable transformation, and then solve it using a constrained concave convex
procedure (CCCP) based iterative algorithm. Finally, extensive simulations are
conducted with different system configurations to verify the effectiveness of
the proposed scheme.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06306</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-model convolutional neural network for multiple modality data
  representation</dc:title>
 <dc:creator>Wu, Yanbin</dc:creator>
 <dc:creator>Wang, Li</dc:creator>
 <dc:creator>Cui, Fan</dc:creator>
 <dc:creator>Zhai, Hongbin</dc:creator>
 <dc:creator>Dong, Baoming</dc:creator>
 <dc:creator>Wang, Jim Jing-Yan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A novel data representation method of convolutional neural net- work (CNN) is
proposed in this paper to represent data of different modalities. We learn a
CNN model for the data of each modality to map the data of differ- ent
modalities to a common space, and regularize the new representations in the
common space by a cross-model relevance matrix. We further impose that the
class label of data points can also be predicted from the CNN representa- tions
in the common space. The learning problem is modeled as a minimiza- tion
problem, which is solved by an augmented Lagrange method (ALM) with updating
rules of Alternating direction method of multipliers (ADMM). The experiments
over benchmark of sequence data of multiple modalities show its advantage.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06307</identifier>
 <datestamp>2017-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Scale Saliency Detection using Dictionary Learning</dc:title>
 <dc:creator>Pachori, Shubham</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Saliency detection has drawn a lot of attention of researchers in various
fields over the past several years. Saliency is the perceptual quality that
makes an object, person to draw the attention of humans at the very sight.
Salient object detection in an image has been used centrally in many
computational photography and computer vision applications like video
compression, object recognition and classification, object segmentation,
adaptive content delivery, motion detection, content aware resizing, camouflage
images and change blindness images to name a few. We propose a method to detect
saliency in the objects using multimodal dictionary learning which has been
recently used in classification and image fusion. The multimodal dictionary
that we are learning is task driven which gives improved performance over its
counterpart (the one which is not task specific).
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2017-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06309</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Complete Framework for Virtual Data Center Embedding</dc:title>
 <dc:creator>Gilesh, M P</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Cloud computing is widely adopted by corporate as well as retail customers to
reduce the upfront cost of establishing computing infrastructure. However,
switching to the cloud based services poses a multitude of questions, both for
customers and for data center owners. In this work, we propose an algorithm for
optimal placement of multiple virtual data centers on a physical data center.
Our algorithm has two modes of operation - an online mode and a batch mode.
Coordinated batch and online embedding algorithms are used to maximize resource
usage while fulfilling the QoS demands. Experimental evaluation of our
algorithms show that acceptance rate is high - implying higher profit to
infrastructure provider. Additionaly, we try to keep a check on the number of
VM migrations, which can increase operational cost and thus lead to service
level agreement violations.
</dc:description>
 <dc:description>Comment: Technical Report, NIT Calicut</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06310</identifier>
 <datestamp>2017-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local minima in training of neural networks</dc:title>
 <dc:creator>Swirszcz, Grzegorz</dc:creator>
 <dc:creator>Czarnecki, Wojciech Marian</dc:creator>
 <dc:creator>Pascanu, Razvan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  There has been a lot of recent interest in trying to characterize the error
surface of deep models. This stems from a long standing question. Given that
deep networks are highly nonlinear systems optimized by local gradient methods,
why do they not seem to be affected by bad local minima? It is widely believed
that training of deep models using gradient methods works so well because the
error surface either has no local minima, or if they exist they need to be
close in value to the global minimum. It is known that such results hold under
very strong assumptions which are not satisfied by real models. In this paper
we present examples showing that for such theorem to be true additional
assumptions on the data, initialization schemes and/or the model classes have
to be made. We look at the particular case of finite size datasets. We
demonstrate that in this scenario one can construct counter-examples (datasets
or initialization schemes) when the network does become susceptible to bad
local minima over the weight space.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2017-02-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06314</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Determining the Veracity of Rumours on Twitter</dc:title>
 <dc:creator>Giasemidis, Georgios</dc:creator>
 <dc:creator>Singleton, Colin</dc:creator>
 <dc:creator>Agrafiotis, Ioannis</dc:creator>
 <dc:creator>Nurse, Jason R. C.</dc:creator>
 <dc:creator>Pilgrim, Alan</dc:creator>
 <dc:creator>Willis, Chris</dc:creator>
 <dc:creator>Greetham, Danica Vukadinovic</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  While social networks can provide an ideal platform for up-to-date
information from individuals across the world, it has also proved to be a place
where rumours fester and accidental or deliberate misinformation often emerges.
In this article, we aim to support the task of making sense from social media
data, and specifically, seek to build an autonomous message-classifier that
filters relevant and trustworthy information from Twitter. For our work, we
collected about 100 million public tweets, including users' past tweets, from
which we identified 72 rumours (41 true, 31 false). We considered over 80
trustworthiness measures including the authors' profile and past behaviour, the
social network connections (graphs), and the content of tweets themselves. We
ran modern machine-learning classifiers over those measures to produce
trustworthiness scores at various time windows from the outbreak of the rumour.
Such time-windows were key as they allowed useful insight into the progression
of the rumours. From our findings, we identified that our model was
significantly more accurate than similar studies in the literature. We also
identified critical attributes of the data that give rise to the
trustworthiness scores assigned. Finally we developed a software demonstration
that provides a visual user interface to allow the user to examine the
analysis.
</dc:description>
 <dc:description>Comment: 21 pages, 6 figures, 2 tables</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06314</dc:identifier>
 <dc:identifier>SocInfo 2016, Part I, LNCS 10046, pp. 185-205, 2016</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-47880-7_12</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06320</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracking Words in Chinese Poetry of Tang and Song Dynasties with the
  China Biographical Database</dc:title>
 <dc:creator>Liu, Chao-Lin</dc:creator>
 <dc:creator>Luo, Kuo-Feng</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Large-scale comparisons between the poetry of Tang and Song dynasties shed
light on how words, collocations, and expressions were used and shared among
the poets. That some words were used only in the Tang poetry and some only in
the Song poetry could lead to interesting research in linguistics. That the
most frequent colors are different in the Tang and Song poetry provides a trace
of the changing social circumstances in the dynasties. Results of the current
work link to research topics of lexicography, semantics, and social
transitions. We discuss our findings and present our algorithms for efficient
comparisons among the poems, which are crucial for completing billion times of
comparisons within acceptable time.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures, Workshop on Language Technology Resources and
  Tools for Digital Humanities (LT4DH), 26th International Conference on
  Computational Linguistics (COLING)</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06320</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06321</identifier>
 <datestamp>2017-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning the Number of Neurons in Deep Networks</dc:title>
 <dc:creator>Alvarez, Jose M</dc:creator>
 <dc:creator>Salzmann, Mathieu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Nowadays, the number of layers and of neurons in each layer of a deep network
are typically set manually. While very deep and wide networks have proven
effective in general, they come at a high memory and computation cost, thus
making them impractical for constrained platforms. These networks, however, are
known to have many redundant parameters, and could thus, in principle, be
replaced by more compact architectures. In this paper, we introduce an approach
to automatically determining the number of neurons in each layer of a deep
network during learning. To this end, we propose to make use of a group
sparsity regularizer on the parameters of the network, where each group is
defined to act on a single neuron. Starting from an overcomplete network, we
show that our approach can reduce the number of parameters by up to 80\% while
retaining or even improving the network accuracy.
</dc:description>
 <dc:description>Comment: NIPS 2016</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2017-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06322</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spotting Rumors via Novelty Detection</dc:title>
 <dc:creator>Qin, Yumeng</dc:creator>
 <dc:creator>Wurzer, Dominik</dc:creator>
 <dc:creator>Lavrenko, Victor</dc:creator>
 <dc:creator>Tang, Cunchen</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Rumour detection is hard because the most accurate systems operate
retrospectively, only recognizing rumours once they have collected repeated
signals. By then the rumours might have already spread and caused harm. We
introduce a new category of features based on novelty, tailored to detect
rumours early on. To compensate for the absence of repeated signals, we make
use of news wire as an additional data source. Unconfirmed (novel) information
with respect to the news articles is considered as an indication of rumours.
Additionally we introduce pseudo feedback, which assumes that documents that
are similar to previous rumours, are more likely to also be a rumour.
Comparison with other real-time approaches shows that novelty based features in
conjunction with pseudo feedback perform significantly better, when detecting
rumours instantly after their publication.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06329</identifier>
 <datestamp>2017-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Threshold phenomena for interference with randomly placed sensors</dc:title>
 <dc:creator>Kapelko, Rafa&#x142;</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates the problem of efficient displacement of random
sensors where good communication within the network is provided, there is no
interference between sensors and the movement cost is minimized in expectation.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2017-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06334</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Methods for Collective Communication Optimization and Tuning</dc:title>
 <dc:creator>Wickramasinghe, Udayanga</dc:creator>
 <dc:creator>Lumsdaine, Andrew</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  New developments in HPC technology in terms of increasing computing power on
multi/many core processors, high-bandwidth memory/IO subsystems and
communication interconnects, pose a direct impact on software and runtime
system development. These advancements have become useful in producing
high-performance collective communication interfaces that integrate efficiently
on a wide variety of platforms and environments. However, number of
optimization options that shows up with each new technology or software
framework has resulted in a \emph{combinatorial explosion} in feature space for
tuning collective parameters such that finding the optimal set has become a
nearly impossible task. Applicability of algorithmic choices available for
optimizing collective communication depends largely on the scalability
requirement for a particular usecase. This problem can be further exasperated
by any requirement to run collective problems at very large scales such as in
the case of exascale computing, at which impractical tuning by brute force may
require many months of resources. Therefore application of statistical, data
mining and artificial Intelligence or more general hybrid learning models seems
essential in many collectives parameter optimization problems. We hope to
explore current and the cutting edge of collective communication optimization
and tuning methods and culminate with possible future directions towards this
problem.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06334</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06342</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantized neural network design under weight capacity constraint</dc:title>
 <dc:creator>Shin, Sungho</dc:creator>
 <dc:creator>Hwang, Kyuyeon</dc:creator>
 <dc:creator>Sung, Wonyong</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The complexity of deep neural network algorithms for hardware implementation
can be lowered either by scaling the number of units or reducing the
word-length of weights. Both approaches, however, can accompany the performance
degradation although many types of research are conducted to relieve this
problem. Thus, it is an important question which one, between the network size
scaling and the weight quantization, is more effective for hardware
optimization. For this study, the performances of fully-connected deep neural
networks (FCDNNs) and convolutional neural networks (CNNs) are evaluated while
changing the network complexity and the word-length of weights. Based on these
experiments, we present the effective compression ratio (ECR) to guide the
trade-off between the network size and the precision of weights when the
hardware resource is limited.
</dc:description>
 <dc:description>Comment: This paper is accepted at NIPS 2016 workshop on Efficient Methods for
  Deep Neural Networks (EMDNN). arXiv admin note: text overlap with
  arXiv:1511.06488</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06343</identifier>
 <datestamp>2017-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Slow links, fast links, and the cost of gossip</dc:title>
 <dc:creator>Gilbert, Seth</dc:creator>
 <dc:creator>Robinson, Peter</dc:creator>
 <dc:creator>Sourav, Suman</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Consider the classical problem of information dissemination: one (or more)
nodes in a network have some information that they want to distribute to the
remainder of the network. In this paper, we study the cost of information
dissemination in networks where edges have latencies, i.e., sending a message
from one node to another takes some amount of time. We first generalize the
idea of conductance to weighted graphs by defining $\phi_*$ to be the &quot;critical
conductance&quot; and $\ell_*$ to be the &quot;critical latency&quot;. % One goal of this
paper is to argue that $\phi_*$ % characterizes the connectivity of a weighted
graph with latencies in much the same way that conductance characterizes the
connectivity of unweighted graphs. %
  We give near tight lower and upper bounds on the problem of information
dissemination, up to polylogarithmic factors. Specifically, we show that in a
graph with (weighted) diameter $D$ (with latencies as weights) and maximum
degree $\Delta$, any information dissemination algorithm requires at least
$\Omega(\min(D+\Delta, \ell_*/\phi_*))$ time % in the worst case. We show
several variants of the lower bound (e.g., for graphs with small diameter,
graphs with small max-degree, etc.) by reduction to a simple combinatorial
game.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2017-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06345</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Deep Residual Learning for Image Restoration: Persistent
  Homology-Guided Manifold Simplification</dc:title>
 <dc:creator>Bae, Woong</dc:creator>
 <dc:creator>Yoo, Jaejun</dc:creator>
 <dc:creator>Ye, Jong Chul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The latest deep learning approaches perform better than the state-of-the-art
signal processing approaches in various image restoration tasks. However, if an
image contains many patterns and structures, the performance of these CNNs is
still inferior. To address this issue, here we propose a novel feature space
deep residual learning algorithm that outperforms the existing residual
learning. The main idea is originated from the observation that the performance
of a learning algorithm can be improved if the input and/or label manifolds can
be made topologically simpler by an analytic mapping to a feature space. Our
extensive numerical studies using denoising experiments and NTIRE single-image
super-resolution (SISR) competition demonstrate that the proposed feature space
residual learning outperforms the existing state-of-the-art approaches.
Moreover, our algorithm was ranked third in NTIRE competition with 5-10 times
faster computational time compared to the top ranked teams. The source code is
available on page : https://github.com/iorism/CNN.git
</dc:description>
 <dc:description>Comment: Accepted at CVPRW 2017 source code :
  https://github.com/iorism/CNN.git</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2017-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06355</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Invertible Conditional GANs for image editing</dc:title>
 <dc:creator>Perarnau, Guim</dc:creator>
 <dc:creator>van de Weijer, Joost</dc:creator>
 <dc:creator>Raducanu, Bogdan</dc:creator>
 <dc:creator>&#xc1;lvarez, Jose M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Generative Adversarial Networks (GANs) have recently demonstrated to
successfully approximate complex data distributions. A relevant extension of
this model is conditional GANs (cGANs), where the introduction of external
information allows to determine specific representations of the generated
images. In this work, we evaluate encoders to inverse the mapping of a cGAN,
i.e., mapping a real image into a latent space and a conditional
representation. This allows, for example, to reconstruct and modify real images
of faces conditioning on arbitrary attributes. Additionally, we evaluate the
design of cGANs. The combination of an encoder with a cGAN, which we call
Invertible cGAN (IcGAN), enables to re-generate real images with deterministic
complex modifications.
</dc:description>
 <dc:description>Comment: Accepted paper at NIPS 2016 Workshop on Adversarial Training</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06357</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decomposition of bent generalized Boolean functions</dc:title>
 <dc:creator>Sok, Lin</dc:creator>
 <dc:creator>Shi, MinJia</dc:creator>
 <dc:creator>Sol&#xe9;, Patrick</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A one to one correspondence between regular generalized bent functions from
$\F_2^n$ to $\Z_{2^m},$ and $m-$tuples of Boolean bent functions is
established. This correspondence maps self-dual (resp. anti-self-dual)
generalized bent functions to $m-$tuples of self-dual (resp. anti self-dual)
Boolean bent functions. An application to the classification of regular
generalized bent functions under the extended affine group is given.
</dc:description>
 <dc:description>Comment: 3 pages, submitted to IEEE Communication Letters</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06362</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ordinal Constrained Binary Code Learning for Nearest Neighbor Search</dc:title>
 <dc:creator>Liu, Hong</dc:creator>
 <dc:creator>Ji, Rongrong</dc:creator>
 <dc:creator>Wu, Yongjian</dc:creator>
 <dc:creator>Huang, Feiyue</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4.7, H.3.3</dc:subject>
 <dc:description>  Recent years have witnessed extensive attention in binary code learning,
a.k.a. hashing, for nearest neighbor search problems. It has been seen that
high-dimensional data points can be quantized into binary codes to give an
efficient similarity approximation via Hamming distance. Among existing
schemes, ranking-based hashing is recent promising that targets at preserving
ordinal relations of ranking in the Hamming space to minimize retrieval loss.
However, the size of the ranking tuples, which shows the ordinal relations, is
quadratic or cubic to the size of training samples. By given a large-scale
training data set, it is very expensive to embed such ranking tuples in binary
code learning. Besides, it remains a dificulty to build ranking tuples
efficiently for most ranking-preserving hashing, which are deployed over an
ordinal graph-based setting. To handle these problems, we propose a novel
ranking-preserving hashing method, dubbed Ordinal Constraint Hashing (OCH),
which efficiently learns the optimal hashing functions with a graph-based
approximation to embed the ordinal relations. The core idea is to reduce the
size of ordinal graph with ordinal constraint projection, which preserves the
ordinal relations through a small data set (such as clusters or random
samples). In particular, to learn such hash functions effectively, we further
relax the discrete constraints and design a specific stochastic gradient decent
algorithm for optimization. Experimental results on three large-scale visual
search benchmark datasets, i.e. LabelMe, Tiny100K and GIST1M, show that the
proposed OCH method can achieve superior performance over the state-of-the-arts
approaches.
</dc:description>
 <dc:description>Comment: Accepted to AAAI 2017</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06362</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06365</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Case for Malleable Thread-Level Linear Algebra Libraries: The LU
  Factorization with Partial Pivoting</dc:title>
 <dc:creator>Catal&#xe1;n, Sandra</dc:creator>
 <dc:creator>Herrero, Jos&#xe9; R.</dc:creator>
 <dc:creator>Quintana-Ort&#xed;, Enrique S.</dc:creator>
 <dc:creator>Rodr&#xed;guez-S&#xe1;nchez, Rafael</dc:creator>
 <dc:creator>van de Geijn, Robert</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  We propose two novel techniques for overcoming load-imbalance encountered
when implementing so-called look-ahead mechanisms in relevant dense matrix
factorizations for the solution of linear systems. Both techniques target the
scenario where two thread teams are created/activated during the factorization,
with each team in charge of performing an independent task/branch of execution.
The first technique promotes worker sharing (WS) between the two tasks,
allowing the threads of the task that completes first to be reallocated for use
by the costlier task. The second technique allows a fast task to alert the
slower task of completion, enforcing the early termination (ET) of the second
task, and a smooth transition of the factorization procedure into the next
iteration.
  The two mechanisms are instantiated via a new malleable thread-level
implementation of the Basic Linear Algebra Subprograms (BLAS), and their
benefits are illustrated via an implementation of the LU factorization with
partial pivoting enhanced with look-ahead. Concretely, our experimental results
on a six core Intel-Xeon processor show the benefits of combining WS+ET,
reporting competitive performance in comparison with a task-parallel
runtime-based solution.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06366</identifier>
 <datestamp>2017-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grasp Learning by Sampling from Demonstration</dc:title>
 <dc:creator>Zech, Philipp</dc:creator>
 <dc:creator>Piater, Justus</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Robotic grasping traditionally relies on object features or shape information
for learning new or applying already learned grasps. We argue however that such
a strong reliance on object geometric information renders grasping and grasp
learning a difficult task in the event of cluttered environments with high
uncertainty where reasonable object models are not available. This being so, in
this paper we thus investigate the application of model-free stochastic
optimization for grasp learning. For this, our proposed learning method
requires just a handful of user-demonstrated grasps and an initial prior by a
rough sketch of an object's grasp affordance density, yet no object geometric
knowledge except for its pose. Our experiments show promising applicability of
our proposed learning method.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, 2 tables, technical report. arXiv admin note:
  substantial text overlap with arXiv:1611.06367</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06367</identifier>
 <datestamp>2017-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active and Transfer Learning of Grasps by Sampling from Demonstration</dc:title>
 <dc:creator>Zech, Philipp</dc:creator>
 <dc:creator>Piater, Justus</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We guess humans start acquiring grasping skills as early as at the infant
stage by virtue of two key processes. First, infants attempt to learn grasps
for known objects by imitating humans. Secondly, knowledge acquired during this
process is reused in learning to grasp novel objects. We argue that these
processes of active and transfer learning boil down to a random search of
grasps on an object, suitably biased by prior experience. In this paper we
introduce active learning of grasps for known objects as well as transfer
learning of grasps for novel objects grounded on kernel adaptive, mode-hopping
Markov Chain Monte Carlo. Our experiments show promising applicability of our
proposed learning methods.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, 3 tables, technical report. arXiv admin note:
  substantial text overlap with arXiv:1611.06366</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06368</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active and Transfer Learning of Grasps by Kernel Adaptive MCMC</dc:title>
 <dc:creator>Zech, Philipp</dc:creator>
 <dc:creator>Xiong, Hanchen</dc:creator>
 <dc:creator>Piater, Justus</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Human ability of both versatile grasping of given objects and grasping of
novel (as of yet unseen) objects is truly remarkable. This probably arises from
the experience infants gather by actively playing around with diverse objects.
Moreover, knowledge acquired during this process is reused during learning of
how to grasp novel objects. We conjecture that this combined process of active
and transfer learning boils down to a random search around an object, suitably
biased by prior experience, to identify promising grasps. In this paper we
present an active learning method for learning of grasps for given objects, and
a transfer learning method for learning of grasps for novel objects. Our
learning methods apply a kernel adaptive Metropolis-Hastings sampler that
learns an approximation of the grasps' probability density of an object while
drawing grasp proposals from it. The sampler employs simulated annealing to
search for globally-optimal grasps. Our empirical results show promising
applicability of our proposed learning schemes.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, 3 tables, technical report</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06371</identifier>
 <datestamp>2017-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On MDS Negacyclic LCD Codes</dc:title>
 <dc:creator>Sar&#x131;, Mustafa</dc:creator>
 <dc:creator>Koroglu, Mehmet E.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B15, 94B05</dc:subject>
 <dc:description>  This paper is devoted to the study of linear codes with complementary-duals
(LCD) arising from negacyclic codes over finite fields $\mathbb{F}_{q},$ where
$q$ is an odd prime power. We obtain two classes of MDS negacyclic LCD codes of
length $n|\frac{{q-1}}{2}$, $n|\frac{{q+1}}{2}$ and a class of negacyclic LCD
codes of length $n=q-1$. Also, we obtain four classes of $q^{2}-$ary Hermitian
MDS negacyclic LCD codes of length $n|\left( q-1\right)$ and a class of
Hermitian negacyclic LCD codes of length $n=q^{2}+1.$ For both Euclidean and
Hermitian cases the dimensions of these codes are determined and for some
classes the minimum distances are settled. For the other cases, by studying $q$
and $q^{2}-$cyclotomic classes we give lower bounds on the minimum distance.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2017-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06371</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06385</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Embeddings of $\ell_1^k$ from Locally Decodable Codes</dc:title>
 <dc:creator>Bri&#xeb;t, Jop</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We show that any $q$-query locally decodable code (LDC) gives a copy of
$\ell_1^k$ with small distortion in the Banach space of $q$-linear forms on
$\ell_{p_1}^N\times\cdots\times\ell_{p_q}^N$, provided $1/p_1 + \cdots + 1/p_q
\leq 1$ and where $k$, $N$, and the distortion are simple functions of the code
parameters. We exhibit the copy of $\ell_1^k$ by constructing a basis for it
directly from &quot;smooth&quot; LDC decoders. Based on this, we give alternative proofs
for known lower bounds on the length of 2-query LDCs. Using similar techniques,
we reprove known lower bounds for larger $q$. We also discuss the relation with
an alternative proof, due to Pisier, of a result of Naor, Regev, and the author
on cotype properties of projective tensor products of $\ell_p$ spaces.
</dc:description>
 <dc:description>Comment: Appeared earlier on ECCC (http://eccc.hpi-web.de/report/2015/086/).
  This version has a slightly shorter abstract and slightly edited
  introduction. Removed left-over notes</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06389</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Explicit Definition of Quantifiers via Hilbert's epsilon is
  Confluent and Terminating</dc:title>
 <dc:creator>Wirth, Claus-Peter</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  We investigate the elimination of quantifiers in first-order formulas via
Hilbert's epsilon-operator (or -binder), following Bernays' explicit
definitions of the existential and the universal quantifier symbol by means of
epsilon-terms. This elimination has its first explicit occurrence in the proof
of the first epsilon-theorem in Hilbert-Bernays in 1939. We think that there is
a lacuna in this proof w.r.t. this elimination, related to the erroneous
assumption that explicit definitions always terminate. Surprisingly, to the
best of our knowledge, nobody ever proved confluence or termination for this
elimination procedure. Even myths on non-confluence and the openness of the
termination problem are circulating. We show confluence and termination of this
elimination procedure by means of a direct, straightforward, and easily
verifiable proof, based on a new theorem on how to obtain termination from weak
normalization.
</dc:description>
 <dc:description>Comment: ii+20pp</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06389</dc:identifier>
 <dc:identifier>IfCoLog Journal of Logics and their Applications, Vol. 4, number
  2, March 2017, pp. 527--547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06391</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Residual Learning for Compressed Sensing CT Reconstruction via
  Persistent Homology Analysis</dc:title>
 <dc:creator>Han, Yo Seob</dc:creator>
 <dc:creator>Yoo, Jaejun</dc:creator>
 <dc:creator>Ye, Jong Chul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, compressed sensing (CS) computed tomography (CT) using sparse
projection views has been extensively investigated to reduce the potential risk
of radiation to patient. However, due to the insufficient number of projection
views, an analytic reconstruction approach results in severe streaking
artifacts and CS-based iterative approach is computationally very expensive. To
address this issue, here we propose a novel deep residual learning approach for
sparse view CT reconstruction. Specifically, based on a novel persistent
homology analysis showing that the manifold of streaking artifacts is
topologically simpler than original ones, a deep residual learning architecture
that estimates the streaking artifacts is developed. Once a streaking artifact
image is estimated, an artifact-free image can be obtained by subtracting the
streaking artifacts from the input image. Using extensive experiments with real
patient data set, we confirm that the proposed residual learning provides
significantly better image reconstruction performance with several orders of
magnitude faster computational speed.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06395</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic tracking: Single-target tracking with inter-supervised
  convolutional networks</dc:title>
 <dc:creator>Xiao, Jingjing</dc:creator>
 <dc:creator>Lan, Qiang</dc:creator>
 <dc:creator>Qiao, Linbo</dc:creator>
 <dc:creator>Leonardis, Ales</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This article presents a semantic tracker which simultaneously tracks a single
target and recognises its category. In general, it is hard to design a tracking
model suitable for all object categories, e.g., a rigid tracker for a car is
not suitable for a deformable gymnast. Category-based trackers usually achieve
superior tracking performance for the objects of that specific category, but
have difficulties being generalised. Therefore, we propose a novel unified
robust tracking framework which explicitly encodes both generic features and
category-based features. The tracker consists of a shared convolutional network
(NetS), which feeds into two parallel networks, NetC for classification and
NetT for tracking. NetS is pre-trained on ImageNet to serve as a generic
feature extractor across the different object categories for NetC and NetT.
NetC utilises those features within fully connected layers to classify the
object category. NetT has multiple branches, corresponding to multiple
categories, to distinguish the tracked object from the background. Since each
branch in NetT is trained by the videos of a specific category or groups of
similar categories, NetT encodes category-based features for tracking. During
online tracking, NetC and NetT jointly determine the target regions with the
right category and foreground labels for target estimation. To improve the
robustness and precision, NetC and NetT inter-supervise each other and trigger
network adaptation when their outputs are ambiguous for the same image regions
(i.e., when the category label contradicts the foreground/background
classification). We have compared the performance of our tracker to other
state-of-the-art trackers on a large-scale tracking benchmark (100
sequences)---the obtained results demonstrate the effectiveness of our proposed
tracker as it outperformed other 38 state-of-the-art tracking algorithms.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06395</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06396</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Studying the influence of inclusion characteristics on the
  characteristic length involved in quasi-brittle materials using the lattice
  element method</dc:title>
 <dc:creator>Bui, Huu Phuoc</dc:creator>
 <dc:creator>Richefeu, Vincent</dc:creator>
 <dc:creator>Dufour, Fr&#xe9;d&#xe9;ric</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Unlike nonlocal models, there is no need to introduce an internal length in
the constitutive law for lattice model at the mesoscopic scale. Actually, the
internal length is not explicitly introduced but rather governed by the
mesostructure characteristics themselves. The influence of the mesostructure on
the width of the fracture process zone which is assumed to be correlated to the
characteristic length of the homogenized quasi-brittle material is studied. The
influence of the ligament size (a structural parameter) is also investigated.
This analysis provides recommendations/warnings when extracting an internal
length required for nonlocal damage models from the material mesostructure
</dc:description>
 <dc:description>Comment: 16 pages, 21 figures</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06396</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06403</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Outdoor Illumination Estimation</dc:title>
 <dc:creator>Hold-Geoffroy, Yannick</dc:creator>
 <dc:creator>Sunkavalli, Kalyan</dc:creator>
 <dc:creator>Hadap, Sunil</dc:creator>
 <dc:creator>Gambaretto, Emiliano</dc:creator>
 <dc:creator>Lalonde, Jean-Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a CNN-based technique to estimate high-dynamic range outdoor
illumination from a single low dynamic range image. To train the CNN, we
leverage a large dataset of outdoor panoramas. We fit a low-dimensional
physically-based outdoor illumination model to the skies in these panoramas
giving us a compact set of parameters (including sun position, atmospheric
conditions, and camera parameters). We extract limited field-of-view images
from the panoramas, and train a CNN with this large set of input image--output
lighting parameter pairs. Given a test image, this network can be used to infer
illumination parameters that can, in turn, be used to reconstruct an outdoor
illumination environment map. We demonstrate that our approach allows the
recovery of plausible illumination conditions and enables photorealistic
virtual object insertion from a single image. An extensive evaluation on both
the panorama dataset and captured HDR environment maps shows that our technique
significantly outperforms previous solutions to this problem.
</dc:description>
 <dc:description>Comment: CVPR'17 preprint, 8 pages + 2 pages of citations, 12 figures</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06405</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The second generalized Hamming weight of some evaluation codes arising
  from a projective torus</dc:title>
 <dc:creator>Gonzalez-Sarabia, Manuel</dc:creator>
 <dc:creator>Camps, Eduardo</dc:creator>
 <dc:creator>Sarmiento, Eliseo</dc:creator>
 <dc:creator>Villarreal, Rafael H.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Commutative Algebra</dc:subject>
 <dc:subject>94B60, 13P25</dc:subject>
 <dc:description>  In this paper we find the second generalized Hamming weight of some
evaluation codes arising from a projective torus, and it allows to compute the
second generalized Hamming weight of the codes parameterized by the edges of
any complete bipartite graph. Also, at the beginning, we obtain some results
about the generalized Hamming weights of some evaluation codes arising from a
complete intersection when the minimum distance is known and they are
non--degenerate codes. Finally we give an example where we use these results to
determine the complete weight hierarchy of some codes.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06413</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formalizing Multi-Agent Systems Using Action Descriptions in Single
  Agent Perspective</dc:title>
 <dc:creator>Sabuncu, Orkunt</dc:creator>
 <dc:creator>Schaub, Torsten</dc:creator>
 <dc:creator>Schulz-Hanke, Christian</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Logic-based representations of multi-agent systems have been extensively
studied. In this work, we focus on the action language BC to formalize global
views of MAS domains. Methodologically, we start representing the behaviour of
each agent by an action description from a single agent perspective. Then, it
goes through two stages that guide the modeler in composing the global view by
first designating multi-agent aspects of the domain via potential conflicts and
later resolving these conflicts according to the expected behaviour of the
overall system. Considering that representing single agent descriptions is
relatively simpler than representing multi-agent description directly, the
formalization developed here is valuable from a knowledge representation
perspective.
</dc:description>
 <dc:description>Comment: Workshop on Trends and Applications of Answer Set Programming,
  TAASP'16</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06417</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discover Aggregates Exceptions over Hidden Web Databases</dc:title>
 <dc:creator>Suhaim, Saad Bin</dc:creator>
 <dc:creator>Liu, Weimo</dc:creator>
 <dc:creator>Zhang, Nan</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Nowadays, many web databases &quot;hidden&quot; behind their restrictive search
interfaces (e.g., Amazon, eBay) contain rich and valuable information that is
of significant interests to various third parties. Recent studies have
demonstrated the possibility of estimating/tracking certain aggregate queries
over dynamic hidden web databases. Nonetheless, tracking all possible aggregate
query answers to report interesting findings (i.e., exceptions), while still
adhering to the stringent query-count limitations enforced by many hidden web
databases providers, is very challenging. In this paper, we develop a novel
technique for tracking and discovering exceptions (in terms of sudden changes
of aggregates) over dynamic hidden web databases. Extensive real-world
experiments demonstrate the superiority of our proposed algorithms over
baseline solutions.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06423</identifier>
 <datestamp>2017-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incorporating Pass-Phrase Dependent Background Models for Text-Dependent
  Speaker Verification</dc:title>
 <dc:creator>Sarkar, A. K.</dc:creator>
 <dc:creator>Tan, Zheng-Hua</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we propose pass-phrase dependent background models (PBMs) for
text-dependent (TD) speaker verification (SV) to integrate the pass-phrase
identification process into the conventional TD-SV system, where a PBM is
derived from a text-independent background model through adaptation using the
utterances of a particular pass-phrase. During training, pass-phrase specific
target speaker models are derived from the particular PBM using the training
data for the respective target model. While testing, the best PBM is first
selected for the test utterance in the maximum likelihood (ML) sense and the
selected PBM is then used for the log likelihood ratio (LLR) calculation with
respect to the claimant model. The proposed method incorporates the pass-phrase
identification step in the LLR calculation, which is not considered in
conventional standalone TD-SV systems. The performance of the proposed method
is compared to conventional text-independent background model based TD-SV
systems using either Gaussian mixture model (GMM)-universal background model
(UBM) or Hidden Markov model (HMM)-UBM or i-vector paradigms. In addition, we
consider two approaches to build PBMs: speaker-independent and
speaker-dependent. We show that the proposed method significantly reduces the
error rates of text-dependent speaker verification for the non-target types:
target-wrong and imposter-wrong while it maintains comparable TD-SV performance
when imposters speak a correct utterance with respect to the conventional
system. Experiments are conducted on the RedDots challenge and the RSR2015
databases that consist of short utterances.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2017-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06426</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conservative Contextual Linear Bandits</dc:title>
 <dc:creator>Kazerouni, Abbas</dc:creator>
 <dc:creator>Ghavamzadeh, Mohammad</dc:creator>
 <dc:creator>Abbasi-Yadkori, Yasin</dc:creator>
 <dc:creator>Van Roy, Benjamin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Safety is a desirable property that can immensely increase the applicability
of learning algorithms in real-world decision-making problems. It is much
easier for a company to deploy an algorithm that is safe, i.e., guaranteed to
perform at least as well as a baseline. In this paper, we study the issue of
safety in contextual linear bandits that have application in many different
fields including personalized ad recommendation in online marketing. We
formulate a notion of safety for this class of algorithms. We develop a safe
contextual linear bandit algorithm, called conservative linear UCB (CLUCB),
that simultaneously minimizes its regret and satisfies the safety constraint,
i.e., maintains its performance above a fixed percentage of the performance of
a baseline strategy, uniformly over time. We prove an upper-bound on the regret
of CLUCB and show that it can be decomposed into two terms: 1) an upper-bound
for the regret of the standard linear UCB algorithm that grows with the time
horizon and 2) a constant (does not grow with the time horizon) term that
accounts for the loss of being conservative in order to satisfy the safety
constraint. We empirically show that our algorithm is safe and validate our
theoretical analysis.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06426</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06427</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rescaling Algorithms for Linear Conic Feasibility</dc:title>
 <dc:creator>Dadush, Daniel</dc:creator>
 <dc:creator>V&#xe9;gh, L&#xe1;szl&#xf3; A.</dc:creator>
 <dc:creator>Zambelli, Giacomo</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We propose simple polynomial-time algorithms for two linear conic feasibility
problems. For a matrix $A\in \mathbb{R}^{m\times n}$, the kernel problem
requires a positive vector in the kernel of $A$, and the image problem requires
a positive vector in the image of $A^\top$. Both algorithms iterate between
simple first order steps and rescaling steps. These rescalings improve natural
geometric potentials. If Goffin's condition measure $\rho_A$ is negative, then
the kernel problem is feasible and the worst-case complexity of the kernel
algorithm is $O\left((m^3n+mn^2)\log{|\rho_A|^{-1}}\right)$; if $\rho_A&gt;0$,
then the image problem is feasible and the image algorithm runs in time
$O\left(m^2n^2\log{\rho_A^{-1}}\right)$. We also extend the image algorithm to
the oracle setting.
  We address the degenerate case $\rho_A=0$ by extending our algorithms to find
maximum support nonnegative vectors in the kernel of $A$ and in the image of
$A^\top$. In this case the running time bounds are expressed in the bit-size
model of computation: for an input matrix $A$ with integer entries and total
encoding length $L$, the maximum support kernel algorithm runs in time
$O\left((m^3n+mn^2)L\right)$, while the maximum support image algorithm runs in
time $O\left(m^2n^2L\right)$. The standard linear programming feasibility
problem can be easily reduced to either maximum support problems, yielding
polynomial-time algorithms for Linear Programming
</dc:description>
 <dc:description>Comment: major revision</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06427</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06430</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-Supervised Learning with Context-Conditional Generative Adversarial
  Networks</dc:title>
 <dc:creator>Denton, Emily</dc:creator>
 <dc:creator>Gross, Sam</dc:creator>
 <dc:creator>Fergus, Rob</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce a simple semi-supervised learning approach for images based on
in-painting using an adversarial loss. Images with random patches removed are
presented to a generator whose task is to fill in the hole, based on the
surrounding pixels. The in-painted images are then presented to a discriminator
network that judges if they are real (unaltered training images) or not. This
task acts as a regularizer for standard supervised training of the
discriminator. Using our approach we are able to directly train large VGG-style
networks in a semi-supervised fashion. We evaluate on STL-10 and PASCAL
datasets, where our approach obtains performance comparable or superior to
existing methods.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06430</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06436</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometrically exact beam elements and smooth contact schemes for the
  modeling of fiber-based materials and structures</dc:title>
 <dc:creator>Meier, Christoph</dc:creator>
 <dc:creator>Grill, Maximilian J.</dc:creator>
 <dc:creator>Wall, Wolfgang A.</dc:creator>
 <dc:creator>Popp, Alexander</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  Recently, the authors have proposed a novel all-angle beam contact (ABC)
formulation that combines the advantages of existing point and line contact
models in a variationally consistent manner. However, the ABC formulation has
so far only been applied in combination with a special torsion-free beam model,
which yields a very simple and efficient finite element formulation, but which
is restricted to initially straight beams with isotropic cross-sections. In
order to abstain from these restrictions, the current work combines the ABC
formulation with a geometrically exact Kirchhoff-Love beam element formulation
that is capable of treating even the most general cases of slender beam
problems in terms of initial geometry and external loads. While the neglect of
shear deformation that is inherent to this formulation has been shown to
provide considerable numerical advantages in the range of high beam slenderness
ratios, alternative shear-deformable beam models are required for examples with
thick beams. The current contribution additionally proposes a novel
geometrically exact beam element based on the Simo-Reissner theory. Similar to
the torsion-free and the Kirchhoff-Love beam elements, also this Simo-Reissner
element is based on a C1-continuous Hermite interpolation of the beam
centerline, which will allow for smooth contact kinematics. For this Hermitian
Simo-Reissner element, a consistent spatial convergence behavior as well as the
successful avoidance of membrane and shear locking will be demonstrated
numerically. All in all, the combination of the ABC formulation with these
different beam element variants (i.e.~the torsion-free element, the
Kirchhoff-Love element and the Simo-Reissner element) results in a very
flexible and modular simulation framework that allows to choose the optimal
element formulation for any given application in terms of accuracy, efficiency
and robustness.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06439</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Credit Card Fraud Detection Techniques: Data and Technique
  Oriented Perspective</dc:title>
 <dc:creator>SamanehSorournejad</dc:creator>
 <dc:creator>Zojaji, Zahra</dc:creator>
 <dc:creator>Atani, Reza Ebrahimi</dc:creator>
 <dc:creator>Monadjemi, Amir Hassan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Credit card plays a very important rule in today's economy. It becomes an
unavoidable part of household, business and global activities. Although using
credit cards provides enormous benefits when used carefully and
responsibly,significant credit and financial damages may be caused by
fraudulent activities. Many techniques have been proposed to confront the
growth in credit card fraud. However, all of these techniques have the same
goal of avoiding the credit card fraud; each one has its own drawbacks,
advantages and characteristics. In this paper, after investigating difficulties
of credit card fraud detection, we seek to review the state of the art in
credit card fraud detection techniques, data sets and evaluation criteria.The
advantages and disadvantages of fraud detection methods are enumerated and
compared.Furthermore, a classification of mentioned techniques into two main
fraud detection approaches, namely, misuses (supervised) and anomaly detection
(unsupervised) is presented. Again, a classification of techniques is proposed
based on capability to process the numerical and categorical data sets.
Different data sets used in literature are then described and grouped into real
and synthesized data and the effective and common attributes are extracted for
further usage.Moreover, evaluation employed criterions in literature are
collected and discussed.Consequently, open issues for credit card fraud
detection are explained as guidelines for new researchers.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06440</identifier>
 <datestamp>2017-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pruning Convolutional Neural Networks for Resource Efficient Inference</dc:title>
 <dc:creator>Molchanov, Pavlo</dc:creator>
 <dc:creator>Tyree, Stephen</dc:creator>
 <dc:creator>Karras, Tero</dc:creator>
 <dc:creator>Aila, Timo</dc:creator>
 <dc:creator>Kautz, Jan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a new formulation for pruning convolutional kernels in neural
networks to enable efficient inference. We interleave greedy criteria-based
pruning with fine-tuning by backpropagation - a computationally efficient
procedure that maintains good generalization in the pruned network. We propose
a new criterion based on Taylor expansion that approximates the change in the
cost function induced by pruning network parameters. We focus on transfer
learning, where large pretrained networks are adapted to specialized tasks. The
proposed criterion demonstrates superior performance compared to other
criteria, e.g. the norm of kernel weights or feature map activation, for
pruning large CNNs after adaptation to fine-grained classification tasks
(Birds-200 and Flowers-102) relaying only on the first order gradient
information. We also show that pruning can lead to more than 10x theoretical
(5x practical) reduction in adapted 3D-convolutional filters with a small drop
in accuracy in a recurrent gesture classifier. Finally, we show results for the
large-scale ImageNet dataset to emphasize the flexibility of our approach.
</dc:description>
 <dc:description>Comment: 17 pages, 14 figures, ICLR 2017 paper</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2017-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06440</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06443</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectrum Sharing Radar: Coexistence via Xampling</dc:title>
 <dc:creator>Cohen, Deborah</dc:creator>
 <dc:creator>Mishra, Kumar Vijay</dc:creator>
 <dc:creator>Eldar, Yonina C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents a spectrum sharing technology enabling interference-free
operation of a surveillance radar and communication transmissions over a common
spectrum. A cognitive radio receiver senses the spectrum using low sampling and
processing rates. The radar is a cognitive system that employs a Xampling-based
receiver and transmits in several narrow bands. Our main contribution is the
alliance of two previous ideas, CRo and cognitive radar (CRr), and their
adaptation to solve the spectrum sharing problem.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06448</identifier>
 <datestamp>2017-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PsyPhy: A Psychophysics Driven Evaluation Framework for Visual
  Recognition</dc:title>
 <dc:creator>RichardWebster, Brandon</dc:creator>
 <dc:creator>Anthony, Samuel E.</dc:creator>
 <dc:creator>Scheirer, Walter J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  By providing substantial amounts of data and standardized evaluation
protocols, datasets in computer vision have helped fuel advances across all
areas of visual recognition. But even in light of breakthrough results on
recent benchmarks, it is still fair to ask if our recognition algorithms are
doing as well as we think they are. The vision sciences at large make use of a
very different evaluation regime known as Visual Psychophysics to study visual
perception. Psychophysics is the quantitative examination of the relationships
between controlled stimuli and the behavioral responses they elicit in
experimental test subjects. Instead of using summary statistics to gauge
performance, psychophysics directs us to construct item-response curves made up
of individual stimulus responses to find perceptual thresholds, thus allowing
one to identify the exact point at which a subject can no longer reliably
recognize the stimulus class. In this article, we introduce a comprehensive
evaluation framework for visual recognition models that is underpinned by this
methodology. Over millions of procedurally rendered 3D scenes and 2D images, we
compare the performance of well-known convolutional neural networks. Our
results bring into question recent claims of human-like performance, and
provide a path forward for correcting newly surfaced algorithmic deficiencies.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures. Submitted for publication. For supplemental
  material see http://bjrichardwebster.com/papers/psyphy/supp</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2017-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06448</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06453</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Video Classification via Adaptive Cascading of Deep Models</dc:title>
 <dc:creator>Shen, Haichen</dc:creator>
 <dc:creator>Han, Seungyeop</dc:creator>
 <dc:creator>Philipose, Matthai</dc:creator>
 <dc:creator>Krishnamurthy, Arvind</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Recent advances have enabled &quot;oracle&quot; classifiers that can classify across
many classes and input distributions with high accuracy without retraining.
However, these classifiers are relatively heavyweight, so that applying them to
classify video is costly. We show that day-to-day video exhibits highly skewed
class distributions over the short term, and that these distributions can be
classified by much simpler models. We formulate the problem of detecting the
short-term skews online and exploiting models based on it as a new sequential
decision making problem dubbed the Online Bandit Problem, and present a new
algorithm to solve it. When applied to recognizing faces in TV shows and
movies, we realize end-to-end classification speedups of 2.4-7.8x/2.6-11.2x (on
GPU/CPU) relative to a state-of-the-art convolutional neural network, at
competitive accuracy.
</dc:description>
 <dc:description>Comment: Accepted at IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR), 2017</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2017-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06453</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06455</identifier>
 <datestamp>2016-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time Series Classification from Scratch with Deep Neural Networks: A
  Strong Baseline</dc:title>
 <dc:creator>Wang, Zhiguang</dc:creator>
 <dc:creator>Yan, Weizhong</dc:creator>
 <dc:creator>Oates, Tim</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a simple but strong baseline for time series classification from
scratch with deep neural networks. Our proposed baseline models are pure
end-to-end without any heavy preprocessing on the raw data or feature crafting.
The proposed Fully Convolutional Network (FCN) achieves premium performance to
other state-of-the-art approaches and our exploration of the very deep neural
networks with the ResNet structure is also competitive. The global average
pooling in our convolutional model enables the exploitation of the Class
Activation Map (CAM) to find out the contributing region in the raw data for
the specific labels. Our models provides a simple choice for the real world
application and a good starting point for the future research. An overall
analysis is provided to discuss the generalization capability of our models,
learned features, network structures and the classification semantics.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2016-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06455</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06458</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Class of Two-Weight and Three-Weight Linear Codes and Their Duals</dc:title>
 <dc:creator>Liu, Li</dc:creator>
 <dc:creator>Xie, Xianhong</dc:creator>
 <dc:creator>Li, Lanqiang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The objective of this paper is to construct a class of linear codes with two
nonzero weights and three nonzero weights by using the general trace functions,
which weight distributions has been determined. These linear codes contain some
optimal codes, which meets certain bound on linear codes. The dual codes are
also studied and proved to be optimal or almost optimal. These codes may have
applications in authentication codes, secret sharing schemes and strongly
regular graphs.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06459</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gendered Conversation in a Social Game-Streaming Platform</dc:title>
 <dc:creator>Nakandala, Supun</dc:creator>
 <dc:creator>Ciampaglia, Giovanni Luca</dc:creator>
 <dc:creator>Su, Norman Makoto</dc:creator>
 <dc:creator>Ahn, Yong-Yeol</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Online social media and games are increasingly replacing offline social
activities. Social media is now an indispensable mode of communication; online
gaming is not only a genuine social activity but also a popular spectator
sport. With support for anonymity and larger audiences, online interaction
shrinks social and geographical barriers. Despite such benefits, social
disparities such as gender inequality persist in online social media. In
particular, online gaming communities have been criticized for persistent
gender disparities and objectification. As gaming evolves into a social
platform, persistence of gender disparity is a pressing question. Yet, there
are few large-scale, systematic studies of gender inequality and
objectification in social gaming platforms. Here we analyze more than one
billion chat messages from Twitch, a social game-streaming platform, to study
how the gender of streamers is associated with the nature of conversation.
Using a combination of computational text analysis methods, we show that
gendered conversation and objectification is prevalent in chats. Female
streamers receive significantly more objectifying comments while male streamers
receive more game-related comments. This difference is more pronounced for
popular streamers. There also exists a large number of users who post only on
female or male streams. Employing a neural vector-space embedding (paragraph
vector) method, we analyze gendered chat messages and create prediction models
that (i) identify the gender of streamers based on messages posted in the
channel and (ii) identify the gender a viewer prefers to watch based on their
chat messages. Our findings suggest that disparities in social game-streaming
platforms is a nuanced phenomenon that involves the gender of streamers as well
as those who produce gendered and game-related conversation.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures, 5 tables</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06467</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On The Stability of Video Detection and Tracking</dc:title>
 <dc:creator>Zhang, Hong</dc:creator>
 <dc:creator>Wang, Naiyan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we study an important yet less explored aspect in video
detection and tracking -- stability. Surprisingly, there is no prior work that
tried to study it. As a result, we start our work by proposing a novel
evaluation metric for video detection which considers both stability and
accuracy. For accuracy, we extend the existing accuracy metric mean Average
Precision (mAP). For stability, we decompose it into three terms: fragment
error, center position error, scale and ratio error. Each error represents one
aspect of stability. Furthermore, we demonstrate that the stability metric has
low correlation with accuracy metric. Thus, it indeed captures a different
perspective of quality. Lastly, based on this metric, we evaluate several
existing methods for video detection and show how they affect accuracy and
stability. We believe our work can provide guidance and solid baselines for
future researches in the related areas.
</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:date>2017-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06467</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06468</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating machine-executable plans from end-user's natural-language
  instructions</dc:title>
 <dc:creator>Liu, Rui</dc:creator>
 <dc:creator>Zhang, Xiaoli</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  It is critical for advanced manufacturing machines to autonomously execute a
task by following an end-user's natural language (NL) instructions. However, NL
instructions are usually ambiguous and abstract so that the machines may
misunderstand and incorrectly execute the task. To address this NL-based
human-machine communication problem and enable the machines to appropriately
execute tasks by following the end-user's NL instructions, we developed a
Machine-Executable-Plan-Generation (exePlan) method. The exePlan method
conducts task-centered semantic analysis to extract task-related information
from ambiguous NL instructions. In addition, the method specifies machine
execution parameters to generate a machine-executable plan by interpreting
abstract NL instructions. To evaluate the exePlan method, an industrial robot
Baxter was instructed by NL to perform three types of industrial tasks {'drill
a hole', 'clean a spot', 'install a screw'}. The experiment results proved that
the exePlan method was effective in generating machine-executable plans from
the end-user's NL instructions. Such a method has the promise to endow a
machine with the ability of NL-instructed task execution.
</dc:description>
 <dc:description>Comment: 16 pages, 10 figures, article submitted to Robotics and
  Computer-Integrated Manufacturing, 2016 Aug</dc:description>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06468</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06473</identifier>
 <datestamp>2017-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LCNN: Lookup-based Convolutional Neural Network</dc:title>
 <dc:creator>Bagherinezhad, Hessam</dc:creator>
 <dc:creator>Rastegari, Mohammad</dc:creator>
 <dc:creator>Farhadi, Ali</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Porting state of the art deep learning algorithms to resource constrained
compute platforms (e.g. VR, AR, wearables) is extremely challenging. We propose
a fast, compact, and accurate model for convolutional neural networks that
enables efficient learning and inference. We introduce LCNN, a lookup-based
convolutional neural network that encodes convolutions by few lookups to a
dictionary that is trained to cover the space of weights in CNNs. Training LCNN
involves jointly learning a dictionary and a small set of linear combinations.
The size of the dictionary naturally traces a spectrum of trade-offs between
efficiency and accuracy. Our experimental results on ImageNet challenge show
that LCNN can offer 3.2x speedup while achieving 55.1% top-1 accuracy using
AlexNet architecture. Our fastest LCNN offers 37.6x speed up over AlexNet while
maintaining 44.3% top-1 accuracy. LCNN not only offers dramatic speed ups at
inference, but it also enables efficient training. In this paper, we show the
benefits of LCNN in few-shot learning and few-iteration learning, two crucial
aspects of on-device training of deep learning models.
</dc:description>
 <dc:description>Comment: CVPR 17</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06474</identifier>
 <datestamp>2017-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nazr-CNN: Fine-Grained Classification of UAV Imagery for Damage
  Assessment</dc:title>
 <dc:creator>Attari, N.</dc:creator>
 <dc:creator>Ofli, F.</dc:creator>
 <dc:creator>Awad, M.</dc:creator>
 <dc:creator>Lucas, J.</dc:creator>
 <dc:creator>Chawla, S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose Nazr-CNN1, a deep learning pipeline for object detection and
fine-grained classification in images acquired from Unmanned Aerial Vehicles
(UAVs) for damage assessment and monitoring. Nazr-CNN consists of two
components. The function of the first component is to localize objects (e.g.
houses or infrastructure) in an image by carrying out a pixel-level
classification. In the second component, a hidden layer of a Convolutional
Neural Network (CNN) is used to encode Fisher Vectors (FV) of the segments
generated from the first component in order to help discriminate between
different levels of damage. To showcase our approach we use data from UAVs that
were deployed to assess the level of damage in the aftermath of a devastating
cyclone that hit the island of Vanuatu in 2015. The collected images were
labeled by a crowdsourcing effort and the labeling categories consisted of
fine-grained levels of damage to built structures. Since our data set is
relatively small, a pre- trained network for pixel-level classification and FV
encoding was used. Nazr-CNN attains promising results both for object detection
and damage assessment suggesting that the integrated pipeline is robust in the
face of small data sets and labeling errors by annotators. While the focus of
Nazr-CNN is on assessment of UAV images in a post-disaster scenario, our
solution is general and can be applied in many diverse settings. We show one
such case of transfer learning to assess the level of damage in aerial images
collected after a typhoon in Philippines.
</dc:description>
 <dc:description>Comment: Accepted for publication in the 4th IEEE International Conference on
  Data Science and Advanced Analytics (DSAA) 2017</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06474</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06475</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dealing with Range Anxiety in Mean Estimation via Statistical Queries</dc:title>
 <dc:creator>Feldman, Vitaly</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We give algorithms for estimating the expectation of a given real-valued
function $\phi:X\to {\bf R}$ on a sample drawn randomly from some unknown
distribution $D$ over domain $X$, namely ${\bf E}_{{\bf x}\sim D}[\phi({\bf
x})]$. Our algorithms work in two well-studied models of restricted access to
data samples. The first one is the statistical query (SQ) model in which an
algorithm has access to an SQ oracle for the input distribution $D$ over $X$
instead of i.i.d. samples from $D$. Given a query function $\phi:X \to [0,1]$,
the oracle returns an estimate of ${\bf E}_{{\bf x}\sim D}[\phi({\bf x})]$
within some tolerance $\tau$. The second, is a model in which only a single bit
is communicated from each sample. In both of these models the error obtained
using a naive implementation would scale polynomially with the range of the
random variable $\phi({\bf x})$ (which might even be infinite). In contrast,
without restrictions on access to data the expected error scales with the
standard deviation of $\phi({\bf x})$. Here we give a simple algorithm whose
error scales linearly in standard deviation of $\phi({\bf x})$ and
logarithmically with an upper bound on the second moment of $\phi({\bf x})$.
  As corollaries, we obtain algorithms for high dimensional mean estimation and
stochastic convex optimization in these models that work in more general
settings than previously known solutions.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06475</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06478</identifier>
 <datestamp>2016-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visualizing Linguistic Shift</dc:title>
 <dc:creator>Mahmood, Salman</dc:creator>
 <dc:creator>Al-Rfou, Rami</dc:creator>
 <dc:creator>Mueller, Klaus</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Neural network based models are a very powerful tool for creating word
embeddings, the objective of these models is to group similar words together.
These embeddings have been used as features to improve results in various
applications such as document classification, named entity recognition, etc.
Neural language models are able to learn word representations which have been
used to capture semantic shifts across time and geography. The objective of
this paper is to first identify and then visualize how words change meaning in
different text corpus. We will train a neural language model on texts from a
diverse set of disciplines philosophy, religion, fiction etc. Each text will
alter the embeddings of the words to represent the meaning of the word inside
that text. We will present a computational technique to detect words that
exhibit significant linguistic shift in meaning and usage. We then use enhanced
scatterplots and storyline visualization to visualize the linguistic shift.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06485</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time-Varying Control Scheduling in Complex Dynamical Networks</dc:title>
 <dc:creator>Nozari, Erfan</dc:creator>
 <dc:creator>Pasqualetti, Fabio</dc:creator>
 <dc:creator>Cortes, Jorge</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  Despite extensive research and remarkable advancements in the control of
complex networks, time-invariant control schedules (TICS) still dominate the
literature. This is both due to their simplicity and the fact that the
potential benefits of time-varying control schedules (TVCS) have remained
largely uncharacterized. Yet, TVCS have the potential to significantly enhance
network controllability over TICS, especially when applied to large networks.
In this paper we study networks with linear and discrete-time dynamics and
analyze the role of network structure in TVCS. Through the analysis of a new
scale-dependent notion of nodal communicability, we show that optimal TVCS
involves the actuation of the most central nodes at appropriate spatial scales
at all times. Consequently, we show that it is the scale-heterogeneity of the
central-nodes in a network that determine whether, and to what extent, TVCS
outperforms conventional policies based on TICS. Several analytical results and
numerical examples support and illustrate this relationship.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06485</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06487</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Sequence Construction of Cyclic Codes over Finite Fields</dc:title>
 <dc:creator>Ding, Cunsheng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Due to their efficient encoding and decoding algorithms, cyclic codes, a
subclass of linear codes, have applications in communication systems, consumer
electronics, and data storage systems. There are several approaches to
constructing all cyclic codes over finite fields, including the generator
matrix approach, the generator polynomial approach, and the generating
idempotent approach. Another one is a sequence approach, which has been
intensively investigated in the past decade. The objective of this paper is to
survey the progress in this direction in the past decade. Many open problems
are also presented in this paper.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1206.4370</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06487</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06492</identifier>
 <datestamp>2017-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Memory Addressing for describing videos</dc:title>
 <dc:creator>Jain, Arnav Kumar</dc:creator>
 <dc:creator>Agarwalla, Abhinav</dc:creator>
 <dc:creator>Agrawal, Kumar Krishna</dc:creator>
 <dc:creator>Mitra, Pabitra</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we introduce Key-Value Memory Networks to a multimodal setting
and a novel key-addressing mechanism to deal with sequence-to-sequence models.
The proposed model naturally decomposes the problem of video captioning into
vision and language segments, dealing with them as key-value pairs. More
specifically, we learn a semantic embedding (v) corresponding to each frame (k)
in the video, thereby creating (k, v) memory slots. We propose to find the next
step attention weights conditioned on the previous attention distributions for
the key-value memory slots in the memory addressing schema. Exploiting this
flexibility of the framework, we additionally capture spatial dependencies
while mapping from the visual to semantic embedding. Experiments done on the
Youtube2Text dataset demonstrate usefulness of recurrent key-addressing, while
achieving competitive scores on BLEU@4, METEOR metrics against state-of-the-art
models.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06495</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Fully Convolutional Networks for Iterative Non-blind
  Deconvolution</dc:title>
 <dc:creator>Zhang, Jiawei</dc:creator>
 <dc:creator>Pan, Jinshan</dc:creator>
 <dc:creator>Lai, Wei-Sheng</dc:creator>
 <dc:creator>Lau, Rynson</dc:creator>
 <dc:creator>Yang, Ming-Hsuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a fully convolutional networks for iterative
non-blind deconvolution We decompose the non-blind deconvolution problem into
image denoising and image deconvolution. We train a FCNN to remove noises in
the gradient domain and use the learned gradients to guide the image
deconvolution step. In contrast to the existing deep neural network based
methods, we iteratively deconvolve the blurred images in a multi-stage
framework. The proposed method is able to learn an adaptive image prior, which
keeps both local (details) and global (structures) information. Both
quantitative and qualitative evaluations on benchmark datasets demonstrate that
the proposed method performs favorably against state-of-the-art algorithms in
terms of quality and speed.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06497</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Reinforcement Learning Approach to Power Control and Rate Adaptation
  in Cellular Networks</dc:title>
 <dc:creator>Ghadimi, Euhanna</dc:creator>
 <dc:creator>Calabrese, Francesco Davide</dc:creator>
 <dc:creator>Peters, Gunnar</dc:creator>
 <dc:creator>Soldati, Pablo</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Optimizing radio transmission power and user data rates in wireless systems
via power control requires an accurate and instantaneous knowledge of the
system model. While this problem has been extensively studied in the
literature, an efficient solution approaching optimality with the limited
information available in practical systems is still lacking. This paper
presents a reinforcement learning framework for power control and rate
adaptation in the downlink of a radio access network that closes this gap. We
present a comprehensive design of the learning framework that includes the
characterization of the system state, the design of a general reward function,
and the method to learn the control policy. System level simulations show that
our design can quickly learn a power control policy that brings significant
energy savings and fairness across users in the system.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06500</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental Exact Min-Cut in Poly-logarithmic Amortized Update Time</dc:title>
 <dc:creator>Goranci, Gramoz</dc:creator>
 <dc:creator>Henzinger, Monika</dc:creator>
 <dc:creator>Thorup, Mikkel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present a deterministic incremental algorithm for \textit{exactly}
maintaining the size of a minimum cut with $\widetilde{O}(1)$ amortized time
per edge insertion and $O(1)$ query time. This result partially answers an open
question posed by Thorup [Combinatorica 2007]. It also stays in sharp contrast
to a polynomial conditional lower-bound for the fully-dynamic weighted minimum
cut problem. Our algorithm is obtained by combining a recent sparsification
technique of Kawarabayashi and Thorup [STOC 2015] and an exact incremental
algorithm of Henzinger [J. of Algorithm 1997]. We also study space-efficient
incremental algorithms for the minimum cut problem. Concretely, we show that
there exists an ${O}(n\log n/\varepsilon^2)$ space Monte-Carlo algorithm that
can process a stream of edge insertions starting from an empty graph, and with
high probability, the algorithm maintains a $(1+\varepsilon)$-approximation to
the minimum cut. The algorithm has $\widetilde{O}(1)$ amortized update-time and
constant query-time.
</dc:description>
 <dc:description>Comment: Extended abstract appeared in proceedings of ESA 2016</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06500</dc:identifier>
 <dc:identifier>doi:10.4230/LIPIcs.ESA.2016.46</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06501</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximation and parameterized algorithms for geometric independent set
  with shrinking</dc:title>
 <dc:creator>Pilipczuk, Micha&#x142;</dc:creator>
 <dc:creator>van Leeuwen, Erik Jan</dc:creator>
 <dc:creator>Wiese, Andreas</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Consider the Maximum Weight Independent Set problem for rectangles: given a
family of weighted axis-parallel rectangles in the plane, find a maximum-weight
subset of non-overlapping rectangles. The problem is notoriously hard both in
the approximation and in the parameterized setting. The best known
polynomial-time approximation algorithms achieve super-constant approximation
ratios [Chalermsook and Chuzhoy, SODA 2009; Chan and Har-Peled, Discrete &amp;
Comp. Geometry 2012], even though there is a $(1+\epsilon)$-approximation
running in quasi-polynomial time [Adamaszek and Wiese, FOCS 2013; Chuzhoy and
Ene, FOCS 2016]. When parameterized by the target size of the solution, the
problem is $\mathsf{W}[1]$-hard even in the unweighted setting [Marx, FOCS
2007].
  To achieve tractability, we study the following shrinking model: one is
allowed to shrink each input rectangle by a multiplicative factor $1-\delta$
for some fixed $\delta&gt;0$, but the performance is still compared against the
optimal solution for the original, non-shrunk instance. We prove that in this
regime, the problem admits an EPTAS with running time $f(\epsilon,\delta)\cdot
n^{\mathcal{O}(1)}$, and an FPT algorithm with running time $f(k,\delta)\cdot
n^{\mathcal{O}(1)}$, in the setting where a maximum-weight solution of size at
most $k$ is to be computed. This improves and significantly simplifies a PTAS
given earlier for this problem [Adamaszek et al., APPROX 2015], and provides
the first parameterized results for the shrinking model. Furthermore, we
explore kernelization in the shrinking model, by giving efficient kernelization
procedures for several variants of the problem when the input rectangles are
squares.
</dc:description>
 <dc:description>Comment: 25 pages, 2 figures</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06505</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decision-Based Transcription of Jazz Guitar Solos Using a Harmonic
  Bident Analysis Filter Bank and Spectral Distribution Weighting</dc:title>
 <dc:creator>Gorlow, Stanislaw</dc:creator>
 <dc:creator>Ramona, Mathieu</dc:creator>
 <dc:creator>Pachet, Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Jazz guitar solos are improvised melody lines played on one instrument on top
of a chordal accompaniment (comping). As the improvisation happens
spontaneously, a reference score is non-existent, only a lead sheet. There are
situations, however, when one would like to have the original melody lines in
the form of notated music, see the Real Book. The motivation is either for the
purpose of practice and imitation or for musical analysis. In this work, an
automatic transcriber for jazz guitar solos is developed. It resorts to a very
intuitive representation of tonal music signals: the pitchgram. No
instrument-specific modeling is involved, so the transcriber should be
applicable to other pitched instruments as well. Neither is there the need to
learn any note profiles prior to or during the transcription. Essentially, the
proposed transcriber is a decision tree, thus a classifier, with a depth of 3.
It has a (very) low computational complexity and can be run on-line. The
decision rules can be refined or extended with no or little musical education.
The transcriber's performance is evaluated on a set of ten jazz solo excerpts
and compared with a state-of-the-art transcription system for the guitar plus
PYIN. We achieve an improvement of 34% w.r.t. the reference system and 19%
w.r.t. PYIN in terms of the F-measure. Another measure of accuracy, the error
score, attests that the number of erroneous pitch detections is reduced by more
than 50% w.r.t. the reference system and by 45% w.r.t. PYIN.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06505</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06527</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Regularized Least-Squares Beamforming Approach to Signal
  Estimation</dc:title>
 <dc:creator>Suliman, Mohamed</dc:creator>
 <dc:creator>Ballal, Tarig</dc:creator>
 <dc:creator>Al-Naffouri, Tareq Y.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we address the problem of robust adaptive beamforming of
signals received by a linear array. The challenge associated with the
beamforming problem is twofold. Firstly, the process requires the inversion of
the usually ill-conditioned covariance matrix of the received signals.
Secondly, the steering vector pertaining to the direction of arrival of the
signal of interest is not known precisely. To tackle these two challenges, the
standard capon beamformer is manipulated to a form where the beamformer output
is obtained as a scaled version of the inner product of two vectors. The two
vectors are linearly related to the steering vector and the received signal
snapshot, respectively. The linear operator, in both cases, is the square root
of the covariance matrix. A regularized least-squares (RLS) approach is
proposed to estimate these two vectors and to provide robustness without
exploiting prior information. Simulation results show that the RLS beamformer
using the proposed regularization algorithm outperforms state-of-the-art
beamforming algorithms, as well as another RLS beamformers using a standard
regularization approaches.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures, conference</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06527</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06529</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on distance labeling in planar graphs</dc:title>
 <dc:creator>Gawrychowski, Pawe&#x142;</dc:creator>
 <dc:creator>Uzna&#x144;ski, Przemys&#x142;aw</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A distance labeling scheme is an assignments of labels, that is binary
strings, to all nodes of a graph, so that the distance between any two nodes
can be computed from their labels and the labels are as short as possible. A
major open problem is to determine the complexity of distance labeling in
unweighted and undirected planar graphs. It is known that, in such a graph on
$n$ nodes, some labels must consist of $\Omega(n^{1/3})$ bits, but the best
known labeling scheme uses labels of length $O(\sqrt{n}\log n)$ [Gavoille,
Peleg, P\'erennes, and Raz, J. Algorithms, 2004]. We show that, in fact, labels
of length $O(\sqrt{n})$ are enough.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06529</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06530</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prototypical Recurrent Unit</dc:title>
 <dc:creator>Long, Dingkun</dc:creator>
 <dc:creator>Zhang, Richong</dc:creator>
 <dc:creator>Mao, Yongyi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The difficulty in analyzing LSTM-like recurrent neural networks lies in the
complex structure of the recurrent unit, which induces highly complex nonlinear
dynamics. In this paper, we design a new simple recurrent unit, which we call
Prototypical Recurrent Unit (PRU). We verify experimentally that PRU performs
comparably to LSTM and GRU. This potentially enables PRU to be a prototypical
example for analytic study of LSTM-like recurrent networks. Along these
experiments, the memorization capability of LSTM-like networks is also studied
and some insights are obtained.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06534</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Thompson Sampling Revisited</dc:title>
 <dc:creator>Abeille, Marc</dc:creator>
 <dc:creator>Lazaric, Alessandro</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We derive an alternative proof for the regret of Thompson sampling (\ts) in
the stochastic linear bandit setting. While we obtain a regret bound of order
$\widetilde{O}(d^{3/2}\sqrt{T})$ as in previous results, the proof sheds new
light on the functioning of the \ts. We leverage on the structure of the
problem to show how the regret is related to the sensitivity (i.e., the
gradient) of the objective function and how selecting optimal arms associated
to \textit{optimistic} parameters does control it. Thus we show that \ts can be
seen as a generic randomized algorithm where the sampling distribution is
designed to have a fixed probability of being optimistic, at the cost of an
additional $\sqrt{d}$ regret factor compared to a UCB-like approach.
Furthermore, we show that our proof can be readily applied to regularized
linear optimization and generalized linear model problems.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06534</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06538</identifier>
 <datestamp>2017-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Storage Allocation in Cache-Enabled Interference Channels with Mixed
  CSIT</dc:title>
 <dc:creator>Nejad, Mohammad Ali Tahmasbi</dc:creator>
 <dc:creator>Shariatpanahi, Seyed Pooya</dc:creator>
 <dc:creator>Khalaj, Babak Hossein</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Recently, it has been shown that in a cache-enabled interference channel, the
storage at the transmit and receive sides are of equal value in terms of
Degrees of Freedom (DoF). This is derived by assuming full Channel State
Information at the Transmitter (CSIT). In this paper, we consider a more
practical scenario, where a training/feedback phase should exist for obtaining
CSIT, during which instantaneous channel state is not known to the
transmitters. This results in a combination of delayed and current CSIT
availability, called mixed CSIT. In this setup, we derive DoF of a
cache-enabled interference channel with mixed CSIT, which depends on the memory
available at transmit and receive sides as well as the training/feedback phase
duration. In contrast to the case of having full CSIT, we prove that, in our
setup, the storage at the receive side is more valuable than the one at the
transmit side. This is due to the fact that cooperation opportunities granted
by transmitters' caches are strongly based on instantaneous CSIT availability.
However, multi-casting opportunities provided by receivers' caches are robust
to such imperfection.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1209.5807 by other authors</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06539</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Stochastic Inference of Bitwise Deep Neural Networks</dc:title>
 <dc:creator>Vogel, Sebastian</dc:creator>
 <dc:creator>Schorn, Christoph</dc:creator>
 <dc:creator>Guntoro, Andre</dc:creator>
 <dc:creator>Ascheid, Gerd</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:subject>C.1.3</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  Recently published methods enable training of bitwise neural networks which
allow reduced representation of down to a single bit per weight. We present a
method that exploits ensemble decisions based on multiple stochastically
sampled network models to increase performance figures of bitwise neural
networks in terms of classification accuracy at inference. Our experiments with
the CIFAR-10 and GTSRB datasets show that the performance of such network
ensembles surpasses the performance of the high-precision base model. With this
technique we achieve 5.81% best classification error on CIFAR-10 test set using
bitwise networks. Concerning inference on embedded systems we evaluate these
bitwise networks using a hardware efficient stochastic rounding procedure. Our
work contributes to efficient embedded bitwise neural networks.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, Workshop on Efficient Methods for Deep Neural
  Networks at Neural Information Processing Systems Conference 2016, NIPS 2016,
  EMDNN 2016</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06539</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06544</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Agent-Based Models of Intimate Partner Violence</dc:title>
 <dc:creator>Guidi, Elisa</dc:creator>
 <dc:creator>Meringolo, Patrizia</dc:creator>
 <dc:creator>Guazzini, Andrea</dc:creator>
 <dc:creator>Bagnoli, Franco</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Intimate partner violence (IPV) is a significant public health problem and
social issue that involves couples from all socioeconomic and cultural
contexts. IPV may affect women and men, but these latter are the most common
perpetrators of IPV. We developed stochastic Agent-Based models of IPV focused
on the couple dynamics, determined by the parallel, individual behaviour of
partners. Based on the psychological theory of the Cycle of Violence, we have
developed a model based on four discrete states: passivity, normal situation,
upset and physical assault. The individual transition probability depends on
the previous state of the subject and that of the partner, and on a control
parameter, the aggressiveness. We then let this parameter evolve depending on
the perceived violence from past experiences (polarisation) or from the support
received from the environment (social influence). From the analysis of the
phase diagrams we observe the emergence of characteristic patterns, in
agreement with the observations of IPV in the literature.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06544</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06547</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A critical comparative analysis of five world university rankings</dc:title>
 <dc:creator>Moed, Henk F.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  To provide users insight into the value and limits of world university
rankings, a comparative analysis is conducted of 5 ranking systems: ARWU,
Leiden, THE, QS and U-Multirank. It links these systems with one another at the
level of individual institutions, and analyses the overlap in institutional
coverage, geographical coverage, how indicators are calculated from raw data,
the skewness of indicator distributions, and statistical correlations between
indicators. Four secondary analyses are presented investigating national
academic systems and selected pairs of indicators. It is argued that current
systems are still one-dimensional in the sense that they provide finalized,
seemingly unrelated indicator values rather than offering a data set and tools
to observe patterns in multi-faceted data. By systematically comparing
different systems, more insight is provided into how their institutional
coverage, rating methods, the selection of indicators and their normalizations
influence the ranking positions of given institutions.
</dc:description>
 <dc:description>Comment: Author copy of a paper accepted for publication in Scientometrics, 15
  Nov. 2016 v2</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06548</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note about &quot;Faster algorithms for computing Hong's bound on absolute
  positiveness&quot; by K. Mehlhorn and S. Ray</dc:title>
 <dc:creator>Koprowski, Przemys&#x142;aw</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>12Y05, 03D15, 68U05</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:description>  We show that a linear-time algorithm for computing Hong's bound for positive
roots of a univariate polynomial, described by K. Mehlhorn and S. Ray in an
article &quot;Faster algorithms for computing Hong's bound on absolute
positiveness&quot;, is incorrect. We present a corrected version.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06557</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proof of a conjecture of Davila and Kenter regarding a lower bound for
  the forcing number in terms of girth and minimum degree</dc:title>
 <dc:creator>Davila, Randy</dc:creator>
 <dc:creator>Kalinowski, Thomas</dc:creator>
 <dc:creator>Stephen, Sudeep</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  In this note, we study a dynamic coloring of vertices in a simple graph $G$.
In particular, one may color an initial set of vertices black, with all other
vertices white. Then, at each discrete time step, a black vertex with exactly
one white neighbor will force its white neighbor to become black. The initial
set of black vertices is called a zero forcing set if by iterating this
aforementioned process, all of the vertices in $G$ become black. The zero
forcing number of $G$ is the cardinality of a minimum zero forcing set in $G$,
and is denoted by $Z(G)$. Davila and Kenter [Bounds for the zero forcing number
of a graph with large girth. Theory and Applications of Graphs, 2(2) (2015)]
conjectured that the zero forcing number satisfies $Z(G)\geq
(g-3)(\delta-2)+\delta$ where $g$ and $\delta$ denote the girth and the minimum
degree of the graph, respectively. This conjecture has been proven for graphs
with girth $g \leq 10$. In this note, we prove it for all graphs with girth $g
\geq 11$ and for all values of $\delta \geq 2$, thereby settling the
conjecture.
</dc:description>
 <dc:description>Comment: fixed a mistake in the proof</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06565</identifier>
 <datestamp>2017-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Tensor Convolution on Multicores</dc:title>
 <dc:creator>Budden, David</dc:creator>
 <dc:creator>Matveev, Alexander</dc:creator>
 <dc:creator>Santurkar, Shibani</dc:creator>
 <dc:creator>Chaudhuri, Shraman Ray</dc:creator>
 <dc:creator>Shavit, Nir</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deep convolutional neural networks (ConvNets) of 3-dimensional kernels allow
joint modeling of spatiotemporal features. These networks have improved
performance of video and volumetric image analysis, but have been limited in
size due to the low memory ceiling of GPU hardware. Existing CPU
implementations overcome this constraint but are impractically slow. Here we
extend and optimize the faster Winograd-class of convolutional algorithms to
the $N$-dimensional case and specifically for CPU hardware. First, we remove
the need to manually hand-craft algorithms by exploiting the relaxed
constraints and cheap sparse access of CPU memory. Second, we maximize CPU
utilization and multicore scalability by transforming data matrices to be
cache-aware, integer multiples of AVX vector widths. Treating 2-dimensional
ConvNets as a special (and the least beneficial) case of our approach, we
demonstrate a 5 to 25-fold improvement in throughput compared to previous
state-of-the-art.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures, 1 supplementary doc</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-06-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06565</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06576</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Nonconvex Optimization for Sparse Representation</dc:title>
 <dc:creator>Sun, Ying</dc:creator>
 <dc:creator>Scutari, Gesualdo</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We consider a non-convex constrained Lagrangian formulation of a fundamental
bi-criteria optimization problem for variable selection in statistical
learning; the two criteria are a smooth (possibly) nonconvex loss function,
measuring the fitness of the model to data, and the latter function is a
difference-of-convex (DC) regularization, employed to promote some extra
structure on the solution, like sparsity. This general class of nonconvex
problems arises in many big-data applications, from statistical machine
learning to physical sciences and engineering. We develop the first unified
distributed algorithmic framework for these problems and establish its
asymptotic convergence to d-stationary solutions. Two key features of the
method are: i) it can be implemented on arbitrary networks (digraphs) with
(possibly) time-varying connectivity; and ii) it does not require the
restrictive assumption that the (sub)gradient of the objective function is
bounded, which enlarges significantly the class of statistical learning
problems that can be solved with convergence guarantees.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2017</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06585</identifier>
 <datestamp>2017-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Boosting: Iteratively Refining Posterior Approximations</dc:title>
 <dc:creator>Miller, Andrew C.</dc:creator>
 <dc:creator>Foti, Nicholas</dc:creator>
 <dc:creator>Adams, Ryan P.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  We propose a black-box variational inference method to approximate
intractable distributions with an increasingly rich approximating class. Our
method, termed variational boosting, iteratively refines an existing
variational approximation by solving a sequence of optimization problems,
allowing the practitioner to trade computation time for accuracy. We show how
to expand the variational approximating class by incorporating additional
covariance structure and by introducing new components to form a mixture. We
apply variational boosting to synthetic and real statistical models, and show
that resulting posterior inferences compare favorably to existing posterior
approximation algorithms in both accuracy and efficiency.
</dc:description>
 <dc:description>Comment: 25 pages, 9 figures, 2 tables</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-02-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06587</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wellformedness Properties in Euler Diagrams: An Eye Tracking Study for
  Visualisation Evaluation</dc:title>
 <dc:creator>Sathiyanarayanan, Mithileysh</dc:creator>
 <dc:creator>Mulling, Tobias</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In the field of information visualisation, Euler diagrams are an important
tool used in various application areas such as engineering, medicine and social
analysis. To effectively use Euler diagrams, some of the wellformedness
properties needs to be avoided, as they are considered to reduce user
comprehension. From the previous empirical studies, we know some properties are
swappable but there is no clear justification which property would be the best
to use. In this paper, we considered two main wellformedness properties
(duplicated curve labels and disconnected zones) to test which among the two
affect user comprehension the most, based on the task performance (accuracy and
response time), preference and eye movements of the users. Twelve participants
performed three different types of tasks with nine diagrams of each property
(so, in total eighteen diagrams) and the results showed that duplicated curve
labels property slows down and trigger extra eye movements, causing delays for
the tasks. Though there is no significant difference in the accuracy but the
insights obtained from the response time, preference and eye movements will be
useful for software developers on the optimal way to visualise Euler diagrams
in real world application areas.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures, the Brazilian Computing Society, the XIV
  Brazilian Symposium on Human Factors in Computer Systems (IHC 2015)</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06589</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fair Division via Social Comparison</dc:title>
 <dc:creator>Abebe, Rediet</dc:creator>
 <dc:creator>Kleinberg, Jon</dc:creator>
 <dc:creator>Parkes, David</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  In the classical cake cutting problem, a resource must be divided among
agents with different utilities so that each agent believes they have received
a fair share of the resource relative to the other agents. We introduce a
variant of the problem in which we model an underlying social network on the
agents with a graph, and agents only evaluate their shares relative to their
neighbors' in the network. This formulation captures many situations in which
it is unrealistic to assume a global view, and also exposes interesting
phenomena in the original problem.
  Specifically, we say an allocation is locally envy-free if no agent envies a
neighbor's allocation and locally proportional if each agent values her own
allocation as much as the average value of her neighbor's allocations, with the
former implying the latter. While global envy-freeness implies local
envy-freeness, global proportionality does not imply local proportionality, or
vice versa. A general result is that for any two distinct graphs on the same
set of nodes and an allocation, there exists a set of valuation functions such
that the allocation is locally proportional on one but not the other.
  We fully characterize the set of graphs for which an oblivious single-cutter
protocol-- a protocol that uses a single agent to cut the cake into pieces
--admits a bounded protocol with $O(n^2)$ query complexity for locally
envy-free allocations in the Robertson-Webb model. We also consider the price
of envy-freeness, which compares the total utility of an optimal allocation to
the best utility of an allocation that is envy-free. We show that a lower bound
of $\Omega(\sqrt{n})$ on the price of envy-freeness for global allocations in
fact holds for local envy-freeness in any connected undirected graph. Thus,
sparse graphs surprisingly do not provide more flexibility with respect to the
quality of envy-free allocations.
</dc:description>
 <dc:description>Comment: 18 pages, 3 figures</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06589</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06591</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coded Caching with Distributed Storage</dc:title>
 <dc:creator>Luo, Tianqiong</dc:creator>
 <dc:creator>Aggarwal, Vaneet</dc:creator>
 <dc:creator>Peleato, Borja</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Content delivery networks store information distributed across multiple
servers, so as to balance the load and avoid unrecoverable losses in case of
node or disk failures. Coded caching has been shown to be a useful technique
which can reduce peak traffic rates by pre-fetching popular content at the end
users and encoding transmissions so that different users can extract different
information from the same packet. On one hand, distributed storage limits the
capability of combining content from different servers into a single message,
causing performance losses in coded caching schemes. But, on the other hand,
the inherent redundancy existing in distributed storage systems can be used to
improve the performance of those schemes through parallelism.
  This paper designs a scheme combining distributed storage of the content in
multiple servers and an efficient coded caching algorithm for delivery to the
users. This scheme is shown to reduce the peak transmission rate below that of
state-of-the-art algorithms.
</dc:description>
 <dc:description>Comment: submitted to IEEE Transactions on Information Theory</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06591</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06593</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterizing Polytopes Contained in the $0/1$-Cube with Bounded
  Chv\'atal-Gomory Rank</dc:title>
 <dc:creator>Benchetrit, Yohann</dc:creator>
 <dc:creator>Fiorini, Samuel</dc:creator>
 <dc:creator>Huynh, Tony</dc:creator>
 <dc:creator>Weltge, Stefan</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Let $S \subseteq \{0,1\}^n$ and $R$ be any polytope contained in $[0,1]^n$
with $R \cap \{0,1\}^n = S$. We prove that $R$ has bounded Chv\'atal-Gomory
rank (CG-rank) provided that $S$ has bounded notch and bounded gap, where the
notch is the minimum integer $p$ such that all $p$-dimensional faces of the
$0/1$-cube have a nonempty intersection with $S$, and the gap is a measure of
the size of the facet coefficients of $\mathsf{conv}(S)$.
  Let $H[\bar{S}]$ denote the subgraph of the $n$-cube induced by the vertices
not in $S$. We prove that if $H[\bar{S}]$ does not contain a subdivision of a
large complete graph, then both the notch and the gap are bounded. By our main
result, this implies that the CG-rank of $R$ is bounded as a function of the
treewidth of $H[\bar{S}]$. We also prove that if $S$ has notch $3$, then the
CG-rank of $R$ is always bounded. Both results generalize a recent theorem of
Cornu\'ejols and Lee, who proved that the CG-rank is bounded by a constant if
the treewidth of $H[\bar{S}]$ is at most $2$.
</dc:description>
 <dc:description>Comment: 10 pages. Changed term 'pitch' to 'notch'. Removed 'Extended
  Formulations' section since those results have been subsumed by
  https://arxiv.org/abs/1711.01358</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06593</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06596</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object Recognition with and without Objects</dc:title>
 <dc:creator>Zhu, Zhuotun</dc:creator>
 <dc:creator>Xie, Lingxi</dc:creator>
 <dc:creator>Yuille, Alan L.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While recent deep neural networks have achieved a promising performance on
object recognition, they rely implicitly on the visual contents of the whole
image. In this paper, we train deep neural net- works on the foreground
(object) and background (context) regions of images respectively. Consider- ing
human recognition in the same situations, net- works trained on the pure
background without ob- jects achieves highly reasonable recognition performance
that beats humans by a large margin if only given context. However, humans
still outperform networks with pure object available, which indicates networks
and human beings have different mechanisms in understanding an image.
Furthermore, we straightforwardly combine multiple trained networks to explore
different visual cues learned by different networks. Experiments show that
useful visual hints can be explicitly learned separately and then combined to
achieve higher performance, which verifies the advantages of the proposed
framework.
</dc:description>
 <dc:description>Comment: To Appear in IJCAI 2017</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06605</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithmic and Hardness Results for the Hub Labeling Problem</dc:title>
 <dc:creator>Angelidakis, Haris</dc:creator>
 <dc:creator>Makarychev, Yury</dc:creator>
 <dc:creator>Oparin, Vsevolod</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  There has been significant success in designing highly efficient algorithms
for distance and shortest-path queries in recent years; many of the
state-of-the-art algorithms use the hub labeling framework. In this paper, we
study the approximability of the Hub Labeling problem. We prove a hardness of
$\Omega(\log n)$ for Hub Labeling, matching known approximation guarantees. The
hardness result applies to graphs that have multiple shortest paths between
some pairs of vertices. No hardness of approximation results were known
previously.
  Then, we focus on graphs that have a unique shortest path between each pair
of vertices. This is a very natural family of graphs, and much research on the
Hub Labeling problem has studied such graphs. We give an $O(\log D)$
approximation algorithm for graphs of diameter $D$ with unique shortest paths.
In particular, we get an $O(\log \log n)$ approximation for graphs of
polylogarithmic diameter, while previously known algorithms gave an $O(\log n)$
proximation. Finally, we present a polynomial-time approximation scheme (PTAS)
and quasi-polynomial time algorithms for Hub Labeling on trees; additionally,
we analyze a simple combinatorial heuristic for Hub Labeling on trees, proposed
by Peleg in 2000. We show that this heuristic gives an approximation factor of
2.
</dc:description>
 <dc:description>Comment: To appear in SODA17</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06605</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06607</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Hierarchical Approach for Generating Descriptive Image Paragraphs</dc:title>
 <dc:creator>Krause, Jonathan</dc:creator>
 <dc:creator>Johnson, Justin</dc:creator>
 <dc:creator>Krishna, Ranjay</dc:creator>
 <dc:creator>Fei-Fei, Li</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recent progress on image captioning has made it possible to generate novel
sentences describing images in natural language, but compressing an image into
a single sentence can describe visual content in only coarse detail. While one
new captioning approach, dense captioning, can potentially describe images in
finer levels of detail by captioning many regions within an image, it in turn
is unable to produce a coherent story for an image. In this paper we overcome
these limitations by generating entire paragraphs for describing images, which
can tell detailed, unified stories. We develop a model that decomposes both
images and paragraphs into their constituent parts, detecting semantic regions
in images and using a hierarchical recurrent neural network to reason about
language. Linguistic analysis confirms the complexity of the paragraph
generation task, and thorough experiments on a new dataset of image and
paragraph pairs demonstrate the effectiveness of our approach.
</dc:description>
 <dc:description>Comment: CVPR 2017 spotlight</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06609</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MAC Protocols for IEEE 802.11ax: Avoiding Collisions on Dense Networks</dc:title>
 <dc:creator>da Silva, Rafael Araujo</dc:creator>
 <dc:creator>Nogueira, Michele</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Wireless networks have become the main form of Internet access. Statistics
show that the global mobile Internet penetration should exceed 70\% until 2019.
Wi-Fi is an important player in this change. Founded on IEEE 802.11, this
technology has a crucial impact in how we share broadband access both in
domestic and corporate networks. However, recent works have indicated
performance issues in Wi-Fi networks, mainly when they have been deployed
without planning and under high user density. Hence, different collision
avoidance techniques and Medium Access Control protocols have been designed in
order to improve Wi-Fi performance. Analyzing the collision problem, this work
strengthens the claims found in the literature about the low Wi-Fi performance
under dense scenarios. Then, in particular, this article overviews the MAC
protocols used in the IEEE 802.11 standard and discusses solutions to mitigate
collisions. Finally, it contributes presenting future trends in MAC protocols.
This assists in foreseeing expected improvements for the next generation of
Wi-Fi devices.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06609</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06610</identifier>
 <datestamp>2017-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Throughput Efficient Large M2M Networks through Incremental Redundancy
  Combining</dc:title>
 <dc:creator>Rajanna, Amogh</dc:creator>
 <dc:creator>Kaveh, Mos</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate the performance of incremental redundancy
combining as a new cooperative relaying protocol for large M2M networks with
opportunistic relaying. The nodes in the large M2M network are modeled by a
Poisson Point Process, experience Rayleigh fading and utilize slotted ALOHA as
the MAC protocol. The progress rate density (PRD) of the M2M network is used to
quantify the performance of proposed relaying protocol and compare it to
conventional multihop relaying with no cooperation. It is shown that
incremental redundancy combining in a large M2M network provides substantial
throughput improvements over conventional relaying with no cooperation at all
practical values of the network parameters.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures, in Proc of IEEE Wireless Communications
  Networking Conference (WCNC) 2017 Workshop (M2M and Internet of Things)</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06610</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06612</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic
  Segmentation</dc:title>
 <dc:creator>Lin, Guosheng</dc:creator>
 <dc:creator>Milan, Anton</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Reid, Ian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, very deep convolutional neural networks (CNNs) have shown
outstanding performance in object recognition and have also been the first
choice for dense classification problems such as semantic segmentation.
However, repeated subsampling operations like pooling or convolution striding
in deep CNNs lead to a significant decrease in the initial image resolution.
Here, we present RefineNet, a generic multi-path refinement network that
explicitly exploits all the information available along the down-sampling
process to enable high-resolution prediction using long-range residual
connections. In this way, the deeper layers that capture high-level semantic
features can be directly refined using fine-grained features from earlier
convolutions. The individual components of RefineNet employ residual
connections following the identity mapping mindset, which allows for effective
end-to-end training. Further, we introduce chained residual pooling, which
captures rich background context in an efficient manner. We carry out
comprehensive experiments and set new state-of-the-art results on seven public
datasets. In particular, we achieve an intersection-over-union score of 83.4 on
the challenging PASCAL VOC 2012 dataset, which is the best reported result to
date.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06612</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06615</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FURL: Fixed-memory and Uncertainty Reducing Local Triangle Counting for
  Graph Streams</dc:title>
 <dc:creator>Jung, Minsoo</dc:creator>
 <dc:creator>Lee, Sunmin</dc:creator>
 <dc:creator>Lim, Yongsub</dc:creator>
 <dc:creator>Kang, U</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>05C85</dc:subject>
 <dc:description>  How can we accurately estimate local triangles for all nodes in simple and
multigraph streams? Local triangle counting in a graph stream is one of the
most fundamental tasks in graph mining with important applications including
anomaly detection and social network analysis. Although there have been several
local triangle counting methods in a graph stream, their estimation has a large
variance which results in low accuracy, and they do not consider multigraph
streams which have duplicate edges. In this paper, we propose FURL, an accurate
local triangle counting method for simple and multigraph streams. FURL improves
the accuracy by reducing a variance through biased estimation and handles
duplicate edges for multigraph streams. Also, FURL handles a stream of any size
by using a fixed amount of memory. Experimental results show that FURL
outperforms the state-of-the-art method in accuracy and performs well in
multigraph streams. In addition, we report interesting patterns discovered from
real graphs by FURL, which include unusual local structures in a user
communication network and a core-periphery structure in the Web.
</dc:description>
 <dc:description>Comment: 24 pages</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06615</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06620</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Business Zone Recommender System Based on Facebook and Urban Planning
  Data</dc:title>
 <dc:creator>Lin, Jovian</dc:creator>
 <dc:creator>Oentaryo, Richard J.</dc:creator>
 <dc:creator>Lim, Ee-Peng</dc:creator>
 <dc:creator>Vu, Casey</dc:creator>
 <dc:creator>Vu, Adrian</dc:creator>
 <dc:creator>Kwee, Agus T.</dc:creator>
 <dc:creator>Prasetyo, Philips K.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  We present ZoneRec---a zone recommendation system for physical businesses in
an urban city, which uses both public business data from Facebook and urban
planning data. The system consists of machine learning algorithms that take in
a business' metadata and outputs a list of recommended zones to establish the
business in. We evaluate our system using data of food businesses in Singapore
and assess the contribution of different feature groups to the recommendation
quality.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06620</dc:identifier>
 <dc:identifier>Proceedings of the European Conference on Information Retrieval,
  2016, pp. 641-647</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-30671-1_47</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06624</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Generative Adversarial Nets with Singular Value Clipping</dc:title>
 <dc:creator>Saito, Masaki</dc:creator>
 <dc:creator>Matsumoto, Eiichi</dc:creator>
 <dc:creator>Saito, Shunta</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a generative model, Temporal Generative Adversarial
Nets (TGAN), which can learn a semantic representation of unlabeled videos, and
is capable of generating videos. Unlike existing Generative Adversarial Nets
(GAN)-based methods that generate videos with a single generator consisting of
3D deconvolutional layers, our model exploits two different types of
generators: a temporal generator and an image generator. The temporal generator
takes a single latent variable as input and outputs a set of latent variables,
each of which corresponds to an image frame in a video. The image generator
transforms a set of such latent variables into a video. To deal with
instability in training of GAN with such advanced networks, we adopt a recently
proposed model, Wasserstein GAN, and propose a novel method to train it stably
in an end-to-end manner. The experimental results demonstrate the effectiveness
of our methods.
</dc:description>
 <dc:description>Comment: to appear in ICCV 2017</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06625</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling Review Spam Using Temporal Patterns and Co-bursting Behaviors</dc:title>
 <dc:creator>Li, Huayi</dc:creator>
 <dc:creator>Fei, Geli</dc:creator>
 <dc:creator>Wang, Shuai</dc:creator>
 <dc:creator>Liu, Bing</dc:creator>
 <dc:creator>Shao, Weixiang</dc:creator>
 <dc:creator>Mukherjee, Arjun</dc:creator>
 <dc:creator>Shao, Jidong</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Online reviews play a crucial role in helping consumers evaluate and compare
products and services. However, review hosting sites are often targeted by
opinion spamming. In recent years, many such sites have put a great deal of
effort in building effective review filtering systems to detect fake reviews
and to block malicious accounts. Thus, fraudsters or spammers now turn to
compromise, purchase or even raise reputable accounts to write fake reviews.
Based on the analysis of a real-life dataset from a review hosting site
(dianping.com), we discovered that reviewers' posting rates are bimodal and the
transitions between different states can be utilized to differentiate spammers
from genuine reviewers. Inspired by these findings, we propose a two-mode
Labeled Hidden Markov Model to detect spammers. Experimental results show that
our model significantly outperforms supervised learning using linguistic and
behavioral features in identifying spammers. Furthermore, we found that when a
product has a burst of reviews, many spammers are likely to be actively
involved in writing reviews to the product as well as to many other products.
We then propose a novel co-bursting network for detecting spammer groups. The
co-bursting network enables us to produce more accurate spammer groups than the
current state-of-the-art reviewer-product (co-reviewing) network.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06625</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06631</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Selecting a Conjunction Operation in Probabilistic Soft Logic</dc:title>
 <dc:creator>Kreinovich, Vladik</dc:creator>
 <dc:creator>Baral, Chitta</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Probabilistic Soft Logic has been proposed and used in several applications
as an efficient way to deal with inconsistency, uncertainty and relational
representation. In several applications, this approach has led to an adequate
description of the corresponding human reasoning. In this paper, we provide a
theoretical explanation for one of the semi-heuristic choices made in this
approach: namely, we explain the choice of the corresponding conjunction
operations. Our explanation leads to a more general family of operations which
may be used in future applications of probabilistic soft logic.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06631</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06632</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on Amortized Branching Program Complexity</dc:title>
 <dc:creator>Potechin, Aaron</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In this paper, we show that while almost all functions require exponential
size branching programs to compute, for all functions $f$ there is a branching
program computing a doubly exponential number of copies of $f$ which has linear
size per copy of $f$. This result disproves a conjecture about non-uniform
catalytic computation, rules out a certain type of bottleneck argument for
proving non-monotone space lower bounds, and can be thought of as a
constructive analogue of Razborov's result that submodular complexity measures
have maximum value $O(n)$.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06632</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06638</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Not Afraid of the Dark: NIR-VIS Face Recognition via Cross-spectral
  Hallucination and Low-rank Embedding</dc:title>
 <dc:creator>Lezama, Jose</dc:creator>
 <dc:creator>Qiu, Qiang</dc:creator>
 <dc:creator>Sapiro, Guillermo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Surveillance cameras today often capture NIR (near infrared) images in
low-light environments. However, most face datasets accessible for training and
verification are only collected in the VIS (visible light) spectrum. It remains
a challenging problem to match NIR to VIS face images due to the different
light spectrum. Recently, breakthroughs have been made for VIS face recognition
by applying deep learning on a huge amount of labeled VIS face samples. The
same deep learning approach cannot be simply applied to NIR face recognition
for two main reasons: First, much limited NIR face images are available for
training compared to the VIS spectrum. Second, face galleries to be matched are
mostly available only in the VIS spectrum. In this paper, we propose an
approach to extend the deep learning breakthrough for VIS face recognition to
the NIR spectrum, without retraining the underlying deep models that see only
VIS faces. Our approach consists of two core components, cross-spectral
hallucination and low-rank embedding, to optimize respectively input and output
of a VIS deep model for cross-spectral face recognition. Cross-spectral
hallucination produces VIS faces from NIR images through a deep learning
approach. Low-rank embedding restores a low-rank structure for faces deep
features across both NIR and VIS spectrum. We observe that it is often equally
effective to perform hallucination to input NIR images or low-rank embedding to
output deep features for a VIS deep model for cross-spectral recognition. When
hallucination and low-rank embedding are deployed together, we observe
significant further improvement; we obtain state-of-the-art accuracy on the
CASIA NIR-VIS v2.0 benchmark, without the need at all to re-train the
recognition system.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06638</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06639</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Text Classification Improved by Integrating Bidirectional LSTM with
  Two-dimensional Max Pooling</dc:title>
 <dc:creator>Zhou, Peng</dc:creator>
 <dc:creator>Qi, Zhenyu</dc:creator>
 <dc:creator>Zheng, Suncong</dc:creator>
 <dc:creator>Xu, Jiaming</dc:creator>
 <dc:creator>Bao, Hongyun</dc:creator>
 <dc:creator>Xu, Bo</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recurrent Neural Network (RNN) is one of the most popular architectures used
in Natural Language Processsing (NLP) tasks because its recurrent structure is
very suitable to process variable-length text. RNN can utilize distributed
representations of words by first converting the tokens comprising each text
into vectors, which form a matrix. And this matrix includes two dimensions: the
time-step dimension and the feature vector dimension. Then most existing models
usually utilize one-dimensional (1D) max pooling operation or attention-based
operation only on the time-step dimension to obtain a fixed-length vector.
However, the features on the feature vector dimension are not mutually
independent, and simply applying 1D pooling operation over the time-step
dimension independently may destroy the structure of the feature
representation. On the other hand, applying two-dimensional (2D) pooling
operation over the two dimensions may sample more meaningful features for
sequence modeling tasks. To integrate the features on both dimensions of the
matrix, this paper explores applying 2D max pooling operation to obtain a
fixed-length representation of the text. This paper also utilizes 2D
convolution to sample more meaningful information of the matrix. Experiments
are conducted on six text classification tasks, including sentiment analysis,
question classification, subjectivity classification and newsgroup
classification. Compared with the state-of-the-art models, the proposed models
achieve excellent performance on 4 out of 6 tasks. Specifically, one of the
proposed models achieves highest accuracy on Stanford Sentiment Treebank binary
classification and fine-grained classification tasks.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06641</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phrase Localization and Visual Relationship Detection with Comprehensive
  Image-Language Cues</dc:title>
 <dc:creator>Plummer, Bryan A.</dc:creator>
 <dc:creator>Mallya, Arun</dc:creator>
 <dc:creator>Cervantes, Christopher M.</dc:creator>
 <dc:creator>Hockenmaier, Julia</dc:creator>
 <dc:creator>Lazebnik, Svetlana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a framework for localization or grounding of phrases in
images using a large collection of linguistic and visual cues. We model the
appearance, size, and position of entity bounding boxes, adjectives that
contain attribute information, and spatial relationships between pairs of
entities connected by verbs or prepositions. Special attention is given to
relationships between people and clothing or body part mentions, as they are
useful for distinguishing individuals. We automatically learn weights for
combining these cues and at test time, perform joint inference over all phrases
in a caption. The resulting system produces state of the art performance on
phrase localization on the Flickr30k Entities dataset and visual relationship
detection on the Stanford VRD dataset.
</dc:description>
 <dc:description>Comment: IEEE ICCV 2017 accepted paper</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06642</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cascaded Face Alignment via Intimacy Definition Feature</dc:title>
 <dc:creator>Li, Hailiang</dc:creator>
 <dc:creator>Lam, Kin-Man</dc:creator>
 <dc:creator>Chiu, Edmond M. Y.</dc:creator>
 <dc:creator>Wu, Kangheng</dc:creator>
 <dc:creator>Lei, Zhibin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we present a random-forest based fast cascaded regression
model for face alignment, via a novel local feature. Our proposed local
lightweight feature, namely intimacy definition feature (IDF), is more
discriminative than landmark pose-indexed feature, more efficient than
histogram of oriented gradients (HOG) feature and scale-invariant feature
transform (SIFT) feature, and more compact than the local binary feature (LBF).
Experimental results show that our approach achieves state-of-the-art
performance when tested on the most challenging datasets. Compared with an
LBF-based algorithm, our method can achieve about two times the speed-up and
more than 20% improvement, in terms of alignment accuracy measurement, and save
an order of magnitude of memory requirement.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06642</dc:identifier>
 <dc:identifier>doi:10.1117/1.JEI.26.5.053024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06645</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Community-enhanced Network Representation Learning for Network Analysis</dc:title>
 <dc:creator>Tu, Cunchao</dc:creator>
 <dc:creator>Wang, Hao</dc:creator>
 <dc:creator>Zeng, Xiangkai</dc:creator>
 <dc:creator>Liu, Zhiyuan</dc:creator>
 <dc:creator>Sun, Maosong</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Network representation learning (NRL) aims to build low-dimensional vectors
for vertices in a network. Most existing NRL methods focus on learning
representations from local context of vertices (such as their neighbors).
Nevertheless, vertices in many complex networks also exhibit significant global
patterns widely known as communities. It's a common sense that vertices in the
same community tend to connect densely, and usually share common attributes.
These patterns are expected to improve NRL and benefit relevant evaluation
tasks, such as link prediction and vertex classification. In this work, we
propose a novel NRL model by introducing community information of vertices to
learn more discriminative network representations, named as Community-enhanced
Network Representation Learning (CNRL). CNRL simultaneously detects community
distribution of each vertex and learns embeddings of both vertices and
communities. In this way, we can obtain more informative representation of a
vertex accompanying with its community information. In experiments, we evaluate
the proposed CNRL model on vertex classification, link prediction, and
community detection using several real-world datasets. The results demonstrate
that CNRL significantly and consistently outperforms other state-of-the-art
methods. Meanwhile, the detected meaningful communities verify our assumptions
on the correlations among vertices, sequences, and communities.
</dc:description>
 <dc:description>Comment: 8 pages, 3 tables, 4 figures</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06645</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06646</identifier>
 <datestamp>2017-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Supervised Video Representation Learning With Odd-One-Out Networks</dc:title>
 <dc:creator>Fernando, Basura</dc:creator>
 <dc:creator>Bilen, Hakan</dc:creator>
 <dc:creator>Gavves, Efstratios</dc:creator>
 <dc:creator>Gould, Stephen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a new self-supervised CNN pre-training technique based on a novel
auxiliary task called &quot;odd-one-out learning&quot;. In this task, the machine is
asked to identify the unrelated or odd element from a set of otherwise related
elements. We apply this technique to self-supervised video representation
learning where we sample subsequences from videos and ask the network to learn
to predict the odd video subsequence. The odd video subsequence is sampled such
that it has wrong temporal order of frames while the even ones have the correct
temporal order. Therefore, to generate a odd-one-out question no manual
annotation is required. Our learning machine is implemented as multi-stream
convolutional neural network, which is learned end-to-end. Using odd-one-out
networks, we learn temporal representations for videos that generalizes to
other related tasks such as action recognition.
  On action classification, our method obtains 60.3\% on the UCF101 dataset
using only UCF101 data for training which is approximately 10% better than
current state-of-the-art self-supervised learning methods. Similarly, on HMDB51
dataset we outperform self-supervised state-of-the art methods by 12.7% on
action classification task.
</dc:description>
 <dc:description>Comment: Accepted in In IEEE International Conference on Computer Vision and
  Pattern Recognition CVPR 2017</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:date>2017-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06646</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06650</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trading information complexity for error</dc:title>
 <dc:creator>Dagan, Yuval</dc:creator>
 <dc:creator>Filmus, Yuval</dc:creator>
 <dc:creator>Hatami, Hamed</dc:creator>
 <dc:creator>Li, Yaqiao</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We consider the standard two-party communication model. The central problem
studied in this article is how much one can save in information complexity by
allowing an error of $\epsilon$.
  For arbitrary functions, we obtain lower bounds and upper bounds indicating a
gain that is of order $\Omega(h(\epsilon))$ and $O(h(\sqrt{\epsilon}))$. Here
$h$ denotes the binary entropy function. We analyze the case of the two-bit AND
function in detail to show that for this function the gain is
$\Theta(h(\epsilon))$. This answers a question of [M. Braverman, A. Garg, D.
Pankratov, and O. Weinstein, From information to exact communication (extended
abstract), STOC'13].
  We obtain sharp bounds for the set disjointness function of order $n$. For
the case of the distributional error, we introduce a new protocol that achieves
a gain of $\Theta(\sqrt{h(\epsilon)})$ provided that $n$ is sufficiently large.
We apply these results to answer another of question of Braverman et al.
regarding the randomized communication complexity of the set disjointness
function.
  Answering a question of [Mark Braverman, Interactive information complexity,
STOC'12], we apply our analysis of the set disjointness function to establish a
gap between the two different notions of the prior-free information cost. This
implies that amortized randomized communication complexity is not necessarily
equal to the amortized distributional communication complexity with respect to
the hardest distribution.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06650</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06651</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning for the Classification of Lung Nodules</dc:title>
 <dc:creator>Yang, He</dc:creator>
 <dc:creator>Yu, Hengyong</dc:creator>
 <dc:creator>Wang, Ge</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep learning, as a promising new area of machine learning, has attracted a
rapidly increasing attention in the field of medical imaging. Compared to the
conventional machine learning methods, deep learning requires no hand-tuned
feature extractor, and has shown a superior performance in many visual object
recognition applications. In this study, we develop a deep convolutional neural
network (CNN) and apply it to thoracic CT images for the classification of lung
nodules. We present the CNN architecture and classification accuracy for the
original images of lung nodules. In order to understand the features of lung
nodules, we further construct new datasets, based on the combination of
artificial geometric nodules and some transformations of the original images,
as well as a stochastic nodule shape model. It is found that simplistic
geometric nodules cannot capture the important features of lung nodules.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06652</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Adaptive Stochastic Optimization Using Random Projections</dc:title>
 <dc:creator>Krummenacher, Gabriel</dc:creator>
 <dc:creator>McWilliams, Brian</dc:creator>
 <dc:creator>Kilcher, Yannic</dc:creator>
 <dc:creator>Buhmann, Joachim M.</dc:creator>
 <dc:creator>Meinshausen, Nicolai</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Adaptive stochastic gradient methods such as AdaGrad have gained popularity
in particular for training deep neural networks. The most commonly used and
studied variant maintains a diagonal matrix approximation to second order
information by accumulating past gradients which are used to tune the step size
adaptively. In certain situations the full-matrix variant of AdaGrad is
expected to attain better performance, however in high dimensions it is
computationally impractical. We present Ada-LR and RadaGrad two computationally
efficient approximations to full-matrix AdaGrad based on randomized
dimensionality reduction. They are able to capture dependencies between
features and achieve similar performance to full-matrix AdaGrad but at a much
smaller computational cost. We show that the regret of Ada-LR is close to the
regret of full-matrix AdaGrad which can have an up-to exponentially smaller
dependence on the dimension than the diagonal variant. Empirically, we show
that Ada-LR and RadaGrad perform similarly to full-matrix AdaGrad. On the task
of training convolutional neural networks as well as recurrent neural networks,
RadaGrad achieves faster convergence than diagonal AdaGrad.
</dc:description>
 <dc:description>Comment: To appear in Advances in Neural Information Processing Systems 29
  (NIPS 2016)</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06656</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ResFeats: Residual Network Based Features for Image Classification</dc:title>
 <dc:creator>Mahmood, Ammar</dc:creator>
 <dc:creator>Bennamoun, Mohammed</dc:creator>
 <dc:creator>An, Senjian</dc:creator>
 <dc:creator>Sohel, Ferdous</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep residual networks have recently emerged as the state-of-the-art
architecture in image segmentation and object detection. In this paper, we
propose new image features (called ResFeats) extracted from the last
convolutional layer of deep residual networks pre-trained on ImageNet. We
propose to use ResFeats for diverse image classification tasks namely, object
classification, scene classification and coral classification and show that
ResFeats consistently perform better than their CNN counterparts on these
classification tasks. Since the ResFeats are large feature vectors, we propose
to use PCA for dimensionality reduction. Experimental results are provided to
show the effectiveness of ResFeats with state-of-the-art classification
accuracies on Caltech-101, Caltech-256 and MLC datasets and a significant
performance improvement on MIT-67 dataset compared to the widely used CNN
features.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06656</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06660</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structure of 311 Service Requests as a Signature of Urban Location</dc:title>
 <dc:creator>Wang, Lingjing</dc:creator>
 <dc:creator>Qian, Cheng</dc:creator>
 <dc:creator>Kontokosta, Constantine</dc:creator>
 <dc:creator>Sobolevsky, Stanislav</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  While urban systems demonstrate high spatial heterogeneity, many urban
planning, economic and political decisions heavily rely on a deep understanding
of local neighborhood contexts. We show that the structure of 311 Service
Requests enables one possible way of building a unique signature of the local
urban context, thus being able to serve as a low-cost decision support tool for
urban stakeholders. Considering examples of New York City, Boston and Chicago,
we demonstrate how 311 Service Requests recorded and categorized by type in
each neighborhood can be utilized to generate a meaningful classification of
locations across the city, based on distinctive socioeconomic profiles.
Moreover, the 311-based classification of urban neighborhoods can present
sufficient information to model various socioeconomic features. Finally, we
show that these characteristics are capable of predicting future trends in
comparative local real estate prices. We demonstrate 311 Service Requests data
can be used to monitor and predict socioeconomic performance of urban
neighborhoods, allowing urban stakeholders to quantify the impacts of their
interventions.
</dc:description>
 <dc:description>Comment: 18 pages, 6 figures, 4 tables plus SI</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06661</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gland Instance Segmentation Using Deep Multichannel Neural Networks</dc:title>
 <dc:creator>Xu, Yan</dc:creator>
 <dc:creator>Li, Yang</dc:creator>
 <dc:creator>Wang, Yipei</dc:creator>
 <dc:creator>Liu, Mingyuan</dc:creator>
 <dc:creator>Fan, Yubo</dc:creator>
 <dc:creator>Lai, Maode</dc:creator>
 <dc:creator>Chang, Eric I-Chao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Objective: A new image instance segmentation method is proposed to segment
individual glands (instances) in colon histology images. This process is
challenging since the glands not only need to be segmented from a complex
background, they must also be individually identified. Methods: We leverage the
idea of image-to-image prediction in recent deep learning by designing an
algorithm that automatically exploits and fuses complex multichannel
information - regional, location, and boundary cues - in gland histology
images. Our proposed algorithm, a deep multichannel framework, alleviates heavy
feature design due to the use of convolutional neural networks and is able to
meet multifarious requirements by altering channels. Results: Compared with
methods reported in the 2015 MICCAI Gland Segmentation Challenge and other
currently prevalent instance segmentation methods, we observe state-of-the-art
results based on the evaluation metrics. Conclusion: The proposed deep
multichannel algorithm is an effective method for gland instance segmentation.
Significance: The generalization ability of our model not only enable the
algorithm to solve gland instance segmentation problems, but the channel is
also alternative that can be replaced for a specific task.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1607.04889</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06661</dc:identifier>
 <dc:identifier>IEEE Transactions on Biomedical Engineering, Volume: 64, Issue:
  12, Dec. 2017, Pages: 2901 - 2912</dc:identifier>
 <dc:identifier>doi:10.1109/TBME.2017.2686418</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06668</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Visual and Textual Recurrent Neural Network for Sequential Prediction</dc:title>
 <dc:creator>Cui, Qiang</dc:creator>
 <dc:creator>Wu, Shu</dc:creator>
 <dc:creator>Liu, Qiang</dc:creator>
 <dc:creator>Wang, Liang</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Sequential prediction is a fundamental task for Web applications. Due to the
insufficiency of user feedbacks, sequential prediction usually suffers from the
cold start problem. There are two kinds of popular approaches based on matrix
factorization (MF) and Markov chains (MC) for item prediction. MF methods
factorize the user-item matrix to learn general tastes of users. MC methods
predict the next behavior based on recent behaviors. However, they have
limitations. MF methods can merge additional information to address cold start
but could not capture dynamic properties of user's interest, and MC based
sequential methods have difficulty in addressing cold start and has a strong
Markov assumption that the next state only depends on the last state. In this
work, to deal with the cold start problem of sequential prediction, we propose
a RNN model adopting visual and textual content of items, which is named as
$\mathbf{V}$isual and $\mathbf{T}$extual $\mathbf{R}$ecurrent $\mathbf{N}$eural
$\mathbf{N}$etwork ($\mathbf{VT}$-$\mathbf{RNN}$). We can simultaneously learn
the sequential latent vectors that dynamically capture the user's interest, as
well as content-based representations that contribute to address the cold
start. Experiments on two real-world datasets show that our proposed VT-RNN
model can effectively generate the personalized ranking list and significantly
alleviate the cold start problem.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06668</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06670</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Error analysis of regularized least-square regression with Fredholm
  kernel</dc:title>
 <dc:creator>Tao, Yanfang</dc:creator>
 <dc:creator>Yuan, Peipei</dc:creator>
 <dc:creator>Song, Biqin</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>68Q25, 68T15</dc:subject>
 <dc:description>  Learning with Fredholm kernel has attracted increasing attention recently
since it can effectively utilize the data information to improve the prediction
performance. Despite rapid progress on theoretical and experimental
evaluations, its generalization analysis has not been explored in learning
theory literature. In this paper, we establish the generalization bound of
least square regularized regression with Fredholm kernel, which implies that
the fast learning rate O(l^{-1}) can be reached under mild capacity conditions.
Simulated examples show that this Fredholm regression algorithm can achieve the
satisfactory prediction performance.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06670</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06671</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ontology Driven Disease Incidence Detection on Twitter</dc:title>
 <dc:creator>Magumba, Mark Abraham</dc:creator>
 <dc:creator>Nabende, Peter</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In this work we address the issue of generic automated disease incidence
monitoring on twitter. We employ an ontology of disease related concepts and
use it to obtain a conceptual representation of tweets. Unlike previous key
word based systems and topic modeling approaches, our ontological approach
allows us to apply more stringent criteria for determining which messages are
relevant such as spatial and temporal characteristics whilst giving a stronger
guarantee that the resulting models will perform well on new data that may be
lexically divergent. We achieve this by training learners on concepts rather
than individual words. For training we use a dataset containing mentions of
influenza and Listeria and use the learned models to classify datasets
containing mentions of an arbitrary selection of other diseases. We show that
our ontological approach achieves good performance on this task using a variety
of Natural Language Processing Techniques. We also show that word vectors can
be learned directly from our concepts to achieve even better results.
</dc:description>
 <dc:description>Comment: 19 pages, 7 figures, 1 table</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06671</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06673</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the List-Decodability of Random Self-Orthogonal Codes</dc:title>
 <dc:creator>Jin, Lingfei</dc:creator>
 <dc:creator>Xing, Chaoping</dc:creator>
 <dc:creator>Zhang, Xiande</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In 2011, Guruswami-H{\aa}stad-Kopparty \cite{Gru} showed that the
list-decodability of random linear codes is as good as that of general random
codes. In the present paper, we further strengthen the result by showing that
the list-decodability of random {\it Euclidean self-orthogonal} codes is as
good as that of general random codes as well, i.e., achieves the classical
Gilbert-Varshamov bound. Specifically, we show that, for any fixed finite field
$\F_q$, error fraction $\delta\in (0,1-1/q)$ satisfying $1-H_q(\delta)\le
\frac12$ and small $\epsilon&gt;0$, with high probability a random Euclidean
self-orthogonal code over $\F_q$ of rate $1-H_q(\delta)-\epsilon$ is $(\delta,
O(1/\epsilon))$-list-decodable. This generalizes the result of linear codes to
Euclidean self-orthogonal codes. In addition, we extend the result to list
decoding {\it symplectic dual-containing} codes by showing that the
list-decodability of random symplectic dual-containing codes achieves the
quantum Gilbert-Varshamov bound as well. This implies that list-decodability of
quantum stabilizer codes can achieve the quantum Gilbert-Varshamov bound.
  The counting argument on self-orthogonal codes is an important ingredient to
prove our result.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06673</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06674</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimation of respiratory pattern from video using selective ensemble
  aggregation</dc:title>
 <dc:creator>Prathosh, A. P.</dc:creator>
 <dc:creator>Praveena, Pragathi</dc:creator>
 <dc:creator>Mestha, Lalit K.</dc:creator>
 <dc:creator>Bharadwaj, Sanjay</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Non-contact estimation of respiratory pattern (RP) and respiration rate (RR)
has multiple applications. Existing methods for RP and RR measurement fall into
one of the three categories - (i) estimation through nasal air flow
measurement, (ii) estimation from video-based remote photoplethysmography, and
(iii) estimation by measurement of motion induced by respiration using motion
detectors. These methods, however, require specialized sensors, are
computationally expensive and/or critically depend on selection of a region of
interest (ROI) for processing. In this paper a general framework is described
for estimating a periodic signal driving noisy LTI channels connected in
parallel with unknown dynamics. The method is then applied to derive a
computationally inexpensive method for estimating RP using 2D cameras that does
not critically depend on ROI. Specifically, RP is estimated by imaging the
changes in the reflected light caused by respiration-induced motion. Each
spatial location in the field of view of the camera is modeled as a
noise-corrupted linear time-invariant (LTI) measurement channel with unknown
system dynamics, driven by a single generating respiratory signal. Estimation
of RP is cast as a blind deconvolution problem and is solved through a method
comprising subspace projection and statistical aggregation. Experiments are
carried out on 31 healthy human subjects by generating multiple RPs and
comparing the proposed estimates with simultaneously acquired ground truth from
an impedance pneumograph device. The proposed estimator agrees well with the
ground truth device in terms of correlation measures, despite variability in
clothing pattern, angle of view and ROI.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06674</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2664048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06678</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Temporal Linear Encoding Networks</dc:title>
 <dc:creator>Diba, Ali</dc:creator>
 <dc:creator>Sharma, Vivek</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The CNN-encoding of features from entire videos for the representation of
human actions has rarely been addressed. Instead, CNN work has focused on
approaches to fuse spatial and temporal networks, but these were typically
limited to processing shorter sequences. We present a new video representation,
called temporal linear encoding (TLE) and embedded inside of CNNs as a new
layer, which captures the appearance and motion throughout entire videos. It
encodes this aggregated information into a robust video feature representation,
via end-to-end learning. Advantages of TLEs are: (a) they encode the entire
video into a compact feature representation, learning the semantics and a
discriminative feature space; (b) they are applicable to all kinds of networks
like 2D and 3D CNNs for video classification; and (c) they model feature
interactions in a more expressive way and without loss of information. We
conduct experiments on two challenging human action datasets: HMDB51 and
UCF101. The experiments show that TLE outperforms current state-of-the-art
methods on both datasets.
</dc:description>
 <dc:description>Comment: Ali Diba and Vivek Sharma contributed equally to this work and listed
  in alphabetical order</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06682</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Significance of Mobility on Received Signal Strength: An Experimental
  Investigation</dc:title>
 <dc:creator>Pedapolu, Pavan Kumar</dc:creator>
 <dc:creator>Kumar, Pradeep</dc:creator>
 <dc:creator>Harish, Vaidya</dc:creator>
 <dc:creator>Venturi, Satvik</dc:creator>
 <dc:creator>Bharti, Sushil Kumar</dc:creator>
 <dc:creator>Kumar, Vinay</dc:creator>
 <dc:creator>Kumar, Sudhir</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, estimation of mobility using received signal strength is
presented. In contrast to standard methods, speed can be inferred without the
use of any additional hardware like accelerometer, gyroscope or position
estimator. The strength of Wi-Fi signal is considered herein to compute the
time-domain features such as mean, minimum, maximum, and autocorrelation. The
experiments are carried out in different environments like academic area,
residential area and in open space. The complexity of the algorithm in training
and testing phase are quadratic and linear with the number of Wi-Fi samples
respectively. The experimental results indicate that the average error in the
estimated speed is 12 % when the maximum signal strength features are taken
into account. The proposed method is cost-effective and having a low complexity
with reasonable accuracy in a Wi-Fi or cellular environment. Additionally, the
proposed method is scalable that is the performance is not affected in a
multi-smartphones scenario.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06683</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Covariate conscious approach for Gait recognition based upon Zernike
  moment invariants</dc:title>
 <dc:creator>Aggarwal, Himanshu</dc:creator>
 <dc:creator>Vishwakarma, Dinesh K.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Gait recognition i.e. identification of an individual from his/her walking
pattern is an emerging field. While existing gait recognition techniques
perform satisfactorily in normal walking conditions, there performance tend to
suffer drastically with variations in clothing and carrying conditions. In this
work, we propose a novel covariate cognizant framework to deal with the
presence of such covariates. We describe gait motion by forming a single 2D
spatio-temporal template from video sequence, called Average Energy Silhouette
image (AESI). Zernike moment invariants (ZMIs) are then computed to screen the
parts of AESI infected with covariates. Following this, features are extracted
from Spatial Distribution of Oriented Gradients (SDOGs) and novel Mean of
Directional Pixels (MDPs) methods. The obtained features are fused together to
form the final well-endowed feature set. Experimental evaluation of the
proposed framework on three publicly available datasets i.e. CASIA dataset B,
OU-ISIR Treadmill dataset B and USF Human-ID challenge dataset with recently
published gait recognition approaches, prove its superior performance.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06684</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Duality for Parallel Gibbs Sampling without Graph Coloring</dc:title>
 <dc:creator>Mescheder, Lars</dc:creator>
 <dc:creator>Nowozin, Sebastian</dc:creator>
 <dc:creator>Geiger, Andreas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a new notion of probabilistic duality for random variables
involving mixture distributions. Using this notion, we show how to implement a
highly-parallelizable Gibbs sampler for weakly coupled discrete pairwise
graphical models with strictly positive factors that requires almost no
preprocessing and is easy to implement. Moreover, we show how our method can be
combined with blocking to improve mixing. Even though our method leads to
inferior mixing times compared to a sequential Gibbs sampler, we argue that our
method is still very useful for large dynamic networks, where factors are added
and removed on a continuous basis, as it is hard to maintain a graph coloring
in this setup. Similarly, our method is useful for parallelizing Gibbs sampling
in graphical models that do not allow for graph colorings with a small number
of colors such as densely connected graphs.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06689</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Modality Fusion based on Consensus-Voting and 3D Convolution for
  Isolated Gesture Recognition</dc:title>
 <dc:creator>Duan, Jiali</dc:creator>
 <dc:creator>Zhou, Shuai</dc:creator>
 <dc:creator>Wan, Jun</dc:creator>
 <dc:creator>Guo, Xiaoyuan</dc:creator>
 <dc:creator>Li, Stan Z.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, the popularity of depth-sensors such as Kinect has made depth
videos easily available while its advantages have not been fully exploited.
This paper investigates, for gesture recognition, to explore the spatial and
temporal information complementarily embedded in RGB and depth sequences. We
propose a convolutional twostream consensus voting network (2SCVN) which
explicitly models both the short-term and long-term structure of the RGB
sequences. To alleviate distractions from background, a 3d depth-saliency
ConvNet stream (3DDSN) is aggregated in parallel to identify subtle motion
characteristics. These two components in an unified framework significantly
improve the recognition accuracy. On the challenging Chalearn IsoGD benchmark,
our proposed method outperforms the first place on the leader-board by a large
margin (10.29%) while also achieving the best result on RGBD-HuDaAct dataset
(96.74%). Both quantitative experiments and qualitative analysis shows the
effectiveness of our proposed framework and codes will be released to
facilitate future research.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06689</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06692</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Control of nonlinear switched systems based on validated simulation</dc:title>
 <dc:creator>Co&#xeb;nt, Adrien Le</dc:creator>
 <dc:creator>Sandretto, Julien Alexandre Dit</dc:creator>
 <dc:creator>Chapoutot, Alexandre</dc:creator>
 <dc:creator>Fribourg, Laurent</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We present an algorithm of control synthesis for nonlinear switched systems,
based on an existing procedure of state-space bisection and made available for
nonlinear systems with the help of validated simulation. The use of validated
simulation also permits to take bounded perturbations and varying parameters
into account. It is particularly interesting for safety critical applications,
such as in aeronautical, military or medical fields. The whole approach is
entirely guaranteed and the induced controllers are correct-by-design.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06692</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06694</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training Sparse Neural Networks</dc:title>
 <dc:creator>Srinivas, Suraj</dc:creator>
 <dc:creator>Subramanya, Akshayvarun</dc:creator>
 <dc:creator>Babu, R. Venkatesh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep neural networks with lots of parameters are typically used for
large-scale computer vision tasks such as image classification. This is a
result of using dense matrix multiplications and convolutions. However, sparse
computations are known to be much more efficient. In this work, we train and
build neural networks which implicitly use sparse computations. We introduce
additional gate variables to perform parameter selection and show that this is
equivalent to using a spike-and-slab prior. We experimentally validate our
method on both small and large networks and achieve state-of-the-art
compression results for sparse neural network models.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06703</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Test Sets for Context-Free Languages</dc:title>
 <dc:creator>Mayer, Mika&#xeb;l</dc:creator>
 <dc:creator>Hamza, Jad</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  A test set for a formal language (set of strings) L is a subset T of L such
that for any two string homomorphisms f and g defined on L, if the restrictions
of f and g on T are identical functions, then f and g are identical on the
entire L. Previously, it was shown that there are context-free grammars for
which smallest test sets are cubic in the size of the grammar, which gives a
lower bound on tests set size. Existing upper bounds were higher degree
polynomials; we here give the first algorithm to compute test sets of cubic
size for all context-free grammars, settling the gap between the upper and
lower bound.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06712</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compute-and-Forward in Cell-Free Massive MIMO: Great Performance with
  Low Backhaul Load</dc:title>
 <dc:creator>Huang, Qinhui</dc:creator>
 <dc:creator>Burr, Alister</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider the uplink of cell-free massive MIMO systems,
where a large number of distributed single antenna access points (APs) serve a
much smaller number of users simultaneously via limited backhaul. For the first
time, we investigate the performance of compute-and-forward (C&amp;F) in such an
ultra dense network with a realistic channel model (including fading, pathloss
and shadowing). By utilising the characteristic of pathloss, a low complexity
coefficient selection algorithm for C\&amp;F is proposed. We also give a greedy AP
selection method for message recovery. Additionally, we compare the performance
of C&amp;F to some other promising linear strategies for distributed massive MIMO,
such as small cells (SC) and maximum ratio combining (MRC). Numerical results
reveal that C&amp;F not only reduces the backhaul load, but also significantly
increases the system throughput for the symmetric scenario.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06721</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple Right-Hand Side Techniques in Semi-Explicit Time Integration
  Methods for Transient Eddy Current Problems</dc:title>
 <dc:creator>Dutin&#xe9;, Jennifer</dc:creator>
 <dc:creator>Clemens, Markus</dc:creator>
 <dc:creator>Sch&#xf6;ps, Sebastian</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65L80, 65N30, 78M10, 78A30</dc:subject>
 <dc:subject>G.1.7</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:description>  The spatially discretized magnetic vector potential formulation of
magnetoquasistatic field problems is transformed from an infinitely stiff
differential algebraic equation system into a finitely stiff ordinary
differential equation (ODE) system by application of a generalized Schur
complement for nonconducting parts. The ODE can be integrated in time using
explicit time integration schemes, e.g. the explicit Euler method. This
requires the repeated evaluation of a pseudo-inverse of the discrete curl-curl
matrix in nonconducting material by the preconditioned conjugate gradient (PCG)
method which forms a multiple right-hand side problem. The subspace projection
extrapolation method and proper orthogonal decomposition are compared for the
computation of suitable start vectors in each time step for the PCG method
which reduce the number of iterations and the overall computational costs.
</dc:description>
 <dc:description>Comment: 4 pages, 5 figures</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-09-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06721</dc:identifier>
 <dc:identifier>IEEE Trans. Magn., Volume: 53, Issue: 6, June 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TMAG.2017.2682558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06722</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>False-Friend Detection and Entity Matching via Unsupervised
  Transliteration</dc:title>
 <dc:creator>Chen, Yanqing</dc:creator>
 <dc:creator>Skiena, Steven</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Transliterations play an important role in multilingual entity reference
resolution, because proper names increasingly travel between languages in news
and social media. Previous work associated with machine translation targets
transliteration only single between language pairs, focuses on specific classes
of entities (such as cities and celebrities) and relies on manual curation,
which limits the expression power of transliteration in multilingual
environment.
  By contrast, we present an unsupervised transliteration model covering 69
major languages that can generate good transliterations for arbitrary strings
between any language pair. Our model yields top-(1, 20, 100) averages of
(32.85%, 60.44%, 83.20%) in matching gold standard transliteration compared to
results from a recently-published system of (26.71%, 50.27%, 72.79%). We also
show the quality of our model in detecting true and false friends from
Wikipedia high frequency lexicons. Our method indicates a strong signal of
pronunciation similarity and boosts the probability of finding true friends in
68 out of 69 languages.
</dc:description>
 <dc:description>Comment: 11 Pages, ACL style</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06722</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06728</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numerical optimal control for HIV prevention with dynamic budget
  allocation</dc:title>
 <dc:creator>Gromov, Dmitry</dc:creator>
 <dc:creator>Bulla, Ingo</dc:creator>
 <dc:creator>Romero-Severson, Ethan O.</dc:creator>
 <dc:creator>Serea, Oana Silvia</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  This paper is about numerical control of HIV propagation. The contribution of
the paper is threefold: first, a novel model of HIV propagation is proposed;
second, the methods from numerical optimal control are successfully applied to
the developed model to compute optimal control profiles; finally, the computed
results are applied to the real problem yielding important and practically
relevant results.
</dc:description>
 <dc:description>Comment: Submitted paper</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06728</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06729</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Convergence Time of a Natural Dynamics for Linear Programming</dc:title>
 <dc:creator>Bonifaci, Vincenzo</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68Q05, 90C05</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>G.1.7</dc:subject>
 <dc:description>  We consider a system of nonlinear ordinary differential equations for the
solution of linear programming (LP) problems that was first proposed in the
mathematical biology literature as a model for the foraging behavior of
acellular slime mold Physarum polycephalum, and more recently considered as a
method to solve LPs. We study the convergence time of the continuous Physarum
dynamics in the context of the linear programming problem, and derive a new
time bound to approximate optimality that depends on the relative entropy
between projected versions of the optimal point and of the initial point. The
bound scales logarithmically with the LP cost coefficients and linearly with
the inverse of the relative accuracy, establishing the efficiency of the
dynamics for arbitrary LP instances with positive costs.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06730</identifier>
 <datestamp>2017-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the convergence of gradient-like flows with noisy gradient input</dc:title>
 <dc:creator>Mertikopoulos, Panayotis</dc:creator>
 <dc:creator>Staudigl, Mathias</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>90C25, 60H10 (Primary), 90C15 (Secondary)</dc:subject>
 <dc:description>  In view of solving convex optimization problems with noisy gradient input, we
analyze the asymptotic behavior of gradient-like flows under stochastic
disturbances. Specifically, we focus on the widely studied class of mirror
descent schemes for convex programs with compact feasible regions, and we
examine the dynamics' convergence and concentration properties in the presence
of noise. In the vanishing noise limit, we show that the dynamics converge to
the solution set of the underlying problem (a.s.). Otherwise, when the noise is
persistent, we show that the dynamics are concentrated around interior
solutions in the long run, and they converge to boundary solutions that are
sufficiently &quot;sharp&quot;. Finally, we show that a suitably rectified variant of the
method converges irrespective of the magnitude of the noise (or the structure
of the underlying convex program), and we derive an explicit estimate for its
rate of convergence.
</dc:description>
 <dc:description>Comment: 36 pages, 5 figures; revised proof structure, added numerical case
  study in Section 5</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-09-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06737</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OSSINT - Open Source Social Network Intelligence An efficient and
  effective way to uncover &quot;private&quot; information in OSN profiles</dc:title>
 <dc:creator>Cascavilla, Giuseppe</dc:creator>
 <dc:creator>Beato, Filipe</dc:creator>
 <dc:creator>Burattin, Andrea</dc:creator>
 <dc:creator>Conti, Mauro</dc:creator>
 <dc:creator>Mancini, Luigi Vincenzo</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Online Social Networks (OSNs), such as Facebook, provide users with tools to
share information along with a set of privacy controls preferences to regulate
the spread of information. Current privacy controls are efficient to protect
content data. However, the complexity of tuning them undermine their efficiency
when protecting contextual information (such as the social network structure)
that many users believe being kept private.
  In this paper, we demonstrate the extent of the problem of information
leakage in Facebook. In particular, we show the possibility of inferring, from
the network &quot;surrounding&quot; a victim user, some information that the victim set
as hidden. We developed a system, named OSSINT (Open Source Social Network
INTelligence), on top of our previous tool SocialSpy, that is able to infer
hidden information of a victim profile and retrieve private information from
public one. OSSINT retrieves the friendship network of a victim and shows how
it is possible to infer additional private information (e.g., user personal
preferences and hobbies). Our proposed system OSSINT goes extra mile about the
network topology information, i.e., predicting new friendships using the
victim's friends of friends network (2-hop of distance from the victim
profile), and hence possibly deduce private information of the full Facebook
network. OSSINT correctly improved the previous results of SocialSpy predicting
an average of 11 additional friendships with peaks of 20 new friends. Moreover,
OSSINT, for the considered victim profiles demonstrated how it is possible to
infer real life information such as current city, hometown, university,
supposed being private.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06737</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06748</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crowd Counting by Adapting Convolutional Neural Networks with Side
  Information</dc:title>
 <dc:creator>Kang, Di</dc:creator>
 <dc:creator>Dhar, Debarun</dc:creator>
 <dc:creator>Chan, Antoni B.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Computer vision tasks often have side information available that is helpful
to solve the task. For example, for crowd counting, the camera perspective
(e.g., camera angle and height) gives a clue about the appearance and scale of
people in the scene. While side information has been shown to be useful for
counting systems using traditional hand-crafted features, it has not been fully
utilized in counting systems based on deep learning. In order to incorporate
the available side information, we propose an adaptive convolutional neural
network (ACNN), where the convolutional filter weights adapt to the current
scene context via the side information. In particular, we model the filter
weights as a low-dimensional manifold, parametrized by the side information,
within the high-dimensional space of filter weights. With the help of side
information and adaptive weights, the ACNN can disentangle the variations
related to the side information, and extract discriminative features related to
the current context. Since existing crowd counting datasets do not contain
ground-truth side information, we collect a new dataset with the ground-truth
camera angle and height as the side information. On experiments in crowd
counting, the ACNN improves counting accuracy compared to a plain CNN with a
similar number of parameters. We also apply ACNN to image deconvolution to show
its potential effectiveness on other computer vision applications.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06748</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06757</identifier>
 <datestamp>2017-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Local Color Image Denoising with Convolutional Neural Networks</dc:title>
 <dc:creator>Lefkimmiatis, Stamatios</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We propose a novel deep network architecture for grayscale and color image
denoising that is based on a non-local image model. Our motivation for the
overall design of the proposed network stems from variational methods that
exploit the inherent non-local self-similarity property of natural images. We
build on this concept and introduce deep networks that perform non-local
processing and at the same time they significantly benefit from discriminative
learning. Experiments on the Berkeley segmentation dataset, comparing several
state-of-the-art methods, show that the proposed non-local models achieve the
best reported denoising performance both for grayscale and color images for all
the tested noise levels. It is also worth noting that this increase in
performance comes at no extra cost on the capacity of the network compared to
existing alternative deep network architectures. In addition, we highlight a
direct link of the proposed non-local models to convolutional neural networks.
This connection is of significant importance since it allows our models to take
full advantage of the latest advances on GPU computing in deep learning and
makes them amenable to efficient implementations through their inherent
parallelism.
</dc:description>
 <dc:description>Comment: 15 pages, accepted to CVPR 2017</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06759</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Emergence of Compositional Representations in Restricted Boltzmann
  Machines</dc:title>
 <dc:creator>Tubiana, J&#xe9;r&#xf4;me</dc:creator>
 <dc:creator>Monasson, R&#xe9;mi</dc:creator>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Extracting automatically the complex set of features composing real
high-dimensional data is crucial for achieving high performance in
machine--learning tasks. Restricted Boltzmann Machines (RBM) are empirically
known to be efficient for this purpose, and to be able to generate distributed
and graded representations of the data. We characterize the structural
conditions (sparsity of the weights, low effective temperature, nonlinearities
in the activation functions of hidden units, and adaptation of fields
maintaining the activity in the visible layer) allowing RBM to operate in such
a compositional phase. Evidence is provided by the replica analysis of an
adequate statistical ensemble of random RBMs and by RBM trained on the
handwritten digits dataset MNIST.
</dc:description>
 <dc:description>Comment: Supplementary material available at the authors' webpage</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06759</dc:identifier>
 <dc:identifier>Phys. Rev. Lett. 118, 138301 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.118.138301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06764</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Convolutional Neural Network with Binary Quantization Layer</dc:title>
 <dc:creator>Ravanbakhsh, Mahdyar</dc:creator>
 <dc:creator>Mousavi, Hossein</dc:creator>
 <dc:creator>Nabi, Moin</dc:creator>
 <dc:creator>Marcenaro, Lucio</dc:creator>
 <dc:creator>Regazzoni, Carlo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we introduce a novel method for segmentation that can benefit
from general semantics of Convolutional Neural Network (CNN). Our segmentation
proposes visually and semantically coherent image segments. We use binary
encoding of CNN features to overcome the difficulty of the clustering on the
high-dimensional CNN feature space. These binary encoding can be embedded into
the CNN as an extra layer at the end of the network. This results in real-time
segmentation. To the best of our knowledge our method is the first attempt on
general semantic image segmentation using CNN. All the previous papers were
limited to few number of category of the images (e.g. PASCAL VOC). Experiments
show that our segmentation algorithm outperform the state-of-the-art
non-semantic segmentation methods by a large margin.
</dc:description>
 <dc:description>Comment: Workshop on Efficient Methods for Deep Neural Networks (EMDNN), NIPS
  2016, Barcelona, Spain. arXiv admin note: substantial text overlap with
  arXiv:1609.09220</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06768</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Symmetries of Canal Surfaces and Dupin Cyclides</dc:title>
 <dc:creator>Alc&#xe1;zar, Juan Gerardo</dc:creator>
 <dc:creator>Dahl, Heidi E. I.</dc:creator>
 <dc:creator>Muntingh, Georg</dc:creator>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>14Q10, 68W30</dc:subject>
 <dc:description>  We develop a characterization for the existence of symmetries of canal
surfaces defined by a rational spine curve and rational radius function. In
turn, this characterization inspires an algorithm for computing the symmetries
of such canal surfaces. For Dupin cyclides in canonical form, we apply the
characterization to derive an intrinsic description of their symmetries and
symmetry groups, which gives rise to a method for computing the symmetries of a
Dupin cyclide not necessarily in canonical form. As a final application, we
discuss the construction of patches and blends of rational canal surfaces with
a prescribed symmetry.
</dc:description>
 <dc:description>Comment: 27 pages</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06768</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06777</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effective Deterministic Initialization for $k$-Means-Like Methods via
  Local Density Peaks Searching</dc:title>
 <dc:creator>Li, Fengfu</dc:creator>
 <dc:creator>Qiao, Hong</dc:creator>
 <dc:creator>Zhang, Bo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The $k$-means clustering algorithm is popular but has the following main
drawbacks: 1) the number of clusters, $k$, needs to be provided by the user in
advance, 2) it can easily reach local minima with randomly selected initial
centers, 3) it is sensitive to outliers, and 4) it can only deal with well
separated hyperspherical clusters. In this paper, we propose a Local Density
Peaks Searching (LDPS) initialization framework to address these issues. The
LDPS framework includes two basic components: one of them is the local density
that characterizes the density distribution of a data set, and the other is the
local distinctiveness index (LDI) which we introduce to characterize how
distinctive a data point is compared with its neighbors. Based on these two
components, we search for the local density peaks which are characterized with
high local densities and high LDIs to deal with 1) and 2). Moreover, we detect
outliers characterized with low local densities but high LDIs, and exclude them
out before clustering begins. Finally, we apply the LDPS initialization
framework to $k$-medoids, which is a variant of $k$-means and chooses data
samples as centers, with diverse similarity measures other than the Euclidean
distance to fix the last drawback of $k$-means. Combining the LDPS
initialization framework with $k$-means and $k$-medoids, we obtain two novel
clustering methods called LDPS-means and LDPS-medoids, respectively.
Experiments on synthetic data sets verify the effectiveness of the proposed
methods, especially when the ground truth of the cluster number $k$ is large.
Further, experiments on several real world data sets, Handwritten Pendigits,
Coil-20, Coil-100 and Olivetti Face Database, illustrate that our methods give
a superior performance than the analogous approaches on both estimating $k$ and
unsupervised object categorization.
</dc:description>
 <dc:description>Comment: 16 pages, 9 figures, journal paper</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06777</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06779</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TextBoxes: A Fast Text Detector with a Single Deep Neural Network</dc:title>
 <dc:creator>Liao, Minghui</dc:creator>
 <dc:creator>Shi, Baoguang</dc:creator>
 <dc:creator>Bai, Xiang</dc:creator>
 <dc:creator>Wang, Xinggang</dc:creator>
 <dc:creator>Liu, Wenyu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents an end-to-end trainable fast scene text detector, named
TextBoxes, which detects scene text with both high accuracy and efficiency in a
single network forward pass, involving no post-process except for a standard
non-maximum suppression. TextBoxes outperforms competing methods in terms of
text localization accuracy and is much faster, taking only 0.09s per image in a
fast implementation. Furthermore, combined with a text recognizer, TextBoxes
significantly outperforms state-of-the-art approaches on word spotting and
end-to-end text recognition tasks.
</dc:description>
 <dc:description>Comment: Accepted by AAAI2017</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06779</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06785</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MAP-Me: Managing Anchor-less Producer Mobility in Information-Centric
  Networks</dc:title>
 <dc:creator>Aug&#xe9;, Jordan</dc:creator>
 <dc:creator>Carofiglio, Giovanna</dc:creator>
 <dc:creator>Grassi, Giulio</dc:creator>
 <dc:creator>Muscariello, Luca</dc:creator>
 <dc:creator>Pau, Giovanni</dc:creator>
 <dc:creator>Zeng, Xuan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Mobility has become a basic premise of network communications, thereby
requiring a native integration into 5G networks. Despite the numerous efforts
to propose and to standardize effective mobility management models for IP, the
result is a complex, poorly flexible set of mechanisms. The natural support for
mobility offered by ICN (Information Centric Networking), makes it a good
candidate to define a radically new solution relieving limitations of
traditional approaches. If consumer mobility is supported in ICN by design, in
virtue of its connectionless pull-based communication model, producer mobility
is still an open challenge. In this work, we propose MAP-Me, an anchor-less
solution to manage micro mobility of content producer via ICN name-based data
plane, with support for latency-sensitive applications. First, we analyze
MAP-Me performance and provide guarantees of correctness and stability.
Further, we set up a realistic simulation environment in NDNSim 2.1 for MAP-Me
evaluation and comparison against existing solutions: either random waypoint
and trace-driven car mobility patterns are considered under 802.11 radio
access. Results are encouraging and highlight the superiority of MAP-Me in
terms of user performance and of network cost metrics.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06785</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06788</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bidirectional Tree-Structured LSTM with Head Lexicalization</dc:title>
 <dc:creator>Teng, Zhiyang</dc:creator>
 <dc:creator>Zhang, Yue</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Sequential LSTM has been extended to model tree structures, giving
competitive results for a number of tasks. Existing methods model constituent
trees by bottom-up combinations of constituent nodes, making direct use of
input word information only for leaf nodes. This is different from sequential
LSTMs, which contain reference to input words for each node. In this paper, we
propose a method for automatic head-lexicalization for tree-structure LSTMs,
propagating head words from leaf nodes to every constituent node. In addition,
enabled by head lexicalization, we build a tree LSTM in the top-down direction,
which corresponds to bidirectional sequential LSTM structurally. Experiments
show that both extensions give better representations of tree structures. Our
final model gives the best results on the Standford Sentiment Treebank and
highly competitive results on the TREC question type classification task.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06791</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Dropout</dc:title>
 <dc:creator>Srinivas, Suraj</dc:creator>
 <dc:creator>Babu, R. Venkatesh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deep Neural Networks often require good regularizers to generalize well.
Dropout is one such regularizer that is widely used among Deep Learning
practitioners. Recent work has shown that Dropout can also be viewed as
performing Approximate Bayesian Inference over the network parameters. In this
work, we generalize this notion and introduce a rich family of regularizers
which we call Generalized Dropout. One set of methods in this family, called
Dropout++, is a version of Dropout with trainable parameters. Classical Dropout
emerges as a special case of this method. Another member of this family selects
the width of neural network layers. Experiments show that these methods help in
improving generalization performance over Dropout.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06791</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06792</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Information Retrieval: A Literature Review</dc:title>
 <dc:creator>Zhang, Ye</dc:creator>
 <dc:creator>Rahman, Md Mustafizur</dc:creator>
 <dc:creator>Braylan, Alex</dc:creator>
 <dc:creator>Dang, Brandon</dc:creator>
 <dc:creator>Chang, Heng-Lu</dc:creator>
 <dc:creator>Kim, Henna</dc:creator>
 <dc:creator>McNamara, Quinten</dc:creator>
 <dc:creator>Angert, Aaron</dc:creator>
 <dc:creator>Banner, Edward</dc:creator>
 <dc:creator>Khetan, Vivek</dc:creator>
 <dc:creator>McDonnell, Tyler</dc:creator>
 <dc:creator>Nguyen, An Thanh</dc:creator>
 <dc:creator>Xu, Dan</dc:creator>
 <dc:creator>Wallace, Byron C.</dc:creator>
 <dc:creator>Lease, Matthew</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  A recent &quot;third wave&quot; of Neural Network (NN) approaches now delivers
state-of-the-art performance in many machine learning tasks, spanning speech
recognition, computer vision, and natural language processing. Because these
modern NNs often comprise multiple interconnected layers, this new NN research
is often referred to as deep learning. Stemming from this tide of NN work, a
number of researchers have recently begun to investigate NN approaches to
Information Retrieval (IR). While deep NNs have yet to achieve the same level
of success in IR as seen in other areas, the recent surge of interest and work
in NNs for IR suggest that this state of affairs may be quickly changing. In
this work, we survey the current landscape of Neural IR research, paying
special attention to the use of learned representations of queries and
documents (i.e., neural embeddings). We highlight the successes of neural IR
thus far, catalog obstacles to its wider adoption, and suggest potentially
promising directions for future research.
</dc:description>
 <dc:description>Comment: 44 pages</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06795</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A randomized polynomial kernelization for Vertex Cover with a smaller
  parameter</dc:title>
 <dc:creator>Kratsch, Stefan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In the Vertex Cover problem we are given a graph $G=(V,E)$ and an integer $k$
and have to determine whether there is a set $X\subseteq V$ of size at most $k$
such that each edge in $E$ has at least one endpoint in $X$. The problem can be
easily solved in time $O^*(2^k)$, making it fixed-parameter tractable (FPT)
with respect to $k$. While the fastest known algorithm takes only time
$O^*(1.2738^k)$, much stronger improvements have been obtained by studying
parameters that are smaller than $k$. Apart from treewidth-related results, the
arguably best algorithm for Vertex Cover runs in time $O^*(2.3146^p)$, where
$p=k-LP(G)$ is only the excess of the solution size $k$ over the best
fractional vertex cover (Lokshtanov et al.\ TALG 2014). Since $p\leq k$ but $k$
cannot be bounded in terms of $p$ alone, this strictly increases the range of
tractable instances.
  Recently, Garg and Philip (SODA 2016) greatly contributed to understanding
the parameterized complexity of the Vertex Cover problem. They prove that
$2LP(G)-MM(G)$ is a lower bound for the vertex cover size of $G$, where $MM(G)$
is the size of a largest matching of $G$, and proceed to study parameter
$\ell=k-(2LP(G)-MM(G))$. They give an algorithm of running time $O^*(3^\ell)$,
proving that Vertex Cover is FPT in $\ell$. It can be easily observed that
$\ell\leq p$ whereas $p$ cannot be bounded in terms of $\ell$ alone. We
complement the work of Garg and Philip by proving that Vertex Cover admits a
randomized polynomial kernelization in terms of $\ell$, i.e., an efficient
preprocessing to size polynomial in $\ell$. This improves over parameter
$p=k-LP(G)$ for which this was previously known (Kratsch and Wahlstr\&quot;om FOCS
2012).
</dc:description>
 <dc:description>Comment: Full version of ESA 2016 paper</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06795</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06796</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Demonstration of a context-switch method for heterogeneous
  reconfigurable systems</dc:title>
 <dc:creator>Wicaksana, Arief</dc:creator>
 <dc:creator>Bourge, Alban</dc:creator>
 <dc:creator>Muller, Olivier</dc:creator>
 <dc:creator>Rousseau, Fr&#xe9;d&#xe9;ric</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Nowadays, FPGAs are integrated in high-performance computing systems,
servers, or even used as accelerators in System-on-Chip (SoC) platforms. Since
the execution is performed in hardware, FPGA gives much higher performance and
lower energy consumption compared to most microprocessor-based systems.
However, the room to improve FPGA performance still exists, e.g. when it is
used by multiple users. In multi-user approaches, FPGA resources are shared
between several users. Therefore, one must be able to interrupt a running
circuit at any given time and continue the task at will. An image of the state
of the running circuit (context) is saved during interruption and restored when
the execution is continued. The ability to extract and restore the context is
known as context-switch.In the previous work [1], an automatic checkpoint
selection method is proposed for circuit generation targeting reconfigurable
systems. The method relies on static analysis of the finite state machine of a
circuit to select the checkpoint states. States with minimum overhead will be
selected as checkpoints, which allow optimal context save and restore. The
maximum time to reach a checkpoint will be defined by the user and consideredas
the context-switch latency. The method is implemented in C code and integrated
as plugin in a free and open-source High-Level Synthesis tool AUGH [2].
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06796</dc:identifier>
 <dc:identifier>2016 26th International Conference on Field Programmable Logic and
  Applications (FPL), Aug 2016, Lausanne, Switzerland. pp.1 - 1, 2016</dc:identifier>
 <dc:identifier>doi:10.1109/FPL.2016.7577384</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06815</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uniquely restricted matchings and edge colorings</dc:title>
 <dc:creator>Baste, Julien</dc:creator>
 <dc:creator>Rautenbach, Dieter</dc:creator>
 <dc:creator>Sau, Ignasi</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>05C70</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  A matching in a graph is uniquely restricted if no other matching covers
exactly the same set of vertices. This notion was defined by Golumbic, Hirst,
and Lewenstein and studied in a number of articles. Our contribution is
twofold. We provide approximation algorithms for computing a uniquely
restricted matching of maximum size in some bipartite graphs. In particular, we
achieve a ratio of $9/5$ for subcubic bipartite graphs, improving over a
$2$-approximation algorithm proposed by Mishra. Furthermore, we study the
uniquely restricted chromatic index of a graph, defined as the minimum number
of uniquely restricted matchings into which its edge set can be partitioned. We
provide tight upper bounds in terms of the maximum degree and characterize all
extremal graphs. Our constructive proofs yield efficient algorithms to
determine the corresponding edge colorings.
</dc:description>
 <dc:description>Comment: 23 pages, 11 figures</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06815</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06816</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Service-Oriented Sharding with Aspen</dc:title>
 <dc:creator>Gencer, Adem Efe</dc:creator>
 <dc:creator>van Renesse, Robbert</dc:creator>
 <dc:creator>Sirer, Emin G&#xfc;n</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The rise of blockchain-based cryptocurrencies has led to an explosion of
services using distributed ledgers as their underlying infrastructure. However,
due to inherently single-service oriented blockchain protocols, such services
can bloat the existing ledgers, fail to provide sufficient security, or
completely forego the property of trustless auditability. Security concerns,
trust restrictions, and scalability limits regarding the resource requirements
of users hamper the sustainable development of loosely-coupled services on
blockchains.
  This paper introduces Aspen, a sharded blockchain protocol designed to
securely scale with increasing number of services. Aspen shares the same trust
model as Bitcoin in a peer-to-peer network that is prone to extreme churn
containing Byzantine participants. It enables introduction of new services
without compromising the security, leveraging the trust assumptions, or
flooding users with irrelevant messages.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06822</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communications and Signals Design for Wireless Power Transmission</dc:title>
 <dc:creator>Zeng, Yong</dc:creator>
 <dc:creator>Clerckx, Bruno</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Radiative wireless power transfer (WPT) is a promising technology to provide
cost-effective and real-time power supplies to wireless devices. Although
radiative WPT shares many similar characteristics with the extensively studied
wireless information transfer or communication, they also differ significantly
in terms of design objectives, transmitter/receiver architectures and hardware
constraints, etc. In this article, we first give an overview on the various WPT
technologies, the historical development of the radiative WPT technology and
the main challenges in designing contemporary radiative WPT systems. Then, we
focus on discussing the new communication and signal processing techniques that
can be applied to tackle these challenges. Topics discussed include energy
harvester modeling, energy beamforming for WPT, channel acquisition, power
region characterization in multi-user WPT, waveform design with linear and
non-linear energy receiver model, safety and health issues of WPT, massive MIMO
(multiple-input multiple-output) and millimeter wave (mmWave) enabled WPT,
wireless charging control, and wireless power and communication systems
co-design. We also point out directions that are promising for future research.
</dc:description>
 <dc:description>Comment: Invited tutorial paper, submitted for publication, 26 pages, 11
  figures</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06824</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Options Discovery with Budgeted Reinforcement Learning</dc:title>
 <dc:creator>L&#xe9;on, Aur&#xe9;lia</dc:creator>
 <dc:creator>Denoyer, Ludovic</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We consider the problem of learning hierarchical policies for Reinforcement
Learning able to discover options, an option corresponding to a sub-policy over
a set of primitive actions. Different models have been proposed during the last
decade that usually rely on a predefined set of options. We specifically
address the problem of automatically discovering options in decision processes.
We describe a new learning model called Budgeted Option Neural Network (BONN)
able to discover options based on a budgeted learning objective. The BONN model
is evaluated on different classical RL problems, demonstrating both
quantitative and qualitative interesting results.
</dc:description>
 <dc:description>Comment: Under review as a conference paper at IJCAI 2017</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06824</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06831</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rhythms of the collective brain: Metastable synchronization and
  cross-scale interactions in connected multitudes</dc:title>
 <dc:creator>Aguilera, Miguel</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Crowd behaviour challenges our fundamental understanding of social phenomena.
Involving complex interactions between multiple temporal and spatial scales of
activity, its governing mechanisms defy conventional analysis. Using 1.5
million Twitter messages from the 15M movement in Spain as an example of
multitudinous self-organization, we describe the coordination dynamics of the
system measuring phase-locking statistics at different frequencies using
wavelet transforms, identifying 8 frequency bands of entrained oscillations
between 15 geographical nodes. Then we apply maximum entropy inference methods
to describe Ising models capturing transient synchrony in our data at each
frequency band. The models show that 1) all frequency bands of the system
operate near critical points of their parameter space and 2) while fast
frequencies present only a few metastable states displaying all-or-none
synchronization, slow frequencies present a diversity of metastable states of
partial synchronization. Furthermore, describing the state at each frequency
band using the energy of the corresponding Ising model, we compute transfer
entropy to characterize cross-scale interactions between frequency bands,
showing 1) a cascade of upward information flows in which each frequency band
influences its contiguous slower bands and 2) downward information flows where
slow frequencies modulate distant fast frequencies.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06831</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06833</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phragm\'en's sequential method with a variance criterion</dc:title>
 <dc:creator>Mora, Xavier</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  A variant of Phragm\'en's method for proportional representation via approval
voting is briefly explored. Instead of D'Hondt's rule, this variant generalizes
Sainte-Lagu\&quot;e's rule.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06833</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06840</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimal and Reduced Reversible Automata</dc:title>
 <dc:creator>Lavado, Giovanna J.</dc:creator>
 <dc:creator>Pighizzini, Giovanni</dc:creator>
 <dc:creator>Prigioniero, Luca</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>68Q45</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.4.3</dc:subject>
 <dc:description>  A condition characterizing the class of regular languages which have several
nonisomorphic minimal reversible automata is presented. The condition concerns
the structure of the minimum automaton accepting the language under
consideration. It is also observed that there exist reduced reversible automata
which are not minimal, in the sense that all the automata obtained by merging
some of their equivalent states are irreversible. Furthermore, a sufficient
condition for the existence of infinitely many reduced reversible automata
accepting a same language is given. It is also proved that, when the language
is accepted by a unique minimal reversible automaton (that does not necessarily
coincide with the minimum deterministic automaton), then no other reduced
reversible automata accepting it can exist.
</dc:description>
 <dc:description>Comment: Preliminary version presented at DCFS 2016 --- Descriptional
  Complexity of Formal Systems, Bucharest, Romania, Jul 5-8, 2016</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06840</dc:identifier>
 <dc:identifier>Lectures Notes in Computer Science, 9777, pp. 168---179, Springer,
  2016</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-41114-9_13</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06845</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Distribution of Optimal Strategies in Symmetric Zero-sum Games</dc:title>
 <dc:creator>Brandl, Florian</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>91A05</dc:subject>
 <dc:description>  Given a skew-symmetric matrix, the corresponding two-player symmetric
zero-sum game is defined as follows: one player, the row player, chooses a row
and the other player, the column player, chooses a column. The payoff of the
row player is given by the corresponding matrix entry, the column player
receives the negative of the row player. A randomized strategy is optimal if it
guarantees an expected payoff of at least 0 for a player independently of the
strategy of the other player. We determine the probability that an optimal
strategy randomizes over a given set of actions when the game is drawn from a
distribution that satisfies certain regularity conditions. The regularity
conditions are quite general and apply to a wide range of natural
distributions.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:date>2017-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06845</dc:identifier>
 <dc:identifier>doi:10.1016/j.geb.2017.06.017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06858</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Do We Elect Committees For? A Voting Committee Model for
  Multi-Winner Rules</dc:title>
 <dc:creator>Skowron, Piotr</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We present a new model that describes the process of electing a group of
representatives (e.g., a parliament) for a group of voters. In this model,
called the voting committee model, the elected group of representatives runs a
number of ballots to make final decisions regarding various issues. The
satisfaction of voters comes from the final decisions made by the elected
committee. Our results suggest that depending on a decision system used by the
committee to make these final decisions, different multi-winner election rules
are most suitable for electing the committee. Furthermore, we show that if we
allow not only a committee, but also an election rule used to make final
decisions, to depend on the voters' preferences, we can obtain an even better
representation of the voters.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06858</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06863</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic structure discovery in time series data</dc:title>
 <dc:creator>Janz, David</dc:creator>
 <dc:creator>Paige, Brooks</dc:creator>
 <dc:creator>Rainforth, Tom</dc:creator>
 <dc:creator>van de Meent, Jan-Willem</dc:creator>
 <dc:creator>Wood, Frank</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Existing methods for structure discovery in time series data construct
interpretable, compositional kernels for Gaussian process regression models.
While the learned Gaussian process model provides posterior mean and variance
estimates, typically the structure is learned via a greedy optimization
procedure. This restricts the space of possible solutions and leads to
over-confident uncertainty estimates. We introduce a fully Bayesian approach,
inferring a full posterior over structures, which more reliably captures the
uncertainty of the model.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06863</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06864</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Population Protocols with Faulty Interactions: the Impact of a Leader</dc:title>
 <dc:creator>Di Luna, Giuseppe Antonio</dc:creator>
 <dc:creator>Flocchini, Paola</dc:creator>
 <dc:creator>Izumi, Taisuke</dc:creator>
 <dc:creator>Izumi, Tomoko</dc:creator>
 <dc:creator>Santoro, Nicola</dc:creator>
 <dc:creator>Viglietta, Giovanni</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We consider the problem of simulating traditional population protocols under
weaker models of communication, which include one-way interactions (as opposed
to two-way interactions) and omission faults (i.e., failure by an agent to read
its partner's state during an interaction), which in turn may be detectable or
undetectable. We focus on the impact of a leader, and we give a complete
characterization of the models in which the presence of a unique leader in the
system allows the construction of simulators: when simulations are possible, we
give explicit protocols; when they are not, we give proofs of impossibility.
Specifically, if each agent has only a finite amount of memory, the simulation
is possible only if there are no omission faults. If agents have an unbounded
amount of memory, the simulation is possible as long as omissions are
detectable. If an upper bound on the number of omissions involving the leader
is known, the simulation is always possible, except in the one-way model in
which one side is unable to detect the interaction.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06868</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Frequency Modeling and Simulation of a Single-Phase Three-Winding
  Transformer Including Taps in Regulating Winding</dc:title>
 <dc:creator>Gustavsen, Bjorn</dc:creator>
 <dc:creator>Portillo, Alvaro</dc:creator>
 <dc:creator>Ronchi, Rodrigo</dc:creator>
 <dc:creator>Mjelve, Asgeir</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Transformer terminal equivalents obtained via admittance measurements are
suitable for simulating high-frequency transient interaction between the
transformer and the network. This paper augments the terminal equivalent
approach with a measurement-based voltage transfer function model which permits
calculation of voltages at internal points in the regulating winding. The
approach is demonstrated for a single-phase three-winding transformer in tap
position Nom+ with inclusion of three internal points in the regulating winding
that represent the mid-point and the two extreme ends. The terminal equivalent
modeling makes use of additional common-mode measurements to avoid error
magnifications to result from the ungrounded tertiary winding. The final model
is used in a time domain simulation where ground-fault initiation results in a
resonant voltage build-up in the winding. It is shown that that the peak value
of the resonant overvoltage can be higher than during the lightning impulse
test, with unfavorable network conditions. Additional measurements show that
the selected tap position affects the terminal behavior of the transformer,
changing the frequency and peak value of the lower resonance point in the
voltage transfer between windings.
</dc:description>
 <dc:description>Comment: 8 pages, 21 figures, to be submitted to IEEE Transactions on Power
  Delivery</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06875</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Throughput analysis in networks of WLANs</dc:title>
 <dc:creator>Bellalta, Boris</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper proposes a simple but accurate approximation to analytically model
both the inter-WLANs (Wireless Local Area Networks) interactions and the
negative effect of collisions in networks of IEEE 802.11 WLANs. Inter-WLANs
interactions are characterized using a continuous time Markov chain (CTMC)
model where states represent the set of active WLANs at a given time. Then, the
effect of collisions is considered by analyzing the local dynamics between
contending WLANs at every state using the well-known IEEE 802.11 Bianchi model.
Results confirm the accuracy of the presented approach.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06875</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06878</identifier>
 <datestamp>2017-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SANet: Structure-Aware Network for Visual Tracking</dc:title>
 <dc:creator>Fan, Heng</dc:creator>
 <dc:creator>Ling, Haibin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural network (CNN) has drawn increasing interest in visual
tracking owing to its powerfulness in feature extraction. Most existing
CNN-based trackers treat tracking as a classification problem. However, these
trackers are sensitive to similar distractors because their CNN models mainly
focus on inter-class classification. To address this problem, we use
self-structure information of object to distinguish it from distractors.
Specifically, we utilize recurrent neural network (RNN) to model object
structure, and incorporate it into CNN to improve its robustness to similar
distractors. Considering that convolutional layers in different levels
characterize the object from different perspectives, we use multiple RNNs to
model object structure in different levels respectively. Extensive experiments
on three benchmarks, OTB100, TC-128 and VOT2015, show that the proposed
algorithm outperforms other methods. Code is released at
http://www.dabi.temple.edu/~hbling/code/SANet/SANet.html.
</dc:description>
 <dc:description>Comment: In CVPR Deep Vision Workshop, 2017</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-05-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06878</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06880</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The subset-matched Jaccard index for evaluation of Segmentation for
  Plant Images</dc:title>
 <dc:creator>Bell, Jonathan</dc:creator>
 <dc:creator>Dee, Hannah M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We describe a new measure for the evaluation of region level segmentation of
objects, as applied to evaluating the accuracy of leaf-level segmentation of
plant images. The proposed approach enforces the rule that a region (e.g. a
leaf) in either the image being evaluated or the ground truth image evaluated
against can be mapped to no more than one region in the other image. We call
this measure the subset-matched Jaccard index.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06880</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06882</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning From Graph Neighborhoods Using LSTMs</dc:title>
 <dc:creator>Agrawal, Rakshit</dc:creator>
 <dc:creator>de Alfaro, Luca</dc:creator>
 <dc:creator>Polychronopoulos, Vassilis</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Many prediction problems can be phrased as inferences over local
neighborhoods of graphs. The graph represents the interaction between entities,
and the neighborhood of each entity contains information that allows the
inferences or predictions. We present an approach for applying machine learning
directly to such graph neighborhoods, yielding predicitons for graph nodes on
the basis of the structure of their local neighborhood and the features of the
nodes in it. Our approach allows predictions to be learned directly from
examples, bypassing the step of creating and tuning an inference model or
summarizing the neighborhoods via a fixed set of hand-crafted features. The
approach is based on a multi-level architecture built from Long Short-Term
Memory neural nets (LSTMs); the LSTMs learn how to summarize the neighborhood
from data. We demonstrate the effectiveness of the proposed technique on a
synthetic example and on real-world data related to crowdsourced grading,
Bitcoin transactions, and Wikipedia edit reversions.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06892</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bidiagonalization with Parallel Tiled Algorithms</dc:title>
 <dc:creator>Faverge, Mathieu</dc:creator>
 <dc:creator>Langou, Julien</dc:creator>
 <dc:creator>Robert, Yves</dc:creator>
 <dc:creator>Dongarra, Jack</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Rings and Algebras</dc:subject>
 <dc:description>  We consider algorithms for going from a &quot;full&quot; matrix to a condensed &quot;band
bidiagonal&quot; form using orthogonal transformations. We use the framework of
&quot;algorithms by tiles&quot;. Within this framework, we study: (i) the tiled
bidiagonalization algorithm BiDiag, which is a tiled version of the standard
scalar bidiagonalization algorithm; and (ii) the R-bidiagonalization algorithm
R-BiDiag, which is a tiled version of the algorithm which consists in first
performing the QR factorization of the initial matrix, then performing the
band-bidiagonalization of the R-factor. For both bidiagonalization algorithms
BiDiag and R-BiDiag, we use four main types of reduction trees, namely FlatTS,
FlatTT, Greedy, and a newly introduced auto-adaptive tree, Auto. We provide a
study of critical path lengths for these tiled algorithms, which shows that (i)
R-BiDiag has a shorter critical path length than BiDiag for tall and skinny
matrices, and (ii) Greedy based schemes are much better than earlier proposed
variants with unbounded resources. We provide experiments on a single multicore
node, and on a few multicore nodes of a parallel distributed shared-memory
system, to show the superiority of the new algorithms on a variety of matrix
sizes, matrix shapes and core counts.
</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06892</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06904</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Isolario: a Do-ut-des Approach to Improve the Appeal of BGP Route
  Collecting</dc:title>
 <dc:creator>Gregori, Enrico</dc:creator>
 <dc:creator>Improta, Alessandro</dc:creator>
 <dc:creator>Sani, Luca</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The incompleteness of data collected from BGP route collecting projects is a
well-known issue which potentially affects every research activity carried out
on the analysis of the Internet inter-domain routing. Recent works explained
that one of the possible solutions is to increase the number of ASes feeding
these projects from the Internet periphery, in order to reveal the hidden
portion of peering connectivity of their upstream providers. The main problem
is that these projects are currently not appealing enough for the network
administrators of these ASes, which are typically not aware of their existence
or not interested enough to share their data. Our contribution is Isolario, a
project based on the do-ut-des principle which aims at persuading network
administrators to share their routing information by offering services in
return, ranging from real-time analyses of the incoming BGP session(s) to
historic analyses of routing reachability. To the best of our knowledge,
Isolario is the only route collecting project publicly available which offers a
set of services to its users to encourage their participation, aiming at
increasing the amount of BGP data publicly available for research purposes.
</dc:description>
 <dc:description>Comment: Technical report</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06905</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Security Schemes in Vehicular Ad hoc Networks with Cognitive Radios</dc:title>
 <dc:creator>Wei, Zhexiong</dc:creator>
 <dc:creator>Yu, F. Richard</dc:creator>
 <dc:creator>Tang, Helen</dc:creator>
 <dc:creator>Liang, Chengchao</dc:creator>
 <dc:creator>Yan, Qiao</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Vehicular Ad hoc NETworks (VANETs) as the basic infrastructure can facilitate
applications and services of connected vehicles (CVs). Cognitive radio (CR)
technology is an effective supplement and enhancement for VANETs. It can reduce
the impact of deficiency of spectrum resource in VANETs. Although CR-VANETs can
utilize the unused licensed spectrum effectively, the distributed nature of
CR-VANETs may open a door for different attacks, such as spectrum sensing data
falsification attack. In this paper, we propose a joint RSU and vehicle-based
light-weighted cloud for CR-VANETs. Based on this cloud computing model, we
propose a new service named Spectrum Sensing as a Service (SSaaS), which can
perform a cooperative spectrum sensing in CR-VANETs with cloud computing
assistance to secure the spectrum sensing procedure. As a result, a reliable
service can be obtained in CR-VANETs. Simulation results show that the cloud
computing in CR-VANETs can effectively reduce latency and improve the security
of CR-VANETs.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06906</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Scale Anisotropic Fourth-Order Diffusion Improves Ridge and Valley
  Localization</dc:title>
 <dc:creator>Zadeh, Shekoufeh Gorgi</dc:creator>
 <dc:creator>Didas, Stephan</dc:creator>
 <dc:creator>Wintergerst, Maximilian W. M.</dc:creator>
 <dc:creator>Schultz, Thomas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Ridge and valley enhancing filters are widely used in applications such as
vessel detection in medical image computing. When images are degraded by noise
or include vessels at different scales, such filters are an essential step for
meaningful and stable vessel localization. In this work, we propose a novel
multi-scale anisotropic fourth-order diffusion equation that allows us to
smooth along vessels, while sharpening them in the orthogonal direction. The
proposed filter uses a fourth order diffusion tensor whose eigentensors and
eigenvalues are determined from the local Hessian matrix, at a scale that is
automatically selected for each pixel. We discuss efficient implementation
using a Fast Explicit Diffusion scheme and demonstrate results on synthetic
images and vessels in fundus images. Compared to previous isotropic and
anisotropic fourth-order filters, as well as established second-order vessel
enhancing filters, our newly proposed one better restores the centerlines in
all cases.
</dc:description>
 <dc:description>Comment: 12 pages, 8 figures, 1 table</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06906</dc:identifier>
 <dc:identifier>Journal of Mathematical Imaging and Vision, 1-13, 2017</dc:identifier>
 <dc:identifier>doi:10.1007/s10851-017-0729-1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06910</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple Mechanisms for Subadditive Buyers via Duality</dc:title>
 <dc:creator>Cai, Yang</dc:creator>
 <dc:creator>Zhao, Mingfei</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We provide simple and approximately revenue-optimal mechanisms in the
multi-item multi-bidder settings. We unify and improve all previous results, as
well as generalize the results to broader cases. In particular, we prove that
the better of the following two simple, deterministic and Dominant Strategy
Incentive Compatible mechanisms, a sequential posted price mechanism or an
anonymous sequential posted price mechanism with entry fee, achieves a constant
fraction of the optimal revenue among all randomized, Bayesian Incentive
Compatible mechanisms, when buyers' valuations are XOS over independent items.
If the buyers' valuations are subadditive over independent items, the
approximation factor degrades to $O(\log m)$, where $m$ is the number of items.
We obtain our results by first extending the Cai-Devanur-Weinberg duality
framework to derive an effective benchmark of the optimal revenue for
subadditive bidders, and then analyzing this upper bound with new techniques.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-06-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06910</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06914</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resilience of Energy Infrastructure and Services: Modeling, Data
  Analytics and Metrics</dc:title>
 <dc:creator>Ji, Chuanyi</dc:creator>
 <dc:creator>Wei, Yun</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Large scale power failures induced by severe weather have become frequent and
damaging in recent years, causing millions of people to be without electricity
service for days. Although the power industry has been battling weather-induced
failures for years, it is largely unknown how resilient the energy
infrastructure and services really are to severe weather disruptions. What
fundamental issues govern the resilience? Can advanced approaches such as
modeling and data analytics help industry to go beyond empirical methods? This
paper discusses the research to date and open issues related to these
questions. The focus is on identifying fundamental challenges and advanced
approaches for quantifying resilience. In particular, a first aspect of this
problem is how to model large-scale failures, recoveries and impacts, involving
the infrastructure, service providers, customers, and weather. A second aspect
is how to identify generic vulnerability (i.e., non-resilience) in the
infrastructure and services through large-scale data analytics. And, a third is
to understand what resilience metrics are needed and how to develop them.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures, submitted and under review</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06914</dc:identifier>
 <dc:identifier>in Proceedings of the IEEE, vol. 105, no. 7, pp. 1354-1366, July
  2017</dc:identifier>
 <dc:identifier>doi:10.1109/JPROC.2017.2698262</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06915</identifier>
 <datestamp>2017-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space-Efficient Hidden Surface Removal</dc:title>
 <dc:creator>Kammer, Frank</dc:creator>
 <dc:creator>L&#xf6;ffler, Maarten</dc:creator>
 <dc:creator>Silveira, Rodrigo I.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We propose a space-efficient algorithm for hidden surface removal that
combines one of the fastest previous algorithms for that problem with
techniques based on bit manipulation. Such techniques had been successfully
used in other settings, for example to reduce working space for several graph
algorithms. However, bit manipulation is not usually employed in geometric
algorithms because the standard model of computation (the real RAM) does not
support it. For this reason, we first revisit our model of computation to have
a reasonable theoretical framework. Under this framework we show how the use of
a bit representation for the union of triangles, in combination with
rank-select data structures, allows us to implicitly compute the union of $n$
triangles with roughly $O(1)$ bits per union boundary vertex. This results in
an algorithm that uses at most as much space as the previous one, and depending
on the input, can give a reduction of up to a factor $\Theta(\log n)$, while
maintaining the running time.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06915</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06924</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Sphere Packing Bound via Augustin's Method</dc:title>
 <dc:creator>Nakibo&#x11f;lu, Bar&#x131;&#x15f;</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The channel coding problem is reviewed for an abstract framework and a
sufficient condition for the strong converse property is provided. A sphere
packing bound with a polynomial prefactor is established for the decay rate of
the error probability with the block length on any sequence of product channels
$\{{W}_{[1,n]}\}_{n\in\mathbb{Z}^{+}}$ satisfying $\max_{t \leq n}
C_{\frac{1}{2},{W}_{t}}=\mathit{O}(\ln n)$, by first establishing a
non-asymptotic sphere packing bound. For discrete stationary product channels
with feedback, the sphere packing exponent is proved to bound the exponential
decay rate of the error probability with block length from above, by first
establishing a non-asymptotic sphere packing bound. The result for channels
with feedback continues to hold for product channels with feedback satisfying a
milder stationarity hypothesis. A non-asymptotic sphere packing bound with a
polynomial prefactor is established for various Poisson channels.
</dc:description>
 <dc:description>Comment: 44 pages. v1:The original submission (arXiv:1608.02424v1) is split
  into two upon the suggestion of the editor-in-chief of IT transactions. v2:A
  review section for Renyi's information measures is added. Paper is
  reorganized in a way that allows readers who are solely interested in the
  sphere packing bound with feedback to bypass unrelated parts. Minor changes
  in the proofs and notation</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06924</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06925</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Design of H-infinity Controller for a Launch Vehicle Autopilot
  against Disturbances</dc:title>
 <dc:creator>Graells, Antonio</dc:creator>
 <dc:creator>Carrabina, Francisco</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Atmospheric flight phase of a launch vehicle is utilized to evaluate the
performance of an H-infinity controller in the presence of disturbances.
Dynamics of the vehicle is linearly modeled using time-varying parameters. An
operating point was found to design a robust command tracker using H-infinity
control theory that guarantees a stable maneuver. At the end, the controller
was employed on the launch vehicle to assess the capability of control design
on the linearized aerospace vehicle. Experimental results illustrate the
excellent performance of the H-infinity controller and accurate tracking
implemented by the autopilot. Also the robustness of the entire system against
disturbances is demonstrated to be acceptable.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06925</dc:identifier>
 <dc:identifier>IOSR Journal of Electrical and Electronics Engineering
  (IOSR-JEEE), Volume 11, Issue 5, PP 135-140, 2016</dc:identifier>
 <dc:identifier>doi:10.9790/1676-110502135140</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06928</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Memory Lens: How Much Memory Does an Agent Use?</dc:title>
 <dc:creator>Dann, Christoph</dc:creator>
 <dc:creator>Hofmann, Katja</dc:creator>
 <dc:creator>Nowozin, Sebastian</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a new method to study the internal memory used by reinforcement
learning policies. We estimate the amount of relevant past information by
estimating mutual information between behavior histories and the current action
of an agent. We perform this estimation in the passive setting, that is, we do
not intervene but merely observe the natural behavior of the agent. Moreover,
we provide a theoretical justification for our approach by showing that it
yields an implementation-independent lower bound on the minimal memory capacity
of any agent that implement the observed policy. We demonstrate our approach by
estimating the use of memory of DQN policies on concatenated Atari frames,
demonstrating sharply different use of memory across 49 games. The study of
memory as information that flows from the past to the current action opens
avenues to understand and improve successful reinforcement learning algorithms.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06933</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Learning for Lexicon-Based Classification</dc:title>
 <dc:creator>Eisenstein, Jacob</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  In lexicon-based classification, documents are assigned labels by comparing
the number of words that appear from two opposed lexicons, such as positive and
negative sentiment. Creating such words lists is often easier than labeling
instances, and they can be debugged by non-experts if classification
performance is unsatisfactory. However, there is little analysis or
justification of this classification heuristic. This paper describes a set of
assumptions that can be used to derive a probabilistic justification for
lexicon-based classification, as well as an analysis of its expected accuracy.
One key assumption behind lexicon-based classification is that all words in
each lexicon are equally predictive. This is rarely true in practice, which is
why lexicon-based approaches are usually outperformed by supervised classifiers
that learn distinct weights on each word from labeled instances. This paper
shows that it is possible to learn such weights without labeled data, by
leveraging co-occurrence statistics across the lexicons. This offers the best
of both worlds: light supervision in the form of lexicons, and data-driven
classification with higher accuracy than traditional word-counting heuristics.
</dc:description>
 <dc:description>Comment: to appear in AAAI 2017</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06933</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06937</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using inspiration from synaptic plasticity rules to optimize traffic
  flow in distributed engineered networks</dc:title>
 <dc:creator>Suen, Jonathan Y.</dc:creator>
 <dc:creator>Navlakha, Saket</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Controlling the flow and routing of data is a fundamental problem in many
distributed networks, including transportation systems, integrated circuits,
and the Internet. In the brain, synaptic plasticity rules have been discovered
that regulate network activity in response to environmental inputs, which
enable circuits to be stable yet flexible. Here, we develop a new
neuro-inspired model for network flow control that only depends on modifying
edge weights in an activity-dependent manner. We show how two fundamental
plasticity rules (long-term potentiation and long-term depression) can be cast
as a distributed gradient descent algorithm for regulating traffic flow in
engineered networks. We then characterize, both via simulation and
analytically, how different forms of edge-weight update rules affect network
routing efficiency and robustness. We find a close correspondence between
certain classes of synaptic weight update rules derived experimentally in the
brain and rules commonly used in engineering, suggesting common principles to
both.
</dc:description>
 <dc:description>Comment: 43 pages, 5 Figures. Submitted to Neural Computation</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06937</dc:identifier>
 <dc:identifier>Neural Comput. 29(5) (2017) 1204-1228</dc:identifier>
 <dc:identifier>doi:10.1162/NECO_a_00945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06939</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting 1p19q Chromosomal Deletion of Low-Grade Gliomas from MR
  Images using Deep Learning</dc:title>
 <dc:creator>Akkus, Zeynettin</dc:creator>
 <dc:creator>Ali, Issa</dc:creator>
 <dc:creator>Sedlar, Jiri</dc:creator>
 <dc:creator>Kline, Timothy L.</dc:creator>
 <dc:creator>Agrawal, Jay P.</dc:creator>
 <dc:creator>Parney, Ian F.</dc:creator>
 <dc:creator>Giannini, Caterina</dc:creator>
 <dc:creator>Erickson, Bradley J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Objective: Several studies have associated codeletion of chromosome arms
1p/19q in low-grade gliomas (LGG) with positive response to treatment and
longer progression free survival. Therefore, predicting 1p/19q status is
crucial for effective treatment planning of LGG. In this study, we predict the
1p/19q status from MR images using convolutional neural networks (CNN), which
could be a noninvasive alternative to surgical biopsy and histopathological
analysis. Method: Our method consists of three main steps: image registration,
tumor segmentation, and classification of 1p/19q status using CNN. We included
a total of 159 LGG with 3 image slices each who had biopsy-proven 1p/19q status
(57 nondeleted and 102 codeleted) and preoperative postcontrast-T1 (T1C) and T2
images. We divided our data into training, validation, and test sets. The
training data was balanced for equal class probability and then augmented with
iterations of random translational shift, rotation, and horizontal and vertical
flips to increase the size of the training set. We shuffled and augmented the
training data to counter overfitting in each epoch. Finally, we evaluated
several configurations of a multi-scale CNN architecture until training and
validation accuracies became consistent. Results: The results of the best
performing configuration on the unseen test set were 93.3% (sensitivity),
82.22% (specificity), and 87.7% (accuracy). Conclusion: Multi-scale CNN with
their self-learning capability provides promising results for predicting 1p/19q
status noninvasively based on T1C and T2 images. Significance: Predicting
1p/19q status noninvasively from MR images would allow selecting effective
treatment strategies for LGG patients without the need for surgical biopsy.
</dc:description>
 <dc:description>Comment: This work has been presented in Conference on Machine Intelligence in
  Medical Imaging 2016 and RSNA 2016</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06940</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for Analyzing Resparsification Algorithms</dc:title>
 <dc:creator>Kyng, Rasmus</dc:creator>
 <dc:creator>Pachocki, Jakub</dc:creator>
 <dc:creator>Peng, Richard</dc:creator>
 <dc:creator>Sachdeva, Sushant</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A spectral sparsifier of a graph $G$ is a sparser graph $H$ that
approximately preserves the quadratic form of $G$, i.e. for all vectors $x$,
$x^T L_G x \approx x^T L_H x$, where $L_G$ and $L_H$ denote the respective
graph Laplacians. Spectral sparsifiers generalize cut sparsifiers, and have
found many applications in designing graph algorithms. In recent years, there
has been interest in computing spectral sparsifiers in semi-streaming and
dynamic settings. Natural algorithms in these settings often involve repeated
sparsification of a graph, and accumulation of errors across these steps. We
present a framework for analyzing algorithms that perform repeated
sparsifications that only incur error corresponding to a single sparsification
step, leading to better results for many resparsification-based algorithms. As
an application, we show how to maintain a spectral sparsifier in the
semi-streaming setting: We present a simple algorithm that, for a graph $G$ on
$n$ vertices and $m$ edges, computes a spectral sparsifier of $G$ with $O(n
\log n)$ edges in a single pass over $G$, using only $O(n \log n)$ space, and
$O(m \log^2 n)$ total time. This improves on previous best semi-streaming
algorithms for both spectral and cut sparsifiers by a factor of $\log{n}$ in
both space and runtime. The algorithm extends to semi-streaming row sampling
for general PSD matrices. We also use our framework to combine a spectral
sparsification algorithm by Koutis with improved spanner constructions to give
a parallel algorithm for constructing $O(n\log^2{n}\log\log{n})$ sized spectral
sparsifiers in $O(m\log^2{n}\log\log{n})$ time. This is the best known
combinatorial graph sparsification algorithm.The size of the sparsifiers is
only a factor $\log{n}\log\log{n}$ more than ones produced by numerical
routines.
</dc:description>
 <dc:description>Comment: This paper supersedes arXiv:1605.08194</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06943</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Full and Fractional Counting in Bibliometric Networks</dc:title>
 <dc:creator>Leydesdorff, Loet</dc:creator>
 <dc:creator>Park, Han Woo</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  In their study entitled &quot;Constructing bibliometric networks: A comparison
between full and fractional counting,&quot; Perianes-Rodriguez, Waltman, &amp; van Eck
(2016; henceforth abbreviated as PWvE) provide arguments for the use of
fractional counting at the network level as different from the level of
publications. Whereas fractional counting in the latter case divides the credit
among co-authors (countries, institutions, etc.), fractional counting at the
network level can normalize the relative weights of links and thereby clarify
the structures in the network. PWvE, however, propose a counting scheme for
fractional counting that is one among other possible ones. Alternative schemes
proposed by Batagelj and Cerin\v{s}ek (2013) and Park, Yoon, &amp; Leydesdorff
(2016; henceforth abbreviated as PYL) are discussed in an appendix. However,
our approach is not correctly identified as identical to their Equation A3.
Here below, we distinguish three approaches analytically; routines for applying
these approaches to bibliometric data are also provided.
</dc:description>
 <dc:description>Comment: accepted for publication in the Journal of Informetrics, 27 November
  2016</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06943</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06945</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Metaprogramming and Autotuning Framework for Deploying Deep Learning
  Applications</dc:title>
 <dc:creator>Moskewicz, Matthew W.</dc:creator>
 <dc:creator>Jannesari, Ali</dc:creator>
 <dc:creator>Keutzer, Kurt</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  In recent years, deep neural networks (DNNs), have yielded strong results on
a wide range of applications. Graphics Processing Units (GPUs) have been one
key enabling factor leading to the current popularity of DNNs. However, despite
increasing hardware flexibility and software programming toolchain maturity,
high efficiency GPU programming remains difficult: it suffers from high
complexity, low productivity, and low portability. GPU vendors such as NVIDIA
have spent enormous effort to write special-purpose DNN libraries. However, on
other hardware targets, especially mobile GPUs, such vendor libraries are not
generally available. Thus, the development of portable, open, high-performance,
energy-efficient GPU code for DNN operations would enable broader deployment of
DNN-based algorithms. Toward this end, this work presents a framework to enable
productive, high-efficiency GPU programming for DNN computations across
hardware platforms and programming models. In particular, the framework
provides specific support for metaprogramming, autotuning, and DNN-tailored
data types. Using our framework, we explore implementing DNN operations on
three different hardware targets: NVIDIA, AMD, and Qualcomm GPUs. On NVIDIA
GPUs, we show both portability between OpenCL and CUDA as well competitive
performance compared to the vendor library. On Qualcomm GPUs, we show that our
framework enables productive development of target-specific optimizations, and
achieves reasonable absolute performance. Finally, On AMD GPUs, we show initial
results that indicate our framework can yield reasonable performance on a new
platform with minimal effort.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06947</identifier>
 <datestamp>2017-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can Self-Censorship in News Media be Detected Algorithmically? A Case
  Study in Latin America</dc:title>
 <dc:creator>Tao, Rongrong</dc:creator>
 <dc:creator>Zhou, Baojian</dc:creator>
 <dc:creator>Chen, Feng</dc:creator>
 <dc:creator>Liu, Naifeng</dc:creator>
 <dc:creator>Mares, David</dc:creator>
 <dc:creator>Butler, Patrick</dc:creator>
 <dc:creator>Ramakrishnan, Naren</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Censorship in social media has been well studied and provides insight into
how governments stifle freedom of expression online. Comparatively less (or no)
attention has been paid to detecting (self) censorship in traditional media
(e.g., news) using social media as a bellweather. We present a novel
unsupervised approach that views social media as a sensor to detect censorship
in news media wherein statistically significant differences between information
published in the news media and the correlated information published in social
media are automatically identified as candidate censored events. We develop a
hypothesis testing framework to identify and evaluate censored clusters of
keywords, and a new near-linear-time algorithm (called GraphDPD) to identify
the highest scoring clusters as indicators of censorship. We outline extensive
experiments on semi-synthetic data as well as real datasets (with Twitter and
local news media) from Mexico and Venezuela, highlighting the capability to
accurately detect real-world self censorship events.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06949</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dense Captioning with Joint Inference and Visual Context</dc:title>
 <dc:creator>Yang, Linjie</dc:creator>
 <dc:creator>Tang, Kevin</dc:creator>
 <dc:creator>Yang, Jianchao</dc:creator>
 <dc:creator>Li, Li-Jia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Dense captioning is a newly emerging computer vision topic for understanding
images with dense language descriptions. The goal is to densely detect visual
concepts (e.g., objects, object parts, and interactions between them) from
images, labeling each with a short descriptive phrase. We identify two key
challenges of dense captioning that need to be properly addressed when tackling
the problem. First, dense visual concept annotations in each image are
associated with highly overlapping target regions, making accurate localization
of each visual concept challenging. Second, the large amount of visual concepts
makes it hard to recognize each of them by appearance alone. We propose a new
model pipeline based on two novel ideas, joint inference and context fusion, to
alleviate these two challenges. We design our model architecture in a
methodical manner and thoroughly evaluate the variations in architecture. Our
final model, compact and efficient, achieves state-of-the-art accuracy on
Visual Genome for dense captioning with a relative gain of 73\% compared to the
previous best algorithm. Qualitative experiments also reveal the semantic
capabilities of our model in dense captioning.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06949</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06950</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Learning for OCR Text Correction</dc:title>
 <dc:creator>Mei, Jie</dc:creator>
 <dc:creator>Islam, Aminul</dc:creator>
 <dc:creator>Wu, Yajing</dc:creator>
 <dc:creator>Moh'd, Abidalrahman</dc:creator>
 <dc:creator>Milios, Evangelos E.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The accuracy of Optical Character Recognition (OCR) is crucial to the success
of subsequent applications used in text analyzing pipeline. Recent models of
OCR post-processing significantly improve the quality of OCR-generated text,
but are still prone to suggest correction candidates from limited observations
while insufficiently accounting for the characteristics of OCR errors. In this
paper, we show how to enlarge candidate suggestion space by using external
corpus and integrating OCR-specific features in a regression approach to
correct OCR-generated errors. The evaluation results show that our model can
correct 61.5% of the OCR-errors (considering the top 1 suggestion) and 71.5% of
the OCR-errors (considering the top 3 suggestions), for cases where the
theoretical correction upper-bound is 78%.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06950</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06951</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enforcing Relational Matching Dependencies with Datalog for Entity
  Resolution</dc:title>
 <dc:creator>Bahmani, Zeinab</dc:creator>
 <dc:creator>Bertossi, Leopoldo</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Entity resolution (ER) is about identifying and merging records in a database
that represent the same real-world entity. Matching dependencies (MDs) have
been introduced and investigated as declarative rules that specify ER policies.
An ER process induced by MDs over a dirty instance leads to multiple clean
instances, in general. General &quot;answer sets programs&quot; have been proposed to
specify the MD-based cleaning task and its results. In this work, we extend MDs
to &quot;relational MDs&quot;, which capture more application semantics, and identify
classes of relational MDs for which the general ASP can be automatically
rewritten into a stratified Datalog program, with the single clean instance as
its standard model.
</dc:description>
 <dc:description>Comment: New revisions applied. To appear in Proc. FLAIRS'17</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06952</identifier>
 <datestamp>2017-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inferring Fine-grained Control Flow Inside SGX Enclaves with Branch
  Shadowing</dc:title>
 <dc:creator>Lee, Sangho</dc:creator>
 <dc:creator>Shih, Ming-Wei</dc:creator>
 <dc:creator>Gera, Prasun</dc:creator>
 <dc:creator>Kim, Taesoo</dc:creator>
 <dc:creator>Kim, Hyesoon</dc:creator>
 <dc:creator>Peinado, Marcus</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper, we explore a new, yet critical, side-channel attack against
Intel Software Guard Extension (SGX), called a branch shadowing attack, which
can reveal fine-grained control flows (i.e., each branch) of an enclave program
running on real SGX hardware. The root cause of this attack is that Intel SGX
does not clear the branch history when switching from enclave mode to
non-enclave mode, leaving the fine-grained traces to the outside world through
a branch-prediction side channel. However, exploiting the channel is not so
straightforward in practice because 1) measuring branch
prediction/misprediction penalties based on timing is too inaccurate to
distinguish fine-grained control-flow changes and 2) it requires sophisticated
control over the enclave execution to force its execution to the interesting
code blocks. To overcome these challenges, we developed two novel exploitation
techniques: 1) Intel PT- and LBR-based history-inferring techniques and 2)
APIC-based technique to control the execution of enclave programs in a
fine-grained manner. As a result, we could demonstrate our attack by breaking
recent security constructs, including ORAM schemes, Sanctum, SGX-Shield, and
T-SGX. Not limiting our work to the attack itself, we thoroughly studied the
feasibility of hardware-based solutions (e.g., branch history clearing) and
also proposed a software-based countermeasure, called Zigzagger, to mitigate
the branch shadowing attack in practice.
</dc:description>
 <dc:description>Comment: A revised version of this paper will be presented at USENIX Security
  Symposium 2017. Please cite this paper as Sangho Lee, Ming-Wei Shih, Prasun
  Gera, Taesoo Kim, Hyesoon Kim, and Marcus Peinado, &quot;Inferring Fine-grained
  Control Flow Inside SGX Enclaves with Branch Shadowing,&quot; in Proceedings of
  the 26th USENIX Security Symposium (Security), Vancouver, Canada, August 2017</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06952</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06953</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Associative Adversarial Networks</dc:title>
 <dc:creator>Arici, Tarik</dc:creator>
 <dc:creator>Celikyilmaz, Asli</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We propose a higher-level associative memory for learning adversarial
networks. Generative adversarial network (GAN) framework has a discriminator
and a generator network. The generator (G) maps white noise (z) to data samples
while the discriminator (D) maps data samples to a single scalar. To do so, G
learns how to map from high-level representation space to data space, and D
learns to do the opposite. We argue that higher-level representation spaces
need not necessarily follow a uniform probability distribution. In this work,
we use Restricted Boltzmann Machines (RBMs) as a higher-level associative
memory and learn the probability distribution for the high-level features
generated by D. The associative memory samples its underlying probability
distribution and G learns how to map these samples to data space. The proposed
associative adversarial networks (AANs) are generative models in the
higher-levels of the learning, and use adversarial non-stochastic models D and
G for learning the mapping between data and higher-level representation spaces.
Experiments show the potential of the proposed networks.
</dc:description>
 <dc:description>Comment: NIPS 2016 Workshop on Adversarial Training</dc:description>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06953</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06956</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal control of VNF deployment and scheduling</dc:title>
 <dc:creator>Shifrin, Mark</dc:creator>
 <dc:creator>Biton, Erez</dc:creator>
 <dc:creator>Gurewitz, Omer</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Managing network-related resources involves sophisticated trade-off between
flexibility, high performance standards, latency demands which adhere to
service level agreements (SLAs) and cost constraints. Network functioning
virtualization (NFV) opens new challenges to the remote network management
which combines activation and control of virtual machines (VMs) according to
variable demand. Currently, this functionality is being handled by harnessing
the traditional orchestration algorithms using suboptimal heuristics. We model
the problem of virtual network function (VNF) allocation by queuing system with
flexible number of queues, which captures variety of constraints including
queue deployment and displacement, delay cost, holding cost, scheduling reward
and fine. Next, we model the system by Markov decision process (MDP) and
numerically solve it to find the optimal policy. We show analytically and by
simulations that the optimal policy possesses decision thresholds which depend
on several parameters.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06956</dc:identifier>
 <dc:identifier>2016 International Conference on the Science of Electrical
  Engineering - ICSEE, November 16-18, Eilat, Israel</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06961</identifier>
 <datestamp>2017-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rising Novelties on Evolving Networks: Recent Behavior Dominant and
  Non-Dominant Model</dc:title>
 <dc:creator>Abbas, Khushnood</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Novelty attracts attention like popularity. Hence predicting novelty is as
important as popularity. Novelty is the side effect of competition and aging in
evolving systems. Recent behavior or recent link gain in networks plays an
important role in emergence or trend. We exploited this wisdom and came up with
two models considering different scenarios and systems. Where recent behavior
dominates over total behavior (total link gain) in the first one, and recent
behavior is as important as total behavior for future link gain in second one.
It suppose that random walker walks on a network and can jump to any node, the
probablity of jumping or making connection to other node is based on which node
is recently more active or receiving more links. In our assumption random
walker can also jump to node which is already popular but recently not popular.
We are able to predict rising novelties or popular nodes which is generally
suppressed under preferential attachment effect. To show performance of our
model we have conducted experiments on four real data sets namely, MovieLens,
Netflix, Facebook and Arxiv High Energy Physics paper citation. For testing our
model we used four information retrieval indices namely Precision, Novelty,
Area Under Receiving Operating Characteristic(AUC) and Kendal's rank
correlation coefficient. We have used four benchmark models for validating our
proposed models. Although our model doesn't perform better in all the cases
but, it has theoretical significance in working better for recent behavior
dominant systems.
</dc:description>
 <dc:description>Comment: 19 pages, 5 figures</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06961</dc:identifier>
 <dc:identifier>Physica A: Statistical Mechanics and its Applications 484C (2017)
  pp. 506-515</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2017.04.156</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06962</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sampled Image Tagging and Retrieval Methods on User Generated Content</dc:title>
 <dc:creator>Ni, Karl</dc:creator>
 <dc:creator>Zaragoza, Kyle</dc:creator>
 <dc:creator>Foster, Charles</dc:creator>
 <dc:creator>Carrano, Carmen</dc:creator>
 <dc:creator>Chen, Barry</dc:creator>
 <dc:creator>Tesfaye, Yonas</dc:creator>
 <dc:creator>Gude, Alex</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Traditional image tagging and retrieval algorithms have limited value as a
result of being trained with heavily curated datasets. These limitations are
most evident when arbitrary search words are used that do not intersect with
training set labels. Weak labels from user generated content (UGC) found in the
wild (e.g., Google Photos, FlickR, etc.) have an almost unlimited number of
unique words in the metadata tags. Prior work on word embeddings successfully
leveraged unstructured text with large vocabularies, and our proposed method
seeks to apply similar cost functions to open source imagery. Specifically, we
train a deep learning image tagging and retrieval system on large scale, user
generated content (UGC) using sampling methods and joint optimization of word
embeddings. By using the Yahoo! FlickR Creative Commons (YFCC100M) dataset,
such an approach builds robustness to common unstructured data issues that
include but are not limited to irrelevant tags, misspellings, multiple
languages, polysemy, and tag imbalance. As a result, the final proposed
algorithm will not only yield comparable results to state of the art in
conventional image tagging, but will enable new capability to train algorithms
on large, scale unstructured text in the YFCC100M dataset and outperform cited
work in zero-shot capability.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06962</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06963</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Catch'Em All: Locating Multiple Diffusion Sources in Networks with
  Partial Observations</dc:title>
 <dc:creator>Zhu, Kai</dc:creator>
 <dc:creator>Chen, Zhen</dc:creator>
 <dc:creator>Ying, Lei</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  This paper studies the problem of locating multiple diffusion sources in
networks with partial observations. We propose a new source localization
algorithm, named Optimal-Jordan-Cover (OJC). The algorithm first extracts a
subgraph using a candidate selection algorithm that selects source candidates
based on the number of observed infected nodes in their neighborhoods. Then, in
the extracted subgraph, OJC finds a set of nodes that &quot;cover&quot; all observed
infected nodes with the minimum radius. The set of nodes is called the Jordan
cover, and is regarded as the set of diffusion sources. Considering the
heterogeneous susceptible-infected-recovered (SIR) diffusion in the Erdos-Renyi
(ER) random graph, we prove that OJC can locate all sources with probability
one asymptotically with partial observations. OJC is a polynomial-time
algorithm in terms of network size. However, the computational complexity
increases exponentially in $m,$ the number of sources. We further propose a
low-complexity heuristic based on the K-Means for approximating the Jordan
cover, named Approximate-Jordan-Cover (AJC). Simulations on random graphs and
real networks demonstrate that both AJC and OJC significantly outperform other
heuristic algorithms.
</dc:description>
 <dc:description>Comment: 16 figures</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06969</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kernel Cross-View Collaborative Representation based Classification for
  Person Re-Identification</dc:title>
 <dc:creator>Prates, Raphael</dc:creator>
 <dc:creator>Schwartz, William Robson</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Person re-identification aims at the maintenance of a global identity as a
person moves among non-overlapping surveillance cameras. It is a hard task due
to different illumination conditions, viewpoints and the small number of
annotated individuals from each pair of cameras (small-sample-size problem).
Collaborative Representation based Classification (CRC) has been employed
successfully to address the small-sample-size problem in computer vision.
However, the original CRC formulation is not well-suited for person
re-identification since it does not consider that probe and gallery samples are
from different cameras. Furthermore, it is a linear model, while appearance
changes caused by different camera conditions indicate a strong nonlinear
transition between cameras. To overcome such limitations, we propose the Kernel
Cross-View Collaborative Representation based Classification (Kernel X-CRC)
that represents probe and gallery images by balancing representativeness and
similarity nonlinearly. It assumes that a probe and its corresponding gallery
image are represented with similar coding vectors using individuals from the
training set. Experimental results demonstrate that our assumption is true when
using a high-dimensional feature vector and becomes more compelling when
dealing with a low-dimensional and discriminative representation computed using
a common subspace learning method. We achieve state-of-the-art for rank-1
matching rates in two person re-identification datasets (PRID450S and GRID) and
the second best results on VIPeR and CUHK01 datasets.
</dc:description>
 <dc:description>Comment: Paper submitted to CVPR 2017 conference</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06972</identifier>
 <datestamp>2017-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring Sample Quality with Diffusions</dc:title>
 <dc:creator>Gorham, Jackson</dc:creator>
 <dc:creator>Duncan, Andrew B.</dc:creator>
 <dc:creator>Vollmer, Sebastian J.</dc:creator>
 <dc:creator>Mackey, Lester</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>60J60, 62-04, 62E17, 60E15, 65C60 (Primary) 62-07, 65C05, 68T05
  (Secondary)</dc:subject>
 <dc:description>  Standard Markov chain Monte Carlo diagnostics, like effective sample size,
are ineffective for biased sampling procedures that sacrifice asymptotic
correctness for computational speed. Recent work addresses this issue for a
class of strongly log-concave target distributions by constructing a computable
discrepancy measure based on Stein's method that provably determines
convergence to the target. We generalize this approach to cover any target with
a fast-coupling Ito diffusion by bounding the derivatives of Stein equation
solutions in terms of Markov process coupling times. As example applications,
we develop computable and convergence-determining diffusion Stein discrepancies
for log-concave, heavy-tailed, and multimodal targets and use these quality
measures to select the hyperparameters of biased samplers, compare random and
deterministic quadrature rules, and quantify bias-variance tradeoffs in
approximate Markov chain Monte Carlo. Our explicit multivariate Stein factor
bounds may be of independent interest.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-06-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06973</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RhoanaNet Pipeline: Dense Automatic Neural Annotation</dc:title>
 <dc:creator>Knowles-Barley, Seymour</dc:creator>
 <dc:creator>Kaynig, Verena</dc:creator>
 <dc:creator>Jones, Thouis Ray</dc:creator>
 <dc:creator>Wilson, Alyssa</dc:creator>
 <dc:creator>Morgan, Joshua</dc:creator>
 <dc:creator>Lee, Dongil</dc:creator>
 <dc:creator>Berger, Daniel</dc:creator>
 <dc:creator>Kasthuri, Narayanan</dc:creator>
 <dc:creator>Lichtman, Jeff W.</dc:creator>
 <dc:creator>Pfister, Hanspeter</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Reconstructing a synaptic wiring diagram, or connectome, from electron
microscopy (EM) images of brain tissue currently requires many hours of manual
annotation or proofreading (Kasthuri and Lichtman, 2010; Lichtman and Sanes,
2008; Seung, 2009). The desire to reconstruct ever larger and more complex
networks has pushed the collection of ever larger EM datasets. A cubic
millimeter of raw imaging data would take up 1 PB of storage and present an
annotation project that would be impractical without relying heavily on
automatic segmentation methods. The RhoanaNet image processing pipeline was
developed to automatically segment large volumes of EM data and ease the burden
of manual proofreading and annotation. Based on (Kaynig et al., 2015), we
updated every stage of the software pipeline to provide better throughput
performance and higher quality segmentation results. We used state of the art
deep learning techniques to generate improved membrane probability maps, and
Gala (Nunez-Iglesias et al., 2014) was used to agglomerate 2D segments into 3D
objects.
  We applied the RhoanaNet pipeline to four densely annotated EM datasets, two
from mouse cortex, one from cerebellum and one from mouse lateral geniculate
nucleus (LGN). All training and test data is made available for benchmark
comparisons. The best segmentation results obtained gave
$V^\text{Info}_\text{F-score}$ scores of 0.9054 and 09182 for the cortex
datasets, 0.9438 for LGN, and 0.9150 for Cerebellum.
  The RhoanaNet pipeline is open source software. All source code, training
data, test data, and annotations for all four benchmark datasets are available
at www.rhoana.org.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06973</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06980</identifier>
 <datestamp>2017-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lower bounds for 2-query LCCs over large alphabet</dc:title>
 <dc:creator>Bhattacharyya, Arnab</dc:creator>
 <dc:creator>Gopi, Sivakanth</dc:creator>
 <dc:creator>Tal, Avishay</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A locally correctable code (LCC) is an error correcting code that allows
correction of any arbitrary coordinate of a corrupted codeword by querying only
a few coordinates. We show that any {\em zero-error} $2$-query locally
correctable code $\mathcal{C}: \{0,1\}^k \to \Sigma^n$ that can correct a
constant fraction of corrupted symbols must have $n \geq \exp(k/\log|\Sigma|)$.
We say that an LCC is zero-error if there exists a non-adaptive corrector
algorithm that succeeds with probability $1$ when the input is an uncorrupted
codeword. All known constructions of LCCs are zero-error.
  Our result is tight upto constant factors in the exponent. The only previous
lower bound on the length of 2-query LCCs over large alphabet was
$\Omega\left((k/\log|\Sigma|)^2\right)$ due to Katz and Trevisan (STOC 2000).
Our bound implies that zero-error LCCs cannot yield $2$-server private
information retrieval (PIR) schemes with sub-polynomial communication. Since
there exists a $2$-server PIR scheme with sub-polynomial communication (STOC
2015) based on a zero-error $2$-query locally decodable code (LDC), we also
obtain a separation between LDCs and LCCs over large alphabet.
  For our proof of the result, we need a new decomposition lemma for directed
graphs that may be of independent interest. Given a dense directed graph $G$,
our decomposition uses the directed version of Szemer\'edi regularity lemma due
to Alon and Shapira (STOC 2003) to partition almost all of $G$ into a constant
number of subgraphs which are either edge-expanding or empty.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-04-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06980</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06981</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple-View Spectral Clustering for Group-wise Functional Community
  Detection</dc:title>
 <dc:creator>Cahill, Nathan D.</dc:creator>
 <dc:creator>Singh, Harmeet</dc:creator>
 <dc:creator>Zhang, Chao</dc:creator>
 <dc:creator>Corcoran, Daryl A.</dc:creator>
 <dc:creator>Prengaman, Alison M.</dc:creator>
 <dc:creator>Wenger, Paul S.</dc:creator>
 <dc:creator>Hamilton, John F.</dc:creator>
 <dc:creator>Bajorski, Peter</dc:creator>
 <dc:creator>Michael, Andrew M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Functional connectivity analysis yields powerful insights into our
understanding of the human brain. Group-wise functional community detection
aims to partition the brain into clusters, or communities, in which functional
activity is inter-regionally correlated in a common manner across a group of
subjects. In this article, we show how to use multiple-view spectral clustering
to perform group-wise functional community detection. In a series of
experiments on 291 subjects from the Human Connectome Project, we compare three
versions of multiple-view spectral clustering: MVSC (uniform weights), MVSCW
(weights based on subject-specific embedding quality), and AASC (weights
optimized along with the embedding) with the competing technique of Joint
Diagonalization of Laplacians (JDL). Results show that multiple-view spectral
clustering not only yields group-wise functional communities that are more
consistent than JDL when using randomly selected subsets of individual brains,
but it is several orders of magnitude faster than JDL.
</dc:description>
 <dc:description>Comment: Presented at The MICCAI-BACON 16 Workshop
  (https://arxiv.org/abs/1611.03363)</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06986</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust end-to-end deep audiovisual speech recognition</dc:title>
 <dc:creator>Sanabria, Ramon</dc:creator>
 <dc:creator>Metze, Florian</dc:creator>
 <dc:creator>De La Torre, Fernando</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Speech is one of the most effective ways of communication among humans. Even
though audio is the most common way of transmitting speech, very important
information can be found in other modalities, such as vision. Vision is
particularly useful when the acoustic signal is corrupted. Multi-modal speech
recognition however has not yet found wide-spread use, mostly because the
temporal alignment and fusion of the different information sources is
challenging.
  This paper presents an end-to-end audiovisual speech recognizer (AVSR), based
on recurrent neural networks (RNN) with a connectionist temporal classification
(CTC) loss function. CTC creates sparse &quot;peaky&quot; output activations, and we
analyze the differences in the alignments of output targets (phonemes or
visemes) between audio-only, video-only, and audio-visual feature
representations. We present the first such experiments on the large vocabulary
IBM ViaVoice database, which outperform previously published approaches on
phone accuracy in clean and noisy conditions.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06987</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sublabel-Accurate Discretization of Nonconvex Free-Discontinuity
  Problems</dc:title>
 <dc:creator>M&#xf6;llenhoff, Thomas</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work we show how sublabel-accurate multilabeling approaches can be
derived by approximating a classical label-continuous convex relaxation of
nonconvex free-discontinuity problems. This insight allows to extend these
sublabel-accurate approaches from total variation to general convex and
nonconvex regularizations. Furthermore, it leads to a systematic approach to
the discretization of continuous convex relaxations. We study the relationship
to existing discretizations and to discrete-continuous MRFs. Finally, we apply
the proposed approach to obtain a sublabel-accurate and convex solution to the
vectorial Mumford-Shah functional and show in several experiments that it leads
to more precise solutions using fewer labels.
</dc:description>
 <dc:description>Comment: ICCV 2017 version</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06987</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06996</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial contrasting for deep unsupervised learning</dc:title>
 <dc:creator>Hoffer, Elad</dc:creator>
 <dc:creator>Hubara, Itay</dc:creator>
 <dc:creator>Ailon, Nir</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Convolutional networks have marked their place over the last few years as the
best performing model for various visual tasks. They are, however, most suited
for supervised learning from large amounts of labeled data. Previous attempts
have been made to use unlabeled data to improve model performance by applying
unsupervised techniques. These attempts require different architectures and
training methods. In this work we present a novel approach for unsupervised
training of Convolutional networks that is based on contrasting between spatial
regions within images. This criterion can be employed within conventional
neural networks and trained using standard techniques such as SGD and
back-propagation, thus complementing supervised methods.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.06997</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coherent Dialogue with Attention-based Language Models</dc:title>
 <dc:creator>Mei, Hongyuan</dc:creator>
 <dc:creator>Bansal, Mohit</dc:creator>
 <dc:creator>Walter, Matthew R.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We model coherent conversation continuation via RNN-based dialogue models
equipped with a dynamic attention mechanism. Our attention-RNN language model
dynamically increases the scope of attention on the history as the conversation
continues, as opposed to standard attention (or alignment) models with a fixed
input scope in a sequence-to-sequence model. This allows each generated word to
be associated with the most relevant words in its corresponding conversation
history. We evaluate the model on two popular dialogue datasets, the
open-domain MovieTriples dataset and the closed-domain Ubuntu Troubleshoot
dataset, and achieve significant improvements over the state-of-the-art and
baselines on several metrics, including complementary diversity-based metrics,
human evaluation, and qualitative visualizations. We also show that a vanilla
RNN with dynamic attention outperforms more complex memory models (e.g., LSTM
and GRU) by allowing for flexible, long-distance memory. We promote further
coherence via topic modeling-based reranking.
</dc:description>
 <dc:description>Comment: To appear at AAAI 2017</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.06997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07004</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image-to-Image Translation with Conditional Adversarial Networks</dc:title>
 <dc:creator>Isola, Phillip</dc:creator>
 <dc:creator>Zhu, Jun-Yan</dc:creator>
 <dc:creator>Zhou, Tinghui</dc:creator>
 <dc:creator>Efros, Alexei A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We investigate conditional adversarial networks as a general-purpose solution
to image-to-image translation problems. These networks not only learn the
mapping from input image to output image, but also learn a loss function to
train this mapping. This makes it possible to apply the same generic approach
to problems that traditionally would require very different loss formulations.
We demonstrate that this approach is effective at synthesizing photos from
label maps, reconstructing objects from edge maps, and colorizing images, among
other tasks. Indeed, since the release of the pix2pix software associated with
this paper, a large number of internet users (many of them artists) have posted
their own experiments with our system, further demonstrating its wide
applicability and ease of adoption without the need for parameter tweaking. As
a community, we no longer hand-engineer our mapping functions, and this work
suggests we can achieve reasonable results without hand-engineering our loss
functions either.
</dc:description>
 <dc:description>Comment: Website: https://phillipi.github.io/pix2pix/</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07004</dc:identifier>
 <dc:identifier>CVPR 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07008</identifier>
 <datestamp>2017-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fine-Grained Complexity and Conditional Hardness for Sparse Graphs</dc:title>
 <dc:creator>Agarwal, Udit</dc:creator>
 <dc:creator>Ramachandran, Vijaya</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We consider the fine-grained complexity of sparse graph problems that
currently have $\tilde{O}(mn)$ time algorithms, where m is the number of edges
and n is the number of vertices in the input graph. This class includes several
important path problems on both directed and undirected graphs, including APSP,
MWC (minimum weight cycle), and Eccentricities, which is the problem of
computing, for each vertex in the graph, the length of a longest shortest path
starting at that vertex.
  We introduce the notion of a sparse reduction which preserves the sparsity of
graphs, and we present near linear-time sparse reductions between various pairs
of graph problems in the $\tilde{O}(mn)$ class. Surprisingly, very few of the
known nontrivial reductions between problems in the $\tilde{O}(mn)$ class are
sparse reductions. In the directed case, our results give a partial order on a
large collection of problems in the $\tilde{O}(mn)$ class (along with some
equivalences). In the undirected case we give two nontrivial sparse reductions:
from MWC to APSP, and from unweighted ANSC (all nodes shortest cycles) to APSP.
The latter reduction also gives an improved algorithm for ANSC (for dense
graphs).
  We propose the MWC Conjecture, a new conditional hardness conjecture that the
weight of a minimum weight cycle in a directed graph cannot be computed in time
polynomially smaller than mn. Our sparse reductions for directed path problems
in the $\tilde{O}(mn)$ class establish that several problems in this class,
including 2-SiSP (second simple shortest path), Radius, and Eccentricities, are
MWCC hard. We also identify Eccentricities as a key problem in the
$\tilde{O}(mn)$ class which is simultaneously MWCC-hard, SETH-hard and
k-DSH-hard, where SETH is the Strong Exponential Time Hypothesis, and k-DSH is
the hypothesis that a dominating set of size k cannot be computed in time
polynomially smaller than n^k.
</dc:description>
 <dc:description>Comment: abstract updated; There is no update to the paper</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-10-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07012</identifier>
 <datestamp>2017-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GRAM: Graph-based Attention Model for Healthcare Representation Learning</dc:title>
 <dc:creator>Choi, Edward</dc:creator>
 <dc:creator>Bahadori, Mohammad Taha</dc:creator>
 <dc:creator>Song, Le</dc:creator>
 <dc:creator>Stewart, Walter F.</dc:creator>
 <dc:creator>Sun, Jimeng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep learning methods exhibit promising performance for predictive modeling
in healthcare, but two important challenges remain: -Data insufficiency:Often
in healthcare predictive modeling, the sample size is insufficient for deep
learning methods to achieve satisfactory results. -Interpretation:The
representations learned by deep learning methods should align with medical
knowledge. To address these challenges, we propose a GRaph-based Attention
Model, GRAM that supplements electronic health records (EHR) with hierarchical
information inherent to medical ontologies. Based on the data volume and the
ontology structure, GRAM represents a medical concept as a combination of its
ancestors in the ontology via an attention mechanism. We compared predictive
performance (i.e. accuracy, data needs, interpretability) of GRAM to various
methods including the recurrent neural network (RNN) in two sequential
diagnoses prediction tasks and one heart failure prediction task. Compared to
the basic RNN, GRAM achieved 10% higher accuracy for predicting diseases rarely
observed in the training data and 3% improved area under the ROC curve for
predicting heart failure using an order of magnitude less training data.
Additionally, unlike other methods, the medical concept representations learned
by GRAM are well aligned with the medical ontology. Finally, GRAM exhibits
intuitive attention behaviors by adaptively generalizing to higher level
concepts when facing data insufficiency at the lower level concepts.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07020</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proactive SRV spectrum handoff protocol based on GCS scheme in cognitive
  radio adhoc network</dc:title>
 <dc:creator>Mehrnoush, Morteza</dc:creator>
 <dc:creator>Vakili, V. T.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Cognitive radio technology allows the secondary users to utilize the
spectrum, when it is not occupied by the primary users. Whenever a primary user
wants to utilize a channel which is occupied by a secondary user, the secondary
user should perform a proactive spectrum handoff to another channel and vacate
the selected channel before the primary user utilizes it. This scheme avoids
collision between the primary users and secondary users; moreover, increases
the throughput of the primary and secondary users. In this paper, a novel
proactive spectrum hand protocol based on the Greedy Channel Selection (GCS) is
proposed which avoids collision between secondary users, as well as, collision
between primary and secondary users. In the proposed scheme, proactive spectrum
handoff is based on the SRV (Single Rendezvous) coordination scheme; therefore,
the secondary users perform proactive spectrum handoff without using the common
control channel. Moreover, the channel selection is distributed which leads to
the higher throughput, and lower average service time. The proposed proactive
spectrum handoff protocol is compared with the other proactive spectrum handoff
protocols. Simulation results illustrate that the proposed protocol outperforms
the other protocols regarding higher average throughput and lower average
service time.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07020</dc:identifier>
 <dc:identifier>International Journal of Power Control Signal and Computation
  (IJPCSC), Vol. 5, No.1, pp.1-08, Jan-March 2013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07054</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Training Algorithm for Kernel Survival Support Vector
  Machines</dc:title>
 <dc:creator>P&#xf6;lsterl, Sebastian</dc:creator>
 <dc:creator>Navab, Nassir</dc:creator>
 <dc:creator>Katouzian, Amin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  Survival analysis is a fundamental tool in medical research to identify
predictors of adverse events and develop systems for clinical decision support.
In order to leverage large amounts of patient data, efficient optimisation
routines are paramount. We propose an efficient training algorithm for the
kernel survival support vector machine (SSVM). We directly optimise the primal
objective function and employ truncated Newton optimisation and order statistic
trees to significantly lower computational costs compared to previous training
algorithms, which require $O(n^4)$ space and $O(p n^6)$ time for datasets with
$n$ samples and $p$ features. Our results demonstrate that our proposed
optimisation scheme allows analysing data of a much larger scale with no loss
in prediction performance. Experiments on synthetic and 5 real-world datasets
show that our technique outperforms existing kernel SSVM formulations if the
amount of right censoring is high ($\geq85\%$), and performs comparably
otherwise.
</dc:description>
 <dc:description>Comment: ECML PKDD MLLS 2016: 3rd Workshop on Machine Learning in Life
  Sciences</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07054</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07055</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Data Structure for Nearest Common Ancestors with Linking</dc:title>
 <dc:creator>Gabow, Harold N.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Consider a forest that evolves via $link$ operations that make the root of
one tree the child of a node in another tree. Intermixed with $link$ operations
are $nca$ operations, which return the nearest common ancestor of two given
nodes when such exists. This paper shows that a sequence of $m$ such $nca$ and
$link$ operations on a forest of $n$ nodes can be processed on-line in time
$O(m\alpha(m,n)+n)$. This was previously known only for a restricted type of
$link$ operation. The special case where a $link$ only extends a tree by adding
a new leaf occurs in Edmonds' algorithm for finding a maximum weight matching
on a general graph. Incorporating our algorithm into the implementation of
Edmonds' algorithm in \cite{G17} achieves time $O(n(m + n\log n))$ for weighted
matching, an arguably optimum asymptotic bound ($n$ and $m$ are the number of
vertices and edges, respectively).
</dc:description>
 <dc:description>Comment: A preliminary version of results in this paper appeared in Proc.1st
  Annual ACM-SIAM Symp. on Disc. Algorithms (SODA), 1990</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07056</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Recycling Gibbs Sampler for Efficient Learning</dc:title>
 <dc:creator>Martino, Luca</dc:creator>
 <dc:creator>Elvira, Victor</dc:creator>
 <dc:creator>Camps-Valls, Gustau</dc:creator>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Monte Carlo methods are essential tools for Bayesian inference. Gibbs
sampling is a well-known Markov chain Monte Carlo (MCMC) algorithm, extensively
used in signal processing, machine learning, and statistics, employed to draw
samples from complicated high-dimensional posterior distributions. The key
point for the successful application of the Gibbs sampler is the ability to
draw efficiently samples from the full-conditional probability density
functions. Since in the general case this is not possible, in order to speed up
the convergence of the chain, it is required to generate auxiliary samples
whose information is eventually disregarded. In this work, we show that these
auxiliary samples can be recycled within the Gibbs estimators, improving their
efficiency with no extra cost. This novel scheme arises naturally after
pointing out the relationship between the standard Gibbs sampler and the chain
rule used for sampling purposes. Numerical simulations involving simple and
real inference problems confirm the excellent performance of the proposed
scheme in terms of accuracy and computational efficiency. In particular we give
empirical evidence of performance in a toy example, inference of Gaussian
processes hyperparameters, and learning dependence graphs through regression.
</dc:description>
 <dc:description>Comment: The MATLAB code of the numerical examples is provided at
  http://isp.uv.es/code/RG.zip</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07056</dc:identifier>
 <dc:identifier>Digital Signal Processing, Volume 74, 2018</dc:identifier>
 <dc:identifier>doi:10.1016/j.dsp.2017.11.012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07060</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SROS: Securing ROS over the wire, in the graph, and through the kernel</dc:title>
 <dc:creator>White, Ruffin</dc:creator>
 <dc:creator>Christensen, Dr. Henrik I.</dc:creator>
 <dc:creator>Quigley, Dr. Morgan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  SROS is a proposed addition to the ROS API and ecosystem to support modern
cryptography and security measures. An overview of current progress will be
presented, rationalizing each major advancement, including: over-the-wire
cryptography for all data transport, namespaced access control enforcing graph
policies/restrictions, and finally process profiles using Linux Security
Modules to harden a node's resource access. By making the community aware of
the vulnerabilities in ROS, as well as the proposed solutions provided by SROS,
we intend to improve the state of security for future robotics subsystems.
</dc:description>
 <dc:description>Comment: Workshop contribution presented at IEEE-RAS International Conference
  on Humanoid Robots (HUMANOIDS). 2016</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07065</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Neural Networks With Limited Numerical Precision</dc:title>
 <dc:creator>Ott, Joachim</dc:creator>
 <dc:creator>Lin, Zhouhan</dc:creator>
 <dc:creator>Zhang, Ying</dc:creator>
 <dc:creator>Liu, Shih-Chii</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Recurrent Neural Networks (RNNs) produce state-of-art performance on many
machine learning tasks but their demand on resources in terms of memory and
computational power are often high. Therefore, there is a great interest in
optimizing the computations performed with these models especially when
considering development of specialized low-power hardware for deep networks.
One way of reducing the computational needs is to limit the numerical precision
of the network weights and biases, and this will be addressed for the case of
RNNs. We present results from the use of different stochastic and deterministic
reduced precision training methods applied to two major RNN types, which are
then tested on three datasets. The results show that the stochastic and
deterministic ternarization, pow2- ternarization, and exponential quantization
methods gave rise to low-precision RNNs that produce similar and even higher
accuracy on certain datasets, therefore providing a path towards training more
efficient implementations of RNNs in specialized hardware.
</dc:description>
 <dc:description>Comment: NIPS 2016 EMDNN Workshop paper, condensed version of arXiv:1608.06902</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07067</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Use of Application Scanners in Software Product Quality Assessment</dc:title>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>D.2.9</dc:subject>
 <dc:description>  Software development needs continuous quality control for a timely detection
and removal of quality problems. This includes frequent quality assessments,
which need to be automated as far as possible to be feasible. One way of
automation in assessing the security of software are application scanners that
test an executing software for vulnerabilities. At present, common quality
assessments do not integrate such scanners for giving an overall quality
statement. This paper presents an integration of application scanners into a
general quality assessment method based on explicit quality models and Bayesian
nets. Its applicability and the detection capabilities of common scanners are
investigated in a case study with two open-source web shops.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07067</dc:identifier>
 <dc:identifier>Proceedings of the 8th international workshop on Software quality
  (WoSQ'11). ACM, 2011</dc:identifier>
 <dc:identifier>doi:10.1145/2024587.2024597</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07073</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Squarability of rectangle arrangements</dc:title>
 <dc:creator>Kone&#x10d;n&#xfd;, Mat&#x11b;j</dc:creator>
 <dc:creator>Ku&#x10d;era, Stanislav</dc:creator>
 <dc:creator>Opler, Michal</dc:creator>
 <dc:creator>Sosnovec, Jakub</dc:creator>
 <dc:creator>&#x160;imsa, &#x160;t&#x11b;p&#xe1;n</dc:creator>
 <dc:creator>T&#xf6;pfer, Martin</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We study when an arrangement of axis-aligned rectangles can be transformed
into an arrangement of axis-aligned squares in $\mathbb{R}^2$ while preserving
its structure. We found a counterexample to the conjecture of J. Klawitter, M.
N\&quot;ollenburg and T. Ueckerdt whether all arrangements without crossing and
side-piercing can be squared. Our counterexample also works in a more general
case when we only need to preserve the intersection graph and we forbid
side-piercing between squares. We also show counterexamples for transforming
box arrangements into combinatorially equivalent hypercube arrangements.
Finally, we introduce a linear program deciding whether an arrangement of
rectangles can be squared in a more restrictive version where the order of all
sides is preserved.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07078</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Deep Learning Approach for Joint Video Frame and Reward Prediction in
  Atari Games</dc:title>
 <dc:creator>Leibfried, Felix</dc:creator>
 <dc:creator>Kushman, Nate</dc:creator>
 <dc:creator>Hofmann, Katja</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Reinforcement learning is concerned with identifying reward-maximizing
behaviour policies in environments that are initially unknown. State-of-the-art
reinforcement learning approaches, such as deep Q-networks, are model-free and
learn to act effectively across a wide range of environments such as Atari
games, but require huge amounts of data. Model-based techniques are more
data-efficient, but need to acquire explicit knowledge about the environment.
  In this paper, we take a step towards using model-based techniques in
environments with a high-dimensional visual state space by demonstrating that
it is possible to learn system dynamics and the reward structure jointly. Our
contribution is to extend a recently developed deep neural network for video
frame prediction in Atari games to enable reward prediction as well. To this
end, we phrase a joint optimization problem for minimizing both video frame and
reward reconstruction loss, and adapt network parameters accordingly. Empirical
evaluations on five Atari games demonstrate accurate cumulative reward
prediction of up to 200 frames. We consider these results as opening up
important directions for model-based reinforcement learning in complex,
initially unknown environments.
</dc:description>
 <dc:description>Comment: Presented at the ICML 2017 Workshop on Principled Approaches to Deep
  Learning, Sydney, Australia, 2017</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07083</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>pocl: A Performance-Portable OpenCL Implementation</dc:title>
 <dc:creator>J&#xe4;&#xe4;skel&#xe4;inen, Pekka</dc:creator>
 <dc:creator>de La Lama, Carlos S&#xe1;nchez</dc:creator>
 <dc:creator>Schnetter, Erik</dc:creator>
 <dc:creator>Raiskila, Kalle</dc:creator>
 <dc:creator>Takala, Jarmo</dc:creator>
 <dc:creator>Berg, Heikki</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  OpenCL is a standard for parallel programming of heterogeneous systems. The
benefits of a common programming standard are clear; multiple vendors can
provide support for application descriptions written according to the standard,
thus reducing the program porting effort. While the standard brings the obvious
benefits of platform portability, the performance portability aspects are
largely left to the programmer. The situation is made worse due to multiple
proprietary vendor implementations with different characteristics, and, thus,
required optimization strategies.
  In this paper, we propose an OpenCL implementation that is both portable and
performance portable. At its core is a kernel compiler that can be used to
exploit the data parallelism of OpenCL programs on multiple platforms with
different parallel hardware styles. The kernel compiler is modularized to
perform target-independent parallel region formation separately from the
target-specific parallel mapping of the regions to enable support for various
styles of fine-grained parallel resources such as subword SIMD extensions, SIMD
datapaths and static multi-issue. Unlike previous similar techniques that work
on the source level, the parallel region formation retains the information of
the data parallelism using the LLVM IR and its metadata infrastructure. This
data can be exploited by the later generic compiler passes for efficient
parallelization.
  The proposed open source implementation of OpenCL is also platform portable,
enabling OpenCL on a wide range of architectures, both already commercialized
and on those that are still under research. The paper describes how the
portability of the implementation is achieved. Our results show that most of
the benchmarked applications when compiled using pocl were faster or close to
as fast as the best proprietary OpenCL implementation for the platform at hand.
</dc:description>
 <dc:description>Comment: This article was published in 2015; it is now openly accessible via
  arxiv</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07083</dc:identifier>
 <dc:identifier>Int J Parallel Prog (2015) 43: 752</dc:identifier>
 <dc:identifier>doi:10.1007/s10766-014-0320-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07096</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structured Prediction by Conditional Risk Minimization</dc:title>
 <dc:creator>Goh, Chong Yang</dc:creator>
 <dc:creator>Jaillet, Patrick</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a general approach for supervised learning with structured output
spaces, such as combinatorial and polyhedral sets, that is based on minimizing
estimated conditional risk functions. Given a loss function defined over pairs
of output labels, we first estimate the conditional risk function by solving a
(possibly infinite) collection of regularized least squares problems. A
prediction is made by solving an inference problem that minimizes the estimated
conditional risk function over the output space. We show that this approach
enables, in some cases, efficient training and inference without explicitly
introducing a convex surrogate for the original loss function, even when it is
discontinuous. Empirical evaluations on real-world and synthetic data sets
demonstrate the effectiveness of our method in adapting to a variety of loss
functions.
</dc:description>
 <dc:description>Comment: 19 pages, with supplements</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07096</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07098</identifier>
 <datestamp>2017-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Risk-Sensitive Learning and Pricing for Demand Response</dc:title>
 <dc:creator>Khezeli, Kia</dc:creator>
 <dc:creator>Bitar, Eilyan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We consider the setting in which an electric power utility seeks to curtail
its peak electricity demand by offering a fixed group of customers a uniform
price for reductions in consumption relative to their predetermined baselines.
The underlying demand curve, which describes the aggregate reduction in
consumption in response to the offered price, is assumed to be affine and
subject to unobservable random shocks. Assuming that both the parameters of the
demand curve and the distribution of the random shocks are initially unknown to
the utility, we investigate the extent to which the utility might dynamically
adjust its offered prices to maximize its cumulative risk-sensitive payoff over
a finite number of $T$ days. In order to do so effectively, the utility must
design its pricing policy to balance the tradeoff between the need to learn the
unknown demand model (exploration) and maximize its payoff (exploitation) over
time. In this paper, we propose such a pricing policy, which is shown to
exhibit an expected payoff loss over $T$ days that is at most $O(\sqrt{T})$,
relative to an oracle pricing policy that knows the underlying demand model.
Moreover, the proposed pricing policy is shown to yield a sequence of prices
that converge to the oracle optimal prices in the mean square sense.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-03-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07098</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07100</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpreting Finite Automata for Sequential Data</dc:title>
 <dc:creator>Hammerschmidt, Christian Albert</dc:creator>
 <dc:creator>Verwer, Sicco</dc:creator>
 <dc:creator>Lin, Qin</dc:creator>
 <dc:creator>State, Radu</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Automaton models are often seen as interpretable models. Interpretability
itself is not well defined: it remains unclear what interpretability means
without first explicitly specifying objectives or desired attributes. In this
paper, we identify the key properties used to interpret automata and propose a
modification of a state-merging approach to learn variants of finite state
automata. We apply the approach to problems beyond typical grammar inference
tasks. Additionally, we cover several use-cases for prediction, classification,
and clustering on sequential data in both supervised and unsupervised scenarios
to show how the identified key properties are applicable in a wide range of
contexts.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07102</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Manipulability of consular election rules</dc:title>
 <dc:creator>Ianovski, Egor</dc:creator>
 <dc:creator>Wilson, Mark C.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The Gibbard-Satterthwaite theorem is a cornerstone of social choice theory,
stating that an onto social choice function cannot be both strategy-proof and
non-dictatorial if the number of alternatives is at least three. The
Duggan-Schwartz theorem proves an analogue in the case of set-valued elections:
if the function is onto with respect to singletons, and can be manipulated by
neither an optimist nor a pessimist, it must have a weak dictator. However, the
assumption that the function is onto with respect to singletons makes the
Duggan-Schwartz theorem inapplicable to elections which necessarily select a
committee with multiple members. In this paper we make a start on this problem
by considering elections which elect a committee of size two (such as the
consulship of ancient Rome). We establish that if such a consular election rule
cannot be expressed as the union of two disjoint social choice functions, then
strategy-proofness implies the existence of a dictator. Although we suspect
that a similar result holds for larger sized committees, there appear to be
many obstacles to proving it, which we discuss in detail.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07105</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two statements of the Duggan-Schwartz theorem</dc:title>
 <dc:creator>Ianovski, Egor</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The Duggan-Schwartz theorem (Duggan and Schwartz, 1992) is a famous result
concerning strategy-proof social choice correspondences, often stated as &quot;A
social choice correspondence that can be manipulated by neither an optimist nor
a pessimist has a weak dictator&quot;. However, this formulation is actually due to
Taylor (2002), and the original theorem, at face value, looks rather different.
In this note we show that the two are in fact equivalent.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07109</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple Power Analysis Attack on the Twofish Key Schedule</dc:title>
 <dc:creator>Ortiz, Jose Javier Gonzalez</dc:creator>
 <dc:creator>Compton, Kevin J.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>E.3</dc:subject>
 <dc:description>  This paper introduces an SPA power attack on the 8-bit implementation of the
Twofish block cipher. The attack is able to unequivocally recover the secret
key even under substantial amounts of error. An initial algorithm is described
using exhaustive search on error free data. An error resistant algorithm is
later described. It employs several threshold preprocessing stages followed by
a combined approach of least mean squares and an optimized Hamming mask search.
Further analysis of 32 and 64-bit Twofish implementations reveals that they are
similarly vulnerable to the described SPA attack.
</dc:description>
 <dc:description>Comment: Keywords: Twofish, SPA, Power Attack, Block Cipher, Error Tolerance</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07112</identifier>
 <datestamp>2017-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Development of an EKF-based localization algorithm using compass sensor
  and LRF</dc:title>
 <dc:creator>Hoang, T. T.</dc:creator>
 <dc:creator>Duong, P. M.</dc:creator>
 <dc:creator>Van, N. T. T.</dc:creator>
 <dc:creator>Viet, D. A.</dc:creator>
 <dc:creator>Vinh, T. Q.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents the implementation of a perceptual system for a mobile
robot. The system is designed and installed with modern sensors and multi-point
communication channels. The goal is to equip the robot with a high level of
perception to support a wide range of navigating applications including
Internet-based telecontrol, semi-autonomy, and autonomy. Due to uncertainties
of acquiring data, a sensor fusion model is developed, in which heterogeneous
measured data including odometry, compass heading and laser range is combined
to get an optimal estimate in a statistical sense. The combination is carried
out by an extended Kalman filter. Experimental results indicate that based on
the system, the robot localization is enhanced and sufficient for navigation
tasks.
</dc:description>
 <dc:description>Comment: In 12th International Conference on Control Automation Robotics &amp;
  Vision (ICARCV), 2012. arXiv admin note: substantial text overlap with
  arXiv:1611.07114</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07112</dc:identifier>
 <dc:identifier>doi:10.1109/ICARCV.2012.6485182</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07114</identifier>
 <datestamp>2017-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-sensor perceptual system for mobile robot and sensor fusion-based
  localization</dc:title>
 <dc:creator>Hoang, T. T.</dc:creator>
 <dc:creator>Duong, P. M.</dc:creator>
 <dc:creator>Van, N. T. T.</dc:creator>
 <dc:creator>Viet, D. A.</dc:creator>
 <dc:creator>Vinh, T. Q.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents an Extended Kalman Filter (EKF) approach to localize a
mobile robot with two quadrature encoders, a compass sensor, a laser range
finder (LRF) and an omni-directional camera. The prediction step is performed
by employing the kinematic model of the robot as well as estimating the input
noise covariance matrix as being proportional to the wheel's angular speed. At
the correction step, the measurements from all sensors including incremental
pulses of the encoders, line segments of the LRF, robot orientation of the
compass and deflection angular of the omni-directional camera are fused.
Experiments in an indoor structured environment were implemented and the good
localization results prove the effectiveness and applicability of the
algorithm.
</dc:description>
 <dc:description>Comment: In 2012 International Conference on Control, Automation and
  Information Sciences (ICCAIS). arXiv admin note: substantial text overlap
  with arXiv:1611.07112</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07114</dc:identifier>
 <dc:identifier>doi:10.1109/ICCAIS.2012.6466599</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07115</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tree Space Prototypes: Another Look at Making Tree Ensembles
  Interpretable</dc:title>
 <dc:creator>Tan, Hui Fen</dc:creator>
 <dc:creator>Hooker, Giles</dc:creator>
 <dc:creator>Wells, Martin T.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Ensembles of decision trees have good prediction accuracy but suffer from a
lack of interpretability. We propose a new approach for interpreting tree
ensembles by finding prototypes in tree space, utilizing the naturally-learned
similarity measure from the tree ensemble. Demonstrating the method on random
forests, we show that the method benefits from unique aspects of tree ensembles
by leveraging tree structure to sequentially find prototypes. The method
provides good prediction accuracy when found prototypes are used in
nearest-prototype classifiers, while using fewer prototypes than competitor
methods. We are investigating the sensitivity of the method to different
prototype-finding procedures and demonstrating it on higher-dimensional data.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07119</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Max-Margin Deep Generative Models for (Semi-)Supervised Learning</dc:title>
 <dc:creator>Li, Chongxuan</dc:creator>
 <dc:creator>Zhu, Jun</dc:creator>
 <dc:creator>Zhang, Bo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep generative models (DGMs) are effective on learning multilayered
representations of complex data and performing inference of input data by
exploring the generative ability. However, it is relatively insufficient to
empower the discriminative ability of DGMs on making accurate predictions. This
paper presents max-margin deep generative models (mmDGMs) and a
class-conditional variant (mmDCGMs), which explore the strongly discriminative
principle of max-margin learning to improve the predictive performance of DGMs
in both supervised and semi-supervised learning, while retaining the generative
capability. In semi-supervised learning, we use the predictions of a max-margin
classifier as the missing labels instead of performing full posterior inference
for efficiency; we also introduce additional max-margin and label-balance
regularization terms of unlabeled data for effectiveness. We develop an
efficient doubly stochastic subgradient algorithm for the piecewise linear
objectives in different settings. Empirical results on various datasets
demonstrate that: (1) max-margin learning can significantly improve the
prediction performance of DGMs and meanwhile retain the generative ability; (2)
in supervised learning, mmDGMs are competitive to the best fully discriminative
networks when employing convolutional neural networks as the generative and
recognition models; and (3) in semi-supervised learning, mmDCGMs can perform
efficient inference and achieve state-of-the-art classification results on
several benchmarks.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1504.06787</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07124</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Outage Effective Capacity of Buffer-Aided Diamond Relay Systems Using
  HARQ with Incremental Redundancy</dc:title>
 <dc:creator>Qiao, Deli</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, transmission over buffer-aided diamond relay systems under
statistical quality of service (QoS) constraints is studied. The statistical
QoS constraints are imposed as limitations on delay violation probabilities. In
the absence of channel state information (CSI) at the transmitter, truncated
hybrid automatic repeat request-incremental redundancy (HARQ-IR) is
incorporated to make better use of the wireless channel and the resources for
each communication link. The packets that cannot be successfully received upon
the maximum number of transmissions will be removed from buffer, i.e., outage
occurs. The \emph{outage effective capacity} of a communication link is defined
as the maximum constant arrival rate to the source that can be supported by the
\emph{goodput} departure processes, i.e., the departure that can be
successfully received by the receiver. Then, the outage effective capacity for
the buffer-aided diamond relay system is obtained for HARQ-IR incorporated
transmission strategy under the \emph{end-to-end} delay constraints. In
comparison with the DF protocol with perfect CSI at the transmitters, it is
shown that HARQ-IR can achieve superior performance when the SNR levels at the
relay are not so large or when the delay constraints are stringent.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07124</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07135</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Citation Networks to Visualize Scholarly Influence Over Time</dc:title>
 <dc:creator>Portenoy, Jason</dc:creator>
 <dc:creator>Hullman, Jessica</dc:creator>
 <dc:creator>West, Jevin D.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:description>  Assessing the influence of a scholar's work is an important task for funding
organizations, academic departments, and researchers. Common methods, such as
measures of citation counts, can ignore much of the nuance and
multidimensionality of scholarly influence. We present an approach for
generating dynamic visualizations of scholars' careers. This approach uses an
animated node-link diagram showing the citation network accumulated around the
researcher over the course of the career in concert with key indicators,
highlighting influence both within and across fields. We developed our design
in collaboration with one funding organization---the Pew Biomedical Scholars
program---but the methods are generalizable to visualizations of scholarly
influence. We applied the design method to the Microsoft Academic Graph, which
includes more than 120 million publications. We validate our abstractions
throughout the process through collaboration with the Pew Biomedical Scholars
program officers and summative evaluations with their scholars.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07135</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07136</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cascaded Neural Networks with Selective Classifiers and its evaluation
  using Lung X-ray CT Images</dc:title>
 <dc:creator>Sakamoto, Masaharu</dc:creator>
 <dc:creator>Nakano, Hiroki</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Lung nodule detection is a class imbalanced problem because nodules are found
with much lower frequency than non-nodules. In the class imbalanced problem,
conventional classifiers tend to be overwhelmed by the majority class and
ignore the minority class. We therefore propose cascaded convolutional neural
networks to cope with the class imbalanced problem. In the proposed approach,
cascaded convolutional neural networks that perform as selective classifiers
filter out obvious non-nodules. Successively, a convolutional neural network
trained with a balanced data set calculates nodule probabilities. The proposed
method achieved the detection sensitivity of 85.3% and 90.7% at 1 and 4 false
positives per scan in FROC curve, respectively.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07138</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A new approach to Laplacian solvers and flow problems</dc:title>
 <dc:creator>Rebeschini, Patrick</dc:creator>
 <dc:creator>Tatikonda, Sekhar</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper investigates message-passing algorithms for solving systems of
linear equations in the Laplacian matrices of graphs and to compute electric
flows. These two problems are fundamental primitives that arise in several
domains such as computer science, electrical engineering, operations research,
and machine learning. Despite the extensive literature on approximately solving
these problems in quasi-linear time, the algorithms that have been proposed are
typically centralized and involve multiple graph theoretic constructions or
sampling mechanisms that make them difficult to implement and analyze. On the
other hand, message-passing routines are distributed, simple, and easy to
implement. In this paper we establish a framework to analyze message-passing
algorithms to solve voltage and flow problems. We characterize the error
committed by the algorithms in d-regular graphs with equal weights. We show
that the convergence of the algorithms is controlled by the total variation
distance between the distributions of non-backtracking random walks that start
from neighbor nodes. More broadly, our analysis of message-passing introduces
new insights to address generic optimization problems with constraints.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07138</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07139</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Natural Language Query Interface for Searching Personal Information on
  Smartwatches</dc:title>
 <dc:creator>Rawassizadeh, Reza</dc:creator>
 <dc:creator>Dobbins, Chelsea</dc:creator>
 <dc:creator>Nourizadeh, Manouchehr</dc:creator>
 <dc:creator>Ghamchili, Zahra</dc:creator>
 <dc:creator>Pazzani, Michael</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Currently, personal assistant systems, run on smartphones and use natural
language interfaces. However, these systems rely mostly on the web for finding
information. Mobile and wearable devices can collect an enormous amount of
contextual personal data such as sleep and physical activities. These
information objects and their applications are known as quantified-self, mobile
health or personal informatics, and they can be used to provide a deeper
insight into our behavior. To our knowledge, existing personal assistant
systems do not support all types of quantified-self queries. In response to
this, we have undertaken a user study to analyze a set of &quot;textual
questions/queries&quot; that users have used to search their quantified-self or
mobile health data. Through analyzing these questions, we have constructed a
light-weight natural language based query interface, including a text parser
algorithm and a user interface, to process the users' queries that have been
used for searching quantified-self information. This query interface has been
designed to operate on small devices, i.e. smartwatches, as well as augmenting
the personal assistant systems by allowing them to process end users' natural
language queries about their quantified-self data.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, 2 tables</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07143</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Multi-level Features For Sensor-based Human Action Recognition</dc:title>
 <dc:creator>Xu, Yan</dc:creator>
 <dc:creator>Shen, Zhengyang</dc:creator>
 <dc:creator>Zhang, Xin</dc:creator>
 <dc:creator>Gao, Yifan</dc:creator>
 <dc:creator>Deng, Shujian</dc:creator>
 <dc:creator>Wang, Yipei</dc:creator>
 <dc:creator>Fan, Yubo</dc:creator>
 <dc:creator>Chang, Eric I-Chao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.5.2</dc:subject>
 <dc:description>  This paper proposes a multi-level feature learning framework for human action
recognition using a single body-worn inertial sensor. The framework consists of
three phases, respectively designed to analyze signal-based (low-level),
components (mid-level) and semantic (high-level) information. Low-level
features capture the time and frequency domain property while mid-level
representations learn the composition of the action. The Max-margin Latent
Pattern Learning (MLPL) method is proposed to learn high-level semantic
descriptions of latent action patterns as the output of our framework. The
proposed method achieves the state-of-the-art performances, 88.7%, 98.8% and
72.6% (weighted F1 score) respectively, on Skoda, WISDM and OPP datasets.
</dc:description>
 <dc:description>Comment: 26 pages, 23 figures</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07143</dc:identifier>
 <dc:identifier>Pervasive and Mobile Computing, Volume 40, September 2017, Pages
  324-338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07144</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster integer multiplication using plain vanilla FFT primes</dc:title>
 <dc:creator>Harvey, David</dc:creator>
 <dc:creator>van der Hoeven, Joris</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>68W30, 68Q17, 68W40</dc:subject>
 <dc:subject>G.1.0</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:description>  Assuming a conjectural upper bound for the least prime in an arithmetic
progression, we show that n-bit integers may be multiplied in O(n log n
4^(log^* n)) bit operations.
</dc:description>
 <dc:description>Comment: 14 pages, to appear in Mathematics of Computation</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-10-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07145</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Multi-level Deep Representations for Image Emotion
  Classification</dc:title>
 <dc:creator>Rao, Tianrong</dc:creator>
 <dc:creator>Xu, Min</dc:creator>
 <dc:creator>Xu, Dong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a new deep network that learns multi-level deep
representations for image emotion classification (MldrNet). Image emotion can
be recognized through image semantics, image aesthetics and low-level visual
features from both global and local views. Existing image emotion
classification works using hand-crafted features or deep features mainly focus
on either low-level visual features or semantic-level image representations
without taking all factors into consideration. Our proposed MldrNet unifies
deep representations of three levels, i.e. image semantics, image aesthetics
and low-level visual features through multiple instance learning (MIL) in order
to effectively cope with noisy labeled data, such as images collected from the
Internet. Extensive experiments on both Internet images and abstract paintings
demonstrate the proposed method outperforms the state-of-the-art methods using
deep features or hand-crafted features. The proposed approach also outperforms
the state-of-the-art methods with at least 6% performance improvement in terms
of overall classification accuracy.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07145</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07151</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast and Energy-Efficient CNN Inference on IoT Devices</dc:title>
 <dc:creator>Motamedi, Mohammad</dc:creator>
 <dc:creator>Fong, Daniel</dc:creator>
 <dc:creator>Ghiasi, Soheil</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Convolutional Neural Networks (CNNs) exhibit remarkable performance in
various machine learning tasks. As sensor-equipped internet of things (IoT)
devices permeate into every aspect of modern life, it is increasingly important
to run CNN inference, a computationally intensive application, on resource
constrained devices. We present a technique for fast and energy-efficient CNN
inference on mobile SoC platforms, which are projected to be a major player in
the IoT space. We propose techniques for efficient parallelization of CNN
inference targeting mobile GPUs, and explore the underlying tradeoffs.
Experiments with running Squeezenet on three different mobile devices confirm
the effectiveness of our approach. For further study, please refer to the
project repository available on our GitHub page:
https://github.com/mtmd/Mobile_ConvNet
</dc:description>
 <dc:description>Comment: 7 pages, 10 figures</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07156</identifier>
 <datestamp>2017-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Web Images for Dataset Construction: A Domain Robust Approach</dc:title>
 <dc:creator>Yao, Yazhou</dc:creator>
 <dc:creator>Zhang, Jian</dc:creator>
 <dc:creator>Shen, Fumin</dc:creator>
 <dc:creator>Hua, Xiansheng</dc:creator>
 <dc:creator>Xu, Jingsong</dc:creator>
 <dc:creator>Tang, Zhenmin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Labelled image datasets have played a critical role in high-level image
understanding. However, the process of manual labelling is both time-consuming
and labor intensive. To reduce the cost of manual labelling, there has been
increased research interest in automatically constructing image datasets by
exploiting web images. Datasets constructed by existing methods tend to have a
weak domain adaptation ability, which is known as the &quot;dataset bias problem&quot;.
To address this issue, we present a novel image dataset construction framework
that can be generalized well to unseen target domains. Specifically, the given
queries are first expanded by searching the Google Books Ngrams Corpus to
obtain a rich semantic description, from which the visually non-salient and
less relevant expansions are filtered out. By treating each selected expansion
as a &quot;bag&quot; and the retrieved images as &quot;instances&quot;, image selection can be
formulated as a multi-instance learning problem with constrained positive bags.
We propose to solve the employed problems by the cutting-plane and
concave-convex procedure (CCCP) algorithm. By using this approach, images from
different distributions can be kept while noisy images are filtered out. To
verify the effectiveness of our proposed approach, we build an image dataset
with 20 categories. Extensive experiments on image classification,
cross-dataset generalization, diversity comparison and object detection
demonstrate the domain robustness of our dataset.
</dc:description>
 <dc:description>Comment: Journal</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07156</dc:identifier>
 <dc:identifier>doi:10.1109/TMM.2017.2684626</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07163</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Will My Tests Tell Me If I Break This Code?</dc:title>
 <dc:creator>Niedermayr, Rainer</dc:creator>
 <dc:creator>Juergens, Elmar</dc:creator>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Automated tests play an important role in software evolution because they can
rapidly detect faults introduced during changes. In practice, code-coverage
metrics are often used as criteria to evaluate the effectiveness of test suites
with focus on regression faults. However, code coverage only expresses which
portion of a system has been executed by tests, but not how effective the tests
actually are in detecting regression faults. Our goal was to evaluate the
validity of code coverage as a measure for test effectiveness. To do so, we
conducted an empirical study in which we applied an extreme mutation testing
approach to analyze the tests of open-source projects written in Java. We
assessed the ratio of pseudo-tested methods (those tested in a way such that
faults would not be detected) to all covered methods and judged their impact on
the software project. The results show that the ratio of pseudo-tested methods
is acceptable for unit tests but not for system tests (that execute large
portions of the whole system). Therefore, we conclude that the coverage metric
is only a valid effectiveness indicator for unit tests.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07163</dc:identifier>
 <dc:identifier>Proceedings of the International Workshop on Continuous Software
  Evolution and Delivery (CSED '16). ACM, 2016</dc:identifier>
 <dc:identifier>doi:10.1145/2896941.2896944</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07164</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distance verification for classical and quantum LDPC codes</dc:title>
 <dc:creator>Dumer, Ilya</dc:creator>
 <dc:creator>Kovalev, Alexey A.</dc:creator>
 <dc:creator>Pryadko, Leonid P.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  The techniques of distance verification known for general linear codes are
re-applied to quantum stabilizer codes. Then distance verification is addressed
for classical and quantum LDPC codes. New complexity bounds for distance
verification with provable performance are derived using the average weight
spectra of the ensembles of LDPC codes. These bounds are expressed in terms of
the erasure-correcting capacity of the corresponding ensemble. We also present
a new irreducible-cluster technique that can be applied to any LDPC code and
takes advantage of parity-checks' sparsity for both classical and quantum LDPC
codes. This technique reduces complexity exponents of all existing
deterministic techniques designed for generic stabilizer codes with small
relative distances, which also include all known families of quantum LDPC
codes.
</dc:description>
 <dc:description>Comment: 16 pages, 2 figures</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07169</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quasi-regular sequences and optimal schedules for security games</dc:title>
 <dc:creator>Kempe, David</dc:creator>
 <dc:creator>Schulman, Leonard J.</dc:creator>
 <dc:creator>Tamuz, Omer</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study security games in which a defender commits to a mixed strategy for
protecting a finite set of targets of different values. An attacker, knowing
the defender's strategy, chooses which target to attack and for how long. If
the attacker spends time $t$ at a target $i$ of value $\alpha_i$, and if he
leaves before the defender visits the target, his utility is $t \cdot \alpha_i
$; if the defender visits before he leaves, his utility is 0. The defender's
goal is to minimize the attacker's utility. The defender's strategy consists of
a schedule for visiting the targets; it takes her unit time to switch between
targets. Such games are a simplified model of a number of real-world scenarios
such as protecting computer networks from intruders, crops from thieves, etc.
  We show that optimal defender play for this continuous time security games
reduces to the solution of a combinatorial question regarding the existence of
infinite sequences over a finite alphabet, with the following properties for
each symbol $i$: (1) $i$ constitutes a prescribed fraction $p_i$ of the
sequence. (2) The occurrences of $i$ are spread apart close to evenly, in that
the ratio of the longest to shortest interval between consecutive occurrences
is bounded by a parameter $K$. We call such sequences $K$-quasi-regular.
  We show that, surprisingly, $2$-quasi-regular sequences suffice for optimal
defender play. What is more, even randomized $2$-quasi-regular sequences
suffice for optimality. We show that such sequences always exist, and can be
calculated efficiently.
  The question of the least $K$ for which deterministic $K$-quasi-regular
sequences exist is fascinating. Using an ergodic theoretical approach, we show
that deterministic $3$-quasi-regular sequences always exist. For $2 \leq K &lt; 3$
we do not know whether deterministic $K$-quasi-regular sequences always exist.
</dc:description>
 <dc:description>Comment: to appear in Proc. of SODA 2018</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07174</identifier>
 <datestamp>2016-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Recurrent Convolutional Neural Network: Improving Performance For
  Speech Recognition</dc:title>
 <dc:creator>Zhang, Zewang</dc:creator>
 <dc:creator>Sun, Zheng</dc:creator>
 <dc:creator>Liu, Jiaqi</dc:creator>
 <dc:creator>Chen, Jingwen</dc:creator>
 <dc:creator>Huo, Zhao</dc:creator>
 <dc:creator>Zhang, Xiao</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A deep learning approach has been widely applied in sequence modeling
problems. In terms of automatic speech recognition (ASR), its performance has
significantly been improved by increasing large speech corpus and deeper neural
network. Especially, recurrent neural network and deep convolutional neural
network have been applied in ASR successfully. Given the arising problem of
training speed, we build a novel deep recurrent convolutional network for
acoustic modeling and then apply deep residual learning to it. Our experiments
show that it has not only faster convergence speed but better recognition
accuracy over traditional deep convolutional recurrent network. In the
experiments, we compare the convergence speed of our novel deep recurrent
convolutional networks and traditional deep convolutional recurrent networks.
With faster convergence speed, our novel deep recurrent convolutional networks
can reach the comparable performance. We further show that applying deep
residual learning can boost the convergence speed of our novel deep recurret
convolutional networks. Finally, we evaluate all our experimental networks by
phoneme error rate (PER) with our proposed bidirectional statistical n-gram
language model. Our evaluation results show that our newly proposed deep
recurrent convolutional network applied with deep residual learning can reach
the best PER of 17.33\% with the fastest convergence speed on TIMIT database.
The outstanding performance of our novel deep recurrent convolutional neural
network with deep residual learning indicates that it can be potentially
adopted in other sequential problems.
</dc:description>
 <dc:description>Comment: 11 pages, 13 figures</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2016-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07175</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Local and Remote Controllers with Unreliable Uplink Channels</dc:title>
 <dc:creator>Asghari, Seyed Mohammad</dc:creator>
 <dc:creator>Ouyang, Yi</dc:creator>
 <dc:creator>Nayyar, Ashutosh</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We consider a networked control system consisting of a remote controller and
a collection of linear plants, each associated with a local controller. Each
local controller directly observes the state of its co-located plant and can
inform the remote controller of the plant's state through an unreliable uplink
channel. We assume that the downlink channels from the remote controller to
local controllers are perfect. The objective of the local controllers and the
remote controller is to cooperatively minimize a quadratic performance cost. We
provide a dynamic program for this decentralized control problem using the
common information approach. Although our problem is not a partially nested
problem, we obtain explicit optimal strategies for all controllers. In the
optimal strategies, all controllers compute common estimates of the states of
the plants based on the common information from the communication network. The
remote controller's action is linear in the common estimated states, and the
action of each local controller is linear in both the actual state of its
co-located plant and the common estimated states. We illustrate our results
with a platoon control problem for autonomous vehicles.
</dc:description>
 <dc:description>Comment: 39 pages, Submitted to IEEE Transactions on Automatic Control</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07178</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings Fifth Workshop on Synthesis</dc:title>
 <dc:creator>Piskac, Ruzica</dc:creator>
 <dc:creator>Dimitrova, Rayna</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The SYNT workshop aims to bring together researchers interested in the broad
area of synthesis of computing systems. The goal is to foster the development
of frontier techniques in automating the development of computing system.
Contributions of interest include algorithms, complexity and decidability
analysis, as well as reproducible heuristics, implemented tools, and
experimental evaluation. Application domains include software, hardware,
embedded, and cyberphysical systems. Computation models include functional,
reactive, hybrid and timed systems. Identifying, formalizing, and evaluating
synthesis in particular application domains is encouraged.
  The fifth iteration of the workshop took place in Toronto, Canada. It was
co-located with the 28th International Conference on Computer Aided
Verification. The workshop included twelve contributed talks and two invited
talks. In addition, it featured a special session about the Syntax-Guided
Synthesis Competition (SyGuS) and the SyntComp Synthesis competition.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07178</dc:identifier>
 <dc:identifier>EPTCS 229, 2016</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.229</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07188</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New bounds of permutation codes under Hamming metric and Kendall's
  $\tau$-metric</dc:title>
 <dc:creator>Wang, Xin</dc:creator>
 <dc:creator>Zhang, Yiwei</dc:creator>
 <dc:creator>Yang, Yiting</dc:creator>
 <dc:creator>Ge, Gennian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Permutation codes are widely studied objects due to their numerous
applications in various areas, such as power line communications, block
ciphers, and the rank modulation scheme for flash memories. Several kinds of
metrics are considered for permutation codes according to their specific
applications. This paper concerns some improvements on the bounds of
permutation codes under Hamming metric and Kendall's $\tau$-metric
respectively, using mainly a graph coloring approach. Specifically, under
Hamming metric, we improve the Gilbert-Varshamov bound asymptotically by a
factor $n$, when the minimum Hamming distance $d$ is fixed and the code length
$n$ goes to infinity. Under Kendall's $\tau$-metric, we narrow the gap between
the known lower bounds and upper bounds. Besides, we also obtain some sporadic
results under Kendall's $\tau$-metric for small parameters.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07191</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributable Consistent Multi-Graph Matching</dc:title>
 <dc:creator>Hu, Nan</dc:creator>
 <dc:creator>Thibert, Boris</dc:creator>
 <dc:creator>Guibas, Leonidas</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we propose an optimization-based framework to multiple graph
matching. The framework takes as input maps computed between pairs of graphs,
and outputs maps that 1) are consistent among all pairs of graphs, and 2)
preserve edge connectivity between pairs of graphs. We show how to formulate
this as solving a piece-wise low-rank matrix recovery problem using a
generalized message passing scheme. We also present necessary and sufficient
conditions under which such global consistency is guaranteed. The key feature
of our approach is that it is scalable to large datasets, while still produce
maps whose quality is competent against state-of-the-art global
optimization-based techniques.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07206</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Distill: The Essence Vector Modeling Framework</dc:title>
 <dc:creator>Chen, Kuan-Yu</dc:creator>
 <dc:creator>Liu, Shih-Hung</dc:creator>
 <dc:creator>Chen, Berlin</dc:creator>
 <dc:creator>Wang, Hsin-Min</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In the context of natural language processing, representation learning has
emerged as a newly active research subject because of its excellent performance
in many applications. Learning representations of words is a pioneering study
in this school of research. However, paragraph (or sentence and document)
embedding learning is more suitable/reasonable for some tasks, such as
sentiment classification and document summarization. Nevertheless, as far as we
are aware, there is relatively less work focusing on the development of
unsupervised paragraph embedding methods. Classic paragraph embedding methods
infer the representation of a given paragraph by considering all of the words
occurring in the paragraph. Consequently, those stop or function words that
occur frequently may mislead the embedding learning process to produce a misty
paragraph representation. Motivated by these observations, our major
contributions in this paper are twofold. First, we propose a novel unsupervised
paragraph embedding method, named the essence vector (EV) model, which aims at
not only distilling the most representative information from a paragraph but
also excluding the general background information to produce a more informative
low-dimensional vector representation for the paragraph. Second, in view of the
increasing importance of spoken content processing, an extension of the EV
model, named the denoising essence vector (D-EV) model, is proposed. The D-EV
model not only inherits the advantages of the EV model but also can infer a
more robust representation for a given spoken paragraph against imperfect
speech recognition.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07212</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Attention Models for Depth-Based Person Identification</dc:title>
 <dc:creator>Haque, Albert</dc:creator>
 <dc:creator>Alahi, Alexandre</dc:creator>
 <dc:creator>Fei-Fei, Li</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present an attention-based model that reasons on human body shape and
motion dynamics to identify individuals in the absence of RGB information,
hence in the dark. Our approach leverages unique 4D spatio-temporal signatures
to address the identification problem across days. Formulated as a
reinforcement learning task, our model is based on a combination of
convolutional and recurrent neural networks with the goal of identifying small,
discriminative regions indicative of human identity. We demonstrate that our
model produces state-of-the-art results on several published datasets given
only depth images. We further study the robustness of our model towards
viewpoint, appearance, and volumetric changes. Finally, we share insights
gleaned from interpretable 2D, 3D, and 4D visualizations of our model's
spatio-temporal attention.
</dc:description>
 <dc:description>Comment: Computer Vision and Pattern Recognition (CVPR) 2016</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07214</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparing entropy rates on finite and infinite rooted trees</dc:title>
 <dc:creator>Hirschler, Thomas</dc:creator>
 <dc:creator>Woess, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>94A17, 60G99, 05C05</dc:subject>
 <dc:description>  We consider stochastic processes with (or without) memory whose evolution is
encoded by a finite or infinite rooted tree. The main goal is to compare the
entropy rates of a given base process and a second one, to be considered as a
perturbation of the former. The processes are described by probability measures
on the boundary of the given tree, and by corresponding forward transition
probabilities at the inner nodes. The comparison is in terms of
Kullback-Leibler divergence. We elaborate and extend ideas and results of
B\&quot;ocherer and Amjad. Our extensions involve length functions on the edges of
the tree as well as nodes with countably many successors. In particular, in the
last part, we consider trees with infinite geodesic rays and random
perturbations of a given process.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07216</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What to Expect When You Are Expecting on the Grassmannian</dc:title>
 <dc:creator>Eftekhari, Armin</dc:creator>
 <dc:creator>Balzano, Laura</dc:creator>
 <dc:creator>Wakin, Michael B.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Consider an incoming sequence of vectors, all belonging to an unknown
subspace $\operatorname{S}$, and each with many missing entries. In order to
estimate $\operatorname{S}$, it is common to partition the data into blocks and
iteratively update the estimate of $\operatorname{S}$ with each new incoming
measurement block.
  In this paper, we investigate a rather basic question: Is it possible to
identify $\operatorname{S}$ by averaging the column span of the partially
observed incoming measurement blocks on the Grassmannian?
  We show that in general the span of the incoming blocks is in fact a biased
estimator of $\operatorname{S}$ when data suffers from erasures, and we find an
upper bound for this bias. We reach this conclusion by examining the defining
optimization program for the Fr\'{e}chet expectation on the Grassmannian, and
with the aid of a sharp perturbation bound and standard large deviation
results.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-03-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07216</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2017.2684784</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07218</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object detection can be improved using human-derived contextual
  expectations</dc:title>
 <dc:creator>Katti, Harish</dc:creator>
 <dc:creator>Peelen, Marius V.</dc:creator>
 <dc:creator>Arun, S. P.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Each object in the world occurs in a specific context: cars are seen on
highways but not in forests. Contextual information is generally thought to
facilitate computation by constraining locations to search. But can knowing
context yield tangible benefits in object detection? For it to do so, scene
context needs to be learned independently from target features. However this is
impossible in traditional object detection where classifiers are trained on
images containing both target features and surrounding coarse scene features.
In contrast, we humans have the opportunity to learn context and target
features separately, such as when we see highways without cars. Here we show
for the first time that human-derived scene expectations can be used to improve
object detection performance in machines. To measure these expectations, we
asked human subjects to indicate the scale, location and likelihood at which
targets may occur on scenes containing no targets. Humans showed highly
systematic expectations that we could accurately predict using scene features.
We then augmented state-of-the-art object detectors (based on deep neural
networks) with these human-derived expectations on novel scenes to produce a
significant (1-3%) improvement in detecting cars and people in scenes. This
improvement was due to low-confidence detector matches being correctly
relabeled as targets when they occurred in likely scenes.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-10-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07224</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Feedback Mechanisms for FDD Massive MIMO under User-level
  Cooperation</dc:title>
 <dc:creator>Chen, Junting</dc:creator>
 <dc:creator>Yin, Haifan</dc:creator>
 <dc:creator>Cottatellucci, Laura</dc:creator>
 <dc:creator>Gesbert, David</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Channel state information (CSI) feedback is a challenging issue in frequency
division multiplexing (FDD) massive MIMO systems. This paper studies a
cooperative feedback scheme, where the users first exchange their CSI with each
other by exploiting device-to-device (D2D) communications, then compute the
precoder by themselves, and feed back the precoder to the base station (BS).
Analytical results are derived to show that the cooperative precoder feedback
is more efficient than the CSI feedback in terms of interference mitigation.
Under the constraint of limited D2D communication capacity, we develop an
adaptive CSI exchange strategy based on signal subspace projection and optimal
bit partition. Numerical results demonstrate that the proposed cooperative
precoder feedback scheme with adaptive CSI exchange significantly outperforms
the CSI feedback scheme, even when the CSI is exchanged via rate-limited D2D
communications.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07231</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Spatial and Temporal Non-Local Filter Based Data Fusion</dc:title>
 <dc:creator>Cheng, Qing</dc:creator>
 <dc:creator>Liu, Huiqing</dc:creator>
 <dc:creator>Shen, Huanfeng</dc:creator>
 <dc:creator>Wu, Penghai</dc:creator>
 <dc:creator>Zhang, Liangpei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The trade-off in remote sensing instruments that balances the spatial
resolution and temporal frequency limits our capacity to monitor spatial and
temporal dynamics effectively. The spatiotemporal data fusion technique is
considered as a cost-effective way to obtain remote sensing data with both high
spatial resolution and high temporal frequency, by blending observations from
multiple sensors with different advantages or characteristics. In this paper,
we develop the spatial and temporal non-local filter based fusion model
(STNLFFM) to enhance the prediction capacity and accuracy, especially for
complex changed landscapes. The STNLFFM method provides a new transformation
relationship between the fine-resolution reflectance images acquired from the
same sensor at different dates with the help of coarse-resolution reflectance
data, and makes full use of the high degree of spatiotemporal redundancy in the
remote sensing image sequence to produce the final prediction. The proposed
method was tested over both the Coleambally Irrigation Area study site and the
Lower Gwydir Catchment study site. The results show that the proposed method
can provide a more accurate and robust prediction, especially for heterogeneous
landscapes and temporally dynamic areas.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07231</dc:identifier>
 <dc:identifier>doi:10.1109/TGRS.2017.2692802</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07232</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compositional Learning of Relation Path Embedding for Knowledge Base
  Completion</dc:title>
 <dc:creator>Lin, Xixun</dc:creator>
 <dc:creator>Liang, Yanchun</dc:creator>
 <dc:creator>Giunchiglia, Fausto</dc:creator>
 <dc:creator>Feng, Xiaoyue</dc:creator>
 <dc:creator>Guan, Renchu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Large-scale knowledge bases have currently reached impressive sizes; however,
these knowledge bases are still far from complete. In addition, most of the
existing methods for knowledge base completion only consider the direct links
between entities, ignoring the vital impact of the consistent semantics of
relation paths. In this paper, we study the problem of how to better embed
entities and relations of knowledge bases into different low-dimensional spaces
by taking full advantage of the additional semantics of relation paths, and we
propose a compositional learning model of relation path embedding (RPE).
Specifically, with the corresponding relation and path projections, RPE can
simultaneously embed each entity into two types of latent spaces. It is also
proposed that type constraints could be extended from traditional
relation-specific constraints to the new proposed path-specific constraints.
The results of experiments show that the proposed model achieves significant
and consistent improvements compared with the state-of-the-art algorithms.
</dc:description>
 <dc:description>Comment: 7 pages,1 figure</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07233</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CAS-CNN: A Deep Convolutional Neural Network for Image Compression
  Artifact Suppression</dc:title>
 <dc:creator>Cavigelli, Lukas</dc:creator>
 <dc:creator>Hager, Pascal</dc:creator>
 <dc:creator>Benini, Luca</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Lossy image compression algorithms are pervasively used to reduce the size of
images transmitted over the web and recorded on data storage media. However, we
pay for their high compression rate with visual artifacts degrading the user
experience. Deep convolutional neural networks have become a widespread tool to
address high-level computer vision tasks very successfully. Recently, they have
found their way into the areas of low-level computer vision and image
processing to solve regression problems mostly with relatively shallow
networks.
  We present a novel 12-layer deep convolutional network for image compression
artifact suppression with hierarchical skip connections and a multi-scale loss
function. We achieve a boost of up to 1.79 dB in PSNR over ordinary JPEG and an
improvement of up to 0.36 dB over the best previous ConvNet result. We show
that a network trained for a specific quality factor (QF) is resilient to the
QF used to compress the input image - a single network trained for QF 60
provides a PSNR gain of more than 1.5 dB over the wide QF range from 40 to 76.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07235</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identity Testing for +-Regular Noncommutative Arithmetic Circuits</dc:title>
 <dc:creator>Arvind, Vikraman</dc:creator>
 <dc:creator>Joglekar, Pushkar</dc:creator>
 <dc:creator>Mukhopadhyay, Partha</dc:creator>
 <dc:creator>Raja, S</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  An efficient randomized polynomial identity test for noncommutative
polynomials given by noncommutative arithmetic circuits remains an open
problem. The main bottleneck to applying known techniques is that a
noncommutative circuit of size $s$ can compute a polynomial of degree
exponential in $s$ with a double-exponential number of nonzero monomials. In
this paper, we report some progress by dealing with two natural subcases (both
allow for polynomials of exponential degree and a double exponential number of
monomials): (1) We consider \emph{$+$-regular} noncommutative circuits: these
are homogeneous noncommutative circuits with the additional property that all
the $+$-gates are layered, and in each $+$-layer all gates have the same
syntactic degree. We give a \emph{white-box} polynomial-time deterministic
polynomial identity test for such circuits. Our algorithm combines some new
structural results for $+$-regular circuits with known results for
noncommutative ABP identity testing [RS05PIT], rank bound of commutative depth
three identities [SS13], and equivalence testing problem for words [Loh15,
MSU97, Pla94]. (2) Next, we consider $\Sigma\Pi^*\Sigma$ noncommutative
circuits: these are noncommutative circuits with layered $+$-gates such that
there are only two layers of $+$-gates. These $+$-layers are the output
$+$-gate and linear forms at the bottom layer; between the $+$-layers the
circuit could have any number of $\times$ gates. We given an efficient
randomized \emph{black-box} identity testing problem for $\Sigma\Pi^*\Sigma$
circuits. In particular, we show if $f\in F&lt;Z&gt;$ is a nonzero noncommutative
polynomial computed by a $\Sigma\Pi^*\Sigma$ circuit of size $s$, then $f$
cannot be a polynomial identity for the matrix algebra $\mathbb{M}_s(F)$, where
the field $F$ is a sufficiently large extension of $F$ depending on the degree
of $f$.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07238</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time and Space Optimal Counting in Population Protocols</dc:title>
 <dc:creator>Aspnes, James</dc:creator>
 <dc:creator>Beauquier, Joffroy</dc:creator>
 <dc:creator>Burman, Janna</dc:creator>
 <dc:creator>Sohier, Devan</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This work concerns the general issue of combined optimality in terms of time
and space complexity. In this context, we study the problem of (exact) counting
resource-limited and passively mobile nodes in the model of population
protocols, in which the space complexity is crucial. The counted nodes are
memory-limited anonymous devices (called agents) communicating asynchronously
in pairs (according to a fairness condition). Moreover, we assume that these
agents are prone to failures so that they cannot be correctly initialized. This
study considers two classical fairness conditions, and for each we investigate
the issue of time optimality of counting given the optimal space per agent. In
the case of randomly interacting agents (probabilistic fairness), as usual, the
convergence time is measured in terms of parallel time (or parallel
interactions), which is defined as the number of pairwise interactions until
convergence, divided by n (the number of agents). In case of weak fairness,
where it is only required that every pair of agents interacts infinitely often,
the convergence time is defined in terms of non-null transitions, i.e, the
transitions that affect the states of the interacting agents.First, assuming
probabilistic fairness, we present a &quot;non-guessing&quot; time optimal protocol of
O(n log n) expected time given an optimal space of only one bit, and we prove
the time optimality of this protocol. Then, for weak fairness, we show that a
space optimal (semi-uniform) solution cannot converge faster than in
$\Omega$(2^n) time (non-null transitions). This result, together with the time
complexity analysis of an already known space optimal protocol, shows that it
is also optimal in time (given the optimal space constrains).
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07238</dc:identifier>
 <dc:identifier>20th International Conference on Principles of Distributed
  Systems, OPODIS 2015, Dec 2016, Madrid, Spain. 2016, 20th International
  Conference on Principles of Distributed Systems, OPODIS 2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07245</identifier>
 <datestamp>2017-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Single-View and Multi-View Depth Fusion</dc:title>
 <dc:creator>F&#xe1;cil, Jos&#xe9; M.</dc:creator>
 <dc:creator>Concha, Alejo</dc:creator>
 <dc:creator>Montesano, Luis</dc:creator>
 <dc:creator>Civera, Javier</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Dense and accurate 3D mapping from a monocular sequence is a key technology
for several applications and still an open research area. This paper leverages
recent results on single-view CNN-based depth estimation and fuses them with
multi-view depth estimation. Both approaches present complementary strengths.
Multi-view depth is highly accurate but only in high-texture areas and
high-parallax cases. Single-view depth captures the local structure of
mid-level regions, including texture-less areas, but the estimated depth lacks
global coherence. The single and multi-view fusion we propose is challenging in
several aspects. First, both depths are related by a deformation that depends
on the image content. Second, the selection of multi-view points of high
accuracy might be difficult for low-parallax configurations. We present
contributions for both problems. Our results in the public datasets of NYUv2
and TUM shows that our algorithm outperforms the individual single and
multi-view approaches. A video showing the key aspects of mapping in our Single
and Multi-view depth proposal is available at https://youtu.be/ipc5HukTb4k
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Robotics and Automation Letters</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-06-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07245</dc:identifier>
 <dc:identifier>doi:10.1109/LRA.2017.2715400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07252</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpretable Recurrent Neural Networks Using Sequential Sparse Recovery</dc:title>
 <dc:creator>Wisdom, Scott</dc:creator>
 <dc:creator>Powers, Thomas</dc:creator>
 <dc:creator>Pitton, James</dc:creator>
 <dc:creator>Atlas, Les</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recurrent neural networks (RNNs) are powerful and effective for processing
sequential data. However, RNNs are usually considered &quot;black box&quot; models whose
internal structure and learned parameters are not interpretable. In this paper,
we propose an interpretable RNN based on the sequential iterative
soft-thresholding algorithm (SISTA) for solving the sequential sparse recovery
problem, which models a sequence of correlated observations with a sequence of
sparse latent vectors. The architecture of the resulting SISTA-RNN is
implicitly defined by the computational structure of SISTA, which results in a
novel stacked RNN architecture. Furthermore, the weights of the SISTA-RNN are
perfectly interpretable as the parameters of a principled statistical model,
which in this case include a sparsifying dictionary, iterative step size, and
regularization parameters. In addition, on a particular sequential compressive
sensing task, the SISTA-RNN trains faster and achieves better performance than
conventional state-of-the-art black box RNNs, including long-short term memory
(LSTM) RNNs.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07255</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Standardization and Conservativity of a Refined Call-by-Value
  lambda-Calculus</dc:title>
 <dc:creator>Guerrieri, Giulio</dc:creator>
 <dc:creator>Paolini, Luca</dc:creator>
 <dc:creator>Della Rocca, Simona Ronchi</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03B40, 68N18</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  We study an extension of Plotkin's call-by-value lambda-calculus via two
commutation rules (sigma-reductions). These commutation rules are sufficient to
remove harmful call-by-value normal forms from the calculus, so that it enjoys
elegant characterizations of many semantic properties. We prove that this
extended calculus is a conservative refinement of Plotkin's one. In particular,
the notions of solvability and potential valuability for this calculus coincide
with those for Plotkin's call-by-value lambda-calculus. The proof rests on a
standardization theorem proved by generalizing Takahashi's approach of parallel
reductions to our set of reduction rules. The standardization is weak (i.e.
redexes are not fully sequentialized) because of overlapping interferences
between reductions.
</dc:description>
 <dc:description>Comment: 27 pages</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07255</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 4 (December
  22, 2017) lmcs:4162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07258</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uniform s-cross-intersecting families</dc:title>
 <dc:creator>Frankl, Peter</dc:creator>
 <dc:creator>Kupavskii, Andrey</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  In this paper we study a question related to the classical Erd\H{o}s-Ko-Rado
theorem, which states that any family of $k$-element subsets of the set $[n] =
\{1,\ldots,n\}$ in which any two sets intersect, has cardinality at most
${n-1\choose k-1}$.
  We say that two non-empty families are $\mathcal A, \mathcal B\subset
{[n]\choose k}$ are {\it $s$-cross-intersecting}, if for any $A\in\mathcal
A,B\in \mathcal B$ we have $|A\cap B|\ge s$. In this paper we determine the
maximum of $|\mathcal A|+|\mathcal B|$ for all $n$. This generalizes a result
of Hilton and Milner, who determined the maximum of $|\mathcal A|+|\mathcal B|$
for nonempty $1$-cross-intersecting families.
</dc:description>
 <dc:description>Comment: This article was previously a portion of arXiv:1603.00938v1, which
  has been split</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07260</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Short monadic second order sentences about sparse random graphs</dc:title>
 <dc:creator>Kupavskii, Andrey</dc:creator>
 <dc:creator>Zhukovskii, Maksim</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  In this paper, we study the so-called zero-one laws for the
Erd\H{o}s-R\'{e}nyi random graph model $G(n,p)$ in the case when $p =
n^{-\alpha}$ for $\alpha&gt;0$. For a given class of properties and $p$, we say
that $G(n,p)$ obeys the zero-one law if any formula from the class either
a.a.s. holds or a.a.s. does not hold in $G(n,p)$. In this paper, we consider
first order properties and monadic second order properties of bounded
\textit{quantifier depth} $k$, that is, the length of the longest chain of
nested quantifiers in the formula expressing the property. Zero-one laws for
properties of quantifier depth $k$ we call the zero-one $k$-laws.
  The main results of this paper concern the zero-one $k$-laws for monadic
second order properties (MSO properties). We determine all values $\alpha&gt;0$,
for which the zero-one $3$-law for MSO properties does not hold. We also show
that, contrary to the case of the $3$-law, there are infinitely many values of
$\alpha$ for which the zero-one $4$-law for MSO properties does not hold.
Studying these zero-one laws forces us to analyze the evolution of certain
properties of $G(n,p)$, which may be of independent interest.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07270</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigating the influence of noise and distractors on the
  interpretation of neural networks</dc:title>
 <dc:creator>Kindermans, Pieter-Jan</dc:creator>
 <dc:creator>Sch&#xfc;tt, Kristof</dc:creator>
 <dc:creator>M&#xfc;ller, Klaus-Robert</dc:creator>
 <dc:creator>D&#xe4;hne, Sven</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Understanding neural networks is becoming increasingly important. Over the
last few years different types of visualisation and explanation methods have
been proposed. However, none of them explicitly considered the behaviour in the
presence of noise and distracting elements. In this work, we will show how
noise and distracting dimensions can influence the result of an explanation
model. This gives a new theoretical insights to aid selection of the most
appropriate explanation model within the deep-Taylor decomposition framework.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07270</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07285</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active learning with version spaces for object detection</dc:title>
 <dc:creator>Roy, Soumya</dc:creator>
 <dc:creator>Namboodiri, Vinay P.</dc:creator>
 <dc:creator>Biswas, Arijit</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Given an image, we would like to learn to detect objects belonging to
particular object categories. Common object detection methods train on large
annotated datasets which are annotated in terms of bounding boxes that contain
the object of interest. Previous works on object detection model the problem as
a structured regression problem which ranks the correct bounding boxes more
than the background ones. In this paper we develop algorithms which actively
obtain annotations from human annotators for a small set of images, instead of
all images, thereby reducing the annotation effort. Towards this goal, we make
the following contributions: 1. We develop a principled version space based
active learning method that solves for object detection as a structured
prediction problem in a weakly supervised setting 2. We also propose two
variants of the margin sampling strategy 3. We analyse the results on standard
object detection benchmarks that show that with only 20% of the data we can
obtain more than 95% of the localization accuracy of full supervision. Our
methods outperform random sampling and the classical uncertainty-based active
learning algorithms like entropy
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07285</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07289</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PVR: Patch-to-Volume Reconstruction for Large Area Motion Correction of
  Fetal MRI</dc:title>
 <dc:creator>Alansary, Amir</dc:creator>
 <dc:creator>Kainz, Bernhard</dc:creator>
 <dc:creator>Rajchl, Martin</dc:creator>
 <dc:creator>Murgasova, Maria</dc:creator>
 <dc:creator>Damodaram, Mellisa</dc:creator>
 <dc:creator>Lloyd, David F. A.</dc:creator>
 <dc:creator>Davidson, Alice</dc:creator>
 <dc:creator>McDonagh, Steven G.</dc:creator>
 <dc:creator>Rutherford, Mary</dc:creator>
 <dc:creator>Hajnal, Joseph V.</dc:creator>
 <dc:creator>Rueckert, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:subject>I.4.3</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:description>  In this paper we present a novel method for the correction of motion
artifacts that are present in fetal Magnetic Resonance Imaging (MRI) scans of
the whole uterus. Contrary to current slice-to-volume registration (SVR)
methods, requiring an inflexible anatomical enclosure of a single investigated
organ, the proposed patch-to-volume reconstruction (PVR) approach is able to
reconstruct a large field of view of non-rigidly deforming structures. It
relaxes rigid motion assumptions by introducing a specific amount of redundant
information that is exploited with parallelized patch-wise optimization,
super-resolution, and automatic outlier rejection. We further describe and
provide an efficient parallel implementation of PVR allowing its execution
within reasonable time on commercially available graphics processing units
(GPU), enabling its use in the clinical practice. We evaluate PVR's
computational overhead compared to standard methods and observe improved
reconstruction accuracy in presence of affine motion artifacts of approximately
30% compared to conventional SVR in synthetic experiments. Furthermore, we have
evaluated our method qualitatively and quantitatively on real fetal MRI data
subject to maternal breathing and sudden fetal movements. We evaluate
peak-signal-to-noise ratio (PSNR), structural similarity index (SSIM), and
cross correlation (CC) with respect to the originally acquired data and provide
a method for visual inspection of reconstruction uncertainty. With these
experiments we demonstrate successful application of PVR motion compensation to
the whole uterus, the human fetus, and the human placenta.
</dc:description>
 <dc:description>Comment: 10 pages, 13 figures, submitted to IEEE Transactions on Medical
  Imaging. v2: wadded funders acknowledgements to preprint</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07289</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07297</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Performance and Distributed Computing in a Probabilistic Finite
  Element Comparison Study of the Human Lower Leg Model with Total Knee
  Replacement</dc:title>
 <dc:creator>Arsene, Corneliu</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:description>  Reliability theory is used to assess the sensitivity of a passive flexion and
active flexion of the human lower leg Finite Element (FE) models with Total
Knee Replacement (TKR) to the variability in the input parameters of the
respective FE models. The sensitivity of the active flexion simulating the
stair ascent of the human lower leg FE model with TKR was presented before in
[1,2] whereas now in this paper a comparison is made with the passive flexion
of the human lower leg FE model with TKR. First, with the Monte Carlo
Simulation Technique (MCST), a number of randomly generated input data of the
FE model(s) are obtained based on the normal standard deviations of the
respective input parameters. Then a series of FE simulations are done and the
output kinematics and peak contact pressures are obtained for the respective FE
models (passive flexion and/or active flexion models). Seven output performance
measures are reported for the passive flexion model and one more parameter was
reported for the active flexion FE model (patello-femoral peak contact
pressure) in [1]. A sensitivity study will be performed based on the Response
Surface Method (RSM) to identify the key parameters that influence the
kinematics and peak contact pressures of the passive flexion FE model. Another
two MCST and RSM-based probabilistic FE analyses will be performed based on a
reduced list of 19 key input parameters. In total 4 probabilistic FE analyses
will be performed: 2 probabilistic FE analyses (MCST and RSM) based on an
extended set of 78 input variables and another 2 probabilistic FE analyses
(MCST and RSM) based on a reduced set of 19 input variables. Due to the likely
computation cost in order to make hundreds of FE simulations with MCST, a
high-performance and distributed computing system will be used for the passive
flexion FE model the same as it was used for the active flexion FE model in
[1].
</dc:description>
 <dc:description>Comment: 2015 IEEE European Modelling Symposium (EMS 2015)</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07297</dc:identifier>
 <dc:identifier>doi:10.5281/zenodo.154259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07299</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cryptanalysis of an Identity-Based Authenticated Key Exchange Protocol</dc:title>
 <dc:creator>Hatri, Younes</dc:creator>
 <dc:creator>Otmani, Ayoub</dc:creator>
 <dc:creator>Guenda, Kenza</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Authenticated Key Exchange (AKE) protocols represent an important
cryptographic mechanism that enables several parties to communicate securely
over an open network. Elashry, Mu and Susilo proposed in 2015 an Identity Based
Authenticated Key Exchange (IBAKE) protocol where different parties establish
secure communication by means of their public identities. The authors also
introduced a new security notion for IBAKE protocols called resiliency, that
is, if a shared secret between a group of parties is compromised or leaked,
they can generate another completely new shared secret without the need to set
up a new key exchange session. They then proved that their IBAKE protocol
satisfies this security notion.
  We analyze the security of their protocol and prove that it has a major
security flaw which renders it insecure against an impersonation attack. We
also disprove the resiliency property of their scheme by proposing an attack
where an adversary can compute any share secret key if just one secret bit is
leaked.
</dc:description>
 <dc:description>Comment: To appear in International Journal of Communication Systems</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07302</identifier>
 <datestamp>2017-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracking Control of Fully-actuated Mechanical port-Hamiltonian Systems
  using Sliding Manifolds and Contraction</dc:title>
 <dc:creator>Reyes-B&#xe1;ez, Rodolfo</dc:creator>
 <dc:creator>van der Schaft, Arjan</dc:creator>
 <dc:creator>Jayawardhana, Bayu</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, we propose a novel trajectory tracking controller for
fully-actuated mechanical port-Hamiltonian (pH) systems, which is based on
recent advances in contraction-based control theory. Our proposed controller
renders a desired sliding manifold (where the reference trajectory lies)
attractive by making the corresponding error system partially contracting.
Finally, we present numerical simulation results where a SCARA robot is
commanded by our proposed tracking control law.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07303</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Furthest Neighbor with Application to Annulus Query</dc:title>
 <dc:creator>Pagh, Rasmus</dc:creator>
 <dc:creator>Silvestri, Francesco</dc:creator>
 <dc:creator>Sivertsen, Johan</dc:creator>
 <dc:creator>Skala, Matthew</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Much recent work has been devoted to approximate nearest neighbor queries.
Motivated by applications in recommender systems, we consider approximate
furthest neighbor (AFN) queries and present a simple, fast, and highly
practical data structure for answering AFN queries in high- dimensional
Euclidean space. The method builds on the technique of In- dyk (SODA 2003),
storing random projections to provide sublinear query time for AFN. However, we
introduce a different query algorithm, improving on Indyk's approximation
factor and reducing the running time by a logarithmic factor. We also present a
variation based on a query- independent ordering of the database points; while
this does not have the provable approximation factor of the query-dependent
data structure, it offers significant improvement in time and space complexity.
We give a theoretical analysis, and experimental results. As an application,
the query-dependent approach is used for deriving a data structure for the
approximate annulus query problem, which is defined as follows: given an input
set S and two parameters r &gt; 0 and w &gt;= 1, construct a data structure that
returns for each query point q a point p in S such that the distance between p
and q is at least r/w and at most wr.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07303</dc:identifier>
 <dc:identifier>Information Systems, Available online 22 July 2016, ISSN 0306-4379</dc:identifier>
 <dc:identifier>doi:10.1016/j.is.2016.07.006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07305</identifier>
 <datestamp>2017-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correlation Clustering with Low-Rank Matrices</dc:title>
 <dc:creator>Veldt, Nate</dc:creator>
 <dc:creator>Wirth, Anthony</dc:creator>
 <dc:creator>Gleich, David F.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Correlation clustering is a technique for aggregating data based on
qualitative information about which pairs of objects are labeled 'similar' or
'dissimilar.' Because the optimization problem is NP-hard, much of the previous
literature focuses on finding approximation algorithms. In this paper we
explore how to solve the correlation clustering objective exactly when the data
to be clustered can be represented by a low-rank matrix. We prove in particular
that correlation clustering can be solved in polynomial time when the
underlying matrix is positive semidefinite with small constant rank, but that
the task remains NP-hard in the presence of even one negative eigenvalue. Based
on our theoretical results, we develop an algorithm for efficiently &quot;solving&quot;
low-rank positive semidefinite correlation clustering by employing a procedure
for zonotope vertex enumeration. We demonstrate the effectiveness and speed of
our algorithm by using it to solve several clustering problems on both
synthetic and real-world data.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:date>2017-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07306</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Groebner Bases for Everyone with CoCoA-5 and CoCoALib</dc:title>
 <dc:creator>Abbott, John</dc:creator>
 <dc:creator>Bigatti, Anna Maria</dc:creator>
 <dc:subject>Mathematics - Commutative Algebra</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>13P15, 13P10, 13-04, 14Q10, 68W30, 05E40, 68W24</dc:subject>
 <dc:description>  We present a survey on the developments related to Groebner bases, and show
explicit examples in CoCoA. The CoCoA project dates back to 1987: its aim was
to create a &quot;mathematician&quot;-friendly computational laboratory for studying
Commutative Algebra, most especially Groebner bases. Always maintaining this
&quot;friendly&quot; tradition, the project has grown and evolved, and the software has
been completely rewritten. CoCoA offers Groebner bases for all levels of
interest: from the basic, explicit call in the interactive system CoCoA-5, to
problem-specific optimized implementations, to the computer--computer
communication with the open source C++ software library, CoCoALib, or the
prototype OpenMath-based server. The openness and clean design of CoCoALib and
CoCoA-5 are intended to offer different levels of usage, and to encourage
external contributions.
</dc:description>
 <dc:description>Comment: 24 pages</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07306</dc:identifier>
 <dc:identifier>Advanced Studies in Pure Mathematics 75, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07308</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Graph Auto-Encoders</dc:title>
 <dc:creator>Kipf, Thomas N.</dc:creator>
 <dc:creator>Welling, Max</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce the variational graph auto-encoder (VGAE), a framework for
unsupervised learning on graph-structured data based on the variational
auto-encoder (VAE). This model makes use of latent variables and is capable of
learning interpretable latent representations for undirected graphs. We
demonstrate this model using a graph convolutional network (GCN) encoder and a
simple inner product decoder. Our model achieves competitive results on a link
prediction task in citation networks. In contrast to most existing models for
unsupervised learning on graph-structured data and link prediction, our model
can naturally incorporate node features, which significantly improves
predictive performance on a number of benchmark datasets.
</dc:description>
 <dc:description>Comment: Bayesian Deep Learning Workshop (NIPS 2016)</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07329</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Autonomous Landing of a Multirotor Micro Air Vehicle on a High Velocity
  Ground Vehicle</dc:title>
 <dc:creator>Borowczyk, Alexandre</dc:creator>
 <dc:creator>Nguyen, Duc-Tien</dc:creator>
 <dc:creator>Nguyen, Andr&#xe9; Phu-Van</dc:creator>
 <dc:creator>Nguyen, Dang Quang</dc:creator>
 <dc:creator>Saussi&#xe9;, David</dc:creator>
 <dc:creator>Ny, Jerome Le</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  While autonomous multirotor micro aerial vehicles (MAVs) are uniquely well
suited for certain types of missions benefiting from stationary flight
capabilities, their more widespread usage still faces many hurdles, due in
particular to their limited range and the difficulty of fully automating their
deployment and retrieval. In this paper we address these issues by solving the
problem of the automated landing of a quadcopter on a ground vehicle moving at
relatively high speed. We present our system architecture, including the
structure of our Kalman filter for the estimation of the relative position and
velocity between the quadcopter and the landing pad, as well as our controller
design for the full rendezvous and landing maneuvers. The system is
experimentally validated by successfully landing in multiple trials a
commercial quadcopter on the roof of a car moving at speeds of up to 50 km/h.
</dc:description>
 <dc:description>Comment: Submitted to IFAC WC 2016</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07336</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotic expansions for factorial moments of some distributions in the
  analysis of algorithms</dc:title>
 <dc:creator>Jha, Sumit Kumar</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We establish asymptotic expansions for factorial moments of following
distributions: number of cycles in a random permutation, number of inversions
in a random permutation, and number of comparisons used by the randomized quick
sort algorithm.To achieve this we use singularity analysis of certain type of
generating functions due to Flajolet and Odlyzko.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07343</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Limbo: A Fast and Flexible Library for Bayesian Optimization</dc:title>
 <dc:creator>Cully, Antoine</dc:creator>
 <dc:creator>Chatzilygeroudis, Konstantinos</dc:creator>
 <dc:creator>Allocati, Federico</dc:creator>
 <dc:creator>Mouret, Jean-Baptiste</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Limbo is an open-source C++11 library for Bayesian optimization which is
designed to be both highly flexible and very fast. It can be used to optimize
functions for which the gradient is unknown, evaluations are expensive, and
runtime cost matters (e.g., on embedded systems or robots). Benchmarks on
standard functions show that Limbo is about 2 times faster than BayesOpt
(another C++ library) for a similar accuracy.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07350</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SPEAKE(a)R: Turn Speakers to Microphones for Fun and Profit</dc:title>
 <dc:creator>Guri, Mordechai</dc:creator>
 <dc:creator>Solewicz, Yosef</dc:creator>
 <dc:creator>Daidakulov, Andrey</dc:creator>
 <dc:creator>Elovici, Yuval</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  It is possible to manipulate the headphones (or earphones) connected to a
computer, silently turning them into a pair of eavesdropping microphones - with
software alone. The same is also true for some types of loudspeakers. This
paper focuses on this threat in a cyber-security context. We present
SPEAKE(a)R, a software that can covertly turn the headphones connected to a PC
into a microphone. We present technical background and explain why most of PCs
and laptops are susceptible to this type of attack. We examine an attack
scenario in which malware can use a computer as an eavesdropping device, even
when a microphone is not present, muted, taped, or turned off. We measure the
signal quality and the effective distance, and survey the defensive
countermeasures.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07351</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MOMOS-MT: Mobile Monophonic System for Music Transcription</dc:title>
 <dc:creator>Makhmutov, Munir</dc:creator>
 <dc:creator>Brown, Joseph Alexander</dc:creator>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:creator>Johard, Leonard</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Music holds a significant cultural role in social identity and in the
encouragement of socialization. Technology, by the destruction of physical and
cultural distance, has lead to many changes in musical themes and the complete
loss of forms. Yet, it also allows for the preservation and distribution of
music from societies without a history of written sheet music. This paper
presents early work on a tool for musicians and ethnomusicologists to
transcribe sheet music from monophonic voiced pieces for preservation and
distribution. Using FFT, the system detects the pitch frequencies, also other
methods detect note durations, tempo, time signatures and generates sheet
music. The final system is able to be used in mobile platforms allowing the
user to take recordings and produce sheet music in situ to a performance.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07351</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07356</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Classical Scaling</dc:title>
 <dc:creator>Shamai, Gil</dc:creator>
 <dc:creator>Zibulevsky, Michael</dc:creator>
 <dc:creator>Kimmel, Ron</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Multidimensional-scaling (MDS) is a dimensionality reduction tool used for
information analysis, data visualization and manifold learning. Most MDS
procedures find embedding of data points in low dimensional Euclidean (flat)
domains, such that distances between the points are as close as possible to
given inter-points dissimilarities. We present an efficient solver for
Classical Scaling, a specific MDS model, by extrapolating the information
provided by distances measured from a subset of the points to the rest. The
computational and space complexities of the new MDS procedures are be thereby
reduced from quadratic to quasi-linear in the number of data points.
Incorporating both local and global information about the data allows us to
construct a low rank approximation to the inter-geodesic distances between the
data points. As a by-product, the proposed method allows for efficient
computation of geodesic distances. Finally, we show how to apply our method to
two geometric analysis applications and obtain state of the art results.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07360</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geodesic Distance Descriptors</dc:title>
 <dc:creator>Shamai, Gil</dc:creator>
 <dc:creator>Kimmel, Ron</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  The Gromov-Hausdorff (GH) distance is traditionally used for measuring
distances between metric spaces. It is defined as the minimal distortion of
embedding one surface into the other, while the optimal correspondence can be
described as the map that minimizes this distortion. Solving such a
minimization is a hard combinatorial problem that requires pre-computation and
storing of all pairwise geodesic distances for the matched surfaces. A popular
way for compact representation of functions on surfaces is by projecting them
into the leading eigenfunctions of the Laplace-Beltrami Operator (LBO). When
truncated, The basis of the LBO is known to be the optimal for representing
functions with bounded gradient in a min-max sense. Methods such as
Spectral-GMDS exploit this idea to simplify and efficiently approximate a
minimization related to the GH distance by operating in the truncated spectral
domain, and obtain state of the art results for matching of nearly isometric
shapes. However, when considering only a specific set of functions on the
surface, such as geodesic distances, an optimized basis could be considered as
an even better alternative. Here, we define the geodesic distance basis, which
is optimal for compact approximation of geodesic distances, in terms of
Frobenius norm. We use the suggested basis to extract the Geodesic Distance
Descriptor (GDD), which encodes the geodesic distances information as a linear
combination of the basis functions. We then show how these ideas can be used to
efficiently and accurately approximate the metric spaces matching problem with
almost no loss of information. These observations are used to construct a very
simple and efficient procedure for shape correspondence. Experimental results
show that the GDD improves both accuracy and efficiency of state of the art
shape matching procedures.
</dc:description>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07360</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07362</identifier>
 <datestamp>2017-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An o-minimal Szemer\'edi-Trotter theorem</dc:title>
 <dc:creator>Basu, Saugata</dc:creator>
 <dc:creator>Raz, Orit E.</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>03C64, 05D40</dc:subject>
 <dc:description>  We prove an analog of the Szemer\'edi-Trotter theorem in the plane for
definable curves and points in any o-minimal structure over an arbitrary real
closed field $\mathrm{R}$. One new ingredient in the proof is an extension of
the well known crossing number inequality for graphs to the case of embeddings
in any o-minimal structure over an arbitrary real closed field.
</dc:description>
 <dc:description>Comment: 15 pages. Final version to appear in The Quarterly Journal of
  Mathematics</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07362</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07366</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Handover Management in 5G and Beyond: A Topology Aware Skipping Approach</dc:title>
 <dc:creator>Arshad, Rabe</dc:creator>
 <dc:creator>ElSawy, Hesham</dc:creator>
 <dc:creator>Sorour, Sameh</dc:creator>
 <dc:creator>Al-Naffouri, Tareq Y.</dc:creator>
 <dc:creator>Alouini, Mohamed Slim</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Network densification is found to be a potential solution to meet 5G capacity
standards. Network densification offers more capacity by shrinking base
stations' (BSs) footprints, thus reduces the number of users served by each BS.
However, the gains in the capacity are achieved at the expense of increased
handover (HO) rates. Hence, HO rate is a key performance limiting factor that
should be carefully considered in densification planning. This paper sheds
light on the HO problem that appears in dense 5G networks and proposes an
effective solution via topology aware HO skipping. Different skipping
techniques are considered and compared with the conventional best connected
scheme. To this end, the effectiveness of the proposed schemes is validated by
studying the average user rate in the downlink single-tier and two-tier
cellular networks, which are modeled using Poisson point process and Poisson
cluster process, respectively. The proposed skipping schemes show up to 47%
gains in the average throughput that would maximize the benefit of network
densification.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Access</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07368</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discretization of Maxwell's Equations for Non-inertial Observers Using
  Space-Time Algebra</dc:title>
 <dc:creator>Klimek, Mariusz</dc:creator>
 <dc:creator>Kurz, Stefan</dc:creator>
 <dc:creator>Schoeps, Sebastian</dc:creator>
 <dc:creator>Weiland, Thomas</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  We employ Maxwell's equations formulated in Space-Time Algebra to perform
discretization of moving geometries directly in space-time. All the derivations
are carried out without any non-relativistic assumptions, thus the application
area of the scheme is not restricted to low velocities. The 4D mesh
construction is based on a 3D mesh stemming from a conventional 3D mesh
generator. The movement of the system is encoded in the 4D mesh geometry,
enabling an easy extension of well-known 3D approaches to the space-time
setting. As a research example, we study a manifestation of Sagnac's effect in
a rotating ring resonator. In case of constant rotation, the space-time
approach enhances the efficiency of the scheme, as the material matrices are
constant for every time step, without abandoning the relativistic framework.
</dc:description>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07369</identifier>
 <datestamp>2017-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometry of 3D Environments and Sum of Squares Polynomials</dc:title>
 <dc:creator>Ahmadi, Amir Ali</dc:creator>
 <dc:creator>Hall, Georgina</dc:creator>
 <dc:creator>Makadia, Ameesh</dc:creator>
 <dc:creator>Sindhwani, Vikas</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Motivated by applications in robotics and computer vision, we study problems
related to spatial reasoning of a 3D environment using sublevel sets of
polynomials. These include: tightly containing a cloud of points (e.g.,
representing an obstacle) with convex or nearly-convex basic semialgebraic
sets, computation of Euclidean distances between two such sets, separation of
two convex basic semalgebraic sets that overlap, and tight containment of the
union of several basic semialgebraic sets with a single convex one. We use
algebraic techniques from sum of squares optimization that reduce all these
tasks to semidefinite programs of small size and present numerical experiments
in realistic scenarios.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-03-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07369</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07371</identifier>
 <datestamp>2016-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lazy Local Search Meets Machine Scheduling</dc:title>
 <dc:creator>Annamalai, Chidambaram</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We study the restricted case of Scheduling on Unrelated Parallel Machines. In
this problem, we are given a set of jobs $J$ with processing times $p_j$ and
each job may be scheduled only on some subset of machines $S_j \subseteq M$.
The goal is to find an assignment of jobs to machines to minimize the time by
which all jobs can be processed. In a seminal paper, Lenstra, Shmoys, and
Tardos designed an elegant $2$-approximation for the problem in 1987. The
question of whether approximation algorithms with better guarantees exist for
this classic scheduling problem has since remained a source of mystery.
  In recent years, with the improvement of our understanding of Configuration
LPs, it now appears an attainable goal to design such an algorithm. Our main
contribution is to make progress towards this goal. When the processing times
of jobs are either $1$ or $\epsilon \in (0,1)$, we design an approximation
algorithm whose guarantee tends to $1 + \sqrt{3}/2 \approx 1.8660254,$ for the
interesting cases when $\epsilon \to 0$. This improves on the $2-\epsilon_0$
guarantee recently obtained by Chakrabarty, Khanna, and Li for some constant
$\epsilon_0 &gt; 0$.
</dc:description>
 <dc:description>Comment: added 4 figures; sharpened the constant from 1+2/sqrt{5} to 17/9</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2016-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07371</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07372</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mending Fences with Self-Invalidation and Self-Downgrade</dc:title>
 <dc:creator>Abdulla, Parosh Aziz</dc:creator>
 <dc:creator>Atig, Mohamed Faouzi</dc:creator>
 <dc:creator>Kaxiras, Stefanos</dc:creator>
 <dc:creator>Leonardsson, Carl</dc:creator>
 <dc:creator>Ros, Alberto</dc:creator>
 <dc:creator>Zhu, Yunyun</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:description>  Cache coherence protocols based on self-invalidation and self-downgrade have
recently seen increased popularity due to their simplicity, potential
performance efficiency, and low energy consumption. However, such protocols
result in memory instruction reordering, thus causing extra program behaviors
that are often not intended by the programmers. We propose a novel formal model
that captures the semantics of programs running under such protocols, and
features a set of fences that interact with the coherence layer. Using the
model, we design an algorithm to analyze the reachability and check whether a
program satisfies a given safety property with the current set of fences. We
describe a method for insertion of optimal sets of fences that ensure
correctness of the program under such protocols. The method relies on a
counter-example guided fence insertion procedure. One feature of our method is
that it can handle a variety of fences (with different costs). This diversity
makes optimization more difficult since one has to optimize the total cost of
the inserted fences, rather than just their number. To demonstrate the strength
of our approach, we have implemented a prototype and run it on a wide range of
examples and benchmarks. We have also, using simulation, evaluated the
performance of the resulting fenced programs.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07379</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomized Mechanisms for Selling Reserved Instances in Cloud</dc:title>
 <dc:creator>Zhang, Jia</dc:creator>
 <dc:creator>Ma, Weidong</dc:creator>
 <dc:creator>Qin, Tao</dc:creator>
 <dc:creator>Sun, Xiaoming</dc:creator>
 <dc:creator>Liu, Tie-Yan</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Selling reserved instances (or virtual machines) is a basic service in cloud
computing. In this paper, we consider a more flexible pricing model for
instance reservation, in which a customer can propose the time length and
number of resources of her request, while in today's industry, customers can
only choose from several predefined reservation packages. Under this model, we
design randomized mechanisms for customers coming online to optimize social
welfare and providers' revenue.
  We first consider a simple case, where the requests from the customers do not
vary too much in terms of both length and value density. We design a randomized
mechanism that achieves a competitive ratio $\frac{1}{42}$ for both
\emph{social welfare} and \emph{revenue}, which is a improvement as there is
usually no revenue guarantee in previous works such as
\cite{azar2015ec,wang2015selling}. This ratio can be improved up to
$\frac{1}{11}$ when we impose a realistic constraint on the maximum number of
resources used by each request. On the hardness side, we show an upper bound
$\frac{1}{3}$ on competitive ratio for any randomized mechanism. We then extend
our mechanism to the general case and achieve a competitive ratio
$\frac{1}{42\log k\log T}$ for both social welfare and revenue, where $T$ is
the ratio of the maximum request length to the minimum request length and $k$
is the ratio of the maximum request value density to the minimum request value
density. This result outperforms the previous upper bound $\frac{1}{CkT}$ for
deterministic mechanisms \cite{wang2015selling}. We also prove an upper bound
$\frac{2}{\log 8kT}$ for any randomized mechanism. All the mechanisms we
provide are in a greedy style. They are truthful and easy to be integrated into
practical cloud systems.
</dc:description>
 <dc:description>Comment: Already accepted by AAAI'17</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07383</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Non-Intrusive and Context-Based Vulnerability Scoring Framework for
  Cloud Services</dc:title>
 <dc:creator>Zhuang, Hao</dc:creator>
 <dc:creator>Pydde, Florian</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Understanding the severity of vulnerabilities within cloud services is
particularly important for today service administrators.Although many systems,
e.g., CVSS, have been built to evaluate and score the severity of
vulnerabilities for administrators, the scoring schemes employed by these
systems fail to take into account the contextual information of specific
services having these vulnerabilities, such as what roles they play in a
particular service. Such a deficiency makes resulting scores unhelpful. This
paper presents a practical framework, NCVS, that offers automatic and
contextual scoring mechanism to evaluate the severity of vulnerabilities for a
particular service. Specifically, for a given service S, NCVS first
automatically collects S contextual information including topology,
configurations, vulnerabilities and their dependencies. Then, NCVS uses the
collected information to build a contextual dependency graph, named CDG, to
model S context. Finally, NCVS scores and ranks all the vulnerabilities in S by
analyzing S context, such as what roles the vulnerabilities play in S, and how
critical they affect the functionality of S. NCVS is novel and useful, because
1) context-based vulnerability scoring results are highly relevant and
meaningful for administrators to understand each vulnerability importance
specific to the target service; and 2) the workflow of NCVS does not need
instrumentation or modifications to any source code. Our experimental results
demonstrate that NCVS can obtain more relevant vulnerability scoring results
than comparable system, such as CVSS.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07385</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smart Library: Identifying Books in a Library using Richly Supervised
  Deep Scene Text Reading</dc:title>
 <dc:creator>Yang, Xiao</dc:creator>
 <dc:creator>He, Dafang</dc:creator>
 <dc:creator>Huang, Wenyi</dc:creator>
 <dc:creator>Zhou, Zihan</dc:creator>
 <dc:creator>Ororbia, Alex</dc:creator>
 <dc:creator>Kifer, Dan</dc:creator>
 <dc:creator>Giles, C. Lee</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Physical library collections are valuable and long standing resources for
knowledge and learning. However, managing books in a large bookshelf and
finding books on it often leads to tedious manual work, especially for large
book collections where books might be missing or misplaced. Recently, deep
neural models, such as Convolutional Neural Networks (CNN) and Recurrent Neural
Networks (RNN) have achieved great success for scene text detection and
recognition. Motivated by these recent successes, we aim to investigate their
viability in facilitating book management, a task that introduces further
challenges including large amounts of cluttered scene text, distortion, and
varied lighting conditions. In this paper, we present a library inventory
building and retrieval system based on scene text reading methods. We
specifically design our scene text recognition model using rich supervision to
accelerate training and achieve state-of-the-art performance on several
benchmark datasets. Our proposed system has the potential to greatly reduce the
amount of human labor required in managing book inventories as well as the
space needed to store book information.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07390</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Image Reconstruction from X-Ray Measurements with Overlap</dc:title>
 <dc:creator>Klodt, Maria</dc:creator>
 <dc:creator>Hauser, Raphael</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  3D image reconstruction from a set of X-ray projections is an important image
reconstruction problem, with applications in medical imaging, industrial
inspection and airport security. The innovation of X-ray emitter arrays allows
for a novel type of X-ray scanners with multiple simultaneously emitting
sources. However, two or more sources emitting at the same time can yield
measurements from overlapping rays, imposing a new type of image reconstruction
problem based on nonlinear constraints. Using traditional linear reconstruction
methods, respective scanner geometries have to be implemented such that no rays
overlap, which severely restricts the scanner design. We derive a new type of
3D image reconstruction model with nonlinear constraints, based on measurements
with overlapping X-rays. Further, we show that the arising optimization problem
is partially convex, and present an algorithm to solve it. Experiments show
highly improved image reconstruction results from both simulated and real-world
measurements.
</dc:description>
 <dc:description>Comment: Published in Computer Vision - ECCV 2016. The final publication is
  available at link.springer.com/chapter/10.1007/978-3-319-46466-4_2</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07390</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-46466-4_2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07392</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Call Trace and Memory Access Pattern based Runtime Insider Threat
  Detection for Big Data Platforms</dc:title>
 <dc:creator>Aditham, Santosh</dc:creator>
 <dc:creator>Ranganathan, Nagarajan</dc:creator>
 <dc:creator>Katkoori, Srinivas</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Big data platforms such as Hadoop and Spark are being widely adopted both by
academia and industry. In this paper, we propose a runtime intrusion detection
technique that understands and works according to the properties of such
distributed compute platforms. The proposed method is based on runtime analysis
of system and library calls and memory access patterns of tasks running on the
datanodes (slaves). First, the primary datanode of a big data system creates a
behavior profile for every task it executes. A behavior profile includes (a)
trace of the system &amp; library calls made, and (b) sequence representing the
sizes of private and shared memory accesses made during task execution. Then,
the process behavior profile is shared with other replica datanodes that are
scheduled to execute the same task on their copy of the same data. Next, these
replica datanodes verify their local tasks with the help of the information
embedded in the received behavior profiles. This is realized in two steps: (i)
comparing the system &amp; library calls metadata, and (ii) statistical matching of
the memory access patterns. Finally, datanodes share their observations for
consensus and report an intrusion to the namenode (master) if they find any
discrepancy. The proposed solution was tested on a small hadoop cluster using
the default MapReduce examples and the results show that our approach can
detect insider attacks that cannot be detected with the traditional analysis
metrics.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07392</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07397</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-linear Barrier Coverage using Mobile Wireless Sensors</dc:title>
 <dc:creator>Baheti, Ashutosh</dc:creator>
 <dc:creator>Gupta, Arobinda</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  A belt region is said to be k-barrier covered by a set of sensors if all
paths crossing the width of the belt region intersect the sensing regions of at
least k sensors. Barrier coverage can be achieved from a random initial
deployment of mobile sensors by suitably relocating the sensors to form a
barrier. Reducing the movement of the sensors is important in such scenarios
due to the energy constraints of sensor devices. In this paper, we propose a
centralized algorithm which achieves 1-barrier coverage by forming a non-linear
barrier from a random initial deployment of sensors in a belt. The algorithm
uses a novel idea of physical behavior of chains along with the concept of
virtual force. Formation of non-linear barrier reduces the movement of the
sensors needed as compared to linear barriers. Detailed simulation results are
presented to show that the proposed algorithm achieves barrier coverage with
less movement of sensors compared to other existing algorithms in the
literature.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07399</identifier>
 <datestamp>2017-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Robust Force Control Approach for Underwater Vehicle Manipulator
  Systems</dc:title>
 <dc:creator>Heshmati-alamdari, Shahab</dc:creator>
 <dc:creator>Nikou, Alexandros</dc:creator>
 <dc:creator>Kyriakopoulos, Kostas J.</dc:creator>
 <dc:creator>Dimarogonas, Dimos V.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In various interaction tasks using Underwater Vehicle Manipulator Systems
(UVMSs) (e.g. sampling of the sea organisms, underwater welding), important
factors such as: i) uncertainties and complexity of UVMS dynamic model ii)
external disturbances (e.g. sea currents and waves) iii) imperfection and
noises of measuring sensors iv) steady state performance as well as v) inferior
overshoot of interaction force error, should be addressed during the force
control design. Motivated by the above factors, this paper presents a
model-free control protocol for force controlling of an Underwater Vehicle
Manipulator System which is in contact with a compliant environment, without
incorporating any knowledge of the UVMS's dynamic model, exogenous disturbances
and sensor's noise model. Moreover, the transient and steady state response as
well as reduction of overshooting force error are solely determined by certain
designer-specified performance functions and are fully decoupled by the UVMS's
dynamic model, the control gain selection, as well as the initial conditions.
Finally, a simulation study clarifies the proposed method and verifies its
efficiency.
</dc:description>
 <dc:description>Comment: Submitted to the International Federation of Automatic Control
  (IFAC), Toulouse, France, July 2017 (Accepted)</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07400</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Deep Learning Based DDoS Detection System in Software-Defined
  Networking (SDN)</dc:title>
 <dc:creator>Niyaz, Quamar</dc:creator>
 <dc:creator>Sun, Weiqing</dc:creator>
 <dc:creator>Javaid, Ahmad Y</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Distributed Denial of Service (DDoS) is one of the most prevalent attacks
that an organizational network infrastructure comes across nowadays. We propose
a deep learning based multi-vector DDoS detection system in a software-defined
network (SDN) environment. SDN provides flexibility to program network devices
for different objectives and eliminates the need for third-party
vendor-specific hardware. We implement our system as a network application on
top of an SDN controller. We use deep learning for feature reduction of a large
set of features derived from network traffic headers. We evaluate our system
based on different performance metrics by applying it on traffic traces
collected from different scenarios. We observe high accuracy with a low
false-positive for attack detection in our proposed system.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07400</dc:identifier>
 <dc:identifier>doi:10.4108/eai.28-12-2017.153515</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07403</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Dimensional Stochastic Modeling of the Electrical Properties of
  Biological Tissues</dc:title>
 <dc:creator>R&#xf6;mer, Ulrich</dc:creator>
 <dc:creator>Schmidt, Christian</dc:creator>
 <dc:creator>van Rienen, Ursula</dc:creator>
 <dc:creator>Sch&#xf6;ps, Sebastian</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>60H30, 60H35, 78M10</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:subject>I.6.3</dc:subject>
 <dc:description>  Uncertainty quantification plays an important role in biomedical engineering
as measurement data is often unavailable and literature data shows a wide
variability. Using state-of-the-art methods one encounters difficulties when
the number of random inputs is large. This is the case, e.g., when using
composite Cole-Cole equations to model random electrical properties. It is
shown how the number of parameters can be significantly reduced by the
Karhunen-Loeve expansion. The low-dimensional random model is used to quantify
uncertainties in the axon activation during deep brain stimulation. Numerical
results for a Medtronic 3387 electrode design are given.
</dc:description>
 <dc:description>Comment: 4 pages, 5 figures</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-09-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07403</dc:identifier>
 <dc:identifier>IEEE Trans. Magn, Volume: 53, Issue: 6, June 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TMAG.2017.2668841</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07409</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Metric for Performance Portability</dc:title>
 <dc:creator>Pennycook, S. J.</dc:creator>
 <dc:creator>Sewall, J. D.</dc:creator>
 <dc:creator>Lee, V. W.</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  The term &quot;performance portability&quot; has been informally used in computing to
refer to a variety of notions which generally include: 1) the ability to run
one application across multiple hardware platforms; and 2) achieving some
notional level of performance on these platforms. However, there has been a
noticeable lack of consensus on the precise meaning of the term, and authors'
conclusions regarding their success (or failure) to achieve performance
portability have thus been subjective. Comparing one approach to performance
portability with another has generally been marked with vague claims and
verbose, qualitative explanation of the comparison. This paper presents a
concise definition for performance portability, along with a simple metric that
accurately captures the performance and portability of an application across
different platforms. The utility of this metric is then demonstrated with a
retroactive application to previous work.
</dc:description>
 <dc:description>Comment: 7 pages, in Proceedings of the 7th International Workshop in
  Performance Modeling, Benchmarking and Simulation of High Performance
  Computer Systems</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07409</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07414</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Heterogeneous Capacitated $k$-Center Problem</dc:title>
 <dc:creator>Chakrabarty, Deeparnab</dc:creator>
 <dc:creator>Krishnaswamy, Ravishankar</dc:creator>
 <dc:creator>Kumar, Amit</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper we initiate the study of the heterogeneous capacitated
$k$-center problem: given a metric space $X = (F \cup C, d)$, and a collection
of capacities. The goal is to open each capacity at a unique facility location
in $F$, and also to assign clients to facilities so that the number of clients
assigned to any facility is at most the capacity installed; the objective is
then to minimize the maximum distance between a client and its assigned
facility. If all the capacities $c_i$'s are identical, the problem becomes the
well-studied uniform capacitated $k$-center problem for which constant-factor
approximations are known. The additional choice of determining which capacity
should be installed in which location makes our problem considerably different
from this problem, as well the non-uniform generalizations studied thus far in
literature. In fact, one of our contributions is in relating the heterogeneous
problem to special-cases of the classical Santa Claus problem. Using this
connection, and by designing new algorithms for these special cases, we get the
following results: (a)A quasi-polynomial time $O(\log
n/\epsilon)$-approximation where every capacity is violated by $1+\varepsilon$,
(b) A polynomial time $O(1)$-approximation where every capacity is violated by
an $O(\log n)$ factor. We get improved results for the {\em soft-capacities}
version where we can place multiple facilities in the same location.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07420</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SMCL - Stochastic Model Checker for Learning in Games</dc:title>
 <dc:creator>Qu, Hongyang</dc:creator>
 <dc:creator>Smyrnakis, Michalis</dc:creator>
 <dc:creator>Veres, Sandor M.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  A stochastic model checker is presented for analysing the performance of
game-theoretic learning algorithms. The method enables the comparison of
short-term behaviour of learning algorithms intended for practical use. The
procedure of comparison is automated and it can be tuned for accuracy and
speed. Users can choose from among various learning algorithms to select a
suitable one for a given practical problem. The powerful performance of the
method is enabled by a novel behaviour-similarity-relation, which compacts
large state spaces into small ones. The stochastic model checking tool is
tested on a set of examples classified into four categories to demonstrate the
effectiveness of selecting suitable algorithms for distributed decision making.
</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07421</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reduction-Based Creative Telescoping for Fuchsian D-finite Functions</dc:title>
 <dc:creator>Chen, Shaoshi</dc:creator>
 <dc:creator>van Hoeij, Mark</dc:creator>
 <dc:creator>Kauers, Manuel</dc:creator>
 <dc:creator>Koutschan, Christoph</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  Continuing a series of articles in the past few years on creative telescoping
using reductions, we adapt Trager's Hermite reduction for algebraic functions
to fuchsian D-finite functions and develop a reduction-based creative
telescoping algorithm for this class of functions, thereby generalizing our
recent reduction-based algorithm for algebraic functions, presented at ISSAC
2016.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1602.00424</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07421</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07422</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning Approximation for Stochastic Control Problems</dc:title>
 <dc:creator>Han, Jiequn</dc:creator>
 <dc:creator>E, Weinan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Many real world stochastic control problems suffer from the &quot;curse of
dimensionality&quot;. To overcome this difficulty, we develop a deep learning
approach that directly solves high-dimensional stochastic control problems
based on Monte-Carlo sampling. We approximate the time-dependent controls as
feedforward neural networks and stack these networks together through model
dynamics. The objective function for the control problem plays the role of the
loss function for the deep neural network. We test this approach using examples
from the areas of optimal trading and energy storage. Our results suggest that
the algorithm presented here achieves satisfactory accuracy and at the same
time, can handle rather high dimensional problems.
</dc:description>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07422</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07425</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Orthogonal Multiple Access (NOMA) for Downlink Multiuser MIMO
  Systems: User Clustering, Beamforming, and Power Allocation</dc:title>
 <dc:creator>Ali, Md Shipon</dc:creator>
 <dc:creator>Hossain, Ekram</dc:creator>
 <dc:creator>Kim, Dong In</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We investigate the application of non-orthogonal multiple access (NOMA) with
successive interference cancellation (SIC) in downlink multiuser multiple-input
multiple-output (MIMO) cellular systems, where the total number of receive
antennas at user equipment (UE) ends in a cell is more than the number of
transmit antennas at the base station (BS). We first dynamically group the UE
receive antennas into a number of clusters equal to or more than the number of
BS transmit antennas. A single beamforming vector is then shared by all the
receive antennas in a cluster. We propose a linear beamforming technique in
which all the receive antennas can significantly cancel the inter-cluster
interference. On the other hand, the receive antennas in each cluster are
scheduled on power domain NOMA basis with SIC at the receiver ends. For
inter-cluster and intra-cluster power allocation, we provide dynamic power
allocation solutions with an objective to maximizing the overall cell capacity.
An extensive performance evaluation is carried out for the proposed MIMO-NOMA
system and the results are compared with those for conventional orthogonal
multiple access (OMA)-based MIMO systems and other existing MIMO-NOMA
solutions. The numerical results quantify the capacity gain of the proposed
MIMO-NOMA model over MIMO-OMA and other existing MIMO-NOMA solutions.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07429</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TreeView: Peeking into Deep Neural Networks Via Feature-Space
  Partitioning</dc:title>
 <dc:creator>Thiagarajan, Jayaraman J.</dc:creator>
 <dc:creator>Kailkhura, Bhavya</dc:creator>
 <dc:creator>Sattigeri, Prasanna</dc:creator>
 <dc:creator>Ramamurthy, Karthikeyan Natesan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  With the advent of highly predictive but opaque deep learning models, it has
become more important than ever to understand and explain the predictions of
such models. Existing approaches define interpretability as the inverse of
complexity and achieve interpretability at the cost of accuracy. This
introduces a risk of producing interpretable but misleading explanations. As
humans, we are prone to engage in this kind of behavior \cite{mythos}. In this
paper, we take a step in the direction of tackling the problem of
interpretability without compromising the model accuracy. We propose to build a
Treeview representation of the complex model via hierarchical partitioning of
the feature space, which reveals the iterative rejection of unlikely class
labels until the correct association is predicted.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07429</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07438</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Achieving non-discrimination in data release</dc:title>
 <dc:creator>Zhang, Lu</dc:creator>
 <dc:creator>Wu, Yongkai</dc:creator>
 <dc:creator>Wu, Xintao</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Discrimination discovery and prevention/removal are increasingly important
tasks in data mining. Discrimination discovery aims to unveil discriminatory
practices on the protected attribute (e.g., gender) by analyzing the dataset of
historical decision records, and discrimination prevention aims to remove
discrimination by modifying the biased data before conducting predictive
analysis. In this paper, we show that the key to discrimination discovery and
prevention is to find the meaningful partitions that can be used to provide
quantitative evidences for the judgment of discrimination. With the support of
the causal graph, we present a graphical condition for identifying a meaningful
partition. Based on that, we develop a simple criterion for the claim of
non-discrimination, and propose discrimination removal algorithms which
accurately remove discrimination while retaining good data utility. Experiments
using real datasets show the effectiveness of our approaches.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07438</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07448</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Assessing the Performance of a 60-GHz Dense Small-Cell Network
  Deployment from Ray-Based Simulations</dc:title>
 <dc:creator>Corre, Yoann</dc:creator>
 <dc:creator>Charbonnier, Romain</dc:creator>
 <dc:creator>Aslam, Mohammed Zahid</dc:creator>
 <dc:creator>Lostanlen, Yves</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Future dense small-cell networks are one key 5G candidates to offer outdoor
high access data rates, especially in millimeter wave (mmWave) frequency bands.
At those frequencies, the free space propagation loss and shadowing (from
buildings, vegetation or any kind of obstacles) are far stronger than in the
traditional radio cellular spectrum. Therefore, the cell range is expected to
be limited to 50 - 100 meters, and directive high gain antennas are required at
least for the base stations. This paper investigates the kind of topology that
is required to serve a suburban area with a small-cell network operating at 60
GHz and equipped with beam-steering antennas. A real environment is considered
to introduce practical deployment and propagation constraints. The analysis
relies on Monte-Carlo system simulations with non-full buffer, and ray-based
predictions. The ray-tracing techniques are today identified as a relevant
solution to capture the main channel properties impacting the beam-steering
performance (angular dispersion, inter-link correlation); and the one involved
in the present study was specifically enhanced to deal with detailed vegetation
modeling. In addition to the user outage, the paper evaluates the evolution of
the inter-cell interference along with the user density, and investigates the
network behavior in case of local strong obstructions.
</dc:description>
 <dc:description>Comment: IEEE 21st International Workshop on Computer Aided Modelling and
  Design of Communication Links and Networks (CAMAD), October 2016</dc:description>
 <dc:date>2016-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07448</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07449</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low Power Wide Area Networks (LPWANs) for Internet of Things (IoT)
  Applications: Research Challenges and Future Trends</dc:title>
 <dc:creator>Boulogeorgos, Alexandros-Apostolos A.</dc:creator>
 <dc:creator>Diamantoulakis, Panagiotis D.</dc:creator>
 <dc:creator>Karagiannidis, George K.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Internet of things (IoT) changes significantly the requirements for
connectivity, mainly with regards to long battery life, low device cost, low
deployment cost, extended coverage and support for a massive number of devices.
Driven from these requirements, several different cellular and non-cellular low
power wide area network (LPWAN) solutions are emerging and competing for IoT
business and the overall connectivity market. Motivated by this, in this paper,
we review and compare the design specifications of different LPWAN solutions,
as well as, we discuss their suitability for different IoT applications.
Finally, we present the challenges, future trends, and potential research
directions for LPWANs.
</dc:description>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07450</identifier>
 <datestamp>2017-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grad-CAM: Why did you say that?</dc:title>
 <dc:creator>Selvaraju, Ramprasaath R</dc:creator>
 <dc:creator>Das, Abhishek</dc:creator>
 <dc:creator>Vedantam, Ramakrishna</dc:creator>
 <dc:creator>Cogswell, Michael</dc:creator>
 <dc:creator>Parikh, Devi</dc:creator>
 <dc:creator>Batra, Dhruv</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a technique for making Convolutional Neural Network (CNN)-based
models more transparent by visualizing input regions that are 'important' for
predictions -- or visual explanations. Our approach, called Gradient-weighted
Class Activation Mapping (Grad-CAM), uses class-specific gradient information
to localize important regions. These localizations are combined with existing
pixel-space visualizations to create a novel high-resolution and
class-discriminative visualization called Guided Grad-CAM. These methods help
better understand CNN-based models, including image captioning and visual
question answering (VQA) models. We evaluate our visual explanations by
measuring their ability to discriminate between classes, to inspire trust in
humans, and their correlation with occlusion maps. Grad-CAM provides a new way
to understand CNN-based models.
  We have released code, an online demo hosted on CloudCV, and a full version
of this extended abstract.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems. This is an extended abstract version of arXiv:1610.02391
  (CVPR format)</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07450</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07451</identifier>
 <datestamp>2017-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sampling Random Spanning Trees Faster than Matrix Multiplication</dc:title>
 <dc:creator>Durfee, David</dc:creator>
 <dc:creator>Kyng, Rasmus</dc:creator>
 <dc:creator>Peebles, John</dc:creator>
 <dc:creator>Rao, Anup B.</dc:creator>
 <dc:creator>Sachdeva, Sushant</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present an algorithm that, with high probability, generates a random
spanning tree from an edge-weighted undirected graph in
$\tilde{O}(n^{4/3}m^{1/2}+n^{2})$ time (The $\tilde{O}(\cdot)$ notation hides
$\operatorname{polylog}(n)$ factors). The tree is sampled from a distribution
where the probability of each tree is proportional to the product of its edge
weights. This improves upon the previous best algorithm due to Colbourn et al.
that runs in matrix multiplication time, $O(n^\omega)$. For the special case of
unweighted graphs, this improves upon the best previously known running time of
$\tilde{O}(\min\{n^{\omega},m\sqrt{n},m^{4/3}\})$ for $m \gg n^{5/3}$ (Colbourn
et al. '96, Kelner-Madry '09, Madry et al. '15).
  The effective resistance metric is essential to our algorithm, as in the work
of Madry et al., but we eschew determinant-based and random walk-based
techniques used by previous algorithms. Instead, our algorithm is based on
Gaussian elimination, and the fact that effective resistance is preserved in
the graph resulting from eliminating a subset of vertices (called a Schur
complement). As part of our algorithm, we show how to compute
$\epsilon$-approximate effective resistances for a set $S$ of vertex pairs via
approximate Schur complements in $\tilde{O}(m+(n + |S|)\epsilon^{-2})$ time,
without using the Johnson-Lindenstrauss lemma which requires $\tilde{O}(
\min\{(m + |S|)\epsilon^{-2}, m+n\epsilon^{-4} +|S|\epsilon^{-2}\})$ time. We
combine this approximation procedure with an error correction procedure for
handing edges where our estimate isn't sufficiently accurate.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-06-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07451</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07454</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Agent-Based Model of Message Propagation in the Facebook Electronic
  Social Network</dc:title>
 <dc:creator>Nasrinpour, Hamid Reza</dc:creator>
 <dc:creator>Friesen, Marcia R.</dc:creator>
 <dc:creator>D., Robert</dc:creator>
 <dc:creator>McLeod</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  A large scale agent-based model of common Facebook users was designed to
develop an understanding of the underlying mechanism of information diffusion
within online social networks at a micro-level analysis. The agent-based model
network structure is based on a sample from Facebook. Using an erased
configuration model and the idea of common neighbours, a new correction
procedure was investigated to overcome the problem of missing graph edges to
construct a representative sample of the Facebook network graph. The model
parameters are based on assumptions and general activity patterns (such as
posting rate, time spent on Facebook etc.) taken from general data on Facebook.
Using the agent-based model, the impact of post length, post score and
publisher's friend count on the spread of wall posts in several scenarios was
analyzed. Findings indicated that post content has the highest impact on the
success of post propagation. However, amusing and absorbing but lengthy posts
(e.g. a funny video) do not spread as well as short but unremarkable ones (e.g.
an interesting photo). In contrast to product adoption and disease spread
propagation models, the absence of a similar &quot;epidemic&quot; threshold in Facebook
post diffusion is observed.
</dc:description>
 <dc:description>Comment: Keywords: Agent-Based Modelling, Facebook, Information Diffusion,
  Online Social Networks; info: 19 pages, 9 figures, 8 tables, 1 appendix, and
  63 references</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07454</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07466</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Depth of vertices with high degree in random recursive trees</dc:title>
 <dc:creator>Eslava, Laura</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>60C05, 05C80</dc:subject>
 <dc:description>  Let $T_n$ be a random recursive tree with $n$ nodes. List vertices of $T_n$
in decreasing order of degree as $v^1,\ldots,v^n$, and write $d^i$ and $h^i$
for the degree of $v^i$ and the distance of $v^i$ from the root, respectively.
We prove that, as $n \to \infty$ along suitable subsequences, \[ \bigg(d^i -
\lfloor \log_2 n \rfloor, \frac{h^i - \mu\ln n}{\sqrt{\sigma^2\ln n}}\bigg) \to
((P_i,i \ge 1),(N_i,i \ge 1))\, , \] where $\mu=1-(\log_2 e)/2$,
$\sigma^2=1-(\log_2 e)/4$, $(P_i,i \ge 1)$ is a Poisson point process on
$\mathbb{Z}$ and $(N_i,i \ge 1)$ is a vector of independent standard Gaussians.
We additionally establish joint normality for the depths of uniformly random
vertices in $T_n$, which extends previous results from Devroye and Mahmoud. The
joint holds even if the random vertices are conditioned to have large degree,
provided the normalization is adjusted accordingly.
  Our results are based on a simple relationship between random recursive trees
and Kingman's $n$-coalescent; a utility that seems to have been largely
overlooked.
</dc:description>
 <dc:description>Comment: 25 pages, 3 figures</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07466</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07468</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>F-Index of Four Operations on Graphs</dc:title>
 <dc:creator>De, Nilanjan</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C35</dc:subject>
 <dc:description>  The F-index of a graph is defined as the sum of cubes of the vertex degrees
of the graph which was introduced in 1972, in the same paper where the first
and second Zagreb indices were introduced. In this paper we study the F-index
of four operations on graphs which were introduced by Eliasi and Taeri [M.
Eliasi, B. Taeri, Four new sums of graphs and their Wiener indices,
\textit{Discrete Appl. Math.}\textbf{157}(2009) 794--803.].
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07468</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07476</identifier>
 <datestamp>2017-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond</dc:title>
 <dc:creator>Sagun, Levent</dc:creator>
 <dc:creator>Bottou, Leon</dc:creator>
 <dc:creator>LeCun, Yann</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We look at the eigenvalues of the Hessian of a loss function before and after
training. The eigenvalue distribution is seen to be composed of two parts, the
bulk which is concentrated around zero, and the edges which are scattered away
from zero. We present empirical evidence for the bulk indicating how
over-parametrized the system is, and for the edges that depend on the input
data.
</dc:description>
 <dc:description>Comment: ICLR submission, 2016 - updated to match the openreview.net version</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-10-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07478</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An unexpected unity among methods for interpreting model predictions</dc:title>
 <dc:creator>Lundberg, Scott</dc:creator>
 <dc:creator>Lee, Su-In</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Understanding why a model made a certain prediction is crucial in many data
science fields. Interpretable predictions engender appropriate trust and
provide insight into how the model may be improved. However, with large modern
datasets the best accuracy is often achieved by complex models even experts
struggle to interpret, which creates a tension between accuracy and
interpretability. Recently, several methods have been proposed for interpreting
predictions from complex models by estimating the importance of input features.
Here, we present how a model-agnostic additive representation of the importance
of input features unifies current methods. This representation is optimal, in
the sense that it is the only set of additive values that satisfies important
properties. We show how we can leverage these properties to create novel visual
explanations of model predictions. The thread of unity that this representation
weaves through the literature indicates that there are common principles to be
learned about the interpretation of model predictions that apply in many
scenarios.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07485</identifier>
 <datestamp>2017-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scene Labeling using Gated Recurrent Units with Explicit Long Range
  Conditioning</dc:title>
 <dc:creator>Huang, Qiangui</dc:creator>
 <dc:creator>Wang, Weiyue</dc:creator>
 <dc:creator>Zhou, Kevin</dc:creator>
 <dc:creator>You, Suya</dc:creator>
 <dc:creator>Neumann, Ulrich</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recurrent neural network (RNN), as a powerful contextual dependency modeling
framework, has been widely applied to scene labeling problems. However, this
work shows that directly applying traditional RNN architectures, which unfolds
a 2D lattice grid into a sequence, is not sufficient to model structure
dependencies in images due to the &quot;impact vanishing&quot; problem. First, we give an
empirical analysis about the &quot;impact vanishing&quot; problem. Then, a new RNN unit
named Recurrent Neural Network with explicit long range conditioning (RNN-ELC)
is designed to alleviate this problem. A novel neural network architecture is
built for scene labeling tasks where one of the variants of the new RNN unit,
Gated Recurrent Unit with Explicit Long-range Conditioning (GRU-ELC), is used
to model multi scale contextual dependencies in images. We validate the use of
GRU-ELC units with state-of-the-art performance on three standard scene
labeling datasets. Comprehensive experiments demonstrate that the new GRU-ELC
unit benefits scene labeling problem a lot as it can encode longer contextual
dependencies in images more effectively than traditional RNN units.
</dc:description>
 <dc:description>Comment: updated version 2</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07485</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07489</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximating k-Forest with Resource Augmentation: A Primal-Dual
  Approach</dc:title>
 <dc:creator>Angel, Eric</dc:creator>
 <dc:creator>Thang, Nguyen Kim</dc:creator>
 <dc:creator>Singh, Shikha</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we study the $k$-forest problem in the model of resource
augmentation. In the $k$-forest problem, given an edge-weighted graph $G(V,E)$,
a parameter $k$, and a set of $m$ demand pairs $\subseteq V \times V$, the
objective is to construct a minimum-cost subgraph that connects at least $k$
demands. The problem is hard to approximate---the best-known approximation
ratio is $O(\min\{\sqrt{n}, \sqrt{k}\})$. Furthermore, $k$-forest is as hard to
approximate as the notoriously-hard densest $k$-subgraph problem.
  While the $k$-forest problem is hard to approximate in the worst-case, we
show that with the use of resource augmentation, we can efficiently approximate
it up to a constant factor.
  First, we restate the problem in terms of the number of demands that are {\em
not} connected. In particular, the objective of the $k$-forest problem can be
viewed as to remove at most $m-k$ demands and find a minimum-cost subgraph that
connects the remaining demands. We use this perspective of the problem to
explain the performance of our algorithm (in terms of the augmentation) in a
more intuitive way.
  Specifically, we present a polynomial-time algorithm for the $k$-forest
problem that, for every $\epsilon&gt;0$, removes at most $m-k$ demands and has
cost no more than $O(1/\epsilon^{2})$ times the cost of an optimal algorithm
that removes at most $(1-\epsilon)(m-k)$ demands.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07490</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can Co-robots Learn to Teach?</dc:title>
 <dc:creator>Maske, Harshal</dc:creator>
 <dc:creator>Kieson, Emily</dc:creator>
 <dc:creator>Chowdhary, Girish</dc:creator>
 <dc:creator>Abramson, Charles</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We explore beyond existing work on learning from demonstration by asking the
question: Can robots learn to teach?, that is, can a robot autonomously learn
an instructional policy from expert demonstration and use it to instruct or
collaborate with humans in executing complex tasks in uncertain environments?
In this paper we pursue a solution to this problem by leveraging the idea that
humans often implicitly decompose a higher level task into several subgoals
whose execution brings the task closer to completion. We propose Dirichlet
process based non-parametric Inverse Reinforcement Learning (DPMIRL) approach
for reward based unsupervised clustering of task space into subgoals. This
approach is shown to capture the latent subgoals that a human teacher would
have utilized to train a novice. The notion of action primitive is introduced
as the means to communicate instruction policy to humans in the least
complicated manner, and as a computationally efficient tool to segment
demonstration data. We evaluate our approach through experiments on hydraulic
actuated scaled model of an excavator and evaluate and compare different
teaching strategies utilized by the robot.
</dc:description>
 <dc:description>Comment: 9 pages, conference</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07492</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inducing Interpretable Representations with Variational Autoencoders</dc:title>
 <dc:creator>Siddharth, N.</dc:creator>
 <dc:creator>Paige, Brooks</dc:creator>
 <dc:creator>Desmaison, Alban</dc:creator>
 <dc:creator>Van de Meent, Jan-Willem</dc:creator>
 <dc:creator>Wood, Frank</dc:creator>
 <dc:creator>Goodman, Noah D.</dc:creator>
 <dc:creator>Kohli, Pushmeet</dc:creator>
 <dc:creator>Torr, Philip H. S.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We develop a framework for incorporating structured graphical models in the
\emph{encoders} of variational autoencoders (VAEs) that allows us to induce
interpretable representations through approximate variational inference. This
allows us to both perform reasoning (e.g. classification) under the structural
constraints of a given graphical model, and use deep generative models to deal
with messy, high-dimensional domains where it is often difficult to model all
the variation. Learning in this framework is carried out end-to-end with a
variational objective, applying to both unsupervised and semi-supervised
schemes.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07502</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Component-based Synthesis of Table Consolidation and Transformation
  Tasks from Examples</dc:title>
 <dc:creator>Feng, Yu</dc:creator>
 <dc:creator>Martins, Ruben</dc:creator>
 <dc:creator>Van Geffen, Jacob</dc:creator>
 <dc:creator>Dillig, Isil</dc:creator>
 <dc:creator>Chaudhuri, Swarat</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:description>  This paper presents an example-driven synthesis technique for automating a
large class of data preparation tasks that arise in data science. Given a set
of input tables and an out- put table, our approach synthesizes a table
transformation program that performs the desired task. Our approach is not
restricted to a fixed set of DSL constructs and can synthesize programs from an
arbitrary set of components, including higher-order combinators. At a
high-level, our approach performs type-directed enumerative search over partial
pro- grams but incorporates two key innovations that allow it to scale: First,
our technique can utilize any first-order specification of the components and
uses SMT-based deduction to reject partial programs. Second, our algorithm uses
partial evaluation to increase the power of deduction and drive enumerative
search. We have evaluated our synthesis algorithm on dozens of data preparation
tasks obtained from on-line forums, and we show that our approach can
automatically solve a large class of problems encountered by R users.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07502</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07503</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Purchasing a C_4 online</dc:title>
 <dc:creator>Anastos, Michael</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Let $G$ be a graph with edge set $(e_1,e_2,...e_N)$. We independently
associate to each edge $e_i$ of $G$ a cost ${x}_i$ that is drawn from a Uniform
[0, 1] distribution. Suppose $\mathcal{F}$ is a set of targeted structures that
consists of subgraphs of $G$. We would like to buy a subset of $\mathcal{F}$ at
small cost, however we do not know a priori the values of the random variables
${x}_1,...,{x}_N$. Instead, we inspect the random variables $x_i$ one at a
time. As soon as we inspect the random variable associated with the cost of an
edge we have to decide whether we want to buy that edge or reject it for ever.
  In the present paper we consider the case where $G$ is the complete graph on
$n$ vertices and $\mathcal{F}$ is the set of all $C_4$ -cycles on 4 vertices-
out of which we want to buy one.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07507</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Intrinsic Control</dc:title>
 <dc:creator>Gregor, Karol</dc:creator>
 <dc:creator>Rezende, Danilo Jimenez</dc:creator>
 <dc:creator>Wierstra, Daan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper we introduce a new unsupervised reinforcement learning method
for discovering the set of intrinsic options available to an agent. This set is
learned by maximizing the number of different states an agent can reliably
reach, as measured by the mutual information between the set of options and
option termination states. To this end, we instantiate two policy gradient
based algorithms, one that creates an explicit embedding space of options and
one that represents options implicitly. The algorithms also provide an explicit
measure of empowerment in a given state that can be used by an empowerment
maximizing agent. The algorithm scales well with function approximation and we
demonstrate the applicability of the algorithm on a range of tasks.
</dc:description>
 <dc:description>Comment: 15 pages, 6 figures</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07507</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07509</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A causal framework for discovering and removing direct and indirect
  discrimination</dc:title>
 <dc:creator>Zhang, Lu</dc:creator>
 <dc:creator>Wu, Yongkai</dc:creator>
 <dc:creator>Wu, Xintao</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Anti-discrimination is an increasingly important task in data science. In
this paper, we investigate the problem of discovering both direct and indirect
discrimination from the historical data, and removing the discriminatory
effects before the data is used for predictive analysis (e.g., building
classifiers). We make use of the causal network to capture the causal structure
of the data. Then we model direct and indirect discrimination as the
path-specific effects, which explicitly distinguish the two types of
discrimination as the causal effects transmitted along different paths in the
network. Based on that, we propose an effective algorithm for discovering
direct and indirect discrimination, as well as an algorithm for precisely
removing both types of discrimination while retaining good data utility.
Different from previous works, our approaches can ensure that the predictive
models built from the modified data will not incur discrimination in decision
making. Experiments using real datasets show the effectiveness of our
approaches.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07511</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can Broken Multicore Hardware be Mended?</dc:title>
 <dc:creator>V&#xe9;gh, J&#xe1;nos</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  A suggestion is made for mending multicore hardware, which has been diagnosed
as broken.
</dc:description>
 <dc:description>Comment: 3 figures; a Viewpoint</dc:description>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07541</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Structures for Weighted Matching and Extensions to $b$-matching and
  $f$-factors</dc:title>
 <dc:creator>Gabow, Harold N.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  This paper shows the weighted matching problem on general graphs can be
solved in time $O(n(m + n\log n))$ for $n$ and $m$ the number of vertices and
edges, respectively. This was previously known only for bipartite graphs. The
crux is a data structure for blossom creation. It uses a dynamic
nearest-common-ancestor algorithm to simplify blossom steps, so they involve
only back edges rather than arbitrary nontree edges.
  The rest of the paper presents direct extensions of Edmonds' blossom
algorithm to weighted $b$-matching and $f$-factors. Again the time bound is the
one previously known for bipartite graphs: for $b$-matching the time is
$O(\min\{b(V),n\log n\}(m + n\log n))$ and for $f$-factors the time is
$O(\min\{f(V),m\log n\}( m + n\log n) )$, where $b(V)$ and $f(V)$ denote the
sum of all degree constraints. Several immediate applications of the $f$-factor
algorithm are given: The generalized shortest path structure of \cite{GS13},
i.e., the analog of the shortest path tree for conservative undirected graphs,
is shown to be a version of the blossom structure for $f$-factors. This
structure is found in time $O(|N|(m+n\log n))$ for $N$ the set of negative
edges ($0&lt;|N|&lt;n$). A shortest $T$-join is found in time $O(n(m+n\log n))$, or
$O(|T|(m+n\log n))$ when all costs are nonnegative. These bounds are all slight
improvements of previously known ones, and are simply achieved by proper
initialization of the $f$-factor algorithm.
</dc:description>
 <dc:description>Comment: This paper is a combination of two conference papers: A preliminary
  version of the data structures part appeared in Proc. 1st Annual ACM-SIAM
  Symp. on Disc. Algorithms (SODA), 1990. A preliminary version of the
  extensions part, based on reduction to matching, appeared in Proc. 15th
  Annual ACM Symp. on Theory of Comp. (STOC), 1983</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07541</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07544</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-learning Scene-specific Pedestrian Detectors using a Progressive
  Latent Model</dc:title>
 <dc:creator>Ye, Qixiang</dc:creator>
 <dc:creator>Zhang, Tianliang</dc:creator>
 <dc:creator>Qiu, Qiang</dc:creator>
 <dc:creator>Zhang, Baochang</dc:creator>
 <dc:creator>Chen, Jie</dc:creator>
 <dc:creator>Sapiro, Guillermo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, a self-learning approach is proposed towards solving
scene-specific pedestrian detection problem without any human' annotation
involved. The self-learning approach is deployed as progressive steps of object
discovery, object enforcement, and label propagation. In the learning
procedure, object locations in each frame are treated as latent variables that
are solved with a progressive latent model (PLM). Compared with conventional
latent models, the proposed PLM incorporates a spatial regularization term to
reduce ambiguities in object proposals and to enforce object localization, and
also a graph-based label propagation to discover harder instances in adjacent
frames. With the difference of convex (DC) objective functions, PLM can be
efficiently optimized with a concave-convex programming and thus guaranteeing
the stability of self-learning. Extensive experiments demonstrate that even
without annotation the proposed self-learning approach outperforms weakly
supervised learning approaches, while achieving comparable performance with
transfer learning and fully supervised approaches.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07544</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07549</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Benefit of Automated Static Analysis for Small and Medium-Sized
  Software Enterprises</dc:title>
 <dc:creator>Gleirscher, Mario</dc:creator>
 <dc:creator>Golubitskiy, Dmitriy</dc:creator>
 <dc:creator>Irlbeck, Maximilian</dc:creator>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Today's small and medium-sized enterprises (SMEs) in the software industry
are faced with major challenges. While having to work efficiently using limited
resources they have to perform quality assurance on their code to avoid the
risk of further effort for bug fixes or compensations. Automated static
analysis can reduce this risk because it promises little effort for running an
analysis. We report on our experience in analysing five projects from and with
SMEs by three different static analysis techniques: code clone detection, bug
pattern detection and architecture conformance analysis. We found that the
effort that was needed to introduce those techniques was small (mostly below
one person-hour), that we can detect diverse defects in production code and
that the participating companies perceived the usefulness of the presented
techniques as well as our analysis results high enough to include the
techniques in their quality assurance.
</dc:description>
 <dc:description>Comment: 25 pages, 0 figures</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07549</dc:identifier>
 <dc:identifier>Proc. 4th International Conference on Software Quality. Process
  Automation in Software Development (SWQD 2012). Springer, 2012</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-642-27213-4_3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07555</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomized Distributed Mean Estimation: Accuracy vs Communication</dc:title>
 <dc:creator>Kone&#x10d;n&#xfd;, Jakub</dc:creator>
 <dc:creator>Richt&#xe1;rik, Peter</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of estimating the arithmetic average of a finite
collection of real vectors stored in a distributed fashion across several
compute nodes subject to a communication budget constraint. Our analysis does
not rely on any statistical assumptions about the source of the vectors. This
problem arises as a subproblem in many applications, including reduce-all
operations within algorithms for distributed and federated optimization and
learning. We propose a flexible family of randomized algorithms exploring the
trade-off between expected communication cost and estimation error. Our family
contains the full-communication and zero-error method on one extreme, and an
$\epsilon$-bit communication and ${\cal O}\left(1/(\epsilon n)\right)$ error
method on the opposite extreme. In the special case where we communicate, in
expectation, a single bit per coordinate of each vector, we improve upon
existing results by obtaining $\mathcal{O}(r/n)$ error, where $r$ is the number
of bits used to represent a floating point value.
</dc:description>
 <dc:description>Comment: 19 pages, 1 figure</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07555</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07556</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cultivating Software Performance in Cloud Computing</dc:title>
 <dc:creator>Chen, Li</dc:creator>
 <dc:creator>Cunningham, Colin</dc:creator>
 <dc:creator>Jain, Pooja</dc:creator>
 <dc:creator>Qin, Chenggang</dc:creator>
 <dc:creator>Chow, Kingsum</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  There exist multitudes of cloud performance metrics, including workload
performance, application placement, software/hardware optimization,
scalability, capacity, reliability, agility and so on. In this paper, we
consider jointly optimizing the performance of the software applications in the
cloud. The challenges lie in bringing a diversity of raw data into tidy data
format, unifying performance data from multiple systems based on timestamps,
and assessing the quality of the processed performance data. Even after
verifying the quality of cloud performance data, additional challenges block
optimizing cloud computing. In this paper, we identify the challenges of cloud
computing from the perspectives of computing environment, data collection,
performance analytics and production environment.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07556</dc:identifier>
 <dc:identifier>Pacific NW Software Quality Conference 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07558</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the linear quadratic problem for systems with time reversed Markov
  jump parameters and the duality with filtering of Markov jump linear systems</dc:title>
 <dc:creator>Gutierrez, Daniel</dc:creator>
 <dc:creator>Costa, Eduardo F.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We study a class of systems whose parameters are driven by a Markov chain in
reverse time. A recursive characterization for the second moment matrix, a
spectral radius test for mean square stability and the formulas for optimal
control are given. Our results are determining for the question: is it possible
to extend the classical duality between filtering and control of linear systems
(whose matrices are transposed in the dual problem) by simply adding the jump
variable of a Markov jump linear system. The answer is positive provided the
jump process is reversed in time.
</dc:description>
 <dc:description>Comment: 5 pages, technical note</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07559</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sar image despeckling based on nonlocal similarity sparse decomposition</dc:title>
 <dc:creator>Sang, Chengwei</dc:creator>
 <dc:creator>Sun, Hong</dc:creator>
 <dc:creator>Xia, Quisong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This letter presents a method of synthetic aperture radar (SAR) image
despeckling aimed to preserve the detail information while suppressing speckle
noise. This method combines the nonlocal self-similarity partition and a
proposed modified sparse decomposition. The nonlocal partition method groups a
series of structure-similarity data sets. Each data set has a good sparsity for
learning an over-complete dictionary in sparse representation. In the sparse
decomposition, we propose a novel method to identify principal atoms from
over-complete dictionary to form a principal dictionary. Despeckling is
performed on each data set over the principal dictionary with principal atoms.
Experimental results demonstrate that the proposed method can achieve high
performances in terms of both speckle noise reduction and structure details
preservation.
</dc:description>
 <dc:description>Comment: 5pages,5 figures,20 conference</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07560</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Introduction of Static Quality Analysis in Small and Medium-Sized
  Software Enterprises: Experiences from Technology Transfer</dc:title>
 <dc:creator>Gleirscher, Mario</dc:creator>
 <dc:creator>Golubitskiy, Dmitriy</dc:creator>
 <dc:creator>Irlbeck, Maximilian</dc:creator>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Today, small and medium-sized enterprises (SMEs) in the software industry
face major challenges. Their resource constraints require high efficiency in
development. Furthermore, quality assurance (QA) measures need to be taken to
mitigate the risk of additional, expensive effort for bug fixes or
compensations. Automated static analysis (ASA) can reduce this risk because it
promises low application effort. SMEs seem to take little advantage of this
opportunity. Instead, they still mainly rely on the dynamic analysis approach
of software testing. In this article, we report on our experiences from a
technology transfer project. Our aim was to evaluate the results static
analysis can provide for SMEs as well as the problems that occur when
introducing and using static analysis in SMEs. We analysed five software
projects from five collaborating SMEs using three different ASA techniques:
code clone detection, bug pattern detection and architecture conformance
analysis. Following the analysis, we applied a quality model to aggregate and
evaluate the results. Our study shows that the effort required to introduce ASA
techniques in SMEs is small (mostly below one person-hour each). Furthermore,
we encountered only few technical problems. By means of the analyses, we could
detect multiple defects in production code. The participating companies
perceived the analysis results to be a helpful addition to their current QA and
will include the analyses in their QA process. With the help of the Quamoco
quality model, we could efficiently aggregate and rate static analysis results.
However, we also encountered a partial mismatch with the opinions of the SMEs.
We conclude, that ASA and quality models can be a valuable and affordable
addition to the QA process of SMEs.
</dc:description>
 <dc:description>Comment: 46 pages, 1 figure</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07560</dc:identifier>
 <dc:identifier>Software Quality Journal, Volume 22, Issue 3, pp 499-542,
  September 2014</dc:identifier>
 <dc:identifier>doi:10.1007/s11219-013-9217-z</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07567</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Importance Measure for Non-linear Learning Algorithms</dc:title>
 <dc:creator>Vidovic, Marina M. -C.</dc:creator>
 <dc:creator>G&#xf6;rnitz, Nico</dc:creator>
 <dc:creator>M&#xfc;ller, Klaus-Robert</dc:creator>
 <dc:creator>Kloft, Marius</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Complex problems may require sophisticated, non-linear learning methods such
as kernel machines or deep neural networks to achieve state of the art
prediction accuracies. However, high prediction accuracies are not the only
objective to consider when solving problems using machine learning. Instead,
particular scientific applications require some explanation of the learned
prediction function. Unfortunately, most methods do not come with out of the
box straight forward interpretation. Even linear prediction functions are not
straight forward to explain if features exhibit complex correlation structure.
  In this paper, we propose the Measure of Feature Importance (MFI). MFI is
general and can be applied to any arbitrary learning machine (including kernel
machines and deep learning). MFI is intrinsically non-linear and can detect
features that by itself are inconspicuous and only impact the prediction
function through their interaction with other features. Lastly, MFI can be used
for both --- model-based feature importance and instance-based feature
importance (i.e, measuring the importance of a feature for a particular data
point).
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07571</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quad-networks: unsupervised learning to rank for interest point
  detection</dc:title>
 <dc:creator>Savinov, Nikolay</dc:creator>
 <dc:creator>Seki, Akihito</dc:creator>
 <dc:creator>Ladicky, Lubor</dc:creator>
 <dc:creator>Sattler, Torsten</dc:creator>
 <dc:creator>Pollefeys, Marc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Several machine learning tasks require to represent the data using only a
sparse set of interest points. An ideal detector is able to find the
corresponding interest points even if the data undergo a transformation typical
for a given domain. Since the task is of high practical interest in computer
vision, many hand-crafted solutions were proposed. In this paper, we ask a
fundamental question: can we learn such detectors from scratch? Since it is
often unclear what points are &quot;interesting&quot;, human labelling cannot be used to
find a truly unbiased solution. Therefore, the task requires an unsupervised
formulation. We are the first to propose such a formulation: training a neural
network to rank points in a transformation-invariant manner. Interest points
are then extracted from the top/bottom quantiles of this ranking. We validate
our approach on two tasks: standard RGB image interest point detection and
challenging cross-modal interest point detection between RGB and depth images.
We quantitatively show that our unsupervised method performs better or on-par
with baselines.
</dc:description>
 <dc:description>Comment: Accepted at CVPR 2017</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07573</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relaxed Earth Mover's Distances for Chain- and Tree-connected Spaces and
  their use as a Loss Function in Deep Learning</dc:title>
 <dc:creator>Martinez, Manuel</dc:creator>
 <dc:creator>Haurilet, Monica</dc:creator>
 <dc:creator>Al-Halah, Ziad</dc:creator>
 <dc:creator>Tapaswi, Makarand</dc:creator>
 <dc:creator>Stiefelhagen, Rainer</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The Earth Mover's Distance (EMD) computes the optimal cost of transforming
one distribution into another, given a known transport metric between them. In
deep learning, the EMD loss allows us to embed information during training
about the output space structure like hierarchical or semantic relations. This
helps in achieving better output smoothness and generalization. However EMD is
computationally expensive.Moreover, solving EMD optimization problems usually
require complex techniques like lasso. These properties limit the applicability
of EMD-based approaches in large scale machine learning.
  We address in this work the difficulties facing incorporation of EMD-based
loss in deep learning frameworks. Additionally, we provide insight and novel
solutions on how to integrate such loss function in training deep neural
networks. Specifically, we make three main contributions: (i) we provide an
in-depth analysis of the fastest state-of-the-art EMD algorithm (Sinkhorn
Distance) and discuss its limitations in deep learning scenarios. (ii) we
derive fast and numerically stable closed-form solutions for the EMD gradient
in output spaces with chain- and tree- connectivity; and (iii) we propose a
relaxed form of the EMD gradient with equivalent computational complexity but
faster convergence rate. We support our claims with experiments on real
datasets. In a restricted data setting on the ImageNet dataset, we train a
model to classify 1000 categories using 50K images, and demonstrate that our
relaxed EMD loss achieves better Top-1 accuracy than the cross entropy loss.
Overall, we show that our relaxed EMD loss criterion is a powerful asset for
deep learning in the small data regime.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07573</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07579</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Programs as Black-Box Explanations</dc:title>
 <dc:creator>Singh, Sameer</dc:creator>
 <dc:creator>Ribeiro, Marco Tulio</dc:creator>
 <dc:creator>Guestrin, Carlos</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recent work in model-agnostic explanations of black-box machine learning has
demonstrated that interpretability of complex models does not have to come at
the cost of accuracy or model flexibility. However, it is not clear what kind
of explanations, such as linear models, decision trees, and rule lists, are the
appropriate family to consider, and different tasks and models may benefit from
different kinds of explanations. Instead of picking a single family of
representations, in this work we propose to use &quot;programs&quot; as model-agnostic
explanations. We show that small programs can be expressive yet intuitive as
explanations, and generalize over a number of existing interpretable families.
We propose a prototype program induction method based on simulated annealing
that approximates the local behavior of black-box classifiers around a specific
prediction using random perturbations. Finally, we present preliminary
application on small datasets and show that the generated explanations are
intuitive and accurate for a number of classifiers.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07579</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07580</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pricing Mechanisms for Crowd-Sensed Spatial-Statistics-Based Radio
  Mapping</dc:title>
 <dc:creator>Ying, Xuhang</dc:creator>
 <dc:creator>Roy, Sumit</dc:creator>
 <dc:creator>Poovendran, Radha</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Networking on white spaces (i.e., locally unused spectrum) relies on active
monitoring of spectrum usage. Spectrum databases based on empirical radio
propagation models are widely adopted but shown to be error-prone, since they
do not account for built environments like trees and man-made buildings. As an
economically viable option, crowd-sensed radio mapping acquires more accurate
local spectrum data from mobile users and constructs radio maps using spatial
models such as Kriging and Gaussian Process. Success of such crowd-sensing
systems presumes some incentive mechanisms to attract user participation. In
this work, we consider the scenario where the platform who constructs radio
environment maps makes one-time offers to selected users, and collects data
from those who accept the offers. We design pricing mechanisms based on
expected utility (EU) maximization, where EU captures the tradeoff between
radio mapping performance (location and data quality), crowd-sensing cost and
uncertainty in offer outcomes (i.e., possible expiration and rejection).
Specifically, we consider sequential offering, where one best price offer is
sent to the best user in each round, and batched offering, where a batch of
multiple offers are made in each round. For the later, we show that EU is
submodular in the discrete domain, and propose a mechanism that first fixes the
pricing rule and selects users based on Unconstrained Submodular Maximization
(USM); it then compares different pricing rules to find the best batch of
offers in each round. We show that USM-based user selection has provable
performance guarantee. Proposed mechanisms are evaluated and compared against
utility-maximization-based baseline mechanisms.
</dc:description>
 <dc:description>Comment: Part of this work was present at IEEE GLOBECOM 2016</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07580</dc:identifier>
 <dc:identifier>doi:10.1109/TCCN.2017.2701812</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07583</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alternating Direction Graph Matching</dc:title>
 <dc:creator>L&#xea;-Huu, D. Khu&#xea;</dc:creator>
 <dc:creator>Paragios, Nikos</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we introduce a graph matching method that can account for
constraints of arbitrary order, with arbitrary potential functions. Unlike
previous decomposition approaches that rely on the graph structures, we
introduce a decomposition of the matching constraints. Graph matching is then
reformulated as a non-convex non-separable optimization problem that can be
split into smaller and much-easier-to-solve subproblems, by means of the
alternating direction method of multipliers. The proposed framework is modular,
scalable, and can be instantiated into different variants. Two instantiations
are studied exploring pairwise and higher-order constraints. Experimental
results on widely adopted benchmarks involving synthetic and real examples
demonstrate that the proposed solutions outperform existing pairwise graph
matching methods, and competitive with the state of the art in higher-order
settings.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07588</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Neural Network Model to Classify Liver Cancer Patients Using Data
  Expansion and Compression</dc:title>
 <dc:creator>Zeinalzadeh, Ashkan</dc:creator>
 <dc:creator>Wenska, Tom</dc:creator>
 <dc:creator>Okimoto, Gordon</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  We develop a neural network model to classify liver cancer patients into
high-risk and low-risk groups using genomic data. Our approach provides a novel
technique to classify big data sets using neural network models. We preprocess
the data before training the neural network models. We first expand the data
using wavelet analysis. We then compress the wavelet coefficients by mapping
them onto a new scaled orthonormal coordinate system. Then the data is used to
train a neural network model that enables us to classify cancer patients into
two different classes of high-risk and low-risk patients. We use the
leave-one-out approach to build a neural network model. This neural network
model enables us to classify a patient using genomic data as a high-risk or
low-risk patient without any information about the survival time of the
patient. The results from genomic data analysis are compared with survival time
analysis. It is shown that the expansion and compression of data using wavelet
analysis and singular value decomposition (SVD) is essential to train the
neural network model.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07588</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07592</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The game of Overprescribed Cops and Robbers played on graphs</dc:title>
 <dc:creator>Bonato, Anthony</dc:creator>
 <dc:creator>P&#xe9;rez-Gim&#xe9;nez, Xavier</dc:creator>
 <dc:creator>Pra&#x142;at, Pawe&#x142;</dc:creator>
 <dc:creator>Reiniger, Benjamin</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We consider the effect on the length of the game of Cops and Robbers when
more cops are added to the game play. In Overprescribed Cops and Robbers, as
more cops are added, the capture time (the minimum length of the game assuming
optimal play) monotonically decreases. We give the full range of capture times
for any number of cops on trees, and classify the capture time for an
asymptotic number of cops on grids, hypercubes, and binomial random graphs. The
capture time of planar graphs with a number of cops at and far above the cop
number is considered.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07592</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07593</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Joint Feature Adaptation for Zero-Shot Recognition</dc:title>
 <dc:creator>Zhang, Ziming</dc:creator>
 <dc:creator>Saligrama, Venkatesh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Zero-shot recognition (ZSR) aims to recognize target-domain data instances of
unseen classes based on the models learned from associated pairs of seen-class
source and target domain data. One of the key challenges in ZSR is the relative
scarcity of source-domain features (e.g. one feature vector per class), which
do not fully account for wide variability in target-domain instances. In this
paper we propose a novel framework of learning data-dependent feature
transforms for scoring similarity between an arbitrary pair of source and
target data instances to account for the wide variability in target domain. Our
proposed approach is based on optimizing over a parameterized family of local
feature displacements that maximize the source-target adaptive similarity
functions. Accordingly we propose formulating zero-shot learning (ZSL) using
latent structural SVMs to learn our similarity functions from training data. As
demonstration we design a specific algorithm under the proposed framework
involving bilinear similarity functions and regularized least squares as
penalties for feature displacement. We test our approach on several benchmark
datasets for ZSR and show significant improvement over the state-of-the-art.
For instance, on aP&amp;Y dataset we can achieve 80.89% in terms of recognition
accuracy, outperforming the state-of-the-art by 11.15%.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07593</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07596</identifier>
 <datestamp>2017-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Fourier Color Constancy</dc:title>
 <dc:creator>Barron, Jonathan T.</dc:creator>
 <dc:creator>Tsai, Yun-Ta</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present Fast Fourier Color Constancy (FFCC), a color constancy algorithm
which solves illuminant estimation by reducing it to a spatial localization
task on a torus. By operating in the frequency domain, FFCC produces lower
error rates than the previous state-of-the-art by 13-20% while being 250-3000
times faster. This unconventional approach introduces challenges regarding
aliasing, directional statistics, and preconditioning, which we address. By
producing a complete posterior distribution over illuminants instead of a
single illuminant estimate, FFCC enables better training techniques, an
effective temporal smoothing technique, and richer methods for error analysis.
Our implementation of FFCC runs at ~700 frames per second on a mobile device,
allowing it to be used as an accurate, real-time, temporally-coherent automatic
white balance algorithm.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-03-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07599</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Delivery Policy to Minimize User Traffic Consumption in
  Guaranteed Advertising</dc:title>
 <dc:creator>Zhang, Jia</dc:creator>
 <dc:creator>Wang, Zheng</dc:creator>
 <dc:creator>Li, Qian</dc:creator>
 <dc:creator>Zhang, Jialin</dc:creator>
 <dc:creator>Lan, Yanyan</dc:creator>
 <dc:creator>Li, Qiang</dc:creator>
 <dc:creator>Sun, Xiaoming</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this work, we study the guaranteed delivery model which is widely used in
online display advertising. In the guaranteed delivery scenario, ad exposures
(which are also called impressions in some works) to users are guaranteed by
contracts signed in advance between advertisers and publishers. A crucial
problem for the advertising platform is how to fully utilize the valuable user
traffic to generate as much as possible revenue.
  Different from previous works which usually minimize the penalty of
unsatisfied contracts and some other cost (e.g. representativeness), we propose
the novel consumption minimization model, in which the primary objective is to
minimize the user traffic consumed to satisfy all contracts. Under this model,
we develop a near optimal method to deliver ads for users. The main advantage
of our method lies in that it consumes nearly as least as possible user traffic
to satisfy all contracts, therefore more contracts can be accepted to produce
more revenue. It also enables the publishers to estimate how much user traffic
is redundant or short so that they can sell or buy this part of traffic in bulk
in the exchange market. Furthermore, it is robust with regard to priori
knowledge of user type distribution. Finally, the simulation shows that our
method outperforms the traditional state-of-the-art methods.
</dc:description>
 <dc:description>Comment: Already accepted by AAAI'17</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07599</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07601</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Future Wireless Network: MyNET Platform and End-to-End Network Slicing</dc:title>
 <dc:creator>Zhang, Hang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Future wireless networks are facing new challenges. These new challenges
require new solutions and strategies of the network deployment, management, and
operation. Many driving factors are decisive in the re-definition and re-design
of the future wireless network architecture. In the previously published paper
&quot;5G Wireless Network - MyNET and SONAC&quot;, MyNET and SONAC, a future network
architecture, are described. This paper elaborates MyNET platform with more
details. The design principles of MyNET architecture, the development of MyNET
platform, the functions of MyNET platform, the automation of the creation and
the management of end-to-end slices by MyNET, and the new capabilities enabled
by MyNET are described in details.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07605</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Pricing for Submodular Valuations with Bounded Curvature</dc:title>
 <dc:creator>Maehara, Takanori</dc:creator>
 <dc:creator>Kawase, Yasushi</dc:creator>
 <dc:creator>Sumita, Hanna</dc:creator>
 <dc:creator>Tono, Katsuya</dc:creator>
 <dc:creator>Kawarabayashi, Ken-ichi</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The optimal pricing problem is a fundamental problem that arises in
combinatorial auctions. Suppose that there is one seller who has indivisible
items and multiple buyers who want to purchase a combination of the items. The
seller wants to sell his items for the highest possible prices, and each buyer
wants to maximize his utility (i.e., valuation minus payment) as long as his
payment does not exceed his budget. The optimal pricing problem seeks a price
of each item and an assignment of items to buyers such that every buyer
achieves the maximum utility under the prices. The goal of the problem is to
maximize the total payment from buyers. In this paper, we consider the case
that the valuations are submodular. We show that the problem is computationally
hard even if there exists only one buyer. Then we propose approximation
algorithms for the unlimited budget case. We also extend the algorithm for the
limited budget case when there exists one buyer and multiple buyers collaborate
with each other.
</dc:description>
 <dc:description>Comment: Full paper version of our AAAI'17 paper</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07605</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07608</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for Collision-Tolerant Optimal Trajectory Planning of
  Autonomous Vehicles</dc:title>
 <dc:creator>Mote, Mark L.</dc:creator>
 <dc:creator>Afman, Juan-Pablo</dc:creator>
 <dc:creator>Feron, Eric</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Collision-tolerant trajectory planning is the consideration that collisions,
if they are planned appropriately, enable more effective path planning for
robots capable of handling them. A mixed integer programming (MIP) optimization
formulation demonstrates the computational practicality of optimizing
trajectories that comprise planned collisions. A damage quantification function
is proposed, and the influence of damage functions constraints on the
trajectory are studied in simulation. Using a simple example, an increase in
performance is achieved under this schema as compared to collision-free optimal
trajectories.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07608</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07610</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mutable WadlerFest DOT</dc:title>
 <dc:creator>Rapoport, Marianna</dc:creator>
 <dc:creator>Lhot&#xe1;k, Ond&#x159;ej</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  The Dependent Object Types (DOT) calculus aims to model the essence of Scala,
with a focus on abstract type members, path-dependent types, and subtyping.
Other Scala features could be defined by translation to DOT. Mutation is a
fundamental feature of Scala currently missing in DOT. Mutation in DOT is
needed not only to model effectful computation and mutation in Scala programs,
but even to precisely specify how Scala initializes immutable variables and
fields (vals). We present an extension to DOT that adds typed mutable reference
cells. We have proven the extension sound with a mechanized proof in Coq. We
present the key features of our extended calculus and its soundness proof, and
discuss the challenges that we encountered in our search for a sound design and
the alternative solutions that we considered.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07610</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07612</identifier>
 <datestamp>2017-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster Population Counts Using AVX2 Instructions</dc:title>
 <dc:creator>Mu&#x142;a, Wojciech</dc:creator>
 <dc:creator>Kurz, Nathan</dc:creator>
 <dc:creator>Lemire, Daniel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Counting the number of ones in a binary stream is a common operation in
database, information-retrieval, cryptographic and machine-learning
applications. Most processors have dedicated instructions to count the number
of ones in a word (e.g., popcnt on x64 processors). Maybe surprisingly, we show
that a vectorized approach using SIMD instructions can be twice as fast as
using the dedicated instructions on recent Intel processors. The benefits can
be even greater for applications such as similarity measures (e.g., the Jaccard
index) that require additional Boolean operations. Our approach has been
adopted by LLVM: it is used by its popular C compiler (clang).
</dc:description>
 <dc:description>Comment: Software is at https://github.com/CountOnes/hamming_weight</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-10-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07612</dc:identifier>
 <dc:identifier>doi:10.1093/comjnl/bxx046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07617</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Framework for Ranking Vulnerabilities in the Clouds</dc:title>
 <dc:creator>Zhu, He</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Qualifying and ranking threat degrees of vulnerabilities in cloud service are
known to be full of challenges. Although there have been several efforts aiming
to address this problem, most of them are too simple or cannot be applied into
cloud infrastructure. This paper aims to propose a novel framework to qualify
and rank the vulnerabilities based on their threat degrees in cloud service.
Through inputting or constructing service dependency graph, our framework is
able to generate the importance degree of each service and the ranking list of
all the vulnerabilities in cloud service. Moreover, our framework can be
adopted not only into various cloud infrastructures, but also different
categories of algorithms according to concrete requirements. To evaluate our
framework, we adopt AssetRank algorithm into the framework, and present the
whole design of our work. Comprehensive experiments prove the effectiveness of
our framework on qualifying and ranking vulnerabilities in cloud service.
</dc:description>
 <dc:description>Comment: arXiv admin note: submission has been withdrawn by arXiv
  administrators due to inappropriate text reuse from external sources</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07617</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07619</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Truthful $(1-\epsilon)$-Optimal Mechanism for On-demand Cloud Resource
  Provisioning</dc:title>
 <dc:creator>Zhang, Xiaoxi</dc:creator>
 <dc:creator>Wu, Chuan</dc:creator>
 <dc:creator>Li, Zongpeng</dc:creator>
 <dc:creator>Lau, Francis C. M.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  On-demand resource provisioning in cloud computing provides tailor-made
resource packages (typically in the form of VMs) to meet users' demands. Public
clouds nowadays provide more and more elaborated types of VMs, but have yet to
offer the most flexible dynamic VM assembly, which is partly due to the lack of
a mature mechanism for pricing tailor-made VMs on the spot. This work proposes
an efficient randomized auction mechanism based on a novel application of
smoothed analysis and randomized reduction, for dynamic VM provisioning and
pricing in geo-distributed cloud data centers. This auction, to the best of our
knowledge, is the first one in literature that achieves (i) truthfulness in
expectation, (ii) polynomial running time in expectation, and (iii)
$(1-\epsilon)$-optimal social welfare in expectation for resource allocation,
where $\epsilon$ can be arbitrarily close to 0. Our mechanism consists of three
modules: (1) an exact algorithm to solve the NP-hard social welfare
maximization problem, which runs in polynomial time in expectation, (2) a
perturbation-based randomized resource allocation scheme which produces a VM
provisioning solution that is $(1-\epsilon)$-optimal, and (3) an auction
mechanism that applies the perturbation-based scheme for dynamic VM
provisioning and prices the customized VMs using a randomized VCG payment, with
a guarantee in truthfulness in expectation. We validate the efficacy of the
mechanism through careful theoretical analysis and trace-driven simulations.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07620</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using SyGuS to Synthesize Reactive Motion Plans</dc:title>
 <dc:creator>Chasins, Sarah</dc:creator>
 <dc:creator>Newcomb, Julie L.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present an approach for synthesizing reactive robot motion plans, based on
compilation to Syntax-Guided Synthesis (SyGuS) specifications. Our method
reduces the motion planning problem to the problem of synthesizing a function
that can choose the next robot action in response to the current state of the
system. This technique offers reactivity not by generating new motion plans
throughout deployment, but by synthesizing a single program that causes the
robot to reach its target from any system state that is consistent with the
system model. This approach allows our tool to handle environments with
adversarial obstacles. This work represents the first use of the SyGuS
formalism to solve robot motion planning problems. We investigate whether using
SyGuS for a bounded two-player reachability game is practical at this point in
time.
</dc:description>
 <dc:description>Comment: In Proceedings SYNT 2016, arXiv:1611.07178</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07620</dc:identifier>
 <dc:identifier>EPTCS 229, 2016, pp. 3-20</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.229.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07621</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What You Really Need To Know About Your Neighbor</dc:title>
 <dc:creator>Damm, Werner</dc:creator>
 <dc:creator>Finkbeiner, Bernd</dc:creator>
 <dc:creator>Rakow, Astrid</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  A fundamental question in system design is to decide how much of the design
of one component must be known in order to successfully design another
component of the system. We study this question in the setting of reactive
synthesis, where one constructs a system implementation from a specification
given in temporal logic. In previous work, we have shown that the system can be
constructed compositionally, one component at a time, if the specification
admits a &quot;dominant&quot; (as explained in Introduction) strategy for each component.
In this paper, we generalize the approach to settings where dominant strategies
only exist under certain assumptions about the future behavior of the other
components. We present an incremental synthesis method based on the automatic
construction of such assumptions.
</dc:description>
 <dc:description>Comment: In Proceedings SYNT 2016, arXiv:1611.07178</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07621</dc:identifier>
 <dc:identifier>EPTCS 229, 2016, pp. 21-34</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.229.4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07622</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Symbolic BDD and ADD Algorithms for Energy Games</dc:title>
 <dc:creator>Maoz, Shahar</dc:creator>
 <dc:creator>Pistiner, Or</dc:creator>
 <dc:creator>Ringert, Jan Oliver</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Energy games, which model quantitative consumption of a limited resource,
e.g., time or energy, play a central role in quantitative models for reactive
systems. Reactive synthesis constructs a controller which satisfies a given
specification, if one exists. For energy games a synthesized controller ensures
to satisfy not only the safety constraints of the specification but also the
quantitative constraints expressed in the energy game. A symbolic algorithm for
energy games, recently presented by Chatterjee et al., is symbolic in its
representation of quantitative values but concrete in the representation of
game states and transitions. In this paper we present an algorithm that is
symbolic both in the quantitative values and in the underlying game
representation. We have implemented our algorithm using two different symbolic
representations for reactive games, Binary Decision Diagrams (BDD) and
Algebraic Decision Diagrams (ADD). We investigate the commonalities and
differences of the two implementations and compare their running times on
specifications of energy games.
</dc:description>
 <dc:description>Comment: In Proceedings SYNT 2016, arXiv:1611.07178</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07622</dc:identifier>
 <dc:identifier>EPTCS 229, 2016, pp. 35-54</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.229.5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07623</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Parallel Data Processing Frameworks with Verified Lifting</dc:title>
 <dc:creator>Ahmad, Maaz Bin Safeer</dc:creator>
 <dc:creator>Cheung, Alvin</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Many parallel data frameworks have been proposed in recent years that let
sequential programs access parallel processing. To capitalize on the benefits
of such frameworks, existing code must often be rewritten to the
domain-specific languages that each framework supports. This rewriting-tedious
and error-prone-also requires developers to choose the framework that best
optimizes performance given a specific workload.
  This paper describes Casper, a novel compiler that automatically retargets
sequential Java code for execution on Hadoop, a parallel data processing
framework that implements the MapReduce paradigm. Given a sequential code
fragment, Casper uses verified lifting to infer a high-level summary expressed
in our program specification language that is then compiled for execution on
Hadoop. We demonstrate that Casper automatically translates Java benchmarks
into Hadoop. The translated results execute on average 3.3x faster than the
sequential implementations and scale better, as well, to larger datasets.
</dc:description>
 <dc:description>Comment: In Proceedings SYNT 2016, arXiv:1611.07178</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07623</dc:identifier>
 <dc:identifier>EPTCS 229, 2016, pp. 67-83</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.229.7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07624</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Developing a Practical Reactive Synthesis Tool: Experience and Lessons
  Learned</dc:title>
 <dc:creator>Ryzhyk, Leonid</dc:creator>
 <dc:creator>Walker, Adam</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We summarise our experience developing and using Termite, the first reactive
synthesis tool intended for use by software development practitioners. We
identify the main barriers to making reactive synthesis accessible to software
developers and describe the key features of Termite designed to overcome these
barriers, including an imperative C-like specification language, an interactive
source-level debugger, and a user-guided code generator. Based on our
experience applying Termite to synthesising real-world reactive software, we
identify several caveats of the practical use of the reactive synthesis
technology. We hope that these findings will help define the agenda for future
research on practical reactive synthesis.
</dc:description>
 <dc:description>Comment: In Proceedings SYNT 2016, arXiv:1611.07178</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07624</dc:identifier>
 <dc:identifier>EPTCS 229, 2016, pp. 84-99</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.229.8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07625</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Update on Deductive Synthesis and Repair in the Leon Tool</dc:title>
 <dc:creator>Koukoutos, Manos</dc:creator>
 <dc:creator>Kneuss, Etienne</dc:creator>
 <dc:creator>Kuncak, Viktor</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We report our progress in scaling deductive synthesis and repair of recursive
functional Scala programs in the Leon tool. We describe new techniques,
including a more precise mechanism for encoding the space of meaningful
candidate programs. Our techniques increase the scope of synthesis by expanding
the space of programs we can synthesize and by reducing the synthesis time in
many cases. As a new example, we present a run-length encoding function for a
list of values, which Leon can now automatically synthesize from specification
consisting of the decoding function and the local minimality property of the
encoded value.
</dc:description>
 <dc:description>Comment: In Proceedings SYNT 2016, arXiv:1611.07178</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07625</dc:identifier>
 <dc:identifier>EPTCS 229, 2016, pp. 100-111</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.229.9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07626</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Reactive Synthesis Competition: SYNTCOMP 2016 and Beyond</dc:title>
 <dc:creator>Jacobs, Swen</dc:creator>
 <dc:creator>Bloem, Roderick</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We report on the design of the third reactive synthesis competition (SYNTCOMP
2016), including a major extension of the competition to specifications in full
linear temporal logic. We give a brief overview of the synthesis problem as
considered in SYNTCOMP, and present the rules of the competition in 2016, as
well as the ideas behind our design choices. Furthermore, we evaluate the
recent changes to the competition based on the experiences with SYNTCOMP 2016.
Finally, we give an outlook on further changes and extensions of the
competition that are planned for the future.
</dc:description>
 <dc:description>Comment: In Proceedings SYNT 2016, arXiv:1611.07178</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07626</dc:identifier>
 <dc:identifier>EPTCS 229, 2016, pp. 133-148</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.229.11</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07627</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SyGuS-Comp 2016: Results and Analysis</dc:title>
 <dc:creator>Alur, Rajeev</dc:creator>
 <dc:creator>Fisman, Dana</dc:creator>
 <dc:creator>Singh, Rishabh</dc:creator>
 <dc:creator>Solar-Lezama, Armando</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:subject>D.1.2</dc:subject>
 <dc:subject>D.2.2</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  Syntax-Guided Synthesis (SyGuS) is the computational problem of finding an
implementation f that meets both a semantic constraint given by a logical
formula $\varphi$ in a background theory T, and a syntactic constraint given by
a grammar G, which specifies the allowed set of candidate implementations. Such
a synthesis problem can be formally defined in SyGuS-IF, a language that is
built on top of SMT-LIB.
  The Syntax-Guided Synthesis Competition (SyGuS-Comp) is an effort to
facilitate, bring together and accelerate research and development of efficient
solvers for SyGuS by providing a platform for evaluating different synthesis
techniques on a comprehensive set of benchmarks. In this year's competition we
added a new track devoted to programming by examples. This track consisted of
two categories, one using the theory of bit-vectors and one using the theory of
strings. This paper presents and analyses the results of SyGuS-Comp'16.
</dc:description>
 <dc:description>Comment: In Proceedings SYNT 2016, arXiv:1611.07178. arXiv admin note: text
  overlap with arXiv:1602.01170</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07627</dc:identifier>
 <dc:identifier>EPTCS 229, 2016, pp. 178-202</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.229.13</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07628</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nearly Optimal Bounds for Orthogonal Least Squares</dc:title>
 <dc:creator>Wen, Jinming</dc:creator>
 <dc:creator>Wang, Jian</dc:creator>
 <dc:creator>Zhang, Qinyu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study the orthogonal least squares (OLS) algorithm for
sparse recovery. On the one hand, we show that if the sampling matrix
$\mathbf{A}$ satisfies the restricted isometry property (RIP) of order $K + 1$
with isometry constant $$ \delta_{K + 1} &lt; \frac{1}{\sqrt{K+1}}, $$ then OLS
exactly recovers the support of any $K$-sparse vector $\mathbf{x}$ from its
samples $\mathbf{y} = \mathbf{A} \mathbf{x}$ in $K$ iterations. On the other
hand, we show that OLS may not be able to recover the support of a $K$-sparse
vector $\mathbf{x}$ in $K$ iterations for some $K$ if $$ \delta_{K + 1} \geq
\frac{1}{\sqrt{K+\frac{1}{4}}}. $$
</dc:description>
 <dc:description>Comment: To appear in IEEE Transactions on Signal Processing</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07628</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2728502</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07629</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approaching Symbolic Parallelization by Synthesis of Recurrence
  Decompositions</dc:title>
 <dc:creator>Fedyukovich, Grigory</dc:creator>
 <dc:creator>Bod&#xed;k, Rastislav</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We present GraSSP, a novel approach to perform automated parallelization
relying on recent advances in formal verification and synthesis. GraSSP
augments an existing sequential program with an additional functionality to
decompose data dependencies in loop iterations, to compute partial results, and
to compose them together. We show that for some classes of the sequential
prefix sum problems, such parallelization can be performed efficiently.
</dc:description>
 <dc:description>Comment: In Proceedings SYNT 2016, arXiv:1611.07178</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07629</dc:identifier>
 <dc:identifier>EPTCS 229, 2016, pp. 55-66</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.229.6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07630</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Degrees of Freedom of the Bursty MIMO X Channel without Feedback</dc:title>
 <dc:creator>Yeh, Shih-Yi</dc:creator>
 <dc:creator>Wang, I-Hsiang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the sum degrees of freedom (DoF) of the bursty MIMO X channel
without feedback, where the four transmitter-receiver links are intermittently
on-and-off, controlled by four Bernoulli random sequences which may be
arbitrarily correlated, subject to a symmetry assumption: The two direct-links
have the same level of burstiness, modeled by $\mathrm{Ber}(p_d)$, and so do
the cross-links, modeled by $\mathrm{Ber}(p_c)$. The sum DoF is fully
characterized in the regime where $\frac{p_c}{p_d}$ is small, i.e. below a
certain threshold, and is partially characterized in the other regime where
$\frac{p_c}{p_d}$ is above the threshold. The achievability is proved with a
combination of Han-Kobayashi strategy and interference alignment, which can
achieve strictly higher DoF than interference alignment alone. The converse
proof employs a channel-state-sequence pairing technique. We highlight that
burstiness of the channel disrupts the network topology, turning the MIMO X
channel into a network with time-varying topology. This fundamental difference
has striking ramifications. In particular, various interference alignment
schemes that achieve the DoF of non-bursty X channels are found to be
suboptimal when the channels become bursty. The reciprocity between the forward
and the reverse links is lost, and the sum DoF does not saturate when the ratio
of the transmitter and the receiver antennas exceeds $\frac{2}{3}$.
</dc:description>
 <dc:description>Comment: Minor revision: Enhanced the central message of the paper and
  clarified Section IV. Submitted to IEEE Transactions on Information Theory</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2018-01-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07630</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07633</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards the Secure Storage of Images on Multi-Cloud System</dc:title>
 <dc:creator>Jacob, Dr. Grasha</dc:creator>
 <dc:creator>Murugan, Dr. A.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  With the rapidly changing technological realm, there is an urgent need to
provide and protect the confidentiality of confidential images when stored in a
cloud environment. To overcome the security risks associated with single cloud,
multiple clouds offered by unrelated cloud providers have to be used. This
paper outlines an integrated encryption scheme for the secure storage of
confidential images on multiple clouds based on DNA sequences.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07633</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07634</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpretation of Prediction Models Using the Input Gradient</dc:title>
 <dc:creator>Hechtlinger, Yotam</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  State of the art machine learning algorithms are highly optimized to provide
the optimal prediction possible, naturally resulting in complex models. While
these models often outperform simpler more interpretable models by order of
magnitudes, in terms of understanding the way the model functions, we are often
facing a &quot;black box&quot;.
  In this paper we suggest a simple method to interpret the behavior of any
predictive model, both for regression and classification. Given a particular
model, the information required to interpret it can be obtained by studying the
partial derivatives of the model with respect to the input. We exemplify this
insight by interpreting convolutional and multi-layer neural networks in the
field of natural language processing.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07634</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07635</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>T-CONV: A Convolutional Neural Network For Multi-scale Taxi Trajectory
  Prediction</dc:title>
 <dc:creator>Lv, Jianming</dc:creator>
 <dc:creator>Li, Qing</dc:creator>
 <dc:creator>Wang, Xintong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  Precise destination prediction of taxi trajectories can benefit many
intelligent location based services such as accurate ad for passengers.
Traditional prediction approaches, which treat trajectories as one-dimensional
sequences and process them in single scale, fail to capture the diverse
two-dimensional patterns of trajectories in different spatial scales. In this
paper, we propose T-CONV which models trajectories as two-dimensional images,
and adopts multi-layer convolutional neural networks to combine multi-scale
trajectory patterns to achieve precise prediction. Furthermore, we conduct
gradient analysis to visualize the multi-scale spatial patterns captured by
T-CONV and extract the areas with distinct influence on the ultimate
prediction. Finally, we integrate multiple local enhancement convolutional
fields to explore these important areas deeply for better prediction.
Comprehensive experiments based on real trajectory data show that T-CONV can
achieve higher accuracy than the state-of-the-art methods.
</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07635</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07636</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mechanism Design for Multi-Type Housing Markets</dc:title>
 <dc:creator>Adali, Sibel</dc:creator>
 <dc:creator>Sikdar, Sujoy</dc:creator>
 <dc:creator>Xia, Lirong</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We study multi-type housing markets, where there are $p\ge 2$ types of items,
each agent is initially endowed one item of each type, and the goal is to
design mechanisms without monetary transfer to (re)allocate items to the agents
based on their preferences over bundles of items, such that each agent gets one
item of each type. In sharp contrast to classical housing markets, previous
studies in multi-type housing markets have been hindered by the lack of natural
solution concepts, because the strict core might be empty.
  We break the barrier in the literature by leveraging AI techniques and making
natural assumptions on agents' preferences. We show that when agents'
preferences are lexicographic, even with different importance orders, the
classical top-trading-cycles mechanism can be extended while preserving most of
its nice properties. We also investigate computational complexity of checking
whether an allocation is in the strict core and checking whether the strict
core is empty. Our results convey an encouragingly positive message: it is
possible to design good mechanisms for multi-type housing markets under natural
assumptions on preferences.
</dc:description>
 <dc:description>Comment: full version of the AAAI-17 paper</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07641</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Phase Retrieval via Truncated Amplitude Flow</dc:title>
 <dc:creator>Wang, Gang</dc:creator>
 <dc:creator>Zhang, Liang</dc:creator>
 <dc:creator>Giannakis, Georgios B.</dc:creator>
 <dc:creator>Akcakaya, Mehmet</dc:creator>
 <dc:creator>Chen, Jie</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper develops a novel algorithm, termed \emph{SPARse Truncated
Amplitude flow} (SPARTA), to reconstruct a sparse signal from a small number of
magnitude-only measurements. It deals with what is also known as sparse phase
retrieval (PR), which is \emph{NP-hard} in general and emerges in many science
and engineering applications. Upon formulating sparse PR as an amplitude-based
nonconvex optimization task, SPARTA works iteratively in two stages: In stage
one, the support of the underlying sparse signal is recovered using an
analytically well-justified rule, and subsequently, a sparse
orthogonality-promoting initialization is obtained via power iterations
restricted on the support; and, in the second stage, the initialization is
successively refined by means of hard thresholding based gradient-type
iterations. SPARTA is a simple yet effective, scalable, and fast sparse PR
solver. On the theoretical side, for any $n$-dimensional $k$-sparse ($k\ll n$)
signal $\bm{x}$ with minimum (in modulus) nonzero entries on the order of
$(1/\sqrt{k})\|\bm{x}\|_2$, SPARTA recovers the signal exactly (up to a global
unimodular constant) from about $k^2\log n$ random Gaussian measurements with
high probability. Furthermore, SPARTA incurs computational complexity on the
order of $k^2n\log n$ with total runtime proportional to the time required to
read the data, which improves upon the state-of-the-art by at least a factor of
$k$. Finally, SPARTA is robust against additive noise of bounded support.
Extensive numerical tests corroborate markedly improved recovery performance
and speedups of SPARTA relative to existing alternatives.
</dc:description>
 <dc:description>Comment: 23 pages; 5 figures</dc:description>
 <dc:date>2016-11-22</dc:date>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07649</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Control-flow based Intrusion Detection Technique for Big Data
  Systems</dc:title>
 <dc:creator>Aditham, Santosh</dc:creator>
 <dc:creator>Ranganathan, Nagarajan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Security and distributed infrastructure are two of the most common
requirements for big data software. But the security features of the big data
platforms are still premature. It is critical to identify, modify, test and
execute some of the existing security mechanisms before using them in the big
data world. In this paper, we propose a novel intrusion detection technique
that understands and works according to the needs of big data systems. Our
proposed technique identifies program level anomalies using two methods - a
profiling method that models application behavior by creating process
signatures from control-flow graphs; and a matching method that checks for
coherence among the replica nodes of a big data system by matching the process
signatures. The profiling method creates a process signature by reducing the
control-flow graph of a process to a set of minimum spanning trees and then
creates a hash of that set. The matching method first checks for similarity in
process behavior by matching the received process signature with the local
signature and then shares the result with all replica datanodes for consensus.
Experimental results show only 0.8% overhead due to the proposed technique when
tested on the hadoop map-reduce examples in real-time.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07649</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07650</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Design and Optimization of an Autonomous Microgravity Enabling
  Aerial Robot</dc:title>
 <dc:creator>Afman, Juan-Pablo</dc:creator>
 <dc:creator>Franklin, John</dc:creator>
 <dc:creator>Mote, Mark L.</dc:creator>
 <dc:creator>Gurriet, Thomas</dc:creator>
 <dc:creator>Feron, Eric</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper describes the process and challenges behind the design and
development of a micro-gravity enabling aerial robot. The vehicle, designed to
provide at minimum 4 seconds of micro-gravity at an accuracy of .001 g's, is
designed with suggestions and constraints from both academia and industry as
well a regulatory agency. The feasibility of the flight mission is validated
using a simulation environment, where models obtained from system
identification of existing hardware are implemented to increase the fidelity of
the simulation. The current development of a physical test bed is described.
The vehicle employs both control and autonomy logic, which is developed in the
Simulink environment and executed in a Pixhawk flight control board.
</dc:description>
 <dc:description>Comment: 8 Pages, 15 figures</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07650</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07651</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hadamard quantum broadcast channels</dc:title>
 <dc:creator>Wang, Qingle</dc:creator>
 <dc:creator>Das, Siddhartha</dc:creator>
 <dc:creator>Wilde, Mark M.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider three different communication tasks for quantum broadcast
channels, and we determine the capacity region of a Hadamard broadcast channel
for these various tasks. We define a Hadamard broadcast channel to be such that
the channel from the sender to one of the receivers is entanglement-breaking
and the channel from the sender to the other receiver is complementary to this
one. As such, this channel is a quantum generalization of a degraded broadcast
channel, which is well known in classical information theory. The first
communication task we consider is classical communication to both receivers,
the second is quantum communication to the stronger receiver and classical
communication to other, and the third is entanglement-assisted classical
communication to the stronger receiver and unassisted classical communication
to the other. The structure of a Hadamard broadcast channel plays a critical
role in our analysis: the channel to the weaker receiver can be simulated by
performing a measurement channel on the stronger receiver's system, followed by
a preparation channel. As such, we can incorporate the classical output of the
measurement channel as an auxiliary variable and solve all three of the above
capacities for Hadamard broadcast channels, in this way avoiding known
difficulties associated with quantum auxiliary variables.
</dc:description>
 <dc:description>Comment: v2: 20 pages, accepted for publication in Quantum Information
  Processing</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07651</dc:identifier>
 <dc:identifier>Quantum Information Processing, vol 16., no. 10, article no. 248,
  October 2017</dc:identifier>
 <dc:identifier>doi:10.1007/s11128-017-1697-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07658</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Network Formation Model Based on Subgraphs</dc:title>
 <dc:creator>Chandrasekhar, Arun</dc:creator>
 <dc:creator>Jackson, Matthew O.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We develop a new class of random-graph models for the statistical estimation
of network formation that allow for substantial correlation in links. Various
subgraphs (e.g., links, triangles, cliques, stars) are generated and their
union results in a network. We provide estimation techniques for recovering the
rates at which the underlying subgraphs were formed. We illustrate the models
via a series of applications including testing for incentives to form
cross-caste relationships in rural India, testing to see whether network
structure is used to enforce risk-sharing, testing as to whether networks
change in response to a community's exposure to microcredit, and show that
these models significantly outperform stochastic block models in matching
observed network characteristics. We also establish asymptotic properties of
the models and various estimators, which requires proving a new Central Limit
Theorem for correlated random variables.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07659</identifier>
 <datestamp>2017-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Efficiency of SVM k-fold Cross-validation by Alpha Seeding</dc:title>
 <dc:creator>Wen, Zeyi</dc:creator>
 <dc:creator>Li, Bin</dc:creator>
 <dc:creator>Kotagiri, Rao</dc:creator>
 <dc:creator>Chen, Jian</dc:creator>
 <dc:creator>Chen, Yawen</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The k-fold cross-validation is commonly used to evaluate the effectiveness of
SVMs with the selected hyper-parameters. It is known that the SVM k-fold
cross-validation is expensive, since it requires training k SVMs. However,
little work has explored reusing the h-th SVM for training the (h+1)-th SVM for
improving the efficiency of k-fold cross-validation. In this paper, we propose
three algorithms that reuse the h-th SVM for improving the efficiency of
training the (h+1)-th SVM. Our key idea is to efficiently identify the support
vectors and to accurately estimate their associated weights (also called alpha
values) of the next SVM by using the previous SVM. Our experimental results
show that our algorithms are several times faster than the k-fold
cross-validation which does not make use of the previously trained SVM.
Moreover, our algorithms produce the same results (hence same accuracy) as the
k-fold cross-validation which does not make use of the previously trained SVM.
</dc:description>
 <dc:description>Comment: 9 pages, 2 figures, accepted by AAAI-17</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07661</identifier>
 <datestamp>2017-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multigrid Neural Architectures</dc:title>
 <dc:creator>Ke, Tsung-Wei</dc:creator>
 <dc:creator>Maire, Michael</dc:creator>
 <dc:creator>Yu, Stella X.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We propose a multigrid extension of convolutional neural networks (CNNs).
Rather than manipulating representations living on a single spatial grid, our
network layers operate across scale space, on a pyramid of grids. They consume
multigrid inputs and produce multigrid outputs; convolutional filters
themselves have both within-scale and cross-scale extent. This aspect is
distinct from simple multiscale designs, which only process the input at
different scales. Viewed in terms of information flow, a multigrid network
passes messages across a spatial pyramid. As a consequence, receptive field
size grows exponentially with depth, facilitating rapid integration of context.
Most critically, multigrid structure enables networks to learn internal
attention and dynamic routing mechanisms, and use them to accomplish tasks on
which modern CNNs fail.
  Experiments demonstrate wide-ranging performance advantages of multigrid. On
CIFAR and ImageNet classification tasks, flipping from a single grid to
multigrid within the standard CNN paradigm improves accuracy, while being
compute and parameter efficient. Multigrid is independent of other
architectural choices; we show synergy in combination with residual
connections. Multigrid yields dramatic improvement on a synthetic semantic
segmentation dataset. Most strikingly, relatively shallow multigrid networks
can learn to directly perform spatial transformation tasks, where, in contrast,
current CNNs fail. Together, our results suggest that continuous evolution of
features on a multigrid pyramid is a more powerful alternative to existing CNN
designs on a flat grid.
</dc:description>
 <dc:description>Comment: updated with ImageNet results; to appear at CVPR 2017</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-05-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07675</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video Captioning with Transferred Semantic Attributes</dc:title>
 <dc:creator>Pan, Yingwei</dc:creator>
 <dc:creator>Yao, Ting</dc:creator>
 <dc:creator>Li, Houqiang</dc:creator>
 <dc:creator>Mei, Tao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatically generating natural language descriptions of videos plays a
fundamental challenge for computer vision community. Most recent progress in
this problem has been achieved through employing 2-D and/or 3-D Convolutional
Neural Networks (CNN) to encode video content and Recurrent Neural Networks
(RNN) to decode a sentence. In this paper, we present Long Short-Term Memory
with Transferred Semantic Attributes (LSTM-TSA)---a novel deep architecture
that incorporates the transferred semantic attributes learnt from images and
videos into the CNN plus RNN framework, by training them in an end-to-end
manner. The design of LSTM-TSA is highly inspired by the facts that 1) semantic
attributes play a significant contribution to captioning, and 2) images and
videos carry complementary semantics and thus can reinforce each other for
captioning. To boost video captioning, we propose a novel transfer unit to
model the mutually correlated attributes learnt from images and videos.
Extensive experiments are conducted on three public datasets, i.e., MSVD, M-VAD
and MPII-MD. Our proposed LSTM-TSA achieves to-date the best published
performance in sentence generation on MSVD: 52.8% and 74.0% in terms of BLEU@4
and CIDEr-D. Superior results when compared to state-of-the-art methods are
also reported on M-VAD and MPII-MD.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07682</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Special cases of the quadratic shortest path problem</dc:title>
 <dc:creator>Hu, Hao</dc:creator>
 <dc:creator>Sotirov, Renata</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The quadratic shortest path problem (QSPP) is \textcolor{black}{the problem
of finding a path with prespecified start vertex $s$ and end vertex $t$ in a
digraph} such that the sum of weights of arcs and the sum of interaction costs
over all pairs of arcs on the path is minimized. We first consider a variant of
the QSPP known as the adjacent QSPP. It was recently proven that the adjacent
QSPP on cyclic digraphs cannot be approximated unless P=NP. Here, we give a
simple proof for the same result.
  We also show that if the quadratic cost matrix is a symmetric weak sum matrix
\textcolor{black}{ and all $s$-$t$ paths have the same length,} then an optimal
solution for the QSPP can be obtained by solving the corresponding instance of
the shortest path problem. Similarly, it is shown that the QSPP with a
symmetric product cost matrix is solvable in polynomial time.
  Further, we provide sufficient and necessary conditions for a QSPP instance
on a complete symmetric digraph with four vertices to be linearizable. We also
characterize linearizable QSPP instances on complete symmetric digraphs with
more than four vertices. Finally, we derive an algorithm that examines whether
a QSPP instance on the directed grid graph $G_{pq}$ ($p,q\geq 2$) is
linearizable. The complexity of this algorithm is
${\mathcal{O}(p^{3}q^{2}+p^{2}q^{3})}$.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07688</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UniMiB SHAR: a new dataset for human activity recognition using
  acceleration data from smartphones</dc:title>
 <dc:creator>Micucci, Daniela</dc:creator>
 <dc:creator>Mobilio, Marco</dc:creator>
 <dc:creator>Napoletano, Paolo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Smartphones, smartwatches, fitness trackers, and ad-hoc wearable devices are
being increasingly used to monitor human activities. Data acquired by the
hosted sensors are usually processed by machine-learning-based algorithms to
classify human activities. The success of those algorithms mostly depends on
the availability of training (labeled) data that, if made publicly available,
would allow researchers to make objective comparisons between techniques.
Nowadays, publicly available data sets are few, often contain samples from
subjects with too similar characteristics, and very often lack of specific
information so that is not possible to select subsets of samples according to
specific criteria. In this article, we present a new dataset of acceleration
samples acquired with an Android smartphone designed for human activity
recognition and fall detection. The dataset includes 11,771 samples of both
human activities and falls performed by 30 subjects of ages ranging from 18 to
60 years. Samples are divided in 17 fine grained classes grouped in two coarse
grained classes: one containing samples of 9 types of activities of daily
living (ADL) and the other containing samples of 8 types of falls. The dataset
has been stored to include all the information useful to select samples
according to different criteria, such as the type of ADL, the age, the gender,
and so on. Finally, the dataset has been benchmarked with four different
classifiers and with two different feature vectors. We evaluated four different
classification tasks: fall vs no fall, 9 activities, 8 falls, 17 activities and
falls. For each classification task we performed a subject-dependent and
independent evaluation. The major findings of the evaluation are the following:
i) it is more difficult to distinguish between types of falls than types of
activities; ii) subject-dependent evaluation outperforms the
subject-independent one
</dc:description>
 <dc:description>Comment: submitted to MDPI Sensors</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07688</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07700</identifier>
 <datestamp>2017-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Menagerie: Modeling the 3D shape and pose of animals</dc:title>
 <dc:creator>Zuffi, Silvia</dc:creator>
 <dc:creator>Kanazawa, Angjoo</dc:creator>
 <dc:creator>Jacobs, David</dc:creator>
 <dc:creator>Black, Michael J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  There has been significant work on learning realistic, articulated, 3D models
of the human body. In contrast, there are few such models of animals, despite
many applications. The main challenge is that animals are much less cooperative
than humans. The best human body models are learned from thousands of 3D scans
of people in specific poses, which is infeasible with live animals.
Consequently, we learn our model from a small set of 3D scans of toy figurines
in arbitrary poses. We employ a novel part-based shape model to compute an
initial registration to the scans. We then normalize their pose, learn a
statistical shape model, and refine the registrations and the model together.
In this way, we accurately align animal scans from different quadruped families
with very different shapes and poses. With the registration to a common
template we learn a shape space representing animals including lions, cats,
dogs, horses, cows and hippos. Animal shapes can be sampled from the model,
posed, animated, and fit to data. We demonstrate generalization by fitting it
to images of real animals including species not seen in training.
</dc:description>
 <dc:description>Comment: Accepted at CVPR 2017 (camera ready version)</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07700</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07701</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simultaneous Feedback Edge Set: A Parameterized Perspective</dc:title>
 <dc:creator>Agrawal, Akanksha</dc:creator>
 <dc:creator>Panolan, Fahad</dc:creator>
 <dc:creator>Saurabh, Saket</dc:creator>
 <dc:creator>Zehavi, Meirav</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper we consider Simultaneous Feedback Edge Set (Sim-FES) problem.
In this problem, the input is an $n$-vertex graph $G$, an integer $k$ and a
coloring function ${\sf col}: E(G) \rightarrow 2^{[\alpha]}$ and the objective
is to check whether there is an edge subset $S$ of cardinality at most $k$ in
$G$ such that for all $i \in [\alpha]$, $G_i - S$ is acyclic. Here, $G_i=(V(G),
\{e\in E(G) \mid i \in {\sf col}(e)\})$ and $[\alpha]=\{1,\ldots,\alpha\}$.
When $\alpha =1$, the problem is polynomial time solvable. We show that for
$\alpha =3$ Sim-FES is NP-hard by giving a reduction from Vertex Cover on cubic
graphs. The same reduction shows that the problem does not admit an algorithm
of running time $O(2^{o(k)}n^{O(1)})$ unless ETH fails. This hardness result is
complimented by an FPT algorithm for Sim-FES running in time $O(2^{\omega
k\alpha+\alpha \log k} n^{O(1)})$, where $\omega$ is the exponent in the
running time of matrix multiplication. The same algorithm gives a polynomial
time algorithm for the case when $\alpha =2$. We also give a kernel for Sim-FES
with $(k\alpha)^{O(\alpha)}$ vertices. Finally, we consider the problem Maximum
Simultaneous Acyclic Subgraph. Here, the input is a graph $G$, an integer $q$
and, a coloring function ${\sf col}: E(G) \rightarrow 2^{[\alpha]}$. The
question is whether there is a edge subset $F$ of cardinality at least $q$ in
$G$ such that for all $i\in [\alpha]$, $G[F_i]$ is acyclic. Here, $F_i=\{e \in
F \mid i \in \textsf{col}(e)\}$. We give an FPT algorithm for running in time
$O(2^{\omega q \alpha}n^{O(1)})$.
</dc:description>
 <dc:description>Comment: A preliminary version of this paper will appear in the proceedings of
  ISAAC 2016</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07702</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Timing Attack Resilient Decoding Algorithms for Physical Unclonable
  Functions</dc:title>
 <dc:creator>Puchinger, Sven</dc:creator>
 <dc:creator>M&#xfc;elich, Sven</dc:creator>
 <dc:creator>Wachter-Zeh, Antonia</dc:creator>
 <dc:creator>Bossert, Martin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper deals with the application of list decoding of Reed--Solomon codes
to a concatenated code for key reproduction using Physical Unclonable
Functions. The resulting codes achieve a higher error-correction performance at
the same code rate than known schemes in this scenario. We also show that their
decoding algorithms can be protected from side-channel attacks on the runtime
both by masking techniques and by directly modifying the algorithms to have
constant runtime.
</dc:description>
 <dc:description>Comment: 6 pages, accepted for publication at the 11th International ITG
  Conference on Systems, Communications and Coding (SCC 2017)</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07703</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>'Part'ly first among equals: Semantic part-based benchmarking for
  state-of-the-art object recognition systems</dc:title>
 <dc:creator>Sarvadevabhatla, Ravi Kiran</dc:creator>
 <dc:creator>Venkatraman, Shanthakumar</dc:creator>
 <dc:creator>Babu, R. Venkatesh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  An examination of object recognition challenge leaderboards (ILSVRC,
PASCAL-VOC) reveals that the top-performing classifiers typically exhibit small
differences amongst themselves in terms of error rate/mAP. To better
differentiate the top performers, additional criteria are required. Moreover,
the (test) images, on which the performance scores are based, predominantly
contain fully visible objects. Therefore, `harder' test images, mimicking the
challenging conditions (e.g. occlusion) in which humans routinely recognize
objects, need to be utilized for benchmarking. To address the concerns
mentioned above, we make two contributions. First, we systematically vary the
level of local object-part content, global detail and spatial context in images
from PASCAL VOC 2010 to create a new benchmarking dataset dubbed PPSS-12.
Second, we propose an object-part based benchmarking procedure which quantifies
classifiers' robustness to a range of visibility and contextual settings. The
benchmarking procedure relies on a semantic similarity measure that naturally
addresses potential semantic granularity differences between the category
labels in training and test datasets, thus eliminating manual mapping. We use
our procedure on the PPSS-12 dataset to benchmark top-performing classifiers
trained on the ILSVRC-2012 dataset. Our results show that the proposed
benchmarking procedure enables additional differentiation among
state-of-the-art object classifiers in terms of their ability to handle missing
content and insufficient object detail. Given this capability for additional
differentiation, our approach can potentially supplement existing benchmarking
procedures used in object recognition challenge leaderboards.
</dc:description>
 <dc:description>Comment: Extended version of our ACCV-2016 paper. Author formatting modified</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07709</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully Convolutional Instance-aware Semantic Segmentation</dc:title>
 <dc:creator>Li, Yi</dc:creator>
 <dc:creator>Qi, Haozhi</dc:creator>
 <dc:creator>Dai, Jifeng</dc:creator>
 <dc:creator>Ji, Xiangyang</dc:creator>
 <dc:creator>Wei, Yichen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present the first fully convolutional end-to-end solution for
instance-aware semantic segmentation task. It inherits all the merits of FCNs
for semantic segmentation and instance mask proposal. It performs instance mask
prediction and classification jointly. The underlying convolutional
representation is fully shared between the two sub-tasks, as well as between
all regions of interest. The proposed network is highly integrated and achieves
state-of-the-art performance in both accuracy and efficiency. It wins the COCO
2016 segmentation competition by a large margin. Code would be released at
\url{https://github.com/daijifeng001/TA-FCN}.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07710</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatio-Temporal Modeling of Users' Check-ins in Location-Based Social
  Networks</dc:title>
 <dc:creator>Zarezade, Ali</dc:creator>
 <dc:creator>Jafarzadeh, Sina</dc:creator>
 <dc:creator>Rabiee, Hamid R.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Social networks are getting closer to our real physical world. People share
the exact location and time of their check-ins and are influenced by their
friends. Modeling the spatio-temporal behavior of users in social networks is
of great importance for predicting the future behavior of users, controlling
the users' movements, and finding the latent influence network. It is observed
that users have periodic patterns in their movements. Also, they are influenced
by the locations that their close friends recently visited. Leveraging these
two observations, we propose a probabilistic model based on a doubly stochastic
point process with a periodic decaying kernel for the time of check-ins and a
time-varying multinomial distribution for the location of check-ins of users in
the location-based social networks. We learn the model parameters using an
efficient EM algorithm, which distributes over the users. Experiments on
synthetic and real data gathered from Foursquare show that the proposed
inference algorithm learns the parameters efficiently and our model outperforms
the other alternatives in the prediction of time and location of check-ins.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07715</identifier>
 <datestamp>2017-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Feature Flow for Video Recognition</dc:title>
 <dc:creator>Zhu, Xizhou</dc:creator>
 <dc:creator>Xiong, Yuwen</dc:creator>
 <dc:creator>Dai, Jifeng</dc:creator>
 <dc:creator>Yuan, Lu</dc:creator>
 <dc:creator>Wei, Yichen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep convolutional neutral networks have achieved great success on image
recognition tasks. Yet, it is non-trivial to transfer the state-of-the-art
image recognition networks to videos as per-frame evaluation is too slow and
unaffordable. We present deep feature flow, a fast and accurate framework for
video recognition. It runs the expensive convolutional sub-network only on
sparse key frames and propagates their deep feature maps to other frames via a
flow field. It achieves significant speedup as flow computation is relatively
fast. The end-to-end training of the whole architecture significantly boosts
the recognition accuracy. Deep feature flow is flexible and general. It is
validated on two recent large scale video datasets. It makes a large step
towards practical video recognition.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07715</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07716</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the locality of arb-invariant first-order formulas with modulo
  counting quantifiers</dc:title>
 <dc:creator>Harwath, Frederik</dc:creator>
 <dc:creator>Schweikardt, Nicole</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>H.2.3</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:description>  We study Gaifman locality and Hanf locality of an extension of first-order
logic with modulo p counting quantifiers (FO+MOD_p, for short) with arbitrary
numerical predicates. We require that the validity of formulas is independent
of the particular interpretation of the numerical predicates and refer to such
formulas as arb-invariant formulas. This paper gives a detailed picture of
locality and non-locality properties of arb-invariant FO+MOD_p. For example, on
the class of all finite structures, for any p &gt;= 2, arb-invariant FO+MOD_p is
neither Hanf nor Gaifman local with respect to a sublinear locality radius.
However, in case that p is an odd prime power, it is weakly Gaifman local with
a polylogarithmic locality radius. And when restricting attention to the class
of string structures, for odd prime powers p, arb-invariant FO+MOD_p is both
Hanf and Gaifman local with a polylogarithmic locality radius. Our negative
results build on examples of order-invariant FO+MOD_p formulas presented in
Niemist\&quot;o's PhD thesis. Our positive results make use of the close connection
between FO+MOD_p and Boolean circuits built from NOT-gates and AND-, OR-, and
MOD_p- gates of arbitrary fan-in.
</dc:description>
 <dc:description>Comment: This is the full version of the conference contribution &quot;On the
  locality of arb-invariant first-order logic with modulo counting
  quantifiers&quot;, CSL 2013</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2016-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07716</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 12, Issue 4 (December
  28, 2016) lmcs:2620</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07718</identifier>
 <datestamp>2017-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Convolutional Neural Networks with Merge-and-Run Mappings</dc:title>
 <dc:creator>Zhao, Liming</dc:creator>
 <dc:creator>Wang, Jingdong</dc:creator>
 <dc:creator>Li, Xi</dc:creator>
 <dc:creator>Tu, Zhuowen</dc:creator>
 <dc:creator>Zeng, Wenjun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A deep residual network, built by stacking a sequence of residual blocks, is
easy to train, because identity mappings skip residual branches and thus
improve information flow. To further reduce the training difficulty, we present
a simple network architecture, deep merge-and-run neural networks. The novelty
lies in a modularized building block, merge-and-run block, which assembles
residual branches in parallel through a merge-and-run mapping: Average the
inputs of these residual branches (Merge), and add the average to the output of
each residual branch as the input of the subsequent residual branch (Run),
respectively. We show that the merge-and-run mapping is a linear idempotent
function in which the transformation matrix is idempotent, and thus improves
information flow, making training easy. In comparison to residual networks, our
networks enjoy compelling advantages: they contain much shorter paths, and the
width, i.e., the number of channels, is increased. We evaluate the performance
on the standard recognition tasks. Our approach demonstrates consistent
improvements over ResNets with the comparable setup, and achieves competitive
results (e.g., $3.57\%$ testing error on CIFAR-$10$, $19.00\%$ on CIFAR-$100$,
$1.51\%$ on SVHN).
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07722</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Privacy-preserving Schemes for Smart Grid Communications</dc:title>
 <dc:creator>Ferrag, Mohamed Amine</dc:creator>
 <dc:creator>Maglaras, Leandros A.</dc:creator>
 <dc:creator>Janicke, Helge</dc:creator>
 <dc:creator>Jiang, Jianmin</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper, we present a comprehensive survey of privacy-preserving
schemes for Smart Grid communications. Specifically, we select and in-detail
examine thirty privacy preserving schemes developed for or applied in the
context of Smart Grids. Based on the communication and system models, we
classify these schemes that are published between 2013 and 2016, in five
categories, including, 1) Smart grid with the advanced metering infrastructure,
2) Data aggregation communications, 3) Smart grid marketing architecture, 4)
Smart community of home gateways, and 5) Vehicle-to grid architecture. For each
scheme, we survey the attacks of leaking privacy, countermeasures, and game
theoretic approaches. In addition, we review the survey articles published in
the recent years that deal with Smart Grids communications, applications,
standardization, and security. Based on the current survey, several
recommendations for further research are discussed at the end of this paper.
</dc:description>
 <dc:description>Comment: 30 pages, 13 figures, 15 tables</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07722</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07724</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knapsack Problems: A Parameterized Point of View</dc:title>
 <dc:creator>Albrecht, Carolin</dc:creator>
 <dc:creator>Gurski, Frank</dc:creator>
 <dc:creator>Rethmann, Jochen</dc:creator>
 <dc:creator>Yilmaz, Eda</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The knapsack problem (KP) is a very famous NP-hard problem in combinatorial
optimization. Also its generalization to multiple dimensions named
d-dimensional knapsack problem (d-KP) and to multiple knapsacks named multiple
knapsack problem (MKP) are well known problems. Since KP, d-KP, and MKP are
integer-valued problems defined on inputs of various informations, we study the
fixed-parameter tractability of these problems. The idea behind fixed-parameter
tractability is to split the complexity into two parts - one part that depends
purely on the size of the input, and one part that depends on some parameter of
the problem that tends to be small in practice. Further we consider the closely
related question, whether the sizes and the values can be reduced, such that
their bit-length is bounded polynomially or even constantly in a given
parameter, i.e. the existence of kernelizations is studied. We discuss the
following parameters: the number of items, the threshold value for the profit,
the sizes, the profits, the number d of dimensions, and the number m of
knapsacks. We also consider the connection of parameterized knapsack problems
to linear programming, approximation, and pseudo-polynomial algorithms.
</dc:description>
 <dc:description>Comment: 27 pages, 1 figure</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07725</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>iCaRL: Incremental Classifier and Representation Learning</dc:title>
 <dc:creator>Rebuffi, Sylvestre-Alvise</dc:creator>
 <dc:creator>Kolesnikov, Alexander</dc:creator>
 <dc:creator>Sperl, Georg</dc:creator>
 <dc:creator>Lampert, Christoph H.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A major open problem on the road to artificial intelligence is the
development of incrementally learning systems that learn about more and more
concepts over time from a stream of data. In this work, we introduce a new
training strategy, iCaRL, that allows learning in such a class-incremental way:
only the training data for a small number of classes has to be present at the
same time and new classes can be added progressively. iCaRL learns strong
classifiers and a data representation simultaneously. This distinguishes it
from earlier works that were fundamentally limited to fixed data
representations and therefore incompatible with deep learning architectures. We
show by experiments on CIFAR-100 and ImageNet ILSVRC 2012 data that iCaRL can
learn many classes incrementally over a long period of time where other
strategies quickly fail.
</dc:description>
 <dc:description>Comment: Accepted paper at CVPR 2017</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07726</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polynomial invariants by linear algebra</dc:title>
 <dc:creator>de Oliveira, Steven</dc:creator>
 <dc:creator>Bensalem, Saddek</dc:creator>
 <dc:creator>Prevosto, Virgile</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We present in this paper a new technique for generating polynomial
invariants, divided in two independent parts : a procedure that reduces
polynomial assignments composed loops analysis to linear loops under certain
hypotheses and a procedure for generating inductive invariants for linear
loops. Both of these techniques have a polynomial complexity for a bounded
number of variables and we guarantee the completeness of the technique for a
bounded degree which we successfully implemented for C programs verification.
</dc:description>
 <dc:description>Comment: 15 pages + 6 appendix</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07726</dc:identifier>
 <dc:identifier>Automated Technology for Verification and Analysis 2016 Volume
  9938 of the series Lecture Notes in Computer Science pp 479-494</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07727</identifier>
 <datestamp>2017-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PoseTrack: Joint Multi-Person Pose Estimation and Tracking</dc:title>
 <dc:creator>Iqbal, Umar</dc:creator>
 <dc:creator>Milan, Anton</dc:creator>
 <dc:creator>Gall, Juergen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we introduce the challenging problem of joint multi-person pose
estimation and tracking of an unknown number of persons in unconstrained
videos. Existing methods for multi-person pose estimation in images cannot be
applied directly to this problem, since it also requires to solve the problem
of person association over time in addition to the pose estimation for each
person. We therefore propose a novel method that jointly models multi-person
pose estimation and tracking in a single formulation. To this end, we represent
body joint detections in a video by a spatio-temporal graph and solve an
integer linear program to partition the graph into sub-graphs that correspond
to plausible body pose trajectories for each person. The proposed approach
implicitly handles occlusion and truncation of persons. Since the problem has
not been addressed quantitatively in the literature, we introduce a challenging
&quot;Multi-Person PoseTrack&quot; dataset, and also propose a completely unconstrained
evaluation protocol that does not make any assumptions about the scale, size,
location or the number of persons. Finally, we evaluate the proposed approach
and several baseline methods on our new dataset.
</dc:description>
 <dc:description>Comment: Accepted to CVPR 2017</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07727</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07738</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MESL: Proposal for a Non-volatile Cascadable Magneto-Electric Spin Logic</dc:title>
 <dc:creator>Jaiswal, Akhilesh</dc:creator>
 <dc:creator>Roy, Kaushik</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  In the quest for novel, scalable and energy-efficient computing technologies,
many non-charge based logic devices are being explored. Recent advances in
multi-ferroic materials have paved the way for electric field induced low
energy and fast switching of nano-magnets using the magneto-electric (ME)
effect. In this paper, we propose a voltage driven logic-device based on the ME
induced switching of nano-magnets. We further demonstrate that the proposed
logic-device, which exhibits decoupled read and write paths, can be used to
construct a complete logic family including XNOR, NAND and NOR gates. The
proposed logic family shows good scalability with a quadratic dependence of
switching energy with respect to the switching voltage. Further, the proposed
logic-device has better robustness against the effect of thermal noise as
compared to the conventional current driven switching of nano-magnets. A
device-to-circuit level coupled simulation framework, including magnetization
dynamics and electron transport model, has been developed for analyzing the
present proposal. Using our simulation framework, we present energy and delay
results for the proposed Magneto-Electric Spin Logic (MESL) gates.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07738</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07743</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tunable Sensitivity to Large Errors in Neural Network Training</dc:title>
 <dc:creator>Keren, Gil</dc:creator>
 <dc:creator>Sabato, Sivan</dc:creator>
 <dc:creator>Schuller, Bj&#xf6;rn</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  When humans learn a new concept, they might ignore examples that they cannot
make sense of at first, and only later focus on such examples, when they are
more useful for learning. We propose incorporating this idea of tunable
sensitivity for hard examples in neural network learning, using a new
generalization of the cross-entropy gradient step, which can be used in place
of the gradient in any gradient-based training method. The generalized gradient
is parameterized by a value that controls the sensitivity of the training
process to harder training examples. We tested our method on several benchmark
datasets. We propose, and corroborate in our experiments, that the optimal
level of sensitivity to hard example is positively correlated with the depth of
the network. Moreover, the test prediction error obtained by our method is
generally lower than that of the vanilla cross-entropy gradient learner. We
therefore conclude that tunable sensitivity can be helpful for neural network
learning.
</dc:description>
 <dc:description>Comment: The paper is accepted to the AAAI 2017 conference</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07743</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07745</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Timing Matters: Online Dynamics in Broadcast Games</dc:title>
 <dc:creator>Chawla, Shuchi</dc:creator>
 <dc:creator>Joseph</dc:creator>
 <dc:creator>Naor</dc:creator>
 <dc:creator>Panigrahi, Debmalya</dc:creator>
 <dc:creator>Singh, Mohit</dc:creator>
 <dc:creator>Umboh, Seeun William</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A central question in algorithmic game theory is to measure the inefficiency
(ratio of costs) of Nash equilibria (NE) with respect to socially optimal
solutions. The two established metrics used for this purpose are price of
anarchy (POA) and price of stability (POS), which respectively provide upper
and lower bounds on this ratio. A deficiency of these metrics, however, is that
they are purely existential and shed no light on which of the equilibrium
states are reachable in an actual game, i.e., via natural game dynamics. This
is particularly striking if these metrics differ significantly, such as in
network design games where the exponential gap between the best and worst NE
states originally prompted the notion of POS in game theory (Anshelevich et
al., FOCS 2002). In this paper, we make progress toward bridging this gap by
studying network design games under natural game dynamics.
  First we show that in a completely decentralized setting, where agents
arrive, depart, and make improving moves in an arbitrary order, the
inefficiency of NE attained can be polynomially large. This implies that the
game designer must have some control over the interleaving of these events in
order to force the game to attain efficient NE. We complement our negative
result by showing that if the game designer is allowed to execute a sequence of
improving moves to create an equilibrium state after every batch of agent
arrivals or departures, then the resulting equilibrium states attained by the
game are exponentially more efficient, i.e., the ratio of costs compared to the
optimum is only logarithmic. Overall, our two results establish that in network
games, the efficiency of equilibrium states is dictated by whether agents are
allowed to join or leave the game in arbitrary states, an observation that
might be useful in analyzing the dynamics of other classes of games with
divergent POS and POA bounds.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07745</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07752</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence Analysis of MAP based Blur Kernel Estimation</dc:title>
 <dc:creator>Cho, Sunghyun</dc:creator>
 <dc:creator>Lee, Seungyong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  One popular approach for blind deconvolution is to formulate a maximum a
posteriori (MAP) problem with sparsity priors on the gradients of the latent
image, and then alternatingly estimate the blur kernel and the latent image.
While several successful MAP based methods have been proposed, there has been
much controversy and confusion about their convergence, because sparsity priors
have been shown to prefer blurry images to sharp natural images. In this paper,
we revisit this problem and provide an analysis on the convergence of MAP based
approaches. We first introduce a slight modification to a conventional joint
energy function for blind deconvolution. The reformulated energy function
yields the same alternating estimation process, but more clearly reveals how
blind deconvolution works. We then show the energy function can actually favor
the right solution instead of the no-blur solution under certain conditions,
which explains the success of previous MAP based approaches. The reformulated
energy function and our conditions for the convergence also provide a way to
compare the qualities of different blur kernels, and we demonstrate its
applicability to automatic blur kernel size selection, blur kernel estimation
using light streaks, and defocus estimation.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07752</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07753</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthesizing invariants by solving solvable loops</dc:title>
 <dc:creator>de Oliveira, Steven</dc:creator>
 <dc:creator>Bensalem, Saddek</dc:creator>
 <dc:creator>Prevosto, Virgile</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  When proving invariance properties of a program, we face two problems. The
first problem is related to the necessity of proving tautologies of considered
assertion language, whereas the second manifests in the need of finding
sufficiently strong invariants. This paper focuses on the second problem and
describes a new method for the automatic generation of loop invariants that
handles polynomial and non deterministic assignments. This technique is based
on the eigenvector generation for a given linear transformation and on the
polynomial optimization problem, which we implemented in the open-source tool
Pilat.
</dc:description>
 <dc:description>Comment: 15 pages + 3 appendix</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07753</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07759</identifier>
 <datestamp>2017-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-View 3D Object Detection Network for Autonomous Driving</dc:title>
 <dc:creator>Chen, Xiaozhi</dc:creator>
 <dc:creator>Ma, Huimin</dc:creator>
 <dc:creator>Wan, Ji</dc:creator>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Xia, Tian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper aims at high-accuracy 3D object detection in autonomous driving
scenario. We propose Multi-View 3D networks (MV3D), a sensory-fusion framework
that takes both LIDAR point cloud and RGB images as input and predicts oriented
3D bounding boxes. We encode the sparse 3D point cloud with a compact
multi-view representation. The network is composed of two subnetworks: one for
3D object proposal generation and another for multi-view feature fusion. The
proposal network generates 3D candidate boxes efficiently from the bird's eye
view representation of 3D point cloud. We design a deep fusion scheme to
combine region-wise features from multiple views and enable interactions
between intermediate layers of different paths. Experiments on the challenging
KITTI benchmark show that our approach outperforms the state-of-the-art by
around 25% and 30% AP on the tasks of 3D localization and 3D detection. In
addition, for 2D detection, our approach obtains 10.3% higher AP than the
state-of-the-art on the hard data among the LIDAR-based methods.
</dc:description>
 <dc:description>Comment: To appear in IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR) 2017</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07759</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07767</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiframe Motion Coupling for Video Super Resolution</dc:title>
 <dc:creator>Geiping, Jonas</dc:creator>
 <dc:creator>Dirks, Hendrik</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:creator>Moeller, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>I.4</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:description>  The idea of video super resolution is to use different view points of a
single scene to enhance the overall resolution and quality. Classical energy
minimization approaches first establish a correspondence of the current frame
to all its neighbors in some radius and then use this temporal information for
enhancement. In this paper, we propose the first variational super resolution
approach that computes several super resolved frames in one batch optimization
procedure by incorporating motion information between the high-resolution image
frames themselves. As a consequence, the number of motion estimation problems
grows linearly in the number of frames, opposed to a quadratic growth of
classical methods and temporal consistency is enforced naturally. We use
infimal convolution regularization as well as an automatic parameter balancing
scheme to automatically determine the reliability of the motion information and
reweight the regularization locally. We demonstrate that our approach yields
state-of-the-art results and even is competitive with machine learning
approaches.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07767</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07769</identifier>
 <datestamp>2017-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The many facets of community detection in complex networks</dc:title>
 <dc:creator>Schaub, Michael T.</dc:creator>
 <dc:creator>Delvenne, Jean-Charles</dc:creator>
 <dc:creator>Rosvall, Martin</dc:creator>
 <dc:creator>Lambiotte, Renaud</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Community detection, the decomposition of a graph into essential building
blocks, has been a core research topic in network science over the past years.
Since a precise notion of what constitutes a community has remained evasive,
community detection algorithms have often been compared on benchmark graphs
with a particular form of assortative community structure and classified based
on the mathematical techniques they employ. However, this comparison can be
misleading because apparent similarities in their mathematical machinery can
disguise different goals and reasons for why we want to employ community
detection in the first place. Here we provide a focused review of these
different motivations that underpin community detection. This problem-driven
classification is useful in applied network science, where it is important to
select an appropriate algorithm for the given purpose. Moreover, highlighting
the different facets of community detection also delineates the many lines of
research and points out open directions and avenues for future research.
</dc:description>
 <dc:description>Comment: 8 Pages, 1 Figure</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-02-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07769</dc:identifier>
 <dc:identifier>Schaub, M.T., Delvenne, JC., Rosvall, M. et al. Appl Netw Sci
  (2017) 2: 4</dc:identifier>
 <dc:identifier>doi:10.1007/s41109-017-0023-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07781</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Down-Sampling and Dimension Reduction in Time Elastic Kernel
  Machines for Efficient Recognition of Isolated Gestures</dc:title>
 <dc:creator>Marteau, Pierre-Fran&#xe7;ois</dc:creator>
 <dc:creator>Gibet, Sylvie</dc:creator>
 <dc:creator>Reverdy, Cl&#xe9;ment</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In the scope of gestural action recognition, the size of the feature vector
representing movements is in general quite large especially when full body
movements are considered. Furthermore, this feature vector evolves during the
movement performance so that a complete movement is fully represented by a
matrix M of size DxT , whose element M i, j represents the value of feature i
at timestamps j. Many studies have addressed dimensionality reduction
considering only the size of the feature vector lying in R D to reduce both the
variability of gestural sequences expressed in the reduced space, and the
computational complexity of their processing. In return, very few of these
methods have explicitly addressed the dimensionality reduction along the time
axis. Yet this is a major issue when considering the use of elastic distances
which are characterized by a quadratic complexity along the time axis. We
present in this paper an evaluation of straightforward approaches aiming at
reducing the dimensionality of the matrix M for each movement, leading to
consider both the dimensionality reduction of the feature vector as well as its
reduction along the time axis. The dimensionality reduction of the feature
vector is achieved by selecting remarkable joints in the skeleton performing
the movement, basically the extremities of the articulatory chains composing
the skeleton. The temporal dimen-sionality reduction is achieved using either a
regular or adaptive down-sampling that seeks to minimize the reconstruction
error of the movements. Elastic and Euclidean kernels are then compared through
support vector machine learning. Two data sets 1 that are widely referenced in
the domain of human gesture recognition, and quite distinctive in terms of
quality of motion capture, are used for the experimental assessment of the
proposed approaches. On these data sets we experimentally show that it is
feasible, and possibly desirable, to significantly reduce simultaneously the
size of the feature vector and the number of skeleton frames to represent body
movements while maintaining a very good recognition rate. The method proves to
give satisfactory results at a level currently reached by state-of-the-art
methods on these data sets. We experimentally show that the computational
complexity reduction that is obtained makes this approach eligible for
real-time applications.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07781</dc:identifier>
 <dc:identifier>Guillet, Fabrice and Pinaud, Bruno and Venturini, Gilles. Advances
  in Knowledge Discovery and Management: volume 6, Volume (665), Springer
  International Publishing, pp.39 - 59, 2016, Studies in Computational
  Intelligence, 978-3-319-45763-5</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-45763-5_3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07782</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What is LTE actually used for? An answer through multi-operator,
  crowd-sourced measurement</dc:title>
 <dc:creator>Malandrino, Francesco</dc:creator>
 <dc:creator>Kirkpatrick, Scott</dc:creator>
 <dc:creator>Bickson, Danny</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  LTE networks are commonplace nowadays; however, comparatively little is known
about where (and why) they are deployed, and the demand they serve. We shed
some light on these issues through large-scale, crowd-sourced measurement. Our
data, collected by users of the WeFi app, spans multiple operators and multiple
cities, allowing us to observe a wide variety of deployment patterns.
Surprisingly, we find that LTE is frequently used to improve the {\em coverage}
of network rather than the capacity thereof, and that no evidence shows that
video traffic be a primary driver for its deployment. Our insights suggest that
such factors as pre-existing networks and commercial policies have a deeper
impact on deployment decisions than purely technical considerations.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07782</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07786</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Faster Algorithm for Cuckoo Insertion and Bipartite Matching in Large
  Graphs</dc:title>
 <dc:creator>Khosla, Megha</dc:creator>
 <dc:creator>Anand, Avishek</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Hash tables are ubiquitous in computer science for efficient access to large
datasets. However, there is always a need for approaches that offer compact
memory utilisation without substantial degradation of lookup performance.
Cuckoo hashing is an efficient technique of creating hash tables with high
space utilisation and offer a guaranteed constant access time. We are given $n$
locations and $m$ items. Each item has to be placed in one of the $k\ge2$
locations chosen by $k$ random hash functions. By allowing more than one choice
for a single item, cuckoo hashing resembles multiple choice allocations
schemes. In addition it supports dynamically changing the location of an item
among its possible locations. We propose and analyse an insertion algorithm for
cuckoo hashing that runs in \emph{linear time} with high probability and in
expectation. Previous work on total allocation time has analysed breadth first
search, and it was shown to be linear only in \emph{expectation}. Our algorithm
finds an assignment (with probability 1) whenever it exists. In contrast, the
other known insertion method, known as \emph{random walk insertion}, may run
indefinitely even for a solvable instance. We also present experimental results
comparing the performance of our algorithm with the random walk method, also
for the case when each location can hold more than one item.
  As a corollary we obtain a linear time algorithm (with high probability and
in expectation) for finding perfect matchings in a special class of sparse
random bipartite graphs. We support this by performing experiments on a real
world large dataset for finding maximum matchings in general large bipartite
graphs. We report an order of magnitude improvement in the running time as
compared to the \emph{Hopkraft-Karp} matching algorithm.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07786</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07790</identifier>
 <datestamp>2017-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Limits of Network Densification</dc:title>
 <dc:creator>Nguyen, Van Minh</dc:creator>
 <dc:creator>Kountouris, Marios</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Network densification is a promising cellular deployment technique that
leverages spatial reuse to enhance coverage and throughput. Recent work has
identified that at some point ultra-densification will no longer be able to
deliver significant throughput gains. In this paper, we provide a unified
treatment of the performance limits of network densification. We develop a
general framework, which incorporates multi-slope pathloss and the entire space
of shadowing and small scale fading distributions, under strongest cell
association in a Poisson field of interferers. First, our results show that
there are three scaling regimes for the downlink
signal-to-interference-plus-noise ratio (SINR), coverage probability, and
average per-user rate. Specifically, depending on the near-field pathloss and
the fading distribution, the user performance of 5G ultra dense networks (UDNs)
would either monotonically increase, saturate, or decay with increasing network
density. Second, we show that network performance in terms of coverage density
and area spectral efficiency can scale with the network density better than the
user performance does. Furthermore, we provide ordering results for both
coverage and average rate as a means to qualitatively compare different
transmission techniques that may exhibit the same performance scaling. Our
results, which are verified by simulations, provide succinct insights and
valuable design guidelines for the deployment of 5G UDNs.
</dc:description>
 <dc:description>Comment: 15 pages, 14 figures. To appear in IEEE JSAC 2017. Part of this work
  was presented in arXiv:1602.03305</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07790</dc:identifier>
 <dc:identifier>doi:10.1109/JSAC.2017.2687638</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07791</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object Detection using Image Processing</dc:title>
 <dc:creator>Jalled, Fares</dc:creator>
 <dc:creator>Voronkov, Ilia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  An Unmanned Ariel vehicle (UAV) has greater importance in the army for border
security. The main objective of this article is to develop an OpenCV-Python
code using Haar Cascade algorithm for object and face detection. Currently,
UAVs are used for detecting and attacking the infiltrated ground targets. The
main drawback for this type of UAVs is that sometimes the object are not
properly detected, which thereby causes the object to hit the UAV. This project
aims to avoid such unwanted collisions and damages of UAV. UAV is also used for
surveillance that uses Voila-jones algorithm to detect and track humans. This
algorithm uses cascade object detector function and vision. train function to
train the algorithm. The main advantage of this code is the reduced processing
time. The Python code was tested with the help of available database of video
and image, the output was verified.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07791</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07793</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Patterns in treeshelves</dc:title>
 <dc:creator>Baril, Jean-Luc</dc:creator>
 <dc:creator>Kirgizov, Sergey</dc:creator>
 <dc:creator>Vajnovszki, Vincent</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We study the distribution and the popularity of left children on sets of
treeshelves avoiding a pattern of size three. (Treeshelves are ordered binary
increasing trees where every child is connected to its parent by a left or a
right link.) The considered patterns are sub-treeshelves, and for each such a
pattern we provide exponential generating function for the corresponding
distribution and popularity. Finally, we present constructive bijections
between treeshelves avoiding a pattern of size three and some classes of
simpler combinatorial objects.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07800</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Infinite Variational Autoencoder for Semi-Supervised Learning</dc:title>
 <dc:creator>Abbasnejad, Ehsan</dc:creator>
 <dc:creator>Dick, Anthony</dc:creator>
 <dc:creator>Hengel, Anton van den</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper presents an infinite variational autoencoder (VAE) whose capacity
adapts to suit the input data. This is achieved using a mixture model where the
mixing coefficients are modeled by a Dirichlet process, allowing us to
integrate over the coefficients when performing inference. Critically, this
then allows us to automatically vary the number of autoencoders in the mixture
based on the data. Experiments show the flexibility of our method, particularly
for semi-supervised learning, where only a small number of training samples are
available.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07803</identifier>
 <datestamp>2017-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpolation-Based GR(1) Assumptions Refinement</dc:title>
 <dc:creator>Cavezza, Davide G.</dc:creator>
 <dc:creator>Alrajeh, Dalal</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This paper considers the problem of assumptions refinement in the context of
unrealizable specifications for reactive systems. We propose a new
counterstrategy-guided synthesis approach for GR(1) specifications based on
Craig's interpolants. Our interpolation-based method identifies causes for
unrealizability and computes assumptions that directly target unrealizable
cores, without the need for user input. Thereby, we discuss how this property
reduces the maximum number of steps needed to converge to realizability
compared with other techniques. We describe properties of interpolants that
yield helpful assumptions in GR(1) and prove the soundness of the results.
Finally, we demonstrate that our approach yields weaker assumptions than
baseline techniques.
</dc:description>
 <dc:description>Comment: To appear in TACAS 2017; sections restructured and abstract
  rephrased; fixed formalism; fixed references; results unchanged</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07803</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07804</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ATR4S: Toolkit with State-of-the-art Automatic Terms Recognition Methods
  in Scala</dc:title>
 <dc:creator>Astrakhantsev, N.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Automatically recognized terminology is widely used for various
domain-specific texts processing tasks, such as machine translation,
information retrieval or sentiment analysis. However, there is still no
agreement on which methods are best suited for particular settings and,
moreover, there is no reliable comparison of already developed methods. We
believe that one of the main reasons is the lack of state-of-the-art methods
implementations, which are usually non-trivial to recreate. In order to address
these issues, we present ATR4S, an open-source software written in Scala that
comprises more than 15 methods for automatic terminology recognition (ATR) and
implements the whole pipeline from text document preprocessing, to term
candidates collection, term candidates scoring, and finally, term candidates
ranking. It is highly scalable, modular and configurable tool with support of
automatic caching. We also compare 10 state-of-the-art methods on 7 open
datasets by average precision and processing time. Experimental comparison
reveals that no single method demonstrates best average precision for all
datasets and that other available tools for ATR do not contain the best
methods.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07804</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07807</identifier>
 <datestamp>2017-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Invariant Representations Of Planar Curves</dc:title>
 <dc:creator>Pai, Gautam</dc:creator>
 <dc:creator>Wetzler, Aaron</dc:creator>
 <dc:creator>Kimmel, Ron</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a metric learning framework for the construction of invariant
geometric functions of planar curves for the Eucledian and Similarity group of
transformations. We leverage on the representational power of convolutional
neural networks to compute these geometric quantities. In comparison with
axiomatic constructions, we show that the invariants approximated by the
learning architectures have better numerical qualities such as robustness to
noise, resiliency to sampling, as well as the ability to adapt to occlusion and
partiality. Finally, we develop a novel multi-scale representation in a
similarity metric learning paradigm.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-02-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07808</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hardness of Liar's Domination on Unit Disk Graphs</dc:title>
 <dc:creator>Jallu, Ramesh K</dc:creator>
 <dc:creator>Das, Gautam K</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  A unit disk graph is the intersection graph of a set of unit diameter disks
in the plane. In this paper we consider liar's domination problem on unit disk
graphs, a variant of dominating set problem. We call this problem as {\it
Euclidean liar's domination problem}. In the Euclidean liar's domination
problem, a set ${\cal P}=\{p_1,p_2,\ldots,p_n\}$ of $n$ points (disk centers)
are given in the Euclidean plane. For $p \in {\cal P}$, $N[p]$ is a subset of
${\cal P}$ such that for any $q \in N[p]$, the Euclidean distance between $p$
and $q$ is less than or equal to 1, i.e., the corresponding unit diameter disks
intersect. The objective of the Euclidean liar's domination problem is to find
a subset $D\; (\subseteq {\cal P})$ of minimum size having the following
properties : (i) $|N[p_i] \cap D| \geq 2$ for $1 \leq i \leq n$, and (ii)
$|(N[p_i] \cup N[p_j]) \cap D| \geq 3$ for $i\neq j, 1\leq i,j \leq n$. This
article aims to prove the Euclidean liar's domination problem is NP-complete.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07808</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07810</identifier>
 <datestamp>2017-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A dataset and exploration of models for understanding video data through
  fill-in-the-blank question-answering</dc:title>
 <dc:creator>Maharaj, Tegan</dc:creator>
 <dc:creator>Ballas, Nicolas</dc:creator>
 <dc:creator>Rohrbach, Anna</dc:creator>
 <dc:creator>Courville, Aaron</dc:creator>
 <dc:creator>Pal, Christopher</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While deep convolutional neural networks frequently approach or exceed
human-level performance at benchmark tasks involving static images, extending
this success to moving images is not straightforward. Having models which can
learn to understand video is of interest for many applications, including
content recommendation, prediction, summarization, event/object detection and
understanding human visual perception, but many domains lack sufficient data to
explore and perfect video models. In order to address the need for a simple,
quantitative benchmark for developing and understanding video, we present
MovieFIB, a fill-in-the-blank question-answering dataset with over 300,000
examples, based on descriptive video annotations for the visually impaired. In
addition to presenting statistics and a description of the dataset, we perform
a detailed analysis of 5 different models' predictions, and compare these with
human performance. We investigate the relative importance of language, static
(2D) visual features, and moving (3D) visual features; the effects of
increasing dataset size, the number of frames sampled; and of vocabulary size.
We illustrate that: this task is not solvable by a language model alone; our
model combining 2D and 3D visual information indeed provides the best result;
all models perform significantly worse than human-level. We provide human
evaluations for responses given by different models and find that accuracy on
the MovieFIB evaluation corresponds well with human judgement. We suggest
avenues for improving video models, and hope that the proposed dataset can be
useful for measuring and encouraging progress in this very interesting field.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07811</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guruswami--Sudan List Decoding for Complex Reed--Solomon Codes</dc:title>
 <dc:creator>Mohamed, Mostafa H.</dc:creator>
 <dc:creator>Puchinger, Sven</dc:creator>
 <dc:creator>Bossert, Martin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We analyze the Guruswami--Sudan list decoding algorithm for Reed--Solomon
codes over the complex field for sparse recovery in Compressed Sensing. We
propose methods of stabilizing both the interpolation and the root-finding
steps against numerical instabilities, where the latter is the most sensitive.
For this purpose, we modify the Roth--Ruckenstein algorithm and propose a
method to refine its result using Newton's method. The overall decoding
performance is then further improved using Generalized Minimum Distance
decoding based on intrinsic soft information. This method also allows to obtain
a unique solution of the recovery problem. The approach is numerically
evaluated and shown to improve upon recently proposed decoding techniques.
</dc:description>
 <dc:description>Comment: 6 pages, accepted for publication at the 11th International ITG
  Conference on Systems, Communications and Coding (SCC 2017)</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07812</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Static Analysis of Communicating Processes using Symbolic Transducers</dc:title>
 <dc:creator>Botbol, Vincent</dc:creator>
 <dc:creator>Chailloux, Emmanuel</dc:creator>
 <dc:creator>Gall, Tristan Le</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We present a general model allowing static analysis based on abstract
interpretation for systems of communicating processes. Our technique, inspired
by Regular Model Checking, represents set of program states as lattice automata
and programs semantics as symbolic transducers. This model can express dynamic
creation/destruction of processes and communications. Using the abstract
interpretation framework, we are able to provide a sound over-approximation of
the reachability set of the system thus allowing us to prove safety properties.
We implemented this method in a prototype that targets the MPI library for C
programs.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07812</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07819</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>dMath: Distributed Linear Algebra for DL</dc:title>
 <dc:creator>Eliuk, Steven</dc:creator>
 <dc:creator>Upright, Cameron</dc:creator>
 <dc:creator>Vardhan, Hars</dc:creator>
 <dc:creator>Walsh, Stephen</dc:creator>
 <dc:creator>Gale, Trevor</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The paper presents a parallel math library, dMath, that demonstrates leading
scaling when using intranode, internode, and hybrid-parallelism for deep
learning (DL). dMath provides easy-to-use distributed primitives and a variety
of domain-specific algorithms including matrix multiplication, convolutions,
and others allowing for rapid development of scalable applications like deep
neural networks (DNNs). Persistent data stored in GPU memory and advanced
memory management techniques avoid costly transfers between host and device.
dMath delivers performance, portability, and productivity to its specific
domain of support.
</dc:description>
 <dc:description>Comment: 5 pages. arXiv admin note: text overlap with arXiv:1604.01416</dc:description>
 <dc:date>2016-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07824</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SimAthens: A spatial microsimulation approach to the estimation and
  analysis of small-area income distributions and poverty rates in Athens,
  Greece</dc:title>
 <dc:creator>Panori, Anastasia</dc:creator>
 <dc:creator>Ballas, Dimitris</dc:creator>
 <dc:creator>Psycharis, Yannis</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>62P25</dc:subject>
 <dc:description>  Published during a severe economic crisis, this study presents the first
spatial microsimulation model for the analysis of income inequalities and
poverty in Greece. First, we present a brief overview of the method and discuss
its potential for the analysis of multidimensional poverty and income
inequality in Greece. We then present the SimAthens model, based on a
combination of small-area demographic and socioeconomic information available
from the Greek census of population with data from the European Union
Statistics on Income and Living Conditions (EU-SILC). The model is based on an
iterative proportional fitting (IPF) algorithm, and is used to reweigh EU-SILC
records to fit in small-area descriptions for Athens based on 2001 and 2011
censuses. This is achieved by using demographic and socioeconomic
characteristics as constraint variables. Finally, synthesis of the labor market
and occupations are chosen as the main variables for externally validating our
results, in order to verify the integrity of the model. Results of this
external validation process are found to be extremely satisfactory, indicating
a high goodness of fit between simulated and real values. Finally, the study
presents a number of model outputs, illustrating changes in social and economic
geography, during a severe economic crisis, offering a great opportunity for
discussing further potential of this model in policy analysis.
</dc:description>
 <dc:description>Comment: Preprint submitted to Computers, Environment and Urban Systems
  (accepted 2 August 2016). Published paper version available from:
  http://www.sciencedirect.com/science/article/pii/S0198971516301685</dc:description>
 <dc:date>2016-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07824</dc:identifier>
 <dc:identifier>2016, Computers, Environment and Urban Systems,
  dx.doi.org/10.1016/j.compenvurbsys.2016.08.001</dc:identifier>
 <dc:identifier>doi:10.1016/j.compenvurbsys.2016.08.001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07828</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose</dc:title>
 <dc:creator>Pavlakos, Georgios</dc:creator>
 <dc:creator>Zhou, Xiaowei</dc:creator>
 <dc:creator>Derpanis, Konstantinos G.</dc:creator>
 <dc:creator>Daniilidis, Kostas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper addresses the challenge of 3D human pose estimation from a single
color image. Despite the general success of the end-to-end learning paradigm,
top performing approaches employ a two-step solution consisting of a
Convolutional Network (ConvNet) for 2D joint localization and a subsequent
optimization step to recover 3D pose. In this paper, we identify the
representation of 3D pose as a critical issue with current ConvNet approaches
and make two important contributions towards validating the value of end-to-end
learning for this task. First, we propose a fine discretization of the 3D space
around the subject and train a ConvNet to predict per voxel likelihoods for
each joint. This creates a natural representation for 3D pose and greatly
improves performance over the direct regression of joint coordinates. Second,
to further improve upon initial estimates, we employ a coarse-to-fine
prediction scheme. This step addresses the large dimensionality increase and
enables iterative refinement and repeated processing of the image features. The
proposed approach outperforms all state-of-the-art methods on standard
benchmarks achieving a relative error reduction greater than 30% on average.
Additionally, we investigate using our volumetric representation in a related
architecture which is suboptimal compared to our end-to-end approach, but is of
practical interest, since it enables training when no image with corresponding
3D groundtruth is available, and allows us to present compelling results for
in-the-wild images.
</dc:description>
 <dc:description>Comment: CVPR 2017 Camera Ready. Project Page:
  https://www.seas.upenn.edu/~pavlakos/projects/volumetric/</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07829</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A General Theory of Information and Computation</dc:title>
 <dc:creator>Adriaans, P. W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper fills a gap in our understanding of the interaction between
information and computation. It unifies other approaches to measuring
information like Kolmogorov complexity and Shannon information. We define a
theory about information flow in deterministic computing based on three
fundamental observations: 1) Information is measured in logarithms, 2) All
countable sets contain the same amount of information and 3) Deterministic
computing does not create information. We analyze the flow of information
through computational processes: exactly, for primitive recursive functions and
elementary artithmetical operations and, under maximal entropy, for polynomial
functions and diophantine equations. Thus we get, by the MRDP-theorem, a theory
of flow of information for general computable functions. We prove some results
like the Fueter-P\'olya conjecture and the existence of an information
conserving enumeration of all finite sets of numbers. We also show that the
information flow in more complex derivatives of the primitive recursive
functions like addition and multiplication is not trivial: in particular
associativity is not information efficient for addition. Using the Cantor
pairing function we develop a universal measuring device for partitions of the
set of finite sets of numbers. We show that these sets can be enumerated by a
polynomial function when ordered by cardinality, but not when ordered by their
sums.
</dc:description>
 <dc:description>Comment: 32 page. 2 figures</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07829</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07832</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AARC: First draft of the Blueprint Architecture for Authentication and
  Authorisation Infrastructures</dc:title>
 <dc:creator>Biancini, A.</dc:creator>
 <dc:creator>Florio, L.</dc:creator>
 <dc:creator>Haase, M.</dc:creator>
 <dc:creator>Hardt, M.</dc:creator>
 <dc:creator>Jankowski, M.</dc:creator>
 <dc:creator>Jensen, J.</dc:creator>
 <dc:creator>Kanellopoulos, C.</dc:creator>
 <dc:creator>Liampotis, N.</dc:creator>
 <dc:creator>Licehammer, S.</dc:creator>
 <dc:creator>Memon, S.</dc:creator>
 <dc:creator>van Dijk, N.</dc:creator>
 <dc:creator>Paetow, S.</dc:creator>
 <dc:creator>Prochazka, M.</dc:creator>
 <dc:creator>Sall&#xe9;, M.</dc:creator>
 <dc:creator>Solagna, P.</dc:creator>
 <dc:creator>Stevanovic, U.</dc:creator>
 <dc:creator>Vaghetti, D.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  AARC (Authentication and Authorisation for Research Communities) is a
two-year EC-funded project to develop and pilot an integrated cross-discipline
authentication and authorisation framework, building on existing authentication
and authorisation infrastructures (AAIs) and production federated
infrastructure. AARC also champions federated access and offers tailored
training to complement the actions needed to test AARC results and to promote
AARC outcomes. This article describes a high-level blueprint architectures for
interoperable AAIs.
</dc:description>
 <dc:description>Comment: This text was part of a (public) EU deliverable document. It has a
  main part and a long appendix with more details about example infrastructures
  that were taken into acount</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07832</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07837</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Feature Abstraction for Translating Video to Text</dc:title>
 <dc:creator>Pu, Yunchen</dc:creator>
 <dc:creator>Min, Martin Renqiang</dc:creator>
 <dc:creator>Gan, Zhe</dc:creator>
 <dc:creator>Carin, Lawrence</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Previous models for video captioning often use the output from a specific
layer of a Convolutional Neural Network (CNN) as video features. However, the
variable context-dependent semantics in the video may make it more appropriate
to adaptively select features from the multiple CNN layers. We propose a new
approach for generating adaptive spatiotemporal representations of videos for
the captioning task. A novel attention mechanism is developed, that adaptively
and sequentially focuses on different layers of CNN features (levels of feature
&quot;abstraction&quot;), as well as local spatiotemporal regions of the feature maps at
each layer. The proposed approach is evaluated on three benchmark datasets:
YouTube2Text, M-VAD and MSR-VTT. Along with visualizing the results and how the
model works, these experiments quantitatively demonstrate the effectiveness of
the proposed adaptive spatiotemporal feature abstraction for translating videos
to sentences with rich semantics.
</dc:description>
 <dc:description>Comment: Accepted to AAAI 2018</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07848</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Integer-Forcing Precoding for the Gaussian MIMO Broadcast Channel</dc:title>
 <dc:creator>Silva, Danilo</dc:creator>
 <dc:creator>Pivaro, Gabriel</dc:creator>
 <dc:creator>Fraidenraich, Gustavo</dc:creator>
 <dc:creator>Aazhang, Behnaam</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Integer-forcing (IF) precoding, also known as downlink IF, is a promising new
approach for communication over multiple-input multiple-output (MIMO) broadcast
channels. Inspired by the integer-forcing linear receiver for multiple-access
channels, it generalizes linear precoding by inducing an effective channel
matrix that is approximately integer, rather than approximately identity.
Combined with lattice encoding and a pre-inversion of the channel matrix at the
transmitter, the scheme has the potential to outperform any linear precoding
scheme, despite enjoying similar low complexity.
  In this paper, a specific IF precoding scheme, called diagonally-scaled exact
IF (DIF), is proposed and shown to achieve maximum spatial multiplexing gain.
For the special case of two receivers, in the high SNR regime, an optimal
choice of parameters is derived analytically, leading to an almost closed-form
expression for the achievable sum rate. In particular, it is shown that the gap
to the sum capacity is upper bounded by 0.27 bits for any channel realization.
For general SNR, a regularized version of DIF (RDIF) is proposed. Numerical
results for two receivers under Rayleigh fading show that RDIF can achieve
performance superior to optimal linear precoding and very close to the sum
capacity.
</dc:description>
 <dc:description>Comment: 13 pages, 5 figures. To appear at the IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-04-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07862</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Browsix: Bridging the Gap Between Unix and the Browser</dc:title>
 <dc:creator>Powers, Bobby</dc:creator>
 <dc:creator>Vilk, John</dc:creator>
 <dc:creator>Berger, Emery D.</dc:creator>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Applications written to run on conventional operating systems typically
depend on OS abstractions like processes, pipes, signals, sockets, and a shared
file system. Porting these applications to the web currently requires extensive
rewriting or hosting significant portions of code server-side because browsers
present a nontraditional runtime environment that lacks OS functionality.
  This paper presents Browsix, a framework that bridges the considerable gap
between conventional operating systems and the browser, enabling unmodified
programs expecting a Unix-like environment to run directly in the browser.
Browsix comprises two core parts: (1) a JavaScript-only system that makes core
Unix features (including pipes, concurrent processes, signals, sockets, and a
shared file system) available to web applications; and (2) extended JavaScript
runtimes for C, C++, Go, and Node.js that support running programs written in
these languages as processes in the browser. Browsix supports running a POSIX
shell, making it straightforward to connect applications together via pipes.
  We illustrate Browsix's capabilities via case studies that demonstrate how it
eases porting legacy applications to the browser and enables new functionality.
We demonstrate a Browsix-enabled LaTeX editor that operates by executing
unmodified versions of pdfLaTeX and BibTeX. This browser-only LaTeX editor can
render documents in seconds, making it fast enough to be practical. We further
demonstrate how Browsix lets us port a client-server application to run
entirely in the browser for disconnected operation. Creating these applications
required less than 50 lines of glue code and no code modifications,
demonstrating how easily Browsix can be used to build sophisticated web
applications from existing parts without modification.
</dc:description>
 <dc:description>Comment: to appear at ASPLOS 2017</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07862</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07865</identifier>
 <datestamp>2017-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Controlling Perceptual Factors in Neural Style Transfer</dc:title>
 <dc:creator>Gatys, Leon A.</dc:creator>
 <dc:creator>Ecker, Alexander S.</dc:creator>
 <dc:creator>Bethge, Matthias</dc:creator>
 <dc:creator>Hertzmann, Aaron</dc:creator>
 <dc:creator>Shechtman, Eli</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Neural Style Transfer has shown very exciting results enabling new forms of
image manipulation. Here we extend the existing method to introduce control
over spatial location, colour information and across spatial scale. We
demonstrate how this enhances the method by allowing high-resolution controlled
stylisation and helps to alleviate common failure cases such as applying ground
textures to sky regions. Furthermore, by decomposing style into these
perceptual factors we enable the combination of style information from multiple
sources to generate new, perceptually appealing styles from existing ones. We
also describe how these methods can be used to more efficiently produce large
size, high-quality stylisation. Finally we show how the introduced control
measures can be applied in recent methods for Fast Neural Style Transfer.
</dc:description>
 <dc:description>Comment: Accepted at CVPR2017</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-05-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07865</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07866</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimizing the Union: Tight Approximations for Small Set Bipartite
  Vertex Expansion</dc:title>
 <dc:creator>Chlamt&#xe1;&#x10d;, Eden</dc:creator>
 <dc:creator>Dinitz, Michael</dc:creator>
 <dc:creator>Makarychev, Yury</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In the Minimum k-Union problem (MkU) we are given a set system with n sets
and are asked to select k sets in order to minimize the size of their union.
Despite being a very natural problem, it has received surprisingly little
attention: the only known approximation algorithm is an
$O(\sqrt{n})$-approximation due to [Chlamt\'a\v{c} et al APPROX '16]. This
problem can also be viewed as the bipartite version of the Small Set Vertex
Expansion problem (SSVE), which we call the Small Set Bipartite Vertex
Expansion problem (SSBVE). SSVE, in which we are asked to find a set of k nodes
to minimize their vertex expansion, has not been as well studied as its
edge-based counterpart Small Set Expansion (SSE), but has recently received
significant attention, e.g. [Louis-Makarychev APPROX '15]. However, due to the
connection to Unique Games and hardness of approximation the focus has mostly
been on sets of size $k = \Omega(n)$, while we focus on the case of general
$k$, for which no polylogarithmic approximation is known.
  We improve the upper bound for this problem by giving an
$n^{1/4+\varepsilon}$ approximation for SSBVE for any constant $\varepsilon &gt;
0$. Our algorithm follows in the footsteps of Densest $k$-Subgraph (DkS) and
related problems, by designing a tight algorithm for random models, and then
extending it to give the same guarantee for arbitrary instances. Moreover, we
show that this is tight under plausible complexity conjectures: it cannot be
approximated better than $O(n^{1/4})$ assuming an extension of the so-called
&quot;Dense vs Random&quot; conjecture for DkS to hypergraphs. We show that the same
bound is also matched by an integrality gap for a super-constant number of
rounds of the Sherali-Adams LP hierarchy, and an even worse integrality gap for
the natural SDP relaxation. Finally, we design a simple bicriteria $\tilde
O(\sqrt{n})$ approximation for the more general SSVE problem.
</dc:description>
 <dc:description>Comment: To appear in SODA 2017</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07867</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis on 60 GHz Wireless Communications with Beamwidth-Dependent
  Misalignment</dc:title>
 <dc:creator>Yang, Guang</dc:creator>
 <dc:creator>Du, Jinfeng</dc:creator>
 <dc:creator>Xiao, Ming</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  High speed wireless access on 60 GHz spectrum relies on high-gain directional
antennas to overcome the severe signal attenuation. However, perfect alignment
between transmitting and receiving antenna beams is rare in practice and
overheard signals from concurrent transmissions may cause significant
interference. In this paper we analyze the impact of antenna beam misalignment
on the system performance of 60 GHz wireless access. We quantify the signal
power loss caused by beam misalignment and the interference power accumulated
from neighboring concurrent transmissions whose signals are leaked either via
the main-beam pointing in the similar direction or via side-lobe emission, and
derive the probability distribution of the signal to interference plus noise
power ratio (SINR). For scenarios where interfering transmitters are
distributed uniformly at random, we derive upper and lower bounds on the
cumulative distribution function (abbreviated as CDF or c.d.f.) of SINR, which
can be easily applied to evaluate system performance. We validate our
analytical results by simulations where random nodes are uniformly distributed
within a circular hall, and evaluate the sensitivity of average throughput and
outage probability against two parameters: the half-power (3 dB) beamwidth to
main-lobe beamwidth ratio and the beam misalignment deviation to main-lobe
beamwidth ratio. Our results indicate that the derived lower bound performs
well when the half-power beamwidth to main-lobe beamwidth ratio or the number
of concurrent transmission links is small. When the number of active links is
high, it is desirable in antenna design to balance the degradation caused by
beam misalignment (wider beam is better) and the interference from concurrent
transmission (narrower beam is better).
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07879</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Testing submodularity and other properties of valuation functions</dc:title>
 <dc:creator>Blais, Eric</dc:creator>
 <dc:creator>Bommireddi, Abhinav</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We show that for any constant $\epsilon &gt; 0$ and $p \ge 1$, it is possible to
distinguish functions $f : \{0,1\}^n \to [0,1]$ that are submodular from those
that are $\epsilon$-far from every submodular function in $\ell_p$ distance
with a constant number of queries.
  More generally, we extend the testing-by-implicit-learning framework of
Diakonikolas et al. (2007) to show that every property of real-valued functions
that is well-approximated in $\ell_2$ distance by a class of $k$-juntas for
some $k = O(1)$ can be tested in the $\ell_p$-testing model with a constant
number of queries. This result, combined with a recent junta theorem of Feldman
and Vondrak (2016), yields the constant-query testability of submodularity. It
also yields constant-query testing algorithms for a variety of other natural
properties of valuation functions, including fractionally additive (XOS)
functions, OXS functions, unit demand functions, coverage functions, and
self-bounding functions.
</dc:description>
 <dc:description>Comment: To appear in 8th Innovations in Theoretical Computer Science (ITCS)
  conference, Jan. 9-11, 2017</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07889</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The World of Fast Moving Objects</dc:title>
 <dc:creator>Rozumnyi, Denys</dc:creator>
 <dc:creator>Kotera, Jan</dc:creator>
 <dc:creator>Sroubek, Filip</dc:creator>
 <dc:creator>Novotny, Lukas</dc:creator>
 <dc:creator>Matas, Jiri</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The notion of a Fast Moving Object (FMO), i.e. an object that moves over a
distance exceeding its size within the exposure time, is introduced. FMOs may,
and typically do, rotate with high angular speed. FMOs are very common in
sports videos, but are not rare elsewhere. In a single frame, such objects are
often barely visible and appear as semi-transparent streaks.
  A method for the detection and tracking of FMOs is proposed. The method
consists of three distinct algorithms, which form an efficient localization
pipeline that operates successfully in a broad range of conditions. We show
that it is possible to recover the appearance of the object and its axis of
rotation, despite its blurred appearance. The proposed method is evaluated on a
new annotated dataset. The results show that existing trackers are inadequate
for the problem of FMO localization and a new approach is required. Two
applications of localization, temporal super-resolution and highlighting, are
presented.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07890</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image-based localization using LSTMs for structured feature correlation</dc:title>
 <dc:creator>Walch, Florian</dc:creator>
 <dc:creator>Hazirbas, Caner</dc:creator>
 <dc:creator>Leal-Taix&#xe9;, Laura</dc:creator>
 <dc:creator>Sattler, Torsten</dc:creator>
 <dc:creator>Hilsenbeck, Sebastian</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work we propose a new CNN+LSTM architecture for camera pose
regression for indoor and outdoor scenes. CNNs allow us to learn suitable
feature representations for localization that are robust against motion blur
and illumination changes. We make use of LSTM units on the CNN output, which
play the role of a structured dimensionality reduction on the feature vector,
leading to drastic improvements in localization performance. We provide
extensive quantitative comparison of CNN-based and SIFT-based localization
methods, showing the weaknesses and strengths of each. Furthermore, we present
a new large-scale indoor dataset with accurate ground truth from a laser
scanner. Experimental results on both indoor and outdoor public datasets show
our method outperforms existing deep architectures, and can localize images in
hard conditions, e.g., in the presence of mostly textureless surfaces, where
classic SIFT-based methods fail.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07890</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07897</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Generic Sentence Representations Using Convolutional Neural
  Networks</dc:title>
 <dc:creator>Gan, Zhe</dc:creator>
 <dc:creator>Pu, Yunchen</dc:creator>
 <dc:creator>Henao, Ricardo</dc:creator>
 <dc:creator>Li, Chunyuan</dc:creator>
 <dc:creator>He, Xiaodong</dc:creator>
 <dc:creator>Carin, Lawrence</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a new encoder-decoder approach to learn distributed sentence
representations that are applicable to multiple purposes. The model is learned
by using a convolutional neural network as an encoder to map an input sentence
into a continuous vector, and using a long short-term memory recurrent neural
network as a decoder. Several tasks are considered, including sentence
reconstruction and future sentence prediction. Further, a hierarchical
encoder-decoder model is proposed to encode a sentence to predict multiple
future sentences. By training our models on a large collection of novels, we
obtain a highly generic convolutional sentence encoder that performs well in
practice. Experimental results on several benchmark datasets, and across a
broad range of applications, demonstrate the superiority of the proposed model
over competing methods.
</dc:description>
 <dc:description>Comment: Accepted by EMNLP 2017</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07897</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07909</identifier>
 <datestamp>2016-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Segmentation Using Overlapping Group Sparsity</dc:title>
 <dc:creator>Minaee, Shervin</dc:creator>
 <dc:creator>Wang, Yao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Sparse decomposition has been widely used for different applications, such as
source separation, image classification and image denoising. This paper
presents a new algorithm for segmentation of an image into background and
foreground text and graphics using sparse decomposition. First, the background
is represented using a suitable smooth model, which is a linear combination of
a few smoothly varying basis functions, and the foreground text and graphics
are modeled as a sparse component overlaid on the smooth background. Then the
background and foreground are separated using a sparse decomposition framework
and imposing some prior information, which promote the smoothness of
background, and the sparsity and connectivity of foreground pixels. This
algorithm has been tested on a dataset of images extracted from HEVC standard
test sequences for screen content coding, and is shown to outperform prior
methods, including least absolute deviation fitting, k-means clustering based
segmentation in DjVu, and shape primitive extraction and coding algorithm.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1602.02434.
  appears in IEEE Signal Processing in Medicine and Biology Symposium, 2016</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2016-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07909</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07910</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Map-aided Dead-reckoning --- A Study on Locational Privacy in Insurance
  Telematics</dc:title>
 <dc:creator>Wahlstr&#xf6;m, Johan</dc:creator>
 <dc:creator>Skog, Isaac</dc:creator>
 <dc:creator>Rodrigues, Jo&#xe3;o G. P.</dc:creator>
 <dc:creator>H&#xe4;ndel, Peter</dc:creator>
 <dc:creator>Aguiar, Ana</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We present a particle-based framework for estimating the position of a
vehicle using map information and measurements of speed. Two measurement
functions are considered. The first is based on the assumption that the lateral
force on the vehicle does not exceed critical limits derived from physical
constraints. The second is based on the assumption that the driver approaches a
target speed derived from the speed limits along the upcoming trajectory.
Performance evaluations of the proposed method indicate that end destinations
often can be estimated with an accuracy in the order of $100\,[m]$. These
results expose the sensitivity and commercial value of data collected in many
of today's insurance telematics programs, and thereby have privacy implications
for millions of policyholders. We end by discussing the strengths and
weaknesses of different methods for anonymization and privacy preservation in
telematics programs.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07910</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07917</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Restricted Boltzmann Networks</dc:title>
 <dc:creator>Hu, Hengyuan</dc:creator>
 <dc:creator>Gao, Lisheng</dc:creator>
 <dc:creator>Ma, Quanbin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Building a good generative model for image has long been an important topic
in computer vision and machine learning. Restricted Boltzmann machine (RBM) is
one of such models that is simple but powerful. However, its restricted form
also has placed heavy constraints on the models representation power and
scalability. Many extensions have been invented based on RBM in order to
produce deeper architectures with greater power. The most famous ones among
them are deep belief network, which stacks multiple layer-wise pretrained RBMs
to form a hybrid model, and deep Boltzmann machine, which allows connections
between hidden units to form a multi-layer structure. In this paper, we present
a new method to compose RBMs to form a multi-layer network style architecture
and a training method that trains all layers jointly. We call the resulted
structure deep restricted Boltzmann network. We further explore the combination
of convolutional RBM with the normal fully connected RBM, which is made trivial
under our composition framework. Experiments show that our model can generate
descent images and outperform the normal RBM significantly in terms of image
quality and feature quality, without losing much efficiency for training.
</dc:description>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07917</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07932</identifier>
 <datestamp>2017-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Straight to Shapes: Real-time Detection of Encoded Shapes</dc:title>
 <dc:creator>Jetley, Saumya</dc:creator>
 <dc:creator>Sapienza, Michael</dc:creator>
 <dc:creator>Golodetz, Stuart</dc:creator>
 <dc:creator>Torr, Philip H. S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Current object detection approaches predict bounding boxes, but these provide
little instance-specific information beyond location, scale and aspect ratio.
In this work, we propose to directly regress to objects' shapes in addition to
their bounding boxes and categories. It is crucial to find an appropriate shape
representation that is compact and decodable, and in which objects can be
compared for higher-order concepts such as view similarity, pose variation and
occlusion. To achieve this, we use a denoising convolutional auto-encoder to
establish an embedding space, and place the decoder after a fast end-to-end
network trained to regress directly to the encoded shape vectors. This yields
what to the best of our knowledge is the first real-time shape prediction
network, running at ~35 FPS on a high-end desktop. With higher-order shape
reasoning well-integrated into the network pipeline, the network shows the
useful practical quality of generalising to unseen categories similar to the
ones in the training set, something that most existing approaches fail to
handle.
</dc:description>
 <dc:description>Comment: 16 pages including appendix; Published at CVPR 2017</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07932</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07933</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Routing Number Of A Pyramid</dc:title>
 <dc:creator>Banerjee, Indranil</dc:creator>
 <dc:creator>Richards, Dana</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  In this short note we give the routing number of pyramid graph under the
\textit{routing via matching} model introduced by Alon et al\cite{5}. This
model can be viewed as a communication scheme on a distributed network. The
nodes in the network can communicate via matchings (a step), where a node
exchanges data with its partner. Formally, given a connected graph $G$ with
vertices labeled from $[1,...,n]$ and a permutation $\pi$ giving the
destination of pebbles on the vertices the problem is to find a minimum step
routing scheme. This is denoted as the routing time $rt(G,\pi)$ of $G$ given
$\pi$. We show that a $d$-dimensional pyramid with $m$ levels has a routing
number of $O(dN^{1/d})$.
</dc:description>
 <dc:description>Comment: 3 pages, 2 figures</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07933</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07941</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Modal Mean-Fields via Cardinality-Based Clamping</dc:title>
 <dc:creator>Baqu&#xe9;, Pierre</dc:creator>
 <dc:creator>Fleuret, Fran&#xe7;ois</dc:creator>
 <dc:creator>Fua, Pascal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Mean Field inference is central to statistical physics. It has attracted much
interest in the Computer Vision community to efficiently solve problems
expressible in terms of large Conditional Random Fields. However, since it
models the posterior probability distribution as a product of marginal
probabilities, it may fail to properly account for important dependencies
between variables. We therefore replace the fully factorized distribution of
Mean Field by a weighted mixture of such distributions, that similarly
minimizes the KL-Divergence to the true posterior. By introducing two new
ideas, namely, conditioning on groups of variables instead of single ones and
using a parameter of the conditional random field potentials, that we identify
to the temperature in the sense of statistical physics to select such groups,
we can perform this minimization efficiently. Our extension of the clamping
method proposed in previous works allows us to both produce a more descriptive
approximation of the true posterior and, inspired by the diverse MAP paradigms,
fit a mixture of Mean Field approximations. We demonstrate that this positively
impacts real-world algorithms that initially relied on mean fields.
</dc:description>
 <dc:description>Comment: Submitted for review to CVPR 2017</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07946</identifier>
 <datestamp>2016-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Highly-Secure Physically Unclonable Cryptographic Primitives Using
  Nonlinear Conductance and Analog State Tuning in Memristive Crossbar Arrays</dc:title>
 <dc:creator>Nili, Hussein</dc:creator>
 <dc:creator>Adam, Gina C.</dc:creator>
 <dc:creator>Prezioso, Mirko</dc:creator>
 <dc:creator>Kim, Jeeson</dc:creator>
 <dc:creator>Merrikh-Bayat, Farnood</dc:creator>
 <dc:creator>Kavehei, Omid</dc:creator>
 <dc:creator>Strukov, Dmitri B.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Condensed Matter - Other Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The rapidly expanding hardware-intrinsic security primitives are aimed at
addressing significant security challenges of a massively interconnected world
in the age of information technology. The main idea of such primitives is to
employ instance-specific process-induced variations in electronic hardware as a
source of cryptographic data. Among the emergent technologies, memristive
devices provide unique opportunities for security applications due to the
underlying stochasticity in their operation. Herein, we report a prototype of a
robust, dense, and reconfigurable physical unclonable function primitives based
on the three-dimensional passive metal-oxide memristive crossbar circuits, by
making positive use of process-induced variations in the devices' nonlinear
I-Vs and their analog tuning. We first characterize security metrics for a
basic building block of the security primitives based on a two layer stack with
monolithically integrated 10x10 250-nm half-pitch memristive crossbar circuits.
The experimental results show that the average uniformity and diffusivity,
measured on a random sample of 6,000 64-bit responses, out of ~697,000 total,
is close to ideal 50% with 5% standard deviation for both metrics. The
uniqueness, which was evaluated on a smaller sample by readjusting conductances
of crosspoint devices within the same crossbar, is also close to the ideal 50%
+/- 1%, while the smallest bit error rate, i.e. reciprocal of reliability,
measured over 30-day window under +/-20% power supply variations, was ~ 1.5%
+/- 1%. We then utilize multiple instances of the basic block to demonstrate
physically unclonable functional primitive with 10-bit hidden challenge
generation that encodes more than 10^19 challenge response pairs and has
comparable uniformity, diffusiveness, and bit error rate.
</dc:description>
 <dc:description>Comment: 24 pages, 5 figures</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07954</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Emergent Predication Structure in Hidden State Vectors of Neural Readers</dc:title>
 <dc:creator>Wang, Hai</dc:creator>
 <dc:creator>Onishi, Takeshi</dc:creator>
 <dc:creator>Gimpel, Kevin</dc:creator>
 <dc:creator>McAllester, David</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  A significant number of neural architectures for reading comprehension have
recently been developed and evaluated on large cloze-style datasets. We present
experiments supporting the emergence of &quot;predication structure&quot; in the hidden
state vectors of these readers. More specifically, we provide evidence that the
hidden state vectors represent atomic formulas $\Phi[c]$ where $\Phi$ is a
semantic property (predicate) and $c$ is a constant symbol entity identifier.
</dc:description>
 <dc:description>Comment: Accepted for Repl4NLP: 2nd Workshop on Representation Learning for
  NLP</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07954</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07971</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Representation in Fourier and Local Bases Using ProSparse: A
  Probabilistic Analysis</dc:title>
 <dc:creator>Lu, Yue M.</dc:creator>
 <dc:creator>O&#xf1;ativia, Jon</dc:creator>
 <dc:creator>Dragotti, Pier Luigi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Finding the sparse representation of a signal in an overcomplete dictionary
has attracted a lot of attention over the past years. This paper studies
ProSparse, a new polynomial complexity algorithm that solves the sparse
representation problem when the underlying dictionary is the union of a
Vandermonde matrix and a banded matrix. Unlike our previous work which
establishes deterministic (worst-case) sparsity bounds for ProSparse to
succeed, this paper presents a probabilistic average-case analysis of the
algorithm. Based on a generating-function approach, closed-form expressions for
the exact success probabilities of ProSparse are given. The success
probabilities are also analyzed in the high-dimensional regime. This asymptotic
analysis characterizes a sharp phase transition phenomenon regarding the
performance of the algorithm.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.07995</identifier>
 <datestamp>2017-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Factoring using 2n+2 qubits with Toffoli based modular multiplication</dc:title>
 <dc:creator>H&#xe4;ner, Thomas</dc:creator>
 <dc:creator>Roetteler, Martin</dc:creator>
 <dc:creator>Svore, Krysta M.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  We describe an implementation of Shor's quantum algorithm to factor n-bit
integers using only 2n+2 qubits. In contrast to previous space-optimized
implementations, ours features a purely Toffoli based modular multiplication
circuit. The circuit depth and the overall gate count are in O(n^3) and O(n^3
log(n)), respectively. We thus achieve the same space and time costs as
Takahashi et al., while using a purely classical modular multiplication
circuit. As a consequence, our approach evades most of the cost overheads
originating from rotation synthesis and enables testing and localization of
faults in both, the logical level circuit and an actual quantum hardware
implementation. Our new (in-place) constant-adder, which is used to construct
the modular multiplication circuit, uses only dirty ancilla qubits and features
a circuit size and depth in O(n log(n)) and O(n), respectively.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.07995</dc:identifier>
 <dc:identifier>Quantum Information and Computation, Vol. 17, No. 7 &amp; 8 (2017)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08002</identifier>
 <datestamp>2017-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Compositional Networks for Visual Captioning</dc:title>
 <dc:creator>Gan, Zhe</dc:creator>
 <dc:creator>Gan, Chuang</dc:creator>
 <dc:creator>He, Xiaodong</dc:creator>
 <dc:creator>Pu, Yunchen</dc:creator>
 <dc:creator>Tran, Kenneth</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:creator>Carin, Lawrence</dc:creator>
 <dc:creator>Deng, Li</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A Semantic Compositional Network (SCN) is developed for image captioning, in
which semantic concepts (i.e., tags) are detected from the image, and the
probability of each tag is used to compose the parameters in a long short-term
memory (LSTM) network. The SCN extends each weight matrix of the LSTM to an
ensemble of tag-dependent weight matrices. The degree to which each member of
the ensemble is used to generate an image caption is tied to the
image-dependent probability of the corresponding tag. In addition to captioning
images, we also extend the SCN to generate captions for video clips. We
qualitatively analyze semantic composition in SCNs, and quantitatively evaluate
the algorithm on three benchmark datasets: COCO, Flickr30k, and Youtube2Text.
Experimental results show that the proposed method significantly outperforms
prior state-of-the-art approaches, across multiple evaluation metrics.
</dc:description>
 <dc:description>Comment: Accepted in CVPR 2017</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08004</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>At Ease with Your Warnings: The Principles of the Salutogenesis Model
  Applied to Automatic Static Analysis</dc:title>
 <dc:creator>Ostberg, Jan-Peter</dc:creator>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  The results of an automatic static analysis run can be overwhelming,
especially for beginners. The overflow of information and the resulting need
for many decisions is mentally tiring and can cause stress symptoms. There are
several models in health care which are designed to fight stress. One of these
is the salutogenesis model created by Aaron Antonovsky. In this paper, we will
present an idea on how to transfer this model into a triage and recommendation
model for static analysis tools and give an example of how this can be
implemented in FindBugs, a static analysis tool for Java.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08004</dc:identifier>
 <dc:identifier>Proc. 23rd International Conference on Software Analysis,
  Evolution, and Reengineering (SANER). IEEE, 2016</dc:identifier>
 <dc:identifier>doi:10.1109/SANER.2016.63</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08005</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Relationship of Inconsistent Software Clones and Faults: An
  Empirical Study</dc:title>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:creator>Abdulkhaleq, Asim</dc:creator>
 <dc:creator>Kaya, Kamer</dc:creator>
 <dc:creator>Paar, Alexander</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Background: Code cloning - copying and reusing pieces of source code - is a
common phenomenon in software development in practice. There have been several
empirical studies on the effects of cloning, but there are contradictory
results regarding the connection of cloning and faults. Objective: Our aim is
to clarify the relationship between code clones and faults. In particular, we
focus on inconsistent (or type-3) clones in this work. Method: We conducted a
case study with TWT GmbH where we detected the code clones in three Java
systems, set them into relation to information from issue tracking and version
control and interviewed three key developers. Results: Of the type-3 clones, 17
% contain faults. Developers modified most of the type-3 clones simultaneously
and thereby fixed half of the faults in type-3 clones consistently. Type-2
clones with faults all evolved to fixed type-3 clones. Clone length is only
weakly correlated with faultiness. Conclusion: There are indications that the
developers in two cases have been aware of clones. It might be a reason for the
weak relationship between type-3 clones and faults. Hence, it seems important
to keep developers aware of clones, potentially with new tool support. Future
studies need to investigate if the rate of faults in type-3 clones justifies
using them as cues in defect detection.
</dc:description>
 <dc:description>Comment: 11 pages, 0 figures</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08005</dc:identifier>
 <dc:identifier>Proc. 23rd International Conference on Software Analysis,
  Evolution, and Reengineering (SANER). IEEE, 2016</dc:identifier>
 <dc:identifier>doi:10.1109/SANER.2016.94</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08024</identifier>
 <datestamp>2017-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer
  Interfaces</dc:title>
 <dc:creator>Lawhern, Vernon J.</dc:creator>
 <dc:creator>Solon, Amelia J.</dc:creator>
 <dc:creator>Waytowich, Nicholas R.</dc:creator>
 <dc:creator>Gordon, Stephen M.</dc:creator>
 <dc:creator>Hung, Chou P.</dc:creator>
 <dc:creator>Lance, Brent J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Objective: Brain-Computer Interface (BCI) technologies enable direct
communication between humans and computers by analyzing brain measurements,
such as electroencephalography (EEG). BCI processing typically consists of
heuristically extracting features for specific tasks, limiting the
generalizability of the BCI across tasks. Here, we asked whether we can find a
single generalized neural network architecture that can accurately classify EEG
signals in different BCI tasks. Approach: In this work we introduce EEGNet, a
compact fully convolutional network for EEG-based BCIs. We compare EEGNet to
the current state-of-the-art approach across four different BCI classification
tasks: P300 visual-evoked potentials, error-related negativity responses (ERN),
movement-related cortical potentials (MRCP), and sensory motor rhythms (SMR).
We fit 12 different architectures, all with the same number of parameters, to
statistically control for the effect of model size versus model performance.
Results: We show that one particular architecture performed on average the best
over all datasets, suggesting that a generic model can be used for a variety of
BCIs. We also show that EEGNet compares favorably to the current best
state-of-the-art approach for each dataset across all four datasets.
Significance: Our findings suggest that a common simplified architecture,
EEGNet, can provide robust performance across many different BCI modalities.
</dc:description>
 <dc:description>Comment: 19 pages, 5 figures. Revised and resubmitted</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-05-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08034</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Bayesian Learning of Recurrent Neural Networks for Language
  Modeling</dc:title>
 <dc:creator>Gan, Zhe</dc:creator>
 <dc:creator>Li, Chunyuan</dc:creator>
 <dc:creator>Chen, Changyou</dc:creator>
 <dc:creator>Pu, Yunchen</dc:creator>
 <dc:creator>Su, Qinliang</dc:creator>
 <dc:creator>Carin, Lawrence</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recurrent neural networks (RNNs) have shown promising performance for
language modeling. However, traditional training of RNNs using back-propagation
through time often suffers from overfitting. One reason for this is that
stochastic optimization (used for large training sets) does not provide good
estimates of model uncertainty. This paper leverages recent advances in
stochastic gradient Markov Chain Monte Carlo (also appropriate for large
training sets) to learn weight uncertainty in RNNs. It yields a principled
Bayesian learning algorithm, adding gradient noise during training (enhancing
exploration of the model-parameter space) and model averaging when testing.
Extensive experiments on various RNN models and across a broad range of
applications demonstrate the superiority of the proposed approach over
stochastic optimization.
</dc:description>
 <dc:description>Comment: Accepted to ACL 2017</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08035</identifier>
 <datestamp>2017-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automating the Last-Mile for High Performance Dense Linear Algebra</dc:title>
 <dc:creator>Veras, Richard Michael</dc:creator>
 <dc:creator>Low, Tze Meng</dc:creator>
 <dc:creator>Smith, Tyler Michael</dc:creator>
 <dc:creator>van de Geijn, Robert</dc:creator>
 <dc:creator>Franchetti, Franz</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  High performance dense linear algebra (DLA) libraries often rely on a general
matrix multiply (Gemm) kernel that is implemented using assembly or with vector
intrinsics. In particular, the real-valued Gemm kernels provide the
overwhelming fraction of performance for the complex-valued Gemm kernels, along
with the entire level-3 BLAS and many of the real and complex LAPACK routines.
Thus,achieving high performance for the Gemm kernel translates into a high
performance linear algebra stack above this kernel. However, it is a monumental
task for a domain expert to manually implement the kernel for every
library-supported architecture. This leads to the belief that the craft of a
Gemm kernel is more dark art than science. It is this premise that drives the
popularity of autotuning with code generation in the domain of DLA.
  This paper, instead, focuses on an analytical approach to code generation of
the Gemm kernel for different architecture, in order to shed light on the
details or voo-doo required for implementing a high performance Gemm kernel. We
distill the implementation of the kernel into an even smaller kernel, an
outer-product, and analytically determine how available SIMD instructions can
be used to compute the outer-product efficiently. We codify this approach into
a system to automatically generate a high performance SIMD implementation of
the Gemm kernel. Experimental results demonstrate that our approach yields
generated kernels with performance that is competitive with kernels implemented
manually or using empirical search.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-04-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08036</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robotic Grasp Detection using Deep Convolutional Neural Networks</dc:title>
 <dc:creator>Kumra, Sulabh</dc:creator>
 <dc:creator>Kanan, Christopher</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning has significantly advanced computer vision and natural language
processing. While there have been some successes in robotics using deep
learning, it has not been widely adopted. In this paper, we present a novel
robotic grasp detection system that predicts the best grasping pose of a
parallel-plate robotic gripper for novel objects using the RGB-D image of the
scene. The proposed model uses a deep convolutional neural network to extract
features from the scene and then uses a shallow convolutional neural network to
predict the grasp configuration for the object of interest. Our multi-modal
model achieved an accuracy of 89.21% on the standard Cornell Grasp Dataset and
runs at real-time speeds. This redefines the state-of-the-art for robotic grasp
detection.
</dc:description>
 <dc:description>Comment: 8 pages, 9 figures, 2017 IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS 2017)</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08037</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Spatio-Temporal Representation for the Orienteering Problem with
  Time-Varying Profits</dc:title>
 <dc:creator>Ma, Zhibei</dc:creator>
 <dc:creator>Yin, Kai</dc:creator>
 <dc:creator>Liu, Lantao</dc:creator>
 <dc:creator>Sukhatme, Gaurav S.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We consider an orienteering problem (OP) where an agent needs to visit a
series (possibly a subset) of depots, from which the maximal accumulated
profits are desired within given limited time budget. Different from most
existing works where the profits are assumed to be static, in this work we
investigate a variant that has arbitrary time-dependent profits. Specifically,
the profits to be collected change over time and they follow different (e.g.,
independent) time-varying functions. The problem is of inherent nonlinearity
and difficult to solve by existing methods. To tackle the challenge, we present
a simple and effective framework that incorporates time-variations into the
fundamental planning process. Specifically, we propose a deterministic
spatio-temporal representation where both spatial description and temporal
logic are unified into one routing topology. By employing existing basic
sorting and searching algorithms, the routing solutions can be computed in an
extremely efficient way. The proposed method is easy to implement and extensive
numerical results show that our approach is time efficient and generates
near-optimal solutions.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08050</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields</dc:title>
 <dc:creator>Cao, Zhe</dc:creator>
 <dc:creator>Simon, Tomas</dc:creator>
 <dc:creator>Wei, Shih-En</dc:creator>
 <dc:creator>Sheikh, Yaser</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present an approach to efficiently detect the 2D pose of multiple people
in an image. The approach uses a nonparametric representation, which we refer
to as Part Affinity Fields (PAFs), to learn to associate body parts with
individuals in the image. The architecture encodes global context, allowing a
greedy bottom-up parsing step that maintains high accuracy while achieving
realtime performance, irrespective of the number of people in the image. The
architecture is designed to jointly learn part locations and their association
via two branches of the same sequential prediction process. Our method placed
first in the inaugural COCO 2016 keypoints challenge, and significantly exceeds
the previous state-of-the-art result on the MPII Multi-Person benchmark, both
in performance and efficiency.
</dc:description>
 <dc:description>Comment: Accepted as CVPR 2017 Oral. Video result:
  https://youtu.be/pW6nZXeWlGM</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08055</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Scheduling of Multiple Sensors with Packet Length Constraint</dc:title>
 <dc:creator>Wu, Shuang</dc:creator>
 <dc:creator>Ren, Xiaoqiang</dc:creator>
 <dc:creator>Dey, Subhrakanti</dc:creator>
 <dc:creator>Shi, Ling</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper considers the problem of sensory data scheduling of multiple
processes. There are $n$ independent linear time-invariant processes and a
remote estimator monitoring all the processes. Each process is measured by a
sensor, which sends its local state estimate to the remote estimator. The sizes
of the packets are different due to different dimensions of each process, and
thus it may take different lengths of time steps for the sensors to send their
data. Because of bandwidth limitation, only a portion of all the sensors are
allowed to transmit. Our goal is to minimize the average of estimation error
covariance of the whole system at the remote estimator. The problem is
formulated as a Markov decision process (MDP) with average cost over an
infinite time horizon. We prove the existence of a deterministic and stationary
policy for the problem. We also find that the optimal policy has a consistent
behavior and threshold type structure. A numerical example is provided to
illustrate our main results.
</dc:description>
 <dc:description>Comment: IFAC 2017 World Congress (Full version with proofs)</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08056</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Control with Limited Sensing via Empirical Gramians and
  Piecewise Linear Feedback</dc:title>
 <dc:creator>Alaeddini, Atiye</dc:creator>
 <dc:creator>Morgansen, Kristi A.</dc:creator>
 <dc:creator>Mesbahi, Mehran</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper is concerned with the design of optimal control for
finite-dimensional control-affine nonlinear dynamical systems. We introduce an
optimal control problem that specifically optimizes nonlinear observability in
addition to ensuring stability of the closed loop system. A recursive algorithm
is then proposed to obtain an optimal state feedback controller to maximize the
resulting non-quadratic cost functional. The main contribution of the paper is
presenting a control synthesis procedure that provides closed loop asymptotic
stability, on one hand, and empirical observability of the system, as a
transient performance criteria, on the other.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08056</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08060</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On ($1$, $\epsilon$)-Restricted Max-Min Fair Allocation Problem</dc:title>
 <dc:creator>Chan, T-H. Hubert</dc:creator>
 <dc:creator>Tang, Zhihao Gavin</dc:creator>
 <dc:creator>Wu, Xiaowei</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the max-min fair allocation problem in which a set of $m$
indivisible items are to be distributed among $n$ agents such that the minimum
utility among all agents is maximized. In the restricted setting, the utility
of each item $j$ on agent $i$ is either $0$ or some non-negative weight $w_j$.
For this setting, Asadpour et al. showed that a certain configuration-LP can be
used to estimate the optimal value within a factor of $4+\delta$, for any
$\delta&gt;0$, which was recently extended by Annamalai et al. to give a
polynomial-time $13$-approximation algorithm for the problem. For hardness
results, Bezakova and Dani showed that it is \NP-hard to approximate the
problem within any ratio smaller than $2$.
  In this paper we consider the $(1,\epsilon)$-restricted max-min fair
allocation problem in which each item $j$ is either heavy $(w_j = 1)$ or light
$(w_j = \epsilon)$, for some parameter $\epsilon \in (0,1)$. We show that the
$(1,\epsilon)$-restricted case is also \NP-hard to approximate within any ratio
smaller than $2$. Hence, this simple special case is still algorithmically
interesting.
  Using the configuration-LP, we are able to estimate the optimal value of the
problem within a factor of $3+\delta$, for any $\delta&gt;0$. Extending this idea,
we also obtain a quasi-polynomial time $(3+4\epsilon)$-approximation algorithm
and a polynomial time $9$-approximation algorithm. Moreover, we show that as
$\epsilon$ tends to $0$, the approximation ratio of our polynomial-time
algorithm approaches $3+2\sqrt{2}\approx 5.83$.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08061</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recalling Holistic Information for Semantic Segmentation</dc:title>
 <dc:creator>Hu, Hexiang</dc:creator>
 <dc:creator>Deng, Zhiwei</dc:creator>
 <dc:creator>Zhou, Guang-tong</dc:creator>
 <dc:creator>Sha, Fei</dc:creator>
 <dc:creator>Mori, Greg</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Semantic segmentation requires a detailed labeling of image pixels by object
category. Information derived from local image patches is necessary to describe
the detailed shape of individual objects. However, this information is
ambiguous and can result in noisy labels. Global inference of image content can
instead capture the general semantic concepts present. We advocate that
high-recall holistic inference of image concepts provides valuable information
for detailed pixel labeling. We build a two-stream neural network architecture
that facilitates information flow from holistic information to local pixels,
while keeping common image features shared among the low-level layers of both
the holistic analysis and segmentation branches. We empirically evaluate our
network on four standard semantic segmentation datasets. Our network obtains
state-of-the-art performance on PASCAL-Context and NYUDv2, and ablation studies
verify its effectiveness on ADE20K and SIFT-Flow.
</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08066</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structure and algorithms for (cap, even hole)-free graphs</dc:title>
 <dc:creator>Cameron, Kathie</dc:creator>
 <dc:creator>da Silva, Murilo V. G.</dc:creator>
 <dc:creator>Huang, Shenwei</dc:creator>
 <dc:creator>Vu&#x161;kovi&#x107;, Kristina</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A graph is even-hole-free if it has no induced even cycles of length 4 or
more. A cap is a cycle of length at least 5 with exactly one chord and that
chord creates a triangle with the cycle. In this paper, we consider (cap, even
hole)-free graphs, and more generally, (cap, 4-hole)-free odd-signable graphs.
We give an explicit construction of these graphs. We prove that every such
graph $G$ has a vertex of degree at most $\frac{3}{2}\omega (G) -1$, and hence
$\chi(G)\leq \frac{3}{2}\omega (G)$, where $\omega(G)$ denotes the size of a
largest clique in $G$ and $\chi(G)$ denotes the chromatic number of $G$. We
give an $O(nm)$ algorithm for $q$-coloring these graphs for fixed $q$ and an
$O(nm)$ algorithm for maximum weight stable set. We also give a polynomial-time
algorithm for minimum coloring.
  Our algorithms are based on our results that triangle-free odd-signable
graphs have treewidth at most 5 and thus have clique-width at most 48, and that
(cap, 4-hole)-free odd-signable graphs $G$ without clique cutsets have
treewidth at most $6\omega(G)-1$ and clique-width at most 48.
</dc:description>
 <dc:description>Comment: 19pages</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08067</identifier>
 <datestamp>2017-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Heterogeneous Cellular Networks with Spatio-Temporal Traffic: Delay
  Analysis and Scheduling</dc:title>
 <dc:creator>Zhong, Yi</dc:creator>
 <dc:creator>Quek, Tony Q. S.</dc:creator>
 <dc:creator>Ge, Xiaohu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Emergence of new types of services has led to various traffic and diverse
delay requirements in fifth generation (5G) wireless networks. Meeting diverse
delay requirements is one of the most critical goals for the design of 5G
wireless networks. Though the delay of point-to-point communications has been
well investigated, the delay of multi-point to multi-point communications has
not been thoroughly studied since it is a complicated function of all links in
the network. In this work, we propose a novel tractable approach to analyze the
delay in the heterogenous cellular networks with spatio-temporal random arrival
of traffic. Specifically, we propose the notion of \emph{delay outage} and
evaluated the effect of different scheduling policies on the delay performance.
Our numerical analysis reveals that offloading policy based on cell range
expansion greatly reduces the macrocell traffic while bringing a small amount
of growth for the picocell traffic. Our results also show that the delay
performance of round-robin scheduling outperforms first in first out scheduling
for heavy traffic, and it is reversed for light traffic. In summary, this
analytical framework provides an understanding and a rule-of-thumb for the
practical deployment of 5G systems where delay requirement is increasingly
becoming a key concern.
</dc:description>
 <dc:description>Comment: accepted to appear in IEEE Journal on Selected Areas in
  Communications</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08067</dc:identifier>
 <dc:identifier>doi:10.1109/JSAC.2017.2687379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08069</identifier>
 <datestamp>2017-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Fully Convolutional Network for Vehicle Detection in Point Cloud</dc:title>
 <dc:creator>Li, Bo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  2D fully convolutional network has been recently successfully applied to
object detection from images. In this paper, we extend the fully convolutional
network based detection techniques to 3D and apply it to point cloud data. The
proposed approach is verified on the task of vehicle detection from lidar point
cloud for autonomous driving. Experiments on the KITTI dataset shows a
significant performance improvement over the previous point cloud based
detection approaches.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08070</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiscale Inverse Reinforcement Learning using Diffusion Wavelets</dc:title>
 <dc:creator>Ha, Jung-Su</dc:creator>
 <dc:creator>Choi, Han-Lim</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This work presents a multiscale framework to solve an inverse reinforcement
learning (IRL) problem for continuous-time/state stochastic systems. We take
advantage of a diffusion wavelet representation of the associated Markov chain
to abstract the state space. This not only allows for effectively handling the
large (and geometrically complex) decision space but also provides more
interpretable representations of the demonstrated state trajectories and also
of the resulting policy of IRL. In the proposed framework, the problem is
divided into the global and local IRL, where the global approximation of the
optimal value functions are obtained using coarse features and the local
details are quantified using fine local features. An illustrative numerical
example on robot path control in a complex environment is presented to verify
the proposed method.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08079</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DroidLeaks: Benchmarking Resource Leak Bugs for Android Applications</dc:title>
 <dc:creator>Liu, Yepang</dc:creator>
 <dc:creator>Wei, Lili</dc:creator>
 <dc:creator>Xu, Chang</dc:creator>
 <dc:creator>Cheung, Shing-Chi</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Resource leak bugs in Android apps are pervasive and can cause serious
performance degradation and system crashes. In recent years, several resource
leak detection techniques have been proposed to assist Android developers in
correctly managing system resources. Yet, there exist no common bug benchmarks
for effectively and reliably comparing such techniques and quantitatively
evaluating their strengths and weaknesses. This paper describes our initial
contribution towards constructing such a benchmark. To locate real resource
leak bugs, we mined 124,215 code revisions of 34 large-scale open-source
Android apps. We successfully found 298 fixed resource leaks, which cover a
diverse set of resource classes, from 32 out of the 34 apps. To understand the
characteristics of these bugs, we conducted an empirical study, which revealed
the root causes of frequent resource leaks in Android apps and common patterns
of faults made by developers. With our findings, we further implemented a
static checker to detect a common pattern of resource leaks in Android apps.
Experiments showed that the checker can effectively locate real resource leaks
in popular Android apps, confirming the usefulness of our work.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08079</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08083</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Survey of Expressivity in Deep Neural Networks</dc:title>
 <dc:creator>Raghu, Maithra</dc:creator>
 <dc:creator>Poole, Ben</dc:creator>
 <dc:creator>Kleinberg, Jon</dc:creator>
 <dc:creator>Ganguli, Surya</dc:creator>
 <dc:creator>Sohl-Dickstein, Jascha</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We survey results on neural network expressivity described in &quot;On the
Expressive Power of Deep Neural Networks&quot;. The paper motivates and develops
three natural measures of expressiveness, which all display an exponential
dependence on the depth of the network. In fact, all of these measures are
related to a fourth quantity, trajectory length. This quantity grows
exponentially in the depth of the network, and is responsible for the depth
sensitivity observed. These results translate to consequences for networks
during and after training. They suggest that parameters earlier in a network
have greater influence on its expressive power -- in particular, given a layer,
its influence on expressivity is determined by the remaining depth of the
network after that layer. This is verified with experiments on MNIST and
CIFAR-10. We also explore the effect of training on the input-output map, and
find that it trades off between the stability and expressivity.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08086</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Scaling of NFV Service Chains across Geo-distributed Datacenters</dc:title>
 <dc:creator>Jia, Yongzheng</dc:creator>
 <dc:creator>Wu, Chuan</dc:creator>
 <dc:creator>Li, Zongpeng</dc:creator>
 <dc:creator>Le, Franck</dc:creator>
 <dc:creator>Liu, Alex</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Network Function Virtualization (NFV) is an emerging paradigm that turns
hardware-dependent implementation of network functions (i.e., middleboxes) into
software modules running on virtualized platforms, for significant cost
reduction and ease of management. Such virtual network functions (VNFs)
commonly constitute service chains, to provide network services that traffic
flows need to go through. Efficient deployment of VNFs for network service
provisioning is key to realize the NFV goals. Existing efforts on VNF placement
mostly deal with offline or one-time placement, ignoring the fundamental,
dynamic deployment and scaling need of VNFs to handle practical time-varying
traffic volumes. This work investigates dynamic placement of VNF service chains
across geo-distributed datacenters to serve flows between dispersed source and
destination pairs, for operational cost minimization of the service chain
provider over the entire system span. An efficient online algorithm is
proposed, which consists of two main components: (1) A regularization-based
approach from online learning literature to convert the offline optimal
deployment problem into a sequence of one-shot regularized problems, each to be
efficiently solved in one time slot; (2) An online dependent rounding scheme to
derive feasible integer solutions from the optimal fractional solutions of the
one-shot problems, and to guarantee a good competitive ratio of the online
algorithm over the entire time span. We verify our online algorithm with solid
theoretical analysis and trace-driven simulations under realistic settings.
</dc:description>
 <dc:description>Comment: 14pages, 8 figures</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08091</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Joint Face Hallucination and Recognition</dc:title>
 <dc:creator>Wu, Junyu</dc:creator>
 <dc:creator>Ding, Shengyong</dc:creator>
 <dc:creator>Xu, Wei</dc:creator>
 <dc:creator>Chao, Hongyang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep models have achieved impressive performance for face hallucination
tasks. However, we observe that directly feeding the hallucinated facial images
into recog- nition models can even degrade the recognition performance despite
the much better visualization quality. In this paper, we address this problem
by jointly learning a deep model for two tasks, i.e. face hallucination and
recognition. In particular, we design an end-to-end deep convolution network
with hallucination sub-network cascaded by recognition sub-network. The
recognition sub- network are responsible for producing discriminative feature
representations using the hallucinated images as inputs generated by
hallucination sub-network. During training, we feed LR facial images into the
network and optimize the parameters by minimizing two loss items, i.e. 1) face
hallucination loss measured by the pixel wise difference between the ground
truth HR images and network-generated images; and 2) verification loss which is
measured by the classification error and intra-class distance. We extensively
evaluate our method on LFW and YTF datasets. The experimental results show that
our method can achieve recognition accuracy 97.95% on 4x down-sampled LFW
testing set, outperforming the accuracy 96.35% of conventional face recognition
model. And on the more challenging YTF dataset, we achieve recognition accuracy
90.65%, a margin over the recognition accuracy 89.45% obtained by conventional
face recognition model on the 4x down-sampled version.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08096</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User Personalized Satisfaction Prediction via Multiple Instance Deep
  Learning</dc:title>
 <dc:creator>Chen, Zheqian</dc:creator>
 <dc:creator>Gao, Ben</dc:creator>
 <dc:creator>Zhang, Huimin</dc:creator>
 <dc:creator>Zhao, Zhou</dc:creator>
 <dc:creator>Cai, Deng</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Community based question answering services have arisen as a popular
knowledge sharing pattern for netizens. With abundant interactions among users,
individuals are capable of obtaining satisfactory information. However, it is
not effective for users to attain answers within minutes. Users have to check
the progress over time until the satisfying answers submitted. We address this
problem as a user personalized satisfaction prediction task. Existing methods
usually exploit manual feature selection. It is not desirable as it requires
careful design and is labor intensive. In this paper, we settle this issue by
developing a new multiple instance deep learning framework. Specifically, in
our settings, each question follows a weakly supervised learning multiple
instance learning assumption, where its obtained answers can be regarded as
instance sets and we define the question resolved with at least one
satisfactory answer. We thus design an efficient framework exploiting multiple
instance learning property with deep learning to model the question answer
pairs. Extensive experiments on large scale datasets from Stack Exchange
demonstrate the feasibility of our proposed framework in predicting askers
personalized satisfaction. Our framework can be extended to numerous
applications such as UI satisfaction Prediction, multi armed bandit problem,
expert finding and so on.
</dc:description>
 <dc:description>Comment: draft for www</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08096</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08097</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometric deep learning: going beyond Euclidean data</dc:title>
 <dc:creator>Bronstein, Michael M.</dc:creator>
 <dc:creator>Bruna, Joan</dc:creator>
 <dc:creator>LeCun, Yann</dc:creator>
 <dc:creator>Szlam, Arthur</dc:creator>
 <dc:creator>Vandergheynst, Pierre</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Many scientific fields study data with an underlying structure that is a
non-Euclidean space. Some examples include social networks in computational
social sciences, sensor networks in communications, functional networks in
brain imaging, regulatory networks in genetics, and meshed surfaces in computer
graphics. In many applications, such geometric data are large and complex (in
the case of social networks, on the scale of billions), and are natural targets
for machine learning techniques. In particular, we would like to use deep
neural networks, which have recently proven to be powerful tools for a broad
range of problems from computer vision, natural language processing, and audio
analysis. However, these tools have been most successful on data with an
underlying Euclidean or grid-like structure, and in cases where the invariances
of these structures are built into networks used to model them. Geometric deep
learning is an umbrella term for emerging techniques attempting to generalize
(structured) deep neural models to non-Euclidean domains such as graphs and
manifolds. The purpose of this paper is to overview different examples of
geometric deep learning problems and present available solutions, key
difficulties, applications, and future research directions in this nascent
field.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-05-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08097</dc:identifier>
 <dc:identifier>doi:10.1109/MSP.2017.2693418</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08098</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Feasibility of Attribute-Based Encryption on Internet of Things
  Devices</dc:title>
 <dc:creator>Ambrosin, Moreno</dc:creator>
 <dc:creator>Anzanpour, Arman</dc:creator>
 <dc:creator>Conti, Mauro</dc:creator>
 <dc:creator>Dargahi, Tooska</dc:creator>
 <dc:creator>Moosavi, Sanaz Rahimi</dc:creator>
 <dc:creator>Rahmani, Amir M.</dc:creator>
 <dc:creator>Liljeberg, Pasi</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Attribute-Based Encryption (ABE) could be an effective cryptographic tool for
the secure management of Internet-of-Things (IoT) devices, but its feasibility
in the IoT has been under-investigated thus far. This article explores such
feasibility for well-known IoT platforms, namely, Intel Galileo Gen 2, Intel
Edison, Raspberry Pi 1 Model B, and Raspberry Pi Zero, and concludes that
adopting ABE in the IoT is indeed feasible.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08098</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08103</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Double-quantitative $\gamma^{\ast}-$fuzzy coverings approximation
  operators</dc:title>
 <dc:creator>Lang, Guangming</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In digital-based information boom, the fuzzy covering rough set model is an
important mathematical tool for artificial intelligence, and how to build the
bridge between the fuzzy covering rough set theory and Pawlak's model is
becoming a hot research topic. In this paper, we first present the
$\gamma-$fuzzy covering based probabilistic and grade approximation operators
and double-quantitative approximation operators. We also study the
relationships among the three types of $\gamma-$fuzzy covering based
approximation operators. Second, we propose the $\gamma^{\ast}-$fuzzy coverings
based multi-granulation probabilistic and grade lower and upper approximation
operators and multi-granulation double-quantitative lower and upper
approximation operators. We also investigate the relationships among these
types of $\gamma-$fuzzy coverings based approximation operators. Finally, we
employ several examples to illustrate how to construct the lower and upper
approximations of fuzzy sets with the absolute and relative quantitative
information.
</dc:description>
 <dc:description>Comment: It enriches the fuzzy covering rough set theory</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08104</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Enhanced Inference in Markov Logic Networks</dc:title>
 <dc:creator>Wittek, Peter</dc:creator>
 <dc:creator>Gogolin, Christian</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  Markov logic networks (MLNs) reconcile two opposing schools in machine
learning and artificial intelligence: causal networks, which account for
uncertainty extremely well, and first-order logic, which allows for formal
deduction. An MLN is essentially a first-order logic template to generate
Markov networks. Inference in MLNs is probabilistic and it is often performed
by approximate methods such as Markov chain Monte Carlo (MCMC) Gibbs sampling.
An MLN has many regular, symmetric structures that can be exploited at both
first-order level and in the generated Markov network. We analyze the graph
structures that are produced by various lifting methods and investigate the
extent to which quantum protocols can be used to speed up Gibbs sampling with
state preparation and measurement schemes. We review different such approaches,
discuss their advantages, theoretical limitations, and their appeal to
implementations. We find that a straightforward application of a recent result
yields exponential speedup compared to classical heuristics in approximate
probabilistic inference, thereby demonstrating another example where advanced
quantum resources can potentially prove useful in machine learning.
</dc:description>
 <dc:description>Comment: 8 pages, 1 figure</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08104</dc:identifier>
 <dc:identifier>Scientific Reports 7, 45672 (2017)</dc:identifier>
 <dc:identifier>doi:10.1038/srep45672</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08107</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatically Building Face Datasets of New Domains from Weakly Labeled
  Data with Pretrained Models</dc:title>
 <dc:creator>Ding, Shengyong</dc:creator>
 <dc:creator>Wu, Junyu</dc:creator>
 <dc:creator>Xu, Wei</dc:creator>
 <dc:creator>Chao, Hongyang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Training data are critical in face recognition systems. However, labeling a
large scale face data for a particular domain is very tedious. In this paper,
we propose a method to automatically and incrementally construct datasets from
massive weakly labeled data of the target domain which are readily available on
the Internet under the help of a pretrained face model. More specifically,
given a large scale weakly labeled dataset in which each face image is
associated with a label, i.e. the name of an identity, we create a graph for
each identity with edges linking matched faces verified by the existing model
under a tight threshold. Then we use the maximal subgraph as the cleaned data
for that identity. With the cleaned dataset, we update the existing face model
and use the new model to filter the original dataset to get a larger cleaned
dataset. We collect a large weakly labeled dataset containing 530,560 Asian
face images of 7,962 identities from the Internet, which will be published for
the study of face recognition. By running the filtering process, we obtain a
cleaned datasets (99.7+% purity) of size 223,767 (recall 70.9%). On our testing
dataset of Asian faces, the model trained by the cleaned dataset achieves
recognition rate 93.1%, which obviously outperforms the model trained by the
public dataset CASIA whose recognition rate is 85.9%.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08108</identifier>
 <datestamp>2017-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Key-Value Memory Networks for Knowledge Tracing</dc:title>
 <dc:creator>Zhang, Jiani</dc:creator>
 <dc:creator>Shi, Xingjian</dc:creator>
 <dc:creator>King, Irwin</dc:creator>
 <dc:creator>Yeung, Dit-Yan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Knowledge Tracing (KT) is a task of tracing evolving knowledge state of
students with respect to one or more concepts as they engage in a sequence of
learning activities. One important purpose of KT is to personalize the practice
sequence to help students learn knowledge concepts efficiently. However,
existing methods such as Bayesian Knowledge Tracing and Deep Knowledge Tracing
either model knowledge state for each predefined concept separately or fail to
pinpoint exactly which concepts a student is good at or unfamiliar with. To
solve these problems, this work introduces a new model called Dynamic Key-Value
Memory Networks (DKVMN) that can exploit the relationships between underlying
concepts and directly output a student's mastery level of each concept. Unlike
standard memory-augmented neural networks that facilitate a single memory
matrix or two static memory matrices, our model has one static matrix called
key, which stores the knowledge concepts and the other dynamic matrix called
value, which stores and updates the mastery levels of corresponding concepts.
Experiments show that our model consistently outperforms the state-of-the-art
model in a range of KT datasets. Moreover, the DKVMN model can automatically
discover underlying concepts of exercises typically performed by human
annotations and depict the changing knowledge state of a student.
</dc:description>
 <dc:description>Comment: To appear in 26th International Conference on World Wide Web (WWW),
  2017</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-02-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08108</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08120</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Codes from Fibonacci Polynomials and Secret Sharing Schemes</dc:title>
 <dc:creator>Koroglu, Mehmet E.</dc:creator>
 <dc:creator>Ozbek, Ibrahim</dc:creator>
 <dc:creator>Siap, Irfan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, we study cyclic codes that have generators as Fibonacci
polynomials over finite fields. We show that these cyclic codes in most cases
produce families of maximum distance separable and optimal codes with
interesting properties. We explore these relations and present some examples.
Also, we present applications of these codes to secret sharing schemes.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08120</dc:identifier>
 <dc:identifier>Arab. J. Math. (2017)</dc:identifier>
 <dc:identifier>doi:10.1007/s40065-017-0171-7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08131</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extraction of airway trees using multiple hypothesis tracking and
  template matching</dc:title>
 <dc:creator>Selvan, Raghavendra</dc:creator>
 <dc:creator>Petersen, Jens</dc:creator>
 <dc:creator>Pedersen, Jesper H.</dc:creator>
 <dc:creator>de Bruijne, Marleen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Knowledge of airway tree morphology has important clinical applications in
diagnosis of chronic obstructive pulmonary disease. We present an automatic
tree extraction method based on multiple hypothesis tracking and template
matching for this purpose and evaluate its performance on chest CT images. The
method is adapted from a semi-automatic method devised for vessel segmentation.
Idealized tubular templates are constructed that match airway probability
obtained from a trained classifier and ranked based on their relative
significance. Several such regularly spaced templates form the local hypotheses
used in constructing a multiple hypothesis tree, which is then traversed to
reach decisions. The proposed modifications remove the need for local
thresholding of hypotheses as decisions are made entirely based on statistical
comparisons involving the hypothesis tree. The results show improvements in
performance when compared to the original method and region growing on
intensity images. We also compare the method with region growing on the
probability images, where the presented method does not show substantial
improvement, but we expect it to be less sensitive to local anomalies in the
data.
</dc:description>
 <dc:description>Comment: 12 pages. Presented at the MICCAI Pulmonary Image Analysis Workshop,
  Athens, Greece, 2016</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08134</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparative study of histogram distance measures for re-identification</dc:title>
 <dc:creator>Mar&#xed;n-Reyes, Pedro A.</dc:creator>
 <dc:creator>Lorenzo-Navarro, Javier</dc:creator>
 <dc:creator>Castrill&#xf3;n-Santana, Modesto</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Color based re-identification methods usually rely on a distance function to
measure the similarity between individuals. In this paper we study the behavior
of several histogram distance measures in different color spaces. We wonder
whether there is a particular histogram distance measure better than others,
likewise also, if there is a color space that present better discrimination
features. Several experiments are designed and evaluated in several images to
obtain measures against various color spaces. We test in several image
databases. A measure ranking is generated to calculate the area under the CMC,
this area is the indicator used to evaluate which distance measure and color
space present the best performance for the considered databases. Also, other
parameters such as the image division in horizontal stripes and number of
histogram bins, have been studied.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08135</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Question Retrieval for Community-based Question Answering via
  Heterogeneous Network Integration Learning</dc:title>
 <dc:creator>Chen, Zheqian</dc:creator>
 <dc:creator>Zhang, Chi</dc:creator>
 <dc:creator>Zhao, Zhou</dc:creator>
 <dc:creator>Cai, Deng</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Community based question answering platforms have attracted substantial users
to share knowledge and learn from each other. As the rapid enlargement of CQA
platforms, quantities of overlapped questions emerge, which makes users
confounded to select a proper reference. It is urgent for us to take effective
automated algorithms to reuse historical questions with corresponding answers.
In this paper we focus on the problem with question retrieval, which aims to
match historical questions that are relevant or semantically equivalent to
resolve one s query directly. The challenges in this task are the lexical gaps
between questions for the word ambiguity and word mismatch problem.
Furthermore, limited words in queried sentences cause sparsity of word
features. To alleviate these challenges, we propose a novel framework named
HNIL which encodes not only the question contents but also the askers social
interactions to enhance the question embedding performance. More specifically,
we apply random walk based learning method with recurrent neural network to
match the similarities between askers question and historical questions
proposed by other users. Extensive experiments on a large scale dataset from a
real world CQA site show that employing the heterogeneous social network
information outperforms the other state of the art solutions in this task.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08135</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08144</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How I Stopped Worrying about the Twitter Archive at the Library of
  Congress and Learned to Build a Little One for Myself</dc:title>
 <dc:creator>Gayo-Avello, Daniel</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Twitter is among the commonest sources of data employed in social media
research mainly because of its convenient APIs to collect tweets. However, most
researchers do not have access to the expensive Firehose and Twitter Historical
Archive, and they must rely on data collected with free APIs whose
representativeness has been questioned. In 2010 the Library of Congress
announced an agreement with Twitter to provide researchers access to the whole
Twitter Archive. However, such a task proved to be daunting and, at the moment
of this writing, no researcher has had the opportunity to access such
materials. Still, there have been experiences that proved that smaller
searchable archives are feasible and, therefore, amenable for academics to
build with relatively little resources. In this paper I describe my efforts to
build one of such archives, covering the first three years of Twitter (actually
from March 2006 to July 2009) and containing 1.48 billion tweets. If you
carefully follow my directions you may have your very own little Twitter
Historical Archive and you may forget about paying for historical tweets.
Please note that to achieve that you should be proficient in some programming
language, knowable about Twitter APIs, and have some basic knowledge on
ElasticSearch; moreover, you may very well get disappointed by the quality of
the contents of the final dataset.
</dc:description>
 <dc:description>Comment: 22 pages, 13 figures</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08154</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AutoGain: Adapting Gain Functions by Optimizing Submovement Efficiency</dc:title>
 <dc:creator>Lee, Byungjoo</dc:creator>
 <dc:creator>Nancel, Mathieu</dc:creator>
 <dc:creator>Oulasvirta, Antti</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.m</dc:subject>
 <dc:description>  A well-designed control-to-display (CD) gain function can improve pointing
performance with an indirect pointing device such as a trackpad. However, the
design of gain functions has been challenging and mostly based on trial and
error. AutoGain is an unobtrusive method to obtain a gain function for an
indirect pointing device in contexts where cursor trajectories can be tracked.
It gradually improves pointing efficiency by using a novel submovement-level
tracking+optimization technique. In a study, we show that AutoGain can produce
gain functions with performance comparable to commercial designs in less than a
half hour of active use. This is attributable to reductions in aiming error
(undershooting/overshooting) for each submovement. Our second study shows that
AutoGain can be used to obtain gain functions for emerging input devices (here,
a Leap Motion controller) for which no good gain function may exist yet.
Finally, we discuss deployment in a real interactive system.
</dc:description>
 <dc:description>Comment: 12 pages, 12 figures</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08175</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neyman-Pearson Test for Zero-Rate Multiterminal Hypothesis Testing</dc:title>
 <dc:creator>Watanabe, Shun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The problem of zero-rate multiterminal hypothesis testing is revisited from
the perspective of information-spectrum approach and finite blocklength
analysis. A Neyman-Pearson-like test is proposed and its non-asymptotic
performance is clarified; for a short block length, it is numerically
determined that the proposed test is superior to the previously reported
Hoeffding-like test proposed by Han-Kobayashi. For a large deviation regime, it
is shown that our proposed test achieves an optimal trade-off between the type
I and type II exponents presented by Han-Kobayashi. Among the class of
symmetric (type based) testing schemes, when the type I error probability is
non-vanishing, the proposed test is optimal up to the second-order term of the
type II error exponent; the latter term is characterized in terms of the
variance of the projected relative entropy density. The information geometry
method plays an important role in the analysis as well as the construction of
the test.
</dc:description>
 <dc:description>Comment: 34 pages, 8 figures</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08178</identifier>
 <datestamp>2017-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Associative nature of event participation dynamics: a network theory
  approach</dc:title>
 <dc:creator>Smiljani&#x107;, Jelena</dc:creator>
 <dc:creator>Dankulov, Marija Mitrovi&#x107;</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The affiliation with various social groups can be a critical factor when it
comes to quality of life of each individual, making such groups an essential
element of every society. The group dynamics, longevity and effectiveness
strongly depend on group's ability to attract new members and keep them engaged
in group activities. It was shown that high heterogeneity of scientist's
engagement in conference activities of the specific scientific community
depends on the balance between the numbers of previous attendances and
non-attendances and is directly related to scientist's association with that
community. Here we show that the same holds for leisure groups of the Meetup
website and further quantify individual members' association with the group. We
examine how structure of personal social networks is evolving with the event
attendance. Our results show that member's increasing engagement in the group
activities is primarily associated with the strengthening of already existing
ties and increase in the bonding social capital. We also show that Meetup
social networks mostly grow trough big events, while small events contribute to
the groups cohesiveness.
</dc:description>
 <dc:description>Comment: 16 pages, 6 figs + Supporting information 7 pages, 8 figs</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-02-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08178</dc:identifier>
 <dc:identifier>PLOS ONE 12 (2017) e0171565</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0171565</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08191</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpreting the Predictions of Complex ML Models by Layer-wise
  Relevance Propagation</dc:title>
 <dc:creator>Samek, Wojciech</dc:creator>
 <dc:creator>Montavon, Gr&#xe9;goire</dc:creator>
 <dc:creator>Binder, Alexander</dc:creator>
 <dc:creator>Lapuschkin, Sebastian</dc:creator>
 <dc:creator>M&#xfc;ller, Klaus-Robert</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Complex nonlinear models such as deep neural network (DNNs) have become an
important tool for image classification, speech recognition, natural language
processing, and many other fields of application. These models however lack
transparency due to their complex nonlinear structure and to the complex data
distributions to which they typically apply. As a result, it is difficult to
fully characterize what makes these models reach a particular decision for a
given input. This lack of transparency can be a drawback, especially in the
context of sensitive applications such as medical analysis or security. In this
short paper, we summarize a recent technique introduced by Bach et al. [1] that
explains predictions by decomposing the classification decision of DNN models
in terms of input variables.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08194</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interferences in match kernels</dc:title>
 <dc:creator>Murray, Naila</dc:creator>
 <dc:creator>J&#xe9;gou, Herv&#xe9;</dc:creator>
 <dc:creator>Perronnin, Florent</dc:creator>
 <dc:creator>Zisserman, Andrew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We consider the design of an image representation that embeds and aggregates
a set of local descriptors into a single vector. Popular representations of
this kind include the bag-of-visual-words, the Fisher vector and the VLAD. When
two such image representations are compared with the dot-product, the
image-to-image similarity can be interpreted as a match kernel. In match
kernels, one has to deal with interference, i.e. with the fact that even if two
descriptors are unrelated, their matching score may contribute to the overall
similarity.
  We formalise this problem and propose two related solutions, both aimed at
equalising the individual contributions of the local descriptors in the final
representation. These methods modify the aggregation stage by including a set
of per-descriptor weights. They differ by the objective function that is
optimised to compute those weights. The first is a &quot;democratisation&quot; strategy
that aims at equalising the relative importance of each descriptor in the set
comparison metric. The second one involves equalising the match of a single
descriptor to the aggregated vector.
  These concurrent methods give a substantial performance boost over the state
of the art in image search with short or mid-size vectors, as demonstrated by
our experiments on standard public image retrieval benchmarks.
</dc:description>
 <dc:description>Comment: Accepted as regular paper in IEEE Transactions on Pattern Analysis
  and Machine Intelligence (TPAMI)</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08195</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Domain Adaptation by Mixture of Alignments of Second- or Higher-Order
  Scatter Tensors</dc:title>
 <dc:creator>Koniusz, Piotr</dc:creator>
 <dc:creator>Tas, Yusuf</dc:creator>
 <dc:creator>Porikli, Fatih</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose an approach to the domain adaptation, dubbed
Second- or Higher-order Transfer of Knowledge (So-HoT), based on the mixture of
alignments of second- or higher-order scatter statistics between the source and
target domains. The human ability to learn from few labeled samples is a
recurring motivation in the literature for domain adaptation. Towards this end,
we investigate the supervised target scenario for which few labeled target
training samples per category exist. Specifically, we utilize two CNN streams:
the source and target networks fused at the classifier level. Features from the
fully connected layers fc7 of each network are used to compute second- or even
higher-order scatter tensors; one per network stream per class. As the source
and target distributions are somewhat different despite being related, we align
the scatters of the two network streams of the same class (within-class
scatters) to a desired degree with our bespoke loss while maintaining good
separation of the between-class scatters. We train the entire network in
end-to-end fashion. We provide evaluations on the standard Office benchmark
(visual domains), RGB-D combined with Caltech256 (depth-to-rgb transfer) and
Pascal VOC2007 combined with the TU Berlin dataset (image-to-sketch transfer).
We attain state-of-the-art results.
</dc:description>
 <dc:description>Comment: CVPR'17</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08195</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08198</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Burrows-Wheeler transform and LCP array construction in constant space</dc:title>
 <dc:creator>Louza, Felipe A.</dc:creator>
 <dc:creator>Gagie, Travis</dc:creator>
 <dc:creator>Telles, Guilherme P.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this article we extend the elegant in-place Burrows-Wheeler transform
(BWT) algorithm proposed by Crochemore et al. (Crochemore et al., 2015). Our
extension is twofold: we first show how to compute simultaneously the longest
common prefix (LCP) array as well as the BWT, using constant additional space;
we then show how to build the LCP array directly in compressed representation
using Elias coding, still using constant additional space and with no
asymptotic slowdown. Furthermore, we provide a time/space tradeoff for our
algorithm when additional memory is allowed. Our algorithm runs in quadratic
time, as does Crochemore et al.'s, and is supported by interesting properties
of the BWT and of the LCP array, contributing to our understanding of the
time/space tradeoff curve for building indexing structures.
</dc:description>
 <dc:description>Comment: Accepted to JDA</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08198</dc:identifier>
 <dc:identifier>doi:10.1016/j.jda.2016.11.003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08204</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Perpetually Dominating Large Grids</dc:title>
 <dc:creator>Lamprou, Ioannis</dc:creator>
 <dc:creator>Martin, Russell</dc:creator>
 <dc:creator>Schewe, Sven</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  In the \emph{Eternal Domination} game, a team of guard tokens initially
occupies a dominating set on a graph $G$. A rioter then picks a node without a
guard on it and attacks it. The guards defend against the attack: one of them
has to move to the attacked node, while each remaining one can choose to move
to one of his neighboring nodes. The new guards' placement must again be
dominating. This attack-defend procedure continues perpetually. The guards win
if they can eternally maintain a dominating set against any sequence of
attacks, otherwise, the rioter wins. We study rectangular grids and provide the
first known general upper bound for these graphs. Our novel strategy implements
a square rotation principle and eternally dominates $m \times n$ grids by using
approximately $\frac{mn}{5}$ guards, which is asymptotically optimal even for
ordinary domination.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08207</identifier>
 <datestamp>2017-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Texture Synthesis with Spatial Generative Adversarial Networks</dc:title>
 <dc:creator>Jetchev, Nikolay</dc:creator>
 <dc:creator>Bergmann, Urs</dc:creator>
 <dc:creator>Vollgraf, Roland</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Generative adversarial networks (GANs) are a recent approach to train
generative models of data, which have been shown to work particularly well on
image data. In the current paper we introduce a new model for texture synthesis
based on GAN learning. By extending the input noise distribution space from a
single vector to a whole spatial tensor, we create an architecture with
properties well suited to the task of texture synthesis, which we call spatial
GAN (SGAN). To our knowledge, this is the first successful completely
data-driven texture synthesis method based on GANs.
  Our method has the following features which make it a state of the art
algorithm for texture synthesis: high image quality of the generated textures,
very high scalability w.r.t. the output texture size, fast real-time forward
generation, the ability to fuse multiple diverse source images in complex
textures. To illustrate these capabilities we present multiple experiments with
different classes of texture images and use cases. We also discuss some
limitations of our method with respect to the types of texture images it can
synthesize, and compare it to other neural techniques for texture generation.
</dc:description>
 <dc:description>Comment: presented at the NIPS 2016 adversarial learning workshop, Barcelona,
  Spain</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-09-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08208</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The problem of Pi_2-cut-introduction</dc:title>
 <dc:creator>Leitsch, Alexander</dc:creator>
 <dc:creator>Lettmann, Michael Peter</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  We describe an algorithmic method of proof compression based on the
introduction of Pi_2-cuts into a cut-free LK-proof. The current approach is
based on an inversion of Gentzen s cut-elimination method and extends former
methods for introducing Pi_1-cuts. The Herbrand instances of a cut-free proof
pi of a sequent S are described by a grammar G which encodes substitutions
defined in the elimination of quantified cuts. We present an algorithm which,
given a grammar G, constructs a Pi_2-cut formula A and a proof phi of S with
one cut on A. It is shown that, by this algorithm, we can achieve an
exponential proof compression.
</dc:description>
 <dc:description>Comment: 52 pages</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08208</dc:identifier>
 <dc:identifier>doi:10.1016/j.tcs.2017.10.003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08209</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Search on a Line by Byzantine Robots</dc:title>
 <dc:creator>Czyzowicz, Jurek</dc:creator>
 <dc:creator>Georgiou, Konstantinos</dc:creator>
 <dc:creator>Kranakis, Evangelos</dc:creator>
 <dc:creator>Krizanc, Danny</dc:creator>
 <dc:creator>Narayanan, Lata</dc:creator>
 <dc:creator>Opatrny, Jaroslav</dc:creator>
 <dc:creator>Shende, Sunil</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We consider the problem of fault-tolerant parallel search on an infinite line
by $n$ robots. Starting from the origin, the robots are required to find a
target at an unknown location. The robots can move with maximum speed $1$ and
can communicate in wireless mode among themselves. However, among the $n$
robots, there are $f$ robots that exhibit {\em byzantine faults}. A faulty
robot can fail to report the target even after reaching it, or it can make
malicious claims about having found the target when in fact it has not. Given
the presence of such faulty robots, the search for the target can only be
concluded when the non-faulty robots have sufficient verification that the
target has been found. We aim to design algorithms that minimize the value of
$S_d(n,f)$, the time to find a target at a distance $d$ from the origin by $n$
robots among which $f$ are faulty. We give several different algorithms whose
running time depends on the ratio $f/n$, the density of faulty robots, and also
prove lower bounds. Our algorithms are optimal for some densities of faulty
robots.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08209</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08212</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interference alignment for downlink cellular networks: Joint scheduling
  and precoding</dc:title>
 <dc:creator>Fadlallah, Yasser</dc:creator>
 <dc:creator>Ferrand, Paul</dc:creator>
 <dc:creator>Cardoso, Leonardo</dc:creator>
 <dc:creator>Gorce, Jean-Marie</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Interference Alignment (IA) is technique that, in a large sense, makes use of
the increasing signal dimensions available in the system through MIMO and OFDM
technologies in order to globally reduce the interference suffered by users in
a network. In this paper, we address the problem of downlink cellular networks,
the so-called interfering broadcast channels, where mobile users at cell edges
may suffer from high interference and thus, poor performance. Starting from the
downlink IA scheme proposed by Suh et al., a new approach is proposed where
each user feeds back multiple selected received signal directions with high
signal-to-interference gain. A exhaustive search based scheduler selects a
subset of users to be served simultaneously, balancing between sum-rate
performance and fairness, but becomes untractable in dense network scenarios
where many users send simultaneous requests. Therefore, we develop a
sub-optimal scheduler that greatly decreases the complexity while preserving a
near-optimal data rate gain. More interestingly, our simulations show that the
IA scheme becomes valuable only in correlated channels, whereas the matched
filtering based scheme performs the best in the uncorrelated scenarios.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08212</dc:identifier>
 <dc:identifier>IEEE 17th International Workshop onSignal Processing Advances in
  Wireless Communications (SPAWC), Jul 2016, Edinburgh, United Kingdom. pp.1 -
  5, 2016</dc:identifier>
 <dc:identifier>doi:10.1109/SPAWC.2016.7536752</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08215</identifier>
 <datestamp>2017-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Where to Attend Like a Human Driver</dc:title>
 <dc:creator>Palazzi, Andrea</dc:creator>
 <dc:creator>Solera, Francesco</dc:creator>
 <dc:creator>Calderara, Simone</dc:creator>
 <dc:creator>Alletto, Stefano</dc:creator>
 <dc:creator>Cucchiara, Rita</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Despite the advent of autonomous cars, it's likely - at least in the near
future - that human attention will still maintain a central role as a guarantee
in terms of legal responsibility during the driving task. In this paper we
study the dynamics of the driver's gaze and use it as a proxy to understand
related attentional mechanisms. First, we build our analysis upon two
questions: where and what the driver is looking at? Second, we model the
driver's gaze by training a coarse-to-fine convolutional network on short
sequences extracted from the DR(eye)VE dataset. Experimental comparison against
different baselines reveal that the driver's gaze can indeed be learnt to some
extent, despite i) being highly subjective and ii) having only one driver's
gaze available for each sequence due to the irreproducibility of the scene.
Eventually, we advocate for a new assisted driving paradigm which suggests to
the driver, with no intervention, where she should focus her attention.
</dc:description>
 <dc:description>Comment: To appear in IEEE Intelligent Vehicles Symposium 2017</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-05-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08219</identifier>
 <datestamp>2017-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Off-Switch Game</dc:title>
 <dc:creator>Hadfield-Menell, Dylan</dc:creator>
 <dc:creator>Dragan, Anca</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:creator>Russell, Stuart</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  It is clear that one of the primary tools we can use to mitigate the
potential risk from a misbehaving AI system is the ability to turn the system
off. As the capabilities of AI systems improve, it is important to ensure that
such systems do not adopt subgoals that prevent a human from switching them
off. This is a challenge because many formulations of rational agents create
strong incentives for self-preservation. This is not caused by a built-in
instinct, but because a rational agent will maximize expected utility and
cannot achieve whatever objective it has been given if it is dead. Our goal is
to study the incentives an agent has to allow itself to be switched off. We
analyze a simple game between a human H and a robot R, where H can press R's
off switch but R can disable the off switch. A traditional agent takes its
reward function for granted: we show that such agents have an incentive to
disable the off switch, except in the special case where H is perfectly
rational. Our key insight is that for R to want to preserve its off switch, it
needs to be uncertain about the utility associated with the outcome, and to
treat H's actions as important observations about that utility. (R also has no
incentive to switch itself off in this setting.) We conclude that giving
machines an appropriate level of uncertainty about their objectives leads to
safer designs, and we argue that this setting is a useful generalization of the
classical AI paradigm of rational agents.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08219</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08220</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressive Data Aggregation on Mobile Wireless Sensor Networks for
  Sensing in Bike Races</dc:title>
 <dc:creator>Du, Wei</dc:creator>
 <dc:creator>Gorce, Jean-Marie</dc:creator>
 <dc:creator>Risset, Tanguy</dc:creator>
 <dc:creator>Lauzier, Matthieu</dc:creator>
 <dc:creator>Fraboulet, Antoine</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  -This paper presents an efficient approach to data collection in mobile
wireless sensor networks, with the specific application of sensing in bike
races. Recent sensor technology permits to track GPS position of each bike.
Because of the inherent correlation between bike positions in a bike race, a
simple GPS log is inefficient. The idea presented in this work is to aggregate
GPS data at sensors using compressive sensing techniques. We enforce, in
addition to signal sparsity, a spatial prior on biker motion because of the
group behaviour (peloton) in bike races. The spatial prior is modeled by a
graphical model and the data aggregation problem is solved, with both the
sparsity and the spatial prior, by belief propagation. We validate our approach
on a bike race simulator using trajectories of motorbikes in a real bike race,
the &quot;crit{\'e}rium du dauphin{\'e} 20XX&quot; .
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08220</dc:identifier>
 <dc:identifier>European Signal Processing Conference (EUSIPCO 2016), Aug 2016,
  Budapest, Hungary</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08222</identifier>
 <datestamp>2016-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Stochastic Sensor Network Scheduling for Multiple Processes</dc:title>
 <dc:creator>Han, Duo</dc:creator>
 <dc:creator>Wu, Junfeng</dc:creator>
 <dc:creator>Mo, Yilin</dc:creator>
 <dc:creator>Xie, Lihua</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We consider the problem of multiple sensor scheduling for remote state
estimation of multiple process over a shared link. In this problem, a set of
sensors monitor mutually independent dynamical systems in parallel but only one
sensor can access the shared channel at each time to transmit the data packet
to the estimator. We propose a stochastic event-based sensor scheduling in
which each sensor makes transmission decisions based on both channel
accessibility and distributed event-triggering conditions. The corresponding
minimum mean squared error (MMSE) estimator is explicitly given. Considering
information patterns accessed by sensor schedulers, time-based ones can be
treated as a special case of the proposed one. By ultilizing realtime
information, the proposed schedule outperforms the time-based ones in terms of
the estimation quality. Resorting to solving an Markov decision process (MDP)
problem with average cost criterion, we can find optimal parameters for the
proposed schedule. As for practical use, a greedy algorithm is devised for
parameter design, which has rather low computational complexity. We also
provide a method to quantify the performance gap between the schedule optimized
via MDP and any other schedules.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2016-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08229</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Orthonormal Sparsifying Transforms Based on Householder Reflectors</dc:title>
 <dc:creator>Rusu, Cristian</dc:creator>
 <dc:creator>Gonzalez-Prelcic, Nuria</dc:creator>
 <dc:creator>Heath, Robert</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Dictionary learning is the task of determining a data-dependent transform
that yields a sparse representation of some observed data. The dictionary
learning problem is non-convex, and usually solved via computationally complex
iterative algorithms. Furthermore, the resulting transforms obtained generally
lack structure that permits their fast application to data. To address this
issue, this paper develops a framework for learning orthonormal dictionaries
which are built from products of a few Householder reflectors. Two algorithms
are proposed to learn the reflector coefficients: one that considers a
sequential update of the reflectors and one with a simultaneous update of all
reflectors that imposes an additional internal orthogonal constraint. The
proposed methods have low computational complexity and are shown to converge to
local minimum points which can be described in terms of the spectral properties
of the matrices involved. The resulting dictionaries balance between the
computational complexity and the quality of the sparse representations by
controlling the number of Householder reflectors in their product. Simulations
of the proposed algorithms are shown in the image processing setting where
well-known fast transforms are available for comparisons. The proposed
algorithms have favorable reconstruction error and the advantage of a fast
implementation relative to the classical, unstructured, dictionaries.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08229</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2612168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08230</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Fast Sparsifying Transforms</dc:title>
 <dc:creator>Rusu, Cristian</dc:creator>
 <dc:creator>Thompson, John</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Given a dataset, the task of learning a transform that allows sparse
representations of the data bears the name of dictionary learning. In many
applications, these learned dictionaries represent the data much better than
the static well-known transforms (Fourier, Hadamard etc.). The main downside of
learned transforms is that they lack structure and therefore they are not
computationally efficient, unlike their classical counterparts. These posse
several difficulties especially when using power limited hardware such as
mobile devices, therefore discouraging the application of sparsity techniques
in such scenarios. In this paper we construct orthogonal and non-orthogonal
dictionaries that are factorized as a product of a few basic transformations.
In the orthogonal case, we solve exactly the dictionary update problem for one
basic transformation, which can be viewed as a generalized Givens rotation, and
then propose to construct orthogonal dictionaries that are a product of these
transformations, guaranteeing their fast manipulation. We also propose a method
to construct fast square but non-orthogonal dictionaries that are factorized as
a product of few transforms that can be viewed as a further generalization of
Givens rotations to the non-orthogonal setting. We show how the proposed
transforms can balance very well data representation performance and
computational complexity. We also compare with classical fast and learned
general and orthogonal transforms.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-05-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08230</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2712120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08240</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AdaScan: Adaptive Scan Pooling in Deep Convolutional Neural Networks for
  Human Action Recognition in Videos</dc:title>
 <dc:creator>Kar, Amlan</dc:creator>
 <dc:creator>Rai, Nishant</dc:creator>
 <dc:creator>Sikka, Karan</dc:creator>
 <dc:creator>Sharma, Gaurav</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel method for temporally pooling frames in a video for the
task of human action recognition. The method is motivated by the observation
that there are only a small number of frames which, together, contain
sufficient information to discriminate an action class present in a video, from
the rest. The proposed method learns to pool such discriminative and
informative frames, while discarding a majority of the non-informative frames
in a single temporal scan of the video. Our algorithm does so by continuously
predicting the discriminative importance of each video frame and subsequently
pooling them in a deep learning framework. We show the effectiveness of our
proposed pooling method on standard benchmarks where it consistently improves
on baseline pooling methods, with both RGB and optical flow based Convolutional
networks. Further, in combination with complementary video representations, we
show results that are competitive with respect to the state-of-the-art results
on two challenging and publicly available benchmark datasets.
</dc:description>
 <dc:description>Comment: CVPR 2017 Camera Ready Version</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-06-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08242</identifier>
 <datestamp>2017-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing with volatile memristors: An application of non-pinched
  hysteresis</dc:title>
 <dc:creator>Pershin, Y. V.</dc:creator>
 <dc:creator>Shevchenko, S. N.</dc:creator>
 <dc:subject>Condensed Matter - Mesoscale and Nanoscale Physics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  The possibility of in-memory computing with volatile memristive devices,
namely, memristors requiring a power source to sustain their memory, is
demonstrated. We have adopted a hysteretic graphene-based field emission
structure as a prototype of volatile memristor, which is characterized by a
non-pinched hysteresis loop. Memristive model of the structure is developed and
used to simulate a polymorphic circuit implementing in-memory computing gates
such as the material implication. Specific regions of parameter space realizing
useful logic functions are identified. Our results are applicable to other
realizations of volatile memory devices.
</dc:description>
 <dc:description>Comment: 11 pages, 7 figures</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08242</dc:identifier>
 <dc:identifier>Nanotechnology 28, 075204 (2017)</dc:identifier>
 <dc:identifier>doi:10.1088/1361-6528/aa53bf</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08252</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Integrated approach for the Secure Transmission of Images based on
  DNA Sequences</dc:title>
 <dc:creator>Jacob, Grasha</dc:creator>
 <dc:creator>Murugan, A.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  As long as human beings exist on this earth, there will be confidential
images intended for limited audience. These images have to be transmitted in
such a way that no unauthorized person gets knowledge of them. DNA sequences
play a vital role in modern cryptography and DNA sequence based cryptography
renders a helping hand for transmission of such confidential images over a
public insecure channel as the intended recipient alone can decipher them. This
paper outlines an integrated encryption scheme based on DNA sequences and
scrambling according to magic square of doubly even order pattern. Since there
is negligible correlation between the original and encrypted image this method
is robust against any type of crypt attack.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08258</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly Supervised Cascaded Convolutional Networks</dc:title>
 <dc:creator>Diba, Ali</dc:creator>
 <dc:creator>Sharma, Vivek</dc:creator>
 <dc:creator>Pazandeh, Ali</dc:creator>
 <dc:creator>Pirsiavash, Hamed</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Object detection is a challenging task in visual understanding domain, and
even more so if the supervision is to be weak. Recently, few efforts to handle
the task without expensive human annotations is established by promising deep
neural network. A new architecture of cascaded networks is proposed to learn a
convolutional neural network (CNN) under such conditions. We introduce two such
architectures, with either two cascade stages or three which are trained in an
end-to-end pipeline. The first stage of both architectures extracts best
candidate of class specific region proposals by training a fully convolutional
network. In the case of the three stage architecture, the middle stage provides
object segmentation, using the output of the activation maps of first stage.
The final stage of both architectures is a part of a convolutional neural
network that performs multiple instance learning on proposals extracted in the
previous stage(s). Our experiments on the PASCAL VOC 2007, 2010, 2012 and large
scale object datasets, ILSVRC 2013, 2014 datasets show improvements in the
areas of weakly-supervised object detection, classification and localization.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08262</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correlations Between Human Mobility and Social Interaction Reveal
  General Activity Patterns</dc:title>
 <dc:creator>Mollgaard, Anders</dc:creator>
 <dc:creator>Lehmann, Sune</dc:creator>
 <dc:creator>Mathiesen, Joachim</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  A day in the life of a person involves a broad range of activities which are
common across many people. Going beyond diurnal cycles, a central question is:
to what extent do individuals act according to patterns shared across an entire
population? Here we investigate the interplay between different activity types,
namely communication, motion, and physical proximity by analyzing data
collected from smartphones distributed among 638 individuals. We explore two
central questions: Which underlying principles govern the formation of the
activity patterns? Are the patterns specific to each individual or shared
across the entire population? We find that statistics of the entire population
allows us to successfully predict 71\% of the activity and 85\% of the
inactivity involved in communication, mobility, and physical proximity.
Surprisingly, individual level statistics only result in marginally better
predictions, indicating that a majority of activity patterns are shared across
{our sample population}. Finally, we predict short-term activity patterns using
a generalized linear model, which suggests that a simple linear description
might be sufficient to explain a wide range of actions, whether they be of
social or of physical character.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08262</dc:identifier>
 <dc:identifier>PLoS ONE 12(12): e0188973 (2017)</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0188973</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08266</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Researches on Dynamic Load Balancing Algorithms and hp-Adaptivity in 3-D
  Parallel Adaptive Finite Element Computations</dc:title>
 <dc:creator>Liu, Hui</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  This work is related to PHG (Parallel Hierarchical Grid). PHG is a toolbox
for developing parallel adaptive finite element programs, which is under active
development at the State Key Laboratory of Scientific and Engineering
Computing. The main results of this work are as follows.
  1) For the tetrahedral meshes used in PHG, under reasonable assumptions, we
proved the existence of through-vertex Hamiltonian paths between arbitrary two
vertices, as well as the existence of through-vertex Hamiltonian cycles, and
designed an efficient algorithm with linear complexity for constructing
through-vertex Hamiltonian paths. The resulting algorithm has been implemented
in PHG, and is used for ordering elements in the coarsest mesh for the
refinement tree mesh partitioning algorithm.
  2) We designed encoding and decoding algorithms for high dimensional Hilbert
order. Hilbert order has good locality, and it has wide applications in various
fields in computer science, such as memory management, database, and dynamic
load balancing.
  3) We implemented refinement tree and space filling curve based mesh
partitioning algorithms in PHG, and designed the dynamic load balancing module
of PHG. The refinement tree based partitioning algorithm was originally
proposed by Mitchell, the one implemented in PHG was improved in several
aspects. The space filling curve based mesh partitioning function in PHG can
use either Hilbert or Morton space filling curve.
  4) We studied existing hp-adaptive strategies in the literature, and proposed
a new strategy. Numerical experiments show that our new strategy achieves
exponential convergence, and is superior, in both precision of the solutions
and computation time, to the strategy compared. This part of the work also
serves to validate the hp-adaptivity module of PHG.
</dc:description>
 <dc:description>Comment: in Chinese</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08266</dc:identifier>
 <dc:identifier>doi:10.13140/RG.2.2.16168.98566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08267</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite-Length Analysis of Spatially-Coupled Regular LDPC Ensembles on
  Burst-Erasure Channels</dc:title>
 <dc:creator>Aref, Vahid</dc:creator>
 <dc:creator>Rengaswamy, Narayanan</dc:creator>
 <dc:creator>Schmalen, Laurent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Regular spatially-Coupled LDPC (SC-LDPC) ensembles have gained significant
interest since they were shown to universally achieve the capacity of binary
memoryless channels under low-complexity belief-propagation decoding. In this
work, we focus primarily on the performance of these ensembles over binary
channels affected by bursts of erasures. We first develop an analysis of the
finite length performance for a single burst per codeword and no errors
otherwise. We first assume that the burst erases a complete spatial position,
modeling for instance node failures in distributed storage. We provide new
tight lower bounds for the block erasure probability ($P_{\mathrm{B}}$) at
finite block length and bounds on the coupling parameter for being
asymptotically able to recover the burst. We further show that expurgating the
ensemble can improve the block erasure probability by several orders of
magnitude. Later we extend our methodology to more general channel models. In a
first extension, we consider bursts that can start at a random position in the
codeword and span across multiple spatial positions. Besides the finite length
analysis, we determine by means of density evolution the maximnum correctable
burst length. In a second extension, we consider the case where in addition to
a single burst, random bit erasures may occur. Finally, we consider a block
erasure channel model which erases each spatial position independently with
some probability $p$, potentially introducing multiple bursts simultaneously.
All results are verified using Monte-Carlo simulations.
</dc:description>
 <dc:description>Comment: accepted for publication in IEEE Transactions on Information Theory</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08268</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feedback Control of the Pusher-Slider System: A Story of Hybrid and
  Underactuated Contact Dynamics</dc:title>
 <dc:creator>Hogan, Francois Robert</dc:creator>
 <dc:creator>Rodriguez, Alberto</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper investigates real-time control strategies for dynamical systems
that involve frictional contact interactions. Hybridness and underactuation are
key characteristics of these systems that complicate the design of feedback
controllers. In this research, we examine and test a novel feedback controller
design on a planar pushing system, where the purpose is to control the motion
of a sliding object on a flat surface using a point robotic pusher. The
pusher-slider is a simple dynamical system that retains many of the challenges
that are typical of robotic manipulation tasks.
  Our results show that a model predictive control approach used in tandem with
integer programming offers a powerful solution to capture the dynamic
constraints associated with the friction cone as well as the hybrid nature of
the contact. In order to achieve real-time control, simplifications are
proposed to speed up the integer program. The concept of Family of Modes (FOM)
is introduced to solve an online convex optimization problem by selecting a set
of contact mode schedules that spans a large set of dynamic behaviors that can
occur during the prediction horizon. The controller design is applied to
stabilize the motion of a sliding object about a nominal trajectory, and to
re-plan its trajectory in real-time to follow a moving target. We validate the
controller design through numerical simulations and experimental results on an
industrial ABB IRB 120 robotic arm.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08268</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08269</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On measuring performances of C-SPARQL and CQELS</dc:title>
 <dc:creator>Ren, Xiangnan</dc:creator>
 <dc:creator>Khrouf, Houda</dc:creator>
 <dc:creator>Kazi-Aoul, Zakia</dc:creator>
 <dc:creator>Chabchoub, Yousra</dc:creator>
 <dc:creator>Cur&#xe9;, Olivier</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  To cope with the massive growth of semantic data streams, several RDF Stream
Processing (RSP) engines have been implemented. The efficiency of their
throughput, latency and memory consumption can be evaluated using available
benchmarks such as LSBench and City- Bench. Nevertheless, these benchmarks lack
an in-depth performance evaluation as some measurement metrics have not been
considered. The main goal of this paper is to analyze the performance of two
popular RSP engines, namely C-SPARQL and CQELS, when varying a set of
performance metrics. More precisely, we evaluate the impact of stream rate,
number of streams and window size on execution time as well as on memory
consumption.
</dc:description>
 <dc:description>Comment: 13 pages, 9 figures</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08269</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08271</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Laplacian integrality in P4-sparse and P4-extendible graphs</dc:title>
 <dc:creator>Del-Vecchio, Renata</dc:creator>
 <dc:creator>Jones, Atila</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Let G be a simple graph and L = L(G) the Laplacian matrix of G. G is called
L-integral if all its Laplacian eigenvalues are integer numbers. It is known
that every cograph, a graph free of P4, is L-integral. The class of P4-sparse
graphs and the class of P4-extendible graphs contain the cographs. It seems
natural to investigate if the graphs in these classes are still L-integral. In
this paper we characterized the L-integral graphs for both cases, P4-sparse
graphs and P4-extendible graphs.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08272</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>InstanceCut: from Edges to Instances with MultiCut</dc:title>
 <dc:creator>Kirillov, Alexander</dc:creator>
 <dc:creator>Levinkov, Evgeny</dc:creator>
 <dc:creator>Andres, Bjoern</dc:creator>
 <dc:creator>Savchynskyy, Bogdan</dc:creator>
 <dc:creator>Rother, Carsten</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This work addresses the task of instance-aware semantic segmentation. Our key
motivation is to design a simple method with a new modelling-paradigm, which
therefore has a different trade-off between advantages and disadvantages
compared to known approaches. Our approach, we term InstanceCut, represents the
problem by two output modalities: (i) an instance-agnostic semantic
segmentation and (ii) all instance-boundaries. The former is computed from a
standard convolutional neural network for semantic segmentation, and the latter
is derived from a new instance-aware edge detection model. To reason globally
about the optimal partitioning of an image into instances, we combine these two
modalities into a novel MultiCut formulation. We evaluate our approach on the
challenging CityScapes dataset. Despite the conceptual simplicity of our
approach, we achieve the best result among all published methods, and perform
particularly well for rare object classes.
</dc:description>
 <dc:description>Comment: The code would be released at
  https://github.com/alexander-kirillov/InstanceCut</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08272</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08273</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>State Sensitivity Evaluation Within UD Based Array Covariance Filters</dc:title>
 <dc:creator>Tsyganova, Julia V.</dc:creator>
 <dc:creator>Kulikova, Maria V.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This technical note addresses the UD factorization based Kalman filtering
(KF) algorithms. Using this important class of numerically stable KF schemes,
we extend its functionality and develop an elegant and simple method for
computation of sensitivities of the system state to unknown parameters required
in a variety of applications. For instance, it can be used for efficient
calculations in sensitivity analysis and in gradient-search optimization
algorithms for the maximum likelihood estimation. The new theory presented in
this technical note is a solution to the problem formulated by Bierman in ,
which has been open since 1990s. As in the cited paper, our method avoids the
standard approach based on the conventional KF (and its derivatives with
respect to unknown system parameters) with its inherent numerical instabilities
and, hence, improves the robustness of computations against roundoff errors.
</dc:description>
 <dc:description>Comment: The revised version of this preprint has been accepted for
  publication in IEEE Transactions on Automatic Control. arXiv admin note: text
  overlap with arXiv:1303.4622</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08273</dc:identifier>
 <dc:identifier>IEEE Transactions on Automatic Control, 58(11): 2944-2950, 2013</dc:identifier>
 <dc:identifier>doi:10.1109/TAC.2013.2259093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08280</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-Level Structural Sparsity Regularization for Identifying Lattices
  and Defects in Noisy Images</dc:title>
 <dc:creator>Li, Xin</dc:creator>
 <dc:creator>Belianinov, Alex</dc:creator>
 <dc:creator>Dyck, Ondrej</dc:creator>
 <dc:creator>Jesse, Stephen</dc:creator>
 <dc:creator>Park, Chiwoo</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>62P35</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>I.4.6</dc:subject>
 <dc:description>  This paper presents a regularized regression model with a two-level
structural sparsity penalty applied to locate individual atoms in a noisy
scanning transmission electron microscopy image (STEM). In crystals, the
locations of atoms is symmetric, condensed into a few lattice groups.
Therefore, by identifying the underlying lattice in a given image, individual
atoms can be accurately located. We propose to formulate the identification of
the lattice groups as a sparse group selection problem. Furthermore, real
atomic scale images contain defects and vacancies, so atomic identification
based solely on a lattice group may result in false positives and false
negatives. To minimize error, model includes an individual sparsity
regularization in addition to the group sparsity for a within-group selection,
which results in a regression model with a two-level sparsity regularization.
We propose a modification of the group orthogonal matching pursuit (gOMP)
algorithm with a thresholding step to solve the atom finding problem. The
convergence and statistical analyses of the proposed algorithm are presented.
The proposed algorithm is also evaluated through numerical experiments with
simulated images. The applicability of the algorithm on determination of atom
structures and identification of imaging distortions and atomic defects was
demonstrated using three real STEM images. We believe this is an important step
toward automatic phase identification and assignment with the advent of genomic
databases for materials.
</dc:description>
 <dc:description>Comment: Accepted to Annals of Applied Statistics</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08280</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08292</identifier>
 <datestamp>2017-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying Significant Predictive Bias in Classifiers</dc:title>
 <dc:creator>Zhang, Zhe</dc:creator>
 <dc:creator>Neill, Daniel B.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a novel subset scan method to detect if a probabilistic binary
classifier has statistically significant bias -- over or under predicting the
risk -- for some subgroup, and identify the characteristics of this subgroup.
This form of model checking and goodness-of-fit test provides a way to
interpretably detect the presence of classifier bias or regions of poor
classifier fit. This allows consideration of not just subgroups of a priori
interest or small dimensions, but the space of all possible subgroups of
features. To address the difficulty of considering these exponentially many
possible subgroups, we use subset scan and parametric bootstrap-based methods.
Extending this method, we can penalize the complexity of the detected subgroup
and also identify subgroups with high classification errors. We demonstrate
these methods and find interesting results on the COMPAS crime recidivism and
credit delinquency data.
</dc:description>
 <dc:description>Comment: Presented as a poster at the 2017 Workshop on Fairness,
  Accountability, and Transparency in Machine Learning (FAT/ML 2017); earlier
  version presented at NIPS 2016 Workshop on Interpretable Machine Learning in
  Complex Systems</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08294</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Software-Defined Networking-based Crypto Ransomware Detection Using HTTP
  Traffic Characteristics</dc:title>
 <dc:creator>Cabaj, Krzysztof</dc:creator>
 <dc:creator>Gregorczyk, Marcin</dc:creator>
 <dc:creator>Mazurczyk, Wojciech</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Ransomware is currently the key threat for individual as well as corporate
Internet users. Especially dangerous is crypto ransomware that encrypts
important user data and it is only possible to recover it once a ransom has
been paid. Therefore devising efficient and effective countermeasures is a
rising necessity. In this paper we present a novel Software-Defined Networking
(SDN) based detection approach that utilizes characteristics of ransomware
communication. Based on the observation of network communication of two crypto
ransomware families, namely CryptoWall and Locky we conclude that analysis of
the HTTP messages' sequences and their respective content sizes is enough to
detect such threats. We show feasibility of our approach by designing and
evaluating the proof-of-concept SDN-based detection system. Experimental
results confirm that the proposed approach is feasible and efficient.
</dc:description>
 <dc:description>Comment: 14 pages, 13 figures, 3 tables</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08303</identifier>
 <datestamp>2017-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Watershed Transform for Instance Segmentation</dc:title>
 <dc:creator>Bai, Min</dc:creator>
 <dc:creator>Urtasun, Raquel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Most contemporary approaches to instance segmentation use complex pipelines
involving conditional random fields, recurrent neural networks, object
proposals, or template matching schemes. In our paper, we present a simple yet
powerful end-to-end convolutional neural network to tackle this task. Our
approach combines intuitions from the classical watershed transform and modern
deep learning to produce an energy map of the image where object instances are
unambiguously represented as basins in the energy map. We then perform a cut at
a single energy level to directly yield connected components corresponding to
object instances. Our model more than doubles the performance of the
state-of-the-art on the challenging Cityscapes Instance Level Segmentation
task.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08307</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Python Code Suggestion with a Sparse Pointer Network</dc:title>
 <dc:creator>Bhoopchand, Avishkar</dc:creator>
 <dc:creator>Rockt&#xe4;schel, Tim</dc:creator>
 <dc:creator>Barr, Earl</dc:creator>
 <dc:creator>Riedel, Sebastian</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  To enhance developer productivity, all modern integrated development
environments (IDEs) include code suggestion functionality that proposes likely
next tokens at the cursor. While current IDEs work well for statically-typed
languages, their reliance on type annotations means that they do not provide
the same level of support for dynamic programming languages as for
statically-typed languages. Moreover, suggestion engines in modern IDEs do not
propose expressions or multi-statement idiomatic code. Recent work has shown
that language models can improve code suggestion systems by learning from
software repositories. This paper introduces a neural language model with a
sparse pointer network aimed at capturing very long-range dependencies. We
release a large-scale code suggestion corpus of 41M lines of Python code
crawled from GitHub. On this corpus, we found standard neural language models
to perform well at suggesting local phenomena, but struggle to refer to
identifiers that are introduced many tokens in the past. By augmenting a neural
language model with a pointer network specialized in referring to predefined
classes of identifiers, we obtain a much lower perplexity and a 5 percentage
points increase in accuracy for code suggestion compared to an LSTM baseline.
In fact, this increase in code suggestion accuracy is due to a 13 times more
accurate prediction of identifiers. Furthermore, a qualitative analysis shows
this model indeed captures interesting long-range dependencies, like referring
to a class member defined over 60 tokens in the past.
</dc:description>
 <dc:description>Comment: Under review as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08308</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proxy Voting for Better Outcomes</dc:title>
 <dc:creator>Cohensius, Gal</dc:creator>
 <dc:creator>Manor, Shie</dc:creator>
 <dc:creator>Meir, Reshef</dc:creator>
 <dc:creator>Meirom, Eli</dc:creator>
 <dc:creator>Orda, Ariel</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider a social choice problem where only a small number of people out
of a large population are sufficiently available or motivated to vote. A common
solution to increase participation is to allow voters use a proxy, that is,
transfer their voting rights to another voter. Considering social choice
problems on metric spaces, we compare voting with and without the use of
proxies to see which mechanism better approximates the optimal outcome, and
characterize the regimes in which proxy voting is beneficial. When voters'
opinions are located on an interval, both the median mechanism and the mean
mechanism are substantially improved by proxy voting. When voters vote on many
binary issues, proxy voting is better when the sample of active voters is too
small to provide a good outcome. Our theoretical results extend to situations
where available voters choose strategically whether to participate. We support
our theoretical findings with empirical results showing substantial benefits of
proxy voting on simulated and real preference data.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08309</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Human Intellect and Machine Failures: Troubleshooting Integrative
  Machine Learning Systems</dc:title>
 <dc:creator>Nushi, Besmira</dc:creator>
 <dc:creator>Kamar, Ece</dc:creator>
 <dc:creator>Horvitz, Eric</dc:creator>
 <dc:creator>Kossmann, Donald</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>H.1.2</dc:subject>
 <dc:subject>I.4</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We study the problem of troubleshooting machine learning systems that rely on
analytical pipelines of distinct components. Understanding and fixing errors
that arise in such integrative systems is difficult as failures can occur at
multiple points in the execution workflow. Moreover, errors can propagate,
become amplified or be suppressed, making blame assignment difficult. We
propose a human-in-the-loop methodology which leverages human intellect for
troubleshooting system failures. The approach simulates potential component
fixes through human computation tasks and measures the expected improvements in
the holistic behavior of the system. The method provides guidance to designers
about how they can best improve the system. We demonstrate the effectiveness of
the approach on an automated image captioning system that has been pressed into
real-world use.
</dc:description>
 <dc:description>Comment: 11 pages, Thirty-First AAAI conference on Artificial Intelligence</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08315</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universal Guard Problems</dc:title>
 <dc:creator>Fekete, S&#xe1;ndor P.</dc:creator>
 <dc:creator>Li, Qian</dc:creator>
 <dc:creator>Mitchell, Joseph S. B.</dc:creator>
 <dc:creator>Scheffer, Christian</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We provide a spectrum of results for the Universal Guard Problem, in which
one is to obtain a small set of points (&quot;guards&quot;) that are &quot;universal&quot; in their
ability to guard any of a set of possible polygonal domains in the plane. We
give upper and lower bounds on the number of universal guards that are always
sufficient to guard all polygons having a given set of n vertices, or to guard
all polygons in a given set of k polygons on an n-point vertex set. Our upper
bound proofs include algorithms to construct universal guard sets of the
respective cardinalities.
</dc:description>
 <dc:description>Comment: 28 pages, 19 figures, full version of extended abstract that appeared
  in the 27th International Symposium on Algorithms and Computation (ISAAC
  2016), 32:1-32:13</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08316</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Massive MIMO Pilot Retransmission Strategies for Robustification against
  Jamming</dc:title>
 <dc:creator>Do, Tan Tai</dc:creator>
 <dc:creator>Ngo, Hien Quoc</dc:creator>
 <dc:creator>Duong, Trung Q.</dc:creator>
 <dc:creator>Oechtering, Tobias J.</dc:creator>
 <dc:creator>Skoglund, Mikael</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This letter proposes anti-jamming strategies based on pilot retransmission
for a single user uplink massive MIMO under jamming attack. A jammer is assumed
to attack the system both in the training and data transmission phases. We
first derive an achievable rate which enables us to analyze the effect of
jamming attacks on the system performance. Counter-attack strategies are then
proposed to mitigate this effect under two different scenarios: random and
deterministic jamming attacks. Numerical results illustrate our analysis and
benefit of the proposed schemes.
</dc:description>
 <dc:description>Comment: Accepted for publication in the IEEE Wireless Communications Letters</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08319</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Impact of Vehicular Traffic Demand on 5G Caching Architectures: a
  Data-Driven Study</dc:title>
 <dc:creator>Malandrino, Francesco</dc:creator>
 <dc:creator>Chiasserini, Carla-Fabiana</dc:creator>
 <dc:creator>Kirkpatrick, Scott</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The emergence of in-vehicle entertainment systems and self-driving vehicles,
and the latter's need for high-resolution, up-to-date maps, will bring a
further increase in the amount of data vehicles consume. Considering how
difficult WiFi offloading in vehicular environments is, the bulk of this
additional load will be served by cellular networks. Cellular networks, in
turn, will resort to caching at the network edge in order to reduce the strain
on their core network, an approach also known as mobile edge computing, or fog
computing. In this work, we exploit a real-world, large-scale trace coming from
the users of the We-Fi app in order to (i) understand how significant the
contribution of vehicular users is to the global traffic demand; (ii) compare
the performance of different caching architectures; and (iii) studying how such
a performance is influenced by recommendation systems and content locality. We
express the price of fog computing through a metric called price-of-fog,
accounting for the extra caches to deploy compared to a traditional,
centralized approach. We find that fog computing allows a very significant
reduction of the load on the core network, and the price thereof is low in all
cases and becomes negligible if content demand is location specific. We can
therefore conclude that vehicular networks make an excellent case for the
transition to mobile-edge caching: thanks to the peculiar features of vehicular
demand, we can obtain all the benefits of fog computing, including a reduction
of the load on the core network, reducing the disadvantages to a minimum.
</dc:description>
 <dc:description>Comment: 16 pages, 10 figures. Expanded version for VehCOM journal, presented
  first at ACM MobiHoc 2016, Paderborn, DE, July 2016</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08321</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training and Evaluating Multimodal Word Embeddings with Large-scale Web
  Annotated Images</dc:title>
 <dc:creator>Mao, Junhua</dc:creator>
 <dc:creator>Xu, Jiajing</dc:creator>
 <dc:creator>Jing, Yushi</dc:creator>
 <dc:creator>Yuille, Alan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:description>  In this paper, we focus on training and evaluating effective word embeddings
with both text and visual information. More specifically, we introduce a
large-scale dataset with 300 million sentences describing over 40 million
images crawled and downloaded from publicly available Pins (i.e. an image with
sentence descriptions uploaded by users) on Pinterest. This dataset is more
than 200 times larger than MS COCO, the standard large-scale image dataset with
sentence descriptions. In addition, we construct an evaluation dataset to
directly assess the effectiveness of word embeddings in terms of finding
semantically similar or related words and phrases. The word/phrase pairs in
this evaluation dataset are collected from the click data with millions of
users in an image search system, thus contain rich semantic relationships.
Based on these datasets, we propose and compare several Recurrent Neural
Networks (RNNs) based multimodal (text and image) models. Experiments show that
our model benefits from incorporating the visual information into the word
embeddings, and a weight sharing strategy is crucial for learning such
multimodal embeddings. The project page is:
http://www.stat.ucla.edu/~junhua.mao/multimodal_embedding.html
</dc:description>
 <dc:description>Comment: Appears in NIPS 2016. The datasets introduced in this work will be
  gradually released on the project page</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08322</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental analysis of nonlinear systems with efficient methods for
  piecewise-affine systems</dc:title>
 <dc:creator>Waitman, S&#xe9;rgio</dc:creator>
 <dc:creator>Massioni, Paolo</dc:creator>
 <dc:creator>Bako, Laurent</dc:creator>
 <dc:creator>Scorletti, G&#xe9;rard</dc:creator>
 <dc:creator>Fromion, Vincent</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper is concerned with incremental stability properties of nonlinear
systems. We propose conditions to compute an upper bound on the incremental
L2-gain and to assess incremental asymptotic stability of piecewise-affine
(PWA) systems. The conditions are derived from dissipativity analysis, and are
based on the construction of piecewise-quadratic functions via linear matrix
inequalities (LMI) that can be efficiently solved numerically. The developments
are shown to be less conservative than previous results, and are illustrated
with numerical examples. In the last part of this paper, we study the
connection between incremental L2-gain stability and incremental asymptotic
stability. It is shown that, with appropriate observability and reachability
assumptions on the input-output operator, incremental L2-gain implies
incremental asymptotic stability. Finally, it is shown that the converse
implication follows provided some regularity conditions on the state space
representation are met.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08323</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Full-Resolution Residual Networks for Semantic Segmentation in Street
  Scenes</dc:title>
 <dc:creator>Pohlen, Tobias</dc:creator>
 <dc:creator>Hermans, Alexander</dc:creator>
 <dc:creator>Mathias, Markus</dc:creator>
 <dc:creator>Leibe, Bastian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Semantic image segmentation is an essential component of modern autonomous
driving systems, as an accurate understanding of the surrounding scene is
crucial to navigation and action planning. Current state-of-the-art approaches
in semantic image segmentation rely on pre-trained networks that were initially
developed for classifying images as a whole. While these networks exhibit
outstanding recognition performance (i.e., what is visible?), they lack
localization accuracy (i.e., where precisely is something located?). Therefore,
additional processing steps have to be performed in order to obtain
pixel-accurate segmentation masks at the full image resolution. To alleviate
this problem we propose a novel ResNet-like architecture that exhibits strong
localization and recognition performance. We combine multi-scale context with
pixel-level accuracy by using two processing streams within our network: One
stream carries information at the full image resolution, enabling precise
adherence to segment boundaries. The other stream undergoes a sequence of
pooling operations to obtain robust features for recognition. The two streams
are coupled at the full image resolution using residuals. Without additional
processing steps and without pre-training, our approach achieves an
intersection-over-union score of 71.8% on the Cityscapes dataset.
</dc:description>
 <dc:description>Comment: Changes in v2: Fixed equation (10), fixed legend of Figure 6, fixed
  legend of Figure 9, added page numbers, fixed minor spelling mistakes</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08323</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08326</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting communities is hard, and counting them is even harder</dc:title>
 <dc:creator>Rubinstein, Aviad</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We consider the algorithmic problem of community detection in networks. Given
an undirected friendship graph $G=\left(V,E\right)$, a subset $S\subseteq V$ is
an $\left(\alpha,\beta\right)$-community if:
  * Every member of the community is friends with an $\alpha$-fraction of the
community;
  * Every non-member is friends with at most a $\beta$-fraction of the
community.
  Arora et al [AGSS12] gave a quasi-polynomial time algorithm for enumerating
all the $\left(\alpha,\beta\right)$-communities for any constants
$\alpha&gt;\beta$.
  Here, we prove that, assuming the Exponential Time Hypothesis (ETH),
quasi-polynomial time is in fact necessary - and even for a much weaker
approximation desideratum. Namely, distinguishing between:
  * $G$ contains an $\left(1,o\left(1\right)\right)$-community; and
  * $G$ does not contain an
$\left(\beta+o\left(1\right),\beta\right)$-community for any
$\beta\in\left[0,1\right]$.
  We also prove that counting the number of
$\left(1,o\left(1\right)\right)$-communities requires quasi-polynomial time
assuming the weaker #ETH.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08326</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08327</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental stability of Lur'e systems through piecewise-affine
  approximations</dc:title>
 <dc:creator>Waitman, S&#xe9;rgio</dc:creator>
 <dc:creator>Bako, Laurent</dc:creator>
 <dc:creator>Massioni, Paolo</dc:creator>
 <dc:creator>Scorletti, G&#xe9;rard</dc:creator>
 <dc:creator>Fromion, Vincent</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Lur'e-type nonlinear systems are virtually ubiquitous in applied control
theory, which explains the great interest they have attracted throughout the
years. The purpose of this paper is to propose conditions to assess incremental
asymptotic stability of Lur'e systems that are less conservative than those
obtained with the incremental circle criterion. The method is based on the
approximation of the nonlinearity by a piecewise-affine function. The Lur'e
system can then be rewritten as a so-called piecewise-affine Lur'e system, for
which sufficient conditions for asymptotic incremental stability are provided.
These conditions are expressed as linear matrix inequalities (LMIs) allowing
the construction of a continuous piecewise-quadratic incremental Lyapunov
function, which can be efficiently solved numerically. The results are
illustrated with numerical examples.
</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08327</dc:identifier>
 <dc:identifier>doi:10.1016/j.ifacol.2017.08.491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08331</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Overview on Data Representation Learning: From Traditional Feature
  Learning to Recent Deep Learning</dc:title>
 <dc:creator>Zhong, Guoqiang</dc:creator>
 <dc:creator>Wang, Li-Na</dc:creator>
 <dc:creator>Dong, Junyu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>68T05</dc:subject>
 <dc:description>  Since about 100 years ago, to learn the intrinsic structure of data, many
representation learning approaches have been proposed, including both linear
ones and nonlinear ones, supervised ones and unsupervised ones. Particularly,
deep architectures are widely applied for representation learning in recent
years, and have delivered top results in many tasks, such as image
classification, object detection and speech recognition. In this paper, we
review the development of data representation learning methods. Specifically,
we investigate both traditional feature learning algorithms and
state-of-the-art deep learning models. The history of data representation
learning is introduced, while available resources (e.g. online course, tutorial
and book information) and toolboxes are provided. Finally, we conclude this
paper with remarks and some interesting research directions on data
representation learning.
</dc:description>
 <dc:description>Comment: About 20 pages. Submitted to Journal of Finance and Data Science as
  an invited paper</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08331</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08343</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global optimization framework for real-time route guidance via variable
  message sign</dc:title>
 <dc:creator>Liu, Bai</dc:creator>
 <dc:creator>Han, Ke</dc:creator>
 <dc:creator>Hu, Jianming</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Variable message sign (VMS) is an effective traffic management tool for
congestion mitigation. The VMS is primarily used as a means of providing
factual travel information or genuine route guidance to travelers. However,
this may be rendered sub-optimal on a network level by potential network
paradoxes and lack of consideration for its cascading effect on the rest of the
network. This paper focuses on the design of optimal display strategy of VMS in
response to real-time traffic information and its coordination with other
intelligent transportation systems such as signal control, in order to explore
the full potential of real-time route guidance in combating congestion. We
invoke the linear decision rule framework to design the optimal on-line VMS
strategy, and test its effectiveness in conjunction with on-line signal
control. A simulation case study is conducted on a real-world test network in
China, which shows the advantage of the proposed adaptive VMS display strategy
over genuine route guidance, as well as its synergies with on-line signal
control for congestion mitigation.
</dc:description>
 <dc:description>Comment: Word count: 5,176 words + 7 figures + 2 tables = 7,426</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08350</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning an Invariant Hilbert Space for Domain Adaptation</dc:title>
 <dc:creator>Herath, Samitha</dc:creator>
 <dc:creator>Harandi, Mehrtash</dc:creator>
 <dc:creator>Porikli, Fatih</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper introduces a learning scheme to construct a Hilbert space (i.e., a
vector space along its inner product) to address both unsupervised and
semi-supervised domain adaptation problems. This is achieved by learning
projections from each domain to a latent space along the Mahalanobis metric of
the latent space to simultaneously minimizing a notion of domain variance while
maximizing a measure of discriminatory power. In particular, we make use of the
Riemannian optimization techniques to match statistical properties (e.g., first
and second order statistics) between samples projected into the latent space
from different domains. Upon availability of class labels, we further deem
samples sharing the same label to form more compact clusters while pulling away
samples coming from different classes.We extensively evaluate and contrast our
proposal against state-of-the-art methods for the task of visual domain
adaptation using both handcrafted and deep-net features. Our experiments show
that even with a simple nearest neighbor classifier, the proposed method can
outperform several state-of-the-art methods benefitting from more involved
classification schemes.
</dc:description>
 <dc:description>Comment: 24 pages, 7 figures</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08351</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fine-grained Mining of Illicit Drug Use Patterns Using Social Multimedia
  Data from Instagram</dc:title>
 <dc:creator>Zhou, Yiheng</dc:creator>
 <dc:creator>Sani, Numair</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  According to NSDUH (National Survey on Drug Use and Health), 20 million
Americans consumed drugs in the past few 30 days. Combating illicit drug use is
of great interest to public health and law enforcement agencies. Despite of the
importance, most of the existing studies on drug uses rely on surveys. Surveys
on sensitive topics such as drug use may not be answered truthfully by the
people taking them. Selecting a representative sample to survey is another
major challenge. In this paper, we explore the possibility of using big
multimedia data, including both images and text, from social media in order to
discover drug use patterns at fine granularity with respect to demographics.
Instagram posts are searched and collected by drug related terms by analyzing
the hashtags supplied with each post. A large and dynamic dictionary of
frequent drug related slangs is used to find these posts. User demographics are
extracted using robust face image analysis algorithms. These posts are then
mined to find common trends with regard to the time and location they are
posted, and further in terms of age and gender of the drug users. Furthermore,
by studying the accounts followed by the users of drug related posts, we
extract common interests shared by drug users.
</dc:description>
 <dc:description>Comment: IEEE Big Data Conference, Washington, DC, December 2016</dc:description>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08351</dc:identifier>
 <dc:identifier>Special Session on Intelligent Data Mining, IEEE Big Data
  Conference, Washington, DC, December 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08358</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kannada Spell Checker with Sandhi Splitter</dc:title>
 <dc:creator>Akshatha, A N</dc:creator>
 <dc:creator>Upadhyaya, Chandana G</dc:creator>
 <dc:creator>Murthy, Rajashekara S</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Spelling errors are introduced in text either during typing, or when the user
does not know the correct phoneme or grapheme. If a language contains complex
words like sandhi where two or more morphemes join based on some rules, spell
checking becomes very tedious. In such situations, having a spell checker with
sandhi splitter which alerts the user by flagging the errors and providing
suggestions is very useful. A novel algorithm of sandhi splitting is proposed
in this paper. The sandhi splitter can split about 7000 most common sandhi
words in Kannada language used as test samples. The sandhi splitter was
integrated with a Kannada spell checker and a mechanism for generating
suggestions was added. A comprehensive, platform independent, standalone spell
checker with sandhi splitter application software was thus developed and tested
extensively for its efficiency and correctness. A comparative analysis of this
spell checker with sandhi splitter was made and results concluded that the
Kannada spell checker with sandhi splitter has an improved performance. It is
twice as fast, 200 times more space efficient, and it is 90% accurate in case
of complex nouns and 50% accurate for complex verbs. Such a spell checker with
sandhi splitter will be of foremost significance in machine translation
systems, voice processing, etc. This is the first sandhi splitter in Kannada
and the advantage of the novel algorithm is that, it can be extended to all
Indian languages.
</dc:description>
 <dc:description>Comment: 7 pages, 10 figures</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08364</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Sequential Path Planning Under Disturbances and Adversarial
  Intruder</dc:title>
 <dc:creator>Chen, Mo</dc:creator>
 <dc:creator>Bansal, Somil</dc:creator>
 <dc:creator>Fisac, Jaime F.</dc:creator>
 <dc:creator>Tomlin, Claire J.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Provably safe and scalable multi-vehicle path planning is an important and
urgent problem due to the expected increase of automation in civilian airspace
in the near future. Although this problem has been studied in the past, there
has not been a method that guarantees both goal satisfaction and safety for
vehicles with general nonlinear dynamics while taking into account disturbances
and potential adversarial agents, to the best of our knowledge. Hamilton-Jacobi
(HJ) reachability is the ideal tool for guaranteeing goal satisfaction and
safety under such scenarios, and has been successfully applied to many
small-scale problems. However, a direct application of HJ reachability in most
cases becomes intractable when there are more than two vehicles due to the
exponentially scaling computational complexity with respect to system
dimension. In this paper, we take advantage of the guarantees HJ reachability
provides, and eliminate the computation burden by assigning a strict priority
ordering to the vehicles under consideration. Under this sequential path
planning (SPP) scheme, vehicles reserve &quot;space-time&quot; portions in the airspace,
and the space-time portions guarantee dynamic feasibility, collision avoidance,
and optimality of the paths given the priority ordering. With a computation
complexity that scales quadratically when accounting for both disturbances and
an intruder, and linearly when accounting for only disturbances, SPP can
tractably solve the multi-vehicle path planning problem for vehicles with
general nonlinear dynamics in a practical setting. We demonstrate our theory in
representative simulations.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Control Systems Technology</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08364</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08366</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Discriminant Hyperalignment for multi-subject fMRI data alignment</dc:title>
 <dc:creator>Yousefnezhad, Muhammad</dc:creator>
 <dc:creator>Zhang, Daoqiang</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Multivariate Pattern (MVP) classification can map different cognitive states
to the brain tasks. One of the main challenges in MVP analysis is validating
the generated results across subjects. However, analyzing multi-subject fMRI
data requires accurate functional alignments between neuronal activities of
different subjects, which can rapidly increase the performance and robustness
of the final results. Hyperalignment (HA) is one of the most effective
functional alignment methods, which can be mathematically formulated by the
Canonical Correlation Analysis (CCA) methods. Since HA mostly uses the
unsupervised CCA techniques, its solution may not be optimized for MVP
analysis. By incorporating the idea of Local Discriminant Analysis (LDA) into
CCA, this paper proposes Local Discriminant Hyperalignment (LDHA) as a novel
supervised HA method, which can provide better functional alignment for MVP
analysis. Indeed, the locality is defined based on the stimuli categories in
the train-set, where the correlation between all stimuli in the same category
will be maximized and the correlation between distinct categories of stimuli
approaches to near zero. Experimental studies on multi-subject MVP analysis
confirm that the LDHA method achieves superior performance to other
state-of-the-art HA algorithms.
</dc:description>
 <dc:description>Comment: Published in the Thirty-First AAAI Conference on Artificial
  Intelligence (AAAI-17)</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08367</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Determining Optimal Rates for Communication for Omniscience</dc:title>
 <dc:creator>Ding, Ni</dc:creator>
 <dc:creator>Chan, Chung</dc:creator>
 <dc:creator>Zhou, Qiaoqiao</dc:creator>
 <dc:creator>Kennedy, Rodney A.</dc:creator>
 <dc:creator>Sadeghi, Parastoo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers the communication for omniscience (CO) problem: A set of
users observe a discrete memoryless multiple source and want to recover the
entire multiple source via noise-free broadcast communications. We study the
problem of how to determine an optimal rate vector that attains omniscience
with the minimum sum-rate, the total number of communications. The results
cover both asymptotic and non-asymptotic models where the transmission rates
are real and integral, respectively. We propose a modified decomposition
algorithm (MDA) and a sum-rate increment algorithm (SIA) for the asymptotic and
non-asymptotic models, respectively, both of which determine the value of the
minimum sum-rate and a corresponding optimal rate vector in polynomial time.
For the coordinate saturation capacity (CoordSatCap) algorithm, a nesting
algorithm in MDA and SIA, we propose to implement it by a fusion method and
show by experimental results that this fusion method contributes to a reduction
in computation complexity. Finally, we show that the separable convex
minimization problem over the optimal rate vector set in the asymptotic model
can be decomposed by the fundamental partition, the optimal partition of the
user set that determines the minimum sum-rate, so that the problem can be
solved more efficiently.
</dc:description>
 <dc:description>Comment: 27 pages, 14 figures</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2017-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08372</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Convex Surrogate for the Schatten-$p$ Norm</dc:title>
 <dc:creator>Xu, Chen</dc:creator>
 <dc:creator>Lin, Zhouchen</dc:creator>
 <dc:creator>Zha, Hongbin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The Schatten-$p$ norm ($0&lt;p&lt;1$) has been widely used to replace the nuclear
norm for better approximating the rank function. However, existing methods are
either 1) not scalable for large scale problems due to relying on singular
value decomposition (SVD) in every iteration, or 2) specific to some $p$
values, e.g., $1/2$, and $2/3$. In this paper, we show that for any $p$, $p_1$,
and $p_2 &gt;0$ satisfying $1/p=1/p_1+1/p_2$, there is an equivalence between the
Schatten-$p$ norm of one matrix and the Schatten-$p_1$ and the Schatten-$p_2$
norms of its two factor matrices. We further extend the equivalence to multiple
factor matrices and show that all the factor norms can be convex and smooth for
any $p&gt;0$. In contrast, the original Schatten-$p$ norm for $0&lt;p&lt;1$ is
non-convex and non-smooth. As an example we conduct experiments on matrix
completion. To utilize the convexity of the factor matrix norms, we adopt the
accelerated proximal alternating linearized minimization algorithm and
establish its sequence convergence. Experiments on both synthetic and real
datasets exhibit its superior performance over the state-of-the-art methods.
Its speed is also highly competitive.
</dc:description>
 <dc:description>Comment: The paper is accepted by AAAI-17. We show that multi-factor matrix
  factorization enjoys superiority over the traditional two-factor case</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08373</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bidirectional LSTM-CRF for Clinical Concept Extraction</dc:title>
 <dc:creator>Chalapathy, Raghavendra</dc:creator>
 <dc:creator>Borzeshi, Ehsan Zare</dc:creator>
 <dc:creator>Piccardi, Massimo</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Automated extraction of concepts from patient clinical records is an
essential facilitator of clinical research. For this reason, the 2010 i2b2/VA
Natural Language Processing Challenges for Clinical Records introduced a
concept extraction task aimed at identifying and classifying concepts into
predefined categories (i.e., treatments, tests and problems). State-of-the-art
concept extraction approaches heavily rely on handcrafted features and
domain-specific resources which are hard to collect and define. For this
reason, this paper proposes an alternative, streamlined approach: a recurrent
neural network (the bidirectional LSTM with CRF decoding) initialized with
general-purpose, off-the-shelf word embeddings. The experimental results
achieved on the 2010 i2b2/VA reference corpora using the proposed framework
outperform all recent methods and ranks closely to the best submission from the
original 2010 i2b2/VA challenge.
</dc:description>
 <dc:description>Comment: This paper &quot;Bidirectional LSTM-CRF for Clinical Concept Extraction&quot;
  is accepted for short paper presentation at Clinical Natural Language
  Processing Workshop at COLING 2016 Osaka, Japan. December 11, 2016</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08373</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08374</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decision Support Systems in Fisheries and Aquaculture: A systematic
  review</dc:title>
 <dc:creator>Mathisen, Bj&#xf8;rn Magnus</dc:creator>
 <dc:creator>Haro, Peter</dc:creator>
 <dc:creator>Hanssen, B&#xe5;rd</dc:creator>
 <dc:creator>Bj&#xf6;rk, Sara</dc:creator>
 <dc:creator>Walderhaug, St&#xe5;le</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Decision support systems help decision makers make better decisions in the
face of complex decision problems (e.g. investment or policy decisions).
Fisheries and Aquaculture is a domain where decision makers face such decisions
since they involve factors from many different scientific fields. No systematic
overview of literature describing decision support systems and their
application in fisheries and aquaculture has been conducted. This paper
summarizes scientific literature that describes decision support systems
applied to the domain of Fisheries and Aquaculture. We use an established
systematic mapping survey method to conduct our literature mapping. Our
research questions are: What decision support systems for fisheries and
aquaculture exists? What are the most investigated fishery and aquaculture
decision support systems topics and how have these changed over time? Do any
current DSS for fisheries provide real- time analytics? Do DSSes in Fisheries
and Aquaculture build their models using machine learning done on captured and
grounded data? The paper then detail how we employ the systematic mapping
method in answering these questions. This results in 27 papers being identified
as relevant and gives an exposition on the primary methods concluded in the
study for designing a decision support system. We provide an analysis of the
research done in the studies collected. We discovered that most literature does
not consider multiple aspects for multiple stakeholders in their work. In
addition we observed that little or no work has been done with real-time
analysis in these decision support systems.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08387</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Video Deblurring</dc:title>
 <dc:creator>Su, Shuochen</dc:creator>
 <dc:creator>Delbracio, Mauricio</dc:creator>
 <dc:creator>Wang, Jue</dc:creator>
 <dc:creator>Sapiro, Guillermo</dc:creator>
 <dc:creator>Heidrich, Wolfgang</dc:creator>
 <dc:creator>Wang, Oliver</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Motion blur from camera shake is a major problem in videos captured by
hand-held devices. Unlike single-image deblurring, video-based approaches can
take advantage of the abundant information that exists across neighboring
frames. As a result the best performing methods rely on aligning nearby frames.
However, aligning images is a computationally expensive and fragile procedure,
and methods that aggregate information must therefore be able to identify which
regions have been accurately aligned and which have not, a task which requires
high level scene understanding. In this work, we introduce a deep learning
solution to video deblurring, where a CNN is trained end-to-end to learn how to
accumulate information across frames. To train this network, we collected a
dataset of real videos recorded with a high framerate camera, which we use to
generate synthetic motion blur for supervision. We show that the features
learned from this dataset extend to deblurring motion blur that arises due to
camera shake in a wide range of videos, and compare the quality of results to a
number of other baselines.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08387</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08389</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Color Constancy with Derivative Colors</dc:title>
 <dc:creator>Lei, Huan</dc:creator>
 <dc:creator>Jiang, Guang</dc:creator>
 <dc:creator>Quan, Long</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Information about the illuminant color is well contained in both achromatic
regions and the specular components of highlight regions. In this paper, we
propose a novel way to achieve color constancy by exploiting such clues. The
key to our approach lies in the use of suitably extracted derivative colors,
which are able to compute the illuminant color robustly with kernel density
estimation. While extracting derivative colors from achromatic regions to
approximate the illuminant color well is basically straightforward, the success
of our extraction in highlight regions is attributed to the different rates of
variation of the diffuse and specular magnitudes in the dichromatic reflection
model. The proposed approach requires no training phase and is simple to
implement. More significantly, it performs quite satisfactorily under
inter-database parameter settings. Our experiments on three standard databases
demonstrate its effectiveness and fine performance in comparison to
state-of-the-art methods.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08389</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08396</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CAn't Touch This: Practical and Generic Software-only Defenses Against
  Rowhammer Attacks</dc:title>
 <dc:creator>Brasser, Ferdinand</dc:creator>
 <dc:creator>Davi, Lucas</dc:creator>
 <dc:creator>Gens, David</dc:creator>
 <dc:creator>Liebchen, Christopher</dc:creator>
 <dc:creator>Sadeghi, Ahmad-Reza</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Rowhammer is a hardware bug that can be exploited to implement privilege
escalation and remote code execution attacks. Previous proposals on rowhammer
mitigation either require hardware changes or follow heuristic-based approaches
(based on CPU performance counters). To date, there exists no instant
protection against rowhammer attacks on legacy systems.
  In this paper, we present the design and implementation of two practical and
efficient software-only defenses against rowhammer attacks. Our defenses
prevent the attacker from leveraging rowhammer to corrupt physically co-located
data in memory that is owned by a different system entity. Our first defense,
B-CATT, extends the system bootloader to disable vulnerable physical memory.
B-CATT is highly practical, does not require changes to the operating system,
and can be deployed on virtually all x86-based systems. While B-CATT is able to
stop all known rowhammer attacks, it does not yet tackle the fundamental
problem of missing memory isolation in physical memory. To address this
problem, we introduce our second defense G-CATT, a generic solution that
extends the physical memory allocator of the OS to physically isolate the
memory of different system entities (e.g., kernel and user space).
  As proof of concept, we implemented B-CATT on x86, and our generic defense,
G-CATT, on x86 and ARM to mitigate rowhammer-based kernel exploits. Our
extensive evaluation shows that both mitigation schemes (i) can stop available
real- world rowhammer attacks, (ii) impose virtually no run-time overhead for
common user and kernel benchmarks as well as commonly used applications, and
(iii) do not affect the stability of the overall system.
</dc:description>
 <dc:description>Comment: -- Clarifications based on intial feedback -- p7: clarified formula
  p10: included rest of pts/memory (cachebench/ramspeed) in Tab III p12:
  include discussion on how single-sided rowhammer attacks are mitigated and
  benchmark selection p13: updated related work p14: updated acknowledgment</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08396</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08397</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Second Order Derivatives based Approach for Steganography</dc:title>
 <dc:creator>Couchot, Jean-Fran&#xe7;ois</dc:creator>
 <dc:creator>Couturier, Rapha&#xeb;l</dc:creator>
 <dc:creator>Fadil, Yousra Ahmed</dc:creator>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Steganography schemes are designed with the objective of minimizing a defined
distortion function. In most existing state of the art approaches, this
distortion function is based on image feature preservation. Since smooth
regions or clean edges define image core, even a small modification in these
areas largely modifies image features and is thus easily detectable. On the
contrary, textures, noisy or chaotic regions are so difficult to model that the
features having been modified inside these areas are similar to the initial
ones. These regions are characterized by disturbed level curves. This work
presents a new distortion function for steganography that is based on second
order derivatives, which are mathematical tools that usually evaluate level
curves. Two methods are explained to compute these partial derivatives and have
been completely implemented. The first experiments show that these approaches
are promising.
</dc:description>
 <dc:description>Comment: Accepted to SECRYPT 2016</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08400</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nondeterministic Communication Complexity of Random Boolean Functions</dc:title>
 <dc:creator>Pourmoradnasseri, Mozhgan</dc:creator>
 <dc:creator>Theis, Dirk Oliver</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We study nondeterministic communication complexity and related concepts
(fooling sets, fractional covering number) of random functions $f\colon X\times
Y \to \{0,1\}$ where each value is chosen to be 1 independently with
probability $p=p(n)$, $n := |X|=|Y|$.
</dc:description>
 <dc:description>Comment: Version with proofs (in the appendix). Extended abstract appeared in
  Proceedings of Theory and Applications of Models of Computation, TAMC, 2016</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08401</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigating Low Level Protocols for Wireless Body Sensor Networks</dc:title>
 <dc:creator>Boudargham, Nadine</dc:creator>
 <dc:creator>Abdo, Jacques Bou</dc:creator>
 <dc:creator>Demerjian, Jacques</dc:creator>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:creator>Makhoul, Abdallah</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The rapid development of medical sensors has increased the interest in
Wireless Body Area Network (WBAN) applications where physiological data from
the human body and its environment is gathered, monitored, and analyzed to take
the proper measures. In WBANs, it is essential to design MAC protocols that
ensure adequate Quality of Service (QoS) such as low delay and high
scalability. This paper investigates Medium Access Control (MAC) protocols used
in WBAN, and compares their performance in a high traffic environment. Such
scenario can be induced in case of emergency for example, where physiological
data collected from all sensors on human body should be sent simultaneously to
take appropriate action. This study can also be extended to cover collaborative
WBAN systems where information from different bodies is sent simultaneously
leading to high traffic. OPNET simulations are performed to compare the delay
and scalability performance of the different MAC protocols under the same
experimental conditions and to draw conclusions about the best protocol to be
used in a high traffic environment.
</dc:description>
 <dc:description>Comment: Accepted to AICCSA 2016</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08402</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometric deep learning on graphs and manifolds using mixture model CNNs</dc:title>
 <dc:creator>Monti, Federico</dc:creator>
 <dc:creator>Boscaini, Davide</dc:creator>
 <dc:creator>Masci, Jonathan</dc:creator>
 <dc:creator>Rodol&#xe0;, Emanuele</dc:creator>
 <dc:creator>Svoboda, Jan</dc:creator>
 <dc:creator>Bronstein, Michael M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning has achieved a remarkable performance breakthrough in several
fields, most notably in speech recognition, natural language processing, and
computer vision. In particular, convolutional neural network (CNN)
architectures currently produce state-of-the-art performance on a variety of
image analysis tasks such as object detection and recognition. Most of deep
learning research has so far focused on dealing with 1D, 2D, or 3D
Euclidean-structured data such as acoustic signals, images, or videos.
Recently, there has been an increasing interest in geometric deep learning,
attempting to generalize deep learning methods to non-Euclidean structured data
such as graphs and manifolds, with a variety of applications from the domains
of network analysis, computational social science, or computer graphics. In
this paper, we propose a unified framework allowing to generalize CNN
architectures to non-Euclidean domains (graphs and manifolds) and learn local,
stationary, and compositional task-specific features. We show that various
non-Euclidean CNN methods previously proposed in the literature can be
considered as particular instances of our framework. We test the proposed
method on standard tasks from the realms of image-, graph- and 3D shape
analysis and show that it consistently outperforms previous approaches.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08408</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Segmentation using Adversarial Networks</dc:title>
 <dc:creator>Luc, Pauline</dc:creator>
 <dc:creator>Couprie, Camille</dc:creator>
 <dc:creator>Chintala, Soumith</dc:creator>
 <dc:creator>Verbeek, Jakob</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Adversarial training has been shown to produce state of the art results for
generative image modeling. In this paper we propose an adversarial training
approach to train semantic segmentation models. We train a convolutional
semantic segmentation network along with an adversarial network that
discriminates segmentation maps coming either from the ground truth or from the
segmentation network. The motivation for our approach is that it can detect and
correct higher-order inconsistencies between ground truth segmentation maps and
the ones produced by the segmentation net. Our experiments show that our
adversarial training approach leads to improved accuracy on the Stanford
Background and PASCAL VOC 2012 datasets.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08408</dc:identifier>
 <dc:identifier>NIPS Workshop on Adversarial Training, Dec 2016, Barcelona, Spain</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08410</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FPGA Implementation of $\mathbb{F}_2$-Linear Pseudorandom Number
  Generators Based on Zynq MPSoC: a Chaotic Iterations Post Processing Case
  Study</dc:title>
 <dc:creator>Bakiri, Mohammed</dc:creator>
 <dc:creator>Couchot, Jean-Fran&#xe7;ois</dc:creator>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Pseudorandom number generation (PRNG) is a key element in hardware security
platforms like field-programmable gate array FPGA circuits. In this article, 18
PRNGs belonging in 4 families (xorshift, LFSR, TGFSR, and LCG) are physically
implemented in a FPGA and compared in terms of area, throughput, and
statistical tests. Two flows of conception are used for Register Transfer Level
(RTL) and High-level Synthesis (HLS). Additionally, the relations between
linear complexity, seeds, and arithmetic operations on the one hand, and the
resources deployed in FPGA on the other hand, are deeply investigated. In order
to do that, a SoC based on Zynq EPP with ARM Cortex-$A9$ MPSoC is developed to
accelerate the implementation and the tests of various PRNGs on FPGA hardware.
A case study is finally proposed using chaotic iterations as a post processing
for FPGA. The latter has improved the statistical profile of a combination of
PRNGs that, without it, failed in the so-called TestU01 statistical battery of
tests.
</dc:description>
 <dc:description>Comment: Accepted to Secrypt16</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08410</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08417</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Evaluation of the Privacy Breach in Disassociated Set-Valued
  Datasets</dc:title>
 <dc:creator>Barakat, Sara</dc:creator>
 <dc:creator>Bouna, Bechara Al</dc:creator>
 <dc:creator>Nassar, Mohamed</dc:creator>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Data anonymization is gaining much attention these days as it provides the
fundamental requirements to safely outsource datasets containing identifying
information. While some techniques add noise to protect privacy others use
generalization to hide the link between sensitive and non-sensitive information
or separate the dataset into clusters to gain more utility. In the latter,
often referred to as bucketization, data values are kept intact, only the link
is hidden to maximize the utility. In this paper, we showcase the limits of
disassociation, a bucketization technique that divides a set-valued dataset
into $k^m$-anonymous clusters. We demonstrate that a privacy breach might occur
if the disassociated dataset is subject to a cover problem. We finally evaluate
the privacy breach using the quantitative privacy breach detection algorithm on
real disassociated datasets.
</dc:description>
 <dc:description>Comment: Accepted to Secrypt 2016</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08418</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Card games as pointer structures: case studies in mobile CSP modelling</dc:title>
 <dc:creator>Roscoe, A. W.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The author has long enjoyed using the CSP refinement checker FDR to solve
puzzles, as witnessed by examples in \cite{tpc,ucs}. Recent experiments have
shown that a number of games of patience (card games for one) are now well
within bounds. We discuss the modelling approaches used to tackle these and
avoid symmetric states. For two such games we reveal much higher percentages of
winnable games than was previously believed. The techniques developed for some
of these card games -which employ various dynamic patterns of cards - suggest
techniques for modelling pointer structures in CSP and FDR analogous to those
used with the pi-calculus. Most of these use CSP's ability to express mobile
systems.
</dc:description>
 <dc:description>Comment: Example files available on author's website</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08418</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08419</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Graph of the Pedigree Polytope is Asymptotically Almost Complete
  (Extended Abstract)</dc:title>
 <dc:creator>Makkeh, Abdullah</dc:creator>
 <dc:creator>Pourmoradnasseri, Mozhgan</dc:creator>
 <dc:creator>Theis, Dirk Oliver</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Graphs (1-skeletons) of Traveling-Salesman-related polytopes have attracted a
lot of attention. Pedigree polytopes are extensions of the classical Symmetric
Traveling Salesman Problem polytopes (Arthanari 2000) whose graphs contain the
TSP polytope graphs as spanning subgraphs (Arthanari 2013). Unlike TSP
polytopes, Pedigree polytopes are not &quot;symmetric&quot;, e.g., their graphs are not
vertex transitive, not even regular. We show that in the graph of the pedigree
polytope, the quotient minimum degree over number of vertices tends to 1 as the
number of cities tends to infinity.
</dc:description>
 <dc:description>Comment: CALDAM 2017</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08420</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Demonstration of Fully Nonlinear Spectrum Modulated System in the Highly
  Nonlinear Optical Transmission Regime</dc:title>
 <dc:creator>Aref, Vahid</dc:creator>
 <dc:creator>Le, Son T.</dc:creator>
 <dc:creator>Buelow, Henning</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We report a 3 dB increase in the nonlinear threshold of a 64*0.5Gbaud 16-QAM
continuous-nonlinear-spectrum modulated signal by nonlinear multiplexing with
QPSK modulated multi-solitons, showing the first ever fully nonlinear-spectrum
modulated system in the highly nonlinear regime.
</dc:description>
 <dc:description>Comment: The paper was presented in European Conference on Optical
  Communication (ECOC) 2016, Sept. 2016</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08422</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomness and disorder of chaotic iterations. Applications in
  information security field</dc:title>
 <dc:creator>Fang, Xiaole</dc:creator>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:creator>Wang, Qianxue</dc:creator>
 <dc:creator>Bahi, Jacques M.</dc:creator>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Design and cryptanalysis of chaotic encryption schemes are major concerns to
provide secured information systems. Pursuing our previous research works, some
well-defined discrete chaotic iterations that satisfy the reputed Devaney's
definition of chaos have been proposed. In this article, we summarize these
contributions and propose applications in the fields of pseudorandom number
generation, hash functions, and symmetric cryptography. For all these
applications, the proofs of chaotic properties are outlined.
</dc:description>
 <dc:description>Comment: Accepted to Nolta 2015</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08422</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08431</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Graph of the Pedigree Polytope</dc:title>
 <dc:creator>Makkeh, Abdullah</dc:creator>
 <dc:creator>Pourmoradnasseri, Mozhgan</dc:creator>
 <dc:creator>Theis, Dirk Oliver</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Pedigree polytopes are extensions of the classical Symmetric Traveling
Salesman Problem polytopes whose graphs (1-skeletons) contain the TSP polytope
graphs as spanning subgraphs. While deciding adjacency of vertices in TSP
polytopes is coNP-complete, Arthanari has given a combinatorial (polynomially
decidable) characterization of adjacency in Pedigree polytopes. Based on this
characterization, we study the graphs of Pedigree polytopes asymptotically, for
large numbers of cities. Unlike TSP polytope graphs, which are vertex
transitive, Pedigree graphs are not even regular. Using an &quot;adjacency game&quot; to
handle Arthanari's intricate inductive characterization of adjacency, we prove
that the minimum degree is asymptotically equal to the number of vertices,
i.e., the graph is &quot;asymptotically almost complete&quot;.
</dc:description>
 <dc:description>Comment: An extended abstract [arXiv:1611.08419] will appear in CALDAM 2017</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08432</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Close to the Edge? Delay/utilization tradeoffs in MEC</dc:title>
 <dc:creator>Malandrino, Francesco</dc:creator>
 <dc:creator>Kirkpatrick, Scott</dc:creator>
 <dc:creator>Chiasserini, Carla-Fabiana</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Virtually all of the rapidly increasing data traffic consumed by mobile users
requires some kind of processing, normally performed at cloud servers. A recent
thrust, {\em mobile edge computing}, moves such processing to servers {\em
within} the cellular mobile network. The large temporal and spatial variations
to which mobile data usage is subject could make the reduced latency that edge
clouds offer come at an unacceptable cost in redundant and underutilized
infrastructure. We present some first empirical results on this question, based
on large scale sampled crowd-sourced traces from several major cities spanning
multiple operators and identifying the applications in use. We find
opportunities to obtain both high server utilization and low application
latency, but the best approaches will depend on the individual network
operator's deployment strategy and geographic specifics of the cities we study.
</dc:description>
 <dc:description>Comment: 6 pages 4 figures; presented at the CAN Workshop, ACM CoNEXT
  Conference, UC Irvine, December 2016</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08432</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08438</identifier>
 <datestamp>2017-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Defect Corrected Finite Element Approach for the Accurate Evaluation
  of Magnetic Fields on Unstructured Grids</dc:title>
 <dc:creator>R&#xf6;mer, Ulrich</dc:creator>
 <dc:creator>Sch&#xf6;ps, Sebastian</dc:creator>
 <dc:creator>De Gersem, Herbert</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>65N30, 78M10</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:subject>I.6.3</dc:subject>
 <dc:description>  In electromagnetic simulations of magnets and machines one is often
interested in a highly accurate and local evaluation of the magnetic field
uniformity. Based on local post-processing of the solution, a defect correction
scheme is proposed as an easy to realize alternative to higher order finite
element or hybrid approaches. Radial basis functions (RBF)s are key for the
generality of the method, which in particular can handle unstructured grids.
Also, contrary to conventional finite element basis functions, higher
derivatives of the solution can be evaluated, as required, e.g., for deflection
magnets. Defect correction is applied to obtain a solution with improved
accuracy and adjoint techniques are used to estimate the remaining error for a
specific quantity of interest. Significantly improved (local) convergence
orders are obtained. The scheme is also applied to the simulation of a
Stern-Gerlach magnet currently in operation.
</dc:description>
 <dc:description>Comment: 19 pages, 10 figures</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08438</dc:identifier>
 <dc:identifier>Journal of Computational Physics, 335 (2017), 688-699</dc:identifier>
 <dc:identifier>doi:10.1016/j.jcp.2017.01.041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08459</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Machine Translation with Latent Semantic of Image and Text</dc:title>
 <dc:creator>Toyama, Joji</dc:creator>
 <dc:creator>Misono, Masanori</dc:creator>
 <dc:creator>Suzuki, Masahiro</dc:creator>
 <dc:creator>Nakayama, Kotaro</dc:creator>
 <dc:creator>Matsuo, Yutaka</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Although attention-based Neural Machine Translation have achieved great
success, attention-mechanism cannot capture the entire meaning of the source
sentence because the attention mechanism generates a target word depending
heavily on the relevant parts of the source sentence. The report of earlier
studies has introduced a latent variable to capture the entire meaning of
sentence and achieved improvement on attention-based Neural Machine
Translation. We follow this approach and we believe that the capturing meaning
of sentence benefits from image information because human beings understand the
meaning of language not only from textual information but also from perceptual
information such as that gained from vision. As described herein, we propose a
neural machine translation model that introduces a continuous latent variable
containing an underlying semantic extracted from texts and images. Our model,
which can be trained end-to-end, requires image information only when training.
Experiments conducted with an English--German translation task show that our
model outperforms over the baseline.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08461</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discriminative Correlation Filter with Channel and Spatial Reliability</dc:title>
 <dc:creator>Luke&#x17e;i&#x10d;, Alan</dc:creator>
 <dc:creator>Voj&#xed;&#x159;, Tom&#xe1;&#x161;</dc:creator>
 <dc:creator>&#x10c;ehovin, Luka</dc:creator>
 <dc:creator>Matas, Ji&#x159;&#xed;</dc:creator>
 <dc:creator>Kristan, Matej</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Short-term tracking is an open and challenging problem for which
discriminative correlation filters (DCF) have shown excellent performance. We
introduce the channel and spatial reliability concepts to DCF tracking and
provide a novel learning algorithm for its efficient and seamless integration
in the filter update and the tracking process. The spatial reliability map
adjusts the filter support to the part of the object suitable for tracking.
This both allows to enlarge the search region and improves tracking of
non-rectangular objects. Reliability scores reflect channel-wise quality of the
learned filters and are used as feature weighting coefficients in localization.
Experimentally, with only two simple standard features, HoGs and Colornames,
the novel CSR-DCF method -- DCF with Channel and Spatial Reliability --
achieves state-of-the-art results on VOT 2016, VOT 2015 and OTB100. The CSR-DCF
runs in real-time on a CPU.
</dc:description>
 <dc:description>Comment: Accepted to: International Journal of Computer Vision:
  https://link.springer.com/article/10.1007/s11263-017-1061-3</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08461</dc:identifier>
 <dc:identifier>doi:10.1007/s11263-017-1061-3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08472</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multimodal Latent Variable Analysis</dc:title>
 <dc:creator>Papyan, Vardan</dc:creator>
 <dc:creator>Talmon, Ronen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Consider a set of multiple, multimodal sensors capturing a complex system or
a physical phenomenon of interest. Our primary goal is to distinguish the
underlying sources of variability manifested in the measured data. The first
step in our analysis is to find the common source of variability present in all
sensor measurements. We base our work on a recent paper, which tackles this
problem with alternating diffusion (AD). In this work, we suggest to further
the analysis by extracting the sensor-specific variables in addition to the
common source. We propose an algorithm, which we analyze theoretically, and
then demonstrate on three different applications: a synthetic example, a toy
problem, and the task of fetal ECG extraction.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08480</identifier>
 <datestamp>2017-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Optimization of Multi-Class SVMs</dc:title>
 <dc:creator>Alber, Maximilian</dc:creator>
 <dc:creator>Zimmert, Julian</dc:creator>
 <dc:creator>Dogan, Urun</dc:creator>
 <dc:creator>Kloft, Marius</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Training of one-vs.-rest SVMs can be parallelized over the number of classes
in a straight forward way. Given enough computational resources, one-vs.-rest
SVMs can thus be trained on data involving a large number of classes. The same
cannot be stated, however, for the so-called all-in-one SVMs, which require
solving a quadratic program of size quadratically in the number of classes. We
develop distributed algorithms for two all-in-one SVM formulations (Lee et al.
and Weston and Watkins) that parallelize the computation evenly over the number
of classes. This allows us to compare these models to one-vs.-rest SVMs on
unprecedented scale. The results indicate superior accuracy on text
classification data.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08480</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0178161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08481</identifier>
 <datestamp>2017-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GuessWhat?! Visual object discovery through multi-modal dialogue</dc:title>
 <dc:creator>de Vries, Harm</dc:creator>
 <dc:creator>Strub, Florian</dc:creator>
 <dc:creator>Chandar, Sarath</dc:creator>
 <dc:creator>Pietquin, Olivier</dc:creator>
 <dc:creator>Larochelle, Hugo</dc:creator>
 <dc:creator>Courville, Aaron</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce GuessWhat?!, a two-player guessing game as a testbed for
research on the interplay of computer vision and dialogue systems. The goal of
the game is to locate an unknown object in a rich image scene by asking a
sequence of questions. Higher-level image understanding, like spatial reasoning
and language grounding, is required to solve the proposed task. Our key
contribution is the collection of a large-scale dataset consisting of 150K
human-played games with a total of 800K visual question-answer pairs on 66K
images. We explain our design decisions in collecting the dataset and introduce
the oracle and questioner tasks that are associated with the two players of the
game. We prototyped deep learning models to establish initial baselines of the
introduced tasks.
</dc:description>
 <dc:description>Comment: 23 pages; CVPR 2017 submission; see https://guesswhat.ai</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2017-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08483</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Exponentially Weighted Aggregate with the Laplace Prior</dc:title>
 <dc:creator>Dalalyan, Arnak S.</dc:creator>
 <dc:creator>Grappin, Edwin</dc:creator>
 <dc:creator>Paris, Quentin</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we study the statistical behaviour of the Exponentially
Weighted Aggregate (EWA) in the problem of high-dimensional regression with
fixed design. Under the assumption that the underlying regression vector is
sparse, it is reasonable to use the Laplace distribution as a prior. The
resulting estimator and, specifically, a particular instance of it referred to
as the Bayesian lasso, was already used in the statistical literature because
of its computational convenience, even though no thorough mathematical analysis
of its statistical properties was carried out. The present work fills this gap
by establishing sharp oracle inequalities for the EWA with the Laplace prior.
These inequalities show that if the temperature parameter is small, the EWA
with the Laplace prior satisfies the same type of oracle inequality as the
lasso estimator does, as long as the quality of estimation is measured by the
prediction loss. Extensions of the proposed methodology to the problem of
prediction with low-rank matrices are considered.
</dc:description>
 <dc:description>Comment: 30 pages, 2 figures</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08484</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vertex-centred Method to Detect Communities in Evolving Networks</dc:title>
 <dc:creator>Canu, Ma&#xeb;l</dc:creator>
 <dc:creator>Lesot, Marie-Jeanne</dc:creator>
 <dc:creator>d'Allonnes, Adrien Revault</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Finding communities in evolving networks is a difficult task and raises
issues different from the classic static detection case. We introduce an
approach based on the recent vertex-centred paradigm. The proposed algorithm,
named DynLOCNeSs, detects communities by scanning and evaluating each vertex
neighbourhood, which can be done independently in a parallel way. It is done by
means of a preference measure, using these preferences to handle community
changes. We also introduce a new vertex neighbourhood preference measure, CWCN,
more efficient than current existing ones in the considered context.
Experimental results show the relevance of this measure and the ability of the
proposed approach to detect classical community evolution patterns such as
grow-shrink and merge-split.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08484</dc:identifier>
 <dc:identifier>Fifth International Workshop on Complex Networks and their
  Applications, Nov 2016, Milan, Italy. Proceedings of the Fifth International
  Workshop on Complex Networks and their Applications, Proceedings of the Fifth
  International Workshop on Complex Networks and their Applications</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08487</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pure and Stationary Optimal Strategies in Perfect-Information Stochastic
  Games with Global Preferences</dc:title>
 <dc:creator>Gimbert, Hugo</dc:creator>
 <dc:creator>Zielonka, Wieslaw</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We examine the problem of the existence of optimal deterministic stationary
strategiesintwo-players antagonistic (zero-sum) perfect information stochastic
games with finitely many states and actions.We show that the existenceof such
strategies follows from the existence of optimal deterministic
stationarystrategies for some derived one-player games.Thus we reducethe
problem from two-player to one-player games (Markov decisionproblems), where
usually it is much easier to tackle.The reduction is very general, it holds not
only for all possible payoff mappings but alsoin more a general situations
whereplayers' preferences are not expressed by payoffs.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08487</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08492</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multimodal Approach to Estimating Vigilance Using EEG and Forehead EOG</dc:title>
 <dc:creator>Zheng, Wei-Long</dc:creator>
 <dc:creator>Lu, Bao-Liang</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Objective. Covert aspects of ongoing user mental states provide key context
information for user-aware human computer interactions. In this paper, we focus
on the problem of estimating the vigilance of users using EEG and EOG signals.
Approach. To improve the feasibility and wearability of vigilance estimation
devices for real-world applications, we adopt a novel electrode placement for
forehead EOG and extract various eye movement features, which contain the
principal information of traditional EOG. We explore the effects of EEG from
different brain areas and combine EEG and forehead EOG to leverage their
complementary characteristics for vigilance estimation. Considering that the
vigilance of users is a dynamic changing process because the intrinsic mental
states of users involve temporal evolution, we introduce continuous conditional
neural field and continuous conditional random field models to capture dynamic
temporal dependency. Main results. We propose a multimodal approach to
estimating vigilance by combining EEG and forehead EOG and incorporating the
temporal dependency of vigilance into model training. The experimental results
demonstrate that modality fusion can improve the performance compared with a
single modality, EOG and EEG contain complementary information for vigilance
estimation, and the temporal dependency-based models can enhance the
performance of vigilance estimation. From the experimental results, we observe
that theta and alpha frequency activities are increased, while gamma frequency
activities are decreased in drowsy states in contrast to awake states.
Significance. The forehead setup allows for the simultaneous collection of EEG
and EOG and achieves comparative performance using only four shared electrodes
in comparison with the temporal and posterior sites.
</dc:description>
 <dc:description>Comment: 15 pages, 11 figures</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08496</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Percolation on random graphs with a fixed degree sequence</dc:title>
 <dc:creator>Fountoulakis, Nikolaos</dc:creator>
 <dc:creator>Joos, Felix</dc:creator>
 <dc:creator>Perarnau, Guillem</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We consider bond percolation on random graphs with given degrees and bounded
average degree. In particular, we consider the order of the largest component
after the random deletion of the edges of such a random graph. We give a rough
characterisation of those degree distributions for which bond percolation with
high probability leaves a component of linear order, known usually as a giant
component. We show that essentially the critical condition has to do with the
tail of the degree distribution. Our proof makes use of recent technique
introduced by Joos et al. [FOCS 2016, pp. 695--703], which is based on the
switching method and avoids the use of the classic configuration model as well
as the hypothesis of having a limiting object. Thus our results hold for sparse
degree sequences without the usual restrictions that accompany the
configuration model.
</dc:description>
 <dc:description>Comment: 45 pages</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08499</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Analysis of Tournament Structure</dc:title>
 <dc:creator>Bao, Nhien Pham Hoang</dc:creator>
 <dc:creator>Iida, Hiroyuki</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper explores a novel way for analyzing the tournament structures to
find a best suitable one for the tournament under consideration. It concerns
about three aspects such as tournament conducting cost, competitiveness
development and ranking precision. It then proposes a new method using progress
tree to detect potential throwaway matches. The analysis performed using the
proposed method reveals the strengths and weaknesses of tournament structures.
As a conclusion, single elimination is best if we want to qualify one winner
only, all matches conducted are exciting in term of competitiveness. Double
elimination with proper seeding system is a better choice if we want to qualify
more winners. A reasonable number of extra matches need to be conducted in
exchange of being able to qualify top four winners. Round-robin gives reliable
ranking precision for all participants. However, its conduction cost is very
high, and it fails to maintain competitiveness development.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08499</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08512</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Person Re-Identification by Unsupervised Video Matching</dc:title>
 <dc:creator>Ma, Xiaolong</dc:creator>
 <dc:creator>Zhu, Xiatian</dc:creator>
 <dc:creator>Gong, Shaogang</dc:creator>
 <dc:creator>Xie, Xudong</dc:creator>
 <dc:creator>Hu, Jianming</dc:creator>
 <dc:creator>Lam, Kin-Man</dc:creator>
 <dc:creator>Zhong, Yisheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Most existing person re-identification (ReID) methods rely only on the
spatial appearance information from either one or multiple person images,
whilst ignore the space-time cues readily available in video or image-sequence
data. Moreover, they often assume the availability of exhaustively labelled
cross-view pairwise data for every camera pair, making them non-scalable to
ReID applications in real-world large scale camera networks. In this work, we
introduce a novel video based person ReID method capable of accurately matching
people across views from arbitrary unaligned image-sequences without any
labelled pairwise data. Specifically, we introduce a new space-time person
representation by encoding multiple granularities of spatio-temporal dynamics
in form of time series. Moreover, a Time Shift Dynamic Time Warping (TS-DTW)
model is derived for performing automatically alignment whilst achieving data
selection and matching between inherently inaccurate and incomplete sequences
in a unified way. We further extend the TS-DTW model for accommodating multiple
feature-sequences of an image-sequence in order to fuse information from
different descriptions. Crucially, this model does not require pairwise
labelled training data (i.e. unsupervised) therefore readily scalable to large
scale camera networks of arbitrary camera pairs without the need for exhaustive
data annotation for every camera pair. We show the effectiveness and advantages
of the proposed method by extensive comparisons with related state-of-the-art
approaches using two benchmarking ReID datasets, PRID2011 and iLIDS-VID.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08514</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reliability of k-out-of-n Data Storage System with Deterministic
  Parallel and Serial Repair</dc:title>
 <dc:creator>Aggarwal, Vaneet</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we find the Laplace Stieltjes transform of the probability of
data loss for the k-out-of-n distributed storage system with deterministic
repair times. We consider two repair models, namely the serial and parallel
repair. We show that for failure rate much lower than the repair rate, mean
time of data loss for the two models is the same unlike the case for
exponential repair models.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08514</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08520</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dissecting the End-to-end Latency of Interactive Mobile Video
  Applications</dc:title>
 <dc:creator>K&#xe4;m&#xe4;r&#xe4;inen, Teemu</dc:creator>
 <dc:creator>Siekkinen, Matti</dc:creator>
 <dc:creator>Yl&#xe4;-J&#xe4;&#xe4;ski, Antti</dc:creator>
 <dc:creator>Zhang, Wenxiao</dc:creator>
 <dc:creator>Hui, Pan</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  In this paper we measure the step-wise latency in the pipeline of three kinds
of interactive mobile video applications that are rapidly gaining popularity,
namely Remote Graphics Rendering (RGR) of which we focus on mobile cloud
gaming, Mobile Augmented Reality (MAR), and Mobile Virtual Reality (MVR). The
applications differ from each other by the way in which the user interacts with
the application, i.e., video I/O and user controls, but they all share in
common the fact that their user experience is highly sensitive to end-to-end
latency. Long latency between a user control event and display update renders
the application unusable. Hence, understanding the nature and origins of
latency of these applications is of paramount importance. We show through
extensive measurements that control input and display buffering have a
substantial effect on the overall delay. Our results shed light on the latency
bottlenecks and the maturity of technology for seamless user experience with
these applications.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08527</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Clickstream analysis for crowd-based object segmentation with confidence</dc:title>
 <dc:creator>Heim, Eric</dc:creator>
 <dc:creator>Seitel, Alexander</dc:creator>
 <dc:creator>Andrulis, Jonas</dc:creator>
 <dc:creator>Isensee, Fabian</dc:creator>
 <dc:creator>Stock, Christian</dc:creator>
 <dc:creator>Ross, Tobias</dc:creator>
 <dc:creator>Maier-Hein, Lena</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With the rapidly increasing interest in machine learning based solutions for
automatic image annotation, the availability of reference annotations for
algorithm training is one of the major bottlenecks in the field. Crowdsourcing
has evolved as a valuable option for low-cost and large-scale data annotation;
however, quality control remains a major issue which needs to be addressed. To
our knowledge, we are the first to analyze the annotation process to improve
crowd-sourced image segmentation. Our method involves training a regressor to
estimate the quality of a segmentation from the annotator's clickstream data.
The quality estimation can be used to identify spam and weight individual
annotations by their (estimated) quality when merging multiple segmentations of
one image. Using a total of 29,000 crowd annotations performed on publicly
available data of different object classes, we show that (1) our method is
highly accurate in estimating the segmentation quality based on clickstream
data, (2) outperforms state-of-the-art methods for merging multiple
annotations. As the regressor does not need to be trained on the object class
that it is applied to it can be regarded as a low-cost option for quality
control and confidence analysis in the context of crowd-based image annotation.
</dc:description>
 <dc:description>Comment: to appear in IEEE Transactions on Pattern Analysis and Machine
  Intelligence (TPAMI)</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08527</dc:identifier>
 <dc:identifier>doi:10.1109/TPAMI.2017.2777967</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08541</identifier>
 <datestamp>2017-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reasoning about Strategies: on the Satisfiability Problem</dc:title>
 <dc:creator>Mogavero, Fabio</dc:creator>
 <dc:creator>Murano, Aniello</dc:creator>
 <dc:creator>Perelli, Giuseppe</dc:creator>
 <dc:creator>Vardi, Moshe Y.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  Strategy Logic (SL, for short) has been introduced by Mogavero, Murano, and
Vardi as a useful formalism for reasoning explicitly about strategies, as
first-order objects, in multi-agent concurrent games. This logic turns out to
be very powerful, subsuming all major previously studied modal logics for
strategic reasoning, including ATL, ATL*, and the like. Unfortunately, due to
its high expressiveness, SL has a non-elementarily decidable model-checking
problem and the satisfiability question is undecidable, specifically Sigma_1^1.
  In order to obtain a decidable sublogic, we introduce and study here One-Goal
Strategy Logic (SL[1G], for short). This is a syntactic fragment of SL,
strictly subsuming ATL*, which encompasses formulas in prenex normal form
having a single temporal goal at a time, for every strategy quantification of
agents. We prove that, unlike SL, SL[1G] has the bounded tree-model property
and its satisfiability problem is decidable in 2ExpTime, thus not harder than
the one for ATL*.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1112.6275, arXiv:1202.1309</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2017-03-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08541</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 1 (March 17,
  2017) lmcs:3204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08546</identifier>
 <datestamp>2016-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Throughput Maximization and Power Control in Poisson CoopMAC
  Networks</dc:title>
 <dc:creator>Sadeghi, Masoumeh</dc:creator>
 <dc:creator>Nikbakht, Homa</dc:creator>
 <dc:creator>Rabiei, Amir Masoud</dc:creator>
 <dc:creator>Shah-Mansouri, Vahid</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A cooperative medium access control (CoopMAC) network with randomly
distributed helpers is considered. We introduce a new helper selection scheme
which maximizes the average throughput while maintaining a low power
consumption profile in the network. To this end, all transmissions are assumed
to be performed using power control. We assume that each node can estimate the
channel between itself and a receiving node. Then, it evaluates the minimum
transmission power needed to achieve the desired signal to noise ratio (SNR).
If the required transmission power is less than the maximum transmission power
of the node, the communication is regarded as successful. Otherwise, the
transmission is canceled. %Also, we classify the helpers into six groups
according to their transmission rates IEEE 802.11b Standard. In order to
increase the average throughput, we assume that the cooperative link with the
highest transmission rate is chosen from those that can successfully forward
the source signal to destination. Also, when there are several links with the
same rates, the one with minimum required power is given the highest priority.
Assuming that the helpers are distributed as a Poisson point process with fixed
intensity, we derive exact expressions for the average throughput and the power
consumption of the network. Simulation results show that our scheme is able to
significantly increase the throughput in comparison to the conventional CoopMAC
network. It is also able to reduce the power consumption compared to a network
with no power control approach.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the author due to some modifications
  needed to be done</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2016-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08546</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08547</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The G-ACM Tool: using the Drools Rule Engine for Access Control
  Management</dc:title>
 <dc:creator>S&#xe1;, Jo&#xe3;o</dc:creator>
 <dc:creator>Alves, Sandra</dc:creator>
 <dc:creator>Broda, Sabine</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In this paper we explore the usage of rule engines in a graphical framework
for visualising dynamic access control policies. We use the Drools rule engine
to dynamically compute permissions, following the Category-Based Access Control
metamodel.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08550</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The sum of it all: revealing collaboration patterns by combining
  authorship and acknowledgements</dc:title>
 <dc:creator>Paul-Hus, Adele</dc:creator>
 <dc:creator>Mongeon, Philippe</dc:creator>
 <dc:creator>Sainte-Marie, Maxime</dc:creator>
 <dc:creator>Lariviere, Vincent</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Acknowledgments are one of many conventions by which researchers publicly
bestow recognition towards individuals, organizations and institutions that
contributed in some way to the work that led to publication. Combining data on
both co-authors and acknowledged individuals, the present study analyses
disciplinary differences in researchers credit attribution practices in
collaborative context. Our results show that the important differences
traditionally observed between disciplines in terms of team size are greatly
reduced when acknowledgees are taken into account. Broadening the measurement
of collaboration beyond co-authorship by including individuals credited in the
acknowledgements allows for an assessment of collaboration practices and team
work that might be closer to the reality of contemporary research, especially
in the social sciences and humanities.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08550</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2016.11.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08554</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asynchronous Distributed Automata: A Characterization of the Modal
  Mu-Fragment</dc:title>
 <dc:creator>Reiter, Fabian</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We establish the equivalence between a class of asynchronous distributed
automata and a small fragment of least fixpoint logic, when restricted to
finite directed graphs. More specifically, the logic we consider is (a variant
of) the fragment of the modal $\mu$-calculus that allows least fixpoints but
forbids greatest fixpoints. The corresponding automaton model uses a network of
identical finite-state machines that communicate in an asynchronous manner and
whose state diagram must be acyclic except for self-loops. Exploiting the
connection with logic, we also prove that the expressive power of those
machines is independent of whether or not messages can be lost.
</dc:description>
 <dc:description>Comment: 13 pages, 2 figures</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2017-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08554</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08555</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Trends in Neutrosophic Theory and Applications</dc:title>
 <dc:creator>Smarandache, Florentin</dc:creator>
 <dc:creator>Pramanik, Surapati</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  Neutrosophic theory and applications have been expanding in all directions at
an astonishing rate especially after the introduction the journal entitled
Neutrosophic Sets and Systems. New theories, techniques, algorithms have been
rapidly developed. One of the most striking trends in the neutrosophic theory
is the hybridization of neutrosophic set with other potential sets such as
rough set, bipolar set, soft set, hesitant fuzzy set, etc. The different hybrid
structure such as rough neutrosophic set, single valued neutrosophic rough set,
bipolar neutrosophic set, single valued neutrosophic hesitant fuzzy set, etc.
are proposed in the literature in a short period of time. Neutrosophic set has
been a very important tool in all various areas of data mining, decision
making, e-learning, engineering, medicine, social science, and some more. The
book New Trends in Neutrosophic Theories and Applications focuses on theories,
methods, algorithms for decision making and also applications involving
neutrosophic information. Some topics deal with data mining, decision making,
e-learning, graph theory, medical diagnosis, probability theory, topology, and
some more.
</dc:description>
 <dc:description>Comment: 424 pages</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08555</dc:identifier>
 <dc:identifier>Pons asbl, Brussels, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08560</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User Point Processes in Cellular Networks</dc:title>
 <dc:creator>Haenggi, Martin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  The point process of concurrent users is critical for the analysis of
cellular networks, in particular for the uplink and for full-duplex
communication. We analyze the properties of two popular models. For the first
one, we provide an accurate characterization of the pair correlation functions
from the user and the base station point of view, which are applied to
approximate the user process by Poisson and Ginibre point processes. For the
second model, which includes the first model asymptotically, we study the cell
vacancy probability, the mean area of vacant and occupied cells, the user-base
station distance, and the pair correlation function in lightly and heavily
loaded regimes.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08561</identifier>
 <datestamp>2017-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tight Rate Bound and a Matching Construction for Locally Recoverable
  Codes with Sequential Recovery From Any Number of Multiple Erasures</dc:title>
 <dc:creator>Balaji, S. B.</dc:creator>
 <dc:creator>Kini, Ganesh R.</dc:creator>
 <dc:creator>Kumar, P. Vijay</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  An $[n,k]$ code $\mathcal{C}$ is said to be locally recoverable in the
presence of a single erasure, and with locality parameter $r$, if each of the
$n$ code symbols of $\mathcal{C}$ can be recovered by accessing at most $r$
other code symbols. An $[n,k]$ code is said to be a locally recoverable code
with sequential recovery from $t$ erasures, if for any set of $s \leq t$
erasures, there is an $s$-step sequential recovery process, in which at each
step, a single erased symbol is recovered by accessing at most $r$ other code
symbols. This is equivalent to the requirement that for any set of $s \leq t$
erasures, the dual code contain a codeword whose support contains the
coordinate of precisely one of the $s$ erased symbols. In this paper, a tight
upper bound on the rate of such a code, for any value of number of erasures $t$
and any value $r \geq 3$, of the locality parameter is derived. This bound
proves an earlier conjecture due to Song, Cai and Yuen. While the bound is
valid irrespective of the field over which the code is defined, a matching
construction of {\em binary} codes that are rate-optimal is also provided,
again for any value of $t$ and any value $r\geq3$.
</dc:description>
 <dc:description>Comment: Revised version of the paper with revised title and abstract (longer
  version of ISIT 2017 submission)</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2017-02-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08562</identifier>
 <datestamp>2016-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple, Fast Diverse Decoding Algorithm for Neural Generation</dc:title>
 <dc:creator>Li, Jiwei</dc:creator>
 <dc:creator>Monroe, Will</dc:creator>
 <dc:creator>Jurafsky, Dan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we propose a simple, fast decoding algorithm that fosters
diversity in neural generation. The algorithm modifies the standard beam search
algorithm by adding an inter-sibling ranking penalty, favoring choosing
hypotheses from diverse parents. We evaluate the proposed model on the tasks of
dialogue response generation, abstractive summarization and machine
translation. We find that diverse decoding helps across all tasks, especially
those for which reranking is needed.
  We further propose a variation that is capable of automatically adjusting its
diversity decoding rates for different inputs using reinforcement learning
(RL). We observe a further performance boost from this RL technique. This paper
includes material from the unpublished script &quot;Mutual Information and Diverse
Decoding Improve Neural Machine Translation&quot; (Li and Jurafsky, 2016).
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2016-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08562</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08563</identifier>
 <datestamp>2017-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Real-time Multiple Spatiotemporal Action Localisation and
  Prediction</dc:title>
 <dc:creator>Singh, Gurkirt</dc:creator>
 <dc:creator>Saha, Suman</dc:creator>
 <dc:creator>Sapienza, Michael</dc:creator>
 <dc:creator>Torr, Philip</dc:creator>
 <dc:creator>Cuzzolin, Fabio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a deep-learning framework for real-time multiple spatio-temporal
(S/T) action localisation, classification and early prediction. Current
state-of-the-art approaches work offline and are too slow to be useful in real-
world settings. To overcome their limitations we introduce two major
developments. Firstly, we adopt real-time SSD (Single Shot MultiBox Detector)
convolutional neural networks to regress and classify detection boxes in each
video frame potentially containing an action of interest. Secondly, we design
an original and efficient online algorithm to incrementally construct and label
`action tubes' from the SSD frame level detections. As a result, our system is
not only capable of performing S/T detection in real time, but can also perform
early action prediction in an online fashion. We achieve new state-of-the-art
results in both S/T action localisation and early action prediction on the
challenging UCF101-24 and J-HMDB-21 benchmarks, even when compared to the top
offline competitors. To the best of our knowledge, ours is the first real-time
(up to 40fps) system able to perform online S/T action localisation and early
action prediction on the untrimmed videos of UCF101-24.
</dc:description>
 <dc:description>Comment: 10 pages 3 figures, ICCV 2017, Added link to new annotations of
  ucf101-24</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2017-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08568</identifier>
 <datestamp>2017-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bottleneck Conditional Density Estimation</dc:title>
 <dc:creator>Shu, Rui</dc:creator>
 <dc:creator>Bui, Hung H.</dc:creator>
 <dc:creator>Ghavamzadeh, Mohammad</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce a new framework for training deep generative models for
high-dimensional conditional density estimation. The Bottleneck Conditional
Density Estimator (BCDE) is a variant of the conditional variational
autoencoder (CVAE) that employs layer(s) of stochastic variables as the
bottleneck between the input $x$ and target $y$, where both are
high-dimensional. Crucially, we propose a new hybrid training method that
blends the conditional generative model with a joint generative model. Hybrid
blending is the key to effective training of the BCDE, which avoids overfitting
and provides a novel mechanism for leveraging unlabeled data. We show that our
hybrid training procedure enables models to achieve competitive results in the
MNIST quadrant prediction task in the fully-supervised setting, and sets new
benchmarks in the semi-supervised regime for MNIST, SVHN, and CelebA.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2017-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08568</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08571</identifier>
 <datestamp>2017-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On preparing ground states of gapped Hamiltonians: An efficient Quantum
  Lov\'asz Local Lemma</dc:title>
 <dc:creator>Gily&#xe9;n, Andr&#xe1;s</dc:creator>
 <dc:creator>Sattath, Or</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A frustration-free local Hamiltonian has the property that its ground state
minimises the energy of all local terms simultaneously. In general, even
deciding whether a Hamiltonian is frustration-free is a hard task, as it is
closely related to the QMA1-complete quantum satisfiability problem (QSAT) --
the quantum analogue of SAT, which is the archetypal NP-complete problem in
classical computer science. This connection shows that the frustration-free
property is not only relevant to physics but also to computer science. The
Quantum Lov\'asz Local Lemma (QLLL) provides a sufficient condition for
frustration-freeness. A natural question is whether there is an efficient way
to prepare a frustration-free state under the conditions of the QLLL. Previous
results showed that the answer is positive if all local terms commute. In this
work we improve on the previous constructive results by designing an algorithm
that works efficiently for non-commuting terms as well, assuming that the
system is &quot;uniformly&quot; gapped, by which we mean that the system and all its
subsystems have an inverse polynomial energy gap. Also, our analysis works
under the most general condition for the QLLL, known as Shearer's bound.
Similarly to the previous results, our algorithm has the charming feature that
it uses only local measurement operations corresponding to the local
Hamiltonian terms.
</dc:description>
 <dc:description>Comment: 39 pages</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08571</dc:identifier>
 <dc:identifier>In 58th IEEE Symposium on Foundations of Computer Science (FOCS
  2017), pp.439-450</dc:identifier>
 <dc:identifier>doi:10.1109/FOCS.2017.47</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08572</identifier>
 <datestamp>2016-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bipolar Weighted Argumentation Graphs</dc:title>
 <dc:creator>Mossakowski, Till</dc:creator>
 <dc:creator>Neuhaus, Fabian</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper discusses the semantics of weighted argumentation graphs that are
biplor, i.e. contain both attacks and support graphs. The work builds on
previous work by Amgoud, Ben-Naim et. al., which presents and compares several
semantics for argumentation graphs that contain only supports or only attacks
relationships, respectively.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2016-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08572</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08573</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Marriage of Incremental and Approximate Computing</dc:title>
 <dc:creator>Krishnan, Dhanya R</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Most data analytics systems that require low-latency execution and efficient
utilization of computing resources, increasingly adopt two computational
paradigms, namely, incremental and approximate computing. Incremental
computation updates the output incrementally instead of re-computing everything
from scratch for successive runs of a job with input changes. Approximate
computation returns an approximate output for a job instead of the exact
output.
  Both paradigms rely on computing over a subset of data items instead of
computing over the entire dataset, but they differ in their means for skipping
parts of the computation. Incremental computing relies on the memoization of
intermediate results of sub-computations, and reusing these memoized results
across jobs for sub-computations that are unaffected by the changed input.
Approximate computing relies on representative sampling of the entire dataset
to compute over a subset of data items.
  In this thesis, we make the observation that these two computing paradigms
are complementary, and can be married together! The high level idea is to:
design a sampling algorithm that biases the sample selection to the memoized
data items from previous runs. To concretize this idea, we designed an online
stratified sampling algorithm that uses self-adjusting computation to produce
an incrementally updated approximate output with bounded error. We implemented
our algorithm in a data analytics system called IncAppox based on Apache Spark
Streaming. Our evaluation of the system shows that IncApprox achieves the
benefits of both incremental and approximate computing.
</dc:description>
 <dc:description>Comment: http://dl.acm.org/citation.cfm?id=2883026</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08573</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08574</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Streaming Algorithm for the Submodular Cover Problem</dc:title>
 <dc:creator>Norouzi-Fard, Ashkan</dc:creator>
 <dc:creator>Bazzi, Abbas</dc:creator>
 <dc:creator>Halabi, Marwa El</dc:creator>
 <dc:creator>Bogunovic, Ilija</dc:creator>
 <dc:creator>Hsieh, Ya-Ping</dc:creator>
 <dc:creator>Cevher, Volkan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We initiate the study of the classical Submodular Cover (SC) problem in the
data streaming model which we refer to as the Streaming Submodular Cover (SSC).
We show that any single pass streaming algorithm using sublinear memory in the
size of the stream will fail to provide any non-trivial approximation
guarantees for SSC. Hence, we consider a relaxed version of SSC, where we only
seek to find a partial cover.
  We design the first Efficient bicriteria Submodular Cover Streaming
(ESC-Streaming) algorithm for this problem, and provide theoretical guarantees
for its performance supported by numerical evidence. Our algorithm finds
solutions that are competitive with the near-optimal offline greedy algorithm
despite requiring only a single pass over the data stream. In our numerical
experiments, we evaluate the performance of ESC-Streaming on active set
selection and large-scale graph cover problems.
</dc:description>
 <dc:description>Comment: To appear in NIPS'16</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08583</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning from Maps: Visual Common Sense for Autonomous Driving</dc:title>
 <dc:creator>Seff, Ari</dc:creator>
 <dc:creator>Xiao, Jianxiong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Today's autonomous vehicles rely extensively on high-definition 3D maps to
navigate the environment. While this approach works well when these maps are
completely up-to-date, safe autonomous vehicles must be able to corroborate the
map's information via a real time sensor-based system. Our goal in this work is
to develop a model for road layout inference given imagery from on-board
cameras, without any reliance on high-definition maps. However, no sufficient
dataset for training such a model exists. Here, we leverage the availability of
standard navigation maps and corresponding street view images to construct an
automatically labeled, large-scale dataset for this complex scene understanding
problem. By matching road vectors and metadata from navigation maps with Google
Street View images, we can assign ground truth road layout attributes (e.g.,
distance to an intersection, one-way vs. two-way street) to the images. We then
train deep convolutional networks to predict these road layout attributes given
a single monocular RGB image. Experimental evaluation demonstrates that our
model learns to correctly infer the road attributes using only panoramas
captured by car-mounted cameras as input. Additionally, our results indicate
that this method may be suitable to the novel application of recommending
safety improvements to infrastructure (e.g., suggesting an alternative speed
limit for a street).
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08588</identifier>
 <datestamp>2016-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PVANet: Lightweight Deep Neural Networks for Real-time Object Detection</dc:title>
 <dc:creator>Hong, Sanghoon</dc:creator>
 <dc:creator>Roh, Byungseok</dc:creator>
 <dc:creator>Kim, Kye-Hyeon</dc:creator>
 <dc:creator>Cheon, Yeongjae</dc:creator>
 <dc:creator>Park, Minje</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In object detection, reducing computational cost is as important as improving
accuracy for most practical usages. This paper proposes a novel network
structure, which is an order of magnitude lighter than other state-of-the-art
networks while maintaining the accuracy. Based on the basic principle of more
layers with less channels, this new deep neural network minimizes its
redundancy by adopting recent innovations including C.ReLU and Inception
structure. We also show that this network can be trained efficiently to achieve
solid results on well-known object detection benchmarks: 84.9% and 84.2% mAP on
VOC2007 and VOC2012 while the required compute is less than 10% of the recent
ResNet-101.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop on Efficient Methods for Deep Neural
  Networks (EMDNN). Continuation of arXiv:1608.08021. The affiliation has been
  corrected</dc:description>
 <dc:date>2016-11-23</dc:date>
 <dc:date>2016-12-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08588</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08592</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A conservation rule for constructing bibliometric network matrices</dc:title>
 <dc:creator>Prathap, Gangan</dc:creator>
 <dc:creator>Mukherjee, Somenath</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  The social network analysis of bibliometric data needs matrices to be recast
in a network framework. In this paper we argue that a simple conservation rule
requires that this should be done only using fractional counting so that
conservation at the paper level will be faithfully reproduced at higher levels
ofaggregation (i.e. author, institute, country, journal etc.) of the complex
network.
</dc:description>
 <dc:description>Comment: 8 pages, 2 tables</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08592</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08618</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Benchmark and Comparison of Active Learning for Logistic Regression</dc:title>
 <dc:creator>Yang, Yazhou</dc:creator>
 <dc:creator>Loog, Marco</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Various active learning methods based on logistic regression have been
proposed. In this paper, we investigate seven state-of-the-art strategies,
present an extensive benchmark, and provide a better understanding of their
underlying characteristics. Experiments are carried out both on 3 synthetic
datasets and 43 real-world datasets, providing insights into the behaviour of
these active learning methods with respect to classification accuracy and their
computational cost.
</dc:description>
 <dc:description>Comment: 18 pages, 6 figures, 4 tables</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08618</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08624</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast deterministic tourist walk for texture analysis</dc:title>
 <dc:creator>Ribas, Lucas Correia</dc:creator>
 <dc:creator>Bruno, Odemir Martinez</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deterministic tourist walk (DTW) has attracted increasing interest in
computer vision. In the last years, different methods for analysis of dynamic
and static textures were proposed. So far, all works based on the DTW for
texture analysis use all image pixels as initial point of a walk. However, this
requires much runtime. In this paper, we conducted a study to verify the
performance of the DTW method according to the number of initial points to
start a walk. The proposed method assigns a unique code to each image pixel,
then, the pixels whose code is not divisible by a given $k$ value are ignored
as initial points of walks. Feature vectors were extracted and a classification
process was performed for different percentages of initial points. Experimental
results on the Brodatz and Vistex datasets indicate that to use fewer pixels as
initial points significantly improves the runtime compared to use all image
pixels. In addition, the correct classification rate decreases very little.
</dc:description>
 <dc:description>Comment: 7 page, 7 figure</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08624</dc:identifier>
 <dc:identifier>WVC 2016 proceedings p45-50</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08625</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Directional Mean Curvature for Textured Image Demixing</dc:title>
 <dc:creator>Thai, Duy Hoang</dc:creator>
 <dc:creator>Banks, David</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Approximation theory plays an important role in image processing, especially
image deconvolution and decomposition. For piecewise smooth images, there are
many methods that have been developed over the past thirty years. The goal of
this study is to devise similar and practical methodology for handling textured
images. This problem is motivated by forensic imaging, since fingerprints,
shoeprints and bullet ballistic evidence are textured images. In particular, it
is known that texture information is almost destroyed by a blur operator, such
as a blurred ballistic image captured from a low-cost microscope. The
contribution of this work is twofold: first, we propose a mathematical model
for textured image deconvolution and decomposition into four meaningful
components, using a high-order partial differential equation approach based on
the directional mean curvature. Second, we uncover a link between functional
analysis and multiscale sampling theory, e.g., harmonic analysis and filter
banks. Both theoretical results and examples with natural images are provided
to illustrate the performance of the proposed model.
</dc:description>
 <dc:description>Comment: 72 pages, including main manuscript (36 pages) and Appendix (36
  pages); 14 figures; journal</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08625</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08629</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Texture analysis using deterministic partially self-avoiding walk with
  thresholds</dc:title>
 <dc:creator>Ribas, Lucas Correia</dc:creator>
 <dc:creator>Gon&#xe7;alves, Wesley Nunes</dc:creator>
 <dc:creator>Bruno, Odemir Martinez</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a new texture analysis method using the
deterministic partially self-avoiding walk performed on maps modified with
thresholds. In this method, two pixels of the map are neighbors if the
Euclidean distance between them is less than $\sqrt{2}$ and the weight
(difference between its intensities) is less than a given threshold. The maps
obtained by using different thresholds highlight several properties of the
image that are extracted by the deterministic walk. To compose the feature
vector, deterministic walks are performed with different thresholds and its
statistics are concatenated. Thus, this approach can be considered as a
multi-scale analysis. We validate our method on the Brodatz database, which is
very well known public image database and widely used by texture analysis
methods. Experimental results indicate that the proposed method presents a good
texture discrimination, overcoming traditional texture methods.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08629</dc:identifier>
 <dc:identifier>WVC proceedings 2016, pages 39-44</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08641</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Control for Generalized Network-Flow Problems</dc:title>
 <dc:creator>Sinha, Abhishek</dc:creator>
 <dc:creator>Modiano, Eytan</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We consider the problem of throughput-optimal packet dissemination, in the
presence of an arbitrary mix of unicast, broadcast, multicast and anycast
traffic, in a general wireless network. We propose an online dynamic policy,
called Universal Max-Weight (UMW), which solves the above problem efficiently.
To the best of our knowledge, UMW is the first throughput-optimal algorithm of
such versatility in the context of generalized network flow problems.
Conceptually, the UMW policy is derived by relaxing the precedence constraints
associated with multi-hop routing, and then solving a min-cost routing and
max-weight scheduling problem on a virtual network of queues. When specialized
to the unicast setting, the UMW policy yields a throughput-optimal cycle-free
routing and link scheduling policy. This is in contrast to the well-known
throughput-optimal Back- Pressure (BP) policy which allows for packet cycling,
resulting in excessive latency. Extensive simulation results show that the
proposed UMW policy incurs a substantially smaller delay as compared to the BP
policy. The proof of throughput-optimality of the UMW policy combines ideas
from stochastic Lyapunov theory with a sample path argument from adversarial
queueing theory and may be of independent theoretical interest.
</dc:description>
 <dc:description>Comment: To appear in IEEE INFOCOM, 2017</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08647</identifier>
 <datestamp>2016-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual MCDRR Scheduler for Hybrid TDM/WDM Optical Networks</dc:title>
 <dc:creator>Sathiyanarayanan, Mithileysh</dc:creator>
 <dc:creator>Abubhakar, Babangida</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper we propose and investigate the performance of a dual
multi-channel deficit round-robin (D-MCDRR) scheduler based on the existing
single MCDRR scheduler. The existing scheduler is used for multiple channels
with tunable transmitters and fixed receivers in hybrid time division
multiplexing (TDM)/wavelength division multiplexing (WDM) optical networks. The
proposed dual scheduler will also be used in the same optical networks. We
extend the existing MCDRR scheduling algorithm for n channels to the case of
considering two schedulers for the same n channels. Simulation results show
that the proposed dual MCDRR (D-MCDRR) scheduler can provide better throughput
when compared to the existing single MCDRR scheduler.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures, Networks &amp; Soft Computing (ICNSC), 2014 First
  International Conference on. arXiv admin note: text overlap with
  arXiv:1308.5092</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08647</dc:identifier>
 <dc:identifier>doi:10.1109/CNSC.2014.6906708</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08648</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Patient-Driven Privacy Control through Generalized Distillation</dc:title>
 <dc:creator>Celik, Z. Berkay</dc:creator>
 <dc:creator>Lopez-Paz, David</dc:creator>
 <dc:creator>McDaniel, Patrick</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The introduction of data analytics into medicine has changed the nature of
patient treatment. In this, patients are asked to disclose personal information
such as genetic markers, lifestyle habits, and clinical history. This data is
then used by statistical models to predict personalized treatments. However,
due to privacy concerns, patients often desire to withhold sensitive
information. This self-censorship can impede proper diagnosis and treatment,
which may lead to serious health complications and even death over time. In
this paper, we present privacy distillation, a mechanism which allows patients
to control the type and amount of information they wish to disclose to the
healthcare providers for use in statistical models. Meanwhile, it retains the
accuracy of models that have access to all patient data under a sufficient but
not full set of privacy-relevant information. We validate privacy distillation
using a corpus of patients prescribed to warfarin for a personalized dosage. We
use a deep neural network to implement privacy distillation for training and
making dose predictions. We find that privacy distillation with sufficient
privacy-relevant information i) retains accuracy almost as good as having all
patient data (only 3\% worse), and ii) is effective at preventing errors that
introduce health-related risks (only 3.9\% worse under- or over-prescriptions).
</dc:description>
 <dc:description>Comment: IEEE Symposium on Privacy-Aware Computing (IEEE PAC), 2017</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2017-10-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08651</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings of the 4th and 5th International Workshop on Trends in
  Functional Programming in Education</dc:title>
 <dc:creator>Jeuring, Johan</dc:creator>
 <dc:creator>McCarthy, Jay</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This volume contains the proceedings of the Fourth and Fifth International
Workshops on Trends in Functional Programming in Education, TFPIE 2015 and
TFPIE 2016, which were held on June 2, 2015 in Sophia-Antipolis, France, and on
June 7, 2016 at the University of Maryland College Park in the USA,
respectively.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08651</dc:identifier>
 <dc:identifier>EPTCS 230, 2016</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.230</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08655</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Deep Neural Network to identify foreshocks in real time</dc:title>
 <dc:creator>Vikraman, K.</dc:creator>
 <dc:subject>Physics - Geophysics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Foreshock events provide valuable insight to predict imminent major
earthquakes. However, it is difficult to identify them in real time. In this
paper, I propose an algorithm based on deep learning to instantaneously
classify a seismic waveform as a foreshock, mainshock or an aftershock event
achieving a high accuracy of 99% in classification. As a result, this is by far
the most reliable method to predict major earthquakes that are preceded by
foreshocks. In addition, I discuss methods to create an earthquake dataset that
is compatible with deep networks.
</dc:description>
 <dc:description>Comment: Paper on earthquake prediction based on deep learning approach. 6
  figures, two tables and 4 pages in total</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08655</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08656</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attention-based Memory Selection Recurrent Network for Language Modeling</dc:title>
 <dc:creator>Liu, Da-Rong</dc:creator>
 <dc:creator>Chuang, Shun-Po</dc:creator>
 <dc:creator>Lee, Hung-yi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recurrent neural networks (RNNs) have achieved great success in language
modeling. However, since the RNNs have fixed size of memory, their memory
cannot store all the information about the words it have seen before in the
sentence, and thus the useful long-term information may be ignored when
predicting the next words. In this paper, we propose Attention-based Memory
Selection Recurrent Network (AMSRN), in which the model can review the
information stored in the memory at each previous time step and select the
relevant information to help generate the outputs. In AMSRN, the attention
mechanism finds the time steps storing the relevant information in the memory,
and memory selection determines which dimensions of the memory are involved in
computing the attention weights and from which the information is extracted.In
the experiments, AMSRN outperformed long short-term memory (LSTM) based
language models on both English and Chinese corpora. Moreover, we investigate
using entropy as a regularizer for attention weights and visualize how the
attention mechanism helps language modeling.
</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08656</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08657</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Experts Constrained Local Model for Facial Landmark
  Detection</dc:title>
 <dc:creator>Zadeh, Amir</dc:creator>
 <dc:creator>Baltru&#x161;aitis, Tadas</dc:creator>
 <dc:creator>Morency, Louis-Philippe</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Constrained Local Models (CLMs) are a well-established family of methods for
facial landmark detection. However, they have recently fallen out of favor to
cascaded regression-based approaches. This is in part due to the inability of
existing CLM local detectors to model the very complex individual landmark
appearance that is affected by expression, illumination, facial hair, makeup,
and accessories. In our work, we present a novel local detector --
Convolutional Experts Network (CEN) -- that brings together the advantages of
neural architectures and mixtures of experts in an end-to-end framework. We
further propose a Convolutional Experts Constrained Local Model (CE-CLM)
algorithm that uses CEN as local detectors. We demonstrate that our proposed
CE-CLM algorithm outperforms competitive state-of-the-art baselines for facial
landmark detection by a large margin on four publicly-available datasets. Our
approach is especially accurate and robust on challenging profile images.
</dc:description>
 <dc:description>Comment: Accepted at CVPR-W 2017</dc:description>
 <dc:date>2016-11-25</dc:date>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08657</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08660</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the DoF of Two-way $2\times2\times2$ Relay Networks with or without
  Relay Caching</dc:title>
 <dc:creator>Ashraphijuo, Mehdi</dc:creator>
 <dc:creator>Aggarwal, Vaneet</dc:creator>
 <dc:creator>Wang, Xiaodong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Two-way relay is potentially an effective approach to spectrum sharing and
aggregation by allowing simultaneous bidirectional transmissions between
source-destinations pairs. This paper studies the two-way $2\times2\times2$
relay network, a class of four-unicast networks, where there are four
source/destination nodes and two relay nodes, with each source sending a
message to its destination. We show that without relay caching the total
degrees of freedom (DoF) is bounded from above by $8/3$, indicating that
bidirectional links do not double the DoF (It is known that the total DoF of
one-way $2\times2\times2$ relay network is $2$.). Further, we show that the DoF
of $8/3$ is achievable for the two-way $2\times2\times2$ relay network with
relay caching. Finally, even though the DoF of this network is no more than
$8/3$ for generic channel gains, DoF of $4$ can be achieved for a symmetric
configuration of channel gains.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1607.06042; text overlap
  with arXiv:1102.2498 by other authors</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08660</dc:identifier>
 <dc:identifier>IET Communications, vol. 11, no. 13, pp. 2089-2094, Sept 2017</dc:identifier>
 <dc:identifier>doi:10.1049/iet-com.2017.0252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08661</identifier>
 <datestamp>2016-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Graph Representation with Jointly Structural and Textual
  Encoding</dc:title>
 <dc:creator>Xu, Jiacheng</dc:creator>
 <dc:creator>Chen, Kan</dc:creator>
 <dc:creator>Qiu, Xipeng</dc:creator>
 <dc:creator>Huang, Xuanjing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The objective of knowledge graph embedding is to encode both entities and
relations of knowledge graphs into continuous low-dimensional vector spaces.
Previously, most works focused on symbolic representation of knowledge graph
with structure information, which can not handle new entities or entities with
few facts well. In this paper, we propose a novel deep architecture to utilize
both structural and textual information of entities. Specifically, we introduce
three neural models to encode the valuable information from text description of
entity, among which an attentive model can select related information as
needed. Then, a gating mechanism is applied to integrate representations of
structure and text into a unified architecture. Experiments show that our
models outperform baseline by margin on link prediction and triplet
classification tasks. Source codes of this paper will be available on Github.
</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:date>2016-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08663</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Task Zero-Shot Action Recognition with Prioritised Data
  Augmentation</dc:title>
 <dc:creator>Xu, Xun</dc:creator>
 <dc:creator>Hospedales, Timothy M.</dc:creator>
 <dc:creator>Gong, Shaogang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Zero-Shot Learning (ZSL) promises to scale visual recognition by bypassing
the conventional model training requirement of annotated examples for every
category. This is achieved by establishing a mapping connecting low-level
features and a semantic description of the label space, referred as
visual-semantic mapping, on auxiliary data. Reusing the learned mapping to
project target videos into an embedding space thus allows novel-classes to be
recognised by nearest neighbour inference. However, existing ZSL methods suffer
from auxiliary-target domain shift intrinsically induced by assuming the same
mapping for the disjoint auxiliary and target classes. This compromises the
generalisation accuracy of ZSL recognition on the target data. In this work, we
improve the ability of ZSL to generalise across this domain shift in both
model- and data-centric ways by formulating a visual-semantic mapping with
better generalisation properties and a dynamic data re-weighting method to
prioritise auxiliary data that are relevant to the target classes.
Specifically: (1) We introduce a multi-task visual-semantic mapping to improve
generalisation by constraining the semantic mapping parameters to lie on a
low-dimensional manifold, (2) We explore prioritised data augmentation by
expanding the pool of auxiliary data with additional instances weighted by
relevance to the target domain. The proposed new model is applied to the
challenging zero-shot action recognition problem to demonstrate its advantages
over existing ZSL models.
</dc:description>
 <dc:description>Comment: Published in ECCV 2016</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08663</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-46475-6_22</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08664</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-supervised Learning using Denoising Autoencoders for Brain Lesion
  Detection and Segmentation</dc:title>
 <dc:creator>Alex, Varghese</dc:creator>
 <dc:creator>Vaidhya, Kiran</dc:creator>
 <dc:creator>Thirunavukkarasu, Subramaniam</dc:creator>
 <dc:creator>Kesavdas, Chandrasekharan</dc:creator>
 <dc:creator>Krishnamurthi, Ganapathy</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The work presented explores the use of denoising autoencoders (DAE) for brain
lesion detection, segmentation and false positive reduction. Stacked denoising
autoencoders (SDAE) were pre-trained using a large number of unlabeled patient
volumes and fine tuned with patches drawn from a limited number of patients
(n=20, 40, 65). The results show negligible loss in performance even when SDAE
was fine tuned using 20 patients. Low grade glioma (LGG) segmentation was
achieved using a transfer learning approach wherein a network pre-trained with
High Grade Glioma (HGG) data was fine tuned using LGG image patches. The weakly
supervised SDAE (for HGG) and transfer learning based LGG network were also
shown to generalize well and provide good segmentation on unseen BraTS 2013 &amp;
BraTS 2015 test data. An unique contribution includes a single layer DAE,
referred to as novelty detector(ND). ND was trained to accurately reconstruct
non-lesion patches using a mean squared error loss function. The reconstruction
error maps of test data were used to identify regions containing lesions. The
error maps were shown to assign unique error distributions to various
constituents of the glioma, enabling localization. The ND learns the non-lesion
brain accurately as it was also shown to provide good segmentation performance
on ischemic brain lesions in images from a different database.
</dc:description>
 <dc:description>Comment: 11 Pages, 42 Images</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:date>2017-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08666</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training an Interactive Humanoid Robot Using Multimodal Deep
  Reinforcement Learning</dc:title>
 <dc:creator>Cuay&#xe1;huitl, Heriberto</dc:creator>
 <dc:creator>Couly, Guillaume</dc:creator>
 <dc:creator>Olalainty, Cl&#xe9;ment</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Training robots to perceive, act and communicate using multiple modalities
still represents a challenging problem, particularly if robots are expected to
learn efficiently from small sets of example interactions. We describe a
learning approach as a step in this direction, where we teach a humanoid robot
how to play the game of noughts and crosses. Given that multiple multimodal
skills can be trained to play this game, we focus our attention to training the
robot to perceive the game, and to interact in this game. Our multimodal deep
reinforcement learning agent perceives multimodal features and exhibits verbal
and non-verbal actions while playing. Experimental results using simulations
show that the robot can learn to win or draw up to 98% of the games. A pilot
test of the proposed multimodal system for the targeted game---integrating
speech, vision and gestures---reports that reasonable and fluent interactions
can be achieved using the proposed approach.
</dc:description>
 <dc:description>Comment: NIPS Workshop on Future of Interactive Learning Machines, 2016</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08669</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Dialog</dc:title>
 <dc:creator>Das, Abhishek</dc:creator>
 <dc:creator>Kottur, Satwik</dc:creator>
 <dc:creator>Gupta, Khushi</dc:creator>
 <dc:creator>Singh, Avi</dc:creator>
 <dc:creator>Yadav, Deshraj</dc:creator>
 <dc:creator>Moura, Jos&#xe9; M. F.</dc:creator>
 <dc:creator>Parikh, Devi</dc:creator>
 <dc:creator>Batra, Dhruv</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce the task of Visual Dialog, which requires an AI agent to hold a
meaningful dialog with humans in natural, conversational language about visual
content. Specifically, given an image, a dialog history, and a question about
the image, the agent has to ground the question in image, infer context from
history, and answer the question accurately. Visual Dialog is disentangled
enough from a specific downstream task so as to serve as a general test of
machine intelligence, while being grounded in vision enough to allow objective
evaluation of individual responses and benchmark progress. We develop a novel
two-person chat data-collection protocol to curate a large-scale Visual Dialog
dataset (VisDial). VisDial v0.9 has been released and contains 1 dialog with 10
question-answer pairs on ~120k images from COCO, with a total of ~1.2M dialog
question-answer pairs.
  We introduce a family of neural encoder-decoder models for Visual Dialog with
3 encoders -- Late Fusion, Hierarchical Recurrent Encoder and Memory Network --
and 2 decoders (generative and discriminative), which outperform a number of
sophisticated baselines. We propose a retrieval-based evaluation protocol for
Visual Dialog where the AI agent is asked to sort a set of candidate answers
and evaluated on metrics such as mean-reciprocal-rank of human response. We
quantify gap between machine and human performance on the Visual Dialog task
via human studies. Putting it all together, we demonstrate the first 'visual
chatbot'! Our dataset, code, trained models and visual chatbot are available on
https://visualdialog.org
</dc:description>
 <dc:description>Comment: 23 pages, 18 figures, CVPR 2017 camera-ready, results on VisDial v0.9
  dataset, Webpage: http://visualdialog.org</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08669</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08675</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Reinforcement Learning for Multi-Domain Dialogue Systems</dc:title>
 <dc:creator>Cuay&#xe1;huitl, Heriberto</dc:creator>
 <dc:creator>Yu, Seunghak</dc:creator>
 <dc:creator>Williamson, Ashley</dc:creator>
 <dc:creator>Carse, Jacob</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Standard deep reinforcement learning methods such as Deep Q-Networks (DQN)
for multiple tasks (domains) face scalability problems. We propose a method for
multi-domain dialogue policy learning---termed NDQN, and apply it to an
information-seeking spoken dialogue system in the domains of restaurants and
hotels. Experimental results comparing DQN (baseline) versus NDQN (proposed)
using simulations report that our proposed method exhibits better scalability
and is promising for optimising the behaviour of multi-domain dialogue systems.
</dc:description>
 <dc:description>Comment: NIPS Workshop on Deep Reinforcement Learning, 2016</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08677</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Admissibility in Quantitative Graph Games</dc:title>
 <dc:creator>Brenguier, Romain</dc:creator>
 <dc:creator>P&#xe9;rez, Guillermo A.</dc:creator>
 <dc:creator>Raskin, Jean-Fran&#xe7;ois</dc:creator>
 <dc:creator>Sankur, Ocan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  Admissibility has been studied for games of infinite duration with Boolean
objectives. We extend here this study to games of infinite duration with
quantitative objectives. First, we show that, un- der the assumption that
optimal worst-case and cooperative strategies exist, admissible strategies are
guaranteed to exist. Second, we give a characterization of admissible
strategies using the no- tion of adversarial and cooperative values of a
history, and we characterize the set of outcomes that are compatible with
admissible strategies. Finally, we show how these characterizations can be used
to design algorithms to decide relevant verification and synthesis problems.
</dc:description>
 <dc:description>Comment: This is the full version of an article that will be published in
  FSTTCS'16</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08680</identifier>
 <datestamp>2017-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomized feasible interpolation and monotone circuits with a local
  oracle</dc:title>
 <dc:creator>Krajicek, Jan</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>03F20, 68Q15</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We generalize the feasible interpolation theorem for semantic derivations
from K.(1997) by allowing randomized protocols (protocols in the sense of
K.(1997). We also introduce an extension of the monotone circuit model,
monotone circuits with a local oracle (CLOs), that does correspond to
communication protocols for the monotone Karchmer-Wigderson multi-function
$KW^m[U,V]$ making errors. The new randomized feasible interpolation thus shows
that a short semantic derivation (from a certain class of derivations larger
than in the original method) of the disjointness of $U, V$, $U$ closed upwards,
yields a small randomized protocol for and hence a small monotone CLO
separating the sets. To establish a lower bound for monotone CLOs separating
two NP sets, one closed upwards, is an open problem.
  This research is motivated by the open problem to establish a lower bound for
proof system $R(LIN)$ operating with clauses formed by linear Boolean functions
over the 2-element field. The new randomized feasible interpolation applies to
this proof system and also to the semantic versions of the cutting planes proof
system CP (as randomized protocols efficiently simulate protocols with small
real communication complexity of K.(1998)), to small width resolution over CP,
R(CP), and to random resolution RR of Buss, Kolodziejczyk and Thapen (2014).
</dc:description>
 <dc:description>Comment: Preliminary version November 2016</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:date>2017-02-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08680</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08681</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Truthful Spectrum Auction for Efficient Anti-Jamming in Cognitive Radio
  Networks</dc:title>
 <dc:creator>Alavijeh, Mohammad Aghababaie</dc:creator>
 <dc:creator>Maham, Behrouz</dc:creator>
 <dc:creator>Han, Zhu</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  One significant challenge in cognitive radio networks is to design a
framework in which the selfish secondary users are obliged to interact with
each other truthfully. Moreover, due to the vulnerability of these networks
against jamming attacks, designing anti-jamming defense mechanisms is equally
important. %providing the security defense is also of great importance. In this
paper, we propose a truthful mechanism, robust against the jamming, for a
dynamic stochastic cognitive radio network consisting of several selfish
secondary users and a malicious user. In this model, each secondary user
participates in an auction and wish to use the unjammed spectrum, and the
malicious user aims at jamming a channel by corrupting the communication link.
A truthful auction mechanism is designed among the secondary users.
Furthermore, a zero-sum game is formulated between the set of secondary users
and the malicious user. This joint problem is then cast as a randomized
two-level auctions in which the first auction allocates the vacant channels,
and then the second one assigns the remaining unallocated channels. We have
also changed this solution to a trustful distributed scheme. Simulation results
show that the distributed algorithm can achieve a performance that is close to
the centralized algorithm, without the added overhead and complexity.
</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08686</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cryptanalysis of Xinyu et al.'s NTRU-Lattice Based Key Exchange Protocol</dc:title>
 <dc:creator>Valluri, Maheswara Rao</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Xinyu et al. proposed a public key exchange protocol, which is based on the
NTRU-lattice based cryptography. In this paper, we show how Xinyu et al.'s
NTRU-KE: A lattice based key exchange protocol can be broken, under the
assumption that a man-in-the middle attack is used for extracting private keys
of users who participate in the key exchange protocol.
</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08687</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Whom to befriend to influence people</dc:title>
 <dc:creator>Cordasco, Gennaro</dc:creator>
 <dc:creator>Gargano, Luisa</dc:creator>
 <dc:creator>Lafond, Manuel</dc:creator>
 <dc:creator>Narayanan, Lata</dc:creator>
 <dc:creator>Rescigno, Adele A.</dc:creator>
 <dc:creator>Vaccaro, Ugo</dc:creator>
 <dc:creator>Wu, Kangkang</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Alice wants to join a new social network, and influence its members to adopt
a new product or idea. Each person $v$ in the network has a certain threshold
$t(v)$ for {\em activation}, i.e adoption of the product or idea. If $v$ has at
least $t(v)$ activated neighbors, then $v$ will also become activated. If Alice
wants to activate the entire social network, whom should she befriend? More
generally, we study the problem of finding the minimum number of links that a
set of external influencers should form to people in the network, in order to
activate the entire social network. This {\em Minimum Links} Problem has
applications in viral marketing and the study of epidemics. Its solution can be
quite different from the related and widely studied Target Set Selection
problem. We prove that the Minimum Links problem cannot be approximated to
within a ratio of $O(2^{\log^{1-\epsilon} n})$, for any fixed $\epsilon&gt;0$,
unless $NP\subseteq DTIME(n^{polylog(n)})$, where $n$ is the number of nodes in
the network. On the positive side, we give linear time algorithms to solve the
problem for trees, cycles, and cliques, for any given set of external
influencers, and give precise bounds on the number of links needed. For general
graphs, we design a polynomial time algorithm to compute size-efficient link
sets that can activate the entire graph.
</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08687</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08690</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GSVD-Based Precoding in MIMO Systems With Integrated Services</dc:title>
 <dc:creator>Mei, Weidong</dc:creator>
 <dc:creator>Chen, Zhi</dc:creator>
 <dc:creator>Fang, Jun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This letter considers a two-receiver multiple-input multiple-output (MIMO)
Gaussian broadcast channel model with integrated services. Specifically, we
combine two sorts of service messages, and serve them simultaneously: one
multicast message intended for both receivers and one confidential message
intended for only one receiver. The confidential message is kept perfectly
secure from the unauthorized receiver. Due to the coupling of service messages,
it is intractable to seek capacity-achieving transmit covariance matrices.
Accordingly, we propose a suboptimal precoding scheme based on the generalized
singular value decomposition (GSVD). The GSVD produces several virtual
orthogonal subchannels between the transmitter and the receivers. Subchannel
allocation and power allocation between multicast message and confidential
message are jointly optimized to maximize the secrecy rate in this letter,
subject to the quality of multicast service (QoMS) constraints. Since this
problem is inherently complex, a difference-of-concave (DC) algorithm, together
with an exhaustive search, is exploited to handle the power allocation and
subchannel allocation, respectively. Numerical results are presented to
illustrate the efficacy of our proposed strategies.
</dc:description>
 <dc:description>Comment: IEEE Signal Processing Letters (Volume: 23, Issue: 11, Nov. 2016)</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08690</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2016.2606349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08691</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiwinner Approval Rules as Apportionment Methods</dc:title>
 <dc:creator>Brill, Markus</dc:creator>
 <dc:creator>Laslier, Jean-Fran&#xe7;ois</dc:creator>
 <dc:creator>Skowron, Piotr</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  We establish a link between multiwinner elections and apportionment problems
by showing how approval-based multiwinner election rules can be interpreted as
methods of apportionment. We consider several multiwinner rules and observe
that they induce apportionment methods that are well-established in the
literature on proportional representation. For instance, we show that
Proportional Approval Voting induces the D'Hondt method and that Monroe's rule
induces the largest reminder method. We also consider properties of
apportionment methods and exhibit multiwinner rules that induce apportionment
methods satisfying these properties.
</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08691</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08696</identifier>
 <datestamp>2017-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Expectation with Guarantees in POMDPs (Technical Report)</dc:title>
 <dc:creator>Chatterjee, Krishnendu</dc:creator>
 <dc:creator>Novotn&#xfd;, Petr</dc:creator>
 <dc:creator>P&#xe9;rez, Guillermo A.</dc:creator>
 <dc:creator>Raskin, Jean-Fran&#xe7;ois</dc:creator>
 <dc:creator>&#x17d;ikeli&#x107;, &#x110;or&#x111;e</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  A standard objective in partially-observable Markov decision processes
(POMDPs) is to find a policy that maximizes the expected discounted-sum payoff.
However, such policies may still permit unlikely but highly undesirable
outcomes, which is problematic especially in safety-critical applications.
Recently, there has been a surge of interest in POMDPs where the goal is to
maximize the probability to ensure that the payoff is at least a given
threshold, but these approaches do not consider any optimization beyond
satisfying this threshold constraint. In this work we go beyond both the
&quot;expectation&quot; and &quot;threshold&quot; approaches and consider a &quot;guaranteed payoff
optimization (GPO)&quot; problem for POMDPs, where we are given a threshold $t$ and
the objective is to find a policy $\sigma$ such that a) each possible outcome
of $\sigma$ yields a discounted-sum payoff of at least $t$, and b) the expected
discounted-sum payoff of $\sigma$ is optimal (or near-optimal) among all
policies satisfying a). We present a practical approach to tackle the GPO
problem and evaluate it on standard POMDP benchmarks.
</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:date>2017-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08699</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Learning on Human Connectome Data from MRI</dc:title>
 <dc:creator>Brown, Colin J</dc:creator>
 <dc:creator>Hamarneh, Ghassan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Functional MRI (fMRI) and diffusion MRI (dMRI) are non-invasive imaging
modalities that allow in-vivo analysis of a patient's brain network (known as a
connectome). Use of these technologies has enabled faster and better diagnoses
and treatments of neurological disorders and a deeper understanding of the
human brain. Recently, researchers have been exploring the application of
machine learning models to connectome data in order to predict clinical
outcomes and analyze the importance of subnetworks in the brain. Connectome
data has unique properties, which present both special challenges and
opportunities when used for machine learning. The purpose of this work is to
review the literature on the topic of applying machine learning models to
MRI-based connectome data. This field is growing rapidly and now encompasses a
large body of research. To summarize the research done to date, we provide a
comparative, structured summary of 77 relevant works, tabulated according to
different criteria, that represent the majority of the literature on this
topic. (We also published a living version of this table online at
http://connectomelearning.cs.sfu.ca that the community can continue to
contribute to.) After giving an overview of how connectomes are constructed
from dMRI and fMRI data, we discuss the variety of machine learning tasks that
have been explored with connectome data. We then compare the advantages and
drawbacks of different machine learning approaches that have been employed,
discussing different feature selection and feature extraction schemes, as well
as the learning models and regularization penalties themselves. Throughout this
discussion, we focus particularly on how the methods are adapted to the unique
nature of graphical connectome data. Finally, we conclude by summarizing the
current state of the art and by outlining what we believe are strategic
directions for future research.
</dc:description>
 <dc:description>Comment: 51 pages, 6 figures. To be submitted to a journal</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08699</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08703</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-hop Communication in the Uplink for LPWANs</dc:title>
 <dc:creator>Barrachina, Sergio</dc:creator>
 <dc:creator>Bellalta, Boris</dc:creator>
 <dc:creator>Adame, Toni</dc:creator>
 <dc:creator>Bel, Albert</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Low-Power Wide Area Networks (LPWANs) have arisen as a promising
communication technology for supporting Internet of Things (IoT) services due
to their low power operation, wide coverage range, low cost and scalability.
However, most LPWAN solutions like SIGFOX or LoRaWAN rely on star topology
networks, where stations (STAs) transmit directly to the gateway (GW), which
often leads to rapid battery depletion in STAs located far from it. In this
work, we analyze the impact on LPWANs energy consumption of multi-hop
communication in the uplink, allowing STAs to transmit data packets in lower
power levels and higher data rates to closer parent STAs, reducing their energy
consumption consequently. To that aim, we introduce the Distance-Ring
Exponential Stations Generator (DRESG) framework, designed to evaluate the
performance of the so-called optimal-hop routing model, which establishes
optimal routing connections in terms of energy efficiency, aiming to balance
the consumption among all the STAs in the network. Results show that enabling
such multi-hop connections entails higher network lifetimes, reducing
significantly the bottleneck consumption in LPWANs with up to thousands of
STAs. These results lead to foresee multi-hop communication in the uplink as a
promising routing alternative for extending the lifetime of LPWAN deployments.
</dc:description>
 <dc:description>Comment: 29 pages, 15 figures</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:date>2017-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08714</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-latency Ultra Reliable 5G Communications: Finite-Blocklength Bounds
  and Coding Schemes</dc:title>
 <dc:creator>&#xd6;stman, Johan</dc:creator>
 <dc:creator>Durisi, Giuseppe</dc:creator>
 <dc:creator>Str&#xf6;m, Erik G.</dc:creator>
 <dc:creator>Li, Jingya</dc:creator>
 <dc:creator>Sahlin, Henrik</dc:creator>
 <dc:creator>Liva, Gianluigi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Future autonomous systems require wireless connectivity able to support
extremely stringent requirements on both latency and reliability. In this
paper, we leverage recent developments in the field of finite-blocklength
information theory to illustrate how to optimally design wireless systems in
the presence of such stringent constraints. Focusing on a multi-antenna
Rayleigh block-fading channel, we obtain bounds on the maximum number of bits
that can be transmitted within given bandwidth, latency, and reliability
constraints, using an orthogonal frequency-division multiplexing system similar
to LTE. These bounds unveil the fundamental interplay between latency,
bandwidth, rate, and reliability. Furthermore, they suggest how to optimally
use the available spatial and frequency diversity. Finally, we use our bounds
to benchmark the performance of an actual coding scheme involving the
transmission of short packets.
</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08714</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08725</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine-to-Machine (M2M) Communications in Software-defined and
  Virtualized Cellular Networks</dc:title>
 <dc:creator>Li, Meng</dc:creator>
 <dc:creator>Yu, F. Richard</dc:creator>
 <dc:creator>Si, Pengbo</dc:creator>
 <dc:creator>Sun, Enchang</dc:creator>
 <dc:creator>Zhang, Yanhua</dc:creator>
 <dc:creator>Yao, Haipeng</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Machine-to-machine (M2M) communications have attracted great attention from
both academia and industry. In this paper, with recent advances in wireless
network virtualization and software-defined networking (SDN), we propose a
novel framework for M2M communications in software-defined cellular networks
with wireless network virtualization. In the proposed framework, according to
different functions and quality of service (QoS) requirements of machine-type
communication devices (MTCDs), a hypervisor enables the virtualization of the
physical M2M network, which is abstracted and sliced into multiple virtual M2M
networks. In addition, we develop a decision-theoretic approach to optimize the
random access process of M2M communications. Furthermore, we develop a feedback
and control loop to dynamically adjust the number of resource blocks (RBs) that
are used in the random access phase in a virtual M2M network by the SDN
controller. Extensive simulation results with different system parameters are
presented to show the performance of the proposed scheme.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1611.05087</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08728</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Green Wireless Sensor Networks with Wireless Power Transfer</dc:title>
 <dc:creator>Li, Qiao</dc:creator>
 <dc:creator>Wei, Yifei</dc:creator>
 <dc:creator>Song, Mei</dc:creator>
 <dc:creator>Yu, F. R.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  An energy cooperation policy for energy harvesting wireless sensor networks
(WSNs) with wireless power transfer is proposed in this paper to balance the
energy at each sensor node and increase the total energy utilization ratio of
the whole WSNs. Considering the unbalanced spatio-temporal properties of the
energy supply across the deployment terrain of energy harvesting WSNs and the
dynamic traffic load at each sensor node, the energy cooperation problem among
sensor nodes is decomposed into two steps: the local energy storage at each
sensor node based on its traffic load to meet its own needs; within the energy
storage procedure sensor nodes with excess energy transmit a part of their
energy to nodes with energy shortage through the energy trading. Inventory
theory and game theory are respectively applied to solving the local energy
storage problem at each sensor node and the energy trading problem among
multiple sensor nodes. Numerical results show that compared with the static
energy cooperation method without energy trading, the Stackelberg Model based
Game we design in this paper can significantly improve the trading volume of
energy thereby increasing the utilization ratio of the harvested energy which
is unevenly distributed in the WSNs.
</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08728</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08733</identifier>
 <datestamp>2017-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BliStrTune: Hierarchical Invention of Theorem Proving Strategies</dc:title>
 <dc:creator>Jakubuv, Jan</dc:creator>
 <dc:creator>Urban, Josef</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Inventing targeted proof search strategies for specific problem sets is a
difficult task. State-of-the-art automated theorem provers (ATPs) such as E
allow a large number of user-specified proof search strategies described in a
rich domain specific language. Several machine learning methods that invent
strategies automatically for ATPs were proposed previously. One of them is the
Blind Strategymaker (BliStr), a system for automated invention of ATP
strategies.
  In this paper we introduce BliStrTune -- a hierarchical extension of BliStr.
BliStrTune allows exploring much larger space of E strategies by interleaving
search for high-level parameters with their fine-tuning. We use BliStrTune to
invent new strategies based also on new clause weight functions targeted at
problems from large ITP libraries. We show that the new strategies
significantly improve E's performance in solving problems from the Mizar
Mathematical Library.
</dc:description>
 <dc:description>Comment: Submitted to Certified Programs and Proofs (CPP 2017)</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08733</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08737</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structural Correspondence Learning for Cross-lingual Sentiment
  Classification with One-to-many Mappings</dc:title>
 <dc:creator>Li, Nana</dc:creator>
 <dc:creator>Zhai, Shuangfei</dc:creator>
 <dc:creator>Zhang, Zhongfei</dc:creator>
 <dc:creator>Liu, Boying</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Structural correspondence learning (SCL) is an effective method for
cross-lingual sentiment classification. This approach uses unlabeled documents
along with a word translation oracle to automatically induce task specific,
cross-lingual correspondences. It transfers knowledge through identifying
important features, i.e., pivot features. For simplicity, however, it assumes
that the word translation oracle maps each pivot feature in source language to
exactly only one word in target language. This one-to-one mapping between words
in different languages is too strict. Also the context is not considered at
all. In this paper, we propose a cross-lingual SCL based on distributed
representation of words; it can learn meaningful one-to-many mappings for pivot
words using large amounts of monolingual data and a small dictionary. We
conduct experiments on NLP\&amp;CC 2013 cross-lingual sentiment analysis dataset,
employing English as source language, and Chinese as target language. Our
method does not rely on the parallel corpora and the experimental results show
that our approach is more competitive than the state-of-the-art methods in
cross-lingual sentiment classification.
</dc:description>
 <dc:description>Comment: To appear in AAAI 2017. arXiv admin note: text overlap with
  arXiv:1008.0716 by other authors</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08737</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08738</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adding Path-Functional Dependencies to the Guarded Two-Variable Fragment
  with Counting</dc:title>
 <dc:creator>Kourtis, Georgios</dc:creator>
 <dc:creator>Pratt-Hartmann, Ian</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The satisfiability and finite satisfiability problems for the two-variable
guarded fragment of first-order logic with counting quantifiers, a database,
and path-functional dependencies are both ExpTime-complete.
</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08738</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 4 (October
  30, 2017) lmcs:4028</dc:identifier>
 <dc:identifier>doi:10.23638/LMCS-13(4:4)2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08740</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the number of ordinary lines determined by sets in complex space</dc:title>
 <dc:creator>Basit, Abdul</dc:creator>
 <dc:creator>Dvir, Zeev</dc:creator>
 <dc:creator>Saraf, Shubhangi</dc:creator>
 <dc:creator>Wolf, Charles</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Kelly's theorem states that a set of $n$ points affinely spanning
$\mathbb{C}^3$ must determine at least one ordinary complex line (a line
passing through exactly two of the points). Our main theorem shows that such
sets determine at least $3n/2$ ordinary lines, unless the configuration has
$n-1$ points in a plane and one point outside the plane (in which case there
are at least $n-1$ ordinary lines). In addition, when at most $2n/3$ points are
contained in any plane, we prove a theorem giving stronger bounds that take
advantage of the existence of lines with 4 and more points (in the spirit of
Melchior's and Hirzebruch's inequalities). Furthermore, when the points span 4
or more dimensions, with at most $2n/3$ points contained in any three
dimensional affine subspace, we show that there must be a quadratic number of
ordinary lines.
</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08743</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eliminating Tight Coupling using Subscriptions Subgrouping in Structured
  Overlays</dc:title>
 <dc:creator>Shafique, Muhammad</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Advertisements and subscriptions are tightly coupled to generate publication
routing paths in content--based publish/subscribe systems. Tight coupling
requires instantaneous updates in routing tables to generate alternative paths
which prevents offering scalable and robust dynamic routing in cyclic overlays
when link congestion is detected. We propose, OctopiA, first distributed
publish/subscribe system for content--based inter--cluster dynamic routing
using purpose--built structured cyclic overlays. OctopiA uses a novel concept
of subscription subgrouping, which divides subscriptions into disjoint sets
called subscription subgroups. The purpose--built structured cyclic overlay is
divided into identical clusters where subscriptions in each subgroup are
broadcast to an exclusive cluster. Our advertisement and subscription
forwarding algorithms use subscription subgrouping to eliminate tight coupling
to offer inter--cluster dynamic routing without requiring updates in routing
tables. Experiments on a cluster testbed with real world data show that OctopiA
reduces the number of saved advertisements in routing tables by 93%,
subscription broadcast delay by 33%, static and dynamic publication delivery
delays by 25% and 54%, respectively.
</dc:description>
 <dc:description>Comment: None. arXiv admin note: text overlap with arXiv:1604.06853</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:date>2017-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08743</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08749</identifier>
 <datestamp>2017-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Chirplet Transform to Enhance CNN Machine Listening - Validation on
  Animal calls and Speech</dc:title>
 <dc:creator>Glotin, Herve</dc:creator>
 <dc:creator>Ricard, Julien</dc:creator>
 <dc:creator>Balestriero, Randall</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  The scattering framework offers an optimal hierarchical convolutional
decomposition according to its kernels. Convolutional Neural Net (CNN) can be
seen as an optimal kernel decomposition, nevertheless it requires large amount
of training data to learn its kernels. We propose a trade-off between these two
approaches: a Chirplet kernel as an efficient Q constant bioacoustic
representation to pretrain CNN. First we motivate Chirplet bioinspired auditory
representation. Second we give the first algorithm (and code) of a Fast
Chirplet Transform (FCT). Third, we demonstrate the computation efficiency of
FCT on large environmental data base: months of Orca recordings, and 1000 Birds
species from the LifeClef challenge. Fourth, we validate FCT on the vowels
subset of the Speech TIMIT dataset. The results show that FCT accelerates CNN
when it pretrains low level layers: it reduces training duration by -28\% for
birds classification, and by -26% for vowels classification. Scores are also
enhanced by FCT pretraining, with a relative gain of +7.8% of Mean Average
Precision on birds, and +2.3\% of vowel accuracy against raw audio CNN. We
conclude on perspectives on tonotopic FCT deep machine listening, and
inter-species bioacoustic transfer learning to generalise the representation of
animal communication systems.
</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:date>2017-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08749</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08752</identifier>
 <datestamp>2017-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deterministic Discrepancy Minimization via the Multiplicative Weight
  Update Method</dc:title>
 <dc:creator>Levy, Avi</dc:creator>
 <dc:creator>Ramadas, Harishchandra</dc:creator>
 <dc:creator>Rothvoss, Thomas</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A well-known theorem of Spencer shows that any set system with $n$ sets over
$n$ elements admits a coloring of discrepancy $O(\sqrt{n})$. While the original
proof was non-constructive, recent progress brought polynomial time algorithms
by Bansal, Lovett and Meka, and Rothvoss. All those algorithms are randomized,
even though Bansal's algorithm admitted a complicated derandomization.
  We propose an elegant deterministic polynomial time algorithm that is
inspired by Lovett-Meka as well as the Multiplicative Weight Update method. The
algorithm iteratively updates a fractional coloring while controlling the
exponential weights that are assigned to the set constraints.
  A conjecture by Meka suggests that Spencer's bound can be generalized to
symmetric matrices. We prove that $n \times n$ matrices that are block diagonal
with block size $q$ admit a coloring of discrepancy $O(\sqrt{n} \cdot
\sqrt{\log(q)})$.
  Bansal, Dadush and Garg recently gave a randomized algorithm to find a vector
$x$ with entries in $\lbrace{-1,1\rbrace}$ with $\|Ax\|_{\infty} \leq
O(\sqrt{\log n})$ in polynomial time, where $A$ is any matrix whose columns
have length at most 1. We show that our method can be used to deterministically
obtain such a vector.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:date>2017-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08752</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08754</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Can Be Predicted from Six Seconds of Driver Glances?</dc:title>
 <dc:creator>Fridman, Lex</dc:creator>
 <dc:creator>Toyoda, Heishiro</dc:creator>
 <dc:creator>Seaman, Sean</dc:creator>
 <dc:creator>Seppelt, Bobbie</dc:creator>
 <dc:creator>Angell, Linda</dc:creator>
 <dc:creator>Lee, Joonbum</dc:creator>
 <dc:creator>Mehler, Bruce</dc:creator>
 <dc:creator>Reimer, Bryan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider a large dataset of real-world, on-road driving from a 100-car
naturalistic study to explore the predictive power of driver glances and,
specifically, to answer the following question: what can be predicted about the
state of the driver and the state of the driving environment from a 6-second
sequence of macro-glances? The context-based nature of such glances allows for
application of supervised learning to the problem of vision-based gaze
estimation, making it robust, accurate, and reliable in messy, real-world
conditions. So, it's valuable to ask whether such macro-glances can be used to
infer behavioral, environmental, and demographic variables? We analyze 27
binary classification problems based on these variables. The takeaway is that
glance can be used as part of a multi-sensor real-time system to predict
radio-tuning, fatigue state, failure to signal, talking, and several
environment variables.
</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08757</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Number Balancing is as hard as Minkowski's Theorem and Shortest Vector</dc:title>
 <dc:creator>Hoberg, Rebecca</dc:creator>
 <dc:creator>Ramadas, Harishchandra</dc:creator>
 <dc:creator>Rothvoss, Thomas</dc:creator>
 <dc:creator>Yang, Xin</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The number balancing (NBP) problem is the following: given real numbers
$a_1,\ldots,a_n \in [0,1]$, find two disjoint subsets $I_1,I_2 \subseteq [n]$
so that the difference $|\sum_{i \in I_1}a_i - \sum_{i \in I_2}a_i|$ of their
sums is minimized. An application of the pigeonhole principle shows that there
is always a solution where the difference is at most $O(\frac{\sqrt{n}}{2^n})$.
Finding the minimum, however, is NP-hard. In polynomial time,the differencing
algorithm by Karmarkar and Karp from 1982 can produce a solution with
difference at most $n^{-\Theta(\log n)}$, but no further improvement has been
made since then.
  In this paper, we show a relationship between NBP and Minkowski's Theorem.
First we show that an approximate oracle for Minkowski's Theorem gives an
approximate NBP oracle. Perhaps more surprisingly, we show that an approximate
NBP oracle gives an approximate Minkowski oracle. In particular, we prove that
any polynomial time algorithm that guarantees a solution of difference at most
$2^{\sqrt{n}} / 2^{n}$ would give a polynomial approximation for Minkowski as
well as a polynomial factor approximation algorithm for the Shortest Vector
Problem.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08758</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational inequality approach to enforce the non-negative constraint
  for advection-diffusion equations</dc:title>
 <dc:creator>Chang, J.</dc:creator>
 <dc:creator>Nakshatrala, K. B.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Predictive simulations are crucial for the success of many subsurface
applications, and it is highly desirable to obtain accurate non-negative
solutions for transport equations in these numerical simulations. In this
paper, we propose a computational framework based on the variational inequality
(VI) which can also be used to enforce important mathematical properties (e.g.,
maximum principles) and physical constraints (e.g., the non-negative
constraint). We demonstrate that this framework is not only applicable to
diffusion equations but also to non-symmetric advection-diffusion equations. An
attractive feature of the proposed framework is that it works with with any
weak formulation for the advection-diffusion equations, including single-field
formulations, which are computationally attractive. A particular emphasis is
placed on the parallel and algorithmic performance of the VI approach across
large-scale and heterogeneous problems. It is also shown that QP and VI are
equivalent under certain conditions. State-of-the-art QP and VI solvers
available from the PETSc library are used on a variety of steady-state 2D and
3D benchmarks, and a comparative study on the scalability between the QP and VI
solvers is presented. We then extend the proposed framework to transient
problems by simulating the miscible displacement of fluids in a heterogeneous
porous medium and illustrate the importance of enforcing maximum principles for
these types of coupled problems. Our numerical experiments indicate that VIs
are indeed a viable approach for enforcing the maximum principles and the
non-negative constraint in a large-scale computing environment. Also provided
are Firedrake project files as well as a discussion on the computer
implementation to help facilitate readers in understanding the proposed
framework.
</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:date>2016-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08758</dc:identifier>
 <dc:identifier>doi:10.1016/j.cma.2017.03.022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08765</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fill it up: Exploiting partial dependency annotations in a minimum
  spanning tree parser</dc:title>
 <dc:creator>Sun, Liang</dc:creator>
 <dc:creator>Mielens, Jason</dc:creator>
 <dc:creator>Baldridge, Jason</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Unsupervised models of dependency parsing typically require large amounts of
clean, unlabeled data plus gold-standard part-of-speech tags. Adding indirect
supervision (e.g. language universals and rules) can help, but we show that
obtaining small amounts of direct supervision - here, partial dependency
annotations - provides a strong balance between zero and full supervision. We
adapt the unsupervised ConvexMST dependency parser to learn from partial
dependencies expressed in the Graph Fragment Language. With less than 24 hours
of total annotation, we obtain 7% and 17% absolute improvement in unlabeled
dependency scores for English and Spanish, respectively, compared to the same
parser using only universal grammar constraints.
</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08765</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08767</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrating High Level and Low Level Planning</dc:title>
 <dc:creator>Trautman, Pete</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present a possible method for integrating high level and low level
planning. To do so, we introduce the global plan random \emph{trajectory}
$\boldsymbol{\eta}_0 \colon [1,T] \to \mathbb R^2$, measured by goals $G_i$ and
governed by the distribution $p(\boldsymbol{\eta}_0 \mid \{ G_i\}_{i=1}^m)$.
This distribution is combined with the low level robot-crowd planner
$p(\mathbf{f}^{R},\mathbf{f}^{1},\ldots,\mathbf{f}^{n}\mid\mathbf{z}_{1:t})$
(from~\cite{trautmanicra2013, trautmaniros}) in the distribution
$p(\boldsymbol{\eta}_0,\mathbf{f}^{(R)},\mathbf{f}\mid\mathbf{z}_{1:t})$. We
explore this \emph{integrated planning} formulation in three case studies, and
in the process find that this formulation 1) generalizes the ROS navigation
stack in a practically useful way 2) arbitrates between high and low level
decision making in a statistically sound manner when unanticipated local
disturbances arise and 3) enables the integration of an onboard operator
providing real time input at either the global (e.g., waypoint designation) or
local (e.g., joystick) level. Importantly, the integrated planning formulation
$p(\boldsymbol{\eta}_0,\mathbf{f}^{(R)},\mathbf{f}\mid\mathbf{z}_{1:t})$
highlights failure modes of the ROS navigation stack (and thus for standard
hierarchical planning architectures); these failure modes are resolved by using
$p(\boldsymbol{\eta}_0,\mathbf{f}^{(R)},\mathbf{f}\mid\mathbf{z}_{1:t})$.
Finally, we conclude with a discussion of how results from formal methods can
guide our factorization of
$p(\boldsymbol{\eta}_0,\mathbf{f}^{(R)},\mathbf{f}\mid\mathbf{z}_{1:t})$.
</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08767</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08769</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Fast Fourier Transform using Fully Homomorphic Encryption</dc:title>
 <dc:creator>Shortell, Thomas</dc:creator>
 <dc:creator>Shokoufandeh, Ali</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Secure signal processing is becoming a de facto model for preserving privacy.
We propose a model based on the Fully Homomorphic Encryption (FHE) technique to
mitigate security breaches. Our framework provides a method to perform a Fast
Fourier Transform (FFT) on a user-specified signal. Using encryption of
individual binary values and FHE operations over addition and multiplication,
we enable a user to perform the FFT in a fixed point fractional representation
in binary. Our approach bounds the error of the implementation to enable
user-selectable parameters based on the specific application. We verified our
framework against test cases for one dimensional signals and images (two
dimensional signals).
</dc:description>
 <dc:description>Comment: 14 pages, 4 figures</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08769</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08770</identifier>
 <datestamp>2017-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Multi-Step Power Scheduling and Cost Allocation for
  Cooperative Microgrids</dc:title>
 <dc:creator>An, Lu</dc:creator>
 <dc:creator>Duan, Jie</dc:creator>
 <dc:creator>Zhang, Yuan</dc:creator>
 <dc:creator>Chow, Mo-Yuen</dc:creator>
 <dc:creator>Duel-Hallen, Alexandra</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Microgrids are self-sufficient small-scale power grid systems that can employ
renewable generation sources and energy storage devices and can connect to the
main grid or operate in a stand-alone mode. Most research on energy-storage
management in microgrids does not take into account the dynamic nature of the
problem and the need for fully-distributed, multi-step scheduling. First, we
address these requirements by extending our previously proposed
\textit{multi-step cooperative distributed energy scheduling} (CoDES) algorithm
to include both purchasing power from and selling the generated power to the
main grid. Second, we model the microgrid as a multi-agent system where the
agents (e.g. households) act as players in a cooperative game and employ a
distributed algorithm based on the Nash Bargaining Solution (NBS) to fairly
allocate the costs of cooperative power management (computed using CoDES) among
themselves. The dependency of the day-ahead power schedule and the costs on
system parameters, e.g., the price schedule and the user activity level
(measured by whether it owns storage and renewable generation devices), is
analyzed for a three-agent microgrid example.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures, submitted into PES general meeting 2017</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:date>2017-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08770</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08773</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Embedded Bandits for Large-Scale Black-Box Optimization</dc:title>
 <dc:creator>Al-Dujaili, Abdullah</dc:creator>
 <dc:creator>Suresh, S.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Random embedding has been applied with empirical success to large-scale
black-box optimization problems with low effective dimensions. This paper
proposes the EmbeddedHunter algorithm, which incorporates the technique in a
hierarchical stochastic bandit setting, following the optimism in the face of
uncertainty principle and breaking away from the multiple-run framework in
which random embedding has been conventionally applied similar to stochastic
black-box optimization solvers. Our proposition is motivated by the bounded
mean variation in the objective value for a low-dimensional point projected
randomly into the decision space of Lipschitz-continuous problems. In essence,
the EmbeddedHunter algorithm expands optimistically a partitioning tree over a
low-dimensional---equal to the effective dimension of the problem---search
space based on a bounded number of random embeddings of sampled points from the
low-dimensional space. In contrast to the probabilistic theoretical guarantees
of multiple-run random-embedding algorithms, the finite-time analysis of the
proposed algorithm presents a theoretical upper bound on the regret as a
function of the algorithm's number of iterations. Furthermore, numerical
experiments were conducted to validate its performance. The results show a
clear performance gain over recently proposed random embedding methods for
large-scale problems, provided the intrinsic dimensionality is low.
</dc:description>
 <dc:description>Comment: To appear at AAAI 2017</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08773</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08779</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Throughput Data Detection for Massive MU-MIMO-OFDM using Coordinate
  Descent</dc:title>
 <dc:creator>Wu, Michael</dc:creator>
 <dc:creator>Dick, Chris</dc:creator>
 <dc:creator>Cavallaro, Joseph R.</dc:creator>
 <dc:creator>Studer, Christoph</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Data detection in massive multi-user (MU) multiple-input multiple-output
(MIMO) wireless systems is among the most critical tasks due to the excessively
high implementation complexity. In this paper, we propose a novel,
equalization-based soft-output data-detection algorithm and corresponding
reference FPGA designs for wideband massive MU-MIMO systems that use orthogonal
frequency-division multiplexing (OFDM). Our data-detection algorithm performs
approximate minimum mean-square error (MMSE) or box-constrained equalization
using coordinate descent. We deploy a variety of algorithm-level optimizations
that enable near-optimal error-rate performance at low implementation
complexity, even for systems with hundreds of base-station (BS) antennas and
thousands of subcarriers. We design a parallel VLSI architecture that uses
pipeline interleaving and can be parametrized at design time to support various
antenna configurations. We develop reference FPGA designs for massive
MU-MIMO-OFDM systems and provide an extensive comparison to existing designs in
terms of implementation complexity, throughput, and error-rate performance. For
a 128 BS antenna, 8 user massive MU-MIMO-OFDM system, our FPGA design
outperforms the next-best implementation by more than 2.6x in terms of
throughput per FPGA look-up tables.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Circuits and Systems I: Regular Papers (TCAS I),
  Vol. 63, No. 12, Dec. 2016</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08779</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08780</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-Time Video Highlights for Yahoo Esports</dc:title>
 <dc:creator>Song, Yale</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Esports has gained global popularity in recent years and several companies
have started offering live streaming videos of esports games and events. This
creates opportunities to develop large scale video understanding systems for
new product features and services. We present a technique for detecting
highlights from live streaming videos of esports game matches. Most video games
use pronounced visual effects to emphasize highlight moments; we use CNNs to
learn convolution filters of those visual effects for detecting highlights. We
propose a cascaded prediction approach that allows us to deal with several
challenges arise in a production environment. We demonstrate our technique on
our new dataset of three popular game titles, Heroes of the Storm, League of
Legends, and Dota 2. Our technique achieves 18 FPS on a single CPU with an
average precision of up to 83.18%. Part of our technique is currently deployed
in production on Yahoo Esports.
</dc:description>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08780</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08788</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SAD-GAN: Synthetic Autonomous Driving using Generative Adversarial
  Networks</dc:title>
 <dc:creator>Ghosh, Arna</dc:creator>
 <dc:creator>Bhattacharya, Biswarup</dc:creator>
 <dc:creator>Chowdhury, Somnath Basu Roy</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Autonomous driving is one of the most recent topics of interest which is
aimed at replicating human driving behavior keeping in mind the safety issues.
We approach the problem of learning synthetic driving using generative neural
networks. The main idea is to make a controller trainer network using images
plus key press data to mimic human learning. We used the architecture of a
stable GAN to make predictions between driving scenes using key presses. We
train our model on one video game (Road Rash) and tested the accuracy and
compared it by running the model on other maps in Road Rash to determine the
extent of learning.
</dc:description>
 <dc:description>Comment: 5 pages; 4 figures; Accepted at the Deep Learning for Action and
  Interaction Workshop, 30th Conference on Neural Information Processing
  Systems (NIPS 2016), Barcelona, Spain; All authors have equal contribution</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08789</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Handwriting Profiling using Generative Adversarial Networks</dc:title>
 <dc:creator>Ghosh, Arna</dc:creator>
 <dc:creator>Bhattacharya, Biswarup</dc:creator>
 <dc:creator>Chowdhury, Somnath Basu Roy</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Handwriting is a skill learned by humans from a very early age. The ability
to develop one's own unique handwriting as well as mimic another person's
handwriting is a task learned by the brain with practice. This paper deals with
this very problem where an intelligent system tries to learn the handwriting of
an entity using Generative Adversarial Networks (GANs). We propose a modified
architecture of DCGAN (Radford, Metz, and Chintala 2015) to achieve this. We
also discuss about applying reinforcement learning techniques to achieve faster
learning. Our algorithm hopes to give new insights in this area and its uses
include identification of forged documents, signature verification, computer
generated art, digitization of documents among others. Our early implementation
of the algorithm illustrates a good performance with MNIST datasets.
</dc:description>
 <dc:description>Comment: 2 pages; 2 figures; Accepted at The Thirty-First AAAI Conference on
  Artificial Intelligence (AAAI-17 Student Abstract and Poster Program), San
  Francisco, USA; All authors have equal contribution</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08789</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08791</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning without recall in directed circles and rooted trees</dc:title>
 <dc:creator>Rahimian, M. Amin</dc:creator>
 <dc:creator>Jadbabaie, Ali</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This work investigates the case of a network of agents that attempt to learn
some unknown state of the world amongst the finitely many possibilities. At
each time step, agents all receive random, independently distributed private
signals whose distributions are dependent on the unknown state of the world.
However, it may be the case that some or any of the agents cannot distinguish
between two or more of the possible states based only on their private
observations, as when several states result in the same distribution of the
private signals. In our model, the agents form some initial belief (probability
distribution) about the unknown state and then refine their beliefs in
accordance with their private observations, as well as the beliefs of their
neighbors. An agent learns the unknown state when her belief converges to a
point mass that is concentrated at the true state. A rational agent would use
the Bayes' rule to incorporate her neighbors' beliefs and own private signals
over time. While such repeated applications of the Bayes' rule in networks can
become computationally intractable, in this paper, we show that in the
canonical cases of directed star, circle or path networks and their
combinations, one can derive a class of memoryless update rules that replicate
that of a single Bayesian agent but replace the self beliefs with the beliefs
of the neighbors. This way, one can realize an exponentially fast rate of
learning similar to the case of Bayesian (fully rational) agents. The proposed
rules are a special case of the Learning without Recall.
</dc:description>
 <dc:description>Comment: American Control Conference (ACC), 2015</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08791</dc:identifier>
 <dc:identifier>doi:10.1109/ACC.2015.7171992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08796</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Deformable Registration: Enhancing Accuracy by Fully Convolutional
  Neural Net</dc:title>
 <dc:creator>Ghosal, Sayan</dc:creator>
 <dc:creator>Ray, Nilanjan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deformable registration is ubiquitous in medical image analysis. Many
deformable registration methods minimize sum of squared difference (SSD) as the
registration cost with respect to deformable model parameters. In this work, we
construct a tight upper bound of the SSD registration cost by using a fully
convolutional neural network (FCNN) in the registration pipeline. The upper
bound SSD (UB-SSD) enhances the original deformable model parameter space by
adding a heatmap output from FCNN. Next, we minimize this UB-SSD by adjusting
both the parameters of the FCNN and the parameters of the deformable model in
coordinate descent. Our coordinate descent framework is end-to-end and can work
with any deformable registration method that uses SSD. We demonstrate
experimentally that our method enhances the accuracy of deformable registration
algorithms significantly on two publicly available 3D brain MRI data sets.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08796</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08800</identifier>
 <datestamp>2017-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Sub-Propositional Fragments of Modal Logic</dc:title>
 <dc:creator>Bresolin, Davide</dc:creator>
 <dc:creator>Mu&#xf1;oz-Velasco, Emilio</dc:creator>
 <dc:creator>Sciavicco, Guido</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03D15</dc:subject>
 <dc:description>  In this paper, we consider the well-known modal logics K,T,K4, and S4, and we
study some of their sub-propositional fragments, namely the classical Horn
fragment, the Krom fragment, the so-called core fragment, defined as the
intersection of the Horn and the Krom fragments, plus their sub-fragments
obtained by limiting the use of boxes and diamonds in clauses. We focus, first,
on the relative expressive power of such languages: we introduce a suitable
measure of expressive power, and we obtain a complex hierarchy that encompasses
all fragments of the considered logics. Then, after observing the low
expressive power, in particular, of the Horn fragments without diamonds, we
study the computational complexity of their satisfiability problem, proving
that, in general, it becomes polynomial.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:date>2017-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08802</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relative entropies and their use in quantum information theory</dc:title>
 <dc:creator>Leditzky, Felix</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:description>  This dissertation investigates relative entropies, also called generalized
divergences, and how they can be used to characterize information-theoretic
tasks in quantum information theory. The main goal is to further refine
characterizations of the optimal rates for quantum source coding, state
redistribution, and measurement compression with quantum side information via
second order asymptotic expansions and strong converse theorems. The
dissertation consists of a mathematical and an information-theoretic part. In
the mathematical part, we focus on the $\alpha$-sandwiched R\'enyi divergence
($\alpha$-SRD). We first investigate the limit $\alpha\to 0$ to determine
whether this recovers the well-known $0$-R\'enyi relative divergence. We then
prove various new results for entropic quantities derived from the
$\alpha$-SRD, including dimension bounds and useful bounds in terms of the
fidelity between two quantum states. Furthermore, we derive a necessary and
sufficient algebraic condition for equality in the data processing inequality
(viz. monotonicity under quantum operations) for the $\alpha$-SRD, and give
applications to entropic bounds. In the information-theoretic part, we first
derive the second order asymptotics of visible quantum source coding using a
mixed source. For the achievability part, we develop universal quantum source
codes achieving a given second order rate for a memoryless source. As a
corollary of the main result, we obtain the second order asymptotics of quantum
source coding using a single memoryless source. We then prove strong converse
theorems for state redistribution (with or without feedback) and measurement
compression with quantum side information. The key ingredients in proving these
theorems are the aforementioned fidelity bounds on R\'enyi entropic quantities
derived from the $\alpha$-SRD.
</dc:description>
 <dc:description>Comment: 200 pages, 11 figures. PhD thesis, University of Cambridge, November
  2016. Includes results from arXiv:1308.5961, arXiv:1403.2543,
  arXiv:1407.6616, arXiv:1506.02635, and arXiv:1604.02119 (see Section 1.4 for
  detailed information)</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08802</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08803</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Linear-time Algorithm for Integral Multiterminal Flows in Trees</dc:title>
 <dc:creator>Xiao, Mingyu</dc:creator>
 <dc:creator>Nagamochi, Hiroshi</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  In this paper, we study the problem of finding an integral multiflow which
maximizes the sum of flow values between every two terminals in an undirected
tree with a nonnegative integer edge capacity and a set of terminals. In
general, it is known that the flow value of an integral multiflow is bounded by
the cut value of a cut-system which consists of disjoint subsets each of which
contains exactly one terminal or has an odd cut value, and there exists a pair
of an integral multiflow and a cut-system whose flow value and cut value are
equal; i.e., a pair of a maximum integral multiflow and a minimum cut. In this
paper, we propose an $O(n)$-time algorithm that finds such a pair of an
integral multiflow and a cut-system in a given tree instance with $n$ vertices.
This improves the best previous results by a factor of $\Omega (n)$. Regarding
a given tree in an instance as a rooted tree, we define $O(n)$ rooted tree
instances taking each vertex as a root, and establish a recursive formula on
maximum integral multiflow values of these instances to design a dynamic
programming that computes the maximum integral multiflow values of all $O(n)$
rooted instances in linear time. We can prove that the algorithm implicitly
maintains a cut-system so that not only a maximum integral multiflow but also a
minimum cut-system can be constructed in linear time for any rooted instance
whenever it is necessary. The resulting algorithm is rather compact and
succinct.
</dc:description>
 <dc:description>Comment: 17 pages, 6 figures, ISAAC2016</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08803</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08805</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiuser separation and performance analysis of millimeter wave
  channels with linear precoding</dc:title>
 <dc:creator>Ahmad, Waqas</dc:creator>
 <dc:creator>Alyami, Geamel</dc:creator>
 <dc:creator>Kostanic, Ivica</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In the conventional multiuser MIMO systems, user selection and scheduling has
previously been used as an effective way to increase the sum rate performance
of the system. However, the recent concepts of the massive MIMO systems (at
centimeter wavelength frequencies) have shown that with higher spatial
resolution of antenna arrays different users in the dense scenarios can be
spatially separated. This in turn significantly reduces the signal processing
efforts required for multiuser selection algorithms. On the other hand, recent
measurements at millimeter wave frequencies show that multipath components only
arrive from few angular directions leading to high spatial correlation between
the paths and co-located users. This paper focus at the investigation of
spatial separation among the users at the millimeter wave frequencies with
fully digital linear zero-forcing transmit precoding considering various
channel propagation parameters. Our analysis results convincingly give a proof
that multiuser selection algorithms are still important for millimeter wave
communication systems. Results also show that increased number of antenna
elements does not give a major benefit to sum rate improvements as compared to
the selection of correct number of users to be selected/scheduled.
</dc:description>
 <dc:description>Comment: IEEE International Conference on Communication, Networks and
  Satellite (COMNETSAT) (IEEE COMNETSAT 2016)</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08807</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The polysemy of the words that children learn over time</dc:title>
 <dc:creator>Casas, Bernardino</dc:creator>
 <dc:creator>Catal&#xe0;, Neus</dc:creator>
 <dc:creator>Ferrer-i-Cancho, Ramon</dc:creator>
 <dc:creator>Hern&#xe1;ndez-Fern&#xe1;ndez, Antoni</dc:creator>
 <dc:creator>Baixeries, Jaume</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Here we study polysemy as a potential learning bias in vocabulary learning in
children. We employ a massive set of transcriptions of conversations between
children and adults in English, to analyze the evolution of mean polysemy in
the words produced by children whose ages range between 10 and 60 months. Our
results show that mean polysemy in children increases over time in two phases,
i.e. a fast growth till the 31st month followed by a slower tendency towards
adult speech. In contrast, no dependency with time is found in adults. This
suggests that children have a preference for non-polysemous words in their
early stages of vocabulary acquisition. Our hypothesis is twofold: (a) polysemy
is a standalone bias or (b) polysemy is a side-effect of other biases.
Interestingly, the bias for low polysemy described above weakens when
controlling for syntactic category (noun, verb, adjective or adverb). The
pattern of the evolution of polysemy suggests that both hypotheses may apply to
some extent, and that (b) would originate from a combination of the well-known
preference for nouns and the lower polysemy of nouns with respect to other
syntactic categories.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08809</identifier>
 <datestamp>2017-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fixed-Parameter Algorithms for DAG Partitioning</dc:title>
 <dc:creator>van Bevern, Ren&#xe9;</dc:creator>
 <dc:creator>Bredereck, Robert</dc:creator>
 <dc:creator>Chopin, Morgan</dc:creator>
 <dc:creator>Hartung, Sepp</dc:creator>
 <dc:creator>H&#xfc;ffner, Falk</dc:creator>
 <dc:creator>Nichterlein, Andr&#xe9;</dc:creator>
 <dc:creator>Such&#xfd;, Ond&#x159;ej</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  Finding the origin of short phrases propagating through the web has been
formalized by Leskovec et al. [ACM SIGKDD 2009] as DAG Partitioning: given an
arc-weighted directed acyclic graph on $n$ vertices and $m$ arcs, delete arcs
with total weight at most $k$ such that each resulting weakly-connected
component contains exactly one sink---a vertex without outgoing arcs. DAG
Partitioning is NP-hard.
  We show an algorithm to solve DAG Partitioning in $O(2^k \cdot (n+m))$ time,
that is, in linear time for fixed $k$. We complement it with linear-time
executable data reduction rules. Our experiments show that, in combination,
they can optimally solve DAG Partitioning on simulated citation networks within
five minutes for $k\leq190$ and $m$ being $10^7$ and larger. We use our
obtained optimal solutions to evaluate the solution quality of Leskovec et
al.'s heuristic.
  We show that Leskovec et al.'s heuristic works optimally on trees and
generalize this result by showing that DAG Partitioning is solvable in
$2^{O(w^2)}\cdot n$ time if a width-$w$ tree decomposition of the input graph
is given. Thus, we improve an algorithm and answer an open question of Alamdari
and Mehrabian [WAW 2012].
  We complement our algorithms by lower bounds on the running time of exact
algorithms and on the effectivity of data reduction.
</dc:description>
 <dc:description>Comment: A preliminary version of this article appeared at CIAC'13. Besides
  providing full proof details, this revised and extended version improves our
  O(2^k * n^2)-time algorithm to run in O(2^k * (n+m)) time and provides
  linear-time executable data reduction rules. Moreover, we experimentally
  evaluated the algorithm and compared it to known heuristics</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08809</dc:identifier>
 <dc:identifier>Discrete Applied Mathematics 220:134-160, 2017</dc:identifier>
 <dc:identifier>doi:10.1016/j.dam.2016.12.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08811</identifier>
 <datestamp>2016-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning-Based Coexistence in Two-Tier Heterogeneous Networks with
  Cognitive Small Cells</dc:title>
 <dc:creator>Zhang, Lin</dc:creator>
 <dc:creator>Zhao, Guodong</dc:creator>
 <dc:creator>Zhou, Wenli</dc:creator>
 <dc:creator>Wu, Gang</dc:creator>
 <dc:creator>Liang, Ying-Chang</dc:creator>
 <dc:creator>Li, Shaoqian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the coexistence problem in a two-tier heterogeneous network (HetNet)
with cognitive small cells. In particular, we consider an underlay HetNet,
where the cognitive small base station (C-SBS) is allowed to use the frequency
bands of the macro cell with an access probability (AP) as long as the C-SBS
satisfies a preset interference probability (IP) constraint at macro users
(MUs). To enhance the AP (or transmission opportunity) of the C-SBS, we propose
a learning-based algorithm for the C-SBS and exploit the distance information
between the macro base station (MBS) and MUs. Generally, the signal from the
MBS to a specific MU contains the distance information between the MBS to the
MU. We enable the C-SBS to analyze the MBS signal on a target frequency band,
and learn the distance information between the MBS and the corresponding MU.
With the learnt distance information, we calculate the upper bound of the
probability that the C-SBS may interfere with the MU, and design an AP with a
closed-form expression under the IP constraint. Numerical results indicate that
the proposed algorithm outperforms the existing methods up to $60\%$ AP (or
transmission opportunity).
</dc:description>
 <dc:description>Comment: Submitted to IEEE Journal of Selected Areas in Communications 2017</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:date>2016-12-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08812</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kernel classification of connectomes based on earth mover's distance
  between graph spectra</dc:title>
 <dc:creator>Dodonova, Yulia</dc:creator>
 <dc:creator>Belyaev, Mikhail</dc:creator>
 <dc:creator>Tkachev, Anna</dc:creator>
 <dc:creator>Petrov, Dmitry</dc:creator>
 <dc:creator>Zhukov, Leonid</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper, we tackle a problem of predicting phenotypes from structural
connectomes. We propose that normalized Laplacian spectra can capture
structural properties of brain networks, and hence graph spectral distributions
are useful for a task of connectome-based classification. We introduce a kernel
that is based on earth mover's distance (EMD) between spectral distributions of
brain networks. We access performance of an SVM classifier with the proposed
kernel for a task of classification of autism spectrum disorder versus typical
development based on a publicly available dataset. Classification quality (area
under the ROC-curve) obtained with the EMD-based kernel on spectral
distributions is 0.71, which is higher than that based on simpler graph
embedding methods.
</dc:description>
 <dc:description>Comment: Presented at The MICCAI-BACON 16 Workshop (arXiv:1611.03363)</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08812</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08813</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi Supervised Preposition-Sense Disambiguation using Multilingual Data</dc:title>
 <dc:creator>Gonen, Hila</dc:creator>
 <dc:creator>Goldberg, Yoav</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Prepositions are very common and very ambiguous, and understanding their
sense is critical for understanding the meaning of the sentence. Supervised
corpora for the preposition-sense disambiguation task are small, suggesting a
semi-supervised approach to the task. We show that signals from unannotated
multilingual data can be used to improve supervised preposition-sense
disambiguation. Our approach pre-trains an LSTM encoder for predicting the
translation of a preposition, and then incorporates the pre-trained encoder as
a component in a supervised classification system, and fine-tunes it for the
task. The multilingual signals consistently improve results on two
preposition-sense datasets.
</dc:description>
 <dc:description>Comment: 12 pages; COLING 2016</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08815</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Did Evolution get it right? An evaluation of Near-Infrared imaging in
  semantic scene segmentation using deep learning</dc:title>
 <dc:creator>Siddiqui, J. Rafid</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Animals have evolved to restrict their sensing capabilities to certain region
of electromagnetic spectrum. This is surprisingly a very narrow band on a vast
scale which makes one think if there is a systematic bias underlying such
selective filtration. The situation becomes even more intriguing when we find a
sharp cutoff point at Near-infrared point whereby almost all animal vision
systems seem to have a lower bound. This brings us to an interesting question:
did evolution &quot;intentionally&quot; performed such a restriction in order to evolve
higher visual cognition? In this work this question is addressed by
experimenting with Near-infrared images for their potential applicability in
higher visual processing such as semantic segmentation. A modified version of
Fully Convolutional Networks are trained on NIR images and RGB images
respectively and compared for their respective effectiveness in the wake of
semantic segmentation. The results from the experiments show that visible part
of the spectrum alone is sufficient for the robust semantic segmentation of the
indoor as well as outdoor scenes.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08815</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08822</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Spatial Separation of Multi-user channels Using 73 GHz
  Statistical Channel Models</dc:title>
 <dc:creator>Alyami, Geamel</dc:creator>
 <dc:creator>Kostanic, Ivica</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper focuses at the investigation of the degree of orthogonality of
channels of multiple users in densely populated indoor and outdoor scenarios.
For this purpose, a statistical millimeter wave (mmwave) MIMO channel simulator
is carefully designed using state of the art channel models. At the mmwave
frequencies, human/vehicular mobility around the mobile users may partially or
completely block the communication link. This give rise to the consideration of
new channel modeling parameter i.e. probability of a user to be in LOS
dynamics. Higher line of sight (LOS) probabilities may increase the spatial
correlation among the multiuser channels. Therefore, quantification of the
spatial separation of users in different scenarios with distinct LOS
probabilities is crucial and it is the subject of investigation of this paper.
Additionally, the mutual orthogonality of channels by changing the number of
base station (BS) antennas and inter antenna element distance (IED) have also
been investigated. Analysis shows that LOS blockage of certain scenario has
more impact at the degree of orthogonality among users as compared to the
number of BS antennas and the spacing between the antenna elements.
</dc:description>
 <dc:description>Comment: IEEE International Conference on Communication, Networks and
  Satellite (COMNETSAT) (IEEE COMNETSAT 2016)</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08826</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phragm\'en's and Thiele's election methods</dc:title>
 <dc:creator>Janson, Svante</dc:creator>
 <dc:subject>Mathematics - History and Overview</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The election methods introduced in 1894--1895 by Phragm\'en and Thiele, and
their somewhat later versions for ordered (ranked) ballots, are discussed in
detail. The paper includes definitions and examples and discussion of whether
the methods satisfy some properties, including monotonicity, consistency and
various proportionality criteria. The relation with STV is also discussed. The
paper also contains historical information on the methods.
</dc:description>
 <dc:description>Comment: 95 pages</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08826</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08830</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Distinction of Functional and Quality Requirements in Practice</dc:title>
 <dc:creator>Eckhardt, J.</dc:creator>
 <dc:creator>Vogelsang, A.</dc:creator>
 <dc:creator>Fern&#xe1;ndez, D. M&#xe9;ndez</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Requirements are often divided into functional requirements (FRs) and quality
requirements (QRs). However, we still have little knowledge about to which
extent this distinction makes sense from a practical perspective. In this
paper, we report on a survey we conducted with 103 practitioners to explore
whether and, if so, why they handle requirements labeled as FRs differently
from those labeled as QRs. We additionally asked for consequences of this
distinction w.r.t. the development process. Our results indicate that the
development process for requirements of the two classes strongly differs (e.g.,
in testing). We identified a number of reasons why practitioners do (or do not)
distinguish between QRs and FRs in their documentation and we analyzed both
problems and benefits that arise from that. We found, for instance, that many
reasons are based on expectations rather than on evidence. Those expectations
are, in fact, not reflected in specific negative or positive consequences per
se. It therefore seems more important that the decision whether to make an
explicit distinction or not should be made consciously such that people are
also aware of the risks that this distinction bears so that they may take
appropriate countermeasures.
</dc:description>
 <dc:description>Comment: Proceedings of the 17th International Conference on Product-Focused
  Software Process Improvement, 2016</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08830</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-49094-6_3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08832</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verifying Integer Programming Results</dc:title>
 <dc:creator>Cheung, Kevin K. H.</dc:creator>
 <dc:creator>Gleixner, Ambros</dc:creator>
 <dc:creator>Steffy, Daniel E.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>90C11</dc:subject>
 <dc:description>  Software for mixed-integer linear programming can return incorrect results
for a number of reasons, one being the use of inexact floating-point
arithmetic. Even solvers that employ exact arithmetic may suffer from
programming or algorithmic errors, motivating the desire for a way to produce
independently verifiable certificates of claimed results. Due to the complex
nature of state-of-the-art MILP solution algorithms, the ideal form of such a
certificate is not entirely clear. This paper proposes such a certificate
format, illustrating its capabilities and structure through examples. The
certificate format is designed with simplicity in mind and is composed of a
list of statements that can be sequentially verified using a limited number of
simple yet powerful inference rules. We present a supplementary verification
tool for compressing and checking these certificates independently of how they
were created. We report computational results on a selection of mixed-integer
linear programming instances from the literature. To this end, we have extended
the exact rational version of the MIP solver SCIP to produce such certificates.
</dc:description>
 <dc:description>Comment: Zuse Institute Berlin, Takustr. 7, 14195 Berlin, November 2016,
  http://nbn-resolving.de/urn:nbn:de:0297-zib-61044</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08832</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08833</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Guidelines for Preventing Critical Requirements Engineering
  Problems</dc:title>
 <dc:creator>Mafra, P.</dc:creator>
 <dc:creator>Kalinowski, M.</dc:creator>
 <dc:creator>Fern&#xe1;ndez, D. M&#xe9;ndez</dc:creator>
 <dc:creator>Felderer, M.</dc:creator>
 <dc:creator>Wagner, S.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Context] Problems in Requirements Engineering (RE) can lead to serious
consequences during the software development lifecycle. [Goal] The goal of this
paper is to propose empirically-based guidelines that can be used by different
types of organisations according to their size (small, medium or large) and
process model (agile or plan-driven) to help them in preventing such problems.
[Method] We analysed data from a survey on RE problems answered by 228
organisations in 10 different countries. [Results] We identified the most
critical RE problems, their causes and mitigation actions, organizing this
information by clusters of size and process model. Finally, we analysed the
causes and mitigation actions of the critical problems of each cluster to get
further insights into how to prevent them. [Conclusions] Based on our results,
we suggest preliminary guidelines for preventing critical RE problems in
response to context characteristics of the companies.
</dc:description>
 <dc:description>Comment: Proceedings of the 42th Euromicro Conference on Software Engineering
  and Advanced Applications, 2016</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08833</dc:identifier>
 <dc:identifier>doi:10.1109/SEAA.2016.50</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08834</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Case Studies in Industry: What We Have Learnt</dc:title>
 <dc:creator>Fern&#xe1;ndez, D. M&#xe9;ndez</dc:creator>
 <dc:creator>Wagner, S.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Case study research has become an important research methodology for
exploring phenomena in their natural contexts. Case studies have earned a
distinct role in the empirical analysis of software engineering phenomena which
are difficult to capture in isolation. Such phenomena often appear in the
context of methods and development processes for which it is difficult to run
large, controlled experiments as they usually have to reduce the scale in
several respects and, hence, are detached from the reality of industrial
software development. The other side of the medal is that the realistic
socio-economic environments where we conduct case studies -- with real-life
cases and realistic conditions -- also pose a plethora of practical challenges
to planning and conducting case studies. In this experience report, we discuss
such practical challenges and the lessons we learnt in conducting case studies
in industry. Our goal is to help especially inexperienced researchers facing
their first case studies in industry by increasing their awareness for typical
obstacles they might face and practical ways to deal with those obstacles.
</dc:description>
 <dc:description>Comment: Proceedings of the 4th International Workshop on Conducting Empirical
  Studies in Industry, co-located with ICSE, 2016</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08834</dc:identifier>
 <dc:identifier>doi:10.1145/2896839.2896844</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08839</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ranking Research Institutions Based On Related Academic Conferences</dc:title>
 <dc:creator>Orouskhani, Yasin</dc:creator>
 <dc:creator>Tavabi, Leili</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The detection of influential nodes in a social network is an active research
area with many valuable applications including marketing and advertisement. As
a new application in academia, KDD Cup 2016 shed light on the lack of an
existing objective ranking for institutions within their respective research
areas and proposed a solution for it. In this problem, the academic fields are
defined as social networks whose nodes are the active institutions within the
field, with the most influential nodes representing the highest contributors.
The solution is able to provide a ranking of active institutions within their
specific domains. The problem statement provided an annual scoring mechanism
for institutions based on their publications and encouraged the use of any
publicly available dataset such as the Microsoft Academic Graph (MAG). The
contest was focused on research publications in selected conferences and asked
for a prediction of the ranking for active institutions within those
conferences in 2016. It should be noted that the results of the paper
submissions and therefore the ground truths for KDD Cup were unknown at the
time of the contest. Each team's final ranking list was evaluated by a metric
called NDCG@20 after the results were released. This metric was used to
indicate the distance between each team's proposed ranking and the actual one
once it was known. After computing the scores of institutions for each year
starting from 2011, we aggregated the rankings by summing the normalized scores
across the years and using the final score set to provide the final ranking.
Since the 2016 ground truths were unknown, we utilized the scores from
2011-2014 and used the 2015 publications as a test bed for evaluating our
aggregation method. Based on the testing, summing the normalized scores got us
closest to the actual 2015 rankings and using same heuristic for predicting the
2016 results.
</dc:description>
 <dc:description>Comment: 3 pages, 3 tables , ranked 12nd in KDD Cup 2016</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08839</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08841</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Long-Term Image Boundary Prediction</dc:title>
 <dc:creator>Bhattacharyya, Apratim</dc:creator>
 <dc:creator>Malinowski, Mateusz</dc:creator>
 <dc:creator>Schiele, Bernt</dc:creator>
 <dc:creator>Fritz, Mario</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Boundary estimation in images and videos has been a very active topic of
research, and organizing visual information into boundaries and segments is
believed to be a corner stone of visual perception. While prior work has
focused on estimating boundaries for observed frames, our work aims at
predicting boundaries of future unobserved frames. This requires our model to
learn about the fate of boundaries and corresponding motion patterns --
including a notion of &quot;intuitive physics&quot;. We experiment on natural video
sequences along with synthetic sequences with deterministic physics-based and
agent-based motions. While not being our primary goal, we also show that fusion
of RGB and boundary prediction leads to improved RGB predictions.
</dc:description>
 <dc:description>Comment: Accepted in the AAAI Conference for Artificial Intelligence, 2018</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:date>2017-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08841</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08842</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communication complexity of inevitable intersection</dc:title>
 <dc:creator>Gavinsky, Dmitry</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Many known methods for analysing the communication complexity of unstructured
search are based on the hardness of the set disjointness problem. Such
techniques may &quot;hide&quot; important aspects of the original problem. Intuitively,
search is a much simpler task: while set disjointness is hard even for NP,
successful search necessarily results in a short witness, which makes it easy
for NP. Accordingly, the possibility to deduce hardness of search problems from
that of set disjointness can be viewed as an artefact of specific definitions.
  We construct a natural variation of the intersection-search problem, where
the input comes from a product distribution, and nevertheless, every pair of
input subsets share at least one element. We call this problem inevitable
intersection, its analysis seems to require a new, more subtle approach $-$ in
particular, not relying on the hardness of set disjointness.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08844</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A neuro-mathematical model for geometrical optical illusions</dc:title>
 <dc:creator>Franceschiello, B.</dc:creator>
 <dc:creator>Sarti, A.</dc:creator>
 <dc:creator>Citti, G.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Geometrical optical illusions have been object of many studies due to the
possibility they offer to understand the behaviour of low-level visual
processing. They consist in situations in which the perceived geometrical
properties of an object differ from those of the object in the visual stimulus.
Starting from the geometrical model introduced by Citti and Sarti in [3], we
provide a mathematical model and a computational algorithm which allows to
interpret these phenomena and to qualitatively reproduce the perceived
misperception.
</dc:description>
 <dc:description>Comment: 13 pages, 38 figures divided in 15 groups</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08844</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08847</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rapid quality assurance with Requirements Smells</dc:title>
 <dc:creator>Femmer, H.</dc:creator>
 <dc:creator>Fern&#xe1;ndez, D. M&#xe9;ndez</dc:creator>
 <dc:creator>Wagner, S.</dc:creator>
 <dc:creator>Eder, S.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Bad requirements quality can cause expensive consequences during the software
development lifecycle, especially if iterations are long and feedback comes
late. %-- the faster a problem is found, the cheaper it is to fix. This makes
explicit the need of a lightweight detection mechanism of requirements quality
violations. We aim at a light-weight static requirements analysis approach that
allows for rapid checks immediately when requirements are written down. We
transfer the concept of code smells to Requirements Engineering as Requirements
Smells. To evaluate the benefits and limitations, we define Requirements
Smells, realize our concepts for a smell detection in a prototype called Smella
and apply Smella in a series of cases provided by three industrial and a
university context. The automatic detection yields an average precision of 59%
at an average recall of 82% with high variation. The evaluation in practical
environments indicates benefits such as an increase of the awareness of quality
defects. Yet, some smells were not clearly distinguishable. Lightweight smell
detection can uncover many practically relevant requirements defects in a
reasonably precise way. Although some smells need to be defined more clearly,
smell detection provides a helpful means to support quality assurance in
Requirements Engineering, for instance, as a supplement to reviews.
</dc:description>
 <dc:description>Comment: The Journal of Systems and Software, 2016</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08847</dc:identifier>
 <dc:identifier>doi:10.1016/j.jss.2016.02.047</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08848</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting drug recalls from Internet search engine queries</dc:title>
 <dc:creator>Yom-Tov, Elad</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Batches of pharmaceutical are sometimes recalled from the market when a
safety issue or a defect is detected in specific production runs of a drug.
Such problems are usually detected when patients or healthcare providers report
abnormalities to medical authorities. Here we test the hypothesis that
defective production lots can be detected earlier by monitoring queries to
Internet search engines.
  We extracted queries from the USA to the Bing search engine which mentioned
one of 5,195 pharmaceutical drugs during 2015 and all recall notifications
issued by the Food and Drug Administration (FDA) during that year. By using
attributes that quantify the change in query volume at the state level, we
attempted to predict if a recall of a specific drug will be ordered by FDA in a
time horizon ranging from one to 40 days in future.
  Our results show that future drug recalls can indeed be identified with an
AUC of 0.791 and a lift at 5% of approximately 6 when predicting a recall will
occur one day ahead. This performance degrades as prediction is made for longer
periods ahead. The most indicative attributes for prediction are sudden spikes
in query volume about a specific medicine in each state. Recalls of
prescription drugs and those estimated to be of medium-risk are more likely to
be identified using search query data.
  These findings suggest that aggregated Internet search engine data can be
used to facilitate in early warning of faulty batches of medicines.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08849</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;Smart Girls&quot; versus &quot;Sleeping Beauties&quot; in the Sciences: The
  Identification of Instant and Delayed Recognition by Using the Citation Angle</dc:title>
 <dc:creator>Ye, Fred Y.</dc:creator>
 <dc:creator>Bornmann, Lutz</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In recent years, a number of studies have introduced methods for identifying
papers with delayed recognition (so called &quot;sleeping beauties&quot;, SBs) or have
presented single publications as cases of SBs. Most recently, Ke et al. (2015)
proposed the so called &quot;beauty coefficient&quot; (denoted as B) to quantify how much
a given paper can be considered as a paper with delayed recognition. In this
study, the new term &quot;smart girl&quot; (SG) is suggested to differentiate instant
credit or &quot;flashes in the pan&quot; from SBs. While SG and SB are qualitatively
defined, the dynamic citation angle \b{eta} is introduced in this study as a
simple way for identifying SGs and SBs quantitatively - complementing the
beauty coefficient B. The citation angles for all articles from 1980 (n=166870)
in natural sciences are calculated for identifying SGs and SBs and their
extent. We reveal that about 3% of the articles are typical SGs and about 0.1%
typical SBs. The potential advantages of the citation angle approach are
explained.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08849</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08853</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Low Complexity Detection Algorithm for SCMA</dc:title>
 <dc:creator>Zhang, Chenchen</dc:creator>
 <dc:creator>Luo, Yuan</dc:creator>
 <dc:creator>Chen, Yan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Sparse code multiple access (SCMA) is a new multiple access technique which
supports massive connectivity. Compared with the current Long Term Evolution
(LTE) system, it enables the overloading of active users on limited orthogonal
resources and thus meets the requirement of the fifth generation (5G) wireless
networks. However, the computation complexity of existing detection algorithms
increases exponentially with $d_f$ (the degree of the resource nodes). Although
the codebooks are designed to have low density, the detection still takes
considerable time. The parameter $d_f$ must be designed to be very small, which
largely limits the choice of codebooks. In this paper, a new detection
algorithm is proposed by discretizing the probability distribution functions
(PDFs) in the layer nodes (variable nodes). Given $M$ as the size of one
codebook, the detection complexity of each resource node (function node) is
reduced from $O(d_f M^{d_f})$ to $O(d_f^3 \ln (d_f))$. Its detection accuracy
can quickly approach that of the previous detection algorithms with the
decrease of sampling interval in discretization.
</dc:description>
 <dc:description>Comment: 9 pages, 5 figures</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08860</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>It's Written All Over Your Face: Full-Face Appearance-Based Gaze
  Estimation</dc:title>
 <dc:creator>Zhang, Xucong</dc:creator>
 <dc:creator>Sugano, Yusuke</dc:creator>
 <dc:creator>Fritz, Mario</dc:creator>
 <dc:creator>Bulling, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Eye gaze is an important non-verbal cue for human affect analysis. Recent
gaze estimation work indicated that information from the full face region can
benefit performance. Pushing this idea further, we propose an appearance-based
method that, in contrast to a long-standing line of work in computer vision,
only takes the full face image as input. Our method encodes the face image
using a convolutional neural network with spatial weights applied on the
feature maps to flexibly suppress or enhance information in different facial
regions. Through extensive evaluation, we show that our full-face method
significantly outperforms the state of the art for both 2D and 3D gaze
estimation, achieving improvements of up to 14.3% on MPIIGaze and 27.7% on
EYEDIAP for person-independent 3D gaze estimation. We further show that this
improvement is consistent across different illumination conditions and gaze
directions and particularly pronounced for the most challenging extreme head
poses.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08861</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A spectral gap precludes low-dimensional embeddings</dc:title>
 <dc:creator>Naor, Assaf</dc:creator>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:description>  We prove that there is a universal constant $C&gt;0$ with the following
property. Suppose that $n\in \mathbb{N}$ and that $\mathsf{A}=(a_{ij})\in
M_n(\mathbb{R})$ is a symmetric stochastic matrix. Denote the second-largest
eigenvalue of $\mathsf{A}$ by $\lambda_2(\mathsf{A})$. Then for $\mathrm{\it
any}$ finite-dimensional normed space $(X,\|\cdot\|)$ we have $$ \forall\,
x_1,\ldots,x_n\in X,\qquad \mathrm{dim}(X)\ge \frac12
\exp\left(C\frac{1-\lambda_2(\mathsf{A})}{\sqrt{n}}\bigg(\frac{\sum_{i=1}^n\sum_{j=1}^n\|x_i-x_j\|^2}{\sum_{i=1}^n\sum_{j=1}^na_{ij}\|x_i-x_j\|^2}\bigg)^{\frac12}\right).
$$ This implies that if an $n$-vertex $O(1)$-expander embeds with average
distortion $D\ge 1$ into $X$, then necessarily $\mathrm{dim}(X)\gtrsim n^{c/D}$
for some universal constant $c&gt;0$, thus improving over the previously
best-known estimate $\mathrm{dim}(X)\gtrsim (\log n)^2/D^2$ of Linial, London
and Rabinovich, strengthening a theorem of Matou\v{s}ek, and answering a
question of Andoni, Nikolov, Razenshteyn and Waingarten.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08864</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Max-Min Resource Allocator and Task Scheduling Algorithm in
  Cloud Computing Environment</dc:title>
 <dc:creator>Konjaang, J. Kok</dc:creator>
 <dc:creator>Maipan-uku, J. Y.</dc:creator>
 <dc:creator>Kubuga, Kumangkem Kennedy</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>F.2.2, I.2.7</dc:subject>
 <dc:description>  Cloud computing is a new archetype that provides dynamic computing services
to cloud users through the support of datacenters that employs the services of
datacenter brokers which discover resources and assign them Virtually. The
focus of this research is to efficiently optimize resource allocation in the
cloud by exploiting the Max-Min scheduling algorithm and enhancing it to
increase efficiency in terms of completion time (makespan). This is key to
enhancing the performance of cloud scheduling and narrowing the performance gap
between cloud service providers and cloud resources consumers/users. The
current Max-Min algorithm selects tasks with maximum execution time on a faster
available machine or resource that is capable of giving minimum completion
time. The concern of this algorithm is to give priority to tasks with maximum
execution time first before assigning those with the minimum execution time for
the purpose of minimizing makespan. The drawback of this algorithm is that, the
execution of tasks with maximum execution time first may increase the makespan,
and leads to a delay in executing tasks with minimum execution time if the
number of tasks with maximum execution time exceeds that of tasks with minimum
execution time, hence the need to improve it to mitigate the delay in executing
tasks with minimum execution time. CloudSim is used to compare the
effectiveness of the improved Max-Min algorithm with the traditional one. The
experimented results show that the improved algorithm is efficient and can
produce better makespan than Max-Min and DataAware.
</dc:description>
 <dc:description>Comment: 6 pages,6 figures, Article published</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08868</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Are &quot;Non-functional&quot; Requirements really Non-functional?</dc:title>
 <dc:creator>Eckhardt, J.</dc:creator>
 <dc:creator>Vogelsang, A.</dc:creator>
 <dc:creator>Fern&#xe1;ndez, D. M&#xe9;ndez</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Non-functional requirements (NFRs) are commonly distinguished from functional
requirements by differentiating how the system shall do something in contrast
to what the system shall do. This distinction is not only prevalent in
research, but also influences how requirements are handled in practice. NFRs
are usually documented separately from functional requirements, without
quantitative measures, and with relatively vague descriptions. As a result,
they remain difficult to analyze and test. Several authors argue, however, that
many so-called NFRs actually describe behavioral properties and may be treated
the same way as functional requirements. In this paper, we empirically
investigate this point of view and aim to increase our understanding on the
nature of NFRs addressing system properties. We report on the classification of
530 NFRs extracted from 11 industrial requirements specifications and analyze
to which extent these NFRs describe system behavior. Our results suggest that
most &quot;non-functional&quot; requirements are not non-functional as they describe
behavior of a system. Consequently, we argue that many so-called NFRs can be
handled similarly to functional requirements.
</dc:description>
 <dc:description>Comment: Proceedings of the 38th International Conference on Software
  Engineering, 2016</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08868</dc:identifier>
 <dc:identifier>doi:10.1145/2884781.2884788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08882</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Leakage Between FPGA Long Wires</dc:title>
 <dc:creator>Giechaskiel, Ilias</dc:creator>
 <dc:creator>Rasmussen, Kasper B.</dc:creator>
 <dc:creator>Eguro, Ken</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Field-Programmable Gate Arrays (FPGAs) are integrated circuits that implement
reconfigurable hardware. They are used in modern systems as they are
well-suited for creating specialized, highly-optimized integrated circuits
without the need to design and manufacture dedicated chips. As the capacity of
FPGAs grows, it is increasingly common for designers to incorporate
implementations of algorithms and protocols from a range of third-party
sources. The monolithic nature of FPGAs means that all on-chip circuits,
including third party black-box designs, must share common on-chip
infrastructure, such as routing resources.
  In this paper, we present a covert channel based on a previously unexplored
source of information leakage that occurs between adjacent but unconnected, so
called &quot;long wires&quot;, on the FPGA chip. We observe that a long wire carrying a
logical 1 reduces the delay of nearby wires and that the delay decreases
linearly with the length of wires used. This effect leads to a covert channel
that can be used for both covert communication between circuits, and for
exfiltration of secrets from the chip. We show that the effect is measurable
for both static and dynamic signals, and that it can be detected using very
small on-board circuits. In our prototype, we are able to correctly infer the
logical state of an adjacent long wire over 99% of the time, even without error
correction, and for signals that are maintained for as little as $82\mu s$.
Using a simple encoding scheme, our covert channel bandwidth is as high as
6kbps.
  We characterize the covert channel in detail and show that it can be
replicated on different generations and families of devices (Virtex 5, Virtex
6, and Artix 7), with different configurations, and is measurable even when
multiple competing circuits are present.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08886</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transmission Policies for Interference Management in Full-Duplex D2D
  Communication</dc:title>
 <dc:creator>Giatsoglou, Nikolaos</dc:creator>
 <dc:creator>Antonopoulos, Angelos</dc:creator>
 <dc:creator>Kartsakli, Elli</dc:creator>
 <dc:creator>Vardakas, John</dc:creator>
 <dc:creator>Verikoukis, Christos</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Full-Duplex (FD) wireless and Device-to-Device (D2D) communication are two
promising technologies that aspire to enhance the spectrum and energy
efficiency of wireless networks, thus fulfilling key requirements of the 5th
generation (5G) of mobile networks. Both technologies, however, generate
excessive interference, which, if not managed effectively, threatens to
compromise system performance. To this direction, we propose two transmission
policies that enhance the communication of two interfering FD-enabled D2D
pairs, derived from game theory and optimization theory. The game-theoretic
policy allows the pairs to choose their transmission modes independently and
the optimal policy to maximize their throughput, achieving significant gains
when the pairs interfere strongly with each other.
</dc:description>
 <dc:description>Comment: 6 pages, 7 figures, IEEE Global Communications Conference 2016
  (GLOBECOM), Accepted</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08888</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Propositions in Linear Multirole Logic as Multiparty Session Types</dc:title>
 <dc:creator>Xi, Hongwei</dc:creator>
 <dc:creator>Wu, Hanwen</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  We identify multirole logic as a new form of logic and formalize linear
multirole logic (LMRL) as a natural generalization of classical linear logic
(CLL). Among various meta-properties established for LMRL, we obtain one named
multi-cut elimination stating that every cut between three (or more) sequents
(as a generalization of a cut between two sequents) can be eliminated, thus
extending the celebrated result of cut-elimination by Gentzen. We also present
a variant of $\pi$-calculus for multiparty sessions that demonstrates a tight
correspondence between process communication in this variant and multi-cut
elimination in LMRL, thus extending some recent results by Caires and Pfenning
(2010) and Wadler (2012), among others, along a similar line of work.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08888</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08889</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Security Management Model in Cloud Computing Environment</dc:title>
 <dc:creator>Ahmadpanah, Seyed Hossein</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In the cloud computing environment, cloud virtual machine (VM) will be more
and more the number of virtual machine security and management faced giant
Challenge. In order to address security issues cloud computing virtualization
environment, this paper presents a virtual machine based on efficient and
dynamic deployment VM security management model state migration and scheduling,
study of which virtual machine security architecture, based on AHP (Analytic
Hierarchy Process) virtual machine deployment and scheduling method, based on
CUSUM (Cumulative Sum) DDoS attack detection algorithm, and the above-described
method for functional testing and validation.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08892</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Teams in Online Scheduling Polls: Game-Theoretic Aspects</dc:title>
 <dc:creator>Bredereck, Robert</dc:creator>
 <dc:creator>Chen, Jiehua</dc:creator>
 <dc:creator>Niedermeier, Rolf</dc:creator>
 <dc:creator>Obraztsova, Svetlana</dc:creator>
 <dc:creator>Talmon, Nimrod</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>F.2, J.4, G.2.1</dc:subject>
 <dc:description>  Consider an important meeting to be held in a team-based organization. Taking
availability constraints into account, an online scheduling poll is being used
in order to decide upon the exact time of the meeting. Decisions are to be
taken during the meeting, therefore each team would like to maximize its
relative attendance in the meeting (i.e., the proportional number of its
participating team members). We introduce a corresponding game, where each team
can declare (in the scheduling poll) a lower total availability, in order to
improve its relative attendance---the pay-off. We are especially interested in
situations where teams can form coalitions.
  We provide an efficient algorithm that, given a coalition, finds an optimal
way for each team in a coalition to improve its pay-off. In contrast, we show
that deciding whether such a coalition exists is NP-hard. We also study the
existence of Nash equilibria: Finding Nash equilibria for various small sizes
of teams and coalitions can be done in polynomial time while it is coNP-hard if
the coalition size is unbounded.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08892</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08894</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Effect of Gender in the Publication Patterns in Mathematics</dc:title>
 <dc:creator>Mihaljevi&#x107;-Brandt, Helena</dc:creator>
 <dc:creator>Santamar&#xed;a, Luc&#xed;a</dc:creator>
 <dc:creator>Tullney, Marco</dc:creator>
 <dc:subject>Mathematics - History and Overview</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Despite the increasing number of women graduating in mathematics, a systemic
gender imbalance persists and is signified by a pronounced gender gap in the
distribution of active researchers and professors. Especially at the level of
university faculty, women mathematicians continue being drastically
underrepresented, decades after the first affirmative action measures have been
put into place. A solid publication record is of paramount importance for
securing permanent positions. Thus, the question arises whether the publication
patterns of men and women mathematicians differ in a significant way. Making
use of the zbMATH database, one of the most comprehensive metadata sources on
mathematical publications, we analyze the scholarly output of ~150,000
mathematicians from the past four decades whose gender we algorithmically
inferred. We focus on development over time, collaboration through
coautorships, presumed journal quality and distribution of research topics --
factors known to have a strong impact on job perspectives. We report
significant differences between genders which may put women at a disadvantage
when pursuing an academic career in mathematics.
</dc:description>
 <dc:description>Comment: 24 pages, 12 figures</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08894</dc:identifier>
 <dc:identifier>PLoS ONE 11(10): e0165367 (2016)</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0165367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08896</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uniform Information Segmentation</dc:title>
 <dc:creator>Achanta, Radhakrishna</dc:creator>
 <dc:creator>M&#xe1;rquez-Neila, Pablo</dc:creator>
 <dc:creator>Fua, Pascal</dc:creator>
 <dc:creator>S&#xfc;sstrunk, Sabine</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Size uniformity is one of the main criteria of superpixel methods. But size
uniformity rarely conforms to the varying content of an image. The chosen size
of the superpixels therefore represents a compromise - how to obtain the fewest
superpixels without losing too much important detail. We propose that a more
appropriate criterion for creating image segments is information uniformity. We
introduce a novel method for segmenting an image based on this criterion. Since
information is a natural way of measuring image complexity, our proposed
algorithm leads to image segments that are smaller and denser in areas of high
complexity and larger in homogeneous regions, thus simplifying the image while
preserving its details. Our algorithm is simple and requires just one input
parameter - a threshold on the information content. On segmentation comparison
benchmarks it proves to be superior to the state-of-the-art. In addition, our
method is computationally very efficient, approaching real-time performance,
and is easily extensible to three-dimensional image stacks and video volumes.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08896</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08898</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Size of Lempel-Ziv and Lyndon Factorizations</dc:title>
 <dc:creator>K&#xe4;rkk&#xe4;inen, Juha</dc:creator>
 <dc:creator>Kempa, Dominik</dc:creator>
 <dc:creator>Nakashima, Yuto</dc:creator>
 <dc:creator>Puglisi, Simon J.</dc:creator>
 <dc:creator>Shur, Arseny M.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Lyndon factorization and Lempel-Ziv (LZ) factorization are both important
tools for analysing the structure and complexity of strings, but their
combinatorial structure is very different. In this paper, we establish the
first direct connection between the two by showing that while the Lyndon
factorization can be bigger than the non-overlapping LZ factorization (which we
demonstrate by describing a new, non-trivial family of strings) it is never
more than twice the size.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08898</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08903</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Should I use TensorFlow</dc:title>
 <dc:creator>Schrimpf, Martin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Google's Machine Learning framework TensorFlow was open-sourced in November
2015 [1] and has since built a growing community around it. TensorFlow is
supposed to be flexible for research purposes while also allowing its models to
be deployed productively. This work is aimed towards people with experience in
Machine Learning considering whether they should use TensorFlow in their
environment. Several aspects of the framework important for such a decision are
examined, such as the heterogenity, extensibility and its computation graph. A
pure Python implementation of linear classification is compared with an
implementation utilizing TensorFlow. I also contrast TensorFlow to other
popular frameworks with respect to modeling capability, deployment and
performance and give a brief description of the current adaption of the
framework.
</dc:description>
 <dc:description>Comment: Seminar Paper</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08905</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SISO and SIMO Accompaniment Cancellation for Live Solo Recordings Based
  on Short-Time ERB-Band Wiener Filtering and Spectral Subtraction</dc:title>
 <dc:creator>Gorlow, Stanislaw</dc:creator>
 <dc:creator>Ramona, Mathieu</dc:creator>
 <dc:creator>Pachet, Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Research in collaborative music learning is subject to unresolved problems
demanding new technological solutions. One such problem poses the suppression
of the accompaniment in a live recording of a performance during practice,
which can be for the purposes of self-assessment or further machine-aided
analysis. Being able to separate a solo from the accompaniment allows to create
learning agents that may act as personal tutors and help the apprentice improve
his or her technique. First, we start from the classical adaptive noise
cancelling approach, and adjust it to the problem at hand. In a second step, we
compare some adaptive and Wiener filtering approaches and assess their
performances on the task. Our findings underpin that adaptive filtering is
inapt of dealing with music signals and that Wiener filtering in the short-time
Fourier transform domain is a much more effective approach. In addition, it is
very cheap if carried out in the frequency bands of auditory filters. A
double-output extension based on maximal-ratio combining is also proposed.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08906</identifier>
 <datestamp>2017-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Voronoi-based compact image descriptors: Efficient Region-of-Interest
  retrieval with VLAD and deep-learning-based descriptors</dc:title>
 <dc:creator>Chadha, Aaron</dc:creator>
 <dc:creator>Andreopoulos, Yiannis</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We investigate the problem of image retrieval based on visual queries when
the latter comprise arbitrary regions-of-interest (ROI) rather than entire
images. Our proposal is a compact image descriptor that combines the
state-of-the-art in content-based descriptor extraction with a multi-level,
Voronoi-based spatial partitioning of each dataset image. The proposed
multi-level Voronoi-based encoding uses a spatial hierarchical K-means over
interest-point locations, and computes a content-based descriptor over each
cell. In order to reduce the matching complexity with minimal or no sacrifice
in retrieval performance: (i) we utilize the tree structure of the spatial
hierarchical K-means to perform a top-to-bottom pruning for local similarity
maxima; (ii) we propose a new image similarity score that combines relevant
information from all partition levels into a single measure for similarity;
(iii) we combine our proposal with a novel and efficient approach for optimal
bit allocation within quantized descriptor representations. By deriving both a
Voronoi-based VLAD descriptor (termed as Fast-VVLAD) and a Voronoi-based deep
convolutional neural network (CNN) descriptor (termed as Fast-VDCNN), we
demonstrate that our Voronoi-based framework is agnostic to the descriptor
basis, and can easily be slotted into existing frameworks. Via a range of ROI
queries in two standard datasets, it is shown that the Voronoi-based
descriptors achieve comparable or higher mean Average Precision against
conventional grid-based spatial search, while offering more than two-fold
reduction in complexity. Finally, beyond ROI queries, we show that Voronoi
partitioning improves the geometric invariance of compact CNN descriptors,
thereby resulting in competitive performance to the current state-of-the-art on
whole image retrieval.
</dc:description>
 <dc:description>Comment: IEEE Transaction on Multimedia, to appear</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:date>2017-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08906</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08908</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;Model and Run&quot; Constraint Networks with a MILP Engine</dc:title>
 <dc:creator>Petit, Thierry</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Constraint Programming (CP) users need significant expertise in order to
model their problems appropriately, notably to select propagators and search
strategies. This puts the brakes on a broader uptake of CP. In this paper, we
introduce MICE, a complete Java CP modeler that can use any Mixed Integer
Linear Programming (MILP) solver as a solution technique. Our aim is to provide
an alternative tool for democratizing the &quot;CP-style&quot; modeling thanks to its
simplicity of use, with reasonable solving capabilities. Our contributions
include new decompositions of (reified) constraints and constraints on
numerical variables.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08913</identifier>
 <datestamp>2017-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple Model of Attentional Blink</dc:title>
 <dc:creator>Amir, Nadav</dc:creator>
 <dc:creator>Nelken, Israel</dc:creator>
 <dc:creator>Tishby, Naftali</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The attentional blink (AB) effect is the reduced ability of subjects to
report a second target stimuli (T2) among a rapidly presented series of
non-target stimuli, when it appears within a time window of about 200-500 ms
after a first target (T1). We present a simple dynamical systems model
explaining the AB as resulting from the temporal response dynamics of a
stochastic, linear system with threshold, whose output represents the amount of
attentional resources allocated to the incoming sensory stimuli. The model
postulates that the available attention capacity is limited by activity of the
default mode network (DMN), a correlated set of brain regions related to task
irrelevant processing which is known to exhibit reduced activation following
mental training such as mindfulness meditation. The model provides a
parsimonious account relating key findings from the AB, DMN and meditation
research literature, and suggests some new testable predictions.
</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:date>2017-09-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08913</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08927</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Multiplicity Election Problems</dc:title>
 <dc:creator>Fitzsimmons, Zack</dc:creator>
 <dc:creator>Hemaspaandra, Edith</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  The computational study of elections generally assumes that the preferences
of the electorate come in as a list of votes. Depending on the context, it may
be much more natural to represent the list succinctly, as the distinct votes of
the electorate and their counts, i.e., high-multiplicity representation. We
consider how this representation affects the complexity of election problems.
High-multiplicity representation may be exponentially smaller than standard
representation, and so many polynomial-time algorithms for election problems in
standard representation become exponential. Surprisingly, for polynomial-time
election problems, we are often able to either adapt the same approach or
provide new algorithms to show that these problems remain polynomial-time in
the high-multiplicity case; this is in sharp contrast to the case where each
voter has a weight, where the complexity usually increases. In the process we
explore the relationship between high-multiplicity scheduling and manipulation
of high-multiplicity elections. And we show that for any fixed set of job
lengths, high-multiplicity scheduling on uniform parallel machines is in P,
which was previously known for only two job lengths. We did not find any
natural case where a polynomial-time election problem does not remain in P when
moving to high-multiplicity representation. However, we found one natural
NP-hard election problem where the complexity does increase, namely winner
determination for Kemeny elections.
</dc:description>
 <dc:description>Comment: A preliminary version of this paper (arXiv:1611.08927v1) was titled
  &quot;The Complexity of Succinct Elections.&quot;</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:date>2017-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08927</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1611.08928</identifier>
 <datestamp>2017-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A theory of interpretive clustering in free recall</dc:title>
 <dc:creator>Fumarola, Francesco</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>91E10</dc:subject>
 <dc:description>  A stochastic model of short-term verbal memory is proposed, in which the
psychological state of the subject is encoded as the instantaneous position of
a particle diffusing over a semantic graph with a probabilistic structure. The
model is particularly suitable for studying the dependence of free-recall
observables on semantic properties of the words to be recalled. Besides
predicting some well-known experimental features (contiguity effect, forward
asymmetry, word-length effect), a novel prediction is obtained on the
relationship between the contiguity effect and the syllabic length of words;
shorter words, by way of their wider semantic range, are predicted to be
characterized by stronger forward contiguity. A fresh analysis of archival data
allows to confirm this prediction.
</dc:description>
 <dc:description>Comment: 24 pages, 8 figures</dc:description>
 <dc:date>2016-11-27</dc:date>
 <dc:date>2017-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1611.08928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="110000" completeListSize="155308">2369777|111001</resumptionToken>
</ListRecords>
</OAI-PMH>
