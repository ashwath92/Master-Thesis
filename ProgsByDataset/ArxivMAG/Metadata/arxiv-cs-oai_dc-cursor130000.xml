<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2018-01-29T03:34:53Z</responseDate>
<request verb="ListRecords" resumptionToken="2369777|130001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07811</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for Wireless Broadband Network for Connecting the
  Unconnected</dc:title>
 <dc:creator>Khaturia, Meghna</dc:creator>
 <dc:creator>Chaporkar, Prasanna</dc:creator>
 <dc:creator>Karandikar, Abhay</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  A significant barrier in providing affordable rural broadband is to connect
the rural and remote places to the optical Point of Presence (PoP) over
distances of few kilometers. A lot of work has been done in the area of long
distance Wi-Fi networks. However, these networks require tall towers and high
gain (directional) antennas. Also, they work in the unlicensed band which has
Effective Isotropically Radiated Power (EIRP) limit (e.g. 1 W in India) which
restricts the network design. In this work, we propose a Long Term
Evolution-Advanced (LTE-A) network operating in TV UHF to connect the remote
areas to the optical PoP. In India, around 100 MHz of TV UHF band IV (470-585
MHz) is unused at any location and can be put to an effective use in these
areas. We explore the idea of multi-hop topology for the proposed network. We
also compare the performance of the multi-hop network with the Point to
Multipoint (PMP) topology. The results show that multi-hop network performs
much better than the PMP network. We then formulate a Linear Programming (LP)
problem of generating optimal topology and compare its performance with the
multi-hop network. Overall, the analysis implies that an optimally planned
LTE-A network in TV UHF band can be a potential solution for affordable rural
broadband.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07815</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph-Theoretic Spatiotemporal Context Modeling for Video Saliency
  Detection</dc:title>
 <dc:creator>Wei, Lina</dc:creator>
 <dc:creator>Wang, Fangfang</dc:creator>
 <dc:creator>Li, Xi</dc:creator>
 <dc:creator>Wu, Fei</dc:creator>
 <dc:creator>Xiao, Jun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  As an important and challenging problem in computer vision, video saliency
detection is typically cast as a spatiotemporal context modeling problem over
consecutive frames. As a result, a key issue in video saliency detection is how
to effectively capture the intrinsical properties of atomic video structures as
well as their associated contextual interactions along the spatial and temporal
dimensions. Motivated by this observation, we propose a graph-theoretic video
saliency detection approach based on adaptive video structure discovery, which
is carried out within a spatiotemporal atomic graph. Through graph-based
manifold propagation, the proposed approach is capable of effectively modeling
the semantically contextual interactions among atomic video structures for
saliency detection while preserving spatial smoothness and temporal
consistency. Experiments demonstrate the effectiveness of the proposed approach
over several benchmark datasets.
</dc:description>
 <dc:description>Comment: ICIP 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07815</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07816</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Small-Scale, Local Area, and Transitional Millimeter Wave Propagation
  for 5G Communications</dc:title>
 <dc:creator>Rappaport, Theodore S.</dc:creator>
 <dc:creator>MacCartney Jr., George R.</dc:creator>
 <dc:creator>Sun, Shu</dc:creator>
 <dc:creator>Yan, Hangsong</dc:creator>
 <dc:creator>Deng, Sijia</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies radio propagation mechanisms that impact handoffs, air
interface design, beam steering, and MIMO for 5G mobile communication systems.
Knife edge diffraction (KED) and a creeping wave linear model are shown to
predict diffraction loss around typical building objects from 10 to 26 GHz, and
human blockage measurements at 73 GHz are shown to fit a double knife-edge
diffraction (DKED) model which incorporates antenna gains. Small-scale spatial
fading of millimeter wave received signal voltage amplitude is generally
Ricean-distributed for both omnidirectional and directional receive antenna
patterns under both line-of-sight (LOS) and non-line-of-sight (NLOS) conditions
in most cases, although the log-normal distribution fits measured data better
for the omnidirectional receive antenna pattern in the NLOS environment.
Small-scale spatial autocorrelations of received voltage amplitudes are shown
to fit sinusoidal exponential and exponential functions for LOS and NLOS
environments, respectively, with small decorrelation distances of 0.27 cm to
13.6 cm (smaller than the size of a handset) that are favorable for spatial
multiplexing. Local area measurements using cluster and route scenarios show
how the received signal changes as the mobile moves and transitions from LOS to
NLOS locations, with reasonably stationary signal levels within clusters.
Wideband mmWave power levels are shown to fade from 0.4 dB/ms to 40 dB/s,
depending on travel speed and surroundings.
</dc:description>
 <dc:description>Comment: To appear in the IEEE Transactions on Antennas and Propagation,
  Special Issue on 5G, Nov. 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07819</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Semantic Parts on Partially Occluded Objects</dc:title>
 <dc:creator>Wang, Jianyu</dc:creator>
 <dc:creator>Xie, Cihang</dc:creator>
 <dc:creator>Zhang, Zhishuai</dc:creator>
 <dc:creator>Zhu, Jun</dc:creator>
 <dc:creator>Xie, Lingxi</dc:creator>
 <dc:creator>Yuille, Alan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we address the task of detecting semantic parts on partially
occluded objects. We consider a scenario where the model is trained using
non-occluded images but tested on occluded images. The motivation is that there
are infinite number of occlusion patterns in real world, which cannot be fully
covered in the training data. So the models should be inherently robust and
adaptive to occlusions instead of fitting / learning the occlusion patterns in
the training data. Our approach detects semantic parts by accumulating the
confidence of local visual cues. Specifically, the method uses a simple voting
method, based on log-likelihood ratio tests and spatial constraints, to combine
the evidence of local cues. These cues are called visual concepts, which are
derived by clustering the internal states of deep networks. We evaluate our
voting scheme on the VehicleSemanticPart dataset with dense part annotations.
We randomly place two, three or four irrelevant objects onto the target object
to generate testing images with various occlusions. Experiments show that our
algorithm outperforms several competitors in semantic part detection when
occlusions are present.
</dc:description>
 <dc:description>Comment: Accepted to BMVC 2017 (13 pages, 3 figures)</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07821</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Concept Drift Detection and Adaptation with Hierarchical Hypothesis
  Testing</dc:title>
 <dc:creator>Yu, Shujian</dc:creator>
 <dc:creator>Abraham, Zubin</dc:creator>
 <dc:creator>Wang, Heng</dc:creator>
 <dc:creator>Shah, Mohak</dc:creator>
 <dc:creator>Pr&#xed;ncipe, Jos&#xe9; C.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In a streaming environment, there is often a need for statistical prediction
models to detect and adapt to concept drifts (i.e., changes in the joint
distribution between predictor and response variables) so as to mitigate
deteriorating predictive performance over time. Various concept drift detection
approaches have been proposed in the past decades. However, they do not perform
well across different concept drift types (e.g., gradual or abrupt, recurrent
or irregular) and different data stream distributions (e.g., balanced and
imbalanced labels). This paper presents a novel framework that can detect and
also adapt to the various concept drift types, even in the presence of
imbalanced data labels. The framework leverages a hierarchical set of
hypothesis tests in an online fashion to detect concept drifts and employs an
adaptive training strategy to significantly boost its adaptation capability.
The performance of the proposed framework is compared to benchmark approaches
using both simulated and real-world datasets spanning the breadth of concept
drift types. The proposed approach significantly outperforms benchmark
solutions in terms of precision, delay of detection as well as the adaptability
across different concepts.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07821</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07823</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mathematical Model for Detection of Leakage in Domestic Water Supply
  Systems by Reading Consumption from an Analogue Water Meter</dc:title>
 <dc:creator>Oren, Gal</dc:creator>
 <dc:creator>Stroh, Nerya Y.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  In this article we introduce the principles to detect leakage using a
mathematical model based on machine learning and domestic water consumption
monitoring in real time. The model uses data which is measured from a water
meter, analyzes the water consumption, and uses two criteria simultaneously:
deviation from the average consumption, and comparison of steady water
consumptions over a period of time. Simulation of the model on a regular
household consumer was implemented on Antileaks - device that we have built
that designed to transfer consumption information from an analogue water meter
to a digital form in real time.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07823</dc:identifier>
 <dc:identifier>International Journal of Environmental Science and Development
  (IJESD), Vol. 4, No. 4, International Association of Computer Science and
  Information Technology Press, ISSN: 2010-0264, 2013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07825</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple-Kernel Local-Patch Descriptor</dc:title>
 <dc:creator>Mukundan, Arun</dc:creator>
 <dc:creator>Tolias, Giorgos</dc:creator>
 <dc:creator>Chum, Ondrej</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a multiple-kernel local-patch descriptor based on efficient match
kernels of patch gradients. It combines two parametrizations of gradient
position and direction, each parametrization provides robustness to a different
type of patch miss-registration: polar parametrization for noise in the patch
dominant orientation detection, Cartesian for imprecise location of the feature
point. Even though handcrafted, the proposed method consistently outperforms
the state-of-the-art methods on two local patch benchmarks.
</dc:description>
 <dc:description>Comment: To appear in the British Machine Vision Conference (BMVC), September
  2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07830</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Robustness of Feature Representations to Image Deformations
  using Powered Convolution in CNNs</dc:title>
 <dc:creator>Sun, Zhun</dc:creator>
 <dc:creator>Ozay, Mete</dc:creator>
 <dc:creator>Okatani, Takayuki</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we address the problem of improvement of robustness of feature
representations learned using convolutional neural networks (CNNs) to image
deformation. We argue that higher moment statistics of feature distributions
could be shifted due to image deformations, and the shift leads to degrade of
performance and cannot be reduced by ordinary normalization methods as observed
in experimental analyses. In order to attenuate this effect, we apply
additional non-linearity in CNNs by combining power functions with learnable
parameters into convolution operation. In the experiments, we observe that CNNs
which employ the proposed method obtain remarkable boost in both the
generalization performance and the robustness under various types of
deformations using large scale benchmark datasets. For instance, a model
equipped with the proposed method obtains 3.3\% performance boost in mAP on
Pascal Voc object detection task using deformed images, compared to the
reference model, while both models provide the same performance using original
images. To the best of our knowledge, this is the first work that studies
robustness of deep features learned using CNNs to a wide range of deformations
for object recognition and detection.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07831</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Discriminant Generative Adversarial Networks</dc:title>
 <dc:creator>Sun, Zhun</dc:creator>
 <dc:creator>Ozay, Mete</dc:creator>
 <dc:creator>Okatani, Takayuki</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We develop a novel method for training of GANs for unsupervised and class
conditional generation of images, called Linear Discriminant GAN (LD-GAN). The
discriminator of an LD-GAN is trained to maximize the linear separability
between distributions of hidden representations of generated and targeted
samples, while the generator is updated based on the decision hyper-planes
computed by performing LDA over the hidden representations. LD-GAN provides a
concrete metric of separation capacity for the discriminator, and we
experimentally show that it is possible to stabilize the training of LD-GAN
simply by calibrating the update frequencies between generators and
discriminators in the unsupervised case, without employment of normalization
methods and constraints on weights. In the class conditional generation tasks,
the proposed method shows improved training stability together with better
generalization performance compared to WGAN that employs an auxiliary
classifier.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07831</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07833</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ssEMnet: Serial-section Electron Microscopy Image Registration using a
  Spatial Transformer Network with Learned Features</dc:title>
 <dc:creator>Yoo, Inwan</dc:creator>
 <dc:creator>Hildebrand, David G. C.</dc:creator>
 <dc:creator>Tobin, Willie F.</dc:creator>
 <dc:creator>Lee, Wei-Chung Allen</dc:creator>
 <dc:creator>Jeong, Won-Ki</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The alignment of serial-section electron microscopy (ssEM) images is critical
for efforts in neuroscience that seek to reconstruct neuronal circuits.
However, each ssEM plane contains densely packed structures that vary from one
section to the next, which makes matching features across images a challenge.
Advances in deep learning has resulted in unprecedented performance in similar
computer vision problems, but to our knowledge, they have not been successfully
applied to ssEM image co-registration. In this paper, we introduce a novel deep
network model that combines a spatial transformer for image deformation and a
convolutional autoencoder for unsupervised feature learning for robust ssEM
image alignment. This results in improved accuracy and robustness while
requiring substantially less user intervention than conventional methods. We
evaluate our method by comparing registration quality across several datasets.
</dc:description>
 <dc:description>Comment: DLMIA 2017 accepted</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07833</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-67558-9_29</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07835</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Semantic Query Segmentation</dc:title>
 <dc:creator>Kale, Ajinkya</dc:creator>
 <dc:creator>Taula, Thrivikrama</dc:creator>
 <dc:creator>Hewavitharana, Sanjika</dc:creator>
 <dc:creator>Srivastava, Amit</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Query Segmentation is one of the critical components for understanding users'
search intent in Information Retrieval tasks. It involves grouping tokens in
the search query into meaningful phrases which help downstream tasks like
search relevance and query understanding. In this paper, we propose a novel
approach to segment user queries using distributed query embeddings. Our key
contribution is a supervised approach to the segmentation task using
low-dimensional feature vectors for queries, getting rid of traditional hand
tuned and heuristic NLP features which are quite expensive.
  We benchmark on a 50,000 human-annotated web search engine query corpus
achieving comparable accuracy to state-of-the-art techniques. The advantage of
our technique is its fast and does not use external knowledge-base like
Wikipedia for score boosting. This helps us generalize our approach to other
domains like eCommerce without any fine-tuning. We demonstrate the
effectiveness of this method on another 50,000 human-annotated eCommerce query
corpus from eBay search logs. Our approach is easy to implement and generalizes
well across different search domains proving the power of low-dimensional
embeddings in query segmentation task, opening up a new direction of research
for this problem.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07843</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Saturated Throughput Analysis of Coexistence of Wi-Fi and Cellular
  With Listen-Before-Talk in Unlicensed Spectrum</dc:title>
 <dc:creator>Kim, Yongjae</dc:creator>
 <dc:creator>Song, Yujae</dc:creator>
 <dc:creator>Choi, Yonghoon</dc:creator>
 <dc:creator>Han, Youngnam</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper analyzes the coexistence performance of Wi-Fi and cellular
networks conditioned on non-saturated traffic in the unlicensed spectrum. Under
the condition, the time-domain behavior of a cellular small-cell base station
(SCBS) with a listen-before-talk (LBT) procedure is modeled as a Markov chain,
and it is combined with a Markov chain which describes the time-domain behavior
of a Wi-Fi access point. Using the proposed model, this study finds the optimal
contention window size of cellular SCBSs in which total throughput of both
networks is maximized while satisfying the required throughput of each network,
under the given traffic densities of both networks. This will serve as a
guideline for cellular operators with respect to performing LBT at cellular
SCBSs according to the changes of traffic volumes of both networks over time.
</dc:description>
 <dc:description>Comment: To appear on IEEE Transactions on Vehicular Technology</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07843</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07845</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Implementation of a Reversible Object-Oriented Programming
  Language</dc:title>
 <dc:creator>Haulund, Tue</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>68N15</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:description>  High-level reversible programming languages are few and far between and in
general offer only rudimentary abstractions from the details of the underlying
machine. Modern programming languages offer a wide array of language constructs
and paradigms to facilitate the design of abstract interfaces, but we currently
have a very limited understanding of the applicability of such features for
reversible programming languages.
  We introduce the first reversible object-oriented programming language,
ROOPL, with support for user-defined data types, class inheritance and
subtype-polymorphism. The language extends the design of existing reversible
imperative languages and it allows for effective implementation on reversible
machines.
  We provide a formalization of the language semantics, the type system and we
demonstrate the computational universality of the language by implementing a
reversible Turing machine simulator. ROOPL statements are locally invertible at
no extra cost to program size or computational complexity and the language
provides direct access to the inverse semantics of each class method.
  We describe the techniques required for a garbage-free translation from ROOPL
to the reversible assembly language PISA and provide a full implementation of
said techniques. Our results indicate that core language features for
object-oriented programming carries over to the field of reversible computing
in some capacity.
</dc:description>
 <dc:description>Comment: Master's Thesis, 110 pages, 55 figures</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07846</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applications of Economic and Pricing Models for Wireless Network
  Security: A Survey</dc:title>
 <dc:creator>Luong, Nguyen Cong</dc:creator>
 <dc:creator>Hoang, Dinh Thai</dc:creator>
 <dc:creator>Wang, Ping</dc:creator>
 <dc:creator>Niyato, Dusit</dc:creator>
 <dc:creator>Han, Zhu</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper provides a comprehensive literature review on applications of
economic and pricing theory to security issues in wireless networks. Unlike
wireline networks, the broadcast nature and the highly dynamic change of
network environments pose a number of nontrivial challenges to security design
in wireless networks. While the security issues have not been completely solved
by traditional or system-based solutions, economic and pricing models recently
were employed as one efficient solution to discourage attackers and prevent
attacks to be performed. In this paper, we review economic and pricing
approaches proposed to address major security issues in wireless networks
including eavesdropping attack, Denial-of-Service (DoS) attack such as jamming
and Distributed DoS (DDoS), and illegitimate behaviors of malicious users.
Additionally, we discuss integrating economic and pricing models with
cryptography methods to reduce information privacy leakage as well as to
guarantee the confidentiality and integrity of information in wireless
networks. Finally, we highlight important challenges, open issues and future
research directions of applying economic and pricing models to wireless
security issues.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07846</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07847</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hyperbolic Representation Learning for Fast and Efficient Neural
  Question Answering</dc:title>
 <dc:creator>Tay, Yi</dc:creator>
 <dc:creator>Tuan, Luu Anh</dc:creator>
 <dc:creator>Hui, Siu Cheung</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The dominant neural architectures in question answer retrieval are based on
recurrent or convolutional encoders configured with complex word matching
layers. Given that recent architectural innovations are mostly new word
interaction layers or attention-based matching mechanisms, it seems to be a
well-established fact that these components are mandatory for good performance.
Unfortunately, the memory and computation cost incurred by these complex
mechanisms are undesirable for practical applications. As such, this paper
tackles the question of whether it is possible to achieve competitive
performance with simple neural architectures. We propose a simple but novel
deep learning architecture for fast and efficient question-answer ranking and
retrieval. More specifically, our proposed model, \textsc{HyperQA}, is a
parameter efficient neural network that outperforms other parameter intensive
models such as Attentive Pooling BiLSTMs and Multi-Perspective CNNs on multiple
QA benchmarks. The novelty behind \textsc{HyperQA} is a pairwise ranking
objective that models the relationship between question and answer embeddings
in Hyperbolic space instead of Euclidean space. This empowers our model with a
self-organizing ability and enables automatic discovery of latent hierarchies
while learning embeddings of questions and answers. Our model requires no
feature engineering, no similarity matrix matching, no complicated attention
mechanisms nor over-parameterized layers and yet outperforms and remains
competitive to many models that have these functionalities on multiple
benchmarks.
</dc:description>
 <dc:description>Comment: Accepted at WSDM 2018</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07847</dc:identifier>
 <dc:identifier>doi:10.1145/3159652.3159664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07849</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance evaluation of energy detector over generalized non-linear
  and shadowed composite fading channels using a Mixture Gamma Distribution</dc:title>
 <dc:creator>Huang, He</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The performance of energy detection (ED) for independent and identically
distribution (i.i.d.) signal models is analyzed over generalized composite
non-linear line-of-sight (LOS) and non-line-of-sight (NLOS) shadowed fading
scenarios. The novel expressions for {\alpha}-\k{appa}-{\mu}/Gamma and
{\alpha}-{\eta}-{\mu}/Gamma fading channels have been derived to approximate by
using the mixture gamma (MG) distribution under low instantaneous
signal-to-noise (SNR) condition. On the basis of the deduced fading
distributions, novel, exact and close-form detective models are derived to
evaluate the sensing performance with different key fading parameters over
generalized non-linear and shadowed composite fading channels.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07849</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07857</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Motion-Appearance Interactive Encoding for Object Segmentation in
  Unconstrained Videos</dc:title>
 <dc:creator>Guo, Chunchao</dc:creator>
 <dc:creator>Lai, Jianhuang</dc:creator>
 <dc:creator>Xie, Xiaohua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4.6</dc:subject>
 <dc:subject>I.4.8</dc:subject>
 <dc:description>  We present a novel method of integrating motion and appearance cues for
foreground object segmentation in unconstrained videos. Unlike conventional
methods encoding motion and appearance patterns individually, our method puts
particular emphasis on their mutual assistance. Specifically, we propose using
an interactively constrained encoding (ICE) scheme to incorporate motion and
appearance patterns into a graph that leads to a spatiotemporal energy
optimization. The reason of utilizing ICE is that both motion and appearance
cues for the same target share underlying correlative structure, thus can be
exploited in a deeply collaborative manner. We perform ICE not only in the
initialization but also in the refinement stage of a two-layer framework for
object segmentation. This scheme allows our method to consistently capture
structural patterns about object perceptions throughout the whole framework.
Our method can be operated on superpixels instead of raw pixels to reduce the
number of graph nodes by two orders of magnitude. Moreover, we propose to
partially explore the multi-object localization problem with inter-occlusion by
weighted bipartite graph matching. Comprehensive experiments on three benchmark
datasets (i.e., SegTrack, MOViCS, and GaTech) demonstrate the effectiveness of
our approach compared with extensive state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 11 pages, 7 figures</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07857</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07863</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analyzing First-Person Stories Based on Socializing, Eating and
  Sedentary Patterns</dc:title>
 <dc:creator>Herruzo, Pedro</dc:creator>
 <dc:creator>Portell, Laura</dc:creator>
 <dc:creator>Soto, Alberto</dc:creator>
 <dc:creator>Remeseiro, Beatriz</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  First-person stories can be analyzed by means of egocentric pictures acquired
throughout the whole active day with wearable cameras. This manuscript presents
an egocentric dataset with more than 45,000 pictures from four people in
different environments such as working or studying. All the images were
manually labeled to identify three patterns of interest regarding people's
lifestyle: socializing, eating and sedentary. Additionally, two different
approaches are proposed to classify egocentric images into one of the 12 target
categories defined to characterize these three patterns. The approaches are
based on machine learning and deep learning techniques, including traditional
classifiers and state-of-art convolutional neural networks. The experimental
results obtained when applying these methods to the egocentric dataset
demonstrated their adequacy for the problem at hand.
</dc:description>
 <dc:description>Comment: Accepted at First International Workshop on Social Signal Processing
  and Beyond, 19th International Conference on Image Analysis and Processing
  (ICIAP), September 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07863</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07866</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HornDroid: Practical and Sound Static Analysis of Android Applications
  by SMT Solving</dc:title>
 <dc:creator>Calzavara, Stefano</dc:creator>
 <dc:creator>Grishchenko, Ilya</dc:creator>
 <dc:creator>Maffei, Matteo</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We present HornDroid, a new tool for the static analysis of information flow
properties in Android applications. The core idea underlying HornDroid is to
use Horn clauses for soundly abstracting the semantics of Android applications
and to express security properties as a set of proof obligations that are
automatically discharged by an off-the-shelf SMT solver. This approach makes it
possible to fine-tune the analysis in order to achieve a high degree of
precision while still using off-the-shelf verification tools, thereby
leveraging the recent advances in this field. As a matter of fact, HornDroid
outperforms state-of-the-art Android static analysis tools on benchmarks
proposed by the community. Moreover, HornDroid is the first static analysis
tool for Android to come with a formal proof of soundness, which covers the
core of the analysis technique: besides yielding correctness assurances, this
proof allowed us to identify some critical corner-cases that affect the
soundness guarantees provided by some of the previous static analysis tools for
Android.
</dc:description>
 <dc:description>Comment: In Proceedings of 1st IEEE European Symposium on Security and Privacy
  (IEEE EuroS&amp;P 2016)</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07866</dc:identifier>
 <dc:identifier>doi:10.1109/EuroSP&amp;.P20.196.16</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07872</identifier>
 <datestamp>2017-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Executable Specification of Typing Rules for Extensible Records based
  on Row Polymorphism</dc:title>
 <dc:creator>Ahn, Ki Yung</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:description>  Type inference is an application domain that is a natural fit for logic
programming (LP). LP systems natively support unification, which serves as a
basic building block of typical type inference algorithms. In particular,
polymorphic type inference in the Hindley--Milner type system (HM) can be
succinctly specified and executed in Prolog. In our previous work, we have
demonstrated that more advanced features of parametric polymorphism beyond HM,
such as type-constructor polymorphism and kind polymorphism, can be similarly
specified in Prolog. Here, we demonstrate a specification for records, which is
one of the most widely supported compound data structures in real-world
programming languages, and discuss the advantages and limitations of Prolog as
a specification language for type systems. Record types are specified as
order-irrelevant collections of named fields mapped to their corresponding
types. In addition, an open-ended collection is used to support row
polymorphism for record types to be extensible.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07882</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prices of anarchy of selfish 2D bin packing games</dc:title>
 <dc:creator>Fernandes, Cristina G.</dc:creator>
 <dc:creator>Ferreira, Carlos E.</dc:creator>
 <dc:creator>Miyazawa, Fl&#xe1;vio K.</dc:creator>
 <dc:creator>Wakabayashi, Yoshiko</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>68Q25</dc:subject>
 <dc:description>  We consider a game-theoretical problem called selfish 2-dimensional bin
packing game, a generalization of the 1-dimensional case already treated in the
literature. In this game, the items to be packed are rectangles, and the bins
are unit squares. The game starts with a set of items arbitrarily packed in
bins. The cost of an item is defined as the ratio between its area and the
total occupied area of the respective bin. Each item is a selfish player that
wants to minimize its cost. A migration of an item to another bin is allowed
only when its cost is decreased. We show that this game always converges to a
Nash equilibrium (a stable packing where no single item can decrease its cost
by migrating to another bin). We show that the pure price of anarchy of this
game is unbounded, so we address the particular case where all items are
squares. We show that the pure price of anarchy of the selfish square packing
game is at least 2.3634 and at most 2.6875. We also present analogous results
for the strong Nash equilibrium (a stable packing where no nonempty set of
items can simultaneously migrate to another common bin and decrease the cost of
each item in the set). We show that the strong price of anarchy when all items
are squares is at least 2.0747 and at most 2.3605.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07887</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Not a Technology Person: Motivating Older Adults Toward the Use of
  Mobile Technology</dc:title>
 <dc:creator>Zu&#xf1;iga, Gabriela Villalobos</dc:creator>
 <dc:creator>Cherubini, Mauro</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:description>  Older users population is rapidly increasing all over the World. Presently,
we observe efforts in the human-computer interaction domain aiming to improve
life quality of age 65 and over through the use of mobile apps. Nonetheless,
these efforts focus primary on interface and interaction de- sign. Little work
has focused on the study of motivation to use and adherence to, of elderly to
technology. Developing specific design guidelines for this population is
relevant, however it should be parallel to the study of desire of elderly to
embrace specific technology in their life. Designers should not be limited to
technology design but consider as well how to fully convey the value that
technology can bring to the lives of the users and motivate adoption. This
position paper discusses techniques that might nudge elderly towards the use of
new technology.
</dc:description>
 <dc:description>Comment: Presented at the International Workshop Mobile Interface Design with
  Older Adults, part of CHI 2017, Denver, Colorado
  https://olderadultsmobileinterfaces.wordpress.com/chi-2017/</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07890</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatiotemporal Modeling for Crowd Counting in Videos</dc:title>
 <dc:creator>Xiong, Feng</dc:creator>
 <dc:creator>Shi, Xingjian</dc:creator>
 <dc:creator>Yeung, Dit-Yan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Region of Interest (ROI) crowd counting can be formulated as a regression
problem of learning a mapping from an image or a video frame to a crowd density
map. Recently, convolutional neural network (CNN) models have achieved
promising results for crowd counting. However, even when dealing with video
data, CNN-based methods still consider each video frame independently, ignoring
the strong temporal correlation between neighboring frames. To exploit the
otherwise very useful temporal information in video sequences, we propose a
variant of a recent deep learning model called convolutional LSTM (ConvLSTM)
for crowd counting. Unlike the previous CNN-based methods, our method fully
captures both spatial and temporal dependencies. Furthermore, we extend the
ConvLSTM model to a bidirectional ConvLSTM model which can access long-range
information in both directions. Extensive experiments using four publicly
available datasets demonstrate the reliability of our approach and the
effectiveness of incorporating temporal information to boost the accuracy of
crowd counting. In addition, we also conduct some transfer learning experiments
to show that once our model is trained on one dataset, its learning experience
can be transferred easily to a new dataset which consists of only very few
video frames for model adaptation.
</dc:description>
 <dc:description>Comment: Accepted by ICCV 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07890</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07899</identifier>
 <datestamp>2017-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Many-Objective Pareto Local Search</dc:title>
 <dc:creator>Jaszkiewicz, Andrzej</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We propose a new Pareto Local Search Algorithm for the many-objective
combinatorial optimization. Pareto Local Search proved to be a very effective
tool in the case of the bi-objective combinatorial optimization and it was used
in a number of the state-of-the-art algorithms for problems of this kind. On
the other hand, the standard Pareto Local Search algorithm becomes very
inefficient for problems with more than two objectives. We build an effective
Many-Objective Pareto Local Search algorithm using three new mechanisms: the
efficient update of large Pareto archives with ND-Tree data structure, a new
mechanism for the selection of the promising solutions for the neighborhood
exploration, and a partial exploration of the neighborhoods. We apply the
proposed algorithm to the instances of two different problems, i.e. the
traveling salesperson problem and the traveling salesperson problem with
profits with up to 5 objectives showing high effectiveness of the proposed
algorithm.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07899</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07901</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Partial Transfer Learning with Selective Adversarial Networks</dc:title>
 <dc:creator>Cao, Zhangjie</dc:creator>
 <dc:creator>Long, Mingsheng</dc:creator>
 <dc:creator>Wang, Jianmin</dc:creator>
 <dc:creator>Jordan, Michael I.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Adversarial learning has been successfully embedded into deep networks to
learn transferable features, which reduce distribution discrepancy between the
source and target domains. Existing domain adversarial networks assume fully
shared label space across domains. In the presence of big data, there is strong
motivation of transferring both classification and representation models from
existing big domains to unknown small domains. This paper introduces partial
transfer learning, which relaxes the shared label space assumption to that the
target label space is only a subspace of the source label space. Previous
methods typically match the whole source domain to the target domain, which are
prone to negative transfer for the partial transfer problem. We present
Selective Adversarial Network (SAN), which simultaneously circumvents negative
transfer by selecting out the outlier source classes and promotes positive
transfer by maximally matching the data distributions in the shared label
space. Experiments demonstrate that our models exceed state-of-the-art results
for partial transfer learning tasks on several benchmark datasets.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07901</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07906</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Quantum Theil Index: Characterizing Graph Centralization using von
  Neumann Entropy</dc:title>
 <dc:creator>Simmons, David</dc:creator>
 <dc:creator>Coon, Justin</dc:creator>
 <dc:creator>Datta, Animesh</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>34K30, 35K57, 35Q80, 92D25</dc:subject>
 <dc:description>  We show that the von Neumann entropy of a graph's trace normalized
combinatorial Laplacian provides structural information about the level of
centralization across a graph. This is done by considering the Theil index,
which is an established statistical measure used to determine levels of
inequality across a system of `agents', e.g., income levels across a
population. Here, we establish a Theil index for graphs, which provides us with
a macroscopic measure of graph centralization. Concretely, we show that the von
Neumann entropy can be used to bound the graph's Theil index, and thus we
provide a direct characterization of graph centralization via von Neumann
entropy. Because of the algebraic similarities between the bound and the Theil
index, we call the bound the quantum Theil index. We elucidate our ideas by
providing examples and a discussion of different $n=7$ vertex graphs.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07906</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07907</identifier>
 <datestamp>2017-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mutual Alignment Transfer Learning</dc:title>
 <dc:creator>Wulfmeier, Markus</dc:creator>
 <dc:creator>Posner, Ingmar</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Training robots for operation in the real world is a complex, time consuming
and potentially expensive task. Despite significant success of reinforcement
learning in games and simulations, research in real robot applications has not
been able to match similar progress. While sample complexity can be reduced by
training policies in simulation, such policies can perform sub-optimally on the
real platform given imperfect calibration of model dynamics. We present an
approach -- supplemental to fine tuning on the real robot -- to further benefit
from parallel access to a simulator during training and reduce sample
requirements on the real robot. The developed approach harnesses auxiliary
rewards to guide the exploration for the real world agent based on the
proficiency of the agent in simulation and vice versa. In this context, we
demonstrate empirically that the reciprocal alignment for both agents provides
further benefit as the agent in simulation can adjust to optimize its behaviour
for states commonly visited by the real-world agent.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-09-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07907</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07911</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Translation at Booking.com: Journey and Lessons Learned</dc:title>
 <dc:creator>Levin, Pavel</dc:creator>
 <dc:creator>Dhanuka, Nishikant</dc:creator>
 <dc:creator>Khalilov, Maxim</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We describe our recently developed neural machine translation (NMT) system
and benchmark it against our own statistical machine translation (SMT) system
as well as two other general purpose online engines (statistical and neural).
We present automatic and human evaluation results of the translation output
provided by each system. We also analyze the effect of sentence length on the
quality of output for SMT and NMT systems.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures, 2 tables. In proceedings of EAMT 2017. Prague,
  Czech Republic</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07913</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatio-temporal profiling of public transport delays based on large
  scale vehicle positioning data from GPS in Wroc{\l}aw</dc:title>
 <dc:creator>Szyma&#x144;ski, Piotr</dc:creator>
 <dc:creator>&#x17b;o&#x142;nieruk, Micha&#x142;</dc:creator>
 <dc:creator>Oleszczyk, Piotr</dc:creator>
 <dc:creator>Gisterek, Igor</dc:creator>
 <dc:creator>Kajdanowicz, Tomasz</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In recent years many studies of urban mobility based on large data sets have
been published: most of them based on crowdsourced GPS data or smart-card data.
We present, what is to our knowledge the first, exploration of public transport
delay data harvested from a large-scale, official public transport positioning
system, provided by the Wroc{\l}aw Municipality. We evaluate the
characteristics of delays between stops in relation to direction, time and
delay variance of 1648 stop pairs from 15 mln delay reports. We construct a
normalized feature matrix of likelihood of a given delay change happening at a
given hour on the edge between two stops. We then calculate distances between
such matrices using earth mover's distance and cluster them using hierarchical
agglomerative clustering with Ward's linkage method. We obtain four profiles of
delay changes in Wroc{\l}aw: edges without impact on delay, edges likely to
cause delay, edges likely to decrease delay and edges likely to strongly
decrease delay (ex. when a public transport vehicle is speeding). We analyze
the spatial and mode of transport properties of each cluster and provide
insights into reasons of delay change patterns in each of the detected
profiles.
</dc:description>
 <dc:description>Comment: accepted to KnowME2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07913</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07919</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mean Field Equilibria for Resource Competition in Spatial Settings</dc:title>
 <dc:creator>Yang, Pu</dc:creator>
 <dc:creator>Iyer, Krishnamurthy</dc:creator>
 <dc:creator>Frazier, Peter</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  We study a model of competition among nomadic agents for time-varying and
location-specific resources, arising in crowd-sourced transportation services,
online communities, and traditional location-based economic activity. This
model comprises a group of agents and a single location endowed with a dynamic
stochastic resource process. Periodically, each agent derives a reward
determined by the location's resource level and the number of other agents
there, and has to decide whether to stay at the location or move. Upon moving,
the agent arrives at a different location whose dynamics are independent and
identical to the original location. Using the methodology of mean field
equilibrium, we study the equilibrium behavior of the agents as a function of
the dynamics of the stochastic resource process and the nature of the
competition among co-located agents. We show that an equilibrium exists, where
each agent decides whether to switch locations based only on their current
location's resource level and the number of other agents there. We additionally
show that when an agent's payoff is decreasing in the number of other agents at
her location, equilibrium strategies obey a simple threshold structure. We show
how to exploit this structure to compute equilibria numerically, and use these
numerical techniques to study how system structure affects the agents'
collective ability to explore their domain to find and effectively utilize
resource-rich areas.
</dc:description>
 <dc:description>Comment: 20 pages(46 including appendices), 3 figures</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07922</identifier>
 <datestamp>2017-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Question Dependent Recurrent Entity Network for Question Answering</dc:title>
 <dc:creator>Madotto, Andrea</dc:creator>
 <dc:creator>Attardi, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Question Answering is a task which requires building models capable of
providing answers to questions expressed in human language. Full question
answering involves some form of reasoning ability. We introduce a neural
network architecture for this task, which is a form of $Memory\ Network$, that
recognizes entities and their relations to answers through a focus attention
mechanism. Our model is named $Question\ Dependent\ Recurrent\ Entity\ Network$
and extends $Recurrent\ Entity\ Network$ by exploiting aspects of the question
during the memorization process. We validate the model on both synthetic and
real datasets: the $bAbI$ question answering dataset and the $CNN\ \&amp;\ Daily\
News$ $reading\ comprehension$ dataset. In our experiments, the models achieved
a State-of-The-Art in the former and competitive results in the latter.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-10-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07923</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing Convolutional Neural Networks for Face Recognition with
  Occlusion Maps and Batch Triplet Loss</dc:title>
 <dc:creator>Trigueros, Daniel S&#xe1;ez</dc:creator>
 <dc:creator>Meng, Li</dc:creator>
 <dc:creator>Hartnett, Margaret</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Despite the recent success of convolutional neural networks for computer
vision applications, unconstrained face recognition remains a challenge. In
this work, we make two contributions to the field. Firstly, we consider the
problem of face recognition with partial occlusions and show how current
approaches might suffer significant performance degradation when dealing with
this kind of face images. We propose a simple method to find out which parts of
the human face are more important to achieve a high recognition rate, and use
that information during training to force a convolutional neural network to
learn discriminative features from all the face regions more equally, including
those that typical approaches tend to pay less attention to. We test the
accuracy of the proposed method when dealing with real-life occlusions using
the AR face database. Secondly, we propose a novel loss function called batch
triplet loss that improves the performance of the triplet loss by adding an
extra term to the loss function to cause minimisation of the standard deviation
of both positive and negative scores. We show consistent improvement in the
Labeled Faces in the Wild (LFW) benchmark by combining both proposed
adjustments to the convolutional neural network training.
</dc:description>
 <dc:description>Comment: 11 pages, 7 figures, 2 tables</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07923</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07930</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structural Regularities in Text-based Entity Vector Spaces</dc:title>
 <dc:creator>Van Gysel, Christophe</dc:creator>
 <dc:creator>de Rijke, Maarten</dc:creator>
 <dc:creator>Kanoulas, Evangelos</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Entity retrieval is the task of finding entities such as people or products
in response to a query, based solely on the textual documents they are
associated with. Recent semantic entity retrieval algorithms represent queries
and experts in finite-dimensional vector spaces, where both are constructed
from text sequences.
  We investigate entity vector spaces and the degree to which they capture
structural regularities. Such vector spaces are constructed in an unsupervised
manner without explicit information about structural aspects. For concreteness,
we address these questions for a specific type of entity: experts in the
context of expert finding. We discover how clusterings of experts correspond to
committees in organizations, the ability of expert representations to encode
the co-author graph, and the degree to which they encode academic rank. We
compare latent, continuous representations created using methods based on
distributional semantics (LSI), topic models (LDA) and neural networks
(word2vec, doc2vec, SERT). Vector spaces created using neural methods, such as
doc2vec and SERT, systematically perform better at clustering than LSI, LDA and
word2vec. When it comes to encoding entity relations, SERT performs best.
</dc:description>
 <dc:description>Comment: ICTIR2017. Proceedings of the 3rd ACM International Conference on the
  Theory of Information Retrieval. 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07930</dc:identifier>
 <dc:identifier>doi:10.1145/3121050.3121066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07932</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Functional connectivity patterns of autism spectrum disorder identified
  by deep feature learning</dc:title>
 <dc:creator>Choi, Hongyoon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Autism spectrum disorder (ASD) is regarded as a brain disease with globally
disrupted neuronal networks. Even though fMRI studies have revealed abnormal
functional connectivity in ASD, they have not reached a consensus of the
disrupted patterns. Here, a deep learning-based feature extraction method
identifies multivariate and nonlinear functional connectivity patterns of ASD.
Resting-state fMRI data of 972 subjects (465 ASD 507 normal controls) acquired
from the Autism Brain Imaging Data Exchange were used. A functional
connectivity matrix of each subject was generated using 90 predefined brain
regions. As a data-driven feature extraction method without prior knowledge
such as subjects diagnosis, variational autoencoder (VAE) summarized the
functional connectivity matrix into 2 features. Those feature values of ASD
patients were statistically compared with those of controls. A feature was
significantly different between ASD and normal controls. The extracted features
were visualized by VAE-based generator which can produce virtual functional
connectivity matrices. The ASD-related feature was associated with
frontoparietal connections, interconnections of the dorsal medial frontal
cortex and corticostriatal connections. It also showed a trend of negative
correlation with full-scale IQ. A data-driven feature extraction based on deep
learning could identify complex patterns of functional connectivity of ASD.
This approach will help discover complex patterns of abnormalities in brain
connectivity in various brain disorders.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07932</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07935</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A generic framework for adaptive EEG-based BCI training and operation</dc:title>
 <dc:creator>Mladenovi&#x107;, Jelena</dc:creator>
 <dc:creator>Mattout, J&#xe9;r&#xe9;mie</dc:creator>
 <dc:creator>Lotte, Fabien</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  There are numerous possibilities and motivations for an adaptive BCI, which
may not be easy to clarify and organize for a newcomer to the field. To our
knowledge, there has not been any work done in classifying the literature on
adaptive BCI in a comprehensive and structured way. We propose a conceptual
framework, a taxonomy of adaptive BCI methods which encompasses most important
approaches to fit them in such a way that a reader can clearly visualize which
elements are being adapted and for what reason. In the interest of having a
clear review of existing adaptive BCIs, this framework considers adaptation
approaches for both the user and the machine, i.e., using instructional design
observations as well as the usual machine learning techniques. This framework
not only provides a coherent review of such extensive literature but also
enables the reader to perceive gaps and flaws in the current BCI systems, which
would hopefully bring novel solutions for an overall improvement.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07935</dc:identifier>
 <dc:identifier>Chapter 33: ''A generic framework for adaptive EEG-based BCI
  training and operation'' , 1, CRC Press: Taylor \&amp; Francis Group, 2017,
  Brain-Computer Interfaces Handbook: Technological and Theoretical Advances</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07938</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Error Bounds for Piecewise Smooth and Switching Regression</dc:title>
 <dc:creator>Lauer, Fabien</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The paper deals with regression problems, in which the nonsmooth target is
assumed to switch between different operating modes. Specifically, piecewise
smooth (PWS) regression considers target functions switching deterministically
via a partition of the input space, while switching regression considers
arbitrary switching laws. The paper derives generalization error bounds in
these two settings by following the approach based on Rademacher complexities.
For PWS regression, our derivation involves a chaining argument and a
decomposition of the covering numbers of PWS classes in terms of the ones of
their component functions and the capacity of the classifier partitioning the
input space. This yields error bounds with a radical dependency on the number
of modes. For switching regression, the decomposition can be performed directly
at the level of the Rademacher complexities, which yields bounds with a linear
dependency on the number of modes. By using once more chaining and a
decomposition at the level of covering numbers, we show how to recover a
radical dependency, however at the cost of a slightly worse convergence rate.
Examples of applications are given in particular for PWS and swichting
regression with linear and kernel-based component functions.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice,after which this version may no
  longer be accessible</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07938</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07953</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms for Positive Semidefinite Factorization</dc:title>
 <dc:creator>Vandaele, Arnaud</dc:creator>
 <dc:creator>Glineur, Fran&#xe7;ois</dc:creator>
 <dc:creator>Gillis, Nicolas</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  This paper considers the problem of positive semidefinite factorization (PSD
factorization), a generalization of exact nonnegative matrix factorization.
Given an $m$-by-$n$ nonnegative matrix $X$ and an integer $k$, the PSD
factorization problem consists in finding, if possible, symmetric $k$-by-$k$
positive semidefinite matrices $\{A^1,...,A^m\}$ and $\{B^1,...,B^n\}$ such
that $X_{i,j}=\text{trace}(A^iB^j)$ for $i=1,...,m$, and $j=1,...n$. PSD
factorization is NP-hard. In this work, we introduce several local optimization
schemes to tackle this problem: a fast projected gradient method and two
algorithms based on the coordinate descent framework. The main application of
PSD factorization is the computation of semidefinite extensions, that is, the
representations of polyhedrons as projections of spectrahedra, for which the
matrix to be factorized is the slack matrix of the polyhedron. We compare the
performance of our algorithms on this class of problems. In particular, we
compute the PSD extensions of size $k=1+ \lceil \log_2(n) \rceil$ for the
regular $n$-gons when $n=5$, $8$ and $10$. We also show how to generalize our
algorithms to compute the square root rank (which is the size of the factors in
a PSD factorization where all factor matrices $A^i$ and $B^j$ have rank one)
and completely PSD factorizations (which is the special case where the input
matrix is symmetric and equality $A^i=B^i$ is required for all $i$).
</dc:description>
 <dc:description>Comment: 21 pages, 3 figures, 3 tables</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07953</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07958</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Residual Conv-Deconv Grid Network for Semantic Segmentation</dc:title>
 <dc:creator>Fourure, Damien</dc:creator>
 <dc:creator>Emonet, R&#xe9;mi</dc:creator>
 <dc:creator>Fromont, Elisa</dc:creator>
 <dc:creator>Muselet, Damien</dc:creator>
 <dc:creator>Tremeau, Alain</dc:creator>
 <dc:creator>Wolf, Christian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents GridNet, a new Convolutional Neural Network (CNN)
architecture for semantic image segmentation (full scene labelling). Classical
neural networks are implemented as one stream from the input to the output with
subsampling operators applied in the stream in order to reduce the feature maps
size and to increase the receptive field for the final prediction. However, for
semantic image segmentation, where the task consists in providing a semantic
class to each pixel of an image, feature maps reduction is harmful because it
leads to a resolution loss in the output prediction. To tackle this problem,
our GridNet follows a grid pattern allowing multiple interconnected streams to
work at different resolutions. We show that our network generalizes many well
known networks such as conv-deconv, residual or U-Net networks. GridNet is
trained from scratch and achieves competitive results on the Cityscapes
dataset.
</dc:description>
 <dc:description>Comment: Accepted for publication at BMVC 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07961</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time Series Compression Based on Adaptive Piecewise Recurrent
  Autoencoder</dc:title>
 <dc:creator>Hsu, Daniel</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Time series account for a large proportion of the data stored in financial,
medical and scientific databases. The efficient storage of time series is
important in practical applications. In this paper, we propose a novel
compression scheme for time series. The encoder and decoder are both composed
by recurrent neural networks (RNN) such as long short-term memory (LSTM). There
is an autoencoder between encoder and decoder, which encodes the hidden state
and input together and decodes them at the decoder side. Moreover, we
pre-process the original time series by partitioning it into segments with
various lengths which have similar total variation. The experimental study
shows that the proposed algorithm can achieve competitive compression ratio on
real-world time series.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1707.00666</dc:description>
 <dc:date>2017-07-23</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07961</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07966</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The switch operators and push-the-button games: a sequential compound
  over rulesets</dc:title>
 <dc:creator>Duchene, Eric</dc:creator>
 <dc:creator>Heinrich, Marc</dc:creator>
 <dc:creator>Larsson, Urban</dc:creator>
 <dc:creator>Parreau, Aline</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We study operators that combine combinatorial games. This field was initiated
by Sprague-Grundy (1930s), Milnor (1950s) and Berlekamp-Conway-Guy (1970-80s)
via the now classical disjunctive sum operator on (abstract) games. The new
class consists in operators for rulesets, dubbed the switch-operators. The
ordered pair of rulesets (R 1 , R 2) is compatible if, given any position in R
1 , there is a description of how to move in R 2. Given compatible (R 1 , R 2),
we build the push-the-button game R 1 R 2 , where players start by playing
according to the rules R 1 , but at some point during play, one of the players
must switch the rules to R 2 , by pushing the button &quot;. Thus, the game ends
according to the terminal condition of ruleset R 2. We study the pairwise
combinations of the classical rulesets Nim, Wythoff and Euclid. In addition, we
prove that standard periodicity results for Subtraction games transfer to this
setting, and we give partial results for a variation of Domineering, where R 1
is the game where the players put the domino tiles horizontally and R 2 the
game where they play vertically (thus generalizing the octal game 0.07).
</dc:description>
 <dc:description>Comment: Journal of Theoretical Computer Science (TCS), Elsevier, A
  Para{\^i}tre</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07966</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07976</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scaled Nuclear Norm Minimization for Low-Rank Tensor Completion</dc:title>
 <dc:creator>Ashraphijuo, Morteza</dc:creator>
 <dc:creator>Wang, Xiaodong</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Minimizing the nuclear norm of a matrix has been shown to be very efficient
in reconstructing a low-rank sampled matrix. Furthermore, minimizing the sum of
nuclear norms of matricizations of a tensor has been shown to be very efficient
in recovering a low-Tucker-rank sampled tensor. In this paper, we propose to
recover a low-TT-rank sampled tensor by minimizing a weighted sum of nuclear
norms of unfoldings of the tensor. We provide numerical results to show that
our proposed method requires significantly less number of samples to recover to
the original tensor in comparison with simply minimizing the sum of nuclear
norms since the structure of the unfoldings in the TT tensor model is
fundamentally different from that of matricizations in the Tucker tensor model.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07976</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07980</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning Based MIMO Communications</dc:title>
 <dc:creator>O'Shea, Timothy J.</dc:creator>
 <dc:creator>Erpek, Tugba</dc:creator>
 <dc:creator>Clancy, T. Charles</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We introduce a novel physical layer scheme for single user Multiple-Input
Multiple-Output (MIMO) communications based on unsupervised deep learning using
an autoencoder. This method extends prior work on the joint optimization of
physical layer representation and encoding and decoding processes as a single
end-to-end task by expanding transmitter and receivers to the multi-antenna
case. We introduce a widely used domain appropriate wireless channel impairment
model (Rayleigh fading channel), into the autoencoder optimization problem in
order to directly learn a system which optimizes for it. We considered both
spatial diversity and spatial multiplexing techniques in our implementation.
Our deep learning-based approach demonstrates significant potential for
learning schemes which approach and exceed the performance of the methods which
are widely used in existing wireless MIMO systems. We discuss how the proposed
scheme can be easily adapted for open-loop and closed-loop operation in spatial
diversity and multiplexing modes and extended use with only compact binary
channel state information (CSI) as feedback.
</dc:description>
 <dc:description>Comment: under journal submission</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07980</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07994</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>eSource for clinical trials: Implementation and evaluation of a
  standards-based approach in a real world trial</dc:title>
 <dc:creator>Ethier, Jean-Francois</dc:creator>
 <dc:creator>Curcin, Vasa</dc:creator>
 <dc:creator>McGilchrist, Mark M.</dc:creator>
 <dc:creator>Keung, Sarah N. Lim Choi</dc:creator>
 <dc:creator>Zhao, Lei</dc:creator>
 <dc:creator>Andreasson, Anna</dc:creator>
 <dc:creator>Br&#xf3;dka, Piotr</dc:creator>
 <dc:creator>Michalski, Radoslaw</dc:creator>
 <dc:creator>Arvanitis, Theodoros N.</dc:creator>
 <dc:creator>Mastellos, Nikolaos</dc:creator>
 <dc:creator>Burgun, Anita</dc:creator>
 <dc:creator>Delaney, Brendan C.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Objective: The Learning Health System (LHS) requires integration of research
into routine practice. eSource or embedding clinical trial functionalities into
routine electronic health record (EHR) systems has long been put forward as a
solution to the rising costs of research. We aimed to create and validate an
eSource solution that would be readily extensible as part of a LHS.
  Materials and Methods: The EU FP7 TRANSFoRm project's approach is based on
dual modelling, using the Clinical Research Information Model (CRIM) and the
Clinical Data Integration Model of meaning (CDIM) to bridge the gap between
clinical and research data structures, using the CDISC Operational Data Model
(ODM) standard. Validation against GCP requirements was conducted in a clinical
site, and a cluster randomised evaluation by site nested into a live clinical
trial.
  Results: Using the form definition element of ODM, we linked precisely
modelled data queries to data elements, constrained against CDIM concepts, to
enable automated patient identification for specific protocols and
prepopulation of electronic case report forms (e-CRF). Both control and eSource
sites recruited better than expected with no significant difference.
Completeness of clinical forms was significantly improved by eSource, but
Patient Related Outcome Measures (PROMs) were less well completed on
smartphones than paper in this population.
  Discussion: The TRANSFoRm approach provides an ontologically-based approach
to eSource in a low-resource, heterogeneous, highly distributed environment,
that allows precise prospective mapping of data elements in the EHR.
  Conclusion: Further studies using this approach to CDISC should optimise the
delivery of PROMS, whilst building a sustainable infrastructure for eSource
with research networks, trials units and EHR vendors.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07994</dc:identifier>
 <dc:identifier>International Journal of Medical Informatics Volume 106, October
  2017, Pages 17-24</dc:identifier>
 <dc:identifier>doi:10.1016/j.ijmedinf.2017.06.006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07998</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bottom-Up and Top-Down Attention for Image Captioning and Visual
  Question Answering</dc:title>
 <dc:creator>Anderson, Peter</dc:creator>
 <dc:creator>He, Xiaodong</dc:creator>
 <dc:creator>Buehler, Chris</dc:creator>
 <dc:creator>Teney, Damien</dc:creator>
 <dc:creator>Johnson, Mark</dc:creator>
 <dc:creator>Gould, Stephen</dc:creator>
 <dc:creator>Zhang, Lei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Top-down visual attention mechanisms have been used extensively in image
captioning and visual question answering (VQA) to enable deeper image
understanding through fine-grained analysis and even multiple steps of
reasoning. In this work, we propose a combined bottom-up and top-down attention
mechanism that enables attention to be calculated at the level of objects and
other salient image regions. This is the natural basis for attention to be
considered. Within our approach, the bottom-up mechanism (based on Faster
R-CNN) proposes image regions, each with an associated feature vector, while
the top-down mechanism determines feature weightings. Applying this approach to
image captioning, our results on the MSCOCO test server establish a new
state-of-the-art for the task, improving the best published result in terms of
CIDEr score from 114.7 to 117.9 and BLEU-4 from 35.2 to 36.9. Demonstrating the
broad applicability of the method, applying the same approach to VQA we obtain
first place in the 2017 VQA Challenge.
</dc:description>
 <dc:description>Comment: Winner of the Visual Question Answering Challenge at CVPR 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.07999</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evidence combination for a large number of sources</dc:title>
 <dc:creator>Zhou, Kuang</dc:creator>
 <dc:creator>Martin, Arnaud</dc:creator>
 <dc:creator>Pan, Quan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The theory of belief functions is an effective tool to deal with the multiple
uncertain information. In recent years, many evidence combination rules have
been proposed in this framework, such as the conjunctive rule, the cautious
rule, the PCR (Proportional Conflict Redistribution) rules and so on. These
rules can be adopted for different types of sources. However, most of these
rules are not applicable when the number of sources is large. This is due to
either the complexity or the existence of an absorbing element (such as the
total conflict mass function for the conjunctive-based rules when applied on
unreliable evidence). In this paper, based on the assumption that the majority
of sources are reliable, a combination rule for a large number of sources,
named LNS (stands for Large Number of Sources), is proposed on the basis of a
simple idea: the more common ideas one source shares with others, the
morereliable the source is. This rule is adaptable for aggregating a large
number of sources among which some are unreliable. It will keep the spirit of
the conjunctive rule to reinforce the belief on the focal elements with which
the sources are in agreement. The mass on the empty set will be kept as an
indicator of the conflict. Moreover, it can be used to elicit the major opinion
among the experts. The experimental results on synthetic mass functionsverify
that the rule can be effectively used to combine a large number of mass
functions and to elicit the major opinion.
</dc:description>
 <dc:description>Comment: 2017 20th International Conference on Information Fusion (FUSION),
  Jul 2017, Xi'an, China</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.07999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08000</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Un mod\`ele pour la repr\'esentation des connaissances temporelles dans
  les documents historiques</dc:title>
 <dc:creator>Aljalbout, Sahar</dc:creator>
 <dc:creator>Falquet, Gilles</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Processing and publishing the data of the historical sciences in the semantic
web is an interesting challenge in which the representation of temporal aspects
plays a key role. We propose in this paper a model of temporal knowledge
representation adapted to work on historical documents. This model is based on
the notion of fluent that is represented in RDF graphs. We show how this model
allows to represent the knowledge necessary to the historians and how it can be
used to reason on this knowledge using the SWRL and SPARQL languages. This
model is being used in a project to digitize, study and publish the manuscripts
of linguist Ferdinand de Saussure.
</dc:description>
 <dc:description>Comment: in French, IC\_2017 - 28\`emes Journ\'ees francophones d'Ing\'enierie
  des Connaissances, Jul 2017, Caen, France</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08000</dc:identifier>
 <dc:language>fr</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08002</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Policies for Cooperative Networked Systems</dc:title>
 <dc:creator>Iosifidis, George</dc:creator>
 <dc:creator>Tassiulas, Leandros</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  A set of economic entities embedded in a network graph collaborate by
opportunistically exchanging their resources to satisfy their dynamically
generated needs. Under what conditions their collaboration leads to a
sustainable economy? Which online policy can ensure a feasible resource
exchange point will be attained, and what information is needed to implement
it? Furthermore, assuming there are different resources and the entities have
diverse production capabilities, which production policy each entity should
employ in order to maximize the economy's sustainability? Importantly, can we
design such policies that are also incentive compatible even when there is no a
priori information about the entities' needs? We introduce a dynamic production
scheduling and resource exchange model to capture this fundamental problem and
provide answers to the above questions. Applications range from infrastructure
sharing, trade and organisation management, to social networks and sharing
economy services.
</dc:description>
 <dc:description>Comment: 6-page version appeared at ACM NetEcon' 17</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08005</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Evolutional Compression</dc:title>
 <dc:creator>Wang, Yunhe</dc:creator>
 <dc:creator>Xu, Chang</dc:creator>
 <dc:creator>Qiu, Jiayan</dc:creator>
 <dc:creator>Xu, Chao</dc:creator>
 <dc:creator>Tao, Dacheng</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Compressing convolutional neural networks (CNNs) is essential for
transferring the success of CNNs to a wide variety of applications to mobile
devices. In contrast to directly recognizing subtle weights or filters as
redundant in a given CNN, this paper presents an evolutionary method to
automatically eliminate redundant convolution filters. We represent each
compressed network as a binary individual of specific fitness. Then, the
population is upgraded at each evolutionary iteration using genetic operations.
As a result, an extremely compact CNN is generated using the fittest
individual. In this approach, either large or small convolution filters can be
redundant, and filters in the compressed network are more distinct. In
addition, since the number of filters in each convolutional layer is reduced,
the number of filter channels and the size of feature maps are also decreased,
naturally improving both the compression and speed-up ratios. Experiments on
benchmark deep CNN models suggest the superiority of the proposed algorithm
over the state-of-the-art compression methods.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08008</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boosted Zero-Shot Learning with Semantic Correlation Regularization</dc:title>
 <dc:creator>Pi, Te</dc:creator>
 <dc:creator>Li, Xi</dc:creator>
 <dc:creator>Zhongfei</dc:creator>
 <dc:creator>Zhang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study zero-shot learning (ZSL) as a transfer learning problem, and focus
on the two key aspects of ZSL, model effectiveness and model adaptation. For
effective modeling, we adopt the boosting strategy to learn a zero-shot
classifier from weak models to a strong model. For adaptable knowledge
transfer, we devise a Semantic Correlation Regularization (SCR) approach to
regularize the boosted model to be consistent with the inter-class semantic
correlations. With SCR embedded in the boosting objective, and with a
self-controlled sample selection for learning robustness, we propose a unified
framework, Boosted Zero-shot classification with Semantic Correlation
Regularization (BZ-SCR). By balancing the SCR-regularized boosted model
selection and the self-controlled sample selection, BZ-SCR is capable of
capturing both discriminative and adaptable feature-to-class semantic
alignments, while ensuring the reliability and adaptability of the learned
samples. The experiments on two ZSL datasets show the superiority of BZ-SCR
over the state-of-the-arts.
</dc:description>
 <dc:description>Comment: 7 pages; IJCAI 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08011</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Intelligence, New Interfaces, and the Art of the Soluble</dc:title>
 <dc:creator>Lyons, Michael J.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.1.2</dc:subject>
 <dc:subject>H.5.5</dc:subject>
 <dc:description>  Position: (1) Partial solutions to machine intelligence can lead to systems
which may be useful creating interesting and expressive musical works. (2) An
appropriate general goal for this field is augmenting human expression. (3) The
study of the aesthetics of human augmentation in musical performance is in its
infancy.
</dc:description>
 <dc:description>Comment: CHI 2015 Workshop on Collaborating with Intelligent Machines:
  Interfaces for Creative Sound, April 18, 2015, Seoul, Republic of Korea</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08011</dc:identifier>
 <dc:identifier>doi:10.6084/m9.figshare.5242045.v1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08015</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Exploitation of Disclosed Software Vulnerabilities Using
  Open-source Data</dc:title>
 <dc:creator>Bullough, Benjamin L.</dc:creator>
 <dc:creator>Yanchenko, Anna K.</dc:creator>
 <dc:creator>Smith, Christopher L.</dc:creator>
 <dc:creator>Zipkin, Joseph R.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Each year, thousands of software vulnerabilities are discovered and reported
to the public. Unpatched known vulnerabilities are a significant security risk.
It is imperative that software vendors quickly provide patches once
vulnerabilities are known and users quickly install those patches as soon as
they are available. However, most vulnerabilities are never actually exploited.
Since writing, testing, and installing software patches can involve
considerable resources, it would be desirable to prioritize the remediation of
vulnerabilities that are likely to be exploited. Several published research
studies have reported moderate success in applying machine learning techniques
to the task of predicting whether a vulnerability will be exploited. These
approaches typically use features derived from vulnerability databases (such as
the summary text describing the vulnerability) or social media posts that
mention the vulnerability by name. However, these prior studies share multiple
methodological shortcomings that inflate predictive power of these approaches.
We replicate key portions of the prior work, compare their approaches, and show
how selection of training and test data critically affect the estimated
performance of predictive models. The results of this study point to important
methodological considerations that should be taken into account so that results
reflect real-world utility.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08015</dc:identifier>
 <dc:identifier>In Proceedings of the 3rd ACM on International Workshop on
  Security And Privacy Analytics (IWSPA 2017). ACM, New York, NY, USA, 45-53</dc:identifier>
 <dc:identifier>doi:10.1145/3041008.3041009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08017</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Suszko's Problem: Mixed Consequence and Compositionality</dc:title>
 <dc:creator>Chemla, Emmanuel</dc:creator>
 <dc:creator>Egr&#xe9;, Paul</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03B47, 03B50, 03G27</dc:subject>
 <dc:description>  Suszko's problem is the problem of finding the minimal number of truth values
needed to semantically characterize a syntactic consequence relation. Suszko
proved that every Tarskian consequence relation can be characterized using only
two truth values. Malinowski showed that this number can equal three if some of
Tarski's structural constraints are relaxed. By so doing, Malinowski introduced
a case of so-called mixed consequence, allowing the notion of a designated
value to vary between the premises and the conclusions of an argument. In this
paper we give a more systematic perspective on Suszko's problem and on mixed
consequence. First, we prove general representation theorems relating
structural properties of a consequence relation to their semantic
interpretation, uncovering the semantic counterpart of substitution-invariance,
and establishing that mixed consequence is fundamentally the semantic
counterpart of the structural property of monotonicity. We use those to derive
maximum-rank results proved recently by French and Ripley in a different
setting for logics with various structural properties (reflexivity,
transitivity, none, or both). We strengthen these results into exact rank
results for non-permeable logics (roughly, those which distinguish the role of
premises and conclusions). We discuss the underlying notion of rank, and the
associated reduction proposed independently by Scott and Suszko. As
acknowledged by Suszko, that reduction fails to preserve compositionality in
general. We propose a modification of that notion of reduction, allowing us to
prove that over compact logics with what we call regular connectives, rank
results are maintained even if we request the preservation of
truth-compositionality and additional semantic properties.
</dc:description>
 <dc:description>Comment: Keywords: Suszko's problem; truth value; logical consequence; mixed
  consequence; compositionality; many-valued logic; algebraic logic;
  connectives</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08019</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Evaluation of Vision-based Head and Face Tracking Interfaces
  for Assistive Input</dc:title>
 <dc:creator>Morikawa, Chamin</dc:creator>
 <dc:creator>Lyons, Michael J.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.1.2</dc:subject>
 <dc:description>  Interaction methods based on computer-vision hold the potential to become the
next powerful technology to support breakthroughs in the field of
human-computer interaction. Non-invasive vision-based techniques permit
unconventional interaction methods to be considered, including use of movements
of the face and head for intentional gestural control of computer systems.
Facial gesture interfaces open new possibilities for assistive input
technologies. This chapter gives an overview of research aimed at developing
vision-based head and face-tracking interfaces. This work has important
implications for future assistive input devices. To illustrate this concretely
we describe work from our own research in which we developed two vision-based
facial feature tracking algorithms for human computer interaction and assistive
input. Evaluation forms a critical component of this research and we provide
examples of new quantitative evaluation tasks as well as the use of model
real-world applications for the qualitative evaluation of new interaction
styles.
</dc:description>
 <dc:description>Comment: Current manuscript is not satisfactory with all authors</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08019</dc:identifier>
 <dc:identifier>Chapter 7 of Assistive Technologies and Computer Access for Motor
  Disabilities (ed. G. Kouroupetroglou), IGI Global, 2013 pp. 180 - 205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08029</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Price and Profit Awareness in Recommender Systems</dc:title>
 <dc:creator>Jannach, Dietmar</dc:creator>
 <dc:creator>Adomavicius, Gediminas</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Academic research in the field of recommender systems mainly focuses on the
problem of maximizing the users' utility by trying to identify the most
relevant items for each user. However, such items are not necessarily the ones
that maximize the utility of the service provider (e.g., an online retailer) in
terms of the business value, such as profit. One approach to increasing the
providers' utility is to incorporate purchase-oriented information, e.g., the
price, sales probabilities, and the resulting profit, into the recommendation
algorithms. In this paper we specifically focus on price- and profit-aware
recommender systems. We provide a brief overview of the relevant literature and
use numerical simulations to illustrate the potential business benefit of such
approaches.
</dc:description>
 <dc:description>Comment: Presented at the 2017 Workshop on Value-Aware and Multi-Stakeholder
  Recommendation (VAMS) collocated with ACM RecSys 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08031</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Timing in Dynamic and Robust Attacker Engagement During Advanced
  Persistent Threats</dc:title>
 <dc:creator>Pawlick, Jeffrey</dc:creator>
 <dc:creator>Nguyen, Thi Thu Hang</dc:creator>
 <dc:creator>Colbert, Edward</dc:creator>
 <dc:creator>Zhu, Quanyan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Advanced persistent threats (APTs) are stealthy attacks which make use of
social engineering and deception to give adversaries insider access to
networked systems. Against APTs, active defense technologies aim to create and
exploit information asymmetry for defenders. In this paper, we study a scenario
in which a powerful defender uses honeynets for active defense in order to
observe an attacker who has penetrated the network. Rather than immediately
eject the attacker, the defender may elect to gather information. We introduce
an undiscounted, infinite-horizon Markov decision process on a continuous state
space in order to model the defender's problem. We find a threshold of
information that the defender should gather about the attacker before ejecting
him. Then we study the robustness of this policy using a Stackelberg game.
Finally, we simulate the policy for a conceptual network. Our results provide a
quantitative foundation for studying optimal timing for attacker engagement in
network defense.
</dc:description>
 <dc:description>Comment: Submitted to the 2018 American Control Conference</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08035</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantitative Models of Imperfect Deception in Network Security using
  Signaling Games with Evidence</dc:title>
 <dc:creator>Pawlick, Jeffrey</dc:creator>
 <dc:creator>Zhu, Quanyan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Deception plays a critical role in many interactions in communication and
network security. Game-theoretic models called &quot;cheap talk signaling games&quot;
capture the dynamic and information asymmetric nature of deceptive
interactions. But signaling games inherently model undetectable deception. In
this paper, we investigate a model of signaling games in which the receiver can
detect deception with some probability. This model nests traditional signaling
games and complete information Stackelberg games as special cases. We present
the pure strategy perfect Bayesian Nash equilibria of the game. Then we
illustrate these analytical results with an application to active network
defense. The presence of evidence forces majority-truthful behavior and
eliminates some pure strategy equilibria. It always benefits the deceived
player, but surprisingly sometimes also benefits the deceiving player.
</dc:description>
 <dc:description>Comment: IEEE Communications and Network Security (IEEE CNS) 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-10-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08037</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Liver Segmentation Using an Adversarial Image-to-Image Network</dc:title>
 <dc:creator>Yang, Dong</dc:creator>
 <dc:creator>Xu, Daguang</dc:creator>
 <dc:creator>Zhou, S. Kevin</dc:creator>
 <dc:creator>Georgescu, Bogdan</dc:creator>
 <dc:creator>Chen, Mingqing</dc:creator>
 <dc:creator>Grbic, Sasa</dc:creator>
 <dc:creator>Metaxas, Dimitris</dc:creator>
 <dc:creator>Comaniciu, Dorin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatic liver segmentation in 3D medical images is essential in many
clinical applications, such as pathological diagnosis of hepatic diseases,
surgical planning, and postoperative assessment. However, it is still a very
challenging task due to the complex background, fuzzy boundary, and various
appearance of liver. In this paper, we propose an automatic and efficient
algorithm to segment liver from 3D CT volumes. A deep image-to-image network
(DI2IN) is first deployed to generate the liver segmentation, employing a
convolutional encoder-decoder architecture combined with multi-level feature
concatenation and deep supervision. Then an adversarial network is utilized
during training process to discriminate the output of DI2IN from ground truth,
which further boosts the performance of DI2IN. The proposed method is trained
on an annotated dataset of 1000 CT volumes with various different scanning
protocols (e.g., contrast and non-contrast, various resolution and position)
and large variations in populations (e.g., ages and pathology). Our approach
outperforms the state-of-the-art solutions in terms of segmentation accuracy
and computing efficiency.
</dc:description>
 <dc:description>Comment: Accepted by MICCAI 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08039</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scheduling to Minimize Total Weighted Completion Time via Time-Indexed
  Linear Programming Relaxations</dc:title>
 <dc:creator>Li, Shi</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study approximation algorithms for scheduling problems with the objective
of minimizing total weighted completion time, under identical and related
machine models with job precedence constraints. We give algorithms that improve
upon many previous 15 to 20-year-old state-of-art results. A major theme in
these results is the use of time-indexed linear programming relaxations. These
are natural relaxations for their respective problems, but surprisingly are not
studied in the literature.
  We also consider the scheduling problem of minimizing total weighted
completion time on unrelated machines. The recent breakthrough result of
[Bansal-Srinivasan-Svensson, STOC 2016] gave a $(1.5-c)$-approximation for the
problem, based on some lift-and-project SDP relaxation. Our main result is that
a $(1.5 - c)$-approximation can also be achieved using a natural and
considerably simpler time-indexed LP relaxation for the problem. We hope this
relaxation can provide new insights into the problem.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08040</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple Exponential Family Framework for Zero-Shot Learning</dc:title>
 <dc:creator>Verma, Vinay Kumar</dc:creator>
 <dc:creator>Rai, Piyush</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a simple generative framework for learning to predict previously
unseen classes, based on estimating class-attribute-gated class-conditional
distributions. We model each class-conditional distribution as an exponential
family distribution and the parameters of the distribution of each seen/unseen
class are defined as functions of the respective observed class attributes.
These functions can be learned using only the seen class data and can be used
to predict the parameters of the class-conditional distribution of each unseen
class. Unlike most existing methods for zero-shot learning that represent
classes as fixed embeddings in some vector space, our generative model
naturally represents each class as a probability distribution. It is simple to
implement and also allows leveraging additional unlabeled data from unseen
classes to improve the estimates of their class-conditional distributions using
transductive/semi-supervised learning. Moreover, it extends seamlessly to
few-shot learning by easily updating these distributions when provided with a
small number of additional labelled examples from unseen classes. Through a
comprehensive set of experiments on several benchmark data sets, we demonstrate
the efficacy of our framework.
</dc:description>
 <dc:description>Comment: Accepted in ECML-PKDD 2017, 16 Pages: Code and Data are available:
  https://github.com/vkverma01/Zero-Shot/</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08041</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthesising Sign Language from semantics, approaching &quot;from the target
  and back&quot;</dc:title>
 <dc:creator>Filhol, Michael</dc:creator>
 <dc:creator>Falquet, Gilles</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a Sign Language modelling approach allowing to build grammars and
create linguistic input for Sign synthesis through avatars. We comment on the
type of grammar it allows to build, and observe a resemblance between the
resulting expressions and traditional semantic representations. Comparing the
ways in which the paradigms are designed, we name and contrast two essentially
different strategies for building higher-level linguistic input:
&quot;source-and-forward&quot; vs. &quot;target-and-back&quot;. We conclude by favouring the
latter, acknowledging the power of being able to automatically generate output
from semantically relevant input straight into articulations of the target
language.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08050</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Video Streaming in Heterogeneous Small Cell Networks with
  Untrusted Cache Helpers</dc:title>
 <dc:creator>Xiang, Lin</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:creator>Wong, Vincent W. S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies secure video streaming in cache-enabled small cell
networks, where some of the cache-enabled small cell base stations (BSs)
helping in video delivery are untrusted. Unfavorably, caching improves the
eavesdropping capability of these untrusted helpers as they may intercept both
the cached and the delivered video files. To address this issue, we propose
joint caching and scalable video coding (SVC) of video files to enable secure
cooperative multiple-input multiple-output (MIMO) transmission and, at the same
time, exploit the cache memory of both the trusted and untrusted BSs for
improving the system performance. Considering imperfect channel state
information (CSI) at the transmitters, we formulate a two-timescale non-convex
mixed-integer robust optimization problem to minimize the total transmit power
required for guaranteeing the quality of service (QoS) and secrecy during video
streaming. We develop an iterative algorithm based on a modified generalized
Benders decomposition (GBD) to solve the problem optimally, where the caching
and the cooperative transmission policies are determined via offline
(long-timescale) and online (short-timescale) optimization, respectively.
Furthermore, inspired by the optimal algorithm, a low-complexity suboptimal
algorithm based on a greedy heuristic is proposed. Simulation results show that
the proposed schemes achieve significant gains in power efficiency and secrecy
performance compared to several baseline schemes.
</dc:description>
 <dc:description>Comment: Revision submitted to IEEE Trans. Wireless Commun., 32 pages</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08052</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Challenges in Data-to-Document Generation</dc:title>
 <dc:creator>Wiseman, Sam</dc:creator>
 <dc:creator>Shieber, Stuart M.</dc:creator>
 <dc:creator>Rush, Alexander M.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recent neural models have shown significant progress on the problem of
generating short descriptive texts conditioned on a small number of database
records. In this work, we suggest a slightly more difficult data-to-text
generation task, and investigate how effective current approaches are on this
task. In particular, we introduce a new, large-scale corpus of data records
paired with descriptive documents, propose a series of extractive evaluation
methods for analyzing performance, and obtain baseline results using current
neural generation methods. Experiments show that these models produce fluent
text, but fail to convincingly approximate human-generated documents. Moreover,
even templated baselines exceed the performance of these neural models on some
metrics, though copy- and reconstruction-based extensions lead to noticeable
improvements.
</dc:description>
 <dc:description>Comment: EMNLP 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08055</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Exponential Rate of Convergence of Fictitious Play in Potential
  Games</dc:title>
 <dc:creator>Swenson, Brian</dc:creator>
 <dc:creator>Kar, Soummya</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The paper studies fictitious play (FP) learning dynamics in continuous time.
It is shown that in almost every potential game, and for almost every initial
condition, the rate of convergence of FP is exponential. In particular, the
paper focuses on studying the behavior of FP in potential games in which all
equilibria of the game are regular, as introduced by Harsanyi. Such games are
referred to as regular potential games. Recently it has been shown that almost
all potential games (in the sense of the Lebesgue measure) are regular. In this
paper it is shown that in any regular potential game (and hence, in almost
every potential game), FP converges to the set of Nash equilibria at an
exponential rate from almost every initial condition.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08061</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MVP2P: Layer-Dependency-Aware Live MVC Video Streaming over Peer-to-Peer
  Networks</dc:title>
 <dc:creator>Liu, Zhao</dc:creator>
 <dc:creator>Murray, Niall</dc:creator>
 <dc:creator>Lee, Brian</dc:creator>
 <dc:creator>Fallon, Enda</dc:creator>
 <dc:creator>Qiao, Yuansong</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Multiview video supports observing a scene from different viewpoints. The
Joint Video Team (JVT) developed H.264/MVC to enhance the compression
efficiency for multiview video, however, MVC encoded multiview video (MVC
video) still requires the high bitrates for transmission. This paper
investigates live MVC video streaming over Peer-to-Peer (P2P) networks. The
goal is to minimize the server bandwidth costs whist ensuring high streaming
quality to peers. MVC employs intra-view and inter-view prediction structures,
which leads to a complicated layer dependency relationship. As the peers'
outbound bandwidth is shared while supplying all the MVC video layers, the
bandwidth allocation to one MVC layer affects the available outbound bandwidth
of the other layers. To optimise the utilisation of the peers' outbound
bandwidth for providing video layers, a maximum flow based model is proposed
which considers the MVC video layer dependency and the layer supplying
relationship between peers. Based on the model, a layer dependency aware live
MVC video streaming method over a BitTorrent-like P2P network is proposed,
named MVP2P. The key components of MVP2P include a chunk scheduling strategy
and a peer selection strategy for receiving peers, and a bandwidth scheduling
algorithm for supplying peers. To evaluate the efficiency of the proposed
solution, MVP2P is compared with existing methods considering the constraints
of peer bandwidth, peer numbers, view switching rates, and peer churns. The
test results show that MVP2P significantly outperforms the existing methods.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08063</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relative Depth Order Estimation Using Multi-scale Densely Connected
  Convolutional Networks</dc:title>
 <dc:creator>Deng, Ruoxi</dc:creator>
 <dc:creator>Zhao, Tianqi</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Liu, Shengjun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We study the problem of estimating the relative depth order of point pairs in
a monocular image. Recent advances mainly focus on using deep convolutional
neural networks (DCNNs) to learn and infer the ordinal information from
multiple contextual information of the points pair such as global scene
context, local contextual information, and the locations. However, it remains
unclear how much each context contributes to the task. To address this, we
first examine the contribution of each context cue [1], [2] to the performance
in the context of depth order estimation. We find out the local context
surrounding the points pair contributes the most and the global scene context
helps little. Based on the findings, we propose a simple method, using a
multi-scale densely-connected network to tackle the task. Instead of learning
the global structure, we dedicate to explore the local structure by learning to
regress from regions of multiple sizes around the point pairs. Moreover, we use
the recent densely connected network [3] to encourage substantial feature reuse
as well as deepen our network to boost the performance. We show in experiments
that the results of our approach is on par with or better than the
state-of-the-art methods with the benefit of using only a small number of
training data.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08073</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Gamified Approach to Improve Users' Memorability of Fall-back
  Authentication</dc:title>
 <dc:creator>Micallef, Nicholas</dc:creator>
 <dc:creator>Arachchilage, Nalin Asanka Gamagedara</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Security questions are one of the techniques used in fall-back authentication
to retrieve forgotten passwords. This paper proposes a game design which aims
to improve usability of system-generated security questions. In our game
design, we adapted the popular picture-based &quot;4 Pics 1 word&quot; mobile game. This
game asks users to pick the word that relates the given pictures. We selected
this game because of its use of pictures and cues, in which, psychology
research has found to be important to help with memorability. The proposed game
design focuses on encoding information to users' long- term memory and to aide
memorability by using the follow- ing memory retrieval skills: (a) graphical
cues - by using images in each challenge; (b) verbal cues - by using verbal
descriptions as hints; (c) spatial cues - by keeping same or- der of pictures;
(d) interactivity - engaging nature of the game through the use of persuasive
technology principles.
</dc:description>
 <dc:description>Comment: 6</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08073</dc:identifier>
 <dc:identifier>Symposium on Usable Privacy and Security SOUPS 2017, July, 2017,
  Santa Clara, California</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08074</identifier>
 <datestamp>2017-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Sensing and Data Estimation in a Large Sensor Network</dc:title>
 <dc:creator>Chattopadhyay, Arpan</dc:creator>
 <dc:creator>Mitra, Urbashi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  An energy efficient use of large scale sensor networks necessitates
activating a subset of possible sensors for estimation at a fusion center. The
problem is inherently combinatorial; to this end, a set of iterative,
randomized algorithms are developed for sensor subset selection by exploiting
the underlying statistics. Gibbs sampling-based methods are designed to
optimize the estimation error and the mean number of activated sensors. The
optimality of the proposed strategy is proven, along with guarantees on their
convergence speeds. Also, another new algorithm exploiting stochastic
approximation in conjunction with Gibbs sampling is derived for a constrained
version of the sensor selection problem. The methodology is extended to the
scenario where the fusion center has access to only a parametric form of the
joint statistics, but not the true underlying distribution. Therein,
expectation-maximization is effectively employed to learn the distribution.
Strategies for iid time-varying data are also outlined. Numerical results show
that the proposed methods converge very fast to the respective optimal
solutions, and therefore can be employed for optimal sensor subset selection in
practical sensor networks.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-07-23</dc:date>
 <dc:date>2017-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08081</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Word Relatedness over Time</dc:title>
 <dc:creator>Rosin, Guy D.</dc:creator>
 <dc:creator>Adar, Eytan</dc:creator>
 <dc:creator>Radinsky, Kira</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Search systems are often focused on providing relevant results for the &quot;now&quot;,
assuming both corpora and user needs that focus on the present. However, many
corpora today reflect significant longitudinal collections ranging from 20
years of the Web to hundreds of years of digitized newspapers and books.
Understanding the temporal intent of the user and retrieving the most relevant
historical content has become a significant challenge. Common search features,
such as query expansion, leverage the relationship between terms but cannot
function well across all times when relationships vary temporally. In this
work, we introduce a temporal relationship model that is extracted from
longitudinal data collections. The model supports the task of identifying,
given two words, when they relate to each other. We present an algorithmic
framework for this task and show its application for the task of query
expansion, achieving high gain.
</dc:description>
 <dc:description>Comment: 11 pages, EMNLP 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08084</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ShotgunWSD: An unsupervised algorithm for global word sense
  disambiguation inspired by DNA sequencing</dc:title>
 <dc:creator>Butnaru, Andrei M.</dc:creator>
 <dc:creator>Ionescu, Radu Tudor</dc:creator>
 <dc:creator>Hristea, Florentina</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we present a novel unsupervised algorithm for word sense
disambiguation (WSD) at the document level. Our algorithm is inspired by a
widely-used approach in the field of genetics for whole genome sequencing,
known as the Shotgun sequencing technique. The proposed WSD algorithm is based
on three main steps. First, a brute-force WSD algorithm is applied to short
context windows (up to 10 words) selected from the document in order to
generate a short list of likely sense configurations for each window. In the
second step, these local sense configurations are assembled into longer
composite configurations based on suffix and prefix matching. The resulted
configurations are ranked by their length, and the sense of each word is chosen
based on a voting scheme that considers only the top k configurations in which
the word appears. We compare our algorithm with other state-of-the-art
unsupervised WSD algorithms and demonstrate better performance, sometimes by a
very large margin. We also show that our algorithm can yield better performance
than the Most Common Sense (MCS) baseline on one data set. Moreover, our
algorithm has a very small number of parameters, is robust to parameter tuning,
and, unlike other bio-inspired methods, it gives a deterministic solution (it
does not involve random choices).
</dc:description>
 <dc:description>Comment: In Proceedings of EACL 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08086</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resource-Efficient Common Randomness and Secret-Key Schemes</dc:title>
 <dc:creator>Ghazi, Badih</dc:creator>
 <dc:creator>Jayram, T. S.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study common randomness where two parties have access to i.i.d. samples
from a known random source, and wish to generate a shared random key using
limited (or no) communication with the largest possible probability of
agreement. This problem is at the core of secret key generation in
cryptography, with connections to communication under uncertainty and locality
sensitive hashing. We take the approach of treating correlated sources as a
critical resource, and ask whether common randomness can be generated
resource-efficiently.
  We consider two notable sources in this setup arising from correlated bits
and correlated Gaussians. We design the first explicit schemes that use only a
polynomial number of samples (in the key length) so that the players can
generate shared keys that agree with constant probability using optimal
communication. The best previously known schemes were both non-constructive and
used an exponential number of samples. In the amortized setting, we
characterize the largest achievable ratio of key length to communication in
terms of the external and internal information costs, two well-studied
quantities in theoretical computer science. In the relaxed setting where the
two parties merely wish to improve the correlation between the generated keys
of length $k$, we show that there are no interactive protocols using $o(k)$
bits of communication having agreement probability even as small as
$2^{-o(k)}$. For the related communication problem where the players wish to
compute a joint function $f$ of their inputs using i.i.d. samples from a known
source, we give a zero-communication protocol using $2^{O(c)}$ bits where $c$
is the interactive randomized public-coin communication complexity of $f$. This
matches the lower bound shown previously while the best previously known upper
bound was doubly exponential in $c$.
</dc:description>
 <dc:description>Comment: 37 pages</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08089</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Delay Performance of MISO Wireless Communications</dc:title>
 <dc:creator>Arnau, Jesus</dc:creator>
 <dc:creator>Kountouris, Marios</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Ultra-reliable, low latency communications (URLLC) are currently attracting
significant attention due to the emergence of mission-critical applications and
device-centric communication. URLLC will entail a fundamental paradigm shift
from throughput-oriented system design towards holistic designs for guaranteed
and reliable end-to-end latency. A deep understanding of the delay performance
of wireless networks is essential for efficient URLLC systems. In this paper,
we investigate the network layer performance of multiple-input, single-output
(MISO) systems under statistical delay constraints. We provide closed-form
expressions for MISO diversity-oriented service process and derive
probabilistic delay bounds using tools from stochastic network calculus. In
particular, we analyze transmit beamforming with perfect and imperfect channel
knowledge and compare it with orthogonal space-time codes and antenna
selection. The effect of transmit power, number of antennas, and finite
blocklength channel coding on the delay distribution is also investigated. Our
higher layer performance results reveal key insights of MISO channels and
provide useful guidelines for the design of ultra-reliable communication
systems that can guarantee the stringent URLLC latency requirements.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08092</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressed Sparse Linear Regression</dc:title>
 <dc:creator>Kasiviswanathan, Shiva Prasad</dc:creator>
 <dc:creator>Rudelson, Mark</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  High-dimensional sparse linear regression is a basic problem in machine
learning and statistics. Consider a linear model $y = X\theta^\star + w$, where
$y \in \mathbb{R}^n$ is the vector of observations, $X \in \mathbb{R}^{n \times
d}$ is the covariate matrix and $w \in \mathbb{R}^n$ is an unknown noise
vector. In many applications, the linear regression model is high-dimensional
in nature, meaning that the number of observations $n$ may be substantially
smaller than the number of covariates $d$. In these cases, it is common to
assume that $\theta^\star$ is sparse, and the goal in sparse linear regression
is to estimate this sparse $\theta^\star$, given $(X,y)$.
  In this paper, we study a variant of the traditional sparse linear regression
problem where each of the $n$ covariate vectors in $\mathbb{R}^d$ are
individually projected by a random linear transformation to $\mathbb{R}^m$ with
$m \ll d$. Such transformations are commonly applied in practice for
computational savings in resources such as storage space, transmission
bandwidth, and processing time. Our main result shows that one can estimate
$\theta^\star$ with a low $\ell_2$-error, even with access to only these
projected covariate vectors, under some mild assumptions on the problem
instance. Our approach is based on solving a variant of the popular Lasso
optimization problem. While the conditions (such as the restricted eigenvalue
condition on $X$) for success of a Lasso formulation in estimating
$\theta^\star$ are well-understood, we investigate conditions under which this
variant of Lasso estimates $\theta^\star$.
  As a simple consequence, our approach also provides a new way for estimating
$\theta^\star$ in the traditional sparse linear regression problem setting,
which operates (even) under a weaker assumption on the design matrix than
previously known, albeit achieving a weaker convergence bound.
</dc:description>
 <dc:description>Comment: 23 pages, Updated paper with stronger results</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08095</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Line-Circle: A Geometric Filter for Single Camera Edge-Based Object
  Detection</dc:title>
 <dc:creator>Tafrishi, Seyed Amir</dc:creator>
 <dc:creator>Kandjani, Vahid E.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a state-of-the-art approach in object detection for being
applied in future SLAM problems. Although, many SLAM methods are proposed to
create suitable autonomy for mobile robots namely ground vehicles, they still
face overconfidence and large computations during entrance to immense spaces
with many landmarks. In particular, they suffer from impractical applications
via sole reliance on the limited sensors like camera. Proposed method claims
that unmanned ground vehicles without having huge amount of database for object
definition and highly advance prediction parameters can deal with incoming
objects during straight motion of camera in real-time. Line-Circle (LC) filter
tries to apply detection, tracking and learning to each defined experts to
obtain more information for judging scene without over-calculation. In this
filter, circle expert let us summarize edges in groups. The Interactive
feedback learning between each expert creates minimal error that fights against
overwhelming landmark signs in crowded scenes without mapping. Our experts
basically are dependent on trust factors' covariance with geometric definitions
to ignore, emerge and compare detected landmarks. The experiment for validating
the model is taken place utilizing a camera beside an IMU sensor for location
estimation.
</dc:description>
 <dc:description>Comment: Submitted to 5th International Conference on Robotics and
  Mechatronics 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08098</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Image to Text Classification: A Novel Approach based on Clustering
  Word Embeddings</dc:title>
 <dc:creator>Butnaru, Andrei M.</dc:creator>
 <dc:creator>Ionescu, Radu Tudor</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we propose a novel approach for text classification based on
clustering word embeddings, inspired by the bag of visual words model, which is
widely used in computer vision. After each word in a collection of documents is
represented as word vector using a pre-trained word embeddings model, a k-means
algorithm is applied on the word vectors in order to obtain a fixed-size set of
clusters. The centroid of each cluster is interpreted as a super word embedding
that embodies all the semantically related word vectors in a certain region of
the embedding space. Every embedded word in the collection of documents is then
assigned to the nearest cluster centroid. In the end, each document is
represented as a bag of super word embeddings by computing the frequency of
each super word embedding in the respective document. We also diverge from the
idea of building a single vocabulary for the entire collection of documents,
and propose to build class-specific vocabularies for better performance. Using
this kind of representation, we report results on two text mining tasks, namely
text categorization by topic and polarity classification. On both tasks, our
model yields better performance than the standard bag of words.
</dc:description>
 <dc:description>Comment: Accepted at KES 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08098</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08101</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Singulate Objects using a Push Proposal Network</dc:title>
 <dc:creator>Eitel, Andreas</dc:creator>
 <dc:creator>Hauff, Nico</dc:creator>
 <dc:creator>Burgard, Wolfram</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  A key challenge for manipulation in unstructured environments is action
selection. We present a novel neural network-based approach that separates
unknown objects in clutter by selecting favourable push actions. Our network is
trained from data collected through large-scale interaction of a PR2 robot with
randomly organized tabletop scenes. The model is designed to propose meaningful
push actions based on segmented RGB-D images. We evaluate our approach by
singulating up to six unknown objects in clutter. We demonstrate that our
method enables the robot to perform the task with a high success rate and a low
number of required push actions. Our results based on real-world experiments
show that our network is able to generalize to novel objects of various sizes
and shapes, as well as to arbitrary object configurations. Highlights of our
experiments can be viewed in the following video: https://youtu.be/jWbUJOrSacI .
</dc:description>
 <dc:description>Comment: 13 pages, 7 figures, ISRR 2017 submission, video:
  https://youtu.be/jWbUJOrSacI</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08105</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Bag-of-Features Pooling for Deep Convolutional Neural Networks</dc:title>
 <dc:creator>Passalis, Nikolaos</dc:creator>
 <dc:creator>Tefas, Anastasios</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional Neural Networks (CNNs) are well established models capable of
achieving state-of-the-art classification accuracy for various computer vision
tasks. However, they are becoming increasingly larger, using millions of
parameters, while they are restricted to handling images of fixed size. In this
paper, a quantization-based approach, inspired from the well-known
Bag-of-Features model, is proposed to overcome these limitations. The proposed
approach, called Convolutional BoF (CBoF), uses RBF neurons to quantize the
information extracted from the convolutional layers and it is able to natively
classify images of various sizes as well as to significantly reduce the number
of parameters in the network. In contrast to other global pooling operators and
CNN compression techniques the proposed method utilizes a trainable pooling
layer that it is end-to-end differentiable, allowing the network to be trained
using regular back-propagation and to achieve greater distribution shift
invariance than competitive methods. The ability of the proposed method to
reduce the parameters of the network and increase the classification accuracy
over other state-of-the-art techniques is demonstrated using three image
datasets.
</dc:description>
 <dc:description>Comment: Accepted at ICCV 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08109</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aspects of Chaitin's Omega</dc:title>
 <dc:creator>Barmpalias, George</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The halting probability of a Turing machine,also known as Chaitin's Omega, is
an algorithmically random number with many interesting properties. Since
Chaitin's seminal work, many popular expositions have appeared, mainly focusing
on the metamathematical or philosophical significance of Omega (or debating
against it). At the same time, a rich mathematical theory exploring the
properties of Chaitin's Omega has been brewing in various technical papers,
which quietly reveals the significance of this number to many aspects of
contemporary algorithmic information theory. The purpose of this survey is to
expose these developments and tell a story about Omega, which outlines its
multifaceted mathematical properties and roles in algorithmic randomness.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08110</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Forecast: Deep Learning-based Spatio-Temporal Forecasting</dc:title>
 <dc:creator>Ghaderi, Amir</dc:creator>
 <dc:creator>Sanandaji, Borhan M.</dc:creator>
 <dc:creator>Ghaderi, Faezeh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The paper presents a spatio-temporal wind speed forecasting algorithm using
Deep Learning (DL)and in particular, Recurrent Neural Networks(RNNs). Motivated
by recent advances in renewable energy integration and smart grids, we apply
our proposed algorithm for wind speed forecasting. Renewable energy resources
(wind and solar)are random in nature and, thus, their integration is
facilitated with accurate short-term forecasts. In our proposed framework, we
model the spatiotemporal information by a graph whose nodes are data generating
entities and its edges basically model how these nodes are interacting with
each other. One of the main contributions of our work is the fact that we
obtain forecasts of all nodes of the graph at the same time based on one
framework. Results of a case study on recorded time series data from a
collection of wind mills in the north-east of the U.S. show that the proposed
DL-based forecasting algorithm significantly improves the short-term forecasts
compared to a set of widely-used benchmarks models.
</dc:description>
 <dc:description>Comment: Accepted to the ICML 2017, Time Series Workshop. arXiv admin note:
  text overlap with arXiv:1503.01210</dc:description>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08110</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08113</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recommending Complementary Products in E-Commerce Push Notifications
  with a Mixture Model Approach</dc:title>
 <dc:creator>Zhao, Huasha</dc:creator>
 <dc:creator>Si, Luo</dc:creator>
 <dc:creator>Li, Xiaogang</dc:creator>
 <dc:creator>Zhang, Qiong</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Push notification is a key component for E-commerce mobile applications,
which has been extensively used for user growth and engagement. The
effectiveness of the push notification is generally measured by message open
rate. A push message can contain a recommended product, a shopping news and
etc., but often only one or two items can be shown in the push message due to
the limit of display space. This paper proposes a mixture model approach for
predicting push message open rate for a post-purchase complementary product
recommendation task. The mixture model is trained to learn latent prediction
contexts, which are determined by user and item profiles, and then make open
rate predictions accordingly. The item with the highest predicted open rate is
then chosen to be included in the push notification message for each user. The
parameters of the mixture model are optimized using an EM algorithm. A set of
experiments are conducted to evaluate the proposed method live with a popular
E-Commerce mobile app. The results show that the proposed method is superior
than several existing solutions by a significant margin.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08113</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08114</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Multi-Task Learning</dc:title>
 <dc:creator>Zhang, Yu</dc:creator>
 <dc:creator>Yang, Qiang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Multi-Task Learning (MTL) is a learning paradigm in machine learning and its
aim is to leverage useful information contained in multiple related tasks to
help improve the generalization performance of all the tasks. In this paper, we
give a survey for MTL. First, we classify different MTL algorithms into several
categories: feature learning approach, low-rank approach, task clustering
approach, task relation learning approach, dirty approach, multi-level approach
and deep learning approach. In order to compare different approaches, we
discuss the characteristics of each approach. In order to improve the
performance of learning tasks further, MTL can be combined with other learning
paradigms including semi-supervised learning, active learning, reinforcement
learning, multi-view learning and graphical models. When the number of tasks is
large or the data dimensionality is high, batch MTL models are difficult to
handle this situation and online, parallel and distributed MTL models as well
as feature hashing are reviewed to reveal the computational and storage
advantages. Many real-world applications use MTL to boost their performance and
we introduce some representative works. Finally, we present theoretical
analyses and discuss several future directions for MTL.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08115</identifier>
 <datestamp>2017-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A novel CS Beamformer root-MUSIC algorithm and its subspace deviation
  analysis</dc:title>
 <dc:creator>Aich, Abhishek</dc:creator>
 <dc:creator>Palanisamy, P.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Subspace based techniques for direction of arrival (DOA) estimation need
large amount of snapshots to detect source directions accurately. This poses a
problem in the form of computational burden on practical applications. The
introduction of compressive sensing (CS) to solve this issue has become a norm
in the last decade. In this paper, a novel CS beamformer root-MUSIC algorithm
is presented with a revised optimal measurement matrix bound. With regards to
this algorithm, the effect of signal subspace deviation under low snapshot
scenario (e.g. target tracking) is analysed. The CS beamformer greatly reduces
computational complexity without affecting resolution of the algorithm, works
on par with root-MUSIC under low snapshot scenario and also, gives an option of
non-uniform linear array sensors unlike the case of root-MUSIC algorithm. The
effectiveness of the algorithm is demonstrated with simulations under various
scenarios.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures, IEEE TENCON 2017 accepted paper</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-09-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08117</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Sparse recovery based DOA estimation algorithm by relaxing the
  RIP constraint</dc:title>
 <dc:creator>Aich, Abhishek</dc:creator>
 <dc:creator>Palanisamy, P.</dc:creator>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Direction of Arrival (DOA) estimation of mixed uncorrelated and coherent
sources is a long existing challenge in array signal processing. Application of
compressive sensing to array signal processing has opened up an exciting class
of algorithms. The authors investigated the application of orthogonal matching
pursuit (OMP) for direction of Arrival (DOA) estimation for different
scenarios, especially to tackle the case of coherent sources and observed
inconsistencies in the results. In this paper, a modified OMP algorithm is
proposed to overcome these deficiencies by exploiting maximum variance based
criterion using only one snapshot. This criterion relaxes the imposed
restricted isometry property (RIP) on the measurement matrix to obtain the
sources and hence, reduces the sparsity of the input vector to the local OMP
algorithm. Moreover, it also tackles sources irrespective of their coherency.
The condition for the weak-1 RIP on decreased sparsity is derived and it is
shown that how the algorithm gives better result than the OMP algorithm. With
an addition to this, a simple method is also presented to calculate source
distance from the reference point in a uniform linear sensor array. Numerical
analysis demonstrates the effectiveness of the proposed algorithm.
</dc:description>
 <dc:description>Comment: 16 pages, 9 Figures, 4 Tables, Journal paper (Under Review)</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-10-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08120</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proxy Non-Discrimination in Data-Driven Systems</dc:title>
 <dc:creator>Datta, Anupam</dc:creator>
 <dc:creator>Fredrikson, Matt</dc:creator>
 <dc:creator>Ko, Gihyuk</dc:creator>
 <dc:creator>Mardziel, Piotr</dc:creator>
 <dc:creator>Sen, Shayak</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Machine learnt systems inherit biases against protected classes, historically
disparaged groups, from training data. Usually, these biases are not explicit,
they rely on subtle correlations discovered by training algorithms, and are
therefore difficult to detect. We formalize proxy discrimination in data-driven
systems, a class of properties indicative of bias, as the presence of protected
class correlates that have causal influence on the system's output. We evaluate
an implementation on a corpus of social datasets, demonstrating how to validate
systems against these properties and to repair violations where they occur.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1705.07807</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08134</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Scrubbing by Netlist Analysis for FPGA Configuration Bit
  Classification and Floorplanning</dc:title>
 <dc:creator>Schmidt, Bernhard</dc:creator>
 <dc:creator>Ziener, Daniel</dc:creator>
 <dc:creator>Teich, J&#xfc;rgen</dc:creator>
 <dc:creator>Z&#xf6;llner, Christian</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Existing scrubbing techniques for SEU mitigation on FPGAs do not guarantee an
error-free operation after SEU recovering if the affected configuration bits do
belong to feedback loops of the implemented circuits. In this paper, we a)
provide a netlist-based circuit analysis technique to distinguish so-called
critical configuration bits from essential bits in order to identify
configuration bits which will need also state-restoring actions after a
recovered SEU and which not. Furthermore, b) an alternative classification
approach using fault injection is developed in order to compare both
classification techniques. Moreover, c) we will propose a floorplanning
approach for reducing the effective number of scrubbed frames and d),
experimental results will give evidence that our optimization methodology not
only allows to detect errors earlier but also to minimize the
Mean-Time-To-Repair (MTTR) of a circuit considerably. In particular, we show
that by using our approach, the MTTR for datapath-intensive circuits can be
reduced by up to 48.5% in comparison to standard approaches.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08134</dc:identifier>
 <dc:identifier>Integration, the VLSI Journal 59C (2017) pp. 98-108</dc:identifier>
 <dc:identifier>doi:10.1016/j.vlsi.2017.06.012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08139</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analogs of Linguistic Structure in Deep Representations</dc:title>
 <dc:creator>Andreas, Jacob</dc:creator>
 <dc:creator>Klein, Dan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We investigate the compositional structure of message vectors computed by a
deep network trained on a communication game. By comparing truth-conditional
representations of encoder-produced message vectors to human-produced referring
expressions, we are able to identify aligned (vector, utterance) pairs with the
same meaning. We then search for structured relationships among these aligned
pairs to discover simple vector space transformations corresponding to
negation, conjunction, and disjunction. Our results suggest that neural
representations are capable of spontaneously developing a &quot;syntax&quot; with
functional analogues to qualitative properties of natural language.
</dc:description>
 <dc:description>Comment: In EMNLP 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08147</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human-in-the-loop optimisation: mixed initiative grasping for optimally
  facilitating post-grasp manipulative actions</dc:title>
 <dc:creator>Esfahani, Amir M. Ghalamzan</dc:creator>
 <dc:creator>Abi-Farraj, Firas</dc:creator>
 <dc:creator>Giordano, Paolo Robuffo</dc:creator>
 <dc:creator>Stolkin, Rustam</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper addresses the problem of mixed initiative, shared control for
master-slave grasping and manipulation. We propose a novel system, in which an
autonomous agent assists a human in teleoperating a remote slave arm/gripper,
using a haptic master device. Our system is designed to exploit the human
operator's expertise in selecting stable grasps (still an open research topic
in autonomous robotics). Meanwhile, a-priori knowledge of: i) the slave robot
kinematics, and ii) the desired post-grasp manipulative trajectory, are fed to
an autonomous agent which transmits force cues to the human, to encourage
maximally manipulable grasp pose selections. Specifically, the autonomous agent
provides force cues to the human, during the reach-to-grasp phase, which
encourage the human to select grasp poses which maximise manipulation
capability during the post-grasp object manipulation phase. We introduce a
task-relevant velocity manipulability cost function (TOV), which is used to
identify the maximum kinematic capability of a manipulator during post-grasp
motions, and feed this back as force cues to the human during the pre-grasp
phase. We show that grasps which minimise TOV result in significantly reduced
control effort of the manipulator, compared to other feasible grasps. We
demonstrate the effectiveness of our approach by experiments with both real and
simulated robots.
</dc:description>
 <dc:description>Comment: To be appeared in IEEE/RAS IROS 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08148</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Emotional Filters: Automatic Image Transformation for Inducing Affect</dc:title>
 <dc:creator>Ali, Afsheen Rafaqat</dc:creator>
 <dc:creator>Ali, Mohsen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Current image transformation and recoloring algorithms try to introduce
artistic effects in the photographed images, based on user input of target
image(s) or selection of pre-designed filters. These manipulations, although
intended to enhance the impact of an image on the viewer, do not include the
option of image transformation by specifying the affect information. In this
paper we present an automatic image-transformation method that transforms the
source image such that it can induce an emotional affect on the viewer, as
desired by the user. Our proposed novel image emotion transfer algorithm does
not require a user-specified target image. The proposed algorithm uses features
extracted from top layers of deep convolutional neural network and the
user-specified emotion distribution to select multiple target images from an
image database for color transformation, such that the resultant image has
desired emotional impact. Our method can handle more diverse set of photographs
than the previous methods. We conducted a detailed user study showing the
effectiveness of our proposed method. A discussion and reasoning of failure
cases has also been provided, indicating inherent limitation of color-transfer
based methods in the use of emotion assignment.
</dc:description>
 <dc:description>Comment: Published at British Machine Vision Conference (BMVC) 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08149</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Patch-based Carcinoma Detection on Confocal Laser Endomicroscopy Images
  - A Cross-Site Robustness Assessment</dc:title>
 <dc:creator>Aubreville, Marc</dc:creator>
 <dc:creator>Goncalves, Miguel</dc:creator>
 <dc:creator>Knipfer, Christian</dc:creator>
 <dc:creator>Oetter, Nicolai</dc:creator>
 <dc:creator>Wuerfl, Tobias</dc:creator>
 <dc:creator>Neumann, Helmut</dc:creator>
 <dc:creator>Stelzle, Florian</dc:creator>
 <dc:creator>Bohr, Christopher</dc:creator>
 <dc:creator>Maier, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning technologies such as convolutional neural networks (CNN)
provide powerful methods for image recognition and have recently been employed
in the field of automated carcinoma detection in confocal laser endomicroscopy
(CLE) images. CLE is a (sub-)surface microscopic imaging technique that reaches
magnifications of up to 1000x and is thus suitable for in vivo structural
tissue analysis.
  In this work, we aim to evaluate the prospects of a priorly developed deep
learning-based algorithm targeted at the identification of oral squamous cell
carcinoma with regard to its generalization to further anatomic locations of
squamous cell carcinomas in the area of head and neck. We applied the algorithm
on images acquired from the vocal fold area of five patients with
histologically verified squamous cell carcinoma and presumably healthy control
images of the clinically normal contra-lateral vocal cord.
  We find that the network trained on the oral cavity data reaches an accuracy
of 89.45% and an area-under-the-curve (AUC) value of 0.955, when applied on the
vocal cords data. Compared to the state of the art, we achieve very similar
results, yet with an algorithm that was trained on a completely disjunct data
set. Concatenating both data sets yielded further improvements in
cross-validation with an accuracy of 90.81% and AUC of 0.970.
  In this study, for the first time to our knowledge, a deep learning mechanism
for the identification of oral carcinomas using CLE Images could be applied to
other disciplines in the area of head and neck. This study shows the prospect
of the algorithmic approach to generalize well on other malignant entities of
the head and neck, regardless of the anatomical location and furthermore in an
examiner-independent manner.
</dc:description>
 <dc:description>Comment: 8 pages, 8 figures, submitted to BIOIMAGING 2018</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08150</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Safe Robotic Grasping: Minimum Impact-Force Grasp Selection</dc:title>
 <dc:creator>Mavrakis, Nikos</dc:creator>
 <dc:creator>E., Amir M. Ghalamzan</dc:creator>
 <dc:creator>Stolkin, Rustam</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper addresses the problem of selecting from a choice of possible
grasps, so that impact forces will be minimised if a collision occurs while the
robot is moving the grasped object along a post-grasp trajectory. Such
considerations are important for safety in human-robot interaction, where even
a certified &quot;human-safe&quot; (e.g. compliant) arm may become hazardous once it
grasps and begins moving an object, which may have significant mass, sharp
edges or other dangers. Additionally, minimising collision forces is critical
to preserving the longevity of robots which operate in uncertain and hazardous
environments, e.g. robots deployed for nuclear decommissioning, where removing
a damaged robot from a contaminated zone for repairs may be extremely difficult
and costly. Also, unwanted collisions between a robot and critical
infrastructure (e.g. pipework) in such high-consequence environments can be
disastrous. In this paper, we investigate how the safety of the post-grasp
motion can be considered during the pre-grasp approach phase, so that the
selected grasp is optimal in terms applying minimum impact forces if a
collision occurs during a desired post-grasp manipulation. We build on the
methods of augmented robot-object dynamics models and &quot;effective mass&quot; and
propose a method for combining these concepts with modern grasp and trajectory
planners, to enable the robot to achieve a grasp which maximises the safety of
the post-grasp trajectory, by minimising potential collision forces. We
demonstrate the effectiveness of our approach through several experiments with
both simulated and real robots.
</dc:description>
 <dc:description>Comment: To be appeared in IEEE/RAS IROS 2017</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08150</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08151</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Speeding-up ProbLog's Parameter Learning</dc:title>
 <dc:creator>de Faria, Francisco H. O. V.</dc:creator>
 <dc:creator>Gusm&#xe3;o, Arthur C.</dc:creator>
 <dc:creator>Cozman, Fabio G.</dc:creator>
 <dc:creator>Mau&#xe1;, Denis D.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>97R40</dc:subject>
 <dc:description>  ProbLog is a state-of-art combination of logic programming and probabilities;
in particular ProbLog offers parameter learning through a variant of the EM
algorithm. However, the resulting learning algorithm is rather slow, even when
the data are complete. In this short paper we offer some insights that lead to
orders of magnitude improvements in ProbLog's parameter learning speed with
complete data.
</dc:description>
 <dc:description>Comment: StarAI - International Workshop on Statistical Relational AI</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08160</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Harnessing Natural Experiments to Quantify the Causal Effect of Badges</dc:title>
 <dc:creator>Kusmierczyk, Tomasz</dc:creator>
 <dc:creator>Gomez-Rodriguez, Manuel</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  A wide variety of online platforms use digital badges to encourage users to
take certain types of desirable actions. However, despite their growing
popularity, their causal effect on users' behavior is not well understood. This
is partly due to the lack of counterfactual data and the myriad of complex
factors that influence users' behavior over time. As a consequence, their
design and deployment lacks general principles.
  In this paper, we focus on first-time badges, which are awarded after a user
takes a particular type of action for the first time, and study their causal
effect by harnessing the delayed introduction of several badges in a popular
Q&amp;A website. In doing so, we introduce a novel causal inference framework for
badges whose main technical innovations are a robust survival-based hypothesis
testing procedure, which controls for the utility heterogeneity across users,
and a bootstrap difference-in-differences method, which controls for the random
fluctuations in users' behavior over time. We find that first-time badges steer
users' behavior if the utility a user obtains from taking the corresponding
action is sufficiently low, otherwise, the badge does not have a significant
effect. Moreover, for badges that successfully steered user behavior, we
perform a counterfactual analysis and show that they significantly improved the
functioning of the site at a community level.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08160</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08164</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Opening the black box of energy modelling: Strategies and lessons
  learned</dc:title>
 <dc:creator>Pfenninger, Stefan</dc:creator>
 <dc:creator>Hirth, Lion</dc:creator>
 <dc:creator>Schlecht, Ingmar</dc:creator>
 <dc:creator>Schmid, Eva</dc:creator>
 <dc:creator>Wiese, Frauke</dc:creator>
 <dc:creator>Brown, Tom</dc:creator>
 <dc:creator>Davis, Chris</dc:creator>
 <dc:creator>Fais, Birgit</dc:creator>
 <dc:creator>Gidden, Matthew</dc:creator>
 <dc:creator>Heinrichs, Heidi</dc:creator>
 <dc:creator>Heuberger, Clara</dc:creator>
 <dc:creator>Hilpert, Simon</dc:creator>
 <dc:creator>Krien, Uwe</dc:creator>
 <dc:creator>Matke, Carsten</dc:creator>
 <dc:creator>Nebel, Arjuna</dc:creator>
 <dc:creator>Morrison, Robbie</dc:creator>
 <dc:creator>M&#xfc;ller, Berit</dc:creator>
 <dc:creator>Ple&#xdf;mann, Guido</dc:creator>
 <dc:creator>Reeg, Matthias</dc:creator>
 <dc:creator>Richstein, J&#xf6;rn C.</dc:creator>
 <dc:creator>Shivakumar, Abhishek</dc:creator>
 <dc:creator>Staffell, Iain</dc:creator>
 <dc:creator>Tr&#xf6;ndle, Tim</dc:creator>
 <dc:creator>Wingenbach, Clemens</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - General Literature</dc:subject>
 <dc:description>  The global energy system is undergoing a major transition, and in energy
planning and decision-making across governments, industry and academia, models
play a crucial role. Because of their policy relevance and contested nature,
the transparency and open availability of energy models and data are of
particular importance. Here we provide a practical how-to guide based on the
collective experience of members of the Open Energy Modelling Initiative
(Openmod). We discuss key steps to consider when opening code and data,
including determining intellectual property ownership, choosing a licence and
appropriate modelling languages, distributing code and data, and providing
support and building communities. After illustrating these decisions with
examples and lessons learned from the community, we conclude that even though
individual researchers' choices are important, institutional changes are still
also necessary for more openness and transparency in energy research.
</dc:description>
 <dc:description>Comment: 9 pages, 1 figure</dc:description>
 <dc:date>2017-07-20</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08164</dc:identifier>
 <dc:identifier>Energy Strategy Reviews, Volume 19, January 2018, Pages 63-71</dc:identifier>
 <dc:identifier>doi:10.1016/j.esr.2017.12.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08167</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On The Robustness of a Neural Network</dc:title>
 <dc:creator>Mhamdi, El Mahdi El</dc:creator>
 <dc:creator>Guerraoui, Rachid</dc:creator>
 <dc:creator>Rouault, Sebastien</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  With the development of neural networks based machine learning and their
usage in mission critical applications, voices are rising against the
\textit{black box} aspect of neural networks as it becomes crucial to
understand their limits and capabilities. With the rise of neuromorphic
hardware, it is even more critical to understand how a neural network, as a
distributed system, tolerates the failures of its computing nodes, neurons, and
its communication channels, synapses. Experimentally assessing the robustness
of neural networks involves the quixotic venture of testing all the possible
failures, on all the possible inputs, which ultimately hits a combinatorial
explosion for the first, and the impossibility to gather all the possible
inputs for the second.
  In this paper, we prove an upper bound on the expected error of the output
when a subset of neurons crashes. This bound involves dependencies on the
network parameters that can be seen as being too pessimistic in the average
case. It involves a polynomial dependency on the Lipschitz coefficient of the
neurons activation function, and an exponential dependency on the depth of the
layer where a failure occurs. We back up our theoretical results with
experiments illustrating the extent to which our prediction matches the
dependencies between the network parameters and robustness. Our results show
that the robustness of neural networks to the average crash can be estimated
without the need to neither test the network on all failure configurations, nor
access the training set used to train the network, both of which are
practically impossible requirements.
</dc:description>
 <dc:description>Comment: 36th IEEE International Symposium on Reliable Distributed Systems 26
  - 29 September 2017. Hong Kong, China</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08169</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Data-Driven Approach to Pre-Operative Evaluation of Lung Cancer
  Patients</dc:title>
 <dc:creator>Budilovsky, Oleksiy</dc:creator>
 <dc:creator>Alipour, Golnaz</dc:creator>
 <dc:creator>Knoesen, Andre</dc:creator>
 <dc:creator>Brown, Lisa</dc:creator>
 <dc:creator>Ghiasi, Soheil</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Lung cancer is the number one cause of cancer deaths. Many early stage lung
cancer patients have resectable tumors; however, their cardiopulmonary function
needs to be properly evaluated before they are deemed operative candidates.
Consequently, a subset of such patients is asked to undergo standard pulmonary
function tests, such as cardiopulmonary exercise tests (CPET) or stair climbs,
to have their pulmonary function evaluated. The standard tests are expensive,
labor intensive, and sometimes ineffective due to co-morbidities, such as
limited mobility. Recovering patients would benefit greatly from a device that
can be worn at home, is simple to use, and is relatively inexpensive. Using
advances in information technology, the goal is to design a continuous,
inexpensive, mobile and patient-centric mechanism for evaluation of a patient's
pulmonary function. A light mobile mask is designed, fitted with CO2, O2, flow
volume, and accelerometer sensors and tested on 18 subjects performing 15
minute exercises. The data collected from the device is stored in a cloud
service and machine learning algorithms are used to train and predict a user's
activity .Several classification techniques are compared - K Nearest Neighbor,
Random Forest, Support Vector Machine, Artificial Neural Network, and Naive
Bayes. One useful area of interest involves comparing a patient's predicted
activity levels, especially using only breath data, to that of a normal
person's, using the classification models.
</dc:description>
 <dc:date>2017-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08172</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The RepEval 2017 Shared Task: Multi-Genre Natural Language Inference
  with Sentence Representations</dc:title>
 <dc:creator>Nangia, Nikita</dc:creator>
 <dc:creator>Williams, Adina</dc:creator>
 <dc:creator>Lazaridou, Angeliki</dc:creator>
 <dc:creator>Bowman, Samuel R.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents the results of the RepEval 2017 Shared Task, which
evaluated neural network sentence representation learning models on the
Multi-Genre Natural Language Inference corpus (MultiNLI) recently introduced by
Williams et al. (2017). All of the five participating teams beat the
bidirectional LSTM (BiLSTM) and continuous bag of words baselines reported in
Williams et al.. The best single model used stacked BiLSTMs with residual
connections to extract sentence features and reached 74.5% accuracy on the
genre-matched test set. Surprisingly, the results of the competition were
fairly consistent across the genre-matched and genre-mismatched test sets, and
across subsets of the test data representing a variety of linguistic phenomena,
suggesting that all of the submitted systems learned reasonably
domain-independent representations for sentence meaning.
</dc:description>
 <dc:description>Comment: 10 pages, 1 figure, 6 tables, in Proceedings of The Second Workshop
  on Evaluating Vector Space Representations for NLP (RepEval 2017)</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08172</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08182</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a new Framework linking knowledge management systems and
  organizational agility : an empirical study</dc:title>
 <dc:creator>Marhraoui, Mohamed Amine</dc:creator>
 <dc:creator>Manouar, Abdellah El</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The amount of data has exploded over the last ten years. Data is captured and
shared from personal devices, transactional operations, sensors, social media
and other sources. Firms should, thus, be able to explore the new opportunities
and rapidly seize them by developing the corresponding capabilities. In our
work, we focus on two emerging dynamic capabilities: Absorptive capacity and
organizational agility. We propose a new theoretical Framework based on the
previous literature linking the use of knowledge management systems and
organizational agility by highlighting the mediating role of absorptive
capacity. In addition, we carried out an empirical study based on a survey to
support and validate the proposed Framework. The main findings of this study
are presented.
</dc:description>
 <dc:description>Comment: 16 pages, 7 figures</dc:description>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08182</dc:identifier>
 <dc:identifier>International Journal of Computer Science &amp; Information Technology
  (IJCSIT) Vol 9, No 1, February 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08183</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Joint Matrix Factorization Framework for Data Integration</dc:title>
 <dc:creator>Zhang, Lihua</dc:creator>
 <dc:creator>Zhang, Shihua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  Nonnegative matrix factorization (NMF) is a powerful tool in data exploratory
analysis by discovering the hidden features and part-based patterns from
high-dimensional data. NMF and its variants have been successfully applied into
diverse fields such as pattern recognition, signal processing, data mining,
bioinformatics and so on. Recently, NMF has been extended to analyze multiple
matrices simultaneously. However, a unified framework is still lacking. In this
paper, we introduce a sparse multiple relationship data regularized joint
matrix factorization (JMF) framework and two adapted prediction models for
pattern recognition and data integration. Next, we present four update
algorithms to solve this framework. The merits and demerits of these algorithms
are systematically explored. Furthermore, extensive computational experiments
using both synthetic data and real data demonstrate the effectiveness of JMF
framework and related algorithms on pattern recognition and data mining.
</dc:description>
 <dc:description>Comment: 14 pages, 7 figures</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08183</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08184</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Low Rank Tensor Ring Completion</dc:title>
 <dc:creator>Wang, Wenqi</dc:creator>
 <dc:creator>Aggarwal, Vaneet</dc:creator>
 <dc:creator>Aeron, Shuchin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Using the matrix product state (MPS) representation of the recently proposed
tensor ring decompositions, in this paper we propose a tensor completion
algorithm, which is an alternating minimization algorithm that alternates over
the factors in the MPS representation. This development is motivated in part by
the success of matrix completion algorithms that alternate over the (low-rank)
factors. In this paper, we propose a spectral initialization for the tensor
ring completion algorithm and analyze the computational complexity of the
proposed algorithm. We numerically compare it with existing methods that employ
a low rank tensor train approximation for data completion and show that our
method outperforms the existing ones for a variety of real computer vision
settings, and thus demonstrate the improved expressive power of tensor ring as
compared to tensor train.
</dc:description>
 <dc:description>Comment: in Proc. ICCV, Oct. 2017. arXiv admin note: text overlap with
  arXiv:1609.05587</dc:description>
 <dc:date>2017-07-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08184</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08186</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Persistent Cache-oblivious Streaming Indexes</dc:title>
 <dc:creator>Twigg, Andrew</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In [SPAA2007], Bender et al. define a streaming B-tree (or index) as one that
supports updates in amortized $o(1)$ IOs, and present a structure achieving
amortized $O((\log N)/B)$ IOs and queries in $O(\log N)$ IOs. We extend their
result to the partially-persistent case. For a version $v$, let $N_v$ be the
number of keys accessible at $v$ and $N$ be the total number of updates. We
give a data structure using space $O(N)$, supporting updates to a leaf version
$v$ with $O((\log N_{v})/B)$ amortized IOs and answering range queries
returning $Z$ elements with $O(\log N_{v} + Z/B)$ IOs on average (where the
average is over all queries covering disjoint key ranges at a given version).
This is the first persistent `streaming' index we are aware of, i.e. that
supports updates in $o(1)$ IOs and supports efficient range queries.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08187</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Observability Concept in a Class of Hybrid Control systems</dc:title>
 <dc:creator>Oltean, Virginia Ecaterina</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>93Bxx, 93Cxx</dc:subject>
 <dc:description>  In the discrete modeling approach for hybrid control systems, the continuous
plant is reduced to a discrete event approximation, called the DES-plant, that
is governed by a discrete event system, representing the controller. The
observability of the DES-plant model is crucial for the synthesis of the
controller and for the proper closed loop evolution of the hybrid control
system. Based on a version of the framework for hybrid control systems proposed
by Antsaklis, the paper analysis the relation between the properties of the
cellular space of the continuous plant and a mechanism of plant-symbols
generation, on one side, and the observability of the DES-plant automaton on
the other side. Finally an observable discrete event abstraction of the
continuous double integrator is presented.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures, research article</dc:description>
 <dc:date>2017-07-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08187</dc:identifier>
 <dc:identifier>Revue Roumaine des Sciences Techniques, S\'erie \'Electrotechnique
  et \'Energ\'etique, Tome 44(3), ISSN 0035-4066, Editura Academiei Rom\^ane,
  pp.363-376, 1999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08189</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Study of Joint MSINR and Relay Selection Algorithms for Distributed
  Beamforming</dc:title>
 <dc:creator>Ruan, Hang</dc:creator>
 <dc:creator>de Lamare, Rodrigo C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents joint maximum signal-to-interference-plus-noise ratio
(MSINR) and relay selection algorithms for distributed beamforming. We propose
a joint MSINR and restricted greedy search relay selection (RGSRS) algorithm
with a total relay transmit power constraint that iteratively optimizes both
the beamforming weights at the relays nodes, maximizing the SINR at the
destination. Specifically, we devise a relay selection scheme that based on
greedy search and compare it to other schemes like restricted random relay
selection (RRRS) and restricted exhaustive search relay selection (RESRS). A
complexity analysis is provided and simulation results show that the proposed
joint MSINR and RGSRS algorithm achieves excellent bit error rate (BER) and
SINR performances.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures. arXiv admin note: text overlap with
  arXiv:1707.00953</dc:description>
 <dc:date>2017-07-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08191</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A bijection for essentially 4-connected toroidal triangulations</dc:title>
 <dc:creator>Bonichon, Nicolas</dc:creator>
 <dc:creator>L&#xe9;v&#xea;que, Benjamin</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Transversal structures (also known as regular edge labelings) are
combinatorial structures defined over 4-connected plane triangulations with
quadrangular outer-face. They have been intensively studied and used for many
applications (drawing algorithm, random generation, enumeration ...). In this
paper we introduce and study a generalization of these objects for the toroidal
case. Contrary to what happens in the plane, the set of toroidal transversal
structures of a given toroidal triangulation is partitioned into several
distributive lattices. We exhibit a subset of toroidal transversal structures,
called balanced, and show that it forms a single distributive lattice. Then,
using the minimal element of the lattice, we are able to enumerate bijectively
essentially 4-connected toroidal triangulations.
</dc:description>
 <dc:description>Comment: 67 pages. arXiv admin note: text overlap with arXiv:1702.07589</dc:description>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08192</identifier>
 <datestamp>2017-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rook theory of the finite general linear group</dc:title>
 <dc:creator>Lewis, Joel Brewster</dc:creator>
 <dc:creator>Morales, Alejandro H.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:description>  Matrices over a finite field having fixed rank and restricted support are a
natural $q$-analogue of rook placements on a board. We develop this $q$-rook
theory by defining a corresponding analogue of the hit numbers. Using tools
from coding theory, we show that these $q$-hit and $q$-rook numbers obey a
variety of identities analogous to the classical case. We also explore
connections to earlier $q$-analogues of rook theory, as well as settling a
polynomiality conjecture and finding a counterexample of a positivity
conjecture of the authors and Klein.
</dc:description>
 <dc:description>Comment: 25 pages, 10 figure files. Minor change in definition of q-hit
  numbers changes notation but doesn't substantively affect results</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08192</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08197</identifier>
 <datestamp>2017-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Label Extraction in the CDAWG</dc:title>
 <dc:creator>Belazzougui, Djamal</dc:creator>
 <dc:creator>Cunial, Fabio</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The compact directed acyclic word graph (CDAWG) of a string $T$ of length $n$
takes space proportional just to the number $e$ of right extensions of the
maximal repeats of $T$, and it is thus an appealing index for highly repetitive
datasets, like collections of genomes from similar species, in which $e$ grows
significantly more slowly than $n$. We reduce from $O(m\log{\log{n}})$ to
$O(m)$ the time needed to count the number of occurrences of a pattern of
length $m$, using an existing data structure that takes an amount of space
proportional to the size of the CDAWG. This implies a reduction from
$O(m\log{\log{n}}+\mathtt{occ})$ to $O(m+\mathtt{occ})$ in the time needed to
locate all the $\mathtt{occ}$ occurrences of the pattern. We also reduce from
$O(k\log{\log{n}})$ to $O(k)$ the time needed to read the $k$ characters of the
label of an edge of the suffix tree of $T$, and we reduce from
$O(m\log{\log{n}})$ to $O(m)$ the time needed to compute the matching
statistics between a query of length $m$ and $T$, using an existing
representation of the suffix tree based on the CDAWG. All such improvements
derive from extracting the label of a vertex or of an arc of the CDAWG using a
straight-line program induced by the reversed CDAWG.
</dc:description>
 <dc:description>Comment: 16 pages, 1 figure. In proceedings of the 24th International
  Symposium on String Processing and Information Retrieval (SPIRE 2017). arXiv
  admin note: text overlap with arXiv:1705.08640</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-09-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08200</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Asymptotic Analysis Technique for Diversity Receptions Over
  Correlated Lognormal Fading Channels</dc:title>
 <dc:creator>Zhu, Bingcheng</dc:creator>
 <dc:creator>Cheng, Julian</dc:creator>
 <dc:creator>Yan, Jun</dc:creator>
 <dc:creator>Wang, Jinyuan</dc:creator>
 <dc:creator>Wu, Lenan</dc:creator>
 <dc:creator>Wang, Yongjin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Prior asymptotic performance analyses are based on the series expansion of
the moment-generating function (MGF) or the probability density function (PDF)
of channel coefficients. However, these techniques fail for lognormal fading
channels because the Taylor series of the PDF of a lognormal random variable is
zero at the origin and the MGF does not have an explicit form. Although
lognormal fading model has been widely applied in wireless communications and
free-space optical communications, few analytical tools are available to
provide elegant performance expressions for correlated lognormal channels. In
this work, we propose a novel framework to analyze the asymptotic outage
probabilities of selection combining (SC), equal-gain combining (EGC) and
maximum-ratio combining (MRC) over equally correlated lognormal fading
channels. Based on these closed-form results, we reveal the followings: i) the
outage probability of EGC or MRC becomes an infinitely small quantity compared
to that of SC at large signal-to-noise ratio (SNR); ii) channel correlation can
result in an infinite performance loss at large SNR. More importantly, the
analyses reveal insights into the long-standing problem of performance analyses
over correlated lognormal channels at high SNR, and circumvent the
time-consuming Monte Carlo simulation and numerical integration.
</dc:description>
 <dc:date>2017-05-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08200</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08202</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Digital Domain Power Division Multiplexed Dual Polarization Coherent
  Optical OFDM Transmission</dc:title>
 <dc:creator>Wu, Qiong</dc:creator>
 <dc:creator>Feng, Zhenhua</dc:creator>
 <dc:creator>Tang, Ming</dc:creator>
 <dc:creator>Li, Xiang</dc:creator>
 <dc:creator>Luo, Ming</dc:creator>
 <dc:creator>Zhou, Huibin</dc:creator>
 <dc:creator>Fu, Songnian</dc:creator>
 <dc:creator>Liu, Deming</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Capacity is the eternal pursuit for communication systems due to the
overwhelming demand of bandwidth hungry applications. As the backbone
infrastructure of modern communication networks, the optical fiber transmission
system undergoes a significant capacity growth over decades by exploiting
available physical dimensions (time, frequency, quadrature, polarization and
space) of the optical carrier for multiplexing. For each dimension, stringent
orthogonality must be guaranteed for perfect separation of independent
multiplexed signals. To catch up with the ever-increasing capacity requirement,
it is therefore interesting and important to develop new multiplexing
methodologies relaxing the orthogonal constraint thus achieving better spectral
efficiency and more flexibility of frequency reuse. Inspired by the idea of
non-orthogonal multiple access (NOMA) scheme, here we propose a digital domain
power division multiplexed (PDM) transmission technology which is fully
compatible with current dual polarization (DP) coherent optical communication
system. The coherent optical orthogonal frequency division multiplexing
(CO-OFDM) modulation has been employed owing to its great superiority on high
spectral efficiency, flexible coding, ease of channel estimation and robustness
against fiber dispersion. And a PDM-DP-CO-OFDM has been theoretically and
experimentally demonstrated with 100Gb/s wavelength division multiplexing (WDM)
transmission over 1440km standard single mode fibers (SSMFs). Two baseband
quadrature phase shift keying (QPSK) OFDM signals are overlaid together with
different power levels. After IQ modulation, polarization multiplexing and long
distance fiber transmission, the PDM-DP-CO-OFDM signal has been successfully
recovered in the typical polarization diversity coherent receiver by successive
interference cancellation (SIC) algorithm.
</dc:description>
 <dc:description>Comment: 9 pages,9 figures</dc:description>
 <dc:date>2017-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08203</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Positioning for Visible Light Communication System Exploiting Multipath
  Reflections</dc:title>
 <dc:creator>Hosseinianfar, Hamid</dc:creator>
 <dc:creator>Noshad, Mohammad</dc:creator>
 <dc:creator>Brandt-Pearce, Maite</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we introduce a new uplink visible light indoor positioning
system that estimates the position of the users in the network-side of a
visible light communications (VLC) system. This technique takes advantage of
the diffuse components of the uplink channel impulse response for positioning,
which has been considered as a destructive noise in existing visible light
communication positioning literature. Exploiting the line of sight (LOS)
component, the most significant diffusive component of the channel (the second
power peak (SPP)), and the delay time between LOS and SPP, we present a proof
of concept analysis for positioning using fixed reference points, i.e. uplink
photodetectors (PDs). Simulation results show the root mean square (RMS)
positioning accuracy of 25 cm and 5 cm for one and 4 PDs scenarios,
respectively.
</dc:description>
 <dc:description>Comment: Presented in IEEE International Conference Communications (ICC), May
  2017</dc:description>
 <dc:date>2017-06-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08204</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Power Control for Multi-Cell Networks with Non-Orthogonal Multiple
  Access</dc:title>
 <dc:creator>Yang, Zhaohui</dc:creator>
 <dc:creator>Pan, Cunhua</dc:creator>
 <dc:creator>Pan, Yijin</dc:creator>
 <dc:creator>Xu, Wei</dc:creator>
 <dc:creator>Chen, Ming</dc:creator>
 <dc:creator>Elkashlan, Maged</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate the problems of sum power minimization and sum
rate maximization for multi-cell networks with non-orthogonal multiple access.
Considering the sum power minimization, we obtain closed-form solutions to the
optimal power allocation strategy and then successfully transform the original
problem to a linear one with a much smaller size, which can be optimally solved
by using the standard interference function. To solve the nonconvex sum rate
maximization problem, we first prove that the power allocation problem for a
single cell is a convex problem. By analyzing the Karush-Kuhn-Tucker
conditions, the optimal power allocation for users in a single cell is derived
in closed form. Based on the optimal solution in each cell, a distributed
algorithm is accordingly proposed to acquire efficient solutions. Numerical
results verify our theoretical findings showing the superiority of our
solutions compared to the orthogonal frequency division multiple access and
broadcast channel.
</dc:description>
 <dc:description>Comment: Accepted in IEEE TWC. Key words: NOMA, multicell, distributed
  algorithm, power allocation, rate constraints</dc:description>
 <dc:date>2017-06-14</dc:date>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08205</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploration of Pattern-Matching Techniques for Lossy Compression on
  Cosmology Simulation Data Sets</dc:title>
 <dc:creator>Tao, Dingewn</dc:creator>
 <dc:creator>Di, Sheng</dc:creator>
 <dc:creator>Chen, Zizhong</dc:creator>
 <dc:creator>Cappello, Franck</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:description>  Because of the vast volume of data being produced by today's scientific
simulations, lossy compression allowing user-controlled information loss can
significantly reduce the data size and the I/O burden. However, for large-scale
cosmology simulation, such as the Hardware/Hybrid Accelerated Cosmology Code
(HACC), where memory overhead constraints restrict compression to only one
snapshot at a time, the lossy compression ratio is extremely limited because of
the fairly low spatial coherence and high irregularity of the data. In this
work, we propose a pattern-matching (similarity searching) technique to
optimize the prediction accuracy and compression ratio of SZ lossy compressor
on the HACC data sets. We evaluate our proposed method with different
configurations and compare it with state-of-the-art lossy compressors.
Experiments show that our proposed optimization approach can improve the
prediction accuracy and reduce the compressed size of quantization codes
compared with SZ. We present several lessons useful for future research
involving pattern-matching techniques for lossy compression.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures, accepted for DRBSD-1 in conjunction with ISC'17</dc:description>
 <dc:date>2017-06-17</dc:date>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08206</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Generalized Optimal Hard Decision Fusion</dc:title>
 <dc:creator>Mohammad, Fayazur Rahaman</dc:creator>
 <dc:creator>Mohammed, Zafar Ali Khan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this letter, we formulate a generalized decision fusion problem (GDFP) for
sensing with centralized hard decision fusion. We show that various new and
existing decision fusion rules are special cases of the proposed GDFP. We then
relate our problem to the classical $0-1$ Knapsack problem (KP). Consequently,
we apply dynamic programming to solve the exponentially complex GDFP in
polynomial time. Numerical results are presented to verify the effectiveness of
the proposed solution.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Signal Processing Letters on 05 March 2017 for
  peer-review</dc:description>
 <dc:date>2017-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08207</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fully Quaternion-Valued Capon Beamformer Based on Crossed-Dipole
  Arrays</dc:title>
 <dc:creator>Lan, Xiang</dc:creator>
 <dc:creator>Liu, Wei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Quaternion models have been developed for both direction of arrival
estimation and beamforming based on crossed-dipole arrays in the past. However,
for almost all the models, especially for adaptive beamforming, the desired
signal is still complex-valued and one example is the quaternion-Capon
beamformer. However, since the complex-valued desired signal only has two
components, while there are four components in a quaternion, only two
components of the quaternion-valued beamformer output are used and the
remaining two are simply removed. This leads to significant redundancy in its
implementation. In this work, we consider a quaternion-valued desired signal
and develop a full quaternion-valued Capon beamformer, which has a better
performance and a much lower complexity and is shown to be more robust against
array pointing errors.
</dc:description>
 <dc:description>Comment: 5 pages, 5 figures</dc:description>
 <dc:date>2017-06-26</dc:date>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08208</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Detection of Random Events with Spatially Correlated Data in
  Wireless Sensor Networks via Distributed Compressive Sensing</dc:title>
 <dc:creator>Wimalajeewa, Thakshila</dc:creator>
 <dc:creator>Varshney, Pramod K.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  In this paper, we exploit the theory of compressive sensing to perform
detection of a random source in a dense sensor network. When the sensors are
densely deployed, observations at adjacent sensors are highly correlated while
those corresponding to distant sensors are less correlated. Thus, the
covariance matrix of the concatenated observation vector of all the sensors at
any given time can be sparse where the sparse structure depends on the network
topology and the correlation model. Exploiting the sparsity structure of the
covariance matrix, we develop a robust nonparametric detector to detect the
presence of the random event using a compressed version of the data collected
at the distributed nodes. We employ the multiple access channel (MAC) model
with distributed random projections for sensors to transmit observations so
that a compressed version of the observations is available at the fusion
center. Detection is performed by constructing a decision statistic based on
the covariance information of uncompressed data which is estimated using
compressed data. The proposed approach does not require any knowledge of the
noise parameter to set the threshold, and is also robust when the distributed
random projection matrices become sparse.
</dc:description>
 <dc:date>2017-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08208</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08209</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the letter frequencies and entropy of written Marathi</dc:title>
 <dc:creator>Chipalkatti, Jaydeep</dc:creator>
 <dc:creator>Kulkarni, Mihir</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>H.1.1</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:description>  We carry out a comprehensive analysis of letter frequencies in contemporary
written Marathi. We determine sets of letters which statistically predominate
any large generic Marathi text, and use these sets to estimate the entropy of
Marathi.
</dc:description>
 <dc:date>2017-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08209</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08212</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Physical problem solving: Joint planning with symbolic, geometric, and
  dynamic constraints</dc:title>
 <dc:creator>Yildirim, Ilker</dc:creator>
 <dc:creator>Gerstenberg, Tobias</dc:creator>
 <dc:creator>Saeed, Basil</dc:creator>
 <dc:creator>Toussaint, Marc</dc:creator>
 <dc:creator>Tenenbaum, Josh</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we present a new task that investigates how people interact
with and make judgments about towers of blocks. In Experiment~1, participants
in the lab solved a series of problems in which they had to re-configure three
blocks from an initial to a final configuration. We recorded whether they used
one hand or two hands to do so. In Experiment~2, we asked participants online
to judge whether they think the person in the lab used one or two hands. The
results revealed a close correspondence between participants' actions in the
lab, and the mental simulations of participants online. To explain
participants' actions and mental simulations, we develop a model that plans
over a symbolic representation of the situation, executes the plan using a
geometric solver, and checks the plan's feasibility by taking into account the
physical constraints of the scene. Our model explains participants' actions and
judgments to a high degree of quantitative accuracy.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08213</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Algorithm for the 2D Radix-2 Sliding Window Fourier Transform</dc:title>
 <dc:creator>Richardson, Lee F.</dc:creator>
 <dc:creator>Eddy, William F.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a new algorithm for the 2D Radix-2 Sliding Window Fourier
Transform (SWFT). Our algorithm avoids repeating calculations in overlapping
windows by using a tree representation of the Cooley-Tukey Fast Fourier
Transform (FFT). For an $N_0 \times N_1$ array and $n_0 = 2^{m_0} \times n_1 =
2^{m_1}$ windows, our algorithm takes $O(N_0 N_1 n_0 n_1)$ operations, which is
faster than taking a 2D FFT in each window. We provide a C implementation of
the algorithm, compare ours with existing algorithms, and show how the
algorithm extends to higher dimensions.
</dc:description>
 <dc:description>Comment: 10 pages, 3 figures, submitted to ACM TOMS</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08214</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual Rectified Linear Units (DReLUs): A Replacement for Tanh Activation
  Functions in Quasi-Recurrent Neural Networks</dc:title>
 <dc:creator>Godin, Fr&#xe9;deric</dc:creator>
 <dc:creator>Degrave, Jonas</dc:creator>
 <dc:creator>Dambre, Joni</dc:creator>
 <dc:creator>De Neve, Wesley</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper, we introduce a novel type of Rectified Linear Unit (ReLU),
called a Dual Rectified Linear Unit (DReLU). A DReLU, which comes with an
unbounded positive and negative image, can be used as a drop-in replacement for
a tanh activation function in the recurrent step of Quasi-Recurrent Neural
Networks (QRNNs) (Bradbury et al. (2017)). Similar to ReLUs, DReLUs are less
prone to the vanishing gradient problem, they are noise robust, and they induce
sparse activations.
  We independently reproduce the QRNN experiments of Bradbury et al. (2017) and
compare our DReLU-based QRNNs with the original tanh-based QRNNs and Long
Short-Term Memory networks (LSTMs) on sentiment classification and word-level
language modeling. Additionally, we evaluate on character-level language
modeling, showing that we are able to stack up to eight QRNN layers with
DReLUs, thus making it possible to improve the current state-of-the-art in
character-level language modeling over shallow architectures based on LSTMs.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08216</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Gossip Algorithm based Clock Synchronization Scheme for Smart Grid
  Applications</dc:title>
 <dc:creator>Parvez, Imtiaz</dc:creator>
 <dc:creator>Sarwat, Arif I.</dc:creator>
 <dc:creator>Pinto, Jonathan</dc:creator>
 <dc:creator>Parvez, Zakaria</dc:creator>
 <dc:creator>Khandaker, Mohammad Aqib</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The uprising interest in multi-agent based networked system, and the numerous
number of applications in the distributed control of the smart grid leads us to
address the problem of time synchronization in the smart grid. Utility
companies look for new packet based time synchronization solutions with Global
Positioning System (GPS) level accuracies beyond traditional packet methods
such as Network Time Proto- col (NTP). However GPS based solutions have poor
reception in indoor environments and dense urban canyons as well as GPS antenna
installation might be costly. Some smart grid nodes such as Phasor Measurement
Units (PMUs), fault detection, Wide Area Measurement Systems (WAMS) etc.,
requires synchronous accuracy as low as 1 ms. On the other hand, 1 sec accuracy
is acceptable in management information domain. Acknowledging this, in this
study, we introduce gossip algorithm based clock synchronization method among
network entities from the decision control and communication point of view. Our
method synchronizes clock within dense network with a bandwidth limited
environment. Our technique has been tested in different kinds of network
topologies- complete, star and random geometric network and demonstrated
satisfactory performance.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08225</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating parameters associated with monotone properties</dc:title>
 <dc:creator>Hoppen, Carlos</dc:creator>
 <dc:creator>Kohayakawa, Yoshiharu</dc:creator>
 <dc:creator>Lang, Richard</dc:creator>
 <dc:creator>Lefmann, Hanno</dc:creator>
 <dc:creator>Stagni, Henrique</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  There has been substantial interest in estimating the value of a graph
parameter, i.e., of a real-valued function defined on the set of finite graphs,
by querying a randomly sampled substructure whose size is independent of the
size of the input. Graph parameters that may be successfully estimated in this
way are said to be testable or estimable, and the sample complexity
$q_z=q_z(\epsilon)$ of an estimable parameter $z$ is the size of a random
sample of a graph $G$ required to ensure that the value of $z(G)$ may be
estimated within an error of $\epsilon$ with probability at least 2/3. In this
paper, for any fixed monotone graph property
$\mathcal{P}=\mbox{Forb}(\mathcal{F})$, we study the sample complexity of
estimating a bounded graph parameter $z_{\mathcal{P}}$ that, for an input graph
$G$, counts the number of spanning subgraphs of $G$ that satisfy $\mathcal{P}$.
To improve upon previous upper bounds on the sample complexity, we show that
the vertex set of any graph that satisfies a monotone property $\mathcal{P}$
may be partitioned equitably into a constant number of classes in such a way
that the cluster graph induced by the partition is not far from satisfying a
natural weighted graph generalization of $\mathcal{P}$. Properties for which
this holds are said to be recoverable, and the study of recoverable properties
may be of independent interest.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08232</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quality-Driven Resource Allocation for Full-Duplex Delay-Constrained
  Wireless Video Transmissions</dc:title>
 <dc:creator>Ye, Chuang</dc:creator>
 <dc:creator>Gursoy, M. Cenk</dc:creator>
 <dc:creator>Velipasalar, Senem</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, wireless video transmission over full-duplex channels under
total bandwidth and minimum required quality constraints is studied. In order
to provide the desired performance levels to the end-users in real-time video
transmissions, quality of service (QoS) requirements such as statistical delay
constraints are also considered. Effective capacity (EC) is used as the
throughput metric in the presence of such statistical delay constraints since
deterministic delay bounds are difficult to guarantee due to the time-varying
nature of wireless fading channels. A communication scenario with multiple
pairs of users in which different users have different delay requirements is
addressed. Following characterizations from the rate-distortion (R-D) theory, a
logarithmic model of the quality-rate relation is used for predicting the
quality of the reconstructed video in terms of the peak signal-to-noise ratio
(PSNR) at the receiver side. Since the optimization problem is not concave or
convex, the optimal bandwidth and power allocation policies that maximize the
weighted sum video quality subject to total bandwidth, maximum transmission
power level and minimum required quality constraints are derived by using
monotonic optimization (MO) theory.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08234</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Closed-Loop Policies for Operational Tests of Safety-Critical Systems</dc:title>
 <dc:creator>Morton, Jeremy</dc:creator>
 <dc:creator>Wheeler, Tim A.</dc:creator>
 <dc:creator>Kochenderfer, Mykel J.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Manufacturers of safety-critical systems must make the case that their
product is sufficiently safe for public deployment. Much of this case often
relies upon critical event outcomes from real-world testing, requiring
manufacturers to be strategic about how they allocate testing resources in
order to maximize their chances of demonstrating system safety. This work
frames the partially observable and belief-dependent problem of test scheduling
as a Markov decision process, which can be solved efficiently to yield
closed-loop manufacturer testing policies. By solving for policies over a wide
range of problem formulations, we are able to provide high-level guidance for
manufacturers and regulators on issues relating to the testing of
safety-critical systems. This guidance spans an array of topics, including
circumstances under which manufacturers should continue testing despite
observed incidents, when manufacturers should test aggressively, and when
regulators should increase or reduce the real-world testing requirements for an
autonomous vehicle.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures, 5 tables</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08237</identifier>
 <datestamp>2017-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High Quality Queueing Information from Accelerated Active Network
  Tomography</dc:title>
 <dc:creator>Rizzo, Tommaso</dc:creator>
 <dc:creator>Steger, Jozsef</dc:creator>
 <dc:creator>Pollner, P&#xe9;ter</dc:creator>
 <dc:creator>Csabai, Istvan</dc:creator>
 <dc:creator>Vattay, Gabor</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Monitoring network state can be crucial in Future Internet infrastructures.
Passive monitoring of all the routers is expensive and prohibitive. Storing,
accessing and sharing the data is a technological challenge among networks with
conflicting economic interests. Active monitoring methods can be attractive
alternatives as they are free from most of these issues. Here we demonstrate
that it is possible to improve the active network tomography methodology to
such extent that the quality of the extracted link or router level delay is
comparable to the passively measurable information. We show that the temporal
precision of the measurements and the performance of the data analysis should
be simultaneously improved to achieve this goal. In this paper we not only
introduce a new efficient message-passing based algorithm but we also show that
it is applicable for data collected by the ETOMIC high precision active
measurement infrastructure. The measurements are conducted in the GEANT2 high
speed academic network connecting the sites, which is an ideal test ground for
such Future Internet applications.
</dc:description>
 <dc:description>Comment: 10 pages, Proceedings of the 4th International Conference on Testbeds
  and research infrastructures for the development of networks and communities,
  Article No. 22, Innsbruck, Austria, March 18 - 20, 2008</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08237</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08238</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Nearly Instance Optimal Algorithm for Top-k Ranking under the
  Multinomial Logit Model</dc:title>
 <dc:creator>Chen, Xi</dc:creator>
 <dc:creator>Li, Yuanzhi</dc:creator>
 <dc:creator>Mao, Jieming</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the active learning problem of top-$k$ ranking from multi-wise
comparisons under the popular multinomial logit model. Our goal is to identify
the top-$k$ items with high probability by adaptively querying sets for
comparisons and observing the noisy output of the most preferred item from each
comparison. To achieve this goal, we design a new active ranking algorithm
without using any information about the underlying items' preference scores. We
also establish a matching lower bound on the sample complexity even when the
set of preference scores is given to the algorithm. These two results together
show that the proposed algorithm is nearly instance optimal (similar to
instance optimal [FLN03], but up to polylog factors). Our work extends the
existing literature on rank aggregation in three directions. First, instead of
studying a static problem with fixed data, we investigate the top-$k$ ranking
problem in an active learning setting. Second, we show our algorithm is nearly
instance optimal, which is a much stronger theoretical guarantee. Finally, we
extend the pairwise comparison to the multi-wise comparison, which has not been
fully explored in ranking literature.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08243</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structural Controllability of Linear Time-invariant Systems</dc:title>
 <dc:creator>Liu, Fengjiao</dc:creator>
 <dc:creator>Morse, A. Stephen</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  One version of the concept of structural controllability defined for
single-input systems by Lin and subsequently generalized to multi-input systems
by others, states that a parameterized matrix pair $(A, B)$ whose nonzero
entries are distinct parameters, is structurally controllable if values can be
assigned to the parameters which cause the resulting matrix pair to be
controllable. In this paper the concept of structural controllability is
broadened to allow for the possibility that a parameter may appear in more than
one location in the pair $(A, B)$. Subject to a certain condition on the
parameterization called the &quot;binary assumption&quot;, an explicit graph-theoretic
characterization of such matrix pairs is derived.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08247</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kinetic Simulation of Collisional Magnetized Plasmas with Semi-Implicit
  Time Integration</dc:title>
 <dc:creator>Ghosh, Debojyoti</dc:creator>
 <dc:creator>Dorf, Mikhail A.</dc:creator>
 <dc:creator>Dorr, Milo R.</dc:creator>
 <dc:creator>Hittinger, Jeffrey A. F.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>65M06, 86A10, 76N15</dc:subject>
 <dc:description>  Plasmas with varying collisionalities occur in many applications, such as
tokamak edge regions, where the flows are characterized by significant
variations in density and temperature. While a kinetic model is necessary for
weakly-collisional high-temperature plasmas, high collisionality in colder
regions render the equations numerically stiff due to disparate time scales. In
this paper, we propose an implicit-explicit algorithm for such cases, where the
collisional term is integrated implicitly in time, while the advective term is
integrated explicitly in time, thus allowing time step sizes that are
comparable to the advective time scales. This partitioning results in a more
efficient algorithm than those using explicit time integrators, where the time
step sizes are constrained by the stiff collisional time scales. We implement
semi-implicit additive Runge-Kutta methods in COGENT, a finite-volume
gyrokinetic code for mapped, multiblock grids and test the accuracy,
convergence, and computational cost of these semi-implicit methods for test
cases with highly-collisional plasmas.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08250</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings Sixteenth Conference on Theoretical Aspects of Rationality
  and Knowledge</dc:title>
 <dc:creator>Lang, J&#xe9;r&#xf4;me</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This volume consists of papers presented at the Sixteenth Conference on
Theoretical Aspects of Rationality and Knowledge (TARK) held at the University
of Liverpool, UK, from July 24 to 26, 2017.
  TARK conferences bring together researchers from a wide variety of fields,
including Computer Science (especially, Artificial Intelligence, Cryptography,
Distributed Computing), Economics (especially, Decision Theory, Game Theory,
Social Choice Theory), Linguistics, Philosophy (especially, Philosophical
Logic), and Cognitive Psychology, in order to further understand the issues
involving reasoning about rationality and knowledge.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08250</dc:identifier>
 <dc:identifier>EPTCS 251, 2017</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08254</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Yet Deep Convolutional Neural Networks for Semantic
  Segmentation</dc:title>
 <dc:creator>Kamran, Sharif Amit</dc:creator>
 <dc:creator>Hasan, Muhammad</dc:creator>
 <dc:creator>Sabbir, Ali Shihab</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Semantic Segmentation using deep convolutional neural network pose more
complex challenge for any GPU intensive work, as it has to compute million of
parameters resulting to huge consumption of memory. Moreover, extracting finer
features and conducting supervised training tends to increase the complexity
furthermore. With the introduction of Fully Convolutional Neural Network, which
uses finer strides and utilizes deconvolutional layers for upsampling, it has
been a go to for any image segmentation task. We propose two segmentation
architecture transferring weights from the popular classification neural net
VGG19 and VGG16 which were trained on Imagenet classification dataset,
transform all the fully connected layers to convolutional layers, use dilated
convolution for decreasing the parameters, moreover we add more finer strides
and attach four skip architectures which are element-wise summed with the
deconvolutional layers in steps. We train and test on different sparse and fine
data-sets like Pascal VOC2012, Pascal-Context and NYUDv2 and show how better
our model performs in this tasks. On the other hand our model consumes up to
10-20 percent less memory for training and testing with NVIDIA Pascal GPUs,
making it more efficient and less memory consuming architecture for pixel-wise
segmentation.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08255</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Navigability with Imperfect Information</dc:title>
 <dc:creator>Deuser, Kaya</dc:creator>
 <dc:creator>Naumov, Pavel</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The article studies navigability of an autonomous agent in a maze where some
rooms may be indistinguishable. In a previous work the authors have shown that
the properties of navigability in such a setting depend on whether an agent has
perfect recall. Navigability by an agent with perfect recall is a transitive
relation and without is not transitive.
  This article introduces a notion of restricted navigability and shows that a
certain form of transitivity holds for restricted navigability, even for an
agent without perfect recall. The main technical result is a sound and complete
logical system describing the properties of restricted navigability.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08259</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparative Analysis of XML Documents, XML Enabled Databases and
  Native XML Databases</dc:title>
 <dc:creator>Saba, Amir Mohammad</dc:creator>
 <dc:creator>Shahab, Elham</dc:creator>
 <dc:creator>Abdolrahimpour, Hadi</dc:creator>
 <dc:creator>Hakimi, Mahsa</dc:creator>
 <dc:creator>Moazzam, Akbar</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  With the increasing popularity of XML data and a great need for a database
management system able to store, retrieve and manipulate XML-based data in an
efficient manner, database research communities and software industries have
tried to respond to this requirement. XML-enabled database and native XML
database are two approaches that have been proposed to address this challenge.
These two approaches are a legacy database systems which are extended to store,
retrieve and manipulate XML-based data. The major objective of this paper is to
explore and compare between the two approaches and reach to some criteria to
have a suitable guideline to select the best approach in each circumstance. In
general, native XML database systems have more ability in comparison with
XML-enabled database system for managing XML-based data
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08262</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SLEEPNET: Automated Sleep Staging System via Deep Learning</dc:title>
 <dc:creator>Biswal, Siddharth</dc:creator>
 <dc:creator>Kulas, Joshua</dc:creator>
 <dc:creator>Sun, Haoqi</dc:creator>
 <dc:creator>Goparaju, Balaji</dc:creator>
 <dc:creator>Westover, M Brandon</dc:creator>
 <dc:creator>Bianchi, Matt T</dc:creator>
 <dc:creator>Sun, Jimeng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Sleep disorders, such as sleep apnea, parasomnias, and hypersomnia, affect
50-70 million adults in the United States (Hillman et al., 2006). Overnight
polysomnography (PSG), including brain monitoring using electroencephalography
(EEG), is a central component of the diagnostic evaluation for sleep disorders.
While PSG is conventionally performed by trained technologists, the recent rise
of powerful neural network learning algorithms combined with large
physiological datasets offers the possibility of automation, potentially making
expert-level sleep analysis more widely available. We propose SLEEPNET (Sleep
EEG neural network), a deployed annotation tool for sleep staging. SLEEPNET
uses a deep recurrent neural network trained on the largest sleep physiology
database assembled to date, consisting of PSGs from over 10,000 patients from
the Massachusetts General Hospital (MGH) Sleep Laboratory. SLEEPNET achieves
human-level annotation performance on an independent test set of 1,000 EEGs,
with an average accuracy of 85.76% and algorithm-expert inter-rater agreement
(IRA) of kappa = 79.46%, comparable to expert-expert IRA.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08262</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08265</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dragon: A Computation Graph Virtual Machine Based Deep Learning
  Framework</dc:title>
 <dc:creator>Pan, Ting</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deep Learning has made a great progress for these years. However, it is still
difficult to master the implement of various models because different
researchers may release their code based on different frameworks or interfaces.
In this paper, we proposed a computation graph based framework which only aims
to introduce well-known interfaces. It will help a lot when reproducing a newly
model or transplanting models that were implemented by other frameworks.
Additionally, we implement numerous recent models covering both Computer Vision
and Nature Language Processing. We demonstrate that our framework will not
suffer from model-starving because it is much easier to make full use of the
works that are already done.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08265</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08270</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polynomial-Time Approximation Schemes for k-Center and Bounded-Capacity
  Vehicle Routing in Graphs with Bounded Highway Dimension</dc:title>
 <dc:creator>Becker, Amariah</dc:creator>
 <dc:creator>Klein, Philip N.</dc:creator>
 <dc:creator>Saulpic, David</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The concept of bounded highway dimension was developed to capture observed
properties of the metrics of road networks. We show that a graph with bounded
highway dimension, for any vertex, can be embedded into a a graph of bounded
treewidth in such a way that the distance between $u$ and $v$ is preserved up
to an additive error of $\epsilon$ times the distance from $u$ or $v$ to the
selected vertex. We show that this theorem yields a PTAS for Bounded-Capacity
Vehicle Routing in graphs of bounded highway dimension. In this problem, the
input specifies a depot and a set of clients, each with a location and demand;
the output is a set of depot-to-depot tours, where each client is visited by
some tour and each tour covers at most $Q$ units of client demand. Our PTAS can
be extended to handle penalties for unvisited clients.
  We extend this embedding result to handle a set $S$ of distinguished
vertices. The treewidth depends on $|S|$, and the distance between $u$ and $v$
is preserved up to an additive error of $\epsilon$ times the distance from $u$
and $v$ to $S$.
  This embedding result implies a PTAS for Multiple Depot Bounded-Capacity
Vehicle Routing: the tours can go from one depot to another. The embedding
result also implies that, for fixed $k$, there is a PTAS for $k$-Center in
graphs of bounded highway dimension. In this problem, the goal is to minimize
$d$ such that there exist $k$ vertices (the centers) such that every vertex is
within distance $d$ of some center. Similarly, for fixed $k$, there is a PTAS
for $k$-Median in graphs of bounded highway dimension. In this problem, the
goal is to minimize the sum of distances to the $k$ centers.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08270</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08271</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Preamble Collision Resolution Scheme via Tagged Preambles for Cellular
  IoT/M2M Communications</dc:title>
 <dc:creator>Jang, Han Seung</dc:creator>
 <dc:creator>Kim, Su Min</dc:creator>
 <dc:creator>Park, Hong-Shik</dc:creator>
 <dc:creator>Sung, Dan Keun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a preamble (PA) collision resolution (PACR) scheme
based on multiple timing advance (TA) values captured via tagged PAs. In the
proposed PACR scheme, tags are embedded in random access (RA) PAs and multiple
TA values are captured for a single detected PA during a tag detection
procedure. The proposed PACR scheme significantly improves RA success
probability for stationary machine nodes since the nodes using collided PAs can
successfully complete the corresponding RAs using exclusive data resource
blocks.
</dc:description>
 <dc:description>Comment: 5 page, 5 figures, revised and resubmitted for publication to IEEE
  Transactions on Vehicular Technology</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08272</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Change-Sensitive Algorithm for Maintaining Maximal Bicliques in a
  Dynamic Bipartite Graph</dc:title>
 <dc:creator>Das, Apurba</dc:creator>
 <dc:creator>Tirthapura, Srikanta</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We consider the maintenance of maximal bicliques from a dynamic bipartite
graph that changes over time due to the addition or deletion of edges. When the
set of edges in a graph changes, we are interested in knowing the change in the
set of maximal bicliques (the &quot;change&quot;), rather than in knowing the set of
maximal bicliques that remain unaffected. The challenge in an efficient
algorithm is to enumerate the change without explicitly enumerating the set of
all maximal bicliques. In this work, we present (1) near-tight bounds on the
magnitude of change in the set of maximal bicliques of a graph, due to a change
in the edge set (2) a &quot;change-sensitive&quot; algorithm for enumerating the change
in the set of maximal bicliques, whose time complexity is proportional to the
magnitude of change that actually occurred in the set of maximal bicliques in
the graph. To our knowledge, these are the first algorithms for enumerating
maximal bicliques in a dynamic graph, with such provable performance
guarantees. Our algorithms are easy to implement, and experimental results show
that their performance exceeds that of current baseline implementations by
orders of magnitude.
</dc:description>
 <dc:description>Comment: 12 pages, 9 figures</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08272</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08273</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MMGAN: Manifold Matching Generative Adversarial Network</dc:title>
 <dc:creator>Park, Noseong</dc:creator>
 <dc:creator>Anand, Ankesh</dc:creator>
 <dc:creator>Moniz, Joel Ruben Antony</dc:creator>
 <dc:creator>Lee, Kookjin</dc:creator>
 <dc:creator>Chakraborty, Tanmoy</dc:creator>
 <dc:creator>Choo, Jaegul</dc:creator>
 <dc:creator>Park, Hongkyu</dc:creator>
 <dc:creator>Kim, Youngmin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Generative adversarial networks (GANs) are considered as a totally different
type of generative models. However, it is well known that GANs are very hard to
train. There have been proposed many different techniques in order to stabilize
their training procedures.
  In this paper, we propose a novel training method called manifold matching
and a new GAN model called manifold matching GAN (MMGAN). In MMGAN, vector
representations extracted from the last layer of the discriminator are used to
train the generator. It finds two manifolds representing vector representations
of real and fake images. If these two manifolds are matched, it means that real
and fake images are identical in the perspective of the discriminator because
the manifolds are constructed from the discriminator's last layer. In general,
it is much easier to train the discriminator and it becomes more accurate as
epoch goes by. This implies that the manifold matching also becomes very
accurate as the discriminator is trained. We also use the kernel trick to find
better manifolds.
  We conduct in-depth experiments with three image datasets and several
state-of-the-art GAN models. Our experiments demonstrate the efficacy of the
proposed MMGAN model.
</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08275</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Exploration of Approaches to Integrating Neural Reranking Models in
  Multi-Stage Ranking Architectures</dc:title>
 <dc:creator>Tu, Zhucheng</dc:creator>
 <dc:creator>Crane, Matt</dc:creator>
 <dc:creator>Sequiera, Royal</dc:creator>
 <dc:creator>Zhang, Junchen</dc:creator>
 <dc:creator>Lin, Jimmy</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  We explore different approaches to integrating a simple convolutional neural
network (CNN) with the Lucene search engine in a multi-stage ranking
architecture. Our models are trained using the PyTorch deep learning toolkit,
which is implemented in C/C++ with a Python frontend. One obvious integration
strategy is to expose the neural network directly as a service. For this, we
use Apache Thrift, a software framework for building scalable cross-language
services. In exploring alternative architectures, we observe that once trained,
the feedforward evaluation of neural networks is quite straightforward.
Therefore, we can extract the parameters of a trained CNN from PyTorch and
import the model into Java, taking advantage of the Java Deeplearning4J library
for feedforward evaluation. This has the advantage that the entire end-to-end
system can be implemented in Java. As a third approach, we can extract the
neural network from PyTorch and &quot;compile&quot; it into a C++ program that exposes a
Thrift service. We evaluate these alternatives in terms of performance (latency
and throughput) as well as ease of integration. Experiments show that
feedforward evaluation of the convolutional neural network is significantly
slower in Java, while the performance of the compiled C++ network does not
consistently beat the PyTorch implementation.
</dc:description>
 <dc:description>Comment: SIGIR 2017 Workshop on Neural Information Retrieval (Neu-IR'17),
  August 7-11, 2017, Shinjuku, Tokyo, Japan</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08279</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A General and Yet Efficient Scheme for Sub-Nyquist Radar Processing</dc:title>
 <dc:creator>Chen, Shengyao</dc:creator>
 <dc:creator>Xi, Feng</dc:creator>
 <dc:creator>Liu, Zhong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the target parameter estimation for sub-Nyquist pulse-Doppler radar.
Several past works have addressed this problem but either have low estimation
accuracy for off-grid targets, take large computation load, or lack versatility
for analog-to-information conversion (AIC) systems. To overcome these
difficulties, we present a general and efficient estimation scheme. The scheme
first formulates a general model in the sense that it is applicable to all AICs
regardless of whether the targets are on or off the grids. The estimation of
Doppler shifts and delays is performed sequentially, in which the Doppler
estimation is formulated into a spatial spectrum estimation problem and the
delay estimation is decomposed into a series of compressive parameter
estimation problems with each corresponding to an estimated Doppler shift. By
the sequential and decomposed processing, the computational complexity is
substantially reduced, and by the parametric estimation techniques, the high
accurate estimation is obtained. Theoretical analyses and numerical experiments
show the effectiveness and the correctness of the proposed scheme.
</dc:description>
 <dc:description>Comment: 13 pages, 3 figures</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08279</dc:identifier>
 <dc:identifier>doi:10.1016/j.sigpro.2017.07.018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08287</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Motion Artifact Detection in Wrist-Measured Electrodermal
  Activity Data</dc:title>
 <dc:creator>Zhang, Yuning</dc:creator>
 <dc:creator>Haghdan, Maysam</dc:creator>
 <dc:creator>Xu, Kevin S.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:subject>H.1.2</dc:subject>
 <dc:description>  One of the main benefits of a wrist-worn computer is its ability to collect a
variety of physiological data in a minimally intrusive manner. Among these
data, electrodermal activity (EDA) is readily collected and provides a window
into a person's emotional and sympathetic responses. EDA data collected using a
wearable wristband are easily influenced by motion artifacts (MAs) that may
significantly distort the data and degrade the quality of analyses performed on
the data if not identified and removed. Prior work has demonstrated that MAs
can be successfully detected using supervised machine learning algorithms on a
small data set collected in a lab setting. In this paper, we demonstrate that
unsupervised learning algorithms perform competitively with supervised
algorithms for detecting MAs on EDA data collected in both a lab-based setting
and a real-world setting comprising about 23 hours of data. We also find,
somewhat surprisingly, that incorporating accelerometer data as well as EDA
improves detection accuracy only slightly for supervised algorithms and
significantly degrades the accuracy of unsupervised algorithms.
</dc:description>
 <dc:description>Comment: To appear at International Symposium on Wearable Computers (ISWC)
  2017</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08287</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08289</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Deep Matting for Portrait Animation on Mobile Phone</dc:title>
 <dc:creator>Zhu, Bingke</dc:creator>
 <dc:creator>Chen, Yingying</dc:creator>
 <dc:creator>Wang, Jinqiao</dc:creator>
 <dc:creator>Liu, Si</dc:creator>
 <dc:creator>Zhang, Bo</dc:creator>
 <dc:creator>Tang, Ming</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image matting plays an important role in image and video editing. However,
the formulation of image matting is inherently ill-posed. Traditional methods
usually employ interaction to deal with the image matting problem with trimaps
and strokes, and cannot run on the mobile phone in real-time. In this paper, we
propose a real-time automatic deep matting approach for mobile devices. By
leveraging the densely connected blocks and the dilated convolution, a light
full convolutional network is designed to predict a coarse binary mask for
portrait images. And a feathering block, which is edge-preserving and matting
adaptive, is further developed to learn the guided filter and transform the
binary mask into alpha matte. Finally, an automatic portrait animation system
based on fast deep matting is built on mobile devices, which does not need any
interaction and can realize real-time matting with 15 fps. The experiments show
that the proposed approach achieves comparable results with the
state-of-the-art matting solvers.
</dc:description>
 <dc:description>Comment: ACM Multimedia Conference (MM) 2017 camera-ready</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08289</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08290</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast calculation of entropy with Zhang's estimator</dc:title>
 <dc:creator>Lozano, Antoni</dc:creator>
 <dc:creator>Casas, Bernardino</dc:creator>
 <dc:creator>Bentz, Chris</dc:creator>
 <dc:creator>Ferrer-i-Cancho, Ramon</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Entropy is a fundamental property of a repertoire. Here, we present an
efficient algorithm to estimate the entropy of types with the help of Zhang's
estimator. The algorithm takes advantage of the fact that the number of
different frequencies in a text is in general much smaller than the number of
types. We justify the convenience of the algorithm by means of an analysis of
the statistical properties of texts from more than 1000 languages. Our work
opens up various possibilities for future research.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08290</dc:identifier>
 <dc:identifier>Issues in Quantitative Linguistics 4. E. Kelih, R. Knight, J.
  Macutek and A. Wilson (eds.). No. 23 of the series &quot;Studies in Quantitative
  Linguistics&quot;. L\&quot;udenscheid: RAM-Verlag. pp. 273-285</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08291</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Wideband Spectrum Sensing Using Sparsity</dc:title>
 <dc:creator>Flokas, Lampros</dc:creator>
 <dc:creator>Maragos, Petros</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Wideband spectrum sensing is an essential part of cognitive radio systems.
Exact spectrum estimation is usually inefficient as it requires sampling rates
at or above the Nyquist rate. Using prior information on the structure of the
signal could allow near exact reconstruction at much lower sampling rates.
Sparsity of the sampled signal in the frequency domain is one of the popular
priors studied for cognitive radio applications. Reconstruction of signals
under sparsity assumptions has been studied rigorously by researchers in the
field of Compressed Sensing (CS). CS algorithms that operate on batches of
samples are known to be robust but can be computationally costly, making them
unsuitable for cheap low power cognitive radio devices that require spectrum
sensing in real time. On the other hand, on line algorithms that are based on
variations of the Least Mean Squares (LMS) algorithm have very simple updates
so they are computationally efficient and can easily adapt in real time to
changes of the underlying spectrum. In this paper we will present two
variations of the LMS algorithm that enforce sparsity in the estimated spectrum
given an upper bound on the number of non-zero coefficients. Assuming that the
number of non-zero elements in the spectrum is known we show that under
conditions the hard threshold operation can only reduce the error of our
estimation. We will also show that we can estimate the number of non-zero
elements of the spectrum at each iteration based on our online estimations.
Finally, we numerically compare our algorithm with other on line
sparsity-inducing algorithms in the literature.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1608.01128</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2018-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08291</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08300</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical Adversarial Combinatorial Bandit Algorithm via Compression of
  Decision Sets</dc:title>
 <dc:creator>Sakaue, Shinsaku</dc:creator>
 <dc:creator>Ishihata, Masakazu</dc:creator>
 <dc:creator>Minato, Shin-ichi</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the adversarial combinatorial multi-armed bandit (CMAB) problem,
whose decision set can be exponentially large with respect to the number of
given arms. To avoid dealing with such large decision sets directly, we propose
an algorithm performed on a zero-suppressed binary decision diagram (ZDD),
which is a compressed representation of the decision set. The proposed
algorithm achieves either $O(T^{2/3})$ regret with high probability or
$O(\sqrt{T})$ expected regret as the any-time guarantee, where $T$ is the
number of past rounds. Typically, our algorithm works efficiently for CMAB
problems defined on networks. Experimental results show that our algorithm is
applicable to various large adversarial CMAB instances including adaptive
routing problems on real-world networks.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08300</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08301</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph-Based Classification of Omnidirectional Images</dc:title>
 <dc:creator>Khasanova, Renata</dc:creator>
 <dc:creator>Frossard, Pascal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Omnidirectional cameras are widely used in such areas as robotics and virtual
reality as they provide a wide field of view. Their images are often processed
with classical methods, which might unfortunately lead to non-optimal solutions
as these methods are designed for planar images that have different geometrical
properties than omnidirectional ones. In this paper we study image
classification task by taking into account the specific geometry of
omnidirectional cameras with graph-based representations. In particular, we
extend deep learning architectures to data on graphs; we propose a principled
way of graph construction such that convolutional filters respond similarly for
the same pattern on different positions of the image regardless of lens
distortions. Our experiments show that the proposed method outperforms current
techniques for the omnidirectional image classification problem.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08302</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Precoding in Millimeter Wave Systems: How Many Phase Shifters Are
  Needed?</dc:title>
 <dc:creator>Yu, Xianghao</dc:creator>
 <dc:creator>Zhang, Jun</dc:creator>
 <dc:creator>Letaief, Khaled B.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Hybrid precoding has been recently proposed as a cost-effective transceiver
solution for millimeter wave (mm-wave) systems. The analog component in such
precoders, which is composed of a phase shifter network, is the key
differentiating element in contrast to conventional fully digital precoders.
While a large number of phase shifters with unquantized phases are commonly
assumed in existing works, in practice the phase shifters should be discretized
with a coarse quantization, and their number should be reduced to a minimum due
to cost and power consideration. In this paper, we propose a new hybrid
precoder implementation using a small number of phase shifters with quantized
and fixed phases, i.e., a fixed phase shifter (FPS) implementation, which
significantly reduces the cost and hardware complexity. In addition, a dynamic
switch network is proposed to enhance the spectral efficiency. Based on the
proposed FPS implementation, an effective alternating minimization (AltMin)
algorithm is developed with closed-form solutions in each iteration. Simulation
results show that the proposed algorithm with the FPS implementation
outperforms existing ones. More importantly, it needs much fewer phase shifters
than existing hybrid precoder proposals, e.g., $\sim$10 fixed phase shifters
are sufficient for practically relevant system settings.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures, full version of a paper that is accepted to IEEE
  Global Commun. Conf. (GLOBECOM), Singapore, Dec. 2017, complemented with
  proof</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08305</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Non-Orthogonal Multiple Access with Finite-Alphabet Inputs in
  Z-Channels</dc:title>
 <dc:creator>Dong, Zheng</dc:creator>
 <dc:creator>Chen, He</dc:creator>
 <dc:creator>Zhang, Jian-Kang</dc:creator>
 <dc:creator>Huang, Lei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper focuses on the design of non-orthogonal multiple access (NOMA) in
a classical two-transmitter two-receiver Z-channel, wherein one transmitter
sends information to its intended receiver from the direct link while the other
transmitter sends information to both receivers from the direct and cross
links. Unlike most existing designs using (continuous) Gaussian input
distribution, we consider the practical finite-alphabet (i.e., discrete) inputs
by assuming that the widely-used quadrature amplitude modulation (QAM)
constellations are adopted by both transmitters. To balance the error
performance of two receivers, we apply the max-min fairness design criterion in
this paper. More specifically, we propose to jointly optimize the scaling
factors at both transmitters, which control the minimum Euclidean distance of
transmitting constellations, to maximize the smaller minimum Euclidean distance
of two resulting constellations at the receivers, subject to an individual
average power constraint at each transmitter. The formulated problem is a mixed
continuous-discrete optimization problem and is thus intractable in general. By
resorting to the Farey sequence, we manage to attain the closed-form expression
for the optimal solution to the formulated problem. This is achieved by
dividing the overall feasible region of the original optimization problem into
a finite number of sub-intervals and deriving the optimal solution in each
sub-interval. Through carefully observing the structure of the optimal
solutions in all sub-intervals, we obtain compact and closed-form expressions
for the optimal solutions to the original problem in three possible scenarios
defined by the relative strength of the cross link. Simulation studies are
provided to validate our analysis and demonstrate the merits of the proposed
design over existing orthogonal or non-orthogonal schemes.
</dc:description>
 <dc:description>Comment: To appear in IEEE JSAC Special Issue on Non-Orthogonal Multiple
  Access for 5G Systems</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08308</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tensor Contraction &amp; Regression Networks</dc:title>
 <dc:creator>Kossaifi, Jean</dc:creator>
 <dc:creator>Lipton, Zachary C.</dc:creator>
 <dc:creator>Khanna, Aran</dc:creator>
 <dc:creator>Furlanello, Tommaso</dc:creator>
 <dc:creator>Anandkumar, Anima</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Convolution neural networks typically consist of many convolutional layers
followed by several fully-connected layers. While convolutional layers map
between high-order activation tensors, the fully-connected layers operate on
flattened activation vectors. Despite its success, this approach has notable
drawbacks. Flattening discards the multi-dimensional structure of the
activations, and the fully-connected layers require a large number of
parameters. We present two new techniques to address these problems. First, we
introduce tensor contraction layers which can replace the ordinary
fully-connected layers in a neural network. Second, we introduce tensor
regression layers, which express the output of a neural network as a low-rank
multi-linear mapping from a high-order activation tensor to the softmax layer.
Both the contraction and regression weights are learned end-to-end by
backpropagation. By imposing low rank on both, we use significantly fewer
parameters. Experiments on the ImageNet dataset show that applied to the
popular VGG and ResNet architectures, our methods significantly reduce the
number of parameters in the fully connected layers (about 65% space savings)
while negligibly impacting accuracy.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08309</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Graphical Models for Credibility Analysis in Evolving
  Online Communities</dc:title>
 <dc:creator>Mukherjee, Subhabrata</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  One of the major hurdles preventing the full exploitation of information from
online communities is the widespread concern regarding the quality and
credibility of user-contributed content. Prior works in this domain operate on
a static snapshot of the community, making strong assumptions about the
structure of the data (e.g., relational tables), or consider only shallow
features for text classification.
  To address the above limitations, we propose probabilistic graphical models
that can leverage the joint interplay between multiple factors in online
communities --- like user interactions, community dynamics, and textual content
--- to automatically assess the credibility of user-contributed online content,
and the expertise of users and their evolution with user-interpretable
explanation. To this end, we devise new models based on Conditional Random
Fields for different settings like incorporating partial expert knowledge for
semi-supervised learning, and handling discrete labels as well as numeric
ratings for fine-grained analysis. This enables applications such as extracting
reliable side-effects of drugs from user-contributed posts in healthforums, and
identifying credible content in news communities.
  Online communities are dynamic, as users join and leave, adapt to evolving
trends, and mature over time. To capture this dynamics, we propose generative
models based on Hidden Markov Model, Latent Dirichlet Allocation, and Brownian
Motion to trace the continuous evolution of user expertise and their language
model over time. This allows us to identify expert users and credible content
jointly over time, improving state-of-the-art recommender systems by explicitly
considering the maturity of users. This also enables applications such as
identifying helpful product reviews, and detecting fake and anomalous reviews
with limited information.
</dc:description>
 <dc:description>Comment: PhD thesis, Mar 2017</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08310</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simultaneous Sparse Approximation Using an Iterative Method with
  Adaptive Thresholding</dc:title>
 <dc:creator>Kiani, Shahrzad</dc:creator>
 <dc:creator>Sadrizadeh, Sahar</dc:creator>
 <dc:creator>Boloursaz, Mahdi</dc:creator>
 <dc:creator>Marvasti, Farokh</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies the problem of Simultaneous Sparse Approximation (SSA).
This problem arises in many applications which work with multiple signals
maintaining some degree of dependency such as radar and sensor networks. In
this paper, we introduce a new method towards joint recovery of several
independent sparse signals with the same support. We provide an analytical
discussion on the convergence of our method called Simultaneous Iterative
Method with Adaptive Thresholding (SIMAT). Additionally, we compare our method
with other group-sparse reconstruction techniques, i.e., Simultaneous
Orthogonal Matching Pursuit (SOMP), and Block Iterative Method with Adaptive
Thresholding (BIMAT) through numerical experiments. The simulation results
demonstrate that SIMAT outperforms these algorithms in terms of the metrics
Signal to Noise Ratio (SNR) and Success Rate (SR). Moreover, SIMAT is
considerably less complicated than BIMAT, which makes it feasible for practical
applications such as implementation in MIMO radar systems.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08313</identifier>
 <datestamp>2017-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cascaded Scene Flow Prediction using Semantic Segmentation</dc:title>
 <dc:creator>Ren, Zhile</dc:creator>
 <dc:creator>Sun, Deqing</dc:creator>
 <dc:creator>Kautz, Jan</dc:creator>
 <dc:creator>Sudderth, Erik B.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Given two consecutive frames from a pair of stereo cameras, 3D scene flow
methods simultaneously estimate the 3D geometry and motion of the observed
scene. Many existing approaches use superpixels for regularization, but may
predict inconsistent shapes and motions inside rigidly moving objects. We
instead assume that scenes consist of foreground objects rigidly moving in
front of a static background, and use semantic cues to produce pixel-accurate
scene flow estimates. Our cascaded classification framework accurately models
3D scenes by iteratively refining semantic segmentation masks, stereo
correspondences, 3D rigid motion estimates, and optical flow fields. We
evaluate our method on the challenging KITTI autonomous driving benchmark, and
show that accounting for the motion of segmented vehicles leads to
state-of-the-art performance.
</dc:description>
 <dc:description>Comment: International Conference on 3D Vision (3DV), 2017 (oral presentation)</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-10-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08316</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Sparse Representations in Reinforcement Learning with Sparse
  Coding</dc:title>
 <dc:creator>Le, Lei</dc:creator>
 <dc:creator>Kumaraswamy, Raksha</dc:creator>
 <dc:creator>White, Martha</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A variety of representation learning approaches have been investigated for
reinforcement learning; much less attention, however, has been given to
investigating the utility of sparse coding. Outside of reinforcement learning,
sparse coding representations have been widely used, with non-convex objectives
that result in discriminative representations. In this work, we develop a
supervised sparse coding objective for policy evaluation. Despite the
non-convexity of this objective, we prove that all local minima are global
minima, making the approach amenable to simple optimization strategies. We
empirically show that it is key to use a supervised objective, rather than the
more straightforward unsupervised sparse coding approach. We compare the
learned representations to a canonical fixed sparse representation, called
tile-coding, demonstrating that the sparse coding representation outperforms a
wide variety of tilecoding representations.
</dc:description>
 <dc:description>Comment: 6(+1) pages, 2 figures, International Joint Conference on Artificial
  Intelligence 2017</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08322</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discrete Latent Factor Model for Cross-Modal Hashing</dc:title>
 <dc:creator>Jiang, Qing-Yuan</dc:creator>
 <dc:creator>Li, Wu-Jun</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Due to its storage and retrieval efficiency, cross-modal hashing~(CMH) has
been widely used for cross-modal similarity search in multimedia applications.
According to the training strategy, existing CMH methods can be mainly divided
into two categories: relaxation-based continuous methods and discrete methods.
In general, the training of relaxation-based continuous methods is faster than
discrete methods, but the accuracy of relaxation-based continuous methods is
not satisfactory. On the contrary, the accuracy of discrete methods is
typically better than relaxation-based continuous methods, but the training of
discrete methods is time-consuming. In this paper, we propose a novel CMH
method, called discrete latent factor model based cross-modal hashing~(DLFH),
for cross modal similarity search. DLFH is a discrete method which can directly
learn the binary hash codes for CMH. At the same time, the training of DLFH is
efficient. Experiments on real datasets show that DLFH can achieve
significantly better accuracy than existing methods, and the training time of
DLFH is comparable to that of relaxation-based continuous methods which are
much faster than existing discrete methods.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08323</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pigmento: Pigment-Based Image Analysis and Editing</dc:title>
 <dc:creator>Tan, Jianchao</dc:creator>
 <dc:creator>DiVerdi, Stephen</dc:creator>
 <dc:creator>Lu, Jingwan</dc:creator>
 <dc:creator>Gingold, Yotam</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  The colorful appearance of a physical painting is determined by the
distribution of paint pigments across the canvas, which we model as a per-pixel
mixture of a small number of pigments with multispectral absorption and
scattering coefficients. We present an algorithm to efficiently recover this
structure from an RGB image, yielding a plausible set of pigments and a low RGB
reconstruction error. We show that under certain circumstances we are able to
recover pigments that are close to ground truth, while in all cases our results
are always plausible. Using our decomposition, we repose standard digital image
editing operations as operations in pigment space rather than RGB, with
interestingly novel results. We demonstrate tonal adjustments, selection
masking, cut-copy-paste, recoloring, palette summarization, and edge
enhancement.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08323</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08325</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymmetric Deep Supervised Hashing</dc:title>
 <dc:creator>Jiang, Qing-Yuan</dc:creator>
 <dc:creator>Li, Wu-Jun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Hashing has been widely used for large-scale approximate nearest neighbor
search because of its storage and search efficiency. Recent work has found that
deep supervised hashing can significantly outperform non-deep supervised
hashing in many applications. However, most existing deep supervised hashing
methods adopt a symmetric strategy to learn one deep hash function for both
query points and database (retrieval) points. The training of these symmetric
deep supervised hashing methods is typically time-consuming, which makes them
hard to effectively utilize the supervised information for cases with
large-scale database. In this paper, we propose a novel deep supervised hashing
method, called asymmetric deep supervised hashing (ADSH), for large-scale
nearest neighbor search. ADSH treats the query points and database points in an
asymmetric way. More specifically, ADSH learns a deep hash function only for
query points, while the hash codes for database points are directly learned.
The training of ADSH is much more efficient than that of traditional symmetric
deep supervised hashing methods. Experiments show that ADSH can achieve
state-of-the-art performance in real applications.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08340</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structure-Preserving Image Super-resolution via Contextualized
  Multi-task Learning</dc:title>
 <dc:creator>Shi, Yukai</dc:creator>
 <dc:creator>Wang, Keze</dc:creator>
 <dc:creator>Chen, Chongyu</dc:creator>
 <dc:creator>Xu, Li</dc:creator>
 <dc:creator>Lin, Liang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Single image super resolution (SR), which refers to reconstruct a
higher-resolution (HR) image from the observed low-resolution (LR) image, has
received substantial attention due to its tremendous application potentials.
Despite the breakthroughs of recently proposed SR methods using convolutional
neural networks (CNNs), their generated results usually lack of preserving
structural (high-frequency) details. In this paper, regarding global boundary
context and residual context as complimentary information for enhancing
structural details in image restoration, we develop a contextualized multi-task
learning framework to address the SR problem. Specifically, our method first
extracts convolutional features from the input LR image and applies one
deconvolutional module to interpolate the LR feature maps in a content-adaptive
way. Then, the resulting feature maps are fed into two branched sub-networks.
During the neural network training, one sub-network outputs salient image
boundaries and the HR image, and the other sub-network outputs the local
residual map, i.e., the residual difference between the generated HR image and
ground-truth image. On several standard benchmarks (i.e., Set5, Set14 and
BSD200), our extensive evaluations demonstrate the effectiveness of our SR
method on achieving both higher restoration quality and computational
efficiency compared with several state-of-the-art SR approaches. The source
code and some SR results can be found at:
http://hcp.sysu.edu.cn/structure-preserving-image-super-resolution/
</dc:description>
 <dc:description>Comment: To appear in Transactions on Multimedia 2017</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08340</dc:identifier>
 <dc:identifier>doi:10.1109/TMM.2017.2711263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08341</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Activity-Based Quality Model for Maintainability</dc:title>
 <dc:creator>Deissenboeck, Florian</dc:creator>
 <dc:creator>Wagner, Stefan</dc:creator>
 <dc:creator>Pizka, Markus</dc:creator>
 <dc:creator>Teuchert, Stefan</dc:creator>
 <dc:creator>Girard, Jean-Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Maintainability is a key quality attribute of successful software systems.
However, its management in practice is still problematic. Currently, there is
no comprehensive basis for assessing and improving the maintainability of
software systems. Quality models have been proposed to solve this problem.
Nevertheless, existing approaches do not explicitly take into account the
maintenance activities, that largely determine the software maintenance effort.
This paper proposes a 2-dimensional model of maintainability that explicitly
associates system properties with the activities carried out during
maintenance. The separation of activities and properties facilitates the
identification of sound quality criteria and allows to reason about their
interdependencies. This transforms the quality model into a structured and
comprehensive quality knowledge base that is usable in industrial project
environments. For example, review guidelines can be generated from it. The
model is based on an explicit quality metamodel that supports its systematic
construction and fosters preciseness as well as completeness. An industrial
case study demonstrates the applicability of the model for the evaluation of
the maintainability of Matlab Simulink models that are frequently used in
model-based development of embedded systems.
</dc:description>
 <dc:description>Comment: 11 pages, 6 figures</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08341</dc:identifier>
 <dc:identifier>Proc. IEEE International Conference on Software Maintenance (ICSM
  2007). IEEE, 2007</dc:identifier>
 <dc:identifier>doi:10.1109/ICSM.2007.4362631</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08342</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Declarative Sequential Pattern Mining of Care Pathways</dc:title>
 <dc:creator>Guyet, Thomas</dc:creator>
 <dc:creator>Happe, Andr&#xe9;</dc:creator>
 <dc:creator>Dauxais, Yann</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Sequential pattern mining algorithms are widely used to explore care pathways
database, but they generate a deluge of patterns, mostly redundant or useless.
Clinicians need tools to express complex mining queries in order to generate
less but more significant patterns. These algorithms are not versatile enough
to answer complex clinician queries. This article proposes to apply a
declarative pattern mining approach based on Answer Set Programming paradigm.
It is exemplified by a pharmaco-epidemiological study investigating the
possible association between hospitalization for seizure and antiepileptic drug
switch from a french medico-administrative database.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08342</dc:identifier>
 <dc:identifier>Conference on Artificial Intelligence in Medicine in Europe, Jun
  2017, Vienna, Austria. 24, pp.1161 - 266, 2017</dc:identifier>
 <dc:identifier>doi:10.1002/pds.3879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08347</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RankIQA: Learning from Rankings for No-reference Image Quality
  Assessment</dc:title>
 <dc:creator>Liu, Xialei</dc:creator>
 <dc:creator>van de Weijer, Joost</dc:creator>
 <dc:creator>Bagdanov, Andrew D.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a no-reference image quality assessment (NR-IQA) approach that
learns from rankings (RankIQA). To address the problem of limited IQA dataset
size, we train a Siamese Network to rank images in terms of image quality by
using synthetically generated distortions for which relative image quality is
known. These ranked image sets can be automatically generated without laborious
human labeling. We then use fine-tuning to transfer the knowledge represented
in the trained Siamese Network to a traditional CNN that estimates absolute
image quality from single images. We demonstrate how our approach can be made
significantly more efficient than traditional Siamese Networks by forward
propagating a batch of images through a single network and backpropagating
gradients derived from all pairs of images in the batch. Experiments on the
TID2013 benchmark show that we improve the state-of-the-art by over 5%.
Furthermore, on the LIVE benchmark we show that our approach is superior to
existing NR-IQA techniques and that we even outperform the state-of-the-art in
full-reference IQA (FR-IQA) methods without having to resort to high-quality
reference images to infer IQA.
</dc:description>
 <dc:description>Comment: Accepted by ICCV 2017</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08349</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can string kernels pass the test of time in Native Language
  Identification?</dc:title>
 <dc:creator>Ionescu, Radu Tudor</dc:creator>
 <dc:creator>Popescu, Marius</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We describe a machine learning approach for the 2017 shared task on Native
Language Identification (NLI). The proposed approach combines several kernels
using multiple kernel learning. While most of our kernels are based on
character p-grams (also known as n-grams) extracted from essays or speech
transcripts, we also use a kernel based on i-vectors, a low-dimensional
representation of audio recordings, provided by the shared task organizers. For
the learning stage, we choose Kernel Discriminant Analysis (KDA) over Kernel
Ridge Regression (KRR), because the former classifier obtains better results
than the latter one on the development set. In our previous work, we have used
a similar machine learning approach to achieve state-of-the-art NLI results.
The goal of this paper is to demonstrate that our shallow and simple approach
based on string kernels (with minor improvements) can pass the test of time and
reach state-of-the-art performance in the 2017 NLI shared task, despite the
recent advances in natural language processing. We participated in all three
tracks, in which the competitors were allowed to use only the essays (essay
track), only the speech transcripts (speech track), or both (fusion track).
Using only the data provided by the organizers for training our models, we have
reached a macro F1 score of 86.95% in the closed essay track, a macro F1 score
of 87.55% in the closed speech track, and a macro F1 score of 93.19% in the
closed fusion track. With these scores, our team (UnibucKernel) ranked in the
first group of teams in all three tracks, while attaining the best scores in
the speech and the fusion tracks.
</dc:description>
 <dc:description>Comment: In Proceedings of the 12th Workshop on Building Educational
  Applications Using NLP, 2017</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08350</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling the Scene Dependent Imaging in Cameras with a Deep Neural
  Network</dc:title>
 <dc:creator>Nam, Seonghyeon</dc:creator>
 <dc:creator>Kim, Seon Joo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a novel deep learning framework that models the scene dependent
image processing inside cameras. Often called as the radiometric calibration,
the process of recovering RAW images from processed images (JPEG format in the
sRGB color space) is essential for many computer vision tasks that rely on
physically accurate radiance values. All previous works rely on the
deterministic imaging model where the color transformation stays the same
regardless of the scene and thus they can only be applied for images taken
under the manual mode. In this paper, we propose a data-driven approach to
learn the scene dependent and locally varying image processing inside cameras
under the automode. Our method incorporates both the global and the local scene
context into pixel-wise features via multi-scale pyramid of learnable histogram
layers. The results show that we can model the imaging pipeline of different
cameras that operate under the automode accurately in both directions (from RAW
to sRGB, from sRGB to RAW) and we show how we can apply our method to improve
the performance of image deblurring.
</dc:description>
 <dc:description>Comment: To appear in ICCV 2017</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08352</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>General Latent Feature Modeling for Data Exploration Tasks</dc:title>
 <dc:creator>Valera, Isabel</dc:creator>
 <dc:creator>Pradier, Melanie F.</dc:creator>
 <dc:creator>Ghahramani, Zoubin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper introduces a general Bayesian non- parametric latent feature model
suitable to per- form automatic exploratory analysis of heterogeneous datasets,
where the attributes describing each object can be either discrete, continuous
or mixed variables. The proposed model presents several important properties.
First, it accounts for heterogeneous data while can be inferred in linear time
with respect to the number of objects and attributes. Second, its Bayesian
nonparametric nature allows us to automatically infer the model complexity from
the data, i.e., the number of features necessary to capture the latent
structure in the data. Third, the latent features in the model are
binary-valued variables, easing the interpretability of the obtained latent
features in data exploration tasks.
</dc:description>
 <dc:description>Comment: presented at 2017 ICML Workshop on Human Interpretability in Machine
  Learning (WHI 2017), Sydney, NSW, Australia</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08352</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08357</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Comparison of Various STM Concurrency Control Protocols
  Using Synchrobench</dc:title>
 <dc:creator>Singh, Ajay</dc:creator>
 <dc:creator>Peri, Sathya</dc:creator>
 <dc:creator>Monika, G</dc:creator>
 <dc:creator>Kumari, Anila</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Writing concurrent programs for shared memory multiprocessor systems is a
nightmare. This hinders users to exploit the full potential of multiprocessors.
STM (Software Transactional Memory) is a promising concurrent programming
paradigm which addresses woes of programming for multiprocessor systems.
  In this paper, we implement BTO (Basic Timestamp Ordering), SGT
(Serialization Graph Testing) and MVTO(Multi-Version Time-Stamp Ordering)
concurrency control protocols and build an STM(Software Transactional Memory)
library to evaluate the performance of these protocols. The deferred write
approach is followed to implement the STM. A SET data structure is implemented
using the transactions of our STM library. And this transactional SET is used
as a test application to evaluate the STM. The performance of the protocols is
rigorously compared against the linked-list module of the Synchrobench
benchmark. Linked list module implements SET data structure using lazy-list,
lock-free list, lock-coupling list and ESTM (Elastic Software Transactional
Memory).
  Our analysis shows that for a number of threads greater than 60 and update
rate 70%, BTO takes (17% to 29%) and (6% to 24%) less CPU time per thread when
compared against lazy-list and lock-coupling list respectively. MVTO takes (13%
to 24%) and (3% to 24%) less CPU time per thread when compared against
lazy-list and lock-coupling list respectively. BTO and MVTO have similar per
thread CPU time. BTO and MVTO outperform SGT by 9% to 36%.
</dc:description>
 <dc:description>Comment: 7 pages, 10 figures, This work was selected and presented at
  PARCOMPTECH 2017 : National Conference on Parallel Computing Technologies
  PARCOMPTECH 17</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08358</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Notes on optimal approximations for importance sampling</dc:title>
 <dc:creator>Pantaleoni, Jacopo</dc:creator>
 <dc:creator>Heitz, Eric</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  In this manuscript, we derive optimal conditions for building function
approximations that minimize variance when used as importance sampling
estimators for Monte Carlo integration problems. Particularly, we study the
problem of finding the optimal projection $g$ of an integrand $f$ onto certain
classes of piecewise constant functions, in order to minimize the variance of
the unbiased importance sampling estimator $E_g[f/g]$, as well as the related
problem of finding optimal mixture weights to approximate and importance sample
a target mixture distribution $f = \sum_i \alpha_i f_i$ with components $f_i$
in a family $\mathcal{F}$, through a corresponding mixture of importance
sampling densities $g_i$ that are only approximately proportional to $f_i$. We
further show that in both cases the optimal projection is different from the
commonly used $\ell_1$ projection, and provide an intuitive explanation for the
difference.
</dc:description>
 <dc:description>Comment: 4 pages, 1 figure</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08359</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Optimization Based Control Framework for Balancing and Walking:
  Implementation on the iCub Robot</dc:title>
 <dc:creator>Charbonneau, Marie</dc:creator>
 <dc:creator>Nava, Gabriele</dc:creator>
 <dc:creator>Nori, Francesco</dc:creator>
 <dc:creator>Pucci, Daniele</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  A whole-body torque control framework adapted for balancing and walking tasks
is presented in this paper. In the proposed approach, centroidal momentum terms
are excluded in favor of a hierarchy of high-priority position and orientation
tasks and a low-priority postural task. More specifically, the controller
stabilizes the position of the center of mass, the orientation of the pelvis
frame, as well as the position and orientation of the feet frames. The
low-priority postural task provides reference positions for each joint of the
robot. Joint torques and contact forces to stabilize tasks are obtained through
quadratic programming optimization. Besides the exclusion of centroidal
momentum terms, part of the novelty of the approach lies in the definition of
control laws in SE(3) which do not require the use of Euler parameterization.
Validation of the framework was achieved in a scenario where the robot kept
balance while walking in place. Experiments have been conducted with the iCub
robot, in simulation and in real-world experiments.
</dc:description>
 <dc:description>Comment: manuscript submitted to Humanoids 2017</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08360</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discrete Geodesic Nets for Modeling Developable Surfaces</dc:title>
 <dc:creator>Rabinovich, Michael</dc:creator>
 <dc:creator>Hoffmann, Tim</dc:creator>
 <dc:creator>Sorkine-Hornung, Olga</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:description>  We present a discrete theory for modeling developable surfaces as
quadrilateral meshes satisfying simple angle constraints. The basis of our
model is a lesser known characterization of developable surfaces as manifolds
that can be parameterized through orthogonal geodesics. Our model is simple,
local, and, unlike previous works, it does not directly encode the surface
rulings. This allows us to model continuous deformations of discrete
developable surfaces independently of their decomposition into torsal and
planar patches or the surface topology. We prove and experimentally demonstrate
strong ties to smooth developable surfaces, including a theorem stating that
every sampling of the smooth counterpart satisfies our constraints up to second
order. We further present an extension of our model that enables a local
definition of discrete isometry. We demonstrate the effectiveness of our
discrete model in a developable surface editing system, as well as computation
of an isometric interpolation between isometric discrete developable shapes.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08360</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08361</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supermetric Search</dc:title>
 <dc:creator>Connor, Richard</dc:creator>
 <dc:creator>Vadicamo, Lucia</dc:creator>
 <dc:creator>Cardillo, Franco Alberto</dc:creator>
 <dc:creator>Rabitti, Fausto</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  Metric search is concerned with the efficient evaluation of queries in metric
spaces. In general,a large space of objects is arranged in such a way that,
when a further object is presented as a query, those objects most similar to
the query can be efficiently found. Most mechanisms rely upon the triangle
inequality property of the metric governing the space. The triangle inequality
property is equivalent to a finite embedding property, which states that any
three points of the space can be isometrically embedded in two-dimensional
Euclidean space. In this paper, we examine a class of semimetric space which is
finitely four-embeddable in three-dimensional Euclidean space. In mathematics
this property has been extensively studied and is generally known as the
four-point property. All spaces with the four-point property are metric spaces,
but they also have some stronger geometric guarantees. We coin the term
supermetric space as, in terms of metric search, they are significantly more
tractable. Supermetric spaces include all those governed by Euclidean, Cosine,
Jensen-Shannon and Triangular distances, and are thus commonly used within many
domains. In previous work we have given a generic mathematical basis for the
supermetric property and shown how it can improve indexing performance for a
given exact search structure. Here we present a full investigation into its use
within a variety of different hyperplane partition indexing structures, and go
on to show some more of its flexibility by examining a search structure whose
partition and exclusion conditions are tailored, at each node, to suit the
individual reference points and data set present there. Among the results
given, we show a new best performance for exact search using a well-known
benchmark.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-10-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08364</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Interactive Region Segmentation and Captioning</dc:title>
 <dc:creator>Boroujerdi, Ali Sharifi</dc:creator>
 <dc:creator>Khanian, Maryam</dc:creator>
 <dc:creator>Breuss, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>68T45</dc:subject>
 <dc:description>  With recent innovations in dense image captioning, it is now possible to
describe every object of the scene with a caption while objects are determined
by bounding boxes. However, interpretation of such an output is not trivial due
to the existence of many overlapping bounding boxes. Furthermore, in current
captioning frameworks, the user is not able to involve personal preferences to
exclude out of interest areas. In this paper, we propose a novel hybrid deep
learning architecture for interactive region segmentation and captioning where
the user is able to specify an arbitrary region of the image that should be
processed. To this end, a dedicated Fully Convolutional Network (FCN) named
Lyncean FCN (LFCN) is trained using our special training data to isolate the
User Intention Region (UIR) as the output of an efficient segmentation. In
parallel, a dense image captioning model is utilized to provide a wide variety
of captions for that region. Then, the UIR will be explained with the caption
of the best match bounding box. To the best of our knowledge, this is the first
work that provides such a comprehensive output. Our experiments show the
superiority of the proposed approach over state-of-the-art interactive
segmentation methods on several well-known datasets. In addition, replacement
of the bounding boxes with the result of the interactive segmentation leads to
a better understanding of the dense image captioning output as well as accuracy
enhancement for the object detection in terms of Intersection over Union (IoU).
</dc:description>
 <dc:description>Comment: 17, pages, 9 figures</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08364</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08369</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Updating Singular Value Decomposition for Rank One Matrix Perturbation</dc:title>
 <dc:creator>Gandhi, Ratnik</dc:creator>
 <dc:creator>Rajgor, Amoli</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  An efficient Singular Value Decomposition (SVD) algorithm is an important
tool for distributed and streaming computation in big data problems. It is
observed that update of singular vectors of a rank-1 perturbed matrix is
similar to a Cauchy matrix-vector product. With this observation, in this
paper, we present an efficient method for updating Singular Value Decomposition
of rank-1 perturbed matrix in $O(n^2 \ \text{log}(\frac{1}{\epsilon}))$ time.
The method uses Fast Multipole Method (FMM) for updating singular vectors in
$O(n \ \text{log} (\frac{1}{\epsilon}))$ time, where $\epsilon$ is the
precision of computation.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08369</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08370</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Dimensional Simplexes for Supermetric Search</dc:title>
 <dc:creator>Connor, Richard</dc:creator>
 <dc:creator>Vadicamo, Lucia</dc:creator>
 <dc:creator>Rabitti, Fausto</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  In 1953, Blumenthal showed that every semi-metric space that is isometrically
embeddable in a Hilbert space has the n-point property; we have previously
called such spaces supermetric spaces. Although this is a strictly stronger
property than triangle inequality, it is nonetheless closely related and many
useful metric spaces possess it. These include Euclidean, Cosine and
Jensen-Shannon spaces of any dimension. A simple corollary of the n-point
property is that, for any (n+1) objects sampled from the space, there exists an
n-dimensional simplex in Euclidean space whose edge lengths correspond to the
distances among the objects. We show how the construction of such simplexes in
higher dimensions can be used to give arbitrarily tight lower and upper bounds
on distances within the original space. This allows the construction of an
n-dimensional Euclidean space, from which lower and upper bounds of the
original space can be calculated, and which is itself an indexable space with
the n-point property. For similarity search, the engineering tradeoffs are
good: we show significant reductions in data size and metric cost with little
loss of accuracy, leading to a significant overall improvement in search
performance.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08373</identifier>
 <datestamp>2017-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recursive simplex stars</dc:title>
 <dc:creator>Deffuant, Guillaume</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  This paper proposes a new method which approximates a classification function
separating a $d$ dimensional compact set into two parts. The approach starts by
estimating the intersection between the classification boundary and the edges
of a regular grid covering the compact set. Then it builds a classification
surface made of recursive simplex stars (resistars) defined in the grid cubes
containing such boundary points. A first variant, the simple resistar
(s-resistar) defines a single star of simplices which share the barycentre of
the cube boundary points and include stars of simplices defined similarly in
cube facets, and so on recursively until a face boundary points define a single
simplex. This definition is simple and easy to apply when the dimensionality
increases. However, s-resistars sometimes &quot;glue&quot; together surfaces that should
be separated and this deteriorates the local classification performance. The
second variant, the multi-boundary resistar (or m-resistar) addresses this
problem by defining several simplex stars in a cube or in its faces when
necessary, which is shown to increase the local classification performance.
With both s-resistars and m-resistars, classifying a point requires only a
small number of simple tests without explicitly computing the simplices. It is
thus possible to use resistar classification in spaces of relatively high
dimensionality (up to 9 in our tests) and for resistar surfaces including a
large number of simplices (up to several trillions in our tests). The paper
provides a theoretical argument and empirical evidence suggesting that, when
the surface to approximate is smooth enough, the error of resistar
classification decreases as $\mathcal{O}(n_G^{-2})$ for a grid of size $n_G^d$
in $d$ dimensions, whereas this error decreases as $\mathcal{O}(n_G^{-1})$ when
classifying with the sign of the nearest vertex of the grid.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08373</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08375</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time Warping and Interpolation Operators for Piecewise Smooth Maps</dc:title>
 <dc:creator>Caporale, Salvatore</dc:creator>
 <dc:creator>Petillot, Yvan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65T40</dc:subject>
 <dc:subject>B.2.4</dc:subject>
 <dc:subject>G.1.1</dc:subject>
 <dc:description>  A warping operator consists of an invertible axis deformation applied either
in the signal domain or in the corresponding Fourier domain. Additionally, a
warping transformation is usually required to preserve the signal energy, thus
preserving orthogonality and being invertible by its adjoint. Initially, the
design of such operators has been motivated by the idea of suitably
generalizing the properties of orthogonal time-frequency decompositions such as
wavelets and filter banks, hence the energy preservation property was
essential. Recently, warping operators have been employed for frequency
dispersion compensation in the Fourier domain or the identification of
waveforms similarity in the time domain. For such applications, the energy
preservation requirement can be given up, thus making warping a special case of
interpolation. In this context, the purpose of this work is to provide
analytical models and efficient computational algorithms for time warping with
respect to piecewise smooth warping maps by transposing and extending a
theoretical framework which has been previously introduced for frequency
warping. Moreover, the same approach is generalized to the case of warping
without energy preservation, thus obtaining a fast interpolation operator with
analytically defined and fast inverse operator.
</dc:description>
 <dc:description>Comment: 13 pages, 7 figures, plus 5 page appendixes</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08375</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08378</identifier>
 <datestamp>2017-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Product recognition in store shelves as a sub-graph isomorphism problem</dc:title>
 <dc:creator>Tonioni, Alessio</dc:creator>
 <dc:creator>Di Stefano, Luigi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The arrangement of products in store shelves is carefully planned to maximize
sales and keep customers happy. However, verifying compliance of real shelves
to the ideal layout is a costly task routinely performed by the store
personnel. In this paper, we propose a computer vision pipeline to recognize
products on shelves and verify compliance to the planned layout. We deploy
local invariant features together with a novel formulation of the product
recognition problem as a sub-graph isomorphism between the items appearing in
the given image and the ideal layout. This allows for auto-localizing the given
image within the aisle or store and improving recognition dramatically.
</dc:description>
 <dc:description>Comment: Slightly extended version of the paper accepted at ICIAP 2017. More
  information @project_page --&gt;
  http://vision.disi.unibo.it/index.php?option=com_content&amp;view=article&amp;id=111&amp;catid=78</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08378</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08380</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Internet of Hackable Things</dc:title>
 <dc:creator>Dragoni, Nicola</dc:creator>
 <dc:creator>Giaretta, Alberto</dc:creator>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The Internet of Things makes possible to connect each everyday object to the
Internet, making computing pervasive like never before. From a security and
privacy perspective, this tsunami of connectivity represents a disaster, which
makes each object remotely hackable. We claim that, in order to tackle this
issue, we need to address a new challenge in security: education.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08380</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-70578-1_13</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08381</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prediction of amino acid side chain conformation using a deep neural
  network</dc:title>
 <dc:creator>Liu, Ke</dc:creator>
 <dc:creator>Sun, Xiangyan</dc:creator>
 <dc:creator>Ma, Jun</dc:creator>
 <dc:creator>Zhou, Zhenyu</dc:creator>
 <dc:creator>Dong, Qilin</dc:creator>
 <dc:creator>Peng, Shengwen</dc:creator>
 <dc:creator>Wu, Junqiu</dc:creator>
 <dc:creator>Tan, Suocheng</dc:creator>
 <dc:creator>Blobel, G&#xfc;nter</dc:creator>
 <dc:creator>Fan, Jie</dc:creator>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A deep neural network based architecture was constructed to predict amino
acid side chain conformation with unprecedented accuracy. Amino acid side chain
conformation prediction is essential for protein homology modeling and protein
design. Current widely-adopted methods use physics-based energy functions to
evaluate side chain conformation. Here, using a deep neural network
architecture without physics-based assumptions, we have demonstrated that side
chain conformation prediction accuracy can be improved by more than 25%,
especially for aromatic residues compared with current standard methods. More
strikingly, the prediction method presented here is robust enough to identify
individual conformational outliers from high resolution structures in a protein
data bank without providing its structural factors. We envisage that our amino
acid side chain predictor could be used as a quality check step for future
protein structure model validation and many other potential applications such
as side chain assignment in Cryo-electron microscopy, crystallography model
auto-building, protein folding and small molecule ligand docking.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08385</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Transfer Learning Approach upon Hindi, Arabic, and Bangla
  Numerals using Convolutional Neural Networks</dc:title>
 <dc:creator>Tushar, Abdul Kawsar</dc:creator>
 <dc:creator>Ashiquzzaman, Akm</dc:creator>
 <dc:creator>Afrin, Afia</dc:creator>
 <dc:creator>Islam, Md. Rashedul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Increased accuracy in predictive models for handwritten character recognition
will open up new frontiers for optical character recognition. Major drawbacks
of predictive machine learning models are headed by the elongated training time
taken by some models, and the requirement that training and test data be in the
same feature space and consist of the same distribution. In this study, these
obstacles are minimized by presenting a model for transferring knowledge from
one task to another. This model is presented for the recognition of handwritten
numerals in Indic languages. The model utilizes convolutional neural networks
with backpropagation for error reduction and dropout for data overfitting. The
output performance of the proposed neural network is shown to have closely
matched other state-of-the-art methods using only a fraction of time used by
the state-of-the-arts.
</dc:description>
 <dc:description>Comment: 10 pages; 2 figures, 4 tables; conference - International Conference
  On Computational Vision and Bio Inspired Computing 2017 (http://iccvbic.com/)
  (accepted)</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08386</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reduction of Overfitting in Diabetes Prediction Using Deep Learning
  Neural Network</dc:title>
 <dc:creator>Ashiquzzaman, Akm</dc:creator>
 <dc:creator>Tushar, Abdul Kawsar</dc:creator>
 <dc:creator>Islam, Md. Rashedul</dc:creator>
 <dc:creator>Kim, Jong-Myon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Augmented accuracy in prediction of diabetes will open up new frontiers in
health prognostics. Data overfitting is a performance-degrading issue in
diabetes prognosis. In this study, a prediction system for the disease of
diabetes is pre-sented where the issue of overfitting is minimized by using the
dropout method. Deep learning neural network is used where both fully connected
layers are fol-lowed by dropout layers. The output performance of the proposed
neural network is shown to have outperformed other state-of-art methods and it
is recorded as by far the best performance for the Pima Indians Diabetes Data
Set.
</dc:description>
 <dc:description>Comment: 8 pages, 3 Figures, 3 Tables; Conference - 7th iCatse International
  Conference on IT Convergence and Security, 2017
  (http://icatse.org/icitcs2017/) (accepted)</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08389</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Composition problems for braids: Membership, Identity and Freeness</dc:title>
 <dc:creator>Ko, Sang-Ki</dc:creator>
 <dc:creator>Potapov, Igor</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  In this paper we investigate the decidability and complexity of problems
related to braid composition. While all known problems for a class of braids
with three strands, $B_3$, have polynomial time solutions we prove that a very
natural question for braid composition, the membership problem, is NP-complete
for braids with only three strands. The membership problem is decidable in NP
for $B_3$, but it becomes harder for a class of braids with more strands. In
particular we show that fundamental problems about braid compositions are
undecidable for braids with at least five strands, but decidability of these
problems for $B_4$ remains open. Finally we show that the freeness problem for
semigroups of braids from $B_3$ is also decidable in NP.
  The paper introduces a few challenging algorithmic problems about topological
braids opening new connections between braid groups, combinatorics on words,
complexity theory and provides solutions for some of these problems by
application of several techniques from automata theory, matrix semigroups and
algorithms.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08389</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08390</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What You Sketch Is What You Get: 3D Sketching using Multi-View Deep
  Volumetric Prediction</dc:title>
 <dc:creator>Delanoy, Johanna</dc:creator>
 <dc:creator>Bousseau, Adrien</dc:creator>
 <dc:creator>Aubry, Mathieu</dc:creator>
 <dc:creator>Isola, Phillip</dc:creator>
 <dc:creator>Efros, Alexei A.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:description>  Sketch-based modeling strives to bring the ease and immediacy of drawing to
the 3D world. However, while drawings are easy for humans to create, they are
very challenging for computers to interpret due to their sparsity and
ambiguity. We propose a data-driven approach that tackles this challenge by
learning to reconstruct 3D shapes from one or more drawings. At the core of our
approach is a deep convolutional neural network (CNN) that predicts occupancy
of a voxel grid from a line drawing. This CNN provides us with an initial 3D
reconstruction as soon as the user completes a single drawing of the desired
shape. We complement this single-view network with an updater CNN that refines
an existing prediction given a new drawing of the shape created from a novel
viewpoint. A key advantage of our approach is that we can apply the updater
iteratively to fuse information from an arbitrary number of viewpoints, without
requiring explicit stroke correspondences between the drawings. We train both
CNNs by rendering synthetic contour drawings from hand-modeled shape
collections as well as from procedurally-generated abstract shapes. Finally, we
integrate our CNNs in a minimal modeling interface that allows users to
seamlessly draw an object, rotate it to see its 3D reconstruction, and refine
it by re-drawing from another vantage point using the 3D reconstruction as
guidance. The main strengths of our approach are its robustness to freehand
bitmap drawings, its ability to adapt to different object categories, and the
continuum it offers between single-view and multi-view sketch-based modeling.
</dc:description>
 <dc:description>Comment: See our accompanying video on https://youtu.be/DGIYzmlm2pQ</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08390</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08391</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximum entropy based non-negative optoacoustic tomographic image
  reconstruction</dc:title>
 <dc:creator>Prakash, Jaya</dc:creator>
 <dc:creator>Mandal, Subhamoy</dc:creator>
 <dc:creator>Razansky, Daniel</dc:creator>
 <dc:creator>Ntziachristos, Vasilis</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Optoacoustic (photoacoustic) tomography reconstructs maps of the initial
pressure rise induced by the absorption of light pulses in tissue. In practice,
due to inaccurate assumptions in the forward model employed, noise and other
experimental factors, the images often contain errors, occasionally manifested
as negative values. We present optoacoustic tomography based on an entropy
maximization algorithm that uses logarithmic regularization as a potent method
for imparting non-negative image reconstruction. We experimentally investigate
the performance achieved by the entropy maximization scheme on phantoms and in
vivo samples. The findings demonstrate that the proposed scheme reconstructs
physically relevant image values devoid of unwanted negative contrast, thus
improving quantitative imaging performance.
</dc:description>
 <dc:description>Comment: Currently under consideration for publication by IEEE</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08398</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Harmony Search Based Wrapper Feature Selection Method for Holistic
  Bangla word Recognition</dc:title>
 <dc:creator>Das, Supratim</dc:creator>
 <dc:creator>Singh, Pawan Kumar</dc:creator>
 <dc:creator>Bhowmik, Showmik</dc:creator>
 <dc:creator>Sarkar, Ram</dc:creator>
 <dc:creator>Nasipuri, Mita</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>68T10</dc:subject>
 <dc:description>  A lot of search approaches have been explored for the selection of features
in pattern classification domain in order to discover significant subset of the
features which produces better accuracy. In this paper, we introduced a Harmony
Search (HS) algorithm based feature selection method for feature dimensionality
reduction in handwritten Bangla word recognition problem. This algorithm has
been implemented to reduce the feature dimensionality of a technique described
in one of our previous papers by S. Bhowmik et al.[1]. In the said paper, a set
of 65 elliptical features were computed for handwritten Bangla word recognition
purpose and a recognition accuracy of 81.37% was achieved using Multi Layer
Perceptron (MLP) classifier. In the present work, a subset containing 48
features (approximately 75% of said feature vector) has been selected by HS
based wrapper feature selection method which produces an accuracy rate of
90.29%. Reasonable outcomes also validates that the introduced algorithm
utilizes optimal number of features while showing higher classification
accuracies when compared to two standard evolutionary algorithms like Genetic
Algorithm (GA), Particle Swarm Optimization (PSO) and statistical feature
dimensionality reduction technique like Principal Component Analysis (PCA).
This confirms the suitability of HS algorithm to the holistic handwritten word
recognition problem.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08398</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08401</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting and classifying lesions in mammograms with Deep Learning</dc:title>
 <dc:creator>Ribli, Dezs&#x151;</dc:creator>
 <dc:creator>Horv&#xe1;th, Anna</dc:creator>
 <dc:creator>Unger, Zsuzsa</dc:creator>
 <dc:creator>Pollner, P&#xe9;ter</dc:creator>
 <dc:creator>Csabai, Istv&#xe1;n</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In the last two decades Computer Aided Diagnostics (CAD) systems were
developed to help radiologists analyze screening mammograms. The benefits of
current CAD technologies appear to be contradictory and they should be improved
to be ultimately considered useful. Since 2012 deep convolutional neural
networks (CNN) have been a tremendous success in image recognition, reaching
human performance. These methods have greatly surpassed the traditional
approaches, which are similar to currently used CAD solutions. Deep CNN-s have
the potential to revolutionize medical image analysis. We propose a CAD system
based on one of the most successful object detection frameworks, Faster R-CNN.
The system detects and classifies malignant or benign lesions on a mammogram
without any human intervention. The proposed method sets the state of the art
classification performance on the public INbreast database, AUC = 0.95 . The
approach described here has achieved the 2nd place in the Digital Mammography
DREAM Challenge with AUC = 0.85 . When used as a detector, the system reaches
high sensitivity with very few false positive marks per image on the INbreast
dataset. Source code, the trained model and an OsiriX plugin are availaible
online at https://github.com/riblidezso/frcnn_cad .
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08409</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Caching Policy for Cache-enabled D2D Communications by Learning User
  Preference</dc:title>
 <dc:creator>Chen, Binqiang</dc:creator>
 <dc:creator>Yang, Chenyang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Prior works in designing caching policy do not distinguish content popularity
with user preference. In this paper, we illustrate the caching gain by
exploiting individual user behavior in sending requests. After showing the
connection between the two concepts, we provide a model for synthesizing user
preference from content popularity. We then optimize the caching policy with
the knowledge of user preference and active level to maximize the offloading
probability for cache-enabled device-to-device communications, and develop a
low-complexity algorithm to find the solution. In order to learn user
preference, we model the user request behavior resorting to probabilistic
latent semantic analysis, and learn the model parameters by expectation
maximization algorithm. By analyzing a Movielens dataset, we find that the user
preferences are less similar, and the active level and topic preference of each
user change slowly over time. Based on this observation, we introduce a prior
knowledge based learning algorithm for user preference, which can shorten the
learning time. Simulation results show remarkable performance gain of the
caching policy with user preference over existing policy with content
popularity, both with realistic dataset and synthetic data validated by the
real dataset.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2018-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08409</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08411</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A framework for quantitative modeling and analysis of highly
  (re)configurable systems</dc:title>
 <dc:creator>ter Beek, Maurice H.</dc:creator>
 <dc:creator>Legay, Axel</dc:creator>
 <dc:creator>Lafuente, Alberto Lluch</dc:creator>
 <dc:creator>Vandin, Andrea</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  This paper presents our approach to the quantitative modeling and analysis of
highly (re)configurable systems, such as software product lines. Different
combinations of the optional features of such a system give rise to
combinatorially many individual system variants. We use a formal modeling
language that allows us to model systems with probabilistic behavior, possibly
subject to quantitative feature constraints, and able to dynamically install,
remove or replace features. More precisely, our models are defined in the
probabilistic feature-oriented language QFLAN, a rich domain specific language
(DSL) for systems with variability defined in terms of features. QFLAN
specifications are automatically encoded in terms of a process algebra whose
operational behavior interacts with a store of constraints, and hence allows to
separate system configuration from system behavior. The resulting probabilistic
configurations and behavior converge seamlessly in a semantics based on
discrete-time Markov chains, thus enabling quantitative analysis. Our analysis
is based on statistical model checking techniques, which allow us to scale to
larger models with respect to precise probabilistic analysis techniques. The
analyses we can conduct range from the likelihood of specific behavior to the
expected average cost, in terms of feature attributes, of specific system
variants. Our approach is supported by a novel Eclipse-based tool which
includes state-of-the-art DSL utilities for QFLAN based on the Xtext framework
as well as analysis plug-ins to seamlessly run statistical model checking
analyses. We provide a number of case studies that have driven and validated
the development of our framework.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08418</identifier>
 <datestamp>2017-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Advantage of Evidential Attributes in Social Networks</dc:title>
 <dc:creator>Dhaou, Salma Ben</dc:creator>
 <dc:creator>Zhou, Kuang</dc:creator>
 <dc:creator>Kharoune, Mouloud</dc:creator>
 <dc:creator>Martin, Arnaud</dc:creator>
 <dc:creator>Yaghlane, Boutheina Ben</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Nowadays, there are many approaches designed for the task of detecting
communities in social networks. Among them, some methods only consider the
topological graph structure, while others take use of both the graph structure
and the node attributes. In real-world networks, there are many uncertain and
noisy attributes in the graph. In this paper, we will present how we detect
communities in graphs with uncertain attributes in the first step. The
numerical, probabilistic as well as evidential attributes are generated
according to the graph structure. In the second step, some noise will be added
to the attributes. We perform experiments on graphs with different types of
attributes and compare the detection results in terms of the Normalized Mutual
Information (NMI) values. The experimental results show that the clustering
with evidential attributes gives better results comparing to those with
probabilistic and numerical attributes. This illustrates the advantages of
evidential attributes.
</dc:description>
 <dc:description>Comment: 20th International Conference on Information Fusion, Jul 2017, Xi'an,
  China</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08418</dc:identifier>
 <dc:identifier>20th International Conference on Information Fusion, Jul 2017,
  Xi'an, China. 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08423</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Stationary Bandits with Habituation and Recovery Dynamics</dc:title>
 <dc:creator>Mintz, Yonatan</dc:creator>
 <dc:creator>Aswani, Anil</dc:creator>
 <dc:creator>Kaminsky, Philip</dc:creator>
 <dc:creator>Flowers, Elena</dc:creator>
 <dc:creator>Fukuoka, Yoshimi</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Many settings involve sequential decision-making where a set of actions can
be chosen at each time step, each action provides a stochastic reward, and the
distribution for the reward of each action is initially unknown. However,
frequent selection of a specific action may reduce its expected reward, while
abstaining from choosing an action may cause its expected reward to increase.
Such non-stationary phenomena are observed in many real world settings such as
personalized healthcare-adherence improving interventions and targeted online
advertising. Though finding an optimal policy for general models with
non-stationarity is PSPACE-complete, we propose and analyze a new class of
models called ROGUE (Reducing or Gaining Unknown Efficacy) bandits, which we
show in this paper can capture these phenomena and are amenable to the design
of effective policies. We first present a consistent maximum likelihood
estimator for the parameters of these models. Next, we construct finite sample
concentration bounds that lead to an upper confidence bound policy called the
ROGUE Upper Confidence Bound (ROGUE-UCB) algorithm. We prove that under proper
conditions the ROGUE-UCB algorithm achieves logarithmic in time regret, unlike
existing algorithms which result in linear regret. We conclude with a numerical
experiment using real data from a personalized healthcare-adherence improving
intervention to increase physical activity. In this intervention, the goal is
to optimize the selection of messages (e.g., confidence increasing vs.
knowledge increasing) to send to each individual each day to increase adherence
and physical activity. Our results show that ROGUE-UCB performs better in terms
of regret and average reward as compared to state of the art algorithms, and
the use of ROGUE-UCB increases daily step counts by roughly 1,000 steps a day
(about a half-mile more of walking) as compared to other algorithms.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08435</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SPEECH-COCO: 600k Visually Grounded Spoken Captions Aligned to MSCOCO
  Data Set</dc:title>
 <dc:creator>Havard, William</dc:creator>
 <dc:creator>Besacier, Laurent</dc:creator>
 <dc:creator>Rosec, Olivier</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents an augmentation of MSCOCO dataset where speech is added
to image and text. Speech captions are generated using text-to-speech (TTS)
synthesis resulting in 616,767 spoken captions (more than 600h) paired with
images. Disfluencies and speed perturbation are added to the signal in order to
sound more natural. Each speech signal (WAV) is paired with a JSON file
containing exact timecode for each word/syllable/phoneme in the spoken caption.
Such a corpus could be used for Language and Vision (LaVi) tasks including
speech input or output instead of text. Investigating multimodal learning
schemes for unsupervised speech pattern discovery is also possible with this
corpus, as demonstrated by a preliminary study conducted on a subset of the
corpus (10h, 10k spoken captions).
</dc:description>
 <dc:description>Comment: corpus available at http://mscoco.org/external/ Accepted to GLU
  Satellite Workshop of Interspeech 2017</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08435</dc:identifier>
 <dc:identifier>doi:10.18709/PERSCIDO.2017.06.DS80</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08438</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context-Independent Polyphonic Piano Onset Transcription with an
  Infinite Training Dataset</dc:title>
 <dc:creator>Li, Samuel</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Many of the recent approaches to polyphonic piano note onset transcription
require training a machine learning model on a large piano database. However,
such approaches are limited by dataset availability; additional training data
is difficult to produce, and proposed systems often perform poorly on novel
recording conditions. We propose a method to quickly synthesize arbitrary
quantities of training data, avoiding the need for curating large datasets.
Various aspects of piano note dynamics - including nonlinearity of note
signatures with velocity, different articulations, temporal clustering of
onsets, and nonlinear note partial interference - are modeled to match the
characteristics of real pianos. Our method also avoids the disentanglement
problem, a recently noted issue affecting machine-learning based approaches. We
train a feed-forward neural network with two hidden layers on our generated
training data and achieve both good transcription performance on the large MAPS
piano dataset and excellent generalization qualities.
</dc:description>
 <dc:description>Comment: Comments are welcome</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08438</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08446</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>All that is English may be Hindi: Enhancing language identification
  through automatic ranking of likeliness of word borrowing in social media</dc:title>
 <dc:creator>Patro, Jasabanta</dc:creator>
 <dc:creator>Samanta, Bidisha</dc:creator>
 <dc:creator>Singh, Saurabh</dc:creator>
 <dc:creator>Basu, Abhipsa</dc:creator>
 <dc:creator>Mukherjee, Prithwish</dc:creator>
 <dc:creator>Choudhury, Monojit</dc:creator>
 <dc:creator>Mukherjee, Animesh</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we present a set of computational methods to identify the
likeliness of a word being borrowed, based on the signals from social media. In
terms of Spearman correlation coefficient values, our methods perform more than
two times better (nearly 0.62) in predicting the borrowing likeliness compared
to the best performing baseline (nearly 0.26) reported in literature. Based on
this likeliness estimate we asked annotators to re-annotate the language tags
of foreign words in predominantly native contexts. In 88 percent of cases the
annotators felt that the foreign language tag should be replaced by native
language tag, thus indicating a huge scope for improvement of automatic
language identification systems.
</dc:description>
 <dc:description>Comment: 11 pages, accepted in the 2017 conference on Empirical Methods on
  Natural Language Processing(EMNLP 2017) arXiv admin note: substantial text
  overlap with arXiv:1703.05122</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08446</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08454</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Making the best of data derived from a daily practice in clinical legal
  medicine for research and practice - the example of Spe3dLab</dc:title>
 <dc:creator>Laugier, Vincent</dc:creator>
 <dc:creator>Stindel, Eric</dc:creator>
 <dc:creator>Lichterowicz, Alcibiade</dc:creator>
 <dc:creator>Ansart, S&#xe9;verine</dc:creator>
 <dc:creator>Lef&#xe8;vre, Thomas</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Forensic science suffers from a lack of studies with high-quality design,
such as randomized controlled trials (RCT). Evidence in forensic science may be
of insufficient quality, which is a major concern. Results from RCT are
criticized for providing artificial results that are not useful in real life
and unfit for individualized prescription. Various sources of collected data
(e.g. data collected in routine practice) could be exploited for distinct
goals. Obstacles remain before such data can be practically accessed and used,
including technical issues. We present an easy-to-use software dedicated to
innovative data analyses for practitioners and researchers. We provide 2
examples in forensics. Spe3dLab has been developed by 3 French teams: a
bioinformatics laboratory (LaTIM), a private partner (Tekliko) and a department
of forensic medicine (Jean Verdier Hospital). It was designed to be open
source, relying on documented and maintained libraries, query-oriented and
capable of handling the entire data process from capture to export of best
predictive models for their integration in information systems. Spe3dLab was
used for 2 specific forensics applications: i) the search for multiple causal
factors and ii) the best predictive model of the functional impairment (total
incapacity to work, TIW) of assault survivors. 2,892 patients were included
over a 6-month period. Time to evaluation was the only direct cause identified
for TIW, and victim category was an indirect cause. The specificity and
sensitivity of the predictive model were 99.9% and 90%, respectively. Spe3dLab
is a quick and efficient tool for accessing observational, routinely collected
data and performing innovative analyses. Analyses can be exported for
validation and routine use by practitioners, e.g., for computer-aided
evaluation of complex problems. It can provide a fully integrated solution for
individualized medicine.
</dc:description>
 <dc:description>Comment: 15 pages, 3 tables, 5 figures</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08454</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08458</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Men Are from Mars, Women Are from Venus: Evaluation and Modelling of
  Verbal Associations</dc:title>
 <dc:creator>Vylomova, Ekaterina</dc:creator>
 <dc:creator>Shcherbakov, Andrei</dc:creator>
 <dc:creator>Philippovich, Yuriy</dc:creator>
 <dc:creator>Cherkasova, Galina</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a quantitative analysis of human word association pairs and study
the types of relations presented in the associations. We put our main focus on
the correlation between response types and respondent characteristics such as
occupation and gender by contrasting syntagmatic and paradigmatic associations.
Finally, we propose a personalised distributed word association model and show
the importance of incorporating demographic factors into the models commonly
used in natural language processing.
</dc:description>
 <dc:description>Comment: AIST 2017 camera-ready</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08462</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Optimal Control Formulation of Pulse-Based Control Using Koopman
  Operator</dc:title>
 <dc:creator>Sootla, Aivar</dc:creator>
 <dc:creator>Mauroy, Alexandre</dc:creator>
 <dc:creator>Ernst, Damien</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In many applications, and in systems/synthetic biology, in particular, it is
desirable to compute control policies that force the trajectory of a bistable
system from one equilibrium (the initial point) to another equilibrium (the
target point), or in other words to solve the switching problem. It was
recently shown that, for monotone bistable systems, this problem admits
easy-to-implement open-loop solutions in terms of temporal pulses (i.e., step
functions of fixed length and fixed magnitude). In this paper, we develop this
idea further and formulate a problem of convergence to an equilibrium from an
arbitrary initial point. We show that this problem can be solved using a static
optimization problem in the case of monotone systems. Changing the initial
point to an arbitrary state allows to build closed-loop, event-based or
open-loop policies for the switching/convergence problems. In our derivations
we exploit the Koopman operator, which offers a linear infinite-dimensional
representation of an autonomous nonlinear system. One of the main advantages of
using the Koopman operator is the powerful computational tools developed for
this framework. Besides the presence of numerical solutions, the
switching/convergence problem can also serve as a building block for solving
more complicated control problems and can potentially be applied to
non-monotone systems. We illustrate this argument on the problem of
synchronizing cardiac cells by defibrillation. Potentially, our approach can be
extended to problems with different parametrizations of control signals since
the only fundamental limitation is the finite time application of the control
signal.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08468</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Decidable Very Expressive Description Logic for Databases (Extended
  Version)</dc:title>
 <dc:creator>Artale, Alessandro</dc:creator>
 <dc:creator>Franconi, Enrico</dc:creator>
 <dc:creator>Pe&#xf1;aloza, Rafael</dc:creator>
 <dc:creator>Sportelli, Francesco</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We introduce $\mathcal{DLR}^+$, an extension of the n-ary propositionally
closed description logic $\mathcal{DLR}$ to deal with attribute-labelled tuples
(generalising the positional notation), projections of relations, and global
and local objectification of relations, able to express inclusion, functional,
key, and external uniqueness dependencies. The logic is equipped with both TBox
and ABox axioms. We show how a simple syntactic restriction on the appearance
of projections sharing common attributes in a $\mathcal{DLR}^+$ knowledge base
makes reasoning in the language decidable with the same computational
complexity as $\mathcal{DLR}$. The obtained $\mathcal{DLR}^\pm$ n-ary
description logic is able to encode more thoroughly conceptual data models such
as EER, UML, and ORM.
</dc:description>
 <dc:description>Comment: 20 pages. Extended version of paper appearing in the International
  Semantic Web Conference (ISWC 2017). arXiv admin note: text overlap with
  arXiv:1604.00799</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08468</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08470</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implicit Entity Linking in Tweets</dc:title>
 <dc:creator>Perera, Sujan</dc:creator>
 <dc:creator>Mendes, Pablo N.</dc:creator>
 <dc:creator>Alex, Adarsh</dc:creator>
 <dc:creator>Sheth, Amit</dc:creator>
 <dc:creator>Thirunarayan, Krishnaprasad</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Over the years, Twitter has become one of the largest communication platforms
providing key data to various applications such as brand monitoring, trend
detection, among others. Entity linking is one of the major tasks in natural
language understanding from tweets and it associates entity mentions in text to
corresponding entries in knowledge bases in order to provide unambiguous
interpretation and additional con- text. State-of-the-art techniques have
focused on linking explicitly mentioned entities in tweets with reasonable
success. However, we argue that in addition to explicit mentions i.e. The movie
Gravity was more ex- pensive than the mars orbiter mission entities (movie
Gravity) can also be mentioned implicitly i.e. This new space movie is crazy.
you must watch it!. This paper introduces the problem of implicit entity
linking in tweets. We propose an approach that models the entities by
exploiting their factual and contextual knowledge. We demonstrate how to use
these models to perform implicit entity linking on a ground truth dataset with
397 tweets from two domains, namely, Movie and Book. Specifically, we show: 1)
the importance of linking implicit entities and its value addition to the
standard entity linking task, and 2) the importance of exploiting contextual
knowledge associated with an entity for linking their implicit mentions. We
also make the ground truth dataset publicly available to foster the research in
this new research area.
</dc:description>
 <dc:description>Comment: This paper was accepted at the Extended Semantic Web Conference 2016
  as a full research track paper</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08470</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-34129-3_8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08475</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DARLA: Improving Zero-Shot Transfer in Reinforcement Learning</dc:title>
 <dc:creator>Higgins, Irina</dc:creator>
 <dc:creator>Pal, Arka</dc:creator>
 <dc:creator>Rusu, Andrei A.</dc:creator>
 <dc:creator>Matthey, Loic</dc:creator>
 <dc:creator>Burgess, Christopher P</dc:creator>
 <dc:creator>Pritzel, Alexander</dc:creator>
 <dc:creator>Botvinick, Matthew</dc:creator>
 <dc:creator>Blundell, Charles</dc:creator>
 <dc:creator>Lerchner, Alexander</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Domain adaptation is an important open problem in deep reinforcement learning
(RL). In many scenarios of interest data is hard to obtain, so agents may learn
a source policy in a setting where data is readily available, with the hope
that it generalises well to the target domain. We propose a new multi-stage RL
agent, DARLA (DisentAngled Representation Learning Agent), which learns to see
before learning to act. DARLA's vision is based on learning a disentangled
representation of the observed environment. Once DARLA can see, it is able to
acquire source policies that are robust to many domain shifts - even with no
access to the target domain. DARLA significantly outperforms conventional
baselines in zero-shot domain adaptation scenarios, an effect that holds across
a variety of RL environments (Jaco arm, DeepMind Lab) and base RL algorithms
(DQN, A3C and EC).
</dc:description>
 <dc:description>Comment: ICML 2017</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08475</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08476</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guidelines for Artificial Intelligence Containment</dc:title>
 <dc:creator>Babcock, James</dc:creator>
 <dc:creator>Kramar, Janos</dc:creator>
 <dc:creator>Yampolskiy, Roman V.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  With almost daily improvements in capabilities of artificial intelligence it
is more important than ever to develop safety software for use by the AI
research community. Building on our previous work on AI Containment Problem we
propose a number of guidelines which should help AI safety researchers to
develop reliable sandboxing software for intelligent programs of all levels.
Such safety container software will make it possible to study and analyze
intelligent artificial agent while maintaining certain level of safety against
information leakage, social engineering attacks and cyberattacks from within
the container.
</dc:description>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08477</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resilient Energy Allocation Model for Supply Shortage Outages</dc:title>
 <dc:creator>Mercado, Miguel Alberto</dc:creator>
 <dc:creator>Dong, Roy</dc:creator>
 <dc:creator>Nerves, Allan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Supply Shortage Outages are a major concern during peak demand for developing
countries. In the Philippines, commercial loads have unused backup generation
of up to 3000 MW, at the same time there are shortages of as much as 700 MW
during peak demand. This gives utilities the incentive to implement Demand
Response programs to minimize this shortage. But when considering Demand
Response from a modeling perspective, social welfare through profit is always
the major objective for program implementation. That isn't always the case
during an emergency situation as there can be a trade-off between grid
resilience and cost of electricity.
  The question is how the Distribution Utility (DU) shall optimally allocate
the unused generation to meet the shortage when this trade-off exists. We
formulate a combined multi-objective optimal dispatch model where we can make a
direct comparison between the least-cost and resilience objectives.
  We find that this trade-off is due to the monotonically increasing nature of
energy cost functions. If the supply is larger than the demand, the DU can
perform a least-cost approach in the optimal dispatch since maximizing the
energy generated in this case can lead to multiple solutions. We also find in
our simulation that in cases where the supply of energy from the customers is
less than shortage quantity, the DU must prioritize maximizing the generated
energy rather than minimizing cost.
</dc:description>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08482</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Confidentiality enforcement by hybrid control of information flows</dc:title>
 <dc:creator>Biskup, Joachim</dc:creator>
 <dc:creator>Tadros, Cornelia</dc:creator>
 <dc:creator>Zarouali, Jaouad</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:subject>H.2.7</dc:subject>
 <dc:description>  An information owner, possessing diverse data sources, might want to offer
information services based on these sources to cooperation partners and to this
end interact with these partners by receiving and sending messages, which the
owner on his part generates by program execution. Independently from data
representation or its physical storage, information release to a partner might
be restricted by the owner's confidentiality policy on an integrated, unified
view of the sources. Such a policy should even be enforced if the partner as an
intelligent and only semi-honest attacker attempts to infer hidden information
from message data, also employing background knowledge. For this problem of
inference control, we present a framework for a unified, holistic control of
information flow induced by program-based processing of the data sources to
messages sent to a cooperation partner. Our framework expands on and combines
established concepts for confidentiality enforcement and its verification and
is instantiated in a Java environment. More specifically, as a hybrid control
we combine gradual release of information via declassification, enforced by
static program analysis using a security type system, with a dynamic monitoring
approach. The dynamic monitoring employs flow tracking for generalizing values
to be declassified under confidentiality policy compliance.
</dc:description>
 <dc:description>Comment: 44 pages</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08484</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MST in O(1) Rounds of the Congested Clique</dc:title>
 <dc:creator>Jurdzinski, Tomasz</dc:creator>
 <dc:creator>Nowicki, Krzysztof</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present a distributed randomized algorithm finding Minimum Spanning Tree
(MST) of a given graph in O(1) rounds, with high probability, in the Congested
Clique model. The input graph in the Congested Clique model is a graph of n
nodes, where each node initially knows only its incident edges. The
communication graph is a clique with limited edge bandwidth: each two nodes
(not necessarily neighbours in the input graph) can exchange $O(\log n)$ bits.
  As in previous works, the key part of the MST algorithm is an efficient
Connected Components (CC) algorithm. However, unlike the former approaches, we
do not aim at simulating the standard Boruvka algorithm, at least at initial
stages of the CC algorithm. Instead, we develop a new technique which combines
connected components of sample sparse subgraphs of the input graph in order to
accelerate the process of uncovering connected components of the original input
graph. More specifically, we develop a sparsification technique which reduces
an initial CC problem in $O(1)$ rounds to its two restricted instances. The
former instance has a graph with maximal degree $O(\log \log n)$ as the input
-- here our sample-combining technique helps. In the latter instance, a
partition of the input graph into $O(n/\log \log n)$ connected components is
known. This gives an opportunity to apply previous algorithms to determine
connected components in $O(1)$ rounds.
  Our result addresses the problem from and the $O(\log \log n)$ algorithm of
Lotker et al. [SPAA 2003; SICOMP 2005], improves over previous $O(\log* n)$
algorithm of Ghaffari et al. [PODC 2016] and $O(\log \log \log n)$ algorithm of
Hegeman et al. [PODC 2015] . It also determines $\Theta(1)$ round complexity in
the congested clique for MST, as well as other graph problems, including
bipartiteness, cut verification, s-t connectivity and cycle containment.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08484</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08486</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomized Similar Triangles Method: A Unifying Framework for
  Accelerated Randomized Optimization Methods (Coordinate Descent, Directional
  Search, Derivative-Free Method)</dc:title>
 <dc:creator>Dvurechensky, Pavel</dc:creator>
 <dc:creator>Gasnikov, Alexander</dc:creator>
 <dc:creator>Tiurin, Alexander</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>90C25, 90C30, 90C06, 90C56, 68Q25, 65K05, 49M27, 68W20, 65Y20, 68W40</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  In this paper, we consider smooth convex optimization problems with simple
constraints and inexactness in the oracle information such as value, partial or
directional derivatives of the objective function. We introduce a unifying
framework, which allows to construct different types of accelerated randomized
methods for such problems and to prove convergence rate theorems for them. We
focus on accelerated random block-coordinate descent, accelerated random
directional search, accelerated random derivative-free method and, using our
framework, provide their versions for problems with inexact oracle information.
Our contribution also includes accelerated random block-coordinate descent with
inexact oracle and entropy proximal setup as well as derivative-free version of
this method.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08486</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08488</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Framework for Synthetic Aperture Sonar Micronavigation</dc:title>
 <dc:creator>Caporale, Salvatore</dc:creator>
 <dc:creator>Petillot, Yvan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>93C85</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:description>  Synthetic aperture imaging systems achieve constant azimuth resolution by
coherently summating the observations acquired along the aperture path. At this
aim, their locations have to be known with subwavelength accuracy. In
underwater Synthetic Aperture Sonar (SAS), the nature of propagation and
navigation in water makes the retrieval of this information challenging.
Inertial sensors have to be employed in combination with signal processing
techniques, which are usually referred to as micronavigation. In this paper we
propose a novel micronavigation approach based on the minimization of an error
function between two contiguous pings having some mutual information. This
error is obtained by comparing the vector space intersections between the pings
orthogonal projectors. The effectiveness and generality of the proposed
approach is demonstrated by means of simulations and by means of an experiment
performed in a controlled environment.
</dc:description>
 <dc:description>Comment: 12 pages, 19 figures</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08494</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A compositional modeling framework for the optimal energy management of
  a district network</dc:title>
 <dc:creator>Ioli, Daniele</dc:creator>
 <dc:creator>Falsone, Alessandro</dc:creator>
 <dc:creator>Papadopoulos, Alessandro Vittorio</dc:creator>
 <dc:creator>Prandini, Maria</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper proposes a compositional modeling framework for the optimal energy
management of a district network. The focus is on cooling of buildings, which
can possibly share resources to the purpose of reducing maintenance costs and
using devices at their maximal efficiency. Components of the network are
described in terms of energy fluxes and combined via energy balance equations.
Disturbances are accounted for as well through their contribution in terms of
energy. Different district configurations can be built, and the dimension and
complexity of the resulting model will depend on the number and type of
components and on the adopted disturbance description. Control inputs are
available to efficiently operate and coordinate the district components, thus
enabling energy management strategies to minimize the electrical energy costs
or track some consumption profile agreed with the main grid operator.
</dc:description>
 <dc:description>Comment: 65 pages, 19 figures</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08494</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08496</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Distributed Approximation for Max-Cut</dc:title>
 <dc:creator>Censor-Hillel, Keren</dc:creator>
 <dc:creator>Levy, Rina</dc:creator>
 <dc:creator>Shachnai, Hadas</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Finding a maximum cut is a fundamental task in many computational settings.
Surprisingly, it has been insufficiently studied in the classic distributed
settings, where vertices communicate by synchronously sending messages to their
neighbors according to the underlying graph, known as the $\mathcal{LOCAL}$ or
$\mathcal{CONGEST}$ models. We amend this by obtaining almost optimal
algorithms for Max-Cut on a wide class of graphs in these models. In
particular, for any $\epsilon &gt; 0$, we develop randomized approximation
algorithms achieving a ratio of $(1-\epsilon)$ to the optimum for Max-Cut on
bipartite graphs in the $\mathcal{CONGEST}$ model, and on general graphs in the
$\mathcal{LOCAL}$ model.
  We further present efficient deterministic algorithms, including a
$1/3$-approximation for Max-Dicut in our models, thus improving the best known
(randomized) ratio of $1/4$. Our algorithms make non-trivial use of the greedy
approach of Buchbinder et al. (SIAM Journal on Computing, 2015) for maximizing
an unconstrained (non-monotone) submodular function, which may be of
independent interest.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08514</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analyzing IO Amplification in Linux File Systems</dc:title>
 <dc:creator>Mohan, Jayashree</dc:creator>
 <dc:creator>Kadekodi, Rohan</dc:creator>
 <dc:creator>Chidambaram, Vijay</dc:creator>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  We present the first systematic analysis of read, write, and space
amplification in Linux file systems. While many researchers are tackling write
amplification in key-value stores, IO amplification in file systems has been
largely unexplored. We analyze data and metadata operations on five widely-used
Linux file systems: ext2, ext4, XFS, btrfs, and F2FS. We find that data
operations result in significant write amplification (2-32X) and that metadata
operations have a large IO cost. For example, a single rename requires 648 KB
write IO in btrfs. We also find that small random reads result in read
amplification of 2-13X. Based on these observations, we present the CReWS
conjecture about the relationship between IO amplification, consistency, and
storage space utilization. We hope this paper spurs people to design future
file systems with less IO amplification, especially for non-volatile memory
technologies.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08514</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08517</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two Types of Social Grooming discovered in Primitive and Modern
  Communication Data-Sets</dc:title>
 <dc:creator>Takano, Masanori</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Social networking sites (SNS) provide innovative social bonding methods known
as social grooming. These have drastically decreased time and distance
constraints of social grooming. Here we show two type social grooming
(elaborate social grooming and lightweight social grooming) discovered in a
model constructed by thirty communication data-sets including face to face,
SNS, mobile phones, and Chacma baboons. This demarcation is caused by a
trade-off between the number and strength of social relationships on social
grooming. The trade-off of elaborate social grooming is weaker than the
trade-off of lightweight social grooming. On the other hand, the cost of
elaborate methods is higher than lightweight methods. This model connects
micro-social grooming behaviour and macro-social structures with these
trade-offs. People tend to use elaborate social grooming to reinforce close
relationships and construct deep limited societies (e.g. face to face and
Chacma baboons). This seems to be apriori. On the other hand, people tend to
use lightweight social grooming to maintain many weak social relationships and
construct expanded shallow societies (e.g. SNS). Humans recently have obtained
this method. Humans with lightweight methods who live in significantly complex
societies use various social grooming to effectively construct social
relationships. Elaborate social grooming is for getting cooperation from close
relationships. Lightweight social grooming is for getting information from many
weak relationships.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08517</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08524</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Shape Metric for Clustering Algorithms</dc:title>
 <dc:creator>Alexander, Clark</dc:creator>
 <dc:creator>Akhmametyeva, Sofya</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We construct a method by which we can calculate the precision with which an
algorithm identifies the shape of a cluster. We present our results for several
well known clustering algorithms and suggest ways to improve performance for
newer algorithms.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08525</identifier>
 <datestamp>2017-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Guided Spatial Transformer Network for Histology Cell Differentiation</dc:title>
 <dc:creator>Aubreville, Marc</dc:creator>
 <dc:creator>Krappmann, Maximilian</dc:creator>
 <dc:creator>Bertram, Christof</dc:creator>
 <dc:creator>Klopfleisch, Robert</dc:creator>
 <dc:creator>Maier, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Identification and counting of cells and mitotic figures is a standard task
in diagnostic histopathology. Due to the large overall cell count on
histological slides and the potential sparse prevalence of some relevant cell
types or mitotic figures, retrieving annotation data for sufficient statistics
is a tedious task and prone to a significant error in assessment. Automatic
classification and segmentation is a classic task in digital pathology, yet it
is not solved to a sufficient degree.
  We present a novel approach for cell and mitotic figure classification, based
on a deep convolutional network with an incorporated Spatial Transformer
Network. The network was trained on a novel data set with ten thousand mitotic
figures, about ten times more than previous data sets. The algorithm is able to
derive the cell class (mitotic tumor cells, non-mitotic tumor cells and
granulocytes) and their position within an image. The mean accuracy of the
algorithm in a five-fold cross-validation is 91.45%.
  In our view, the approach is a promising step into the direction of a more
objective and accurate, semi-automatized mitosis counting supporting the
pathologist.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures, EG VCBM 2017 contribution</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08525</dc:identifier>
 <dc:identifier>EG VCBM 2017 Proceedings</dc:identifier>
 <dc:identifier>doi:10.2312/vcbm.20171233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08535</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inference from Randomized Transmissions by Many Backscatter Sensors</dc:title>
 <dc:creator>Zhu, Guangxu</dc:creator>
 <dc:creator>Ko, Seung-Woo</dc:creator>
 <dc:creator>Huang, Kaibin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Attaining the vision of Smart Cities requires the deployment of an enormous
number of sensors for monitoring various conditions of the environment.
Backscatter-sensors have emerged to be a promising solution due to the
uninterruptible energy supply and relative simple hardwares. On the other hand,
backscatter-sensors with limited signal-processing capabilities are unable to
support conventional algorithms for multiple-access and channel-training. Thus,
the key challenge in designing backscatter-sensor networks is to enable readers
to accurately detect sensing-values given simple ALOHA random access, primitive
transmission schemes, and no knowledge of channel-states. We tackle this
challenge by proposing the novel framework of backscatter sensing featuring
random-encoding at sensors and statistical-inference at readers. Specifically,
assuming the on/off keying for backscatter transmissions, the practical
random-encoding scheme causes the on/off transmission of a sensor to follow a
distribution parameterized by the sensing values. Facilitated by the scheme,
statistical-inference algorithms are designed to enable a reader to infer
sensing-values from randomized transmissions by multiple sensors. The specific
design procedure involves the construction of Bayesian networks, namely
deriving conditional distributions for relating unknown parameters and
variables to signals observed by the reader. Then based on the Bayesian
networks and the well-known expectation-maximization principle, inference
algorithms are derived to recover sensing-values.
</dc:description>
 <dc:description>Comment: An extended version of a shorter conference submission</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2018-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08535</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08539</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measurement and Analysis of UDP Traffic over Wi-Fi and GPRS</dc:title>
 <dc:creator>Maheshwari, Sumit</dc:creator>
 <dc:creator>Vasu, K.</dc:creator>
 <dc:creator>Mahapatra, Sudipta</dc:creator>
 <dc:creator>Kumar, C. S.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  With the increasing usage of mobile devices to ubiquitously access
heterogeneous applications in wireless Internet, the measurement and analysis
of Internet traffic has become a key research area. In this paper, we present
the results of our measurements for VBR traffic over UDP in 802.11g and GPRS
networks. We focus on Inter-Packet Arrival Time (IPRT) and Inter-Packet
Transmission Delay (IPTD) and observe that the later has a significant impact
on the round trip delay. Numerical parameters for Weibull, Exponential and
Normal distribution in order to represent such traffic are also presented.
</dc:description>
 <dc:description>Comment: 5 Pages, ICCCD conference, IIT Kharagpur</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08539</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08549</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rational Points on the Unit Sphere: Approximation Complexity and
  Practical Constructions</dc:title>
 <dc:creator>Bahrdt, Daniel</dc:creator>
 <dc:creator>Seybold, Martin P.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Each non-zero point in $\mathbb{R}^d$ identifies a closest point $x$ on the
unit sphere $\mathbb{S}^{d-1}$. We are interested in computing an
$\epsilon$-approximation $y \in \mathbb{Q}^d$ for $x$, that is exactly on
$\mathbb{S}^{d-1}$ and has low bit size. We revise lower bounds on rational
approximations and provide explicit, spherical instances.
  We prove that floating-point numbers can only provide trivial solutions to
the sphere equation in $\mathbb{R}^2$ and $\mathbb{R}^3$. Moreover, we show how
to construct a rational point with denominators of at most
$10(d-1)/\varepsilon^2$ for any given $\epsilon \in \left(0,\tfrac 1 8\right]$,
improving on a previous result. The method further benefits from algorithms for
simultaneous Diophantine approximation.
  Our open-source implementation and experiments demonstrate the practicality
of our approach in the context of massive data sets Geo-referenced by latitude
and longitude values.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08551</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TensorLayer: A Versatile Library for Efficient Deep Learning Development</dc:title>
 <dc:creator>Dong, Hao</dc:creator>
 <dc:creator>Supratak, Akara</dc:creator>
 <dc:creator>Mai, Luo</dc:creator>
 <dc:creator>Liu, Fangde</dc:creator>
 <dc:creator>Oehmichen, Axel</dc:creator>
 <dc:creator>Yu, Simiao</dc:creator>
 <dc:creator>Guo, Yike</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep learning has enabled major advances in the fields of computer vision,
natural language processing, and multimedia among many others. Developing a
deep learning system is arduous and complex, as it involves constructing neural
network architectures, managing training/trained models, tuning optimization
process, preprocessing and organizing data, etc. TensorLayer is a versatile
Python library that aims at helping researchers and engineers efficiently
develop deep learning systems. It offers rich abstractions for neural networks,
model and data management, and parallel workflow mechanism. While boosting
efficiency, TensorLayer maintains both performance and scalability. TensorLayer
was released in September 2016 on GitHub, and has helped people from academia
and industry develop real-world applications of deep learning.
</dc:description>
 <dc:description>Comment: ACM Multimedia 2017</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08551</dc:identifier>
 <dc:identifier>doi:10.1145/3123266.3129391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08552</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Robust Multi-Batch L-BFGS Method for Machine Learning</dc:title>
 <dc:creator>Berahas, Albert S.</dc:creator>
 <dc:creator>Tak&#xe1;&#x10d;, Martin</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper describes an implementation of the L-BFGS method designed to deal
with two adversarial situations. The first occurs in distributed computing
environments where some of the computational nodes devoted to the evaluation of
the function and gradient are unable to return results on time. A similar
challenge occurs in a multi-batch approach in which the data points used to
compute function and gradients are purposely changed at each iteration to
accelerate the learning process. Difficulties arise because L-BFGS employs
gradient differences to update the Hessian approximations, and when these
gradients are computed using different data points the updating process can be
unstable. This paper shows how to perform stable quasi-Newton updating in the
multi-batch setting, studies the convergence properties for both convex and
nonconvex functions, and illustrates the behavior of the algorithm in a
distributed computing platform on binary classification logistic regression and
neural network training problems that arise in machine learning.
</dc:description>
 <dc:description>Comment: 47 pages, 26 figures. Extension of NIPS 2016 paper: arXiv:1605.06049</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08553</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Direct Load Control of Thermostatically Controlled Loads Based on Sparse
  Observations Using Deep Reinforcement Learning</dc:title>
 <dc:creator>Ruelens, Frederik</dc:creator>
 <dc:creator>Claessens, Bert J.</dc:creator>
 <dc:creator>Vrancx, Peter</dc:creator>
 <dc:creator>Spiessens, Fred</dc:creator>
 <dc:creator>Deconinck, Geert</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper considers a demand response agent that must find a near-optimal
sequence of decisions based on sparse observations of its environment.
Extracting a relevant set of features from these observations is a challenging
task and may require substantial domain knowledge. One way to tackle this
problem is to store sequences of past observations and actions in the state
vector, making it high dimensional, and apply techniques from deep learning.
This paper investigates the capabilities of different deep learning techniques,
such as convolutional neural networks and recurrent neural networks, to extract
relevant features for finding near-optimal policies for a residential heating
system and electric water heater that are hindered by sparse observations. Our
simulation results indicate that in this specific scenario, feeding sequences
of time-series to an LSTM network, which is a specific type of recurrent neural
network, achieved a higher performance than stacking these time-series in the
input of a convolutional neural network or deep neural network.
</dc:description>
 <dc:description>Comment: submitted and waiting review in IEEE transactions on smart grid 2017</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08553</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08554</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpatient Respiratory Motion Model Transfer for Virtual Reality
  Simulations of Liver Punctures</dc:title>
 <dc:creator>Mastmeyer, Andre</dc:creator>
 <dc:creator>Wilms, Matthias</dc:creator>
 <dc:creator>Handels, Heinz</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Current virtual reality (VR) training simulators of liver punctures often
rely on static 3D patient data and use an unrealistic (sinusoidal) periodic
animation of the respiratory movement. Existing methods for the animation of
breathing motion support simple mathematical or patient-specific, estimated
breathing models. However with personalized breathing models for each new
patient, a heavily dose relevant or expensive 4D data acquisition is mandatory
for keyframe-based motion modeling. Given the reference 4D data, first a model
building stage using linear regression motion field modeling takes place. Then
the methodology shown here allows the transfer of existing reference
respiratory motion models of a 4D reference patient to a new static 3D patient.
This goal is achieved by using non-linear inter-patient registration to warp
one personalized 4D motion field model to new 3D patient data. This cost- and
dose-saving new method is shown here visually in a qualitative proof-of-concept
study.
</dc:description>
 <dc:description>Comment: World Society for Computer Graphics - WSCG 2017 publication, 9 pages,
  5 figures, 1 movie online</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08554</dc:identifier>
 <dc:identifier>Journal of WSCG, Vol.25, No.1, ISSN 1213-6972, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08557</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Congestion Barcodes: Exploring the Topology of Urban Congestion Using
  Persistent Homology</dc:title>
 <dc:creator>Wu, Yu</dc:creator>
 <dc:creator>Shindnes, Gabriel</dc:creator>
 <dc:creator>Karve, Vaibhav</dc:creator>
 <dc:creator>Yager, Derrek</dc:creator>
 <dc:creator>Work, Daniel B.</dc:creator>
 <dc:creator>Chakraborty, Arnab</dc:creator>
 <dc:creator>Sowers, Richard B.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  This work presents a new method to quantify connectivity in transportation
networks. Inspired by the field of topological data analysis, we propose a
novel approach to explore the robustness of road network connectivity in the
presence of congestion on the roadway. The robustness of the pattern is
summarized in a congestion barcode, which can be constructed directly from
traffic datasets commonly used for navigation. As an initial demonstration, we
illustrate the main technique on a publicly available traffic dataset in a
neighborhood in New York City.
</dc:description>
 <dc:description>Comment: 9 pages, 15 figures, Accepted to IEEE 20th International Conference
  on Intelligent Transportation Systems 2017</dc:description>
 <dc:date>2017-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08559</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video Highlight Prediction Using Audience Chat Reactions</dc:title>
 <dc:creator>Fu, Cheng-Yang</dc:creator>
 <dc:creator>Lee, Joon</dc:creator>
 <dc:creator>Bansal, Mohit</dc:creator>
 <dc:creator>Berg, Alexander C.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Sports channel video portals offer an exciting domain for research on
multimodal, multilingual analysis. We present methods addressing the problem of
automatic video highlight prediction based on joint visual features and textual
analysis of the real-world audience discourse with complex slang, in both
English and traditional Chinese. We present a novel dataset based on League of
Legends championships recorded from North American and Taiwanese Twitch.tv
channels (will be released for further research), and demonstrate strong
results on these using multimodal, character-level CNN-RNN model architectures.
</dc:description>
 <dc:description>Comment: EMNLP 2017</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08561</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum machine learning: a classical perspective</dc:title>
 <dc:creator>Ciliberto, Carlo</dc:creator>
 <dc:creator>Herbster, Mark</dc:creator>
 <dc:creator>Ialongo, Alessandro Davide</dc:creator>
 <dc:creator>Pontil, Massimiliano</dc:creator>
 <dc:creator>Rocchetto, Andrea</dc:creator>
 <dc:creator>Severini, Simone</dc:creator>
 <dc:creator>Wossnig, Leonard</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recently, increased computational power and data availability, as well as
algorithmic advances, have led machine learning techniques to impressive
results in regression, classification, data-generation and reinforcement
learning tasks. Despite these successes, the proximity to the physical limits
of chip fabrication alongside the increasing size of datasets are motivating a
growing number of researchers to explore the possibility of harnessing the
power of quantum computation to speed-up classical machine learning algorithms.
Here we review the literature in quantum machine learning and discuss
perspectives for a mixed readership of classical machine learning and quantum
computation experts. Particular emphasis will be placed on clarifying the
limitations of quantum algorithms, how they compare with their best classical
counterparts and why quantum resources are expected to provide advantages for
learning problems. Learning in the presence of noise and certain
computationally hard problems in machine learning are identified as promising
directions for the field. Practical questions, like how to upload classical
data into quantum form, will also be addressed.
</dc:description>
 <dc:description>Comment: 32 pages; typos corrected and references added</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08567</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings of Workshop AEW10: Concepts in Information Theory and
  Communications</dc:title>
 <dc:creator>Immink, Kees A. Schouhamer</dc:creator>
 <dc:creator>Baggen, Stan</dc:creator>
 <dc:creator>Chaabane, Ferdaous</dc:creator>
 <dc:creator>Chen, Yanling</dc:creator>
 <dc:creator>de With, Peter H. N.</dc:creator>
 <dc:creator>Gassara, Hela</dc:creator>
 <dc:creator>Gharbi, Hamed</dc:creator>
 <dc:creator>Ghazel, Adel</dc:creator>
 <dc:creator>Grati, Khaled</dc:creator>
 <dc:creator>Grigoryan, Naira M.</dc:creator>
 <dc:creator>Harutyunyan, Ashot</dc:creator>
 <dc:creator>Imanishi, Masayuki</dc:creator>
 <dc:creator>Iwamoto, Mitsugu</dc:creator>
 <dc:creator>Iwata, Ken-ichi</dc:creator>
 <dc:creator>Kamabe, Hiroshi</dc:creator>
 <dc:creator>Kurkoski, Brian M.</dc:creator>
 <dc:creator>Kuzuoka, Shigeaki</dc:creator>
 <dc:creator>Langenhuizen, Patrick</dc:creator>
 <dc:creator>Lewandowsky, Jan</dc:creator>
 <dc:creator>Manada, Akiko</dc:creator>
 <dc:creator>Miyake, Shigeki</dc:creator>
 <dc:creator>Morita, Hiroyoshi</dc:creator>
 <dc:creator>Muramatsu, Jun</dc:creator>
 <dc:creator>Najjar, Safa</dc:creator>
 <dc:creator>Poghosyan, Arnak V.</dc:creator>
 <dc:creator>Rouissi, Fatma</dc:creator>
 <dc:creator>Sakai, Yuta</dc:creator>
 <dc:creator>Tamm, Ulrich</dc:creator>
 <dc:creator>van der Putten, Joost</dc:creator>
 <dc:creator>van der Sommen, Fons</dc:creator>
 <dc:creator>Vinck, A. J. Han</dc:creator>
 <dc:creator>Wadayama, Tadashi</dc:creator>
 <dc:creator>W&#xfc;bben, Dirk</dc:creator>
 <dc:creator>Yamamoto, Hirosuke</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>68P30, 94A05</dc:subject>
 <dc:description>  The 10th Asia-Europe workshop in &quot;Concepts in Information Theory and
Communications&quot; AEW10 was held in Boppard, Germany on June 21-23, 2017. It is
based on a longstanding cooperation between Asian and European scientists. The
first workshop was held in Eindhoven, the Netherlands in 1989. The idea of the
workshop is threefold: 1) to improve the communication between the scientist in
the different parts of the world; 2) to exchange knowledge and ideas; and 3) to
pay a tribute to a well respected and special scientist.
</dc:description>
 <dc:description>Comment: 44 pages, editors for the proceedings: Yanling Chen and A. J. Han
  Vinck</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08569</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wisture: RNN-based Learning of Wireless Signals for Gesture Recognition
  in Unmodified Smartphones</dc:title>
 <dc:creator>Haseeb, Mohamed Abudulaziz Ali</dc:creator>
 <dc:creator>Parasuraman, Ramviyas</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper introduces Wisture, a new online machine learning solution for
recognizing touch-less dynamic hand gestures on a smartphone. Wisture relies on
the standard Wi-Fi Received Signal Strength (RSS) using a Long Short-Term
Memory (LSTM) Recurrent Neural Network (RNN), thresholding filters and traffic
induction. Unlike other Wi-Fi based gesture recognition methods, the proposed
method does not require a modification of the smartphone hardware or the
operating system, and performs the gesture recognition without interfering with
the normal operation of other smartphone applications.
  We discuss the characteristics of Wisture, and conduct extensive experiments
to compare its performance against state-of-the-art machine learning solutions
in terms of both accuracy and time efficiency. The experiments include a set of
different scenarios in terms of both spatial setup and traffic between the
smartphone and Wi-Fi access points (AP). The results show that Wisture achieves
an online recognition accuracy of up to 94% (average 78%) in detecting and
classifying three hand gestures.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08588</identifier>
 <datestamp>2017-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-organized Hierarchical Softmax</dc:title>
 <dc:creator>Shen, Yikang</dc:creator>
 <dc:creator>Tan, Shawn</dc:creator>
 <dc:creator>Pal, Chrisopher</dc:creator>
 <dc:creator>Courville, Aaron</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a new self-organizing hierarchical softmax formulation for
neural-network-based language models over large vocabularies. Instead of using
a predefined hierarchical structure, our approach is capable of learning word
clusters with clear syntactical and semantic meaning during the language model
training process. We provide experiments on standard benchmarks for language
modeling and sentence compression tasks. We find that this approach is as fast
as other efficient softmax approximations, while achieving comparable or even
better performance relative to similar full softmax models.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08588</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08589</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polarization-Division Multiplexing Based on the Nonlinear Fourier
  Transform</dc:title>
 <dc:creator>Goossens, Jan-Willem</dc:creator>
 <dc:creator>Yousefi, Mansoor I.</dc:creator>
 <dc:creator>Jaou&#xeb;n, Yves</dc:creator>
 <dc:creator>Hafermann, Hartmut</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Polarization-division multiplexed (PDM) transmission based on the nonlinear
Fourier transform (NFT) is proposed for optical fiber communication. The NFT
algorithms are generalized from the scalar nonlinear Schr\&quot;odinger equation for
one polarization to the Manakov system for two polarizations. The transmission
performance of the PDM nonlinear frequency-division multiplexing (NFDM) and PDM
orthogonal frequency-division multiplexing (OFDM) are determined. It is shown
that the transmission performance in terms of Q-factor is approximately the
same in PDM-NFDM and single polarization NFDM at twice the data rate and that
the polarization-mode dispersion does not seriously degrade system performance.
Compared with PDM-OFDM, PDM-NFDM achieves a Q-factor gain of 6.4 dB. The theory
can be generalized to multi-mode fibers in the strong coupling regime, paving
the way for the application of the NFT to address the nonlinear effects in
space-division multiplexing.
</dc:description>
 <dc:description>Comment: 15 pages, 9 figures</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08589</dc:identifier>
 <dc:identifier>doi:10.1364/OE.25.026437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08598</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cognitive Hierarchy and Voting Manipulation</dc:title>
 <dc:creator>Elkind, Edith</dc:creator>
 <dc:creator>Grandi, Umberto</dc:creator>
 <dc:creator>Rossi, Francesca</dc:creator>
 <dc:creator>Slinko, Arkadii</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  By the Gibbard--Satterthwaite theorem, every reasonable voting rule for three
or more alternatives is susceptible to manipulation: there exist elections
where one or more voters can change the election outcome in their favour by
unilaterally modifying their vote. When a given election admits several such
voters, strategic voting becomes a game among potential manipulators: a
manipulative vote that leads to a better outcome when other voters are truthful
may lead to disastrous results when other voters choose to manipulate as well.
We consider this situation from the perspective of a boundedly rational voter,
and use the cognitive hierarchy framework to identify good strategies. We then
investigate the associated algorithmic questions under the k-approval voting
rule. We obtain positive algorithmic results for k=1 and 2, and NP- and
coNP-hardness results for k&gt;3.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08598</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08607</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effects of Contact Network Models on Stochastic Epidemic Simulations</dc:title>
 <dc:creator>Ahmad, Rehan</dc:creator>
 <dc:creator>Xu, Kevin S.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The importance of modeling the spread of epidemics through a population has
led to the development of mathematical models for infectious disease
propagation. A number of empirical studies have collected and analyzed data on
contacts between individuals using a variety of sensors. Typically one uses
such data to fit a probabilistic model of network contacts over which a disease
may propagate. In this paper, we investigate the effects of different contact
network models with varying levels of complexity on the outcomes of simulated
epidemics using a stochastic Susceptible-Infectious-Recovered (SIR) model. We
evaluate these network models on six datasets of contacts between people in a
variety of settings. Our results demonstrate that the choice of network model
can have a significant effect on how closely the outcomes of an epidemic
simulation on a simulated network match the outcomes on the actual network
constructed from the sensor data. In particular, preserving degrees of nodes
appears to be much more important than preserving cluster structure for
accurate epidemic simulations.
</dc:description>
 <dc:description>Comment: To appear at International Conference on Social Informatics (SocInfo)
  2017</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08608</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enforcing Constraints on Outputs with Unconstrained Inference</dc:title>
 <dc:creator>Lee, Jay Yoon</dc:creator>
 <dc:creator>Wick, Michael</dc:creator>
 <dc:creator>Tristan, Jean-Baptiste</dc:creator>
 <dc:creator>Carbonell, Jaime</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Increasingly, practitioners apply neural networks to complex problems in
natural language processing (NLP), such as syntactic parsing, that have rich
output structures. Many such applications require deterministic constraints on
the output values; for example, requiring that the sequential outputs encode a
valid tree. While hidden units might capture such properties, the network is
not always able to learn them from the training data alone, and practitioners
must then resort to post-processing. In this paper, we present an inference
method for neural networks that enforces deterministic constraints on outputs
without performing post-processing or expensive discrete search over the
feasible space. Instead, for each input, we nudge the continuous weights until
the network's unconstrained inference procedure generates an output that
satisfies the constraints. We find that our method reduces the number of
violating outputs by up to 94%, while improving accuracy in constituency
parsing.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08608</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08616</identifier>
 <datestamp>2017-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guiding Reinforcement Learning Exploration Using Natural Language</dc:title>
 <dc:creator>Harrison, Brent</dc:creator>
 <dc:creator>Ehsan, Upol</dc:creator>
 <dc:creator>Riedl, Mark O.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this work we present a technique to use natural language to help
reinforcement learning generalize to unseen environments. This technique uses
neural machine translation, specifically the use of encoder-decoder networks,
to learn associations between natural language behavior descriptions and
state-action information. We then use this learned model to guide agent
exploration using a modified version of policy shaping to make it more
effective at learning in unseen environments. We evaluate this technique using
the popular arcade game, Frogger, under ideal and non-ideal conditions. This
evaluation shows that our modified policy shaping algorithm improves over a
Q-learning agent as well as a baseline version of policy shaping.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08616</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08617</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>n-Dimensional Fuzzy Negations</dc:title>
 <dc:creator>Bedregal, Benjam&#xed;n</dc:creator>
 <dc:creator>Mezzomo, Ivan</dc:creator>
 <dc:creator>Reiser, Renata Hax Sander</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  n-Dimensional fuzzy sets is a fuzzy set extension where the membership values
are n-tuples of real numbers in the unit interval [0,1] orderly increased,
called n-dimensional intervals. The set of n-dimensional intervals is denoted
by Ln([0,1]). This paper aims to investigate a special extension from [0,1] -
n-representable fuzzy negations on Ln([0,1]), summarizing the class of such
functions which are continuous and monotone by part. The main properties of
(strong) fuzzy negations on [0,1] are preserved by representable (strong) fuzzy
negation on Ln([0,1]), mainly related to the analysis of degenerate elements
and equilibrium points. The conjugate obtained by action of an n-dimensional
automorphism on an $n$-dimensional fuzzy negation provides a method to obtain
other n-dimensional fuzzy negation, in which properties such as
representability, continuity and monotonicity on Ln([0,1]) are preserved.
</dc:description>
 <dc:description>Comment: 20 pages and no figures</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08617</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08618</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Process Description, Behavior, and Control</dc:title>
 <dc:creator>Al-Fedaghi, Sabah</dc:creator>
 <dc:creator>Alahmad, Haya</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Modeling processes are the activities of capturing and representing processes
and control of their dynamic behavior. Desired features of the model include
capture of relevant aspects of a real phenomenon, understandability, and
completeness of static and dynamic specifications. This paper proposes a
diagrammatic language for engineering process modeling that provides an
integration tool for capturing the static description of processes, framing
their behaviors in terms of events, and utilizing the resultant model for
controlling processes. Without loss of generality, the focus of the paper is on
process modeling in the area of computer engineering, and specifically, on
modeling of computer services. To demonstrate the viability of the method, the
proposed model is applied to depicting flow of services in the Information
Technology department of a government ministry.
</dc:description>
 <dc:description>Comment: 10 pages, 12 figures</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08618</dc:identifier>
 <dc:identifier>International Journal of Computer Science and Information
  Security, Vol. 15, No. 7, July 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08619</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Public Evidence from Secret Ballots</dc:title>
 <dc:creator>Bernhard, Matthew</dc:creator>
 <dc:creator>Benaloh, Josh</dc:creator>
 <dc:creator>Halderman, J. Alex</dc:creator>
 <dc:creator>Rivest, Ronald L.</dc:creator>
 <dc:creator>Ryan, Peter Y. A.</dc:creator>
 <dc:creator>Stark, Philip B.</dc:creator>
 <dc:creator>Teague, Vanessa</dc:creator>
 <dc:creator>Vora, Poorvi L.</dc:creator>
 <dc:creator>Wallach, Dan S.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Elections seem simple---aren't they just counting? But they have a unique,
challenging combination of security and privacy requirements. The stakes are
high; the context is adversarial; the electorate needs to be convinced that the
results are correct; and the secrecy of the ballot must be ensured. And they
have practical constraints: time is of the essence, and voting systems need to
be affordable and maintainable, and usable by voters, election officials, and
pollworkers. It is thus not surprising that voting is a rich research area
spanning theory, applied cryptography, practical systems analysis, usable
security, and statistics. Election integrity involves two key concepts:
convincing evidence that outcomes are correct and privacy, which amounts to
convincing assurance that there is no evidence about how any given person
voted. These are obviously in tension. We examine how current systems walk this
tightrope.
</dc:description>
 <dc:description>Comment: To appear in E-Vote-Id '17</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08621</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communication versus Computation: Duality for multiple access channels
  and source coding</dc:title>
 <dc:creator>Zhu, Jingge</dc:creator>
 <dc:creator>Lim, Sung Hoon</dc:creator>
 <dc:creator>Gastpar, Michael</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Computation codes in network information theory are designed for the
scenarios where the decoder is not interested in recovering the information
sources themselves, but only a function thereof. K\&quot;orner and Marton showed for
distributed source coding that such function decoding can be achieved more
efficiently than decoding the full information sources. Compute-and-forward has
shown that function decoding, in combination with network coding ideas, is a
useful building block for end-to-end communication. In both cases, good
computation codes are the key component in the coding schemes. In this work, we
expose the fact that good computation codes could undermine the capability of
the codes for recovering the information sources individually, e.g., for the
purpose of multiple access and distributed source coding. Particularly, we
establish duality results between the codes which are good for computation and
the codes which are good for multiple access or distributed compression.
</dc:description>
 <dc:description>Comment: submitted</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08621</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08626</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Rigid Point Registration based on Convolution of Adaptive
  Gaussian Mixture Models</dc:title>
 <dc:creator>Pu, Can</dc:creator>
 <dc:creator>Li, Nanbo</dc:creator>
 <dc:creator>Fisher, Robert B</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Matching 3D rigid point clouds in complex environments robustly and
accurately is still a core technique used in many applications. This paper
proposes a new architecture combining error estimation from sample covariances
and dual global probability alignment based on the convolution of adaptive
Gaussian Mixture Models (GMM) from point clouds. Firstly, a novel adaptive GMM
is defined using probability distributions from the corresponding points. Then
rigid point cloud alignment is performed by maximizing the global probability
from the convolution of dual adaptive GMMs in the whole 2D or 3D space, which
can be efficiently optimized and has a large zone of accurate convergence.
Thousands of trials have been conducted on 200 models from public 2D and 3D
datasets to demonstrate superior robustness and accuracy in complex
environments with unpredictable noise, outliers, occlusion, initial rotation,
shape and missing points.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08626</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08627</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Feasibility Study of Using Light Fidelity With Multiple Unmanned
  Aerial Vehicles For Indoor Collaborative And Cooperative Networking</dc:title>
 <dc:creator>Sadiq, B. O</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper evaluates the feasibility of using light fidelity with multiple
Unmanned Aerial Vehicles (UAVs) for indoor collaborative and cooperative
networking. A number of works have presentedchallenges for wireless networking
with multiple UAVs such as bandwidth efficiency, security and environment
amongst others. Due to this fact, there is a need to secure information and
data in UAV ad hoc network (FANETs) using a secure transmission medium that
guarantees bandwidth efficiency such as the light fidelity (Li-Fi). Li-Fi
enables data transmission using visible light through a light emitting diode
(LED) and is chosen as against wireless fidelity (Wi- Fi) because it is more
ideal for high density wireless data coverage in confined areas, better at
addressing radio interference related issues and provides better bandwidth,
efficiency, availability and security. Thus, using Light Fidelity as a means of
communication necessitates the need to develop a Link Velocity Based
Connectivity Algorithm (LVCA) that governs communication between the UAVs and
the Li-Fi transmitter and receiver circuits for collaborative and cooperative
networking.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-07-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08630</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Filter Size in Convolutional Neural Networks for Facial
  Action Unit Recognition</dc:title>
 <dc:creator>Han, Shizhong</dc:creator>
 <dc:creator>Meng, Zibo</dc:creator>
 <dc:creator>Li, Zhiyuan</dc:creator>
 <dc:creator>O'Reilly, James</dc:creator>
 <dc:creator>Cai, Jie</dc:creator>
 <dc:creator>Wang, Xiaofeng</dc:creator>
 <dc:creator>Tong, Yan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recognizing facial action units (AUs) during spontaneous facial displays is a
challenging problem. Most recently, Convolutional Neural Networks (CNNs) have
shown promise for facial AU recognition, where predefined and fixed convolution
filter sizes are employed. In order to achieve the best performance, the
optimal filter size is often empirically found by conducting extensive
experimental validation. Such a training process suffers from expensive
training cost, especially as the network becomes deeper.
  This paper proposes a novel Optimized Filter Size CNN (OFS-CNN), where the
filter sizes and weights of all convolutional layers are learned simultaneously
from the training data along with learning convolution filters. Specifically,
the filter size is defined as a continuous variable, which is optimized by
minimizing the training loss. Experimental results on two AU-coded spontaneous
databases have shown that the proposed OFS-CNN is capable of estimating optimal
filter size for varying image resolution and outperforms traditional CNNs with
the best filter size obtained by exhaustive search. The OFS-CNN also beats the
CNN using multiple filter sizes and more importantly, is much more efficient
during testing with the proposed forward-backward propagation algorithm.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08630</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08645</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning a Target Sample Re-Generator for Cross-Database
  Micro-Expression Recognition</dc:title>
 <dc:creator>Zong, Yuan</dc:creator>
 <dc:creator>Huang, Xiaohua</dc:creator>
 <dc:creator>Zheng, Wenming</dc:creator>
 <dc:creator>Cui, Zhen</dc:creator>
 <dc:creator>Zhao, Guoying</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we investigate the cross-database micro-expression recognition
problem, where the training and testing samples are from two different
micro-expression databases. Under this setting, the training and testing
samples would have different feature distributions and hence the performance of
most existing micro-expression recognition methods may decrease greatly. To
solve this problem, we propose a simple yet effective method called Target
Sample Re-Generator (TSRG) in this paper. By using TSRG, we are able to
re-generate the samples from target micro-expression database and the
re-generated target samples would share same or similar feature distributions
with the original source samples. For this reason, we can then use the
classifier learned based on the labeled source samples to accurately predict
the micro-expression categories of the unlabeled target samples. To evaluate
the performance of the proposed TSRG method, extensive cross-database
micro-expression recognition experiments designed based on SMIC and CASME II
databases are conducted. Compared with recent state-of-the-art cross-database
emotion recognition methods, the proposed TSRG achieves more promising results.
</dc:description>
 <dc:description>Comment: To appear at ACM Multimedia 2017</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08645</dc:identifier>
 <dc:identifier>doi:10.1145/3123266.3123367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08652</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on IC-Planar Graphs</dc:title>
 <dc:creator>Bachmaier, Christian</dc:creator>
 <dc:creator>Brandenburg, Franz J.</dc:creator>
 <dc:creator>Hanauer, Kathrin</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A graph is IC-planar if it admits a drawing in the plane with at most one
crossing per edge and such that two pairs of crossing edges share no common end
vertex. IC-planarity specializes both NIC-planarity, which allows a pair of
crossing edges to share at most one vertex, and 1-planarity, where each edge
may be crossed at most once. We show that there are infinitely maximal
IC-planar graphs with n vertices and 3n-5 edges and thereby prove a tight lower
bound on the density of this class of graphs.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08660</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal dynamics of semantic relations in word embeddings: an
  application to predicting armed conflict participants</dc:title>
 <dc:creator>Kutuzov, Andrey</dc:creator>
 <dc:creator>Velldal, Erik</dc:creator>
 <dc:creator>&#xd8;vrelid, Lilja</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper deals with using word embedding models to trace the temporal
dynamics of semantic relations between pairs of words. The set-up is similar to
the well-known analogies task, but expanded with a time dimension. To this end,
we apply incremental updating of the models with new training texts, including
incremental vocabulary expansion, coupled with learned transformation matrices
that let us map between members of the relation. The proposed approach is
evaluated on the task of predicting insurgent armed groups based on
geographical locations. The gold standard data for the time span 1994--2010 is
extracted from the UCDP Armed Conflicts dataset. The results show that the
method is feasible and outperforms the baselines, but also that important work
still remains to be done.
</dc:description>
 <dc:description>Comment: to appear in EMNLP 2017 proceedings</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08668</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tale of Two DRAGGNs: A Hybrid Approach for Interpreting
  Action-Oriented and Goal-Oriented Instructions</dc:title>
 <dc:creator>Karamcheti, Siddharth</dc:creator>
 <dc:creator>Williams, Edward C.</dc:creator>
 <dc:creator>Arumugam, Dilip</dc:creator>
 <dc:creator>Rhee, Mina</dc:creator>
 <dc:creator>Gopalan, Nakul</dc:creator>
 <dc:creator>Wong, Lawson L. S.</dc:creator>
 <dc:creator>Tellex, Stefanie</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Robots operating alongside humans in diverse, stochastic environments must be
able to accurately interpret natural language commands. These instructions
often fall into one of two categories: those that specify a goal condition or
target state, and those that specify explicit actions, or how to perform a
given task. Recent approaches have used reward functions as a semantic
representation of goal-based commands, which allows for the use of a
state-of-the-art planner to find a policy for the given task. However, these
reward functions cannot be directly used to represent action-oriented commands.
We introduce a new hybrid approach, the Deep Recurrent Action-Goal Grounding
Network (DRAGGN), for task grounding and execution that handles natural
language from either category as input, and generalizes to unseen environments.
Our robot-simulation results demonstrate that a system successfully
interpreting both goal-oriented and action-oriented task specifications brings
us closer to robust natural language understanding for human-robot interaction.
</dc:description>
 <dc:description>Comment: Accepted at the 1st Workshop on Language Grounding for Robotics at
  ACL 2017</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08668</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08680</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entropy-Based $Sim(3)$ Calibration of 2D Lidars to Egomotion Sensors</dc:title>
 <dc:creator>Lambert, Jacob</dc:creator>
 <dc:creator>Clement, Lee</dc:creator>
 <dc:creator>Giamou, Matthew</dc:creator>
 <dc:creator>Kelly, Jonathan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper explores the use of an entropy-based technique for point cloud
reconstruction with the goal of calibrating a lidar to a sensor capable of
providing egomotion information. We extend recent work in this area to the
problem of recovering the $Sim(3)$ transformation between a 2D lidar and a
rigidly attached monocular camera, where the scale of the camera trajectory is
not known a priori. We demonstrate the robustness of our approach on realistic
simulations in multiple environments, as well as on data collected from a
hand-held sensor rig. Given a non-degenerate trajectory and a sufficient number
of lidar measurements, our calibration procedure achieves millimetre-scale and
sub-degree accuracy. Moreover, our method relaxes the need for specific scene
geometry, fiducial markers, or overlapping sensor fields of view, which had
previously limited similar techniques.
</dc:description>
 <dc:description>Comment: In Proceedings of the IEEE International Conference on Multisensor
  Fusion and Integration for Intelligent Systems (MFI'16), Baden-Baden,
  Germany, September 19-21, 2016. Best Student Paper Award</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08680</dc:identifier>
 <dc:identifier>doi:10.1109/MFI.2016.7849530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08682</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context-aware Single-Shot Detector</dc:title>
 <dc:creator>Xiang, Wei</dc:creator>
 <dc:creator>Zhang, Dong-Qing</dc:creator>
 <dc:creator>Athitsos, Vassilis</dc:creator>
 <dc:creator>Yu, Heather</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  SSD is one of the state-of-the-art object detection algorithms, and it
combines high detection accuracy with real-time speed. However, it is widely
recognized that SSD is less accurate in detecting small objects compared to
large objects, because it ignores the context from outside the proposal boxes.
In this paper, we present CSSD--a shorthand for context-aware single-shot
multibox object detector. CSSD is built on top of SSD, with additional layers
modeling multi-scale contexts. We describe two variants of CSSD, which differ
in their context layers, using dilated convolution layers (DiCSSD) and
deconvolution layers (DeCSSD) respectively. The experimental results show that
the multi-scale context modeling significantly improves the detection accuracy.
In addition, we study the relationship between effective receptive fields
(ERFs) and the theoretical receptive fields (TRFs), particularly on a VGGNet.
The empirical results further strengthen our conclusion that SSD coupled with
context layers achieves better detection results especially for small objects
($+3.2\% {\rm AP}_{@0.5}$ on MS-COCO compared to the newest SSD), while
maintaining comparable runtime performance.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08684</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Naive Algorithm for Feedback Vertex Set</dc:title>
 <dc:creator>Cao, Yixin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68R10</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Given a graph on $n$ vertices and an integer $k$, the feedback vertex set
problem asks for the deletion of at most $k$ vertices to make the graph
acyclic. We show that a greedy branching algorithm, which always branches on an
undecided vertex with the largest degree, runs in single-exponential time,
i.e., $O(c^k\cdot n^2)$ for some constant $c$.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08689</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Robot Transfer Learning: A Dynamical System Perspective</dc:title>
 <dc:creator>Helwa, Mohamed K.</dc:creator>
 <dc:creator>Schoellig, Angela P.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Multi-robot transfer learning allows a robot to use data generated by a
second, similar robot to improve its own behavior. The potential advantages are
reducing the time of training and the unavoidable risks that exist during the
training phase. Transfer learning algorithms aim to find an optimal transfer
map between different robots. In this paper, we investigate, through a
theoretical study of single-input single-output (SISO) systems, the properties
of such optimal transfer maps. We first show that the optimal transfer learning
map is, in general, a dynamic system. The main contribution of the paper is to
provide an algorithm for determining the properties of this optimal dynamic map
including its order and regressors (i.e., the variables it depends on). The
proposed algorithm does not require detailed knowledge of the robots' dynamics,
but relies on basic system properties easily obtainable through simple
experimental tests. We validate the proposed algorithm experimentally through
an example of transfer learning between two different quadrotor platforms.
Experimental results show that an optimal dynamic map, with correct properties
obtained from our proposed algorithm, achieves 60-70% reduction of transfer
learning error compared to the cases when the data is directly transferred or
transferred using an optimal static map.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures, accepted at the 2017 IEEE/RSJ International
  Conference on Intelligent Robots and Systems</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08689</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08690</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vertex Deletion Problems on Chordal Graphs</dc:title>
 <dc:creator>Cao, Yixin</dc:creator>
 <dc:creator>Ke, Yuping</dc:creator>
 <dc:creator>Otachi, Yota</dc:creator>
 <dc:creator>You, Jie</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Containing many classic optimization problems, the family of vertex deletion
problems has an important position in algorithm and complexity study. The
celebrated result of Lewis and Yannakakis gives a complete dichotomy of their
complexity. It however has nothing to say about the case when the input graph
is also special. This paper initiates a systematic study of vertex deletion
problems from one subclass of chordal graphs to another. We give
polynomial-time algorithms or proofs of NP-completeness for most of the
problems. In particular, we show that the vertex deletion problem from chordal
graphs to interval graphs is NP-complete.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08691</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive and Resilient Revenue Maximizing Resource Allocation and
  Pricing in Cloud Computing Environments</dc:title>
 <dc:creator>Farooq, Muhammad Junaid</dc:creator>
 <dc:creator>Zhu, Quanyan</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Cloud computing is becoming an essential component of modern computer and
communication systems. The available resources at the cloud such as computing
nodes, storage, databases, etc. are often packaged in the form of virtual
machines (VMs) to be used by remotely located client applications for
computational tasks. However, the cloud has a limited number of VMs available,
which have to be efficiently utilized to generate higher productivity and
subsequently generate maximum revenue. Client applications generate requests
with computational tasks at random times with random complexity to be processed
by the cloud. The cloud service provider (CSP) has to decide whether to
allocate a VM to a task at hand or to wait for a higher complexity task in the
future. We propose a threshold-based mechanism to optimally decide the
allocation and pricing of VMs to sequentially arriving requests in order to
maximize the revenue of the CSP over a finite time horizon. Moreover, we
develop an adaptive and resilient framework based that can counter the effect
of realtime changes in the number of available VMs at the cloud server, the
frequency and nature of arriving tasks on the revenue of the CSP.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08691</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08696</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Digital Forensic Approaches for Amazon Alexa Ecosystem</dc:title>
 <dc:creator>Chung, Hyunji</dc:creator>
 <dc:creator>Park, Jungheum</dc:creator>
 <dc:creator>Lee, Sangjin</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Internet of Things devices such as the Amazon Echo are undoubtedly great
sources of potential digital evidence due to their ubiquitous use and their
always on mode of operation, constituting a human life black box. The Amazon
Echo in particular plays a centric role for the cloud based intelligent virtual
assistant Alexa developed by Amazon Lab126. The Alexa enabled wireless smart
speaker is the gateway for all voice commands submitted to Alexa. Moreover, the
IVA interacts with a plethora of compatible IoT devices and third party
applications that leverage cloud resources. Understanding the complex cloud
ecosystem that allows ubiquitous use of Alexa is paramount on supporting
digital investigations when need raises. This paper discusses methods for
digital forensics pertaining to the IVA Alexa ecosystem. The primary
contribution of this paper consists of a new efficient approach of combining
cloud native forensics with client side forensics, to support practical digital
investigations. Based on a deep understanding of the targeted ecosystem, we
propose a proof of concept tool, CIFT, that supports identification,
acquisition and analysis of both native artifacts from the cloud and client
centric artifacts from local devices.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures, conference accepted paper</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08704</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anytime Exact Belief Propagation</dc:title>
 <dc:creator>Ferreira, Gabriel Azevedo</dc:creator>
 <dc:creator>Bertrand, Quentin</dc:creator>
 <dc:creator>Maussion, Charles</dc:creator>
 <dc:creator>Braz, Rodrigo de Salvo</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Statistical Relational Models and, more recently, Probabilistic Programming,
have been making strides towards an integration of logic and probabilistic
reasoning. A natural expectation for this project is that a probabilistic logic
reasoning algorithm reduces to a logic reasoning algorithm when provided a
model that only involves 0-1 probabilities, exhibiting all the advantages of
logic reasoning such as short-circuiting, intelligibility, and the ability to
provide proof trees for a query answer. In fact, we can take this further and
require that these characteristics be present even for probabilistic models
with probabilities \emph{near} 0 and 1, with graceful degradation as the model
becomes more uncertain. We also seek inference that has amortized constant time
complexity on a model's size (even if still exponential in the induced width of
a more directly relevant portion of it) so that it can be applied to huge
knowledge bases of which only a relatively small portion is relevant to typical
queries. We believe that, among the probabilistic reasoning algorithms, Belief
Propagation is the most similar to logic reasoning: messages are propagated
among neighboring variables, and the paths of message-passing are similar to
proof trees. However, Belief Propagation is either only applicable to tree
models, or approximate (and without guarantees) for precision and convergence.
In this paper we present work in progress on an Anytime Exact Belief
Propagation algorithm that is very similar to Belief Propagation but is exact
even for graphical models with cycles, while exhibiting soft short-circuiting,
amortized constant time complexity in the model size, and which can provide
probabilistic proof trees.
</dc:description>
 <dc:description>Comment: Submission to StaRAI-17 workshop at UAI-17 conference</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08704</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08705</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Jointly Learned Deep Architecture for Facial Attribute Analysis and
  Face Detection in the Wild</dc:title>
 <dc:creator>He, Keke</dc:creator>
 <dc:creator>Fu, Yanwei</dc:creator>
 <dc:creator>Xue, Xiangyang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Facial attribute analysis in the real world scenario is very challenging
mainly because of complex face variations. Existing works of analyzing face
attributes are mostly based on the cropped and aligned face images. However,
this result in the capability of attribute prediction heavily relies on the
preprocessing of face detector. To address this problem, we present a novel
jointly learned deep architecture for both facial attribute analysis and face
detection. Our framework can process the natural images in the wild and our
experiments on CelebA and LFWA datasets clearly show that the state-of-the-art
performance is obtained.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08711</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Example Setups of Navier-Stokes Equations with Control and Observation:
  Spatial Discretization and Representation via Linear-quadratic Matrix
  Coefficients</dc:title>
 <dc:creator>Behr, Maximilian</dc:creator>
 <dc:creator>Benner, Peter</dc:creator>
 <dc:creator>Heiland, Jan</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>68U20</dc:subject>
 <dc:description>  We provide spatial discretizations of nonlinear incompressible Navier-Stokes
equations with inputs and outputs in the form of matrices ready to use in any
numerical linear algebra package. We discuss the assembling of the system
operators and the realization of boundary conditions and inputs and outputs. We
describe the two benchmark problems - the driven cavity and the cylinder wake -
and provide the corresponding data. The use of the data is illustrated by
numerous example setups. The test cases are provided as plain PYTHON or
OCTAVE/MATLAB script files for immediate replication.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08713</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Determining Semantic Textual Similarity using Natural Deduction Proofs</dc:title>
 <dc:creator>Yanaka, Hitomi</dc:creator>
 <dc:creator>Mineshima, Koji</dc:creator>
 <dc:creator>Martinez-Gomez, Pascual</dc:creator>
 <dc:creator>Bekki, Daisuke</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Determining semantic textual similarity is a core research subject in natural
language processing. Since vector-based models for sentence representation
often use shallow information, capturing accurate semantics is difficult. By
contrast, logical semantic representations capture deeper levels of sentence
semantics, but their symbolic nature does not offer graded notions of textual
similarity. We propose a method for determining semantic textual similarity by
combining shallow features with features extracted from natural deduction
proofs of bidirectional entailment relations between sentence pairs. For the
natural deduction proofs, we use ccg2lambda, a higher-order automatic inference
system, which converts Combinatory Categorial Grammar (CCG) derivation trees
into semantic representations and conducts natural deduction proofs.
Experiments show that our system was able to outperform other logic-based
systems and that features derived from the proofs are effective for learning
textual similarity.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures, accepted as long paper of EMNLP2017</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08713</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08715</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Safety Requirement Specifications for Connected Vehicles</dc:title>
 <dc:creator>Singh, Madhusudan</dc:creator>
 <dc:creator>Kim, Shiho</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In the coming years, transportation system will be revamped in a manner that
there will be more intelligent and autonomous vehicle phenomenon around us such
as smart cars, auto driving system, etc. Some of automotive industries are
already producing smart cars. However, the main concern of this paper is on the
infrastructure for connected vehicles, which can support such intelligent
transportation. Current transportation system lacks proper infrastructure to
support connected vehicles. Hence, in this article, we have surveyed and
analyzed the current transportation system in developed and developing
countries. In contrast, we are going to introduce secure intelligent
transportation (roadside) infrastructure that is user centric (Driver,
Autonomous driver etc.) for connected vehicles. In this paper we present the
basic requirements of safety engineering infrastructure of roadside
infrastructure in ITS for connected vehicles. Connected vehicles has network
infrastructure to communicate with vehicle-to-vehicle (V-to-V),
vehicle-to-infrastructure (V-to-I), lane correction system, and traffic
information system etc. The connected vehicle is a good model for learning
demands of infrastructure for ITS process because the system having a lot of
use-cases and we must understand relationship between public institutions,
people, companies in order to proceed ITS System.
</dc:description>
 <dc:description>Comment: 5 pages, 5 figures, 1 table</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08715</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08716</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A vehicle with a two-wheel steering system mobile in shallow dense
  granular media</dc:title>
 <dc:creator>Lee, Po-Yi</dc:creator>
 <dc:creator>Tsai, Meng-Chi</dc:creator>
 <dc:creator>Hsieh, I-Ta</dc:creator>
 <dc:creator>Tseng, Pin-Ju</dc:creator>
 <dc:creator>Gao, Guo-Jie Jason</dc:creator>
 <dc:subject>Condensed Matter - Soft Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We design a vehicle with a steering system made of two independently
rotatable wheels on the front. We quantify the effectiveness of the steering
system in the mobility and maneuverability of the vehicle running in a box
containing a layer ping-pong balls with a packing density 0.8, below the random
close packing value 0.84 in 2D. The steering system can reduce the resistance
exerted by the jammed balls formed ahead of the fast-moving vehicle. Moreover,
if only one of the two steering wheels rotates, the vehicle can turn into the
direction opposite to the rotating wheel. The steering system performs more
efficiently if the wheels engage the ping-pong balls better by increasing the
contact area between the wheels and the balls. We advocate applying our design
to machines moving in granular materials with a moderate packing density.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08718</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ultra-low-power Wireless Streaming Cameras</dc:title>
 <dc:creator>Naderiparizi, Saman</dc:creator>
 <dc:creator>Hessar, Mehrdad</dc:creator>
 <dc:creator>Talla, Vamsi</dc:creator>
 <dc:creator>Gollakota, Shyamnath</dc:creator>
 <dc:creator>Smith, Joshua R.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Wireless video streaming has traditionally been considered an extremely
power-hungry operation. Existing approaches optimize the camera and
communication modules individually to minimize their power consumption.
However, the joint redesign and optimization of wireless communication as well
as the camera is what that provides more power saving. We present an
ultra-low-power wireless video streaming camera. To achieve this, we present a
novel &quot;analog&quot; video backscatter technique that feeds analog pixels from the
photo-diodes directly to the backscatter hardware, thereby eliminating power
consuming hardware components such as ADCs and amplifiers. We prototype our
wireless camera using off-the-shelf hardware and show that our design can
stream video at up to 13 FPS and can operate up to a distance of 150 feet from
the access point. Our COTS prototype consumes 2.36mW. Finally, to demonstrate
the potential of our design, we built two proof-of-concept applications: video
streaming for micro-robots and security cameras for face detection.
</dc:description>
 <dc:description>Comment: 9 pages, 11 figures</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08721</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Web Images for Weakly Supervised Object Detection</dc:title>
 <dc:creator>Tao, Qingyi</dc:creator>
 <dc:creator>Yang, Hao</dc:creator>
 <dc:creator>Cai, Jianfei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In recent years, the performance of object detection has advanced
significantly with the evolving deep convolutional neural networks. However,
the state-of-the-art object detection methods still rely on accurate bounding
box annotations that require extensive human labelling. Object detection
without bounding box annotations, i.e, weakly supervised detection methods, are
still lagging far behind. As weakly supervised detection only uses image level
labels and does not require the ground truth of bounding box location and label
of each object in an image, it is generally very difficult to distill knowledge
of the actual appearances of objects. Inspired by curriculum learning, this
paper proposes an easy-to-hard knowledge transfer scheme that incorporates easy
web images to provide prior knowledge of object appearance as a good starting
point. While exploiting large-scale free web imagery, we introduce a
sophisticated labour free method to construct a web dataset with good diversity
in object appearance. After that, semantic relevance and distribution relevance
are introduced and utilized in the proposed curriculum training scheme. Our
end-to-end learning with the constructed web data achieves remarkable
improvement across most object classes especially for the classes that are
often considered hard in other works.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08721</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08722</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algebraic Relations and Triangulation of Unlabeled Image Points</dc:title>
 <dc:creator>Wagner, Andr&#xe9;</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In multiview geometry when correspondences among multiple views are unknown
the image points can be understood as being unlabeled. This is a common problem
in computer vision. We give a novel approach to handle such a situation by
regarding unlabeled point configurations as points on the Chow variety
$\text{Sym}_m(\mathbb{P}^2)$. For two unlabeled points we design an algorithm
that solves the triangulation problem with unknown correspondences. Further the
unlabeled multiview variety $\text{Sym}_m(V_A)$ is studied.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08722</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08725</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Improved Subsumption Testing Algorithm for the Optimal-Size Sorting
  Network Problem</dc:title>
 <dc:creator>Frasinaru, Cristian</dc:creator>
 <dc:creator>Raschip, Madalina</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper a new method for checking the subsumption relation for the
optimal-size sorting network problem is described. The new approach is based on
creating a bipartite graph and modelling the subsumption test as the problem of
enumerating all perfect matchings in this graph. Experiments showed significant
improvements over the previous approaches when considering the number of
subsumption checks and the time needed to find optimal-size sorting networks.
We were able to generate all the complete sets of filters for comparator
networks with 9 channels, confirming that the 25-comparators sorting network is
optimal. The running time was reduced more than 10 times, compared to the
state-of-the-art results.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08729</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Audio Sequence Representations for Acoustic Event
  Classification</dc:title>
 <dc:creator>Zhang, Zixing</dc:creator>
 <dc:creator>Liu, Ding</dc:creator>
 <dc:creator>Han, Jing</dc:creator>
 <dc:creator>Schuller, Bj&#xf6;rn</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Acoustic Event Classification (AEC) has become a significant task for
machines to perceive the surrounding auditory scene. However, extracting
effective representations that capture the underlying characteristics of the
acoustic events is still challenging. Previous methods mainly focused on
designing the audio features in a 'hand-crafted' manner. Interestingly,
data-learnt features have been recently reported to show better performance. Up
to now, these were only considered on the frame-level. In this paper, we
propose an unsupervised learning framework to learn a vector representation of
an audio sequence for AEC. This framework consists of a Recurrent Neural
Network (RNN) encoder and a RNN decoder, which respectively transforms the
variable-length audio sequence into a fixed-length vector and reconstructs the
input sequence on the generated vector. After training the encoder-decoder, we
feed the audio sequences to the encoder and then take the learnt vectors as the
audio sequence representations. Compared with previous methods, the proposed
method can not only deal with the problem of arbitrary-lengths of audio
streams, but also learn the salient information of the sequence. Extensive
evaluation on a large-size acoustic event database is performed, and the
empirical results demonstrate that the learnt audio sequence representation
yields a significant performance improvement by a large margin compared with
other state-of-the-art hand-crafted sequence features for AEC.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08730</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Quantum Approach to Subset-Sum and Similar Problems</dc:title>
 <dc:creator>Daskin, Ammar</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we study the subset-sum problem by using a quantum heuristic
approach similar to the verification circuit of quantum Arthur-Merlin games.
Under described certain assumptions, we show that the exact solution of the
subset sum problem my be obtained in polynomial time and the exponential
speed-up over the classical algorithms may be possible. We give a numerical
example and discuss the complexity of the approach and its further application
to the knapsack problem.
</dc:description>
 <dc:description>Comment: Missing references added, 13 pages</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08734</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Common Knowledge in a Logic of Gossips</dc:title>
 <dc:creator>Apt, Krzysztof R.</dc:creator>
 <dc:creator>Wojtczak, Dominik</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Gossip protocols aim at arriving, by means of point-to-point or group
communications, at a situation in which all the agents know each other secrets.
Recently a number of authors studied distributed epistemic gossip protocols.
These protocols use as guards formulas from a simple epistemic logic, which
makes their analysis and verification substantially easier.
  We study here common knowledge in the context of such a logic. First, we
analyze when it can be reduced to iterated knowledge. Then we show that the
semantics and truth for formulas without nested common knowledge operator are
decidable. This implies that implementability, partial correctness and
termination of distributed epistemic gossip protocols that use non-nested
common knowledge operator is decidable, as well. Given that common knowledge is
equivalent to an infinite conjunction of nested knowledge, these results are
non-trivial generalizations of the corresponding decidability results for the
original epistemic logic, established in (Apt &amp; Wojtczak, 2016).
  K. R. Apt &amp; D. Wojtczak (2016): On Decidability of a Logic of Gossips. In
Proc. of JELIA 2016, pp. 18-33, doi:10.1007/ 978-3-319-48758-8_2.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08734</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 10-27</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08735</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Logic for Global and Local Announcements</dc:title>
 <dc:creator>Belardinelli, Francesco</dc:creator>
 <dc:creator>van Ditmarsch, Hans</dc:creator>
 <dc:creator>van der Hoek, Wiebe</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper we introduce {\em global and local announcement logic} (GLAL),
a dynamic epistemic logic with two distinct announcement operators --
$[\phi]^+_A$ and $[\phi]^-_A$ indexed to a subset $A$ of the set $Ag$ of all
agents -- for global and local announcements respectively. The boundary case
$[\phi]^+_{Ag}$ corresponds to the public announcement of $\phi$, as known from
the literature. Unlike standard public announcements, which are {\em model
transformers}, the global and local announcements are {\em pointed model
transformers}. In particular, the update induced by the announcement may be
different in different states of the model. Therefore, the resulting
computations are trees of models, rather than the typical sequences. A
consequence of our semantics is that modally bisimilar states may be
distinguished in our logic. Then, we provide a stronger notion of bisimilarity
and we show that it preserves modal equivalence in GLAL. Additionally, we show
that GLAL is strictly more expressive than public announcement logic with
common knowledge. We prove a wide range of validities for GLAL involving the
interaction between dynamics and knowledge, and show that the satisfiability
problem for GLAL is decidable. We illustrate the formal machinery by means of
detailed epistemic scenarios.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08735</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 28-42</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08736</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relaxing Exclusive Control in Boolean Games</dc:title>
 <dc:creator>Belardinelli, Francesco</dc:creator>
 <dc:creator>Grandi, Umberto</dc:creator>
 <dc:creator>Herzig, Andreas</dc:creator>
 <dc:creator>Longin, Dominique</dc:creator>
 <dc:creator>Lorini, Emiliano</dc:creator>
 <dc:creator>Novaro, Arianna</dc:creator>
 <dc:creator>Perrussel, Laurent</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In the typical framework for boolean games (BG) each player can change the
truth value of some propositional atoms, while attempting to make her goal
true. In standard BG goals are propositional formulas, whereas in iterated BG
goals are formulas of Linear Temporal Logic. Both notions of BG are
characterised by the fact that agents have exclusive control over their set of
atoms, meaning that no two agents can control the same atom. In the present
contribution we drop the exclusivity assumption and explore structures where an
atom can be controlled by multiple agents. We introduce Concurrent Game
Structures with Shared Propositional Control (CGS-SPC) and show that they ac-
count for several classes of repeated games, including iterated boolean games,
influence games, and aggregation games. Our main result shows that, as far as
verification is concerned, CGS-SPC can be reduced to concurrent game structures
with exclusive control. This result provides a polynomial reduction for the
model checking problem of specifications in Alternating-time Temporal Logic on
CGS-SPC.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08736</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 43-56</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08737</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Game Equivalence and its Modal Logic</dc:title>
 <dc:creator>van Benthem, Johan</dc:creator>
 <dc:creator>Bezhanishvili, Nick</dc:creator>
 <dc:creator>Enqvist, Sebastian</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We revisit the crucial issue of natural game equivalences, and semantics of
game logics based on these. We present reasons for investigating finer concepts
of game equivalence than equality of standard powers, though staying short of
modal bisimulation. Concretely, we propose a more finegrained notion of
equality of &quot;basic powers&quot; which record what players can force plus what they
leave to others to do, a crucial feature of interaction. This notion is closer
to game-theoretic strategic form, as we explain in detail, while remaining
amenable to logical analysis. We determine the properties of basic powers via a
new representation theorem, find a matching &quot;instantial neighborhood game
logic&quot;, and show how our analysis can be extended to a new game algebra and
dynamic game logic.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08737</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 57-74</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08738</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Type Spaces to Probability Frames and Back, via Language</dc:title>
 <dc:creator>Bjorndahl, Adam</dc:creator>
 <dc:creator>Halpern, Joseph Y.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We investigate the connection between the two major mathematical frameworks
for modeling interactive beliefs: Harsanyi type spaces and possible-worlds
style probability frames. While translating the former into the latter is
straightforward, we demonstrate that the reverse translation relies implicitly
on a background logical language. Once this &quot;language parameter&quot; is made
explicit, it reveals a close relationship between universal type spaces and
canonical models: namely, that they are essentially the same construct. As the
nature of a canonical model depends heavily on the background logic used to
generate it, this work suggests a new view into a corresponding landscape of
universal type spaces.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08738</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 75-87</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08739</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rationalizability and Epistemic Priority Orderings</dc:title>
 <dc:creator>Catonini, Emiliano</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>C72, C73, D86</dc:subject>
 <dc:description>  At the beginning of a dynamic game, players may have exogenous theories about
how the opponents are going to play. Suppose that these theories are commonly
known. Then, players will refine their first-order beliefs, and challenge their
own theories, through strategic reasoning. I develop and characterize
epistemically a new solution concept, Selective Rationalizability, which
accomplishes this task under the following assumption: when the observed
behavior is not compatible with the beliefs in players' rationality and
theories of all orders, players keep the orders of belief in rationality that
are per se compatible with the observed behavior, and drop the incompatible
beliefs in the theories. Thus, Selective Rationalizability captures Common
Strong Belief in Rationality (Battigalli and Siniscalchi, 2002) and refines
Extensive-Form Rationalizability (Pearce, 1984; BS, 2002), whereas
Strong-$\Delta$-Rationalizability (Battigalli, 2003; Battigalli and
Siniscalchi, 2003) captures the opposite epistemic priority choice. Selective
Rationalizability can be extended to encompass richer epistemic priority
orderings among different theories of opponents' behavior. This allows to
establish a surprising connection with strategic stability (Kohlberg and
Mertens, 1986).
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08739</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 102-117</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08740</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preservation of Semantic Properties during the Aggregation of Abstract
  Argumentation Frameworks</dc:title>
 <dc:creator>Chen, Weiwei</dc:creator>
 <dc:creator>Endriss, Ulle</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  An abstract argumentation framework can be used to model the argumentative
stance of an agent at a high level of abstraction, by indicating for every pair
of arguments that is being considered in a debate whether the first attacks the
second. When modelling a group of agents engaged in a debate, we may wish to
aggregate their individual argumentation frameworks to obtain a single such
framework that reflects the consensus of the group. Even when agents disagree
on many details, there may well be high-level agreement on important semantic
properties, such as the acceptability of a given argument. Using techniques
from social choice theory, we analyse under what circumstances such semantic
properties agreed upon by the individual agents can be preserved under
aggregation.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08740</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 118-133</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08741</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary Voting with Delegable Proxy: An Analysis of Liquid Democracy</dc:title>
 <dc:creator>Christoff, Zo&#xe9;</dc:creator>
 <dc:creator>Grossi, Davide</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The paper provides an analysis of the voting method known as delegable proxy
voting, or liquid democracy. The analysis first positions liquid democracy
within the theory of binary aggregation. It then focuses on two issues of the
system: the occurrence of delegation cycles; and the effect of delegations on
individual rationality when voting on logically interdependent propositions. It
finally points to proposals on how the system may be modified in order to
address the above issues.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08741</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 134-150</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.10</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08742</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bisimulation in Inquisitive Modal Logic</dc:title>
 <dc:creator>Ciardelli, Ivano</dc:creator>
 <dc:creator>Otto, Martin</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  Inquisitive modal logic, InqML, is a generalisation of standard Kripke-style
modal logic. In its epistemic incarnation, it extends standard epistemic logic
to capture not just the information that agents have, but also the questions
that they are interested in. Technically, InqML fits within the family of
logics based on team semantics. From a model-theoretic perspective, it takes us
a step in the direction of monadic second-order logic, as inquisitive modal
operators involve quantification over sets of worlds. We introduce and
investigate the natural notion of bisimulation equivalence in the setting of
InqML. We compare the expressiveness of InqML and first-order logic, and
characterise inquisitive modal logic as the bisimulation invariant fragments of
first-order logic over various classes of two-sorted relational structures.
These results crucially require non-classical methods in studying bisimulations
and first-order expressiveness over non-elementary classes.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08742</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 151-166</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.11</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08743</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward an Epistemic-Logical Theory of Categorization</dc:title>
 <dc:creator>Conradie, Willem</dc:creator>
 <dc:creator>Frittella, Sabine</dc:creator>
 <dc:creator>Palmigiano, Alessandra</dc:creator>
 <dc:creator>Piazzai, Michele</dc:creator>
 <dc:creator>Tzimoulis, Apostolos</dc:creator>
 <dc:creator>Wijnberg, Nachoem M.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Categorization systems are widely studied in psychology, sociology, and
organization theory as information-structuring devices which are critical to
decision-making processes. In the present paper, we introduce a sound and
complete epistemic logic of categories and agents' categorical perception. The
Kripke-style semantics of this logic is given in terms of data structures based
on two domains: one domain representing objects (e.g. market products) and one
domain representing the features of the objects which are relevant to the
agents' decision-making. We use this framework to discuss and propose
logic-based formalizations of some core concepts from psychological,
sociological, and organizational research in categorization theory.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08743</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 167-186</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.12</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08744</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conditional Belief, Knowledge and Probability</dc:title>
 <dc:creator>van Eijck, Jan</dc:creator>
 <dc:creator>Li, Kai</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  A natural way to represent beliefs and the process of updating beliefs is
presented by Bayesian probability theory, where belief of an agent a in P can
be interpreted as a considering that P is more probable than not P. This paper
attempts to get at the core logical notion underlying this.
  The paper presents a sound and complete neighbourhood logic for conditional
belief and knowledge, and traces the connections with probabilistic logics of
belief and knowledge. The key notion in this paper is that of an agent a
believing P conditionally on having information Q, where it is assumed that Q
is compatible with what a knows.
  Conditional neighbourhood logic can be viewed as a core system for reasoning
about subjective plausibility that is not yet committed to an interpretation in
terms of numerical probability. Indeed, every weighted Kripke model gives rise
to a conditional neighbourhood model, but not vice versa. We show that our
calculus for conditional neighbourhood logic is sound but not complete for
weighted Kripke models. Next, we show how to extend the calculus to get
completeness for the class of weighted Kripke models.
  Neighbourhood models for conditional belief are closed under model
restriction (public announcement update), while earlier neighbourhood models
for belief as `willingness to bet' were not. Therefore the logic we present
improves on earlier neighbourhood logics for belief and knowledge. We present
complete calculi for public announcement and for publicly revealing the truth
value of propositions using reduction axioms. The reductions show that adding
these announcement operators to the language does not increase expressive
power.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08744</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 188-206</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.14</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08746</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coalition and Group Announcement Logic</dc:title>
 <dc:creator>Galimullin, Rustam</dc:creator>
 <dc:creator>Alechina, Natasha</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Dynamic epistemic logics which model abilities of agents to make various
announcements and influence each other's knowledge have been studied
extensively in recent years. Two notable examples of such logics are Group
Announcement Logic and Coalition Announcement Logic. They allow us to reason
about what groups of agents can achieve through joint announcements in
non-competitive and competitive environments. In this paper, we consider a
combination of these logics -- Coalition and Group Announcement Logic and
provide its complete axiomatisation. Moreover, we partially answer the question
of how group and coalition announcement operators interact, and settle some
other open problems.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08746</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 207-220</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.15</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08747</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Formal Approach to the Problem of Logical Non-Omniscience</dc:title>
 <dc:creator>Garrabrant, Scott</dc:creator>
 <dc:creator>Benson-Tilsen, Tsvi</dc:creator>
 <dc:creator>Critch, Andrew</dc:creator>
 <dc:creator>Soares, Nate</dc:creator>
 <dc:creator>Taylor, Jessica</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.0</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  We present the logical induction criterion for computable algorithms that
assign probabilities to every logical statement in a given formal language, and
refine those probabilities over time. The criterion is motivated by a series of
stock trading analogies. Roughly speaking, each logical sentence phi is
associated with a stock that is worth $1 per share if phi is true and nothing
otherwise, and we interpret the belief-state of a logically uncertain reasoner
as a set of market prices, where pt_N(phi)=50% means that on day N, shares of
phi may be bought or sold from the reasoner for 50%. A market is then called a
logical inductor if (very roughly) there is no polynomial-time computable
trading strategy with finite risk tolerance that earns unbounded profits in
that market over time. We then describe how this single criterion implies a
number of desirable properties of bounded reasoners; for example, logical
inductors outpace their underlying deductive process, perform universal
empirical induction given enough time to think, and place strong trust in their
own reasoning process.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08747</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 221-235</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.16</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08748</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Games With Tolerant Players</dc:title>
 <dc:creator>Ghosh, Arpita</dc:creator>
 <dc:creator>Halpern, Joseph Y.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  A notion of pi-tolerant equilibrium is defined that takes into account that
players have some tolerance regarding payoffs in a game. This solution concept
generalizes Nash and refines epsilon-Nash equilibrium in a natural way. We show
that pi-tolerant equilibrium can explain cooperation in social dilemmas such as
Prisoner's Dilemma and the Public Good game. We then examine the structure of
particularly cooperative pi-tolerant equilibria, where players are as
cooperative as they can be, subject to their tolerances, in Prisoner's Dilemma.
To the extent that cooperation is due to tolerance, these results provide
guidance to a mechanism designer who has some control over the payoffs in a
game, and suggest ways in which cooperation can be increased.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08748</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 251-264</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.18</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08749</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Drives People's Choices in Turn-Taking Games, if not Game-Theoretic
  Rationality?</dc:title>
 <dc:creator>Ghosh, Sujata</dc:creator>
 <dc:creator>Heifetz, Aviad</dc:creator>
 <dc:creator>Verbrugge, Rineke</dc:creator>
 <dc:creator>de Weerd, Harmen</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In an earlier experiment, participants played a perfect information game
against a computer, which was programmed to deviate often from its backward
induction strategy right at the beginning of the game. Participants knew that
in each game, the computer was nevertheless optimizing against some belief
about the participant's future strategy. In the aggregate, it appeared that
participants applied forward induction. However, cardinal effects seemed to
play a role as well: a number of participants might have been trying to
maximize expected utility.
  In order to find out how people really reason in such a game, we designed
centipede-like turn-taking games with new payoff structures in order to make
such cardinal effects less likely. We ran a new experiment with 50
participants, based on marble drop visualizations of these revised payoff
structures. After participants played 48 test games, we asked a number of
questions to gauge the participants' reasoning about their own and the
opponent's strategy at all decision nodes of a sample game. We also checked how
the verbalized strategies fit to the actual choices they made at all their
decision points in the 48 test games.
  Even though in the aggregate, participants in the new experiment still tend
to slightly favor the forward induction choice at their first decision node,
their verbalized strategies most often depend on their own attitudes towards
risk and those they assign to the computer opponent, sometimes in addition to
considerations about cooperativeness and competitiveness.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08749</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 265-284</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.19</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08750</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Epistemic Foundation for Authentication Logics (Extended Abstract)</dc:title>
 <dc:creator>Halpern, Joseph Y.</dc:creator>
 <dc:creator>van der Meyden, Ron</dc:creator>
 <dc:creator>Pucella, Riccardo</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  While there have been many attempts, going back to BAN logic, to base
reasoning about security protocols on epistemic notions, they have not been all
that successful. Arguably, this has been due to the particular logics chosen.
We present a simple logic based on the well-understood modal operators of
knowledge, time, and probability, and show that it is able to handle issues
that have often been swept under the rug by other approaches, while being
flexible enough to capture all the higher- level security notions that appear
in BAN logic. Moreover, while still assuming that the knowledge operator allows
for unbounded computation, it can handle the fact that a computationally
bounded agent cannot decrypt messages in a natural way, by distinguishing
strings and message terms. We demonstrate that our logic can capture BAN logic
notions by providing a translation of the BAN operators into our logic,
capturing belief by a form of probabilistic knowledge.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08750</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 306-323</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.21</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08751</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Knowledge-Based Analysis of the Blockchain Protocol</dc:title>
 <dc:creator>Halpern, Joseph Y.</dc:creator>
 <dc:creator>Pass, Rafael</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  At the heart of the Bitcoin is a blockchain protocol, a protocol for
achieving consensus on a public ledger that records bitcoin transactions. To
the extent that a blockchain protocol is used for applications such as contract
signing and making certain transactions (such as house sales) public, we need
to understand what guarantees the protocol gives us in terms of agents'
knowledge. Here, we provide a complete characterization of agent's knowledge
when running a blockchain protocol using a variant of common knowledge that
takes into account the fact that agents can enter and leave the system, it is
not known which agents are in fact following the protocol (some agents may want
to deviate if they can gain by doing so), and the fact that the guarantees
provided by blockchain protocols are probabilistic. We then consider some
scenarios involving contracts and show that this level of knowledge suffices
for some scenarios, but not others.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08751</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 324-335</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.22</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08752</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Indicative Conditionals and Dynamic Epistemic Logic</dc:title>
 <dc:creator>Holliday, Wesley H.</dc:creator>
 <dc:creator>Icard III, Thomas F.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  Recent ideas about epistemic modals and indicative conditionals in formal
semantics have significant overlap with ideas in modal logic and dynamic
epistemic logic. The purpose of this paper is to show how greater interaction
between formal semantics and dynamic epistemic logic in this area can be of
mutual benefit. In one direction, we show how concepts and tools from modal
logic and dynamic epistemic logic can be used to give a simple, complete
axiomatization of Yalcin's [16] semantic consequence relation for a language
with epistemic modals and indicative conditionals. In the other direction, the
formal semantics for indicative conditionals due to Kolodny and MacFarlane [9]
gives rise to a new dynamic operator that is very natural from the point of
view of dynamic epistemic logic, allowing succinct expression of dependence (as
in dependence logic) or supervenience statements. We prove decidability for the
logic with epistemic modals and Kolodny and MacFarlane's indicative conditional
via a full and faithful computable translation from their logic to the modal
logic K45.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08752</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 337-351</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.24</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08753</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Categories for Dynamic Epistemic Logic</dc:title>
 <dc:creator>Kishida, Kohei</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  The primary goal of this paper is to recast the semantics of modal logic, and
dynamic epistemic logic (DEL) in particular, in category-theoretic terms. We
first review the category of relations and categories of Kripke frames, with
particular emphasis on the duality between relations and adjoint homomorphisms.
Using these categories, we then reformulate the semantics of DEL in a more
categorical and algebraic form. Several virtues of the new formulation will be
demonstrated: The DEL idea of updating a model into another is captured
naturally by the categorical perspective -- which emphasizes a family of
objects and structural relationships among them, as opposed to a single object
and structure on it. Also, the categorical semantics of DEL can be merged
straightforwardly with a standard categorical semantics for first-order logic,
providing a semantics for first-order DEL.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08753</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 353-372</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.26</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08754</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Arbitrary Arrow Update Logic with Common Knowledge is neither RE nor
  co-RE</dc:title>
 <dc:creator>Kuijer, Louwe B.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Arbitrary Arrow Update Logic with Common Knowledge (AAULC) is a dynamic
epistemic logic with (i) an arrow update operator, which represents a
particular type of information change and (ii) an arbitrary arrow update
operator, which quantifies over arrow updates.
  By encoding the execution of a Turing machine in AAULC, we show that neither
the valid formulas nor the satisfiable formulas of AAULC are recursively
enumerable. In particular, it follows that AAULC does not have a recursive
axiomatization.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08754</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 373-381</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.27</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08755</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Group Recommendations: Axioms, Impossibilities, and Random Walks</dc:title>
 <dc:creator>Lev, Omer</dc:creator>
 <dc:creator>Tennenholtz, Moshe</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  We introduce an axiomatic approach to group recommendations, in line of
previous work on the axiomatic treatment of trust-based recommendation systems,
ranking systems, and other foundational work on the axiomatic approach to
internet mechanisms in social choice settings. In group recommendations we wish
to recommend to a group of agents, consisting of both opinionated and undecided
members, a joint choice that would be acceptable to them. Such a system has
many applications, such as choosing a movie or a restaurant to go to with a
group of friends, recommending games for online game players, &amp; other communal
activities.
  Our method utilizes a given social graph to extract information on the
undecided, relying on the agents influencing them. We first show that a set of
fairly natural desired requirements (a.k.a axioms) leads to an impossibility,
rendering mutual satisfaction of them unreachable. However, we also show a
modified set of axioms that fully axiomatize a group variant of the random-walk
recommendation system, expanding a previous result from the individual
recommendation case.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08755</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 382-397</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.28</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08756</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Epistemic Model Checking Using Conditional Independence
  (Extended Abstract)</dc:title>
 <dc:creator>van der Meyden, Ron</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This paper shows that conditional independence reasoning can be applied to
optimize epistemic model checking, in which one verifies that a model for a
number of agents operating with imperfect information satisfies a formula
expressed in a modal multi-agent logic of knowledge. The optimization has been
implemented in the epistemic model checker MCK. The paper reports experimental
results demonstrating that it can yield multiple orders of magnitude
performance improvements.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08756</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 398-414</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.29</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08757</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Decision Theory and Stochastic Independence</dc:title>
 <dc:creator>Mongin, Philippe</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>J2</dc:subject>
 <dc:description>  Stochastic independence has a complex status in probability theory. It is not
part of the definition of a probability measure, but it is nonetheless an
essential property for the mathematical development of this theory. Bayesian
decision theorists such as Savage can be criticized for being silent about
stochastic independence. From their current preference axioms, they can derive
no more than the definitional properties of a probability measure. In a new
framework of twofold uncertainty, we introduce preference axioms that entail
not only these definitional properties, but also the stochastic independence of
the two sources of uncertainty. This goes some way towards filling a curious
lacuna in Bayesian decision theory.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08757</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 415-425</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.30</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08758</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Endogenizing Epistemic Actions</dc:title>
 <dc:creator>Nalls, Will</dc:creator>
 <dc:creator>Bjorndahl, Adam</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Through a series of examples, we illustrate some important drawbacks that the
action logic framework suffers from in its ability to represent the dynamics of
information updates. We argue that these problems stem from the fact that the
action model, a central construct designed to encode agents' uncertainty about
actions, is itself effectively common knowledge amongst the agents. In response
to these difficulties, we motivate and propose an alternative semantics that
avoids them by (roughly speaking) endogenizing the action model. We discuss the
relationship to action logic, and provide a sound and complete axiomatization.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08758</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 426-440</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.31</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08759</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Together We Know How to Achieve: An Epistemic Logic of Know-How
  (Extended Abstract)</dc:title>
 <dc:creator>Naumov, Pavel</dc:creator>
 <dc:creator>Tao, Jia</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The existence of a coalition strategy to achieve a goal does not necessarily
mean that the coalition has enough information to know how to follow the
strategy. Neither does it mean that the coalition knows that such a strategy
exists. The paper studies an interplay between the distributed knowledge,
coalition strategies, and coalition &quot;know-how&quot; strategies. The main technical
result is a sound and complete trimodal logical system that describes the
properties of this interplay.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08759</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 441-453</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.32</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08760</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Condorcet's Principle and the Preference Reversal Paradox</dc:title>
 <dc:creator>Peters, Dominik</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We prove that every Condorcet-consistent voting rule can be manipulated by a
voter who completely reverses their preference ranking, assuming that there are
at least 4 alternatives. This corrects an error and improves a result of
[Sanver, M. R. and Zwicker, W. S. (2009). One-way monotonicity as a form of
strategy-proofness. Int J Game Theory 38(4), 553-574.] For the case of
precisely 4 alternatives, we exactly characterise the number of voters for
which this impossibility result can be proven. We also show analogues of our
result for irresolute voting rules. We then leverage our result to state a
strong form of the Gibbard-Satterthwaite Theorem.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250. 15 pages</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08760</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 455-469</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.34</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08761</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-confirming Games: Unawareness, Discovery, and Equilibrium</dc:title>
 <dc:creator>Schipper, Burkhard C.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Equilibrium notions for games with unawareness in the literature cannot be
interpreted as steady-states of a learning process because players may discover
novel actions during play. In this sense, many games with unawareness are
&quot;self-destroying&quot; as a player's representation of the game must change after
playing it once. We define discovery processes where at each state there is an
extensive-form game with unawareness that together with the players' play
determines the transition to possibly another extensive-form games with
unawareness in which players are now aware of actions that they have previously
discovered. A discovery process is rationalizable if players play
extensive-form rationalizable strategies in each game with unawareness. We show
that for any game with unawareness there is a rationalizable discovery process
that leads to a self-confirming game that possesses an extensive-form
rationalizable self-confirming equilibrium. This notion of equilibrium can be
interpreted as steady-state of a learning and discovery process.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08761</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 470-488</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.35</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08762</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Argument-based Belief in Topological Structures</dc:title>
 <dc:creator>Shi, Chenwei</dc:creator>
 <dc:creator>Smets, Sonja</dc:creator>
 <dc:creator>Vel&#xe1;zquez-Quesada, Fernando R.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This paper combines two studies: a topological semantics for epistemic
notions and abstract argumentation theory. In our combined setting, we use a
topological semantics to represent the structure of an agent's collection of
evidence, and we use argumentation theory to single out the relevant sets of
evidence through which a notion of beliefs grounded on arguments is defined. We
discuss the formal properties of this newly defined notion, providing also a
formal language with a matching modality together with a sound and complete
axiom system for it. Despite the fact that our agent can combine her evidence
in a 'rational' way (captured via the topological structure), argument-based
beliefs are not closed under conjunction. This illustrates the difference
between an agent's reasoning abilities (i.e. the way she is able to combine her
available evidence) and the closure properties of her beliefs. We use this
point to argue for why the failure of closure under conjunction of belief
should not bear the burden of the failure of rationality.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08762</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 489-503</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.36</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08763</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reconciling Bayesian Epistemology and Narration-based Approaches to
  Judiciary Fact-finding</dc:title>
 <dc:creator>Urbaniak, Rafal</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Legal probabilism (LP) claims the degrees of conviction in juridical
fact-finding are to be modeled exactly the way degrees of beliefs are modeled
in standard bayesian epistemology. Classical legal probabilism (CLP) adds that
the conviction is justified if the credence in guilt given the evidence is
above an appropriate guilt probability threshold. The views are challenged on
various counts, especially by the proponents of the so-called narrative
approach, on which the fact-finders' decision is the result of a dynamic
interplay between competing narratives of what happened. I develop a way a
bayesian epistemologist can make sense of the narrative approach. I do so by
formulating a probabilistic framework for evaluating competing narrations in
terms of formal explications of the informal evaluation criteria used in the
narrative approach.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08763</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 504-514</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.37</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08764</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Modal Framework for Epistemic Logic</dc:title>
 <dc:creator>Wang, Yanjing</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Recent years witnessed a growing interest in non-standard epistemic logics of
knowing whether, knowing how, knowing what, knowing why and so on. The new
epistemic modalities introduced in those logics all share, in their semantics,
the general schema of $\exists x \Box \phi$, e.g., knowing how to achieve
$\phi$ roughly means that there exists a way such that you know that it is a
way to ensure that $\phi$. Moreover, the resulting logics are decidable.
Inspired by those particular logics, in this work, we propose a very general
and powerful framework based on quantifier-free predicate language extended by
a new modality $\Box^x$, which packs exactly $\exists x \Box$ together. We show
that the resulting language, though much more expressive, shares many good
properties of the basic propositional modal logic over arbitrary models, such
as finite-tree-model property and van Benthem-like characterization w.r.t.\
first-order modal logic. We axiomatize the logic over S5 frames with intuitive
axioms to capture the interaction between $\Box^x$ and know-that operator in an
epistemic setting.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08764</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 515-534</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.38</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08767</identifier>
 <datestamp>2017-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Improved Epsilon Constraint-handling Method in MOEA/D for CMOPs with
  Large Infeasible Regions</dc:title>
 <dc:creator>Fan, Zhun</dc:creator>
 <dc:creator>Li, Wenji</dc:creator>
 <dc:creator>Cai, Xinye</dc:creator>
 <dc:creator>Huang, Han</dc:creator>
 <dc:creator>Fang, Yi</dc:creator>
 <dc:creator>You, Yugen</dc:creator>
 <dc:creator>Mo, Jiajie</dc:creator>
 <dc:creator>Wei, Caimin</dc:creator>
 <dc:creator>Goodman, Erik</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  This paper proposes an improved epsilon constraint-handling mechanism, and
combines it with a decomposition-based multi-objective evolutionary algorithm
(MOEA/D) to solve constrained multi-objective optimization problems (CMOPs).
The proposed constrained multi-objective evolutionary algorithm (CMOEA) is
named MOEA/D-IEpsilon. It adjusts the epsilon level dynamically according to
the ratio of feasible to total solutions (RFS) in the current population. In
order to evaluate the performance of MOEA/D-IEpsilon, a new set of CMOPs with
two and three objectives is designed, having large infeasible regions (relative
to the feasible regions), and they are called LIR-CMOPs. Then the fourteen
benchmarks, including LIR-CMOP1-14, are used to test MOEA/D-IEpsilon and four
other decomposition-based CMOEAs, including MOEA/D-Epsilon, MOEA/D-SR,
MOEA/D-CDP and C-MOEA/D. The experimental results indicate that MOEA/D-IEpsilon
is significantly better than the other four CMOEAs on all of the test
instances, which shows that MOEA/D-IEpsilon is more suitable for solving CMOPs
with large infeasible regions. Furthermore, a real-world problem, namely the
robot gripper optimization problem, is used to test the five CMOEAs. The
experimental results demonstrate that MOEA/D-IEpsilon also outperforms the
other four CMOEAs on this problem.
</dc:description>
 <dc:description>Comment: 17 pages, 7 figures and 6 tables</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08767</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08769</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ramsey Spanning Trees and their Applications</dc:title>
 <dc:creator>Abraham, Ittai</dc:creator>
 <dc:creator>Chechik, Shiri</dc:creator>
 <dc:creator>Elkin, Michael</dc:creator>
 <dc:creator>Filtser, Arnold</dc:creator>
 <dc:creator>Neiman, Ofer</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The metric Ramsey problem asks for the largest subset $S$ of a metric space
that can be embedded into an ultrametric (more generally into a Hilbert space)
with a given distortion. Study of this problem was motivated as a non-linear
version of Dvoretzky theorem. Mendel and Naor 2007 devised the so called Ramsey
Partitions to address this problem, and showed the algorithmic applications of
their techniques to approximate distance oracles and ranking problems.
  In this paper we study the natural extension of the metric Ramsey problem to
graphs, and introduce the notion of Ramsey Spanning Trees. We ask for the
largest subset $S\subseteq V$ of a given graph $G=(V,E)$, such that there
exists a spanning tree of $G$ that has small stretch for $S$. Applied
iteratively, this provides a small collection of spanning trees, such that each
vertex has a tree providing low stretch paths to all other vertices. The union
of these trees serves as a special type of spanner, a tree-padding spanner. We
use this spanner to devise the first compact stateless routing scheme with
$O(1)$ routing decision time, and labels which are much shorter than in all
currently existing schemes.
  We first revisit the metric Ramsey problem, and provide a new deterministic
construction. We prove that for every $k$, any $n$-point metric space has a
subset $S$ of size at least $n^{1-1/k}$ which embeds into an ultrametric with
distortion $8k$. This results improves the best previous result of Mendel and
Naor that obtained distortion $128k$ and required randomization. In addition,
it provides the state-of-the-art deterministic construction of a distance
oracle. Building on this result, we prove that for every $k$, any $n$-vertex
graph $G=(V,E)$ has a subset $S$ of size at least $n^{1-1/k}$, and a spanning
tree of $G$, that has stretch $O(k \log \log n)$ between any point in $S$ and
any point in $V$.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08769</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08771</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Runtime Model Based Approach to Smart Home System Development</dc:title>
 <dc:creator>Wu, Kaidong</dc:creator>
 <dc:creator>He, Xiao</dc:creator>
 <dc:creator>Chen, Xing</dc:creator>
 <dc:creator>Huang, Gang</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  When developing smart home systems, developers integrate and compose smart
devices and software applications. Because of their diversity and
heterogeneity, developers usually encounter many problems. In this paper, we
present a runtime model based approach to smart home system development. First,
we analyze mobile applications associated with smart devices and then extract
some device control APIs. Second, we use SM@RT framework to build the device
runtime model. Third, we define the scenario model, that is an abstraction of
devices and objects which the system consists of. Fourth, we specify mapping
rules from the scenario model to the runtime model and employ a synchronizer,
which can interpret the mapping rules, to keep the synchronization between the
scenario model and the device runtime model. The mapping handler reads the
mapping rules that are defined by developers and does the mapping in terms of
them. At last, developers can program smart home systems upon the MOF-compliant
scenario model using the state-of-the-art model driven technologies.
https://youtu.be/SP12OtmHj50
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08771</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08772</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spike sorting using non-volatile metal-oxide memristors</dc:title>
 <dc:creator>Gupta, Isha</dc:creator>
 <dc:creator>Serb, Alexantrou</dc:creator>
 <dc:creator>Khiat, Ali</dc:creator>
 <dc:creator>Trapatseli, Maria</dc:creator>
 <dc:creator>Prodromakis, Themistoklis</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Electrophysiological techniques have improved substantially over the past
years to the point that neuroprosthetics applications are becoming viable. This
evolution has been fuelled by the advancement of implantable microelectrode
technologies that have followed their own version of Moore's scaling law.
Similarly to electronics, however, excessive data-rates and strained power
budgets require the development of more efficient computation paradigms for
handling neural data in-situ, in particular the computationally heavy task of
events classification. Here, we demonstrate how the intrinsic analogue
programmability of memristive devices can be exploited to perform
spike-sorting. We then show how combining memristors with standard logic
enables efficient in-silico template matching. Leveraging the physical
properties of nanoscale memristors allows us to implement ultra-compact
analogue circuits for neural signal processing at the power cost of digital.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08772</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08776</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Evolutionary Stochastic-Local-Search Framework for One-Dimensional
  Cutting-Stock Problems</dc:title>
 <dc:creator>Chasparis, Georgios C.</dc:creator>
 <dc:creator>Rossbory, Michael</dc:creator>
 <dc:creator>Haunschmid, Verena</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We introduce an evolutionary stochastic-local-search (SLS) algorithm for
addressing a generalized version of the so-called 1/V/D/R cutting-stock
problem. Cutting-stock problems are encountered often in industrial
environments and the ability to address them efficiently usually results in
large economic benefits. Traditionally linear-programming-based techniques have
been utilized to address such problems, however their flexibility might be
limited when nonlinear constraints and objective functions are introduced. To
this end, this paper proposes an evolutionary SLS algorithm for addressing
one-dimensional cutting-stock problems. The contribution lies in the
introduction of a flexible structural framework of the optimization that may
accommodate a large family of diversification strategies including a novel
parallel pattern appropriate for SLS algorithms (not necessarily restricted to
cutting-stock problems). We finally demonstrate through experiments in a
real-world manufacturing problem the benefit in cost reduction of the
considered diversification strategies.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08776</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08781</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consensus-based joint target tracking and sensor localization</dc:title>
 <dc:creator>Gao, Lin</dc:creator>
 <dc:creator>Battistelli, Giorgio</dc:creator>
 <dc:creator>Chisci, Luigi</dc:creator>
 <dc:creator>Wei, Ping</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, consensus-based Kalman filtering is extended to deal with the
problem of joint target tracking and sensor self-localization in a distributed
wireless sensor network. The average weighted Kullback-Leibler divergence,
which is a function of the unknown drift parameters, is employed as the cost to
measure the discrepancy between the fused posterior distribution and the local
distribution at each sensor. Further, a reasonable approximation of the cost is
proposed and an online technique is introduced to minimize the approximated
cost function with respect to the drift parameters stored in each node. The
remarkable features of the proposed algorithm are that it needs no additional
data exchanges, slightly increased memory space and computational load
comparable to the standard consensus-based Kalman filter. Finally, the
effectiveness of the proposed algorithm is demonstrated through simulation
experiments on both a tree network and a network with cycles as well as for
both linear and nonlinear sensors.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08781</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08783</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Italian Word Embeddings</dc:title>
 <dc:creator>Tripodi, Rocco</dc:creator>
 <dc:creator>Pira, Stefano Li</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this work we analyze the performances of two of the most used word
embeddings algorithms, skip-gram and continuous bag of words on Italian
language. These algorithms have many hyper-parameter that have to be carefully
tuned in order to obtain accurate word representation in vectorial space. We
provide an accurate analysis and an evaluation, showing what are the best
configuration of parameters for specific tasks.
</dc:description>
 <dc:description>Comment: 5 pages, 8 figures</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08789</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On {\sigma}-LCD codes</dc:title>
 <dc:creator>Carlet, Claude</dc:creator>
 <dc:creator>Mesnager, Sihem</dc:creator>
 <dc:creator>Tang, Chunming</dc:creator>
 <dc:creator>Qi, Yanfeng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Linear complementary pairs (LCP) of codes play an important role in armoring
implementations against side-channel attacks and fault injection attacks. One
of the most common ways to construct LCP of codes is to use Euclidean linear
complementary dual (LCD) codes. In this paper, we first introduce the concept
of linear codes with $\sigma$ complementary dual ($\sigma$-LCD), which includes
known Euclidean LCD codes, Hermitian LCD codes, and Galois LCD codes.
  As Euclidean LCD codes, $\sigma$-LCD codes can also be used to construct LCP
of codes. We show that, for $q &gt; 2$, all q-ary linear codes are $\sigma$-LCD
and that, for every binary linear code $\mathcal C$, the code $\{0\}\times
\mathcal C$ is $\sigma$-LCD. Further, we study deeply $\sigma$-LCD generalized
quasi-cyclic (GQC) codes. In particular, we provide characterizations of
$\sigma$-LCD GQC codes, self-orthogonal GQC codes and self-dual GQC codes,
respectively. Moreover, we provide constructions of asymptotically good
$\sigma$-LCD GQC codes. Finally, we focus on $\sigma$-LCD Abelian codes and
prove that all Abelian codes in a semi-simple group algebra are $\sigma$-LCD.
  The results derived in this paper extend those on the classical LCD codes and
show that $\sigma$-LCD codes allow the construction of LCP of codes more easily
and with more flexibility.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08789</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08794</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on minimal dispersion of point sets in the unit cube</dc:title>
 <dc:creator>Sosnovec, Jakub</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We study the dispersion of a point set, a notion closely related to the
discrepancy. Given a real $r\in (0,1)$ and an integer $d\geq 2$, let $N(r,d)$
denote the minimum number of points inside the $d$-dimensional unit cube
$[0,1]^d$ such that they intersect every axis-aligned box inside $[0,1]^d$ of
volume greater than $r$. We prove an upper bound on $N(r,d)$, matching a lower
bound of Aistleitner et al. up to a multiplicative constant depending only on
$r$. This fully determines the rate of growth of $N(r,d)$ if $r\in(0,1)$ is
fixed.
</dc:description>
 <dc:description>Comment: 6 pages; accepted for publication in European Journal of
  Combinatorics</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08802</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of Correlation between Interferers on Coverage Probability and
  rate in Cellular Systems</dc:title>
 <dc:creator>Kumar, Suman</dc:creator>
 <dc:creator>Kalyani, Sheetal</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  When the user channel experiences Nakagami-m fading, the coverage probability
expressions are theoretically compared for the following cases: (i). The N
interferers are independent $\eta$-$\mu$ random variables (RVs). (ii). The N
interferers are correlated $\eta$-$\mu$ RVs. It is analytically shown that the
coverage probability in the presence of correlated interferers is greater than
or equal to the coverage probability in the presence of independent interferers
when the shape parameter of the channel between the user and its base station
(BS) is not greater than one. Further, rate is compared for the following
cases: (i). The user channel experiences $\eta$-$\mu$ RV and the $N$
interferers are independent $\eta$-$\mu$ RVs. (ii). The N interferers are
correlated $\eta$-$\mu$ RVs. It is analytically shown that the rate in the
presence of correlated interferers is greater than or equal to the rate in the
presence of independent interferers. Simulation results are provided and these
match with the obtained theoretical results. The utility of our results are
also discussed.
</dc:description>
 <dc:description>Comment: This is a significantly expanded version of our paper arXiv:1401.4663</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08802</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08807</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nearest Common Ancestors: Universal Trees and Improved Labeling Schemes</dc:title>
 <dc:creator>Kuhn, Fabian</dc:creator>
 <dc:creator>Panagiotou, Konstantinos</dc:creator>
 <dc:creator>Su, Pascal</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We investigate the nearest common ancestor (NCA) function in rooted trees. As
the main conceptual contribution, the paper introduces universal trees for the
NCA function: For a given family of rooted trees, an NCA-universal tree $S$ is
a rooted tree such that any tree $T$ of the family can be embedded into $S$
such that the embedding of the NCA in $T$ of two nodes of $T$ is equal to the
NCA in $S$ of the embeddings of the two nodes.
  As the main technical result we give explicit constructions of NCA-universal
trees of size $n^{2.318}$ for the family of rooted $n$-vertex trees and of size
$n^{1.894}$ for the family of rooted binary $n$-vertex trees. A direct
consequence is the explicit construction of NCA-labeling schemes with labels of
size $2.318\log_2 n$ and $1.894\log_2 n$ for the two families of rooted trees.
This improves on the best known such labeling schemes established by Alstrup,
Halvorsen and Larsen [SODA 2014].
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08810</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection of Trending Topic Communities: Bridging Content Creators and
  Distributors</dc:title>
 <dc:creator>Recalde, Lorena</dc:creator>
 <dc:creator>Nettleton, David F.</dc:creator>
 <dc:creator>Baeza-Yates, Ricardo</dc:creator>
 <dc:creator>Boratto, Ludovico</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The rise of a trending topic on Twitter or Facebook leads to the temporal
emergence of a set of users currently interested in that topic. Given the
temporary nature of the links between these users, being able to dynamically
identify communities of users related to this trending topic would allow for a
rapid spread of information. Indeed, individual users inside a community might
receive recommendations of content generated by the other users, or the
community as a whole could receive group recommendations, with new content
related to that trending topic. In this paper, we tackle this challenge, by
identifying coherent topic-dependent user groups, linking those who generate
the content (creators) and those who spread this content, e.g., by
retweeting/reposting it (distributors). This is a novel problem on
group-to-group interactions in the context of recommender systems. Analysis on
real-world Twitter data compare our proposal with a baseline approach that
considers the retweeting activity, and validate it with standard metrics.
Results show the effectiveness of our approach to identify communities
interested in a topic where each includes content creators and content
distributors, facilitating users' interactions and the spread of new
information.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures, 2 tables, Hypertext 2017 conference</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08810</dc:identifier>
 <dc:identifier>doi:10.1145/3078714.3078735</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08813</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparative Study of the Clinical use of Motion Analysis from Kinect
  Skeleton Data</dc:title>
 <dc:creator>Maudsley-Barton, Sean</dc:creator>
 <dc:creator>McPheey, Jamie</dc:creator>
 <dc:creator>Bukowski, Anthony</dc:creator>
 <dc:creator>Leightley, Daniel</dc:creator>
 <dc:creator>Yap, Moi Hoon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The analysis of human motion as a clinical tool can bring many benefits such
as the early detection of disease and the monitoring of recovery, so in turn
helping people to lead independent lives. However, it is currently under used.
Developments in depth cameras, such as Kinect, have opened up the use of motion
analysis in settings such as GP surgeries, care homes and private homes. To
provide an insight into the use of Kinect in the healthcare domain, we present
a review of the current state of the art. We then propose a method that can
represent human motions from time-series data of arbitrary length, as a single
vector. Finally, we demonstrate the utility of this method by extracting a set
of clinically significant features and using them to detect the age related
changes in the motions of a set of 54 individuals, with a high degree of
certainty (F1- score between 0.9 - 1.0). Indicating its potential application
in the detection of a range of age-related motion impairments.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08814</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representation-Aggregation Networks for Segmentation of Multi-Gigapixel
  Histology Images</dc:title>
 <dc:creator>Agarwalla, Abhinav</dc:creator>
 <dc:creator>Shaban, Muhammad</dc:creator>
 <dc:creator>Rajpoot, Nasir M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional Neural Network (CNN) models have become the state-of-the-art
for most computer vision tasks with natural images. However, these are not best
suited for multi-gigapixel resolution Whole Slide Images (WSIs) of histology
slides due to large size of these images. Current approaches construct smaller
patches from WSIs which results in the loss of contextual information. We
propose to capture the spatial context using novel Representation-Aggregation
Network (RAN) for segmentation purposes, wherein the first network learns
patch-level representation and the second network aggregates context from a
grid of neighbouring patches. We can use any CNN for representation learning,
and can utilize CNN or 2D-Long Short Term Memory (2D-LSTM) for
context-aggregation. Our method significantly outperformed conventional
patch-based CNN approaches on segmentation of tumour in WSIs of breast cancer
tissue sections.
</dc:description>
 <dc:description>Comment: Published in Workshop on Deep Learning in Irregular Domains (DLID) in
  BMVC2017</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08816</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Food Ingredients Recognition through Multi-label Learning</dc:title>
 <dc:creator>Bola&#xf1;os, Marc</dc:creator>
 <dc:creator>Ferr&#xe0;, Aina</dc:creator>
 <dc:creator>Radeva, Petia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatically constructing a food diary that tracks the ingredients consumed
can help people follow a healthy diet. We tackle the problem of food
ingredients recognition as a multi-label learning problem. We propose a method
for adapting a highly performing state of the art CNN in order to act as a
multi-label predictor for learning recipes in terms of their list of
ingredients. We prove that our model is able to, given a picture, predict its
list of ingredients, even if the recipe corresponding to the picture has never
been seen by the model. We make public two new datasets suitable for this
purpose. Furthermore, we prove that a model trained with a high variability of
recipes and ingredients is able to generalize better on new data, and visualize
how it specializes each of its neurons to different ingredients.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08817</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Demonstrations for Deep Reinforcement Learning on Robotics
  Problems with Sparse Rewards</dc:title>
 <dc:creator>Ve&#x10d;er&#xed;k, Matej</dc:creator>
 <dc:creator>Hester, Todd</dc:creator>
 <dc:creator>Scholz, Jonathan</dc:creator>
 <dc:creator>Wang, Fumin</dc:creator>
 <dc:creator>Pietquin, Olivier</dc:creator>
 <dc:creator>Piot, Bilal</dc:creator>
 <dc:creator>Heess, Nicolas</dc:creator>
 <dc:creator>Roth&#xf6;rl, Thomas</dc:creator>
 <dc:creator>Lampe, Thomas</dc:creator>
 <dc:creator>Riedmiller, Martin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We propose a general and model-free approach for Reinforcement Learning (RL)
on real robotics with sparse rewards. We build upon the Deep Deterministic
Policy Gradient (DDPG) algorithm to use demonstrations. Both demonstrations and
actual interactions are used to fill a replay buffer and the sampling ratio
between demonstrations and transitions is automatically tuned via a prioritized
replay mechanism. Typically, carefully engineered shaping rewards are required
to enable the agents to efficiently explore on high dimensional control
problems such as robotics. They are also required for model-based acceleration
methods relying on local solvers such as iLQG (e.g. Guided Policy Search and
Normalized Advantage Function). The demonstrations replace the need for
carefully engineered rewards, and reduce the exploration problem encountered by
classical RL approaches in these domains. Demonstrations are collected by a
robot kinesthetically force-controlled by a human demonstrator. Results on four
simulated insertion tasks show that DDPG from demonstrations out-performs DDPG,
and does not require engineered rewards. Finally, we demonstrate the method on
a real robotics task consisting of inserting a clip (flexible object) into a
rigid object.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08819</identifier>
 <datestamp>2017-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Downsampled Variant of ImageNet as an Alternative to the CIFAR
  datasets</dc:title>
 <dc:creator>Chrabaszcz, Patryk</dc:creator>
 <dc:creator>Loshchilov, Ilya</dc:creator>
 <dc:creator>Hutter, Frank</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The original ImageNet dataset is a popular large-scale benchmark for training
Deep Neural Networks. Since the cost of performing experiments (e.g, algorithm
design, architecture search, and hyperparameter tuning) on the original dataset
might be prohibitive, we propose to consider a downsampled version of ImageNet.
In contrast to the CIFAR datasets and earlier downsampled versions of ImageNet,
our proposed ImageNet32$\times$32 (and its variants ImageNet64$\times$64 and
ImageNet16$\times$16) contains exactly the same number of classes and images as
ImageNet, with the only difference that the images are downsampled to
32$\times$32 pixels per image (64$\times$64 and 16$\times$16 pixels for the
variants, respectively). Experiments on these downsampled variants are
dramatically faster than on the original ImageNet and the characteristics of
the downsampled datasets with respect to optimal hyperparameters appear to
remain similar. The proposed datasets and scripts to reproduce our results are
available at http://image-net.org/download-images and
https://github.com/PatrykChrabaszcz/Imagenet32_Scripts
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08820</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Max K-armed bandit: On the ExtremeHunter algorithm and beyond</dc:title>
 <dc:creator>Achab, Mastane</dc:creator>
 <dc:creator>Cl&#xe9;men&#xe7;on, Stephan</dc:creator>
 <dc:creator>Garivier, Aur&#xe9;lien</dc:creator>
 <dc:creator>Sabourin, Anne</dc:creator>
 <dc:creator>Vernade, Claire</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper is devoted to the study of the max K-armed bandit problem, which
consists in sequentially allocating resources in order to detect extreme
values. Our contribution is twofold. We first significantly refine the analysis
of the ExtremeHunter algorithm carried out in Carpentier and Valko (2014), and
next propose an alternative approach, showing that, remarkably, Extreme Bandits
can be reduced to a classical version of the bandit problem to a certain
extent. Beyond the formal analysis, these two approaches are compared through
numerical experiments.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08820</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08821</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Serious Games Application for Memory Training Using Egocentric Images</dc:title>
 <dc:creator>Oliveira-Barra, Gabriel</dc:creator>
 <dc:creator>Bola&#xf1;os, Marc</dc:creator>
 <dc:creator>Talavera, Estefania</dc:creator>
 <dc:creator>Due&#xf1;as, Adri&#xe1;n</dc:creator>
 <dc:creator>Gelonch, Olga</dc:creator>
 <dc:creator>Garolera, Maite</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Mild cognitive impairment is the early stage of several neurodegenerative
diseases, such as Alzheimer's. In this work, we address the use of lifelogging
as a tool to obtain pictures from a patient's daily life from an egocentric
point of view. We propose to use them in combination with serious games as a
way to provide a non-pharmacological treatment to improve their quality of
life. To do so, we introduce a novel computer vision technique that classifies
rich and non rich egocentric images and uses them in serious games. We present
results over a dataset composed by 10,997 images, recorded by 7 different
users, achieving 79% of F1-score. Our model presents the first method used for
automatic egocentric images selection applicable to serious games.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08821</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08824</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Find, Understand, and Extend Development Screencasts on YouTube</dc:title>
 <dc:creator>Ellmann, Mathias</dc:creator>
 <dc:creator>Oeser, Alexander</dc:creator>
 <dc:creator>Fucci, Davide</dc:creator>
 <dc:creator>Maalej, Walid</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  A software development screencast is a video that captures the screen of a
developer working on a particular task while explaining its implementation
details. Due to the increased popularity of software development screencasts
(e.g., available on YouTube), we study how and to what extent they can be used
as additional source of knowledge to answer developer's questions about, for
example, the use of a specific API. We first differentiate between development
and other types of screencasts using video frame analysis. By using the Cosine
algorithm, developers can expect ten development screencasts in the top 20 out
of 100 different YouTube videos. We then extracted popular development topics
on which screencasts are reporting on YouTube: database operations, system
set-up, plug-in development, game development, and testing. Besides, we found
six recurring tasks performed in development screencasts, such as object usage
and UI operations. Finally, we conducted a similarity analysis by considering
only the spoken words (i.e., the screencast transcripts but not the text that
might appear in a scene) to link API documents, such as the Javadoc, to the
appropriate screencasts. By using Cosine similarity, we identified 38 relevant
documents in the top 20 out of 9455 API documents.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08824</dc:identifier>
 <dc:identifier>doi:10.1145/3121257.3121260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08826</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evidence of Fraud in Brazil's Electoral Campaigns Via the Benford's Law</dc:title>
 <dc:creator>Gamermann, Daniel</dc:creator>
 <dc:creator>Antunes, Felipe Leite</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The principle of democracy is that the people govern through elected
representatives. Therefore, a democracy is healthy as long as the elected
politicians do represent the people. We have analyzed data from the Brazilian
electoral court (Tribunal Superior Eleitoral, TSE) concerning money donations
for the electoral campaigns and the election results. Our work points to two
disturbing conclusions: money is a determining factor on whether a candidate is
elected or not (as opposed to representativeness); secondly, the use of
Benford's Law to analyze the declared donations received by the parties and
electoral campaigns shows evidence of fraud in the declarations. A better term
to define Brazil's government system is what we define as chrimatocracy (govern
by money).
</dc:description>
 <dc:description>Comment: 21 pages, 3 figures, 9 tables</dc:description>
 <dc:date>2017-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08826</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08831</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>STN-OCR: A single Neural Network for Text Detection and Text Recognition</dc:title>
 <dc:creator>Bartz, Christian</dc:creator>
 <dc:creator>Yang, Haojin</dc:creator>
 <dc:creator>Meinel, Christoph</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Detecting and recognizing text in natural scene images is a challenging, yet
not completely solved task. In re- cent years several new systems that try to
solve at least one of the two sub-tasks (text detection and text recognition)
have been proposed. In this paper we present STN-OCR, a step towards
semi-supervised neural networks for scene text recognition, that can be
optimized end-to-end. In contrast to most existing works that consist of
multiple deep neural networks and several pre-processing steps we propose to
use a single deep neural network that learns to detect and recognize text from
natural images in a semi-supervised way. STN-OCR is a network that integrates
and jointly learns a spatial transformer network, that can learn to detect text
regions in an image, and a text recognition network that takes the identified
text regions and recognizes their textual content. We investigate how our model
behaves on a range of different tasks (detection and recognition of characters,
and lines of text). Experimental results on public benchmark datasets show the
ability of our model to handle a variety of different tasks, without
substantial changes in its overall network structure.
</dc:description>
 <dc:description>Comment: 9 pages, 6 figures</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08831</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08833</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Planar graphs as L-intersection or L-contact graphs</dc:title>
 <dc:creator>Gon&#xe7;alves, Daniel</dc:creator>
 <dc:creator>Isenmann, Lucas</dc:creator>
 <dc:creator>Pennarun, Claire</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  The L-intersection graphs are the graphs that have a representation as
intersection graphs of axis parallel shapes in the plane. A subfamily of these
graphs are {L, |, --}-contact graphs which are the contact graphs of axis
parallel L, |, and -- shapes in the plane. We prove here two results that were
conjectured by Chaplick and Ueckerdt in 2013. We show that planar graphs are
L-intersection graphs, and that triangle-free planar graphs are {L, |,
--}-contact graphs. These results are obtained by a new and simple
decomposition technique for 4-connected triangulations. Our results also
provide a much simpler proof of the known fact that planar graphs are segment
intersection graphs.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08833</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08834</identifier>
 <datestamp>2017-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Arithmetic Circuits for Multilevel Qudits Based on Quantum Fourier
  Transform</dc:title>
 <dc:creator>Pavlidis, Archimedes</dc:creator>
 <dc:creator>Floratos, Emmanuel</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  We present some basic integer arithmetic quantum circuits, such as adders and
multipliers-accumulators of various forms, as well as diagonal operators, which
operate on multilevel qudits. The integers to be processed are represented in
an alternative basis after they have been Fourier transformed. Several
arithmetic circuits operating on Fourier transformed integers have appeared in
the literature for two level qubits. Here we extend these techniques on
multilevel qudits, as they may offer some advantages relative to qubits
implementations. The arithmetic circuits presented can be used as basic
building blocks for higher level algorithms such as quantum phase estimation,
quantum simulation, quantum optimization etc., but they can also be used in the
implementation of a quantum fractional Fourier transform as it is shown in a
companion work presented separately.
</dc:description>
 <dc:description>Comment: 34 pages, 18 figures</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08834</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08849</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fuzzy Galois connections on fuzzy sets</dc:title>
 <dc:creator>Garc&#xed;a, Javier Guti&#xe9;rrez</dc:creator>
 <dc:creator>Lai, Hongliang</dc:creator>
 <dc:creator>Shen, Lili</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In fairly elementary terms this paper presents how the theory of preordered
fuzzy sets, more precisely quantale-valued preorders on quantale-valued fuzzy
sets, is established under the guidance of enriched category theory. Motivated
by several key results from the theory of quantaloid-enriched categories, this
paper develops all needed ingredients purely in order-theoretic languages for
the readership of fuzzy set theorists, with particular attention paid to fuzzy
Galois connections between preordered fuzzy sets.
</dc:description>
 <dc:description>Comment: 30 pages</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08849</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08852</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting and Explaining Causes From Text For a Time Series Event</dc:title>
 <dc:creator>Kang, Dongyeop</dc:creator>
 <dc:creator>Gangal, Varun</dc:creator>
 <dc:creator>Lu, Ang</dc:creator>
 <dc:creator>Chen, Zheng</dc:creator>
 <dc:creator>Hovy, Eduard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Explaining underlying causes or effects about events is a challenging but
valuable task. We define a novel problem of generating explanations of a time
series event by (1) searching cause and effect relationships of the time series
with textual data and (2) constructing a connecting chain between them to
generate an explanation. To detect causal features from text, we propose a
novel method based on the Granger causality of time series between features
extracted from text such as N-grams, topics, sentiments, and their composition.
The generation of the sequence of causal entities requires a commonsense
causative knowledge base with efficient reasoning. To ensure good
interpretability and appropriate lexical usage we combine symbolic and neural
representations, using a neural reasoning algorithm trained on commonsense
causal tuples to predict the next cause step. Our quantitative and human
analysis show empirical evidence that our method successfully extracts
meaningful causality relationships between time series with textual features
and generates appropriate explanation between them.
</dc:description>
 <dc:description>Comment: Accepted at EMNLP 2017</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08852</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08856</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LCD codes over ${\mathbb F}_q $ are as good as linear codes for q at
  least four</dc:title>
 <dc:creator>Pellikaan, Ruud</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The hull $H(C)$ of a linear code $C$ is defined by $H(C)=C \cap C^\perp$. A
linear code with a complementary dual (LCD) is a linear code with $H(C)=\{0\}$.
The dimension of the hull of a code is an invariant under permutation
equivalence. For binary and ternary codes the dimension of the hull is also
invariant under monomial equivalence and we show that this invariant is
determined by the extended weight enumerator of the code.\\ The hull of a code
is not invariant under monomial equivalence if $q\geq 4$. We show that every
${\mathbb F}_q $-linear code is monomial equivalent with an LCD code in case $q
\geq 4$. The proof uses techniques from Gr\&quot;obner basis theory. We conclude
that if there exists an ${\mathbb F}_q $-linear code with parameters
$[n,k,d]_q$ and $q \geq 4$, then there exists also a LCD code with the same
parameters. Hence this holds for optimal and MDS codes. In particular there
exist LCD codes that are above the Gilbert-Varshamov bound if $q$ is a square
and $q\geq 49$ by the existence of such codes that are algebraic geometric.\\
Similar results are obtained with respect to Hermitian LCD codes.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08856</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08860</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximations and Bounds for (n, k) Fork-Join Queues: A Linear
  Transformation Approach</dc:title>
 <dc:creator>Wang, Huajin</dc:creator>
 <dc:creator>Li, Jianhui</dc:creator>
 <dc:creator>Shen, Zhihong</dc:creator>
 <dc:creator>Zhou, Yuanchun</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Compared to basic fork-join queues, a job in (n, k) fork-join queues only
needs its k out of all n sub-tasks to be finished. Since (n, k) fork-join
queues are prevalent in popular distributed systems, erasure coding based cloud
storages, and modern network protocols like multipath routing, estimating the
sojourn time of such queues is thus critical for the performance measurement
and resource plan of computer clusters. However, the estimating keeps to be a
well-known open challenge for years, and only rough bounds for a limited range
of load factors have been given. In this paper, we developed a closed-form
linear transformation technique for jointly-identical random variables: An
order statistic can be represented by a linear combination of maxima. This
brand-new technique is then used to transform the sojourn time of non-purging
(n, k) fork-join queues into a linear combination of the sojourn times of basic
(k, k), (k+1, k+1), ..., (n, n) fork-join queues. Consequently, existing
approximations for basic fork-join queues can be bridged to the approximations
for non-purging (n, k) fork-join queues. The uncovered approximations are then
used to improve the upper bounds for purging (n, k) fork-join queues.
Simulation experiments show that this linear transformation approach is
practiced well for moderate n and relatively large k.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08861</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effective Edge-Fault-Tolerant Single-Source Spanners via Best (or Good)
  Swap Edges</dc:title>
 <dc:creator>Bil&#xf2;, Davide</dc:creator>
 <dc:creator>Colella, Feliciano</dc:creator>
 <dc:creator>Gual&#xe0;, Luciano</dc:creator>
 <dc:creator>Leucci, Stefano</dc:creator>
 <dc:creator>Proietti, Guido</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Computing \emph{all best swap edges} (ABSE) of a spanning tree $T$ of a given
$n$-vertex and $m$-edge undirected and weighted graph $G$ means to select, for
each edge $e$ of $T$, a corresponding non-tree edge $f$, in such a way that the
tree obtained by replacing $e$ with $f$ enjoys some optimality criterion (which
is naturally defined according to some objective function originally addressed
by $T$). Solving efficiently an ABSE problem is by now a classic algorithmic
issue, since it conveys a very successful way of coping with a (transient)
\emph{edge failure} in tree-based communication networks: just replace the
failing edge with its respective swap edge, so as that the connectivity is
promptly reestablished by minimizing the rerouting and set-up costs. In this
paper, we solve the ABSE problem for the case in which $T$ is a
\emph{single-source shortest-path tree} of $G$, and our two selected swap
criteria aim to minimize either the \emph{maximum} or the \emph{average
stretch} in the swap tree of all the paths emanating from the source. Having
these criteria in mind, the obtained structures can then be reviewed as
\emph{edge-fault-tolerant single-source spanners}. For them, we propose two
efficient algorithms running in $O(m n +n^2 \log n)$ and $O(m n \log
\alpha(m,n))$ time, respectively, and we show that the guaranteed (either
maximum or average, respectively) stretch factor is equal to 3, and this is
tight. Moreover, for the maximum stretch, we also propose an almost linear $O(m
\log \alpha(m,n))$ time algorithm computing a set of \emph{good} swap edges,
each of which will guarantee a relative approximation factor on the maximum
stretch of $3/2$ (tight) as opposed to that provided by the corresponding BSE.
Surprisingly, no previous results were known for these two very natural swap
problems.
</dc:description>
 <dc:description>Comment: 15 pages, 4 figures, SIROCCO 2017</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08866</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Residual Learning for Weakly-Supervised Relation Extraction</dc:title>
 <dc:creator>Huang, Yi Yao</dc:creator>
 <dc:creator>Wang, William Yang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Deep residual learning (ResNet) is a new method for training very deep neural
networks using identity map-ping for shortcut connections. ResNet has won the
ImageNet ILSVRC 2015 classification task, and achieved state-of-the-art
performances in many computer vision tasks. However, the effect of residual
learning on noisy natural language processing tasks is still not well
understood. In this paper, we design a novel convolutional neural network (CNN)
with residual learning, and investigate its impacts on the task of distantly
supervised noisy relation extraction. In contradictory to popular beliefs that
ResNet only works well for very deep networks, we found that even with 9 layers
of CNNs, using identity mapping could significantly improve the performance for
distantly-supervised relation extraction.
</dc:description>
 <dc:description>Comment: Accepted by EMNLP 2017</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08872</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms for Approximate Subtropical Matrix Factorization</dc:title>
 <dc:creator>Karaev, Sanjar</dc:creator>
 <dc:creator>Miettinen, Pauli</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Matrix factorization methods are important tools in data mining and analysis.
They can be used for many tasks, ranging from dimensionality reduction to
visualization. In this paper we concentrate on the use of matrix factorizations
for finding patterns from the data. Rather than using the standard algebra --
and the summation of the rank-1 components to build the approximation of the
original matrix -- we use the subtropical algebra, which is an algebra over the
nonnegative real values with the summation replaced by the maximum operator.
Subtropical matrix factorizations allow &quot;winner-takes-it-all&quot; interpretations
of the rank-1 components, revealing different structure than the normal
(nonnegative) factorizations. We study the complexity and sparsity of the
factorizations, and present a framework for finding low-rank subtropical
factorizations. We present two specific algorithms, called Capricorn and
Cancer, that are part of our framework. They can be used with data that has
been corrupted with different types of noise, and with different error metrics,
including the sum-of-absolute differences, Frobenius norm, and Jensen--Shannon
divergence. Our experiments show that the algorithms perform well on data that
has subtropical structure, and that they can find factorizations that are both
sparse and easy to interpret.
</dc:description>
 <dc:description>Comment: 40 pages, 9 figures. For the associated source code, see
  http://people.mpi-inf.mpg.de/~pmiettin/tropical/</dc:description>
 <dc:date>2017-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08876</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Expressive Stream Reasoning with Laser</dc:title>
 <dc:creator>Bazoobandi, Hamid R.</dc:creator>
 <dc:creator>Beck, Harald</dc:creator>
 <dc:creator>Urbani, Jacopo</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  An increasing number of use cases require a timely extraction of non-trivial
knowledge from semantically annotated data streams, especially on the Web and
for the Internet of Things (IoT). Often, this extraction requires expressive
reasoning, which is challenging to compute on large streams. We propose Laser,
a new reasoner that supports a pragmatic, non-trivial fragment of the logic
LARS which extends Answer Set Programming (ASP) for streams. At its core, Laser
implements a novel evaluation procedure which annotates formulae to avoid the
re-computation of duplicates at multiple time points. This procedure, combined
with a judicious implementation of the LARS operators, is responsible for
significantly better runtimes than the ones of other state-of-the-art systems
like C-SPARQL and CQELS, or an implementation of LARS which runs on the ASP
solver Clingo. This enables the application of expressive logic-based reasoning
to large streams and opens the door to a wider range of stream reasoning use
cases.
</dc:description>
 <dc:description>Comment: 19 pages, 5 figures. Extended version of accepted paper at ISWC 2017</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08876</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08879</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Count Symmetries in Boolean &amp; Multi-Valued Prob. Graphical Models</dc:title>
 <dc:creator>Anand, Ankit</dc:creator>
 <dc:creator>Noothigattu, Ritesh</dc:creator>
 <dc:creator>Singla, Parag</dc:creator>
 <dc:creator>Mausam</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Lifted inference algorithms commonly exploit symmetries in a probabilistic
graphical model (PGM) for efficient inference. However, existing algorithms for
Boolean-valued domains can identify only those pairs of states as symmetric, in
which the number of ones and zeros match exactly (count symmetries). Moreover,
algorithms for lifted inference in multi-valued domains also compute a
multi-valued extension of count symmetries only. These algorithms miss many
symmetries in a domain. In this paper, we present first algorithms to compute
non-count symmetries in both Boolean-valued and multi-valued domains. Our
methods can also find symmetries between multi-valued variables that have
different domain cardinalities. The key insight in the algorithms is that they
change the unit of symmetry computation from a variable to a variable-value
(VV) pair. Our experiments find that exploiting these symmetries in MCMC can
obtain substantial computational gains over existing algorithms.
</dc:description>
 <dc:description>Comment: 9 pages, 5 figures</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08879</dc:identifier>
 <dc:identifier>Proceedings of the 20th International Conference on Artificial
  Intelligence and Statistics, PMLR 54: 1541-1549 (2017)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08883</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analog On-Tag Hashing: Towards Selective Reading as Hash Primitives in
  Gen2 RFID Systems</dc:title>
 <dc:creator>Yang, Lei</dc:creator>
 <dc:creator>Lin, Qiongzheng</dc:creator>
 <dc:creator>Duan, Chunhui</dc:creator>
 <dc:creator>An, Zhenlin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Deployment of billions of Commercial off-the-shelf (COTS) RFID tags has drawn
much of the attention of the research community because of the performance gaps
of current systems. In particular, hash-enabled protocol (HEP) is one of the
most thoroughly studied topics in the past decade. HEPs are designed for a wide
spectrum of notable applications (e.g., missing detection) without need to
collect all tags. HEPs assume that each tag contains a hash function, such that
a tag can select a random but predicable time slot to reply with a one-bit
presence signal that shows its existence. However, the hash function has never
been implemented in COTS tags in reality, which makes HEPs a 10-year
untouchable mirage. This work designs and implements a group of analog on-tag
hash primitives (called Tash) for COTS Gen2-compatible RFID systems, which
moves prior HEPs forward from theory to practice. In particular, we design
three types of hash primitives, namely, tash function, tash table function and
tash operator. All of these hash primitives are implemented through selective
reading, which is a fundamental and mandatory functionality specified in Gen2
protocol, without any hardware modification and fabrication. We further apply
our hash primitives in two typical HEP applications (i.e., cardinality
estimation and missing detection) to show the feasibility and effectiveness of
Tash. Results from our prototype, which is composed of one ImpinJ reader and 3,
000 Alien tags, demonstrate that the new design lowers 60% of the communication
overhead in the air. The tash operator can additionally introduce an overhead
drop of 29.7%.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08883</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08898</identifier>
 <datestamp>2017-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Garden of Eden theorem: old and new</dc:title>
 <dc:creator>Ceccherini-Silberstein, Tullio</dc:creator>
 <dc:creator>Coornaert, Michel</dc:creator>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Cellular Automata and Lattice Gases</dc:subject>
 <dc:subject>37B15, 37B10, 37B40, 37C29, 37D20, 43A07, 68Q80</dc:subject>
 <dc:description>  We review topics in the theory of cellular automata and dynamical systems
that are related to the Moore-Myhill Garden of Eden theorem.
</dc:description>
 <dc:description>Comment: this is an updated version (with a few misprints corrected and a
  final section &quot;added in proof&quot;); Handbook of Group Actions, (ed. L. Ji, A.
  Papadopoulos and S.T. Yau), Vol. V, International Press and Higher Education
  Press, 2018</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-09-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08898</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08900</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Methods for compressible fluid simulation on GPUs using high-order
  finite differences</dc:title>
 <dc:creator>Pekkil&#xe4;, Johannes</dc:creator>
 <dc:creator>V&#xe4;is&#xe4;l&#xe4;, Miikka S.</dc:creator>
 <dc:creator>K&#xe4;pyl&#xe4;, Maarit J.</dc:creator>
 <dc:creator>K&#xe4;pyl&#xe4;, Petri J.</dc:creator>
 <dc:creator>Anjum, Omer</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:description>  We focus on implementing and optimizing a sixth-order finite-difference
solver for simulating compressible fluids on a GPU using third-order
Runge-Kutta integration. Since graphics processing units perform well in
data-parallel tasks, this makes them an attractive platform for fluid
simulation. However, high-order stencil computation is memory-intensive with
respect to both main memory and the caches of the GPU. We present two
approaches for simulating compressible fluids using 55-point and 19-point
stencils. We seek to reduce the requirements for memory bandwidth and cache
size in our methods by using cache blocking and decomposing a latency-bound
kernel into several bandwidth-bound kernels. Our fastest implementation is
bandwidth-bound and integrates $343$ million grid points per second on a Tesla
K40t GPU, achieving a $3.6 \times$ speedup over a comparable hydrodynamics
solver benchmarked on two Intel Xeon E5-2690v3 processors. Our alternative GPU
implementation is latency-bound and achieves the rate of $168$ million updates
per second.
</dc:description>
 <dc:description>Comment: 14 pages, 7 figures</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08900</dc:identifier>
 <dc:identifier>Computer Physics Communications, Volume 217, August 2017, Pages
  11-22</dc:identifier>
 <dc:identifier>doi:10.1016/j.cpc.2017.03.011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08901</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Providing Self-Aware Systems with Reflexivity</dc:title>
 <dc:creator>Valitutti, Alessandro</dc:creator>
 <dc:creator>Trautteur, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.3.3</dc:subject>
 <dc:subject>I.2.0</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:description>  We propose a new type of self-aware systems inspired by ideas from
higher-order theories of consciousness. First, we discussed the crucial
distinction between introspection and reflexion. Then, we focus on
computational reflexion as a mechanism by which a computer program can inspect
its own code at every stage of the computation. Finally, we provide a formal
definition and a proof-of-concept implementation of computational reflexion,
viewed as an enriched form of program interpretation and a way to dynamically
&quot;augment&quot; a computational process.
</dc:description>
 <dc:description>Comment: 12 pages plus bibliography, appendices with code description, code of
  the proof-of-concept implementation, and examples of execution</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08901</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08908</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Deep Learning Models for Wireless Signal Classification with
  Low-Cost Spectrum Sensors</dc:title>
 <dc:creator>Rajendran, Sreeraj</dc:creator>
 <dc:creator>Meert, Wannes</dc:creator>
 <dc:creator>Giustiniano, Domenico</dc:creator>
 <dc:creator>Lenders, Vincent</dc:creator>
 <dc:creator>Pollin, Sofie</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper looks into the technology classification problem for a distributed
wireless spectrum sensing network. First, a new data-driven model for Automatic
Modulation Classification (AMC) based on long short term memory (LSTM) is
proposed. The model learns from the time domain amplitude and phase information
of the modulation schemes present in the training data without requiring expert
features like higher order cyclic moments. Analyses show that the proposed
model yields an average classification accuracy of close to 90% at varying SNR
conditions ranging from 0dB to 20dB. Further, we explore the utility of this
LSTM model for a variable symbol rate scenario. We show that a LSTM based model
can learn good representations of variable length time domain sequences, which
is useful in classifying modulation signals with different symbol rates. The
achieved accuracy of 75% on an input sample length of 64 for which it was not
trained, substantiates the representation power of the model. To reduce the
data communication overhead from distributed sensors, the feasibility of
classification using averaged magnitude spectrum data, or online classification
on the low cost sensors is studied. Furthermore, quantized realizations of the
proposed models are analyzed for deployment on sensors with low processing
power.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08912</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Family of Metrics for Clustering Algorithms</dc:title>
 <dc:creator>Alexander, Clark</dc:creator>
 <dc:creator>Akhmametyeva, Sofya</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We give the motivation for scoring clustering algorithms and a metric $M : A
\rightarrow \mathbb{N}$ from the set of clustering algorithms to the natural
numbers which we realize as \begin{equation} M(A) = \sum_i \alpha_i |f_i -
\beta_i|^{w_i} \end{equation} where $\alpha_i,\beta_i,w_i$ are parameters used
for scoring the feature $f_i$, which is computed empirically.. We give a method
by which one can score features such as stability, noise sensitivity, etc and
derive the necessary parameters. We conclude by giving a sample set of scores.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08912</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08913</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Stakeholder Recommendation: Applications and Challenges</dc:title>
 <dc:creator>Zheng, Yong</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Recommender systems have been successfully applied to assist decision making
by producing a list of item recommendations tailored to user preferences.
Traditional recommender systems only focus on optimizing the utility of the end
users who are the receiver of the recommendations. By contrast,
multi-stakeholder recommendation attempts to generate recommendations that
satisfy the needs of both the end users and other parties or stakeholders. This
paper provides an overview and discussion about the multi-stakeholder
recommendations from the perspective of practical applications, available data
sets, corresponding research challenges and potential solutions.
</dc:description>
 <dc:description>Comment: Presented at the 2017 Workshop on Value-Aware and Multistakeholder
  Recommendation</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08913</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08918</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coloring ($P_5$, bull)-free graphs</dc:title>
 <dc:creator>Maffray, Fr&#xe9;d&#xe9;ric</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We give a polynomial-time algorithm that computes the chromatic number of any
graph that contains no path on five vertices and no bull as an induced subgraph
(where the bull is the graph with five vertices $a,b,c,d,e$ and edges
$ab,bc,cd,be,ce$).
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08918</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08919</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-Stage Architecture Optimization for Differentially Private Kalman
  Filtering</dc:title>
 <dc:creator>Degue, Kwassi H.</dc:creator>
 <dc:creator>Ny, Jerome Le</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The problem of Kalman filtering under a differential privacy constraint is
considered in this paper. This problem arises in scenarios where an aggregate
statistic must be published in real-time based on privacy-sensitive input
signals, which can be assumed to originate from a linear Gaussian model. We
propose an architecture combining the differentially private Gaussian mechanism
with a linear pre-filter for signal shaping and a Kalman filter for output
reconstruction. When the signal shaping block is static, it is shown that the
optimum differentially private mechanism following this architecture can be
computed using semidefinite programming. Performance improvements over the
simpler input perturbation mechanism are illustrated analytically and through
computer simulations.
</dc:description>
 <dc:description>Comment: Long version of a paper presented at GlobalSIP 2017</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08925</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inductive and Functional Types in Ludics</dc:title>
 <dc:creator>Pavaux, Alice</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Ludics is a logical framework in which types/formulas are modelled by sets of
terms with the same computational behaviour. This paper investigates the
representation of inductive data types and functional types in ludics. We study
their structure following a game semantics approach. Inductive types are
interpreted as least fixed points, and we prove an internal completeness result
giving an explicit construction for such fixed points. The interactive
properties of the ludics interpretation of inductive and functional types are
then studied. In particular, we identify which higher-order functions types
fail to satisfy type safety, and we give a computational explanation.
</dc:description>
 <dc:description>Comment: Extended version of the paper accepted for publication in CSL 2017,
  46 pages</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08925</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08926</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Coherent Detection for Diffusive Molecular Communications</dc:title>
 <dc:creator>Jamali, Vahid</dc:creator>
 <dc:creator>Farsad, Nariman</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:creator>Goldsmith, Andrea</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study non-coherent detection schemes for molecular communication (MC)
systems that do not require knowledge of the channel state information (CSI).
In particular, we first derive the optimal maximum likelihood (ML)
multiple-symbol (MS) detector for MC systems. As a special case of the optimal
MS detector, we show that the optimal ML symbol-by-symbol (SS) detector can be
equivalently written in the form of a threshold-based detector, where the
optimal decision threshold is constant and depends only on the statistics of
the MC channel. The main challenge of the MS detector is the complexity
associated with the calculation of the optimal detection metric. To overcome
this issue, we propose an approximate MS detection metric which can be
expressed in closed form. To reduce complexity even further, we develop a
non-coherent decision-feedback (DF) detector and a suboptimal blind detector.
Finally, we derive analytical expressions for the bit error rate (BER) of the
optimal SS detector, as well as upper and lower bounds for the BER of the
optimal MS detector. Simulation results confirm the analysis and reveal the
effectiveness of the proposed optimal and suboptimal detection schemes compared
to a benchmark scheme that assumes perfect CSI knowledge, particularly when the
number of observations used for detection is sufficiently large.
</dc:description>
 <dc:description>Comment: This paper is submitted to IEEE Transactions on Communications</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08926</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08932</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Line codes generated by finite Coxeter groups</dc:title>
 <dc:creator>Biglieri, Ezio</dc:creator>
 <dc:creator>Viterbo, Emanuele</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Using an algebraic approach based on the theory of Coxeter groups, we design,
and describe the performance of, a class of line codes for parallel
transmission of $b$ bits over $b+1$ wires that admit especially simple encoding
and decoding algorithms. A number of designs are exhibited, some of them being
novel or improving on previously obtained codes.
</dc:description>
 <dc:description>Comment: 19 pages, 10 figures</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08932</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08934</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Introduction to OFDM-OQAM</dc:title>
 <dc:creator>Afrasiabi-Gorgani, Saeed</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The Filter Bank MultiCarrier (FBMC) modulation with Offset QAM (OQAM), also
know as OFDM-OQAM, has been very well studied in, roughly speaking, the last 15
years. A rich literature exists on the principle itself, discrete-time version
and implementation, equalization, extension to MIMO, etc. This text, written in
a tutorial style, explains the idea of Offset QAM and why it works from a
Communications Engineer point of view. The language is very simple and the math
elementary. Students and researchers in universities or practitioners who are
interested in gaining an intuition into the logic behind OFDM-OQAM will
hopefully enjoy reading this text. On the other hand, those interested in a
quick understanding of the idea, just enough to start using the waveform, can
find far better material.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08935</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anisotropic EM Segmentation by 3D Affinity Learning and Agglomeration</dc:title>
 <dc:creator>Parag, Toufiq</dc:creator>
 <dc:creator>Tschopp, Fabian</dc:creator>
 <dc:creator>Grisaitis, William</dc:creator>
 <dc:creator>Turaga, Srinivas C</dc:creator>
 <dc:creator>Zhang, Xuewen</dc:creator>
 <dc:creator>Matejek, Brian</dc:creator>
 <dc:creator>Kamentsky, Lee</dc:creator>
 <dc:creator>Lichtman, Jeff W.</dc:creator>
 <dc:creator>Pfister, Hanspeter</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The field of connectomics has recently produced neuron wiring diagrams from
relatively large brain regions from multiple animals. Most of these neural
reconstructions were computed from isotropic (e.g., FIBSEM) or near isotropic
(e.g., SBEM) data. In spite of the remarkable progress on algorithms in recent
years, automatic dense reconstruction from anisotropic data remains a challenge
for the connectomics community. One significant hurdle in the segmentation of
anisotropic data is the difficulty in generating a suitable initial
over-segmentation. In this study, we present a segmentation method for
anisotropic EM data that agglomerates a 3D over-segmentation computed from the
3D affinity prediction. A 3D U-net is trained to predict 3D affinities by the
MALIS approach. Experiments on multiple datasets demonstrates the strength and
robustness of the proposed method for anisotropic EM segmentation.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08935</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08939</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strawman: an Ensemble of Deep Bag-of-Ngrams for Sentiment Analysis</dc:title>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper describes a builder entry, named &quot;strawman&quot;, to the sentence-level
sentiment analysis task of the &quot;Build It, Break It&quot; shared task of the First
Workshop on Building Linguistically Generalizable NLP Systems. The goal of a
builder is to provide an automated sentiment analyzer that would serve as a
target for breakers whose goal is to find pairs of minimally-differing
sentences that break the analyzer.
</dc:description>
 <dc:description>Comment: A builder entry to the sentence-level sentiment analysis task of the
  &quot;Build It, Break It&quot; shared task of the First Workshop on Building
  Linguistically Generalizable NLP Systems</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08943</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Concise Radiometric Calibration Using The Power of Ranking</dc:title>
 <dc:creator>Gong, Han</dc:creator>
 <dc:creator>Finlayson, Graham D.</dc:creator>
 <dc:creator>Darrodi, Maryam M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Compared with raw images, the more common JPEG images are less useful for
machine vision algorithms and professional photographers because JPEG-sRGB does
not preserve a linear relation between pixel values and the light measured from
the scene. A camera is said to be radiometrically calibrated if there is a
computational model which can predict how the raw linear sensor image is mapped
to the corresponding rendered image (e.g. JPEGs) and vice versa. This paper
begins with the observation that the rank order of pixel values are mostly
preserved post colour correction. We show that this observation is the key to
solving for the whole camera pipeline (colour correction, tone and gamut
mapping). Our rank-based calibration method is simpler than the prior art and
so is parametrised by fewer variables which, concomitantly, can be solved for
using less calibration data. Another advantage is that we can derive the camera
pipeline from a single pair of raw-JPEG images. Experiments demonstrate that
our method delivers state-of-the-art results (especially for the most
interesting case of JPEG to raw).
</dc:description>
 <dc:description>Comment: accepted by BMVC 2017</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08943</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08945</identifier>
 <datestamp>2017-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Physical-World Attacks on Deep Learning Models</dc:title>
 <dc:creator>Evtimov, Ivan</dc:creator>
 <dc:creator>Eykholt, Kevin</dc:creator>
 <dc:creator>Fernandes, Earlence</dc:creator>
 <dc:creator>Kohno, Tadayoshi</dc:creator>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Prakash, Atul</dc:creator>
 <dc:creator>Rahmati, Amir</dc:creator>
 <dc:creator>Song, Dawn</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Although deep neural networks (DNNs) perform well in a variety of
applications, they are vulnerable to adversarial examples resulting from
small-magnitude perturbations added to the input data. Inputs modified in this
way can be mislabeled as a target class in targeted attacks or as a random
class different from the ground truth in untargeted attacks. However, recent
studies have demonstrated that such adversarial examples have limited
effectiveness in the physical world due to changing physical conditions--they
either completely fail to cause misclassification or only work in restricted
cases where a relatively complex image is perturbed and printed on paper. In
this paper, we propose a general attack algorithm--Robust Physical
Perturbations (RP2)-- that takes into account the numerous physical conditions
and produces robust adversarial perturbations. Using a real-world example of
road sign recognition, we show that adversarial examples generated using RP2
achieve high attack success rates in the physical world under a variety of
conditions, including different viewpoints. Furthermore, to the best of our
knowledge, there is currently no standardized way to evaluate physical
adversarial perturbations. Therefore, we propose a two-stage evaluation
methodology and tailor it to the road sign recognition use case. Our
methodology captures a range of diverse physical conditions, including those
encountered when images are captured from moving vehicles. We evaluate our
physical attacks using this methodology and effectively fool two road sign
classifiers. Using a perturbation in the shape of black and white stickers, we
attack a real Stop sign, causing targeted misclassification in 100% of the
images obtained in controlled lab settings and above 84% of the captured video
frames obtained on a moving vehicle for one of the classifiers we attack.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08949</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings of the 8th Workshop on Semantic Ambient Media Experiences
  (SAME 2016): Smart Cities for Better Living with HCI and UX (SEACHI),
  International Series on Information Systems and Management in Creative eMedia
  (CreMedia)</dc:title>
 <dc:creator>Sari, Eunice</dc:creator>
 <dc:creator>Tedjasaputra, Adi</dc:creator>
 <dc:creator>Ellen, Do Yi Luen</dc:creator>
 <dc:creator>Duh, Henry</dc:creator>
 <dc:creator>Lugmayr, Artur</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Digital and interactive technologies are becoming increasingly embedded in
everyday lives of people around the world. Application of technologies such as
real-time, context-aware, and interactive technologies; augmented and immersive
realities; social media; and location-based services has been particularly
evident in urban environments where technological and sociocultural
infrastructures enable easier deployment and adoption as compared to non-urban
areas. There has been growing consumer demand for new forms of experiences and
services enabled through these emerging technologies. We call this ambient
media, as the media is embedded in the natural human living environment.
  The 8th Semantic Ambient Media Workshop Experience (SAME) Proceedings where
based on a collaboration between the SEACHI Workshop Smart Cities for Better
Living with HCI and UX, which has been organized by UX Indonesia and was held
in conjunction with Computers and Human-Computer Interaction (CHI) 2016 in San
Jose, CA USA.
  The extended versions of the workshop papers are freely available through
www.ambientmediaassociation.org/Journal under open access by the International
Ambient Media Association (iAMEA). iAMEA is hosting the international open
access journal entitled &quot;International Journal on Information Systems and
Management in Creative eMedia&quot;, and the international open access series
&quot;International Series on Information Systems and Management in Creative eMedia&quot;
(see http://www.ambientmediaassociation.org).
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08949</dc:identifier>
 <dc:identifier>Eunice Sari, et. al., Proc. of the 8th Workshop on Semantic
  Ambient Media Experiences: Smart Cities for Better Living with HCI and UX,
  Int. SERIES on Information Systems and Management in Creative eMedia
  (CreMedia), n. 2016/1, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08951</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Handwritten character recognition using some (anti)-diagonal structural
  features</dc:title>
 <dc:creator>Casas, Jos&#xe9; Manuel</dc:creator>
 <dc:creator>Inassaridze, Nick</dc:creator>
 <dc:creator>Ladra, Manuel</dc:creator>
 <dc:creator>Ladra, Susana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we present a methodology for off-line handwritten character
recognition. The proposed methodology relies on a new feature extraction
technique based on structural characteristics, histograms and profiles. As
novelty, we propose the extraction of new eight histograms and four profiles
from the $32\times 32$ matrices that represent the characters, creating
256-dimension feature vectors. These feature vectors are then employed in a
classification step that uses a $k$-means algorithm. We performed experiments
using the NIST database to evaluate our proposal. Namely, the recognition
system was trained using 1000 samples and 64 classes for each symbol and was
tested on 500 samples for each symbol. We obtain promising accuracy results
that vary from 81.74\% to 93.75\%, depending on the difficulty of the character
category, showing better accuracy results than other methods from the state of
the art also based on structural characteristics.
</dc:description>
 <dc:description>Comment: The paper is under consideration at Pattern Recognition Letters, 9
  pages</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08952</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building Detection from Satellite Images on a Global Scale</dc:title>
 <dc:creator>Zhang, Amy</dc:creator>
 <dc:creator>Liu, Xianming</dc:creator>
 <dc:creator>Gros, Andreas</dc:creator>
 <dc:creator>Tiecke, Tobias</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In the last several years, remote sensing technology has opened up the
possibility of performing large scale building detection from satellite
imagery. Our work is some of the first to create population density maps from
building detection on a large scale. The scale of our work on population
density estimation via high resolution satellite images raises many issues,
that we will address in this paper. The first was data acquisition. Labeling
buildings from satellite images is a hard problem, one where we found our
labelers to only be about 85% accurate at. There is a tradeoff of quantity vs.
quality of labels, so we designed two separate policies for labels meant for
training sets and those meant for test sets, since our requirements of the two
set types are quite different. We also trained weakly supervised footprint
detection models with the classification labels, and semi-supervised approaches
with a small number of pixel-level labels, which are very expensive to procure.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08952</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08976</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effective Inference for Generative Neural Parsing</dc:title>
 <dc:creator>Stern, Mitchell</dc:creator>
 <dc:creator>Fried, Daniel</dc:creator>
 <dc:creator>Klein, Dan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Generative neural models have recently achieved state-of-the-art results for
constituency parsing. However, without a feasible search procedure, their use
has so far been limited to reranking the output of external parsers in which
decoding is more tractable. We describe an alternative to the conventional
action-level beam search used for discriminative neural models that enables us
to decode directly in these generative models. We then show that by improving
our basic candidate selection strategy and using a coarse pruning function, we
can improve accuracy while exploring significantly less of the search space.
Applied to the model of Choe and Charniak (2016), our inference procedure
obtains 92.56 F1 on section 23 of the Penn Treebank, surpassing prior
state-of-the-art results for single-model systems.
</dc:description>
 <dc:description>Comment: EMNLP 2017</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08976</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08985</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Aesthetics in Photography using Deep Convolutional Neural
  Networks</dc:title>
 <dc:creator>Suchecki, Maciej</dc:creator>
 <dc:creator>Trzcinski, Tomasz</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Evaluating aesthetic value of digital photographs is a challenging task,
mainly due to numerous factors that need to be taken into account and
subjective manner of this process. In this paper, we propose to approach this
problem using deep convolutional neural networks. Using a dataset of over 1.7
million photos collected from Flickr, we train and evaluate a deep learning
model whose goal is to classify input images by analysing their aesthetic
value. The result of this work is a publicly available Web-based application
that can be used in several real-life applications, e.g. to improve the
workflow of professional photographers by pre-selecting the best photos.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08985</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08989</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monocular Visual Teach and Repeat Aided by Local Ground Planarity</dc:title>
 <dc:creator>Clement, Lee</dc:creator>
 <dc:creator>Kelly, Jonathan</dc:creator>
 <dc:creator>Barfoot, Timothy D.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Visual Teach and Repeat (VT\&amp;R) allows an autonomous vehicle to repeat a
previously traversed route without a global positioning system. Existing
implementations of VT\&amp;R typically rely on 3D sensors such as stereo cameras
for mapping and localization, but many mobile robots are equipped with only 2D
monocular vision for tasks such as teleoperated bomb disposal. While
simultaneous localization and mapping (SLAM) algorithms exist that can recover
3D structure and motion from monocular images, the scale ambiguity inherent in
these methods complicates the estimation and control of lateral path-tracking
error, which is essential for achieving high-accuracy path following. In this
paper, we propose a monocular vision pipeline that enables kilometre-scale
route repetition with centimetre-level accuracy by approximating the ground
surface near the vehicle as planar (with some uncertainty) and recovering
absolute scale from the known position and orientation of the camera relative
to the vehicle. This system provides added value to many existing robots by
allowing for high-accuracy autonomous route repetition with a simple software
upgrade and no additional sensors. We validate our system over 4.3 km of
autonomous navigation and demonstrate accuracy on par with the conventional
stereo pipeline, even in highly non-planar terrain.
</dc:description>
 <dc:description>Comment: In Proceedings of the International Conference on Field and Service
  Robotics (FSR'15), Toronto, Ontario, Canada, Jun. 24-26 2015</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08989</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-27702-8_36</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08991</identifier>
 <datestamp>2017-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Deformable Shape Correspondence via Kernel Matching</dc:title>
 <dc:creator>L&#xe4;hner, Zorah</dc:creator>
 <dc:creator>Vestner, Matthias</dc:creator>
 <dc:creator>Boyarski, Amit</dc:creator>
 <dc:creator>Litany, Or</dc:creator>
 <dc:creator>Slossberg, Ron</dc:creator>
 <dc:creator>Remez, Tal</dc:creator>
 <dc:creator>Rodol&#xe0;, Emanuele</dc:creator>
 <dc:creator>Bronstein, Alex</dc:creator>
 <dc:creator>Bronstein, Michael</dc:creator>
 <dc:creator>Kimmel, Ron</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a method to match three dimensional shapes under non-isometric
deformations, topology changes and partiality. We formulate the problem as
matching between a set of pair-wise and point-wise descriptors, imposing a
continuity prior on the mapping, and propose a projected descent optimization
procedure inspired by difference of convex functions (DC) programming.
Surprisingly, in spite of the highly non-convex nature of the resulting
quadratic assignment problem, our method converges to a semantically meaningful
and continuous mapping in most of our experiments, and scales well. We provide
preliminary theoretical analysis and several interpretations of the method.
</dc:description>
 <dc:description>Comment: Accepted for oral presentation at 3DV 2017, including supplementary
  material</dc:description>
 <dc:date>2017-07-24</dc:date>
 <dc:date>2017-09-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.08998</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ASDA : Analyseur Syntaxique du Dialecte Alg{\'e}rien dans un but
  d'analyse s{\'e}mantique</dc:title>
 <dc:creator>Guellil, Im&#xe8;ne</dc:creator>
 <dc:creator>Azouaou, Fai&#xe7;al</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Opinion mining and sentiment analysis in social media is a research issue
having a great interest in the scientific community. However, before begin this
analysis, we are faced with a set of problems. In particular, the problem of
the richness of languages and dialects within these media. To address this
problem, we propose in this paper an approach of construction and
implementation of Syntactic analyzer named ASDA. This tool represents a parser
for the Algerian dialect that label the terms of a given corpus. Thus, we
construct a labeling table containing for each term its stem, different
prefixes and suffixes, allowing us to determine the different grammatical parts
a sort of POS tagging. This labeling will serve us later in the semantic
processing of the Algerian dialect, like the automatic translation of this
dialect or sentiment analysis
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.08998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09007</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dealing with Rational Second Order Ordinary Differential Equations where
  both Darboux and Lie Find It Difficult: The $S$-function Method</dc:title>
 <dc:creator>Avellar, J.</dc:creator>
 <dc:creator>Cardoso, M. S.</dc:creator>
 <dc:creator>Duarte, L. G. S.</dc:creator>
 <dc:creator>da Mota, L. A. C. P.</dc:creator>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  Here we present a new approach to search for first order invariants (first
integrals) of rational second order ordinary differential equations. This
method is an alternative to the Darbouxian and symmetry approaches. Our
procedure can succeed in many cases where these two approaches fail. We also
present here a Maple implementation of the theoretical results and methods,
hereby introduced, in a computational package -- {\it InSyDE}. The package is
designed, apart from materializing the algorithms presented, to provide a set
of tools to allow the user to analyse the intermediary steps of the process.
</dc:description>
 <dc:description>Comment: 42 pages</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09029</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fundamental Limits on Latency in Transceiver Cache-Aided HetNets</dc:title>
 <dc:creator>Kakar, Jaber</dc:creator>
 <dc:creator>Gherekhloo, Soheil</dc:creator>
 <dc:creator>Sezgin, Aydin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Stringent mobile usage characteristics force wire- less networks to undergo a
paradigm shift from conventional connection-centric to content-centric
deployment. With respect to 5G, caching and heterogeneous networks (HetNet) are
key technologies that will facilitate the evolution of highly content- centric
networks by facilitating unified quality of service in terms of low-latency
communication. In this paper, we study the impact of transceiver caching on the
latency for a HetNet consisting of a single user, a receiver and one
cache-assisted transceiver. We define an information-theoretic metric, the
delivery time per bit (DTB), that captures the delivery latency. We establish
coinciding lower and upper bounds on the DTB as a function of cache size and
wireless channel parameters; thus, enabling a complete characterization of the
DTB optimality of the network under study. As a result, we identify cache
beneficial and non-beneficial channel regimes.
</dc:description>
 <dc:description>Comment: 5 pages, ISIT 2017</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09030</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Locally Adapting Technique for Boundary Detection using Image
  Segmentation</dc:title>
 <dc:creator>Howard, Marylesa</dc:creator>
 <dc:creator>Hock, Margaret C.</dc:creator>
 <dc:creator>Meehan, B. T.</dc:creator>
 <dc:creator>Dresselhaus-Cooper, Leora</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Rapid growth in the field of quantitative digital image analysis is paving
the way for researchers to make precise measurements about objects in an image.
To compute quantities from the image such as the density of compressed
materials or the velocity of a shockwave, we must determine object boundaries.
Images containing regions that each have a spatial trend in intensity are of
particular interest. We present a supervised image segmentation method that
incorporates spatial information to locate boundaries between regions with
overlapping intensity histograms. The segmentation of a pixel is determined by
comparing its intensity to distributions from local, nearby pixel intensities.
Because of the statistical nature of the algorithm, we use maximum likelihood
estimation theory to quantify uncertainty about each boundary. We demonstrate
the success of this algorithm on a radiograph of a multicomponent cylinder and
on an optical image of a laser-induced shockwave, and we provide final boundary
locations with associated bands of uncertainty.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09032</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolution towards Smart Optical Networking: Where Artificial
  Intelligence (AI) meets the World of Photonics</dc:title>
 <dc:creator>Jukan, Admela</dc:creator>
 <dc:creator>Chamania, Mohit</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Smart optical networks are the next evolution of programmable networking and
programmable automation of optical networks, with human-in-the-loop network
control and management. The paper discusses this evolution and the role of
Artificial Intelligence (AI).
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09038</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling Mutation Testing for Android Apps</dc:title>
 <dc:creator>Linares-V&#xe1;squez, Mario</dc:creator>
 <dc:creator>Bavota, Gabriele</dc:creator>
 <dc:creator>Tufano, Michele</dc:creator>
 <dc:creator>Moran, Kevin</dc:creator>
 <dc:creator>Di Penta, Massimiliano</dc:creator>
 <dc:creator>Vendome, Christopher</dc:creator>
 <dc:creator>Bernal-C&#xe1;rdenas, Carlos</dc:creator>
 <dc:creator>Poshyvanyk, Denys</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Mutation testing has been widely used to assess the fault-detection
effectiveness of a test suite, as well as to guide test case generation or
prioritization. Empirical studies have shown that, while mutants are generally
representative of real faults, an effective application of mutation testing
requires &quot;traditional&quot; operators designed for programming languages to be
augmented with operators specific to an application domain and/or technology.
This paper proposes MDroid+, a framework for effective mutation testing of
Android apps. First, we systematically devise a taxonomy of 262 types of
Android faults grouped in 14 categories by manually analyzing 2,023 software
artifacts from different sources (e.g., bug reports, commits). Then, we
identified a set of 38 mutation operators, and implemented an infrastructure to
automatically seed mutations in Android apps with 35 of the identified
operators. The taxonomy and the proposed operators have been evaluated in terms
of stillborn/trivial mutants generated and their capacity to represent real
faults in Android apps, as compared to other well know mutation tools.
</dc:description>
 <dc:description>Comment: Accepted at 11TH Joint Meeting of the European Software Engineering
  Conference and the ACM SIGSOFT Symposium on the Foundations of Software
  Engineering (ESEC/FSE 17)</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09038</dc:identifier>
 <dc:identifier>doi:10.1145/3106237.3106275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09040</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Physically Feasible Decomposition of Engino$^{\circledR}$ Toy Models: A
  Graph Theoretic Approach</dc:title>
 <dc:creator>Antoniou, Efstathios N.</dc:creator>
 <dc:creator>Ara&#xfa;jo, Ad&#xe9;rito</dc:creator>
 <dc:creator>Bustamante, Miguel D.</dc:creator>
 <dc:creator>Gibali, Aviv</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  During the 125th European Study Group with Industry held in Limassol, Cyprus,
5-9 December 2016, one of the participating companies, Engino.net Ltd, posed a
very interesting challenge to the members of the study group. Engino.net Ltd is
a Cypriot company, founded in 2004, that produces a series of toy sets -- the
Engino$^{\circledR}$ toy sets -- consisting of a number of building blocks
which can be assembled by pupils to compose toy models. Depending on the
contents of a particular toy set, the company has developed a number of models
that can be built utilizing the blocks present in the set, however the
production of a step-by-step assembly manual for each model could only be done
manually. The goal of the challenge posed by the company was to implement a
procedure to automatically generate the assembly instructions for a given toy.
In the present paper we propose a graph-theoretic approach to model the problem
and provide a series of results to solve it by employing modified versions of
well established algorithms in graph theory. An algorithmic procedure to obtain
a hierarchical, physically feasible decomposition of a given toy model, from
which the assembly instructions can be recovered, is proposed.
</dc:description>
 <dc:description>Comment: Added acknowledgements</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09043</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ERASMUS: Efficient Remote Attestation via Self- Measurement for
  Unattended Settings</dc:title>
 <dc:creator>Carpent, Xavier</dc:creator>
 <dc:creator>Rattanavipanon, Norrathep</dc:creator>
 <dc:creator>Tsudik, Gene</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Remote attestation (RA) is a popular means of detecting malware in embedded
and IoT devices. RA is usually realized as an interactive protocol, whereby a
trusted party -- verifier -- measures integrity of a potentially compromised
remote device -- prover. Early work focused on purely software-based and fully
hardware-based techniques, neither of which is ideal for low-end devices. More
recent results have yielded hybrid (SW/HW) security architectures comprised of
a minimal set of features to support efficient and secure RA on low-end
devices.
  All prior RA techniques require on-demand operation, i.e, RA is performed in
real time. We identify some drawbacks of this general approach in the context
of unattended devices: First, it fails to detect mobile malware that enters and
leaves the prover between successive RA instances. Second, it requires the
prover to engage in a potentially expensive (in terms of time and energy)
computation, which can be harmful for critical or real-time devices.
  To address these drawbacks, we introduce the concept of self-measurement
where a prover device periodically (and securely) measures and records its own
software state, based on a pre-established schedule. A possibly untrusted
verifier occasionally collects and verifies these measurements. We present the
design of a concrete technique called ERASMUS : Efficient Remote Attestation
via Self-Measurement for Unattended Settings, justify its features and evaluate
its performance. In the process, we also define a new metric -- Quality of
Attestation (QoA). We argue that ERASMUS is well-suited for time-sensitive
and/or safety-critical applications that are not served well by on-demand RA.
Finally, we show that ERASMUS is a promising stepping stone towards handling
attestation of multiple devices (i.e., a group or swarm) with high mobility.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09050</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Shared Task on Bandit Learning for Machine Translation</dc:title>
 <dc:creator>Sokolov, Artem</dc:creator>
 <dc:creator>Kreutzer, Julia</dc:creator>
 <dc:creator>Sunderland, Kellen</dc:creator>
 <dc:creator>Danchenko, Pavel</dc:creator>
 <dc:creator>Szymaniak, Witold</dc:creator>
 <dc:creator>F&#xfc;rstenau, Hagen</dc:creator>
 <dc:creator>Riezler, Stefan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce and describe the results of a novel shared task on bandit
learning for machine translation. The task was organized jointly by Amazon and
Heidelberg University for the first time at the Second Conference on Machine
Translation (WMT 2017). The goal of the task is to encourage research on
learning machine translation from weak user feedback instead of human
references or post-edits. On each of a sequence of rounds, a machine
translation system is required to propose a translation for an input, and
receives a real-valued estimate of the quality of the proposed translation for
learning. This paper describes the shared task's learning and evaluation setup,
using services hosted on Amazon Web Services (AWS), the data and evaluation
metrics, and the results of various machine translation architectures and
learning protocols.
</dc:description>
 <dc:description>Comment: Conference on Machine Translation (WMT) 2017</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09055</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simultaneous active parameter estimation and control using
  sampling-based Bayesian reinforcement learning</dc:title>
 <dc:creator>Slade, Patrick</dc:creator>
 <dc:creator>Culbertson, Preston</dc:creator>
 <dc:creator>Sunberg, Zachary</dc:creator>
 <dc:creator>Kochenderfer, Mykel</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Robots performing manipulation tasks must operate under uncertainty about
both their pose and the dynamics of the system. In order to remain robust to
modeling error and shifts in payload dynamics, agents must simultaneously
perform estimation and control tasks. However, the optimal estimation actions
are often not the optimal actions for accomplishing the control tasks, and thus
agents trade between exploration and exploitation. This work frames the problem
as a Bayes-adaptive Markov decision process and solves it online using Monte
Carlo tree search and an extended Kalman filter to handle Gaussian process
noise and parameter uncertainty in a continuous space. MCTS selects control
actions to reduce model uncertainty and reach the goal state nearly optimally.
Certainty equivalent model predictive control is used as a benchmark to compare
performance in simulations with varying process noise and parameter
uncertainty.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09060</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bandit Convex Optimization for Scalable and Dynamic IoT Management</dc:title>
 <dc:creator>Chen, Tianyi</dc:creator>
 <dc:creator>Giannakis, Georgios B.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The present paper deals with online convex optimization involving both
time-varying loss functions, and time-varying constraints. The loss functions
are not fully accessible to the learner, and instead only the function values
(a.k.a. bandit feedback) are revealed at queried points. The constraints are
revealed after making decisions, and can be instantaneously violated, yet they
must be satisfied in the long term. This setting fits nicely the emerging
online network tasks such as fog computing in the Internet-of-Things (IoT),
where online decisions must flexibly adapt to the changing user preferences
(loss functions), and the temporally unpredictable availability of resources
(constraints). Tailored for such human-in-the-loop systems where the loss
functions are hard to model, a family of bandit online saddle-point (BanSaP)
schemes are developed, which adaptively adjust the online operations based on
(possibly multiple) bandit feedback of the loss functions, and the changing
environment. Performance here is assessed by: i) dynamic regret that
generalizes the widely used static regret; and, ii) fit that captures the
accumulated amount of constraint violations. Specifically, BanSaP is proved to
simultaneously yield sub-linear dynamic regret and fit, provided that the best
dynamic solutions vary slowly over time. Numerical tests in fog computation
offloading tasks corroborate that our proposed BanSaP approach offers
competitive performance relative to existing approaches that are based on
gradient feedback.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09062</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Kernels for Optimizing Locomotion Controllers</dc:title>
 <dc:creator>Antonova, Rika</dc:creator>
 <dc:creator>Rai, Akshara</dc:creator>
 <dc:creator>Atkeson, Christopher G.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Sample efficiency is important when optimizing parameters of locomotion
controllers, since hardware experiments are time consuming and expensive.
Bayesian Optimization, a sample-efficient optimization framework, has recently
been widely applied to address this problem, but further improvements in sample
efficiency are needed for practical applicability to real-world robots and
high-dimensional controllers. To address this, prior work has proposed using
domain expertise for constructing custom distance metrics for locomotion. In
this work we show how to learn such a distance metric automatically. We use a
neural network to learn an informed distance metric from data obtained in
high-fidelity simulations. We conduct experiments on two different controllers
and robot architectures. First, we demonstrate improvement in sample efficiency
when optimizing a 5-dimensional controller on the ATRIAS robot hardware. We
then conduct simulation experiments to optimize a 16-dimensional controller for
a 7-link robot model and obtain significant improvements even when optimizing
in perturbed environments. This demonstrates that our approach is able to
enhance sample efficiency for two different controllers, hence is a fitting
candidate for further experiments on hardware in the future.
</dc:description>
 <dc:description>Comment: (Rika Antonova and Akshara Rai contributed equally)</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09067</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adapting Sequence Models for Sentence Correction</dc:title>
 <dc:creator>Schmaltz, Allen</dc:creator>
 <dc:creator>Kim, Yoon</dc:creator>
 <dc:creator>Rush, Alexander M.</dc:creator>
 <dc:creator>Shieber, Stuart M.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In a controlled experiment of sequence-to-sequence approaches for the task of
sentence correction, we find that character-based models are generally more
effective than word-based models and models that encode subword information via
convolutions, and that modeling the output data as a series of diffs improves
effectiveness over standard approaches. Our strongest sequence-to-sequence
model improves over our strongest phrase-based statistical machine translation
model, with access to the same data, by 6 M2 (0.5 GLEU) points. Additionally,
in the data environment of the standard CoNLL-2014 setup, we demonstrate that
modeling (and tuning against) diffs yields similar or better M2 scores with
simpler models and/or significantly less data than previous
sequence-to-sequence approaches.
</dc:description>
 <dc:description>Comment: EMNLP 2017</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09067</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09068</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tartan: Accelerating Fully-Connected and Convolutional Layers in Deep
  Learning Networks by Exploiting Numerical Precision Variability</dc:title>
 <dc:creator>Delmas, Alberto</dc:creator>
 <dc:creator>Sharify, Sayeh</dc:creator>
 <dc:creator>Judd, Patrick</dc:creator>
 <dc:creator>Moshovos, Andreas</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Tartan (TRT), a hardware accelerator for inference with Deep Neural Networks
(DNNs), is presented and evaluated on Convolutional Neural Networks. TRT
exploits the variable per layer precision requirements of DNNs to deliver
execution time that is proportional to the precision p in bits used per layer
for convolutional and fully-connected layers. Prior art has demonstrated an
accelerator with the same execution performance only for convolutional layers.
Experiments on image classification CNNs show that on average across all
networks studied, TRT outperforms a state-of-the-art bit-parallel accelerator
by 1:90x without any loss in accuracy while it is 1:17x more energy efficient.
TRT requires no network retraining while it enables trading off accuracy for
additional improvements in execution performance and energy efficiency. For
example, if a 1% relative loss in accuracy is acceptable, TRT is on average
2:04x faster and 1:25x more energy efficient than a conventional bit-parallel
accelerator. A Tartan configuration that processes 2-bits at time, requires
less area than the 1-bit configuration, improves efficiency to 1:24x over the
bit-parallel baseline while being 73% faster for convolutional layers and 60%
faster for fully-connected layers is also presented.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09068</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09070</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sectoring in Multi-cell Massive MIMO Systems</dc:title>
 <dc:creator>Shahsavari, Shahram</dc:creator>
 <dc:creator>Hassanzadeh, Parisa</dc:creator>
 <dc:creator>Ashikhmin, Alexei</dc:creator>
 <dc:creator>Erkip, Elza</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, the downlink of a typical massive MIMO system is studied when
each base station is composed of three antenna arrays with directional antenna
elements serving 120 degrees of the two-dimensional space. A lower bound for
the achievable rate is provided. Furthermore, a power optimization problem is
formulated and as a result, centralized and decentralized power allocation
schemes are proposed. The simulation results reveal that using directional
antennas at base stations along with sectoring can lead to a notable increase
in the achievable rates by increasing the received signal power and decreasing
'pilot contamination' interference in multicell massive MIMO systems. Moreover,
it is shown that using optimized power allocation can increase 0.95-likely rate
in the system significantly.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09074</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning from Video and Text via Large-Scale Discriminative Clustering</dc:title>
 <dc:creator>Miech, Antoine</dc:creator>
 <dc:creator>Alayrac, Jean-Baptiste</dc:creator>
 <dc:creator>Bojanowski, Piotr</dc:creator>
 <dc:creator>Laptev, Ivan</dc:creator>
 <dc:creator>Sivic, Josef</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Discriminative clustering has been successfully applied to a number of
weakly-supervised learning tasks. Such applications include person and action
recognition, text-to-video alignment, object co-segmentation and colocalization
in videos and images. One drawback of discriminative clustering, however, is
its limited scalability. We address this issue and propose an online
optimization algorithm based on the Block-Coordinate Frank-Wolfe algorithm. We
apply the proposed method to the problem of weakly supervised learning of
actions and actors from movies together with corresponding movie scripts. The
scaling up of the learning problem to 66 feature length movies enables us to
significantly improve weakly supervised action recognition.
</dc:description>
 <dc:description>Comment: To appear in ICCV 2017</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09075</identifier>
 <datestamp>2017-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Early Fusion Strategy for Entity-Relationship Retrieval</dc:title>
 <dc:creator>Saleiro, Pedro</dc:creator>
 <dc:creator>Milic-Frayling, Natasa</dc:creator>
 <dc:creator>Rodrigues, Eduarda Mendes</dc:creator>
 <dc:creator>Soares, Carlos</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  We address the task of entity-relationship (E-R) retrieval, i.e, given a
query characterizing types of two or more entities and relationships between
them, retrieve the relevant tuples of related entities. Answering E-R queries
requires gathering and joining evidence from multiple unstructured documents.
In this work, we consider entity and relationships of any type, i.e,
characterized by context terms instead of pre-defined types or relationships.
We propose a novel IR-centric approach for E-R retrieval, that builds on the
basic early fusion design pattern for object retrieval, to provide extensible
entity-relationship representations, suitable for complex, multi-relationships
queries. We performed experiments with Wikipedia articles as entity
representations combined with relationships extracted from ClueWeb-09-B with
FACC1 entity linking. We obtained promising results using 3 different query
collections comprising 469 E-R queries.
</dc:description>
 <dc:description>Comment: KG4IR (SIGIR workshop)</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-10-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09075</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09078</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Witness-Functions versus Interpretation-Functions for Secrecy in
  Cryptographic Protocols: What to Choose?</dc:title>
 <dc:creator>Fattahi, Jaouhar</dc:creator>
 <dc:creator>Mejri, Mohamed</dc:creator>
 <dc:creator>Ziadia, Marwa</dc:creator>
 <dc:creator>Omrani, Takwa</dc:creator>
 <dc:creator>Pricop, Emil</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Proving that a cryptographic protocol is correct for secrecy is a hard task.
One of the strongest strategies to reach this goal is to show that it is
increasing, which means that the security level of every single atomic message
exchanged in the protocol, safely evaluated, never deceases. Recently, two
families of functions have been proposed to measure the security level of
atomic messages. The first one is the family of interpretation-functions. The
second is the family of witness-functions. In this paper, we show that the
witness-functions are more efficient than interpretation-functions. We give a
detailed analysis of an ad-hoc protocol on which the witness-functions succeed
in proving its correctness for secrecy while the interpretation-functions fail
to do so.
</dc:description>
 <dc:description>Comment: Accepted at the IEEE SMC (6 two column pages) on 2017-07-10</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09079</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Teach Reinforcement Learning Agents</dc:title>
 <dc:creator>Fachantidis, Anestis</dc:creator>
 <dc:creator>Taylor, Matthew E.</dc:creator>
 <dc:creator>Vlahavas, Ioannis</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this article we study the transfer learning model of action advice under a
budget. We focus on reinforcement learning teachers providing action advice to
heterogeneous students playing the game of Pac-Man under a limited advice
budget. First, we examine several critical factors affecting advice quality in
this setting, such as the average performance of the teacher, its variance and
the importance of reward discounting in advising. The experiments show the
non-trivial importance of the coefficient of variation (CV) as a statistic for
choosing policies that generate advice. The CV statistic relates variance to
the corresponding mean. Second, the article studies policy learning for
distributing advice under a budget. Whereas most methods in the relevant
literature rely on heuristics for advice distribution we formulate the problem
as a learning one and propose a novel RL algorithm capable of learning when to
advise, adapting to the student and the task at hand. Furthermore, we argue
that learning to advise under a budget is an instance of a more generic
learning problem: Constrained Exploitation Reinforcement Learning.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09079</dc:identifier>
 <dc:identifier>doi:10.3390/make1010002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09092</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Benchmarking 6DOF Outdoor Visual Localization in Changing Conditions</dc:title>
 <dc:creator>Sattler, Torsten</dc:creator>
 <dc:creator>Maddern, Will</dc:creator>
 <dc:creator>Toft, Carl</dc:creator>
 <dc:creator>Torii, Akihiko</dc:creator>
 <dc:creator>Hammarstrand, Lars</dc:creator>
 <dc:creator>Stenborg, Erik</dc:creator>
 <dc:creator>Safari, Daniel</dc:creator>
 <dc:creator>Okutomi, Masatoshi</dc:creator>
 <dc:creator>Pollefeys, Marc</dc:creator>
 <dc:creator>Sivic, Josef</dc:creator>
 <dc:creator>Kahl, Fredrik</dc:creator>
 <dc:creator>Pajdla, Tomas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual localization enables autonomous vehicles to navigate in their
surroundings and augmented reality applications to link virtual to real worlds.
Practical visual localization approaches need to be robust to a wide variety of
viewing condition, including day-night changes, as well as weather and seasonal
variations, while providing highly accurate 6 degree-of-freedom (6DOF) camera
pose estimates. In this paper, we introduce the first benchmark datasets
specifically designed for analyzing the impact of such factors on visual
localization. Using carefully created ground truth poses for query images taken
under a wide variety of conditions, we evaluate the impact of various factors
on 6DOF camera pose estimation accuracy through extensive experiments with
state-of-the-art localization approaches. Based on our results, we draw
conclusions about the difficulty of different conditions, showing that
long-term localization is far from solved, and propose promising avenues for
future work, including sequence-based localization approaches and the need for
better local features. We will make our benchmark publicly available.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09093</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Often Should CSI be Updated for Massive MIMO Systems with Massive
  Connectivity?</dc:title>
 <dc:creator>Deng, Ruichen</dc:creator>
 <dc:creator>Jiang, Zhiyuan</dc:creator>
 <dc:creator>Zhou, Sheng</dc:creator>
 <dc:creator>Niu, Zhisheng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Massive multiple-input multiple-output (MIMO) systems need to support massive
connectivity for the application of the Internet of things (IoT). The overhead
of channel state information (CSI) acquisition becomes a bottleneck in the
system performance due to the increasing number of users. An intermittent
estimation scheme is proposed to ease the burden of channel estimation and
maximize the sum capacity. In the scheme, we exploit the temporal correlation
of MIMO channels and analyze the influence of the age of CSI on the downlink
transmission rate using linear precoders. We show the CSI updating interval
should follow a quasi-periodic distribution and reach a trade-off between the
accuracy of CSI estimation and the overhead of CSI acquisition by optimizing
the CSI updating frequency of each user. Numerical results show that the
proposed intermittent scheme provides significant capacity gains over the
conventional continuous estimation scheme.
</dc:description>
 <dc:description>Comment: To appear in GLOBECOM 2017</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09094</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Open Source C++ Implementation of Multi-Threaded Gaussian Mixture
  Models, k-Means and Expectation Maximisation</dc:title>
 <dc:creator>Sanderson, Conrad</dc:creator>
 <dc:creator>Curtin, Ryan</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>65Y05, 68N99</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:subject>G.1</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  Modelling of multivariate densities is a core component in many signal
processing, pattern recognition and machine learning applications. The
modelling is often done via Gaussian mixture models (GMMs), which use
computationally expensive and potentially unstable training algorithms. We
provide an overview of a fast and robust implementation of GMMs in the C++
language, employing multi-threaded versions of the Expectation Maximisation
(EM) and k-means training algorithms. Multi-threading is achieved through
reformulation of the EM and k-means algorithms into a MapReduce-like framework.
Furthermore, the implementation uses several techniques to improve numerical
stability and modelling accuracy. We demonstrate that the multi-threaded
implementation achieves a speedup of an order of magnitude on a recent 16 core
machine, and that it can achieve higher modelling accuracy than a previously
well-established publically accessible implementation. The multi-threaded
implementation is included as a user-friendly class in recent releases of the
open source Armadillo C++ linear algebra library. The library is provided under
the permissive Apache~2.0 license, allowing unencumbered use in commercial
products.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09094</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09095</identifier>
 <datestamp>2017-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward the Starting Line: A Systems Engineering Approach to Strong AI</dc:title>
 <dc:creator>Alpcan, Tansu</dc:creator>
 <dc:creator>Erfani, Sarah M.</dc:creator>
 <dc:creator>Leckie, Christopher</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Artificial General Intelligence (AGI) or Strong AI aims to create machines
with human-like or human-level intelligence, which is still a very ambitious
goal when compared to the existing computing and AI systems. After many hype
cycles and lessons from AI history, it is clear that a big conceptual leap is
needed for crossing the starting line to kick-start mainstream AGI research.
This position paper aims to make a small conceptual contribution toward
reaching that starting line. After a broad analysis of the AGI problem from
different perspectives, a system-theoretic and engineering-based research
approach is introduced, which builds upon the existing mainstream AI and
systems foundations. Several promising cross-fertilization opportunities
between systems disciplines and AI research are identified. Specific potential
research directions are discussed.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:date>2017-10-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09097</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beamspace Channel Estimation in mmWave Systems via Cosparse Image
  Reconstruction Technique</dc:title>
 <dc:creator>Yang, Jie</dc:creator>
 <dc:creator>Wen, Chao-Kai</dc:creator>
 <dc:creator>Jin, Shi</dc:creator>
 <dc:creator>Gao, Feifei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers the beamspace channel estimation problem in 3D lens
antenna array under a millimeter-wave communication system. We analyze the
focusing capability of the 3D lens antenna array and the sparsity of the
beamspace channel response matrix. Considering the analysis, we observe that
the channel matrix can be treated as a 2D natural image; that is, the channel
is sparse, and the changes between adjacent elements are subtle. Thus, for the
channel estimation, we incorporate an image reconstruction technique called
sparse non-informative parameter estimator-based cosparse analysis AMP for
imaging (SCAMPI) algorithm. The SCAMPI algorithm is faster and more accurate
than earlier algorithms such as orthogonal matching pursuit and support
detection algorithms. To further improve the SCAMPI algorithm, we model the
channel distribution as a generic Gaussian mixture (GM) probability and embed
the expectation maximization learning algorithm into the SCAMPI algorithm to
learn the parameters in the GM probability. We show that the GM probability
outperforms the common uniform distribution used in image reconstruction. We
also propose a phase-shifter-reduced selection network structure to decrease
the power consumption of the system and prove that the SCAMPI algorithm is
robust even if the number of phase shifters is reduced by 10%.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09097</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09098</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MEMEN: Multi-layer Embedding with Memory Networks for Machine
  Comprehension</dc:title>
 <dc:creator>Pan, Boyuan</dc:creator>
 <dc:creator>Li, Hao</dc:creator>
 <dc:creator>Zhao, Zhou</dc:creator>
 <dc:creator>Cao, Bin</dc:creator>
 <dc:creator>Cai, Deng</dc:creator>
 <dc:creator>He, Xiaofei</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Machine comprehension(MC) style question answering is a representative
problem in natural language processing. Previous methods rarely spend time on
the improvement of encoding layer, especially the embedding of syntactic
information and name entity of the words, which are very crucial to the quality
of encoding. Moreover, existing attention methods represent each query word as
a vector or use a single vector to represent the whole query sentence, neither
of them can handle the proper weight of the key words in query sentence. In
this paper, we introduce a novel neural network architecture called Multi-layer
Embedding with Memory Network(MEMEN) for machine reading task. In the encoding
layer, we employ classic skip-gram model to the syntactic and semantic
information of the words to train a new kind of embedding layer. We also
propose a memory network of full-orientation matching of the query and passage
to catch more pivotal information. Experiments show that our model has
competitive results both from the perspectives of precision and efficiency in
Stanford Question Answering Dataset(SQuAD) among all published results and
achieves the state-of-the-art results on TriviaQA dataset.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09098</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09099</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object Detection of Satellite Images Using Multi-Channel Higher-order
  Local Autocorrelation</dc:title>
 <dc:creator>Uehara, Kazuki</dc:creator>
 <dc:creator>Sakanashi, Hidenori</dc:creator>
 <dc:creator>Nosato, Hirokazu</dc:creator>
 <dc:creator>Murakawa, Masahiro</dc:creator>
 <dc:creator>Miyamoto, Hiroki</dc:creator>
 <dc:creator>Nakamura, Ryosuke</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The Earth observation satellites have been monitoring the earth's surface for
a long time, and the images taken by the satellites contain large amounts of
valuable data. However, it is extremely hard work to manually analyze such huge
data. Thus, a method of automatic object detection is needed for satellite
images to facilitate efficient data analyses. This paper describes a new image
feature extended from higher-order local autocorrelation to the object
detection of multispectral satellite images. The feature has been extended to
extract spectral inter-relationships in addition to spatial relationships to
fully exploit multispectral information. The results of experiments with object
detection tasks conducted to evaluate the effectiveness of the proposed feature
extension indicate that the feature realized a higher performance compared to
existing methods.
</dc:description>
 <dc:description>Comment: 6 pages, 2 column, 7 figures, Accepted by IEEE International
  Conference on Systems, Man, and Cybernetics (SMC) 2017</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09100</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MixedPeds: Pedestrian Detection in Unannotated Videos using
  Synthetically Generated Human-agents for Training</dc:title>
 <dc:creator>Cheung, Ernest C.</dc:creator>
 <dc:creator>Wong, Tsan Kwong</dc:creator>
 <dc:creator>Bera, Aniket</dc:creator>
 <dc:creator>Manocha, Dinesh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a new method for training pedestrian detectors on an unannotated
set of images. We produce a mixed reality dataset that is composed of
real-world background images and synthetically generated static human-agents.
Our approach is general, robust, and makes no other assumptions about the
unannotated dataset regarding the number or location of pedestrians. We
automatically extract from the dataset: i) the vanishing point to calibrate the
virtual camera, and ii) the pedestrians' scales to generate a Spawn Probability
Map, which is a novel concept that guides our algorithm to place the
pedestrians at appropriate locations. After putting synthetic human-agents in
the unannotated images, we use these augmented images to train a Pedestrian
Detector, with the annotations generated along with the synthetic agents. We
conducted our experiments using Faster R-CNN by comparing the detection results
on the unannotated dataset performed by the detector trained using our approach
and detectors trained with other manually labeled datasets. We showed that our
approach improves the average precision by 5-13% over these detectors.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:date>2017-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09102</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fine-Pruning: Joint Fine-Tuning and Compression of a Convolutional
  Network with Bayesian Optimization</dc:title>
 <dc:creator>Tung, Frederick</dc:creator>
 <dc:creator>Muralidharan, Srikanth</dc:creator>
 <dc:creator>Mori, Greg</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  When approaching a novel visual recognition problem in a specialized image
domain, a common strategy is to start with a pre-trained deep neural network
and fine-tune it to the specialized domain. If the target domain covers a
smaller visual space than the source domain used for pre-training (e.g.
ImageNet), the fine-tuned network is likely to be over-parameterized. However,
applying network pruning as a post-processing step to reduce the memory
requirements has drawbacks: fine-tuning and pruning are performed
independently; pruning parameters are set once and cannot adapt over time; and
the highly parameterized nature of state-of-the-art pruning methods make it
prohibitive to manually search the pruning parameter space for deep networks,
leading to coarse approximations. We propose a principled method for jointly
fine-tuning and compressing a pre-trained convolutional network that overcomes
these limitations. Experiments on two specialized image domains (remote sensing
images and describable textures) demonstrate the validity of the proposed
approach.
</dc:description>
 <dc:description>Comment: BMVC 2017 oral</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09108</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensemble Performance of Biometric Authentication Systems Based on Secret
  Key Generation</dc:title>
 <dc:creator>Merhav, Neri</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the ensemble performance of biometric authentication systems, based
on secret key generation, which work as follows. In the enrollment stage, an
individual provides a biometric signal that is mapped into a secret key and a
helper message, the former being prepared to become available to the system at
a later time (for authentication), and the latter is stored in a public
database. When an authorized user requests authentication, claiming his/her
identity as one of the subscribers, s/he has to provide a biometric signal
again, and then the system, which retrieves also the helper message of the
claimed subscriber, produces an estimate of the secret key, that is finally
compared to the secret key of the claimed user. In case of a match, the
authentication request is approved, otherwise, it is rejected.Referring to an
ensemble of systems based on Slepian-Wolf binning, we provide a detailed
analysis of the false-reject and false-accept probabilities, for a wide class
of stochastic decoders. We also comment on the security for the typical code in
the ensemble.
</dc:description>
 <dc:description>Comment: 26 pages; submitted for publication</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09108</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09109</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Convergence of Least-Squares Progressive Iterative Approximation
  with Singular Iterative Matrix</dc:title>
 <dc:creator>Lin, Hongwei</dc:creator>
 <dc:creator>Cao, Qi</dc:creator>
 <dc:creator>Zhang, Xiaoting</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>65D07, 65D17</dc:subject>
 <dc:subject>G.1.2</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:description>  Developed in [Deng and Lin, 2014], Least-Squares Progressive Iterative
Approximation (LSPIA) is an efficient iterative method for solving B-spline
curve and surface least-squares fitting systems. In [Deng and Lin 2014], it was
shown that LSPIA is convergent when the iterative matrix is nonsingular. In
this paper, we will show that LSPIA is still convergent even the iterative
matrix is singular.
</dc:description>
 <dc:description>Comment: 12 pages, 2 figures</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09110</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptivity of Social Grooming Strategies caused by Social Closeness</dc:title>
 <dc:creator>Takano, Masanori</dc:creator>
 <dc:creator>Ichinose, Genki</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Human beings tend to cooperate with close friends, therefore they have to
construct strong social relationships to recieve cooperation from others.
Therefore they should have acquired their strategies of social relationship
construction through an evolutionary process. The behavior of social
relationship construction is know as &quot;social grooming.&quot; In this paper, we show
that there are four classes including a human-like strategy in evolutionary
dynamics of social grooming strategies based on an evolutionary game
simulation. Social relationship strengths (as measured by frequency of social
grooming) often show a much skewed distribution (a power law distribution). It
may be due to time costs constraints on social grooming, because the costs are
too large to ignore for having many strong social relationships. Evolution of
humans' strategies of construction of social relationships may explain the
origin of human intelligence based on a social brain hypothesis. We constructed
an individual-based model to explore the evolutionary dynamics of social
grooming strategies. The model is based on behavior to win over others by
strengthening social relationships with cooperators. The results of
evolutionary simulations show the four classes of evolutionary dynamics. The
results depend on total resources and the ratio of each cooperator's resource
to the number of cooperators. One of the four classes is similar to a human
strategy, i.e. the strategies based on the Yule--Simon process of power law.
</dc:description>
 <dc:description>Comment: 16 pages, 10 figures</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09110</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09112</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Almost Everywhere Matrix Recovery</dc:title>
 <dc:creator>Rong, Yi</dc:creator>
 <dc:creator>Wang, Yang</dc:creator>
 <dc:creator>Xu, Zhiqiang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:description>  Matrix recovery is raised in many areas. In this paper, we build up a
framework for almost everywhere matrix recovery which means to recover almost
all the $P\in {\mathcal M}\subset {\mathbb H}^{p\times q}$ from $Tr(A_jP),
j=1,\ldots,N$ where $A_j\in V_j\subset {\mathbb H}^{p\times q}$. We mainly
focus on the following question: how many measurements are needed to recover
almost all the matrices in ${\mathcal M}$? For the case where both ${\mathcal
M}$ and $V_j$ are algebraic varieties, we use the tools from algebraic geometry
to study the question and present some results to address it under many
different settings.
</dc:description>
 <dc:description>Comment: 22 pages</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09118</identifier>
 <datestamp>2017-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Counterfactual Learning from Bandit Feedback under Deterministic
  Logging: A Case Study in Statistical Machine Translation</dc:title>
 <dc:creator>Lawrence, Carolin</dc:creator>
 <dc:creator>Sokolov, Artem</dc:creator>
 <dc:creator>Riezler, Stefan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The goal of counterfactual learning for statistical machine translation (SMT)
is to optimize a target SMT system from logged data that consist of user
feedback to translations that were predicted by another, historic SMT system. A
challenge arises by the fact that risk-averse commercial SMT systems
deterministically log the most probable translation. The lack of sufficient
exploration of the SMT output space seemingly contradicts the theoretical
requirements for counterfactual learning. We show that counterfactual learning
from deterministic bandit logs is possible nevertheless by smoothing out
deterministic components in learning. This can be achieved by additive and
multiplicative control variates that avoid degenerate behavior in empirical
risk minimization. Our simulation experiments show improvements of up to 2 BLEU
points by counterfactual learning from deterministic bandit feedback.
</dc:description>
 <dc:description>Comment: Conference on Empirical Methods in Natural Language Processing
  (EMNLP), 2017, Copenhagen, Denmark</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:date>2017-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09119</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Co-Space: Sample Mining Across Feature Transformation for
  Semi-Supervised Learning</dc:title>
 <dc:creator>Chen, Ziliang</dc:creator>
 <dc:creator>Wang, Keze</dc:creator>
 <dc:creator>Wang, Xiao</dc:creator>
 <dc:creator>Peng, Pai</dc:creator>
 <dc:creator>Izquierdo, Ebroul</dc:creator>
 <dc:creator>Lin, Liang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Aiming at improving performance of visual classification in a cost-effective
manner, this paper proposes an incremental semi-supervised learning paradigm
called Deep Co-Space (DCS). Unlike many conventional semi-supervised learning
methods usually performing within a fixed feature space, our DCS gradually
propagates information from labeled samples to unlabeled ones along with deep
feature learning. We regard deep feature learning as a series of steps pursuing
feature transformation, i.e., projecting the samples from a previous space into
a new one, which tends to select the reliable unlabeled samples with respect to
this setting. Specifically, for each unlabeled image instance, we measure its
reliability by calculating the category variations of feature transformation
from two different neighborhood variation perspectives, and merged them into an
unified sample mining criterion deriving from Hellinger distance. Then, those
samples keeping stable correlation to their neighboring samples (i.e., having
small category variation in distribution) across the successive feature space
transformation, are automatically received labels and incorporated into the
model for incrementally training in terms of classification. Our extensive
experiments on standard image classification benchmarks (e.g., Caltech-256 and
SUN-397) demonstrate that the proposed framework is capable of effectively
mining from large-scale unlabeled images, which boosts image classification
performance and achieves promising results compared to other semi-supervised
learning methods.
</dc:description>
 <dc:description>Comment: To appear in IEEE Transactions on Circuits and Systems for Video
  Technology (T-CSVT), 2017</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09119</dc:identifier>
 <dc:identifier>doi:10.1109/TCSVT.2017.2710478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09123</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Research on Shape Mapping of 3D Mesh Models based on Hidden Markov
  Random Field and EM Algorithm</dc:title>
 <dc:creator>Wang, Yong</dc:creator>
 <dc:creator>Wu, Huai-yu</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  How to establish the matching (or corresponding) between two different 3D
shapes is a classical problem. This paper focused on the research on shape
mapping of 3D mesh models, and proposed a shape mapping algorithm based on
Hidden Markov Random Field and EM algorithm, as introducing a hidden state
random variable associated with the adjacent blocks of shape matching when
establishing HMRF. This algorithm provides a new theory and method to ensure
the consistency of the edge data of adjacent blocks, and the experimental
results show that the algorithm in this paper has a great improvement on the
shape mapping of 3D mesh models.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09123</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09132</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Formation in the Sky: Unmanned Aerial Vehicles for Multi-hop
  Wireless Backhauling</dc:title>
 <dc:creator>Challita, Ursula</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  To reap the benefits of dense small base station (SBS) deployment, innovative
backhaul solutions are needed in order to manage scenarios in which high-speed
ground backhaul links are either unavailable or limited in capacity. In this
paper, a novel backhaul scheme that utilizes unmanned aerial vehicles (UAVs) as
an on-demand flying network linking ground SBSs and the core network is
proposed. The design of the aerial backhaul scheme is formulated as a network
formation game among UAVs that seek to form a multi-hop backhaul network in the
air. To solve this game, a myopic network formation algorithm which reaches a
pairwise stable network upon convergence, is introduced. The proposed network
formation algorithm enables the UAVs to form the necessary multi-hop backhaul
network in a decentralized manner thus adapting the backhaul architecture to
the dynamics of the network. Simulation results show that the proposed network
formation algorithm achieves substantial performance gains in terms of both
rate and delay reaching, respectively, up to 40% and 41% compared to the
formation of direct communication links with the gateway node (for a network
with 15 UAVs).
</dc:description>
 <dc:description>Comment: This paper has been accepted for publication at Globecom 2017</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09135</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Pixel-Distribution Prior with Wider Convolution for Image
  Denoising</dc:title>
 <dc:creator>Liu, Peng</dc:creator>
 <dc:creator>Fang, Ruogu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we explore an innovative strategy for image denoising by using
convolutional neural networks (CNN) to learn pixel-distribution from noisy
data. By increasing CNN's width with large reception fields and more channels
in each layer, CNNs can reveal the ability to learn pixel-distribution, which
is a prior existing in many different types of noise. The key to our approach
is a discovery that wider CNNs tends to learn the pixel-distribution features,
which provides the probability of that inference-mapping primarily relies on
the priors instead of deeper CNNs with more stacked nonlinear layers. We
evaluate our work: Wide inference Networks (WIN) on additive white Gaussian
noise (AWGN) and demonstrate that by learning the pixel-distribution in images,
WIN-based network consistently achieves significantly better performance than
current state-of-the-art deep CNN-based methods in both quantitative and visual
evaluations. \textit{Code and models are available at
\url{https://github.com/cswin/WIN}}.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09135</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09143</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Localizing Actions from Video Labels and Pseudo-Annotations</dc:title>
 <dc:creator>Mettes, Pascal</dc:creator>
 <dc:creator>Snoek, Cees G. M.</dc:creator>
 <dc:creator>Chang, Shih-Fu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The goal of this paper is to determine the spatio-temporal location of
actions in video. Where training from hard to obtain box annotations is the
norm, we propose an intuitive and effective algorithm that localizes actions
from their class label only. We are inspired by recent work showing that
unsupervised action proposals selected with human point-supervision perform as
well as using expensive box annotations. Rather than asking users to provide
point supervision, we propose fully automatic visual cues that replace manual
point annotations. We call the cues pseudo-annotations, introduce five of them,
and propose a correlation metric for automatically selecting and combining
them. Thorough evaluation on challenging action localization datasets shows
that we reach results comparable to results with full box supervision. We also
show that pseudo-annotations can be leveraged during testing to improve weakly-
and strongly-supervised localizers.
</dc:description>
 <dc:description>Comment: BMVC</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09143</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09145</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial-Aware Object Embeddings for Zero-Shot Localization and
  Classification of Actions</dc:title>
 <dc:creator>Mettes, Pascal</dc:creator>
 <dc:creator>Snoek, Cees G. M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We aim for zero-shot localization and classification of human actions in
video. Where traditional approaches rely on global attribute or object
classification scores for their zero-shot knowledge transfer, our main
contribution is a spatial-aware object embedding. To arrive at spatial
awareness, we build our embedding on top of freely available actor and object
detectors. Relevance of objects is determined in a word embedding space and
further enforced with estimated spatial preferences. Besides local object
awareness, we also embed global object awareness into our embedding to maximize
actor and object interaction. Finally, we exploit the object positions and
sizes in the spatial-aware embedding to demonstrate a new spatio-temporal
action retrieval scenario with composite queries. Action localization and
classification experiments on four contemporary action video datasets support
our proposal. Apart from state-of-the-art results in the zero-shot localization
and classification settings, our spatial-aware embedding is even competitive
with recent supervised action localization alternatives.
</dc:description>
 <dc:description>Comment: ICCV</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09145</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09157</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Algorithms for Non-convex Isotonic Regression through
  Submodular Optimization</dc:title>
 <dc:creator>Bach, Francis</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the minimization of submodular functions subject to ordering
constraints. We show that this optimization problem can be cast as a convex
optimization problem on a space of uni-dimensional measures, with ordering
constraints corresponding to first-order stochastic dominance. We propose new
discretization schemes that lead to simple and efficient algorithms based on
zero-th, first, or higher order oracles; these algorithms also lead to
improvements without isotonic constraints. Finally, our experiments show that
non-convex loss functions can be much more robust to outliers for isotonic
regression, while still leading to an efficient optimization problem.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09157</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09161</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Empirical Bayes Estimators for High-Dimensional Sparse Vectors</dc:title>
 <dc:creator>Srinath, Pavan</dc:creator>
 <dc:creator>Venkataramanan, Ramji</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The problem of estimating a high-dimensional sparse vector
$\boldsymbol{\theta} \in \mathbb{R}^n$ from an observation in i.i.d. Gaussian
noise is considered. The performance is measured using squared-error loss. An
empirical Bayes shrinkage estimator, derived using a Bernoulli-Gaussian prior,
is analyzed and compared with the well-known soft-thresholding estimator. We
obtain concentration inequalities for the Stein's unbiased risk estimate and
the loss function of both estimators. The results show that for large $n$, both
the risk estimate and the loss function concentrate on deterministic values
close to the true risk.
  Depending on the underlying $\boldsymbol{\theta}$, either the proposed
empirical Bayes (eBayes) estimator or soft-thresholding may have smaller loss.
We consider a hybrid estimator that attempts to pick the better of the
soft-thresholding estimator and the eBayes estimator by comparing their risk
estimates. It is shown that: i) the loss of the hybrid estimator concentrates
on the minimum of the losses of the two competing estimators, and ii) the risk
of the hybrid estimator is within order $\frac{1}{\sqrt{n}}$ of the minimum of
the two risks. Simulation results are provided to support the theoretical
results. Finally, we use the eBayes and hybrid estimators as denoisers in the
approximate message passing (AMP) algorithm for compressed sensing, and show
that their performance is superior to the soft-thresholding denoiser in a wide
range of settings.
</dc:description>
 <dc:description>Comment: 34 pages, 5 figures</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09166</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Enhanced Classical Sensor Networks</dc:title>
 <dc:creator>Simmons, David</dc:creator>
 <dc:creator>Coon, Justin</dc:creator>
 <dc:creator>Datta, Animesh</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Physics - Instrumentation and Detectors</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  The quantum enhanced classical sensor network consists of $K$ clusters of
$N_e$ entangled quantum states that have been trialled $r$ times, each feeding
into a classical estimation process. Previous literature has shown that each
cluster can {ideally} achieve an estimation variance of $1/N_e^2r$ for
sufficient $r$. We begin by deriving the optimal values for the minimum mean
squared error of this quantum enhanced classical system. We then show that if
noise is \emph{absent} in the classical estimation process, the mean estimation
error will decay like $\Omega(1/KN_e^2r)$. However, when noise is
\emph{present} we find that the mean estimation error will decay like
$\Omega(1/K)$, so that \emph{all} the sensing gains obtained from the
individual quantum clusters will be lost.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09166</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09168</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Predict Charges for Criminal Cases with Legal Basis</dc:title>
 <dc:creator>Luo, Bingfeng</dc:creator>
 <dc:creator>Feng, Yansong</dc:creator>
 <dc:creator>Xu, Jianbo</dc:creator>
 <dc:creator>Zhang, Xiang</dc:creator>
 <dc:creator>Zhao, Dongyan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The charge prediction task is to determine appropriate charges for a given
case, which is helpful for legal assistant systems where the user input is fact
description. We argue that relevant law articles play an important role in this
task, and therefore propose an attention-based neural network method to jointly
model the charge prediction task and the relevant article extraction task in a
unified framework. The experimental results show that, besides providing legal
basis, the relevant articles can also clearly improve the charge prediction
results, and our full model can effectively predict appropriate charges for
cases with different expression styles.
</dc:description>
 <dc:description>Comment: 10 pages, accepted by EMNLP 2017</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09173</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Group Re-Identification via Unsupervised Transfer of Sparse Features
  Encoding</dc:title>
 <dc:creator>Lisanti, Giuseppe</dc:creator>
 <dc:creator>Martinel, Niki</dc:creator>
 <dc:creator>Del Bimbo, Alberto</dc:creator>
 <dc:creator>Foresti, Gian Luca</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Person re-identification is best known as the problem of associating a single
person that is observed from one or more disjoint cameras. The existing
literature has mainly addressed such an issue, neglecting the fact that people
usually move in groups, like in crowded scenarios. We believe that the
additional information carried by neighboring individuals provides a relevant
visual context that can be exploited to obtain a more robust match of single
persons within the group. Despite this, re-identifying groups of people
compound the common single person re-identification problems by introducing
changes in the relative position of persons within the group and severe
self-occlusions. In this paper, we propose a solution for group
re-identification that grounds on transferring knowledge from single person
re-identification to group re-identification by exploiting sparse dictionary
learning. First, a dictionary of sparse atoms is learned using patches
extracted from single person images. Then, the learned dictionary is exploited
to obtain a sparsity-driven residual group representation, which is finally
matched to perform the re-identification. Extensive experiments on the i-LIDS
groups and two newly collected datasets show that the proposed solution
outperforms state-of-the-art approaches.
</dc:description>
 <dc:description>Comment: This paper has been accepted for publication at ICCV 2017</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09173</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09177</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized deconvolution procedure for structural modeling of
  turbulence</dc:title>
 <dc:creator>San, Omer</dc:creator>
 <dc:creator>Vedula, Prakash</dc:creator>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Approximate deconvolution forms a mathematical framework for the structural
modeling of turbulence. The sub-filter scale flow quantities are typically
recovered by using the Van Cittert iterative procedure. In this paper, however,
we put forth a generalized approach for the iterative deconvolution process of
sub-filter scale recovery of turbulent flows by introducing Krylov space
iterative methods. Their accuracy and efficiency are demonstrated through a
systematic a-priori analysis of solving the Kraichnan and Kolmogorov
homogeneous isotropic turbulence problems in two- and three-dimensional
domains, respectively. Our numerical assessments show that the conjugate
gradient based iterative techniques lead to significantly improved performance
over the Van Cittert procedure and offer great promise for approximate
deconvolution turbulence models. In fact, our energy spectra analysis
illustrates that a substantially longer inertial range can be recovered by
using the proposed procedure equipped with the BiCGSTAB iterative scheme. This
trend is also confirmed by capturing tails of the probability density function
of turbulent flow quantities.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09177</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09183</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Learning in Multiagent Environments: Dealing with
  Non-Stationarity</dc:title>
 <dc:creator>Hernandez-Leal, Pablo</dc:creator>
 <dc:creator>Kaisers, Michael</dc:creator>
 <dc:creator>Baarslag, Tim</dc:creator>
 <dc:creator>de Cote, Enrique Munoz</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The key challenge in multiagent learning is learning a best response to the
behaviour of other agents, which may be non-stationary: if the other agents
adapt their strategy as well, the learning target moves. Disparate streams of
research have approached non-stationarity from several angles, which make a
variety of implicit assumptions that make it hard to keep an overview of the
state of the art and to validate the innovation and significance of new works.
This survey presents a coherent overview of work that addresses
opponent-induced non-stationarity with tools from game theory, reinforcement
learning and multi-armed bandits. Further, we reflect on the principle
approaches how algorithms model and cope with this non-stationarity, arriving
at a new framework and five categories (in increasing order of sophistication):
ignore, forget, respond to target models, learn models, and theory of mind. A
wide range of state-of-the-art algorithms is classified into a taxonomy, using
these categories and key characteristics of the environment (e.g.,
observability) and adaptation behaviour of the opponents (e.g., smooth,
abrupt). To clarify even further we present illustrative variations of one
domain, contrasting the strengths and limitations of each category. Finally, we
discuss in which environments the different approaches yield most merit, and
point to promising avenues of future research.
</dc:description>
 <dc:description>Comment: 64 pages, 7 figures. Under review since November 2016</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09183</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09198</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-Driven Stochastic Robust Optimization: A General Computational
  Framework and Algorithm for Optimization under Uncertainty in the Big Data
  Era</dc:title>
 <dc:creator>Ning, Chao</dc:creator>
 <dc:creator>You, Fengqi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  A novel data-driven stochastic robust optimization (DDSRO) framework is
proposed for optimization under uncertainty leveraging labeled multi-class
uncertainty data. Uncertainty data in large datasets are often collected from
various conditions, which are encoded by class labels. Machine learning methods
including Dirichlet process mixture model and maximum likelihood estimation are
employed for uncertainty modeling. A DDSRO framework is further proposed based
on the data-driven uncertainty model through a bi-level optimization structure.
The outer optimization problem follows a two-stage stochastic programming
approach to optimize the expected objective across different data classes;
adaptive robust optimization is nested as the inner problem to ensure the
robustness of the solution while maintaining computational tractability. A
decomposition-based algorithm is further developed to solve the resulting
multi-level optimization problem efficiently. Case studies on process network
design and planning are presented to demonstrate the applicability of the
proposed framework and algorithm.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09217</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extracting Event-Centric Document Collections from Large-Scale Web
  Archives</dc:title>
 <dc:creator>Gossen, Gerhard</dc:creator>
 <dc:creator>Demidova, Elena</dc:creator>
 <dc:creator>Risse, Thomas</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Web archives are typically very broad in scope and extremely large in scale.
This makes data analysis appear daunting, especially for non-computer
scientists. These collections constitute an increasingly important source for
researchers in the social sciences, the historical sciences and journalists
interested in studying past events. However, there are currently no access
methods that help users to efficiently access information, in particular about
specific events, beyond the retrieval of individual disconnected documents.
Therefore we propose a novel method to extract event-centric document
collections from large scale Web archives. This method relies on a specialized
focused extraction algorithm. Our experiments on the German Web archive
(covering a time period of 19 years) demonstrate that our method enables the
extraction of event-centric collections for different event types.
</dc:description>
 <dc:description>Comment: To be published in the proceedings of the Conference on Theory and
  Practice of Digital Libraries (TPDL) 2017</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09217</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09219</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Ladder Networks</dc:title>
 <dc:creator>Pr&#xe9;mont-Schwarz, Isabeau</dc:creator>
 <dc:creator>Ilin, Alexander</dc:creator>
 <dc:creator>Hao, Tele Hotloo</dc:creator>
 <dc:creator>Rasmus, Antti</dc:creator>
 <dc:creator>Boney, Rinu</dc:creator>
 <dc:creator>Valpola, Harri</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a recurrent extension of the Ladder networks whose structure is
motivated by the inference required in hierarchical latent variable models. We
demonstrate that the recurrent Ladder is able to handle a wide variety of
complex learning tasks that benefit from iterative inference and temporal
modeling. The architecture shows close-to-optimal results on temporal modeling
of video data, competitive results on music modeling, and improved perceptual
grouping based on higher order abstractions, such as stochastic textures and
motion cues. We present results for fully supervised, semi-supervised, and
unsupervised tasks. The results suggest that the proposed architecture and
principles are powerful tools for learning a hierarchy of abstractions,
learning iterative inference and handling temporal information.
</dc:description>
 <dc:description>Comment: 9 pages, 9 figures, 7-page appendix, fixed fig 9 (c)</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09219</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09225</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mathematical Programming formulations for the efficient solution of the
  $k$-sum approval voting problem</dc:title>
 <dc:creator>Ponce, Diego</dc:creator>
 <dc:creator>Puerto, Justo</dc:creator>
 <dc:creator>Ricca, Federica</dc:creator>
 <dc:creator>Scozzari, Andrea</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>90C11, 90C47, 90B99</dc:subject>
 <dc:description>  In this paper we address the problem of electing a committee among a set of
$m$ candidates and on the basis of the preferences of a set of $n$ voters. We
consider the approval voting method in which each voter can approve as many
candidates as she/he likes by expressing a preference profile (boolean
$m$-vector). In order to elect a committee, a voting rule must be established
to `transform' the $n$ voters' profiles into a winning committee. The problem
is widely studied in voting theory; for a variety of voting rules the problem
was shown to be computationally difficult and approximation algorithms and
heuristic techniques were proposed in the literature. In this paper we follow
an Ordered Weighted Averaging approach and study the $k$-sum approval voting
(optimization) problem in the general case $1 \leq k &lt;n$. For this problem we
provide different mathematical programming formulations that allow us to solve
it in an exact solution framework. We provide computational results showing
that our approach is efficient for medium-size test problems ($n$ up to 200,
$m$ up to 60) since in all tested cases it was able to find the exact optimal
solution in very short computational times.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09226</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling and Control of Humanoid Robots in Dynamic Environments: iCub
  Balancing on a Seesaw</dc:title>
 <dc:creator>Nava, Gabriele</dc:creator>
 <dc:creator>Pucci, Daniele</dc:creator>
 <dc:creator>Guedelha, Nuno</dc:creator>
 <dc:creator>Traversaro, Silvio</dc:creator>
 <dc:creator>Romano, Francesco</dc:creator>
 <dc:creator>Dafarra, Stefano</dc:creator>
 <dc:creator>Nori, Francesco</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Future applications involving humanoid robots may require physical
interaction between the robot and a dynamic environment. In this case,
classical balancing and walking controllers that neglect the environment
dynamics may not be sufficient for achieving a stable robot behaviour. This
paper presents a modeling and control framework for balancing humanoid robots
in contact with a dynamic environment. We first model the dynamics of the robot
and the environment, together with the contact constraints. Then, a control
strategy for stabilizing the extended system is proposed. Theoretical results
are verified in simulation with a model of the robot iCub balancing on a
seesaw.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09231</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving coreference resolution with automatically predicted prosodic
  information</dc:title>
 <dc:creator>R&#xf6;siger, Ina</dc:creator>
 <dc:creator>Stehwien, Sabrina</dc:creator>
 <dc:creator>Riester, Arndt</dc:creator>
 <dc:creator>Vu, Ngoc Thang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Adding manually annotated prosodic information, specifically pitch accents
and phrasing, to the typical text-based feature set for coreference resolution
has previously been shown to have a positive effect on German data. Practical
applications on spoken language, however, would rely on automatically predicted
prosodic information. In this paper we predict pitch accents (and phrase
boundaries) using a convolutional neural network (CNN) model from acoustic
features extracted from the speech signal. After an assessment of the quality
of these automatic prosodic annotations, we show that they also significantly
improve coreference resolution.
</dc:description>
 <dc:description>Comment: 1st Workshop on Speech-Centric Natural Language Processing (SCNLP) at
  EMNLP 2017; 6 pages, 1 figure</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09233</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A weighting strategy for Active Shape Models</dc:title>
 <dc:creator>Eguizabal, Alma</dc:creator>
 <dc:creator>Schreier, Peter J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Active Shape Models (ASM) are an iterative segmentation technique to find a
landmark-based contour of an object. In each iteration, a least-squares fit of
a plausible shape to some detected target landmarks is determined. Finding
these targets is a critical step: some landmarks are more reliably detected
than others, and some landmarks may not be within the field of view of their
detectors. To add robustness while preserving simplicity at the same time, a
generalized least-squares approach can be used, where a weighting matrix
incorporates reliability information about the landmarks. We propose a strategy
to choose this matrix, based on the covariance of empirically determined
residuals of the fit. We perform a further step to determine whether the target
landmarks are within the range of their detectors. We evaluate our strategy on
fluoroscopic X-ray images to segment the femur. We show that our technique
outperforms the standard ASM as well as other more heuristic weighted
least-squares strategies.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09240</identifier>
 <datestamp>2017-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human Pose Forecasting via Deep Markov Models</dc:title>
 <dc:creator>Toyer, Sam</dc:creator>
 <dc:creator>Cherian, Anoop</dc:creator>
 <dc:creator>Han, Tengda</dc:creator>
 <dc:creator>Gould, Stephen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Human pose forecasting is an important problem in computer vision with
applications to human-robot interaction, visual surveillance, and autonomous
driving. Usually, forecasting algorithms use 3D skeleton sequences and are
trained to forecast for a few milliseconds into the future. Long-range
forecasting is challenging due to the difficulty of estimating how long a
person continues an activity. To this end, our contributions are threefold: (i)
we propose a generative framework for poses using variational autoencoders
based on Deep Markov Models (DMMs); (ii) we evaluate our pose forecasts using a
pose-based action classifier, which we argue better reflects the subjective
quality of pose forecasts than distance in coordinate space; (iii) last, for
evaluation of the new model, we introduce a 480,000-frame video dataset called
Ikea Furniture Assembly (Ikea FA), which depicts humans repeatedly assembling
and disassembling furniture. We demonstrate promising results for our approach
on both Ikea FA and the existing NTU RGB+D dataset.
</dc:description>
 <dc:description>Comment: Accepted to DICTA'17</dc:description>
 <dc:date>2017-07-24</dc:date>
 <dc:date>2017-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09241</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generator Reversal</dc:title>
 <dc:creator>Kilcher, Yannic</dc:creator>
 <dc:creator>Lucchi, Aur&#xe9;lien</dc:creator>
 <dc:creator>Hofmann, Thomas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the problem of training generative models with deep neural
networks as generators, i.e. to map latent codes to data points. Whereas the
dominant paradigm combines simple priors over codes with complex deterministic
models, we propose instead to use more flexible code distributions. These
distributions are estimated non-parametrically by reversing the generator map
during training. The benefits include: more powerful generative models, better
modeling of latent structure and explicit control of the degree of
generalization.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09241</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09242</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consistency models with global operation sequencing and their
  composition (extended version)</dc:title>
 <dc:creator>Gotsman, Alexey</dc:creator>
 <dc:creator>Burckhardt, Sebastian</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Modern distributed systems often achieve availability and scalability by
providing consistency guarantees about the data they manage weaker than
linearizability. We consider a class of such consistency models that, despite
this weakening, guarantee that clients eventually agree on a global sequence of
operations, while seeing a subsequence of this final sequence at any given
point of time. Examples of such models include the classical Total Store Order
(TSO) and recently proposed dual TSO, Global Sequence Protocol (GSP) and
Ordered Sequential Consistency.
  We define a unified model, called Global Sequence Consistency (GSC), that has
the above models as its special cases, and investigate its key properties.
First, we propose a condition under which multiple objects each satisfying GSC
can be composed so that the whole set of objects satisfies GSC. Second, we
prove an interesting relationship between special cases of GSC---GSP, TSO and
dual TSO: we show that clients that do not communicate out-of-band cannot tell
the difference between these models. To obtain these results, we propose a
novel axiomatic specification of GSC and prove its equivalence to the
operational definition of the model.
</dc:description>
 <dc:description>Comment: Extended version of the paper from DISC'17</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09252</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mining Device-Specific Apps Usage Patterns from Large-Scale Android
  Users</dc:title>
 <dc:creator>Li, Huoran</dc:creator>
 <dc:creator>Lu, Xuan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  When smartphones, applications (a.k.a, apps), and app stores have been widely
adopted by the billions, an interesting debate emerges: whether and to what
extent do device models influence the behaviors of their users? The answer to
this question is critical to almost every stakeholder in the smartphone app
ecosystem, including app store operators, developers, end-users, and network
providers. To approach this question, we collect a longitudinal data set of app
usage through a leading Android app store in China, called Wandoujia. The data
set covers the detailed behavioral profiles of 0.7 million (761,262) unique
users who use 500 popular types of Android devices and about 0.2 million
(228,144) apps, including their app management activities, daily network access
time, and network traffic of apps. We present a comprehensive study on
investigating how the choices of device models affect user behaviors such as
the adoption of app stores, app selection and abandonment, data plan usage,
online time length, the tendency to use paid/free apps, and the preferences to
choosing competing apps. Some significant correlations between device models
and app usage are derived, leading to important findings on the various user
behaviors. For example, users owning different device models have a substantial
diversity of selecting competing apps, and users owning lower-end devices spend
more money to purchase apps and spend more time under cellular network.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1702.05060</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09258</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Patterns of Multistakeholder Recommendation</dc:title>
 <dc:creator>Burke, Robin</dc:creator>
 <dc:creator>Abdollahpouri, Himan</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Recommender systems are personalized information systems. However, in many
settings, the end-user of the recommendations is not the only party whose needs
must be represented in recommendation generation. Incorporating this insight
gives rise to the notion of multistakeholder recommendation, in which the
interests of multiple parties are represented in recommendation algorithms and
evaluation. In this paper, we identify patterns of stakeholder utility that
characterize different multistakeholder recommendation applications, and
provide a taxonomy of the different possible systems, only some of which have
currently been implemented.
</dc:description>
 <dc:description>Comment: Presented at the 2017 Workshop on Value-Aware and Multistakeholder
  Recommendation</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09280</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modular AWG-based Optical Shuffle Network</dc:title>
 <dc:creator>Ding, Jingjie</dc:creator>
 <dc:creator>Ye, Tong</dc:creator>
 <dc:creator>Lee, Tony T.</dc:creator>
 <dc:creator>Hu, Weisheng</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  This paper proposes an arrayed-waveguide grating (AWG) based
wavelength-division-multiplexing (WDM) shuffle network. Compared with previous
optical shuffle networks, our proposal is compact, easy to implement, highly
scalable, and cost effective.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09280</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09281</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correction of &quot;A Comparative Study to Benchmark Cross-project Defect
  Prediction Approaches&quot;</dc:title>
 <dc:creator>Herbold, Steffen</dc:creator>
 <dc:creator>Trautsch, Alexander</dc:creator>
 <dc:creator>Grabowski, Jens</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Unfortunately, the article &quot;A Comparative Study to Benchmark Cross-project
Defect Prediction Approaches&quot; has a problem in the statistical analysis which
was pointed out almost immediately after the pre-print of the article appeared
online. While the problem does not negate the contribution of the the article
and all key findings remain the same, it does alter some rankings of approaches
used in the study. Within this correction, we will explain the problem, how we
resolved it, and present the updated results.
</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09281</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09299</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The WILDTRACK Multi-Camera Person Dataset</dc:title>
 <dc:creator>Chavdarova, Tatjana</dc:creator>
 <dc:creator>Baqu&#xe9;, Pierre</dc:creator>
 <dc:creator>Bouquet, St&#xe9;phane</dc:creator>
 <dc:creator>Maksai, Andrii</dc:creator>
 <dc:creator>Jose, Cijo</dc:creator>
 <dc:creator>Lettry, Louis</dc:creator>
 <dc:creator>Fua, Pascal</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:creator>Fleuret, Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  People detection methods are highly sensitive to the perpetual occlusions
among the targets. As multi-camera set-ups become more frequently encountered,
joint exploitation of the across views information would allow for improved
detection performances. We provide a large-scale HD dataset named WILDTRACK
which finally makes advanced deep learning methods applicable to this problem.
The seven-static-camera set-up captures realistic and challenging scenarios of
walking people.
  Notably, its camera calibration with jointly high-precision projection widens
the range of algorithms which may make use of this dataset. In aim to help
accelerate the research on automatic camera calibration, such annotations also
accompany this dataset.
  Furthermore, the rich-in-appearance visual context of the pedestrian class
makes this dataset attractive for monocular pedestrian detection as well,
since: the HD cameras are placed relatively close to the people, and the size
of the dataset further increases seven-fold.
  In summary, we overview existing multi-camera datasets and detection methods,
enumerate details of our dataset, and we benchmark multi-camera state of the
art detectors on this new dataset.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09300</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From 4G to 5G: Self-organized Network Management meets Machine Learning</dc:title>
 <dc:creator>Moysen, Jessica</dc:creator>
 <dc:creator>Giupponi, Lorenza</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, we provide an analysis of self-organized network management,
with an end-to-end perspective of the network. Self-organization as applied to
cellular networks is usually referred to Self-organizing Networks (SONs), and
it is a key driver for improving Operations, Administration, and Maintenance
(OAM) activities. SON aims at reducing the cost of installation and management
of 4G and future 5G networks, by simplifying operational tasks through the
capability to configure, optimize and heal itself. To satisfy 5G network
management requirements, this autonomous management vision has to be extended
to the end to end network. In literature and also in some instances of products
available in the market, Machine Learning (ML) has been identified as the key
tool to implement autonomous adaptability and take advantage of experience when
making decisions. In this paper, we survey how network management can
significantly benefit from ML solutions. We review and provide the basic
concepts and taxonomy for SON, network management and ML. We analyse the
available state of the art in the literature, standardization, and in the
market. We pay special attention to 3rd Generation Partnership Project (3GPP)
evolution in the area of network management and to the data that can be
extracted from 3GPP networks, in order to gain knowledge and experience in how
the network is working, and improve network performance in a proactive way.
Finally, we go through the main challenges associated with this line of
research, in both 4G and in what 5G is getting designed, while identifying new
directions for research.
</dc:description>
 <dc:description>Comment: 23 pages, 3 figures, Survey</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09300</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09302</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-point Gaussian states, quadratic-exponential cost functionals, and
  large deviations estimates for linear quantum stochastic systems</dc:title>
 <dc:creator>Vladimirov, Igor G.</dc:creator>
 <dc:creator>Petersen, Ian R.</dc:creator>
 <dc:creator>James, Matthew R.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>81S25, 81S05, 81S22, 81P16, 81P40, 81Q93, 81Q10, 60G15</dc:subject>
 <dc:description>  This paper is concerned with risk-sensitive performance analysis for linear
quantum stochastic systems interacting with external bosonic fields. We
consider a cost functional in the form of the exponential moment of the
integral of a quadratic polynomial of the system variables over a bounded time
interval. An integro-differential equation is obtained for the time evolution
of this quadratic-exponential functional, which is compared with the original
quantum risk-sensitive performance criterion employed previously for
measurement-based quantum control and filtering problems. Using multi-point
Gaussian quantum states for the past history of the system variables and their
first four moments, we discuss a quartic approximation of the cost functional
and its infinite-horizon asymptotic behaviour. The computation of the
asymptotic growth rate of this approximation is reduced to solving two
algebraic Lyapunov equations. We also outline further approximations of the
cost functional, based on higher-order cumulants and their growth rates,
together with large deviations estimates. For comparison, an auxiliary
classical Gaussian Markov diffusion process is considered in a complex
Euclidean space which reproduces the quantum system variables at the level of
covariances but has different higher-order moments relevant to the
risk-sensitive criteria. The results of the paper are also demonstrated by a
numerical example and may find applications to coherent quantum risk-sensitive
control problems, where the plant and controller form a fully quantum
closed-loop system, and other settings with nonquadratic cost functionals.
</dc:description>
 <dc:description>Comment: 34 pages, 3 figures, 2 tables</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09315</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Synchronization in Duty-cycled Internet of Things (IoT)
  Applications</dc:title>
 <dc:creator>Yadav, Poonam</dc:creator>
 <dc:creator>McCann, Julie A.</dc:creator>
 <dc:creator>Pereira, Tiago</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In recent years, the networks of low-power devices have gained popularity.
Typically these devices are wireless and interact to form large networks such
as the Machine to Machine (M2M) networks, Internet of Things (IoT), Wearable
Computing, and Wireless Sensor Networks. The collaboration among these devices
is a key to achieving the full potential of these networks. A major problem in
this field is to guarantee robust communication between elements while keeping
the whole network energy efficient. In this paper, we introduce an extended and
improved emergent broadcast slot (EBS) scheme, which facilitates collaboration
for robust communication and is energy efficient. In the EBS, nodes
communication unit remains in sleeping mode and are awake just to communicate.
The EBS scheme is fully decentralized, that is, nodes coordinate their wake-up
window in partially overlapped manner within each duty-cycle to avoid message
collisions. We show the theoretical convergence behavior of the scheme, which
is confirmed through real test-bed experimentation.
</dc:description>
 <dc:description>Comment: 12 Pages, 11 Figures, Journal</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09316</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Deep Nonnegative Matrix Factorization</dc:title>
 <dc:creator>Guo, Zhenxing</dc:creator>
 <dc:creator>Zhang, Shihua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  Nonnegative matrix factorization is a powerful technique to realize dimension
reduction and pattern recognition through single-layer data representation
learning. Deep learning, however, with its carefully designed hierarchical
structure, is able to combine hidden features to form more representative
features for pattern recognition. In this paper, we proposed sparse deep
nonnegative matrix factorization models to analyze complex data for more
accurate classification and better feature interpretation. Such models are
designed to learn localized features or generate more discriminative
representations for samples in distinct classes by imposing $L_1$-norm penalty
on the columns of certain factors. By extending one-layer model into
multi-layer one with sparsity, we provided a hierarchical way to analyze big
data and extract hidden features intuitively due to nonnegativity. We adopted
the Nesterov's accelerated gradient algorithm to accelerate the computing
process with the convergence rate of $O(1/k^2)$ after $k$ steps iteration. We
also analyzed the computing complexity of our framework to demonstrate their
efficiency. To improve the performance of dealing with linearly inseparable
data, we also considered to incorporate popular nonlinear functions into this
framework and explored their performance. We applied our models onto two
benchmarking image datasets, demonstrating our models can achieve competitive
or better classification performance and produce intuitive interpretations
compared with the typical NMF and competing multi-layer models.
</dc:description>
 <dc:description>Comment: 13 pages, 8 figures</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09317</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Minimum-Cost Flow Model for Workload Optimization on Cloud
  Infrastructure</dc:title>
 <dc:creator>Nwanganga, Frederick</dc:creator>
 <dc:creator>Saebi, Mandana</dc:creator>
 <dc:creator>Madey, Gregory</dc:creator>
 <dc:creator>Chawla, Nitesh</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Recent technology advancements in the areas of compute, storage and
networking, along with the increased demand for organizations to cut costs
while remaining responsive to increasing service demands have led to the growth
in the adoption of cloud computing services. Cloud services provide the promise
of improved agility, resiliency, scalability and a lowered Total Cost of
Ownership (TCO). This research introduces a framework for minimizing cost and
maximizing resource utilization by using an Integer Linear Programming (ILP)
approach to optimize the assignment of workloads to servers on Amazon Web
Services (AWS) cloud infrastructure. The model is based on the classical
minimum-cost flow model, known as the assignment model.
</dc:description>
 <dc:description>Comment: 2017 IEEE 10th International Conference on Cloud Computing</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09317</dc:identifier>
 <dc:identifier>doi:10.1109/CLOUD.2017.68</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09319</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fourier-invariant method for locating point-masses and computing their
  attributes</dc:title>
 <dc:creator>Chui, Charles K.</dc:creator>
 <dc:creator>Mhaskar, Hrushikesh N.</dc:creator>
 <dc:subject>Statistics - Other Statistics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Motivated by the interest of observing the growth of cancer cells among
normal living cells and exploring how galaxies and stars are truly formed, the
objective of this paper is to introduce a rigorous and effective method for
counting point-masses, determining their spatial locations, and computing their
attributes. Based on computation of Hermite moments that are Fourier-invariant,
our approach facilitates the processing of both spatial and Fourier data in any
dimension.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09320</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Z-checker: A Framework for Assessing Lossy Compression of Scientific
  Data</dc:title>
 <dc:creator>Tao, Dingwen</dc:creator>
 <dc:creator>Di, Sheng</dc:creator>
 <dc:creator>Guo, Hanqi</dc:creator>
 <dc:creator>Chen, Zizhong</dc:creator>
 <dc:creator>Cappello, Franck</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Because of vast volume of data being produced by today's scientific
simulations and experiments, lossy data compressor allowing user-controlled
loss of accuracy during the compression is a relevant solution for
significantly reducing the data size. However, lossy compressor developers and
users are missing a tool to explore the features of scientific datasets and
understand the data alteration after compression in a systematic and reliable
way. To address this gap, we have designed and implemented a generic framework
called Z-checker. On the one hand, Z-checker combines a battery of data
analysis components for data compression. On the other hand, Z-checker is
implemented as an open-source community tool to which users and developers can
contribute and add new analysis components based on their additional analysis
demands. In this paper, we present a survey of existing lossy compressors. Then
we describe the design framework of Z-checker, in which we integrated
evaluation metrics proposed in prior work as well as other analysis tools.
Specifically, for lossy compressor developers, Z-checker can be used to
characterize critical properties of any dataset to improve compression
strategies. For lossy compression users, Z-checker can detect the compression
quality, provide various global distortion analysis comparing the original data
with the decompressed data and statistical analysis of the compression error.
Z-checker can perform the analysis with either coarse granularity or fine
granularity, such that the users and developers can select the best-fit,
adaptive compressors for different parts of the dataset. Z-checker features a
visualization interface displaying all analysis results in addition to some
basic views of the datasets such as time series. To the best of our knowledge,
Z-checker is the first tool designed to assess lossy compression
comprehensively for scientific datasets.
</dc:description>
 <dc:description>Comment: Accepted by The International Journal of High Performance Computing
  Application</dc:description>
 <dc:date>2017-06-12</dc:date>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09320</dc:identifier>
 <dc:identifier>doi:10.1177/1094342017737147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09323</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying the potential of Near Data Computing for Apache Spark</dc:title>
 <dc:creator>Awan, Ahsan Javed</dc:creator>
 <dc:creator>Brorsson, Mats</dc:creator>
 <dc:creator>Vlassov, Vladimir</dc:creator>
 <dc:creator>Ayguade, Eduard</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  While cluster computing frameworks are continuously evolving to provide
real-time data analysis capabilities, Apache Spark has managed to be at the
forefront of big data analytics for being a unified framework for both, batch
and stream data processing. There is also a renewed interest is Near Data
Computing (NDC) due to technological advancement in the last decade. However,
it is not known if NDC architectures can improve the performance of big data
processing frameworks such as Apache Spark. In this position paper, we
hypothesize in favour of NDC architecture comprising programmable logic based
hybrid 2D integrated processing-in-memory and in-storage processing for Apache
Spark, by extensive profiling of Apache Spark based workloads on Ivy Bridge
Server.
</dc:description>
 <dc:description>Comment: position paper</dc:description>
 <dc:date>2017-05-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09323</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09324</identifier>
 <datestamp>2017-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Empirical Evaluation of Abstract Argumentation: Supporting the Need for
  Bipolar and Probabilistic Approaches</dc:title>
 <dc:creator>Polberg, Sylwia</dc:creator>
 <dc:creator>Hunter, Anthony</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In dialogical argumentation it is often assumed that the involved parties
always correctly identify the intended statements posited by each other,
realize all of the associated relations, conform to the three acceptability
states (accepted, rejected, undecided), adjust their views when new and correct
information comes in, and that a framework handling only attack relations is
sufficient to represent their opinions. Although it is natural to make these
assumptions as a starting point for further research, removing them or even
acknowledging that such removal should happen is more challenging for some of
these concepts than for others. Probabilistic argumentation is one of the
approaches that can be harnessed for more accurate user modelling. The
epistemic approach allows us to represent how much a given argument is believed
by a given person, offering us the possibility to express more than just three
agreement states. It is equipped with a wide range of postulates, including
those that do not make any restrictions concerning how initial arguments should
be viewed, thus potentially being more adequate for handling beliefs of the
people that have not fully disclosed their opinions in comparison to Dung's
semantics. The constellation approach can be used to represent the views of
different people concerning the structure of the framework we are dealing with,
including cases in which not all relations are acknowledged or when they are
seen differently than intended. Finally, bipolar argumentation frameworks can
be used to express both positive and negative relations between arguments. In
this paper we describe the results of an experiment in which participants
judged dialogues in terms of agreement and structure. We compare our findings
with the aforementioned assumptions as well as with the constellation and
epistemic approaches to probabilistic argumentation and bipolar argumentation.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:date>2017-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09327</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A syntactic tool for proving hardness in the Second Level of the
  Polynomial-Time Hierarchy</dc:title>
 <dc:creator>Pin, Edwin</dc:creator>
 <dc:creator>Borges, Nerio</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In the nineties Immerman and Medina initiated the search for syn- tactic
tools to prove NP-completeness. In their work, amongst several results, they
conjecture that the NP-completeness of a problem defined by the conjunction of
a sentence in Existential Second Order Logic with a First Order sentence,
necessarily imply the NP-completeness of the problem defined by the Existential
Second Order sentence alone. This is interesting because if true it would
justify the restriction heuristic pro- posed in Garey and Johnson in his
classical book on NP completeness, which roughly says that in some cases one
can prove NP- complete a problem A by proving NP-complete a problem B contained
in A. Borges and Bonet extend some results from Immerman and Medina and they
also prove for a host of complexity classes that the Immerman- Medina
conjecture is true when the First Order sentence in the conjunc- tion is
universal. Our work extends that result to the Second Level of the
Polynomial-Time Hierarchy.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09327</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09332</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two Hilbert schemes in computer vision</dc:title>
 <dc:creator>Lieblich, Max</dc:creator>
 <dc:creator>Van Meter, Lucas</dc:creator>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We study the multiview moduli problems that arise in computer vision. We show
that these moduli spaces are always smooth and irreducible, in both the
calibrated and uncalibrated cases, for any number of views. We also show that
these moduli spaces always embed in (diagram) Hilbert schemes, and that these
embeddings are open immersions for more than four views. Our approach also
yields a natural smooth cover of the classical variety of essential matrices
that seems not to have appeared in the literature to date.
</dc:description>
 <dc:description>Comment: 20 pages, comments welcome at any time</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09332</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09334</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressive Sensing with Cross-Validation and Stop-Sampling for Sparse
  Polynomial Chaos Expansions</dc:title>
 <dc:creator>Huan, Xun</dc:creator>
 <dc:creator>Safta, Cosmin</dc:creator>
 <dc:creator>Sargsyan, Khachik</dc:creator>
 <dc:creator>Vane, Zachary P.</dc:creator>
 <dc:creator>Lacaze, Guilhem</dc:creator>
 <dc:creator>Oefelein, Joseph C.</dc:creator>
 <dc:creator>Najm, Habib N.</dc:creator>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>62J05, 94A12, 65Z05, 62P35</dc:subject>
 <dc:description>  Compressive sensing is a powerful technique for recovering sparse solutions
of underdetermined linear systems, which is often encountered in uncertainty
quantification analysis of expensive and high-dimensional physical models. We
perform numerical investigations employing several compressive sensing solvers
that target the unconstrained LASSO formulation, with a focus on linear systems
that arise in the construction of polynomial chaos expansions. With core
solvers of l1_ls, SpaRSA, CGIST, FPC_AS, and ADMM, we develop techniques to
mitigate overfitting through an automated selection of regularization constant
based on cross-validation, and a heuristic strategy to guide the stop-sampling
decision. Practical recommendations on parameter settings for these techniques
are provided and discussed. The overall method is applied to a series of
numerical examples of increasing complexity, including large eddy simulations
of supersonic turbulent jet-in-crossflow involving a 24-dimensional input.
Through empirical phase-transition diagrams and convergence plots, we
illustrate sparse recovery performance under structures induced by polynomial
chaos, accuracy and computational tradeoffs between polynomial bases of
different degrees, and practicability of conducting compressive sensing for a
realistic, high-dimensional physical application. Across test cases studied in
this paper, we find ADMM to have demonstrated empirical advantages through
consistent lower errors and faster computational times.
</dc:description>
 <dc:description>Comment: Preprint 29 pages, 16 figures (56 small figures)</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09334</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09346</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generic second-order macroscopic traffic node model for general
  multi-input multi-output road junctions via a dynamic system approach</dc:title>
 <dc:creator>Wright, Matthew A.</dc:creator>
 <dc:creator>Horowitz, Roberto</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper addresses an open problem in traffic modeling: the second-order
macroscopic node problem. A second-order macroscopic traffic model, in contrast
to a first-order model, allows for variation of driving behavior across
subpopulations of vehicles in the flow. The second-order models are thus more
descriptive (e.g., they have been used to model variable mixtures of
behaviorally-different traffic, like car/truck traffic, autonomous/human-driven
traffic, etc.), but are much more complex. The second-order node problem is a
particularly complex problem, as it requires the resolution of discontinuities
in traffic density and mixture characteristics, and solving of throughflows for
arbitrary numbers of input and output roads to a node (in other words, this is
an arbitrary-dimensional Riemann problem with two conserved quantities). We
propose a solution to this problem by making use of a recently-introduced
dynamic system characterization of the first-order node model problem, which
gives insight and intuition as to the continuous-time dynamics implicit in
first-order node models. We use this intuition to extend the dynamic system
node model to the second-order setting. We also extend the well-known &quot;Generic
Class of Node Model&quot; constraints to the second order and present a simple
solution algorithm to the second-order node problem. This node model has
immediate applications in allowing modeling of behaviorally-complex traffic
flows of contemporary interest (like partially-autonomous-vehicle flows) in
arbitrary road networks.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09349</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Out-degree reducing partitions of digraphs</dc:title>
 <dc:creator>Bang-Jensen, Joergen</dc:creator>
 <dc:creator>Bessy, St&#xe9;phane</dc:creator>
 <dc:creator>Havet, Fr&#xe9;d&#xe9;ric</dc:creator>
 <dc:creator>Yeo, Anders</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C20</dc:subject>
 <dc:description>  Let $k$ be a fixed integer. We determine the complexity of finding a
$p$-partition $(V_1, \dots, V_p)$ of the vertex set of a given digraph such
that the maximum out-degree of each of the digraphs induced by $V_i$, ($1\leq
i\leq p$) is at least $k$ smaller than the maximum out-degree of $D$. We show
that this problem is polynomial-time solvable when $p\geq 2k$ and ${\cal
NP}$-complete otherwise. The result for $k=1$ and $p=2$ answers a question
posed in \cite{bangTCS636}. We also determine, for all fixed non-negative
integers $k_1,k_2,p$, the complexity of deciding whether a given digraph of
maximum out-degree $p$ has a $2$-partition $(V_1,V_2)$ such that the digraph
induced by $V_i$ has maximum out-degree at most $k_i$ for $i\in [2]$. It
follows from this characterization that the problem of deciding whether a
digraph has a 2-partition $(V_1,V_2)$ such that each vertex $v\in V_i$ has at
least as many neighbours in the set $V_{3-i}$ as in $V_i$, for $i=1,2$ is
${\cal NP}$-complete. This solves a problem from \cite{kreutzerEJC24} on
majority colourings.
</dc:description>
 <dc:description>Comment: 11 pages, 1 figure</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09350</identifier>
 <datestamp>2017-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Centrality measures for graphons</dc:title>
 <dc:creator>Avella-Medina, Marco</dc:creator>
 <dc:creator>Parise, Francesca</dc:creator>
 <dc:creator>Schaub, Michael T.</dc:creator>
 <dc:creator>Segarra, Santiago</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Graphs provide a natural mathematical abstraction for systems with pairwise
interactions, and thus have become a prevalent tool for the representation of
systems across various scientific domains. However, as the size of relational
datasets continues to grow, traditional graph-based approaches are increasingly
replaced by other modeling paradigms, which enable a more flexible treatment of
such datasets. A promising framework in this context is provided by graphons,
which have been formally introduced as the natural limiting objects for graphs
of increasing sizes. However, while the theory of graphons is already well
developed, some prominent tools in network analysis still have no counterpart
within the realm of graphons. In particular, node centrality measures, which
have been successfully employed in various applications to reveal important
nodes in a network, have so far not been defined for graphons. In this work we
introduce formal definitions of centrality measures for graphons and establish
their connections to centrality measures defined on finite graphs. In
particular, we build on the theory of linear integral operators to define
degree, eigenvector, and Katz centrality functions for graphons. We further
establish concentration inequalities showing that these centrality functions
are natural limits of their analogous counterparts defined on sequences of
random graphs of increasing size. We discuss several strategies for computing
these centrality measures, and illustrate them through a set of numerical
examples.
</dc:description>
 <dc:description>Comment: Authors ordered alphabetically, all authors contributed equally. 32
  pages, 4 figures</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09364</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Face Detection and Alignment using Cascade Deep Convolutional
  Network</dc:title>
 <dc:creator>Cong, Weilin</dc:creator>
 <dc:creator>Zhao, Sanyuan</dc:creator>
 <dc:creator>Tian, Hui</dc:creator>
 <dc:creator>Shen, Jianbing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Real-world face detection and alignment demand an advanced discriminative
model to address challenges by pose, lighting and expression. Illuminated by
the deep learning algorithm, some convolutional neural networks based face
detection and alignment methods have been proposed. Recent studies have
utilized the relation between face detection and alignment to make models
computationally efficiency, however they ignore the connection between each
cascade CNNs. In this paper, we propose an structure to propose higher quality
training data for End-to-End cascade network training, which give computers
more space to automatic adjust weight parameter and accelerate convergence.
Experiments demonstrate considerable improvement over existing detection and
alignment models.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09364</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09366</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuous Global Optimization in Surface Reconstruction from an
  Oriented Point Cloud</dc:title>
 <dc:creator>Pan, Rongjiang</dc:creator>
 <dc:creator>Skala, Vaclav</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We introduce a continuous global optimization method to the field of surface
reconstruction from discrete noisy cloud of points with weak information on
orientation. The proposed method uses an energy functional combining flux-based
data-fit measures and a regularization term. A continuous convex relaxation
scheme assures the global minima of the geometric surface functional. The
reconstructed surface is implicitly represented by the binary segmentation of
vertices of a 3D uniform grid and a triangulated surface can be obtained by
extracting an appropriate isosurface. Unlike the discrete graph-cut solution,
the continuous global optimization entails advantages like memory requirements,
reduction of metrication errors for geometric quantities, allowing globally
optimal surface reconstruction at higher grid resolutions. We demonstrate the
performance of the proposed method on several oriented point clouds captured by
laser scanners. Experimental results confirm that our approach is robust to
noise, large holes and non-uniform sampling density under the condition of very
coarse orientation information.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09366</dc:identifier>
 <dc:identifier>Computer Aided Design, Vol.43, No.8, pp.896-901, Elsevier, ISSN
  0010-4485, 2011</dc:identifier>
 <dc:identifier>doi:10.1016/j.cad.2011.03.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09376</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Face Deidentification with Generative Deep Neural Networks</dc:title>
 <dc:creator>Meden, Bla&#x17e;</dc:creator>
 <dc:creator>Mall&#x131;, Refik Can</dc:creator>
 <dc:creator>Fabijan, Sebastjan</dc:creator>
 <dc:creator>Ekenel, Haz&#x131;m Kemal</dc:creator>
 <dc:creator>&#x160;truc, Vitomir</dc:creator>
 <dc:creator>Peer, Peter</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Face deidentification is an active topic amongst privacy and security
researchers. Early deidentification methods relying on image blurring or
pixelization were replaced in recent years with techniques based on formal
anonymity models that provide privacy guaranties and at the same time aim at
retaining certain characteristics of the data even after deidentification. The
latter aspect is particularly important, as it allows to exploit the
deidentified data in applications for which identity information is irrelevant.
In this work we present a novel face deidentification pipeline, which ensures
anonymity by synthesizing artificial surrogate faces using generative neural
networks (GNNs). The generated faces are used to deidentify subjects in images
or video, while preserving non-identity-related aspects of the data and
consequently enabling data utilization. Since generative networks are very
adaptive and can utilize a diverse set of parameters (pertaining to the
appearance of the generated output in terms of facial expressions, gender,
race, etc.), they represent a natural choice for the problem of face
deidentification. To demonstrate the feasibility of our approach, we perform
experiments using automated recognition tools and human annotators. Our results
show that the recognition performance on deidentified images is close to
chance, suggesting that the deidentification process based on GNNs is highly
effective.
</dc:description>
 <dc:description>Comment: IET Signal Processing Special Issue on Deidentification 2017</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09376</dc:identifier>
 <dc:identifier>doi:10.1049/iet-spr.2017.0049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09377</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Adaptive Resolution Molecular Dynamics Simulation</dc:title>
 <dc:creator>Marin, Iuliana</dc:creator>
 <dc:creator>Tudose, Virgil</dc:creator>
 <dc:creator>Hadar, Anton</dc:creator>
 <dc:creator>Goga, Nicolae</dc:creator>
 <dc:creator>Doncescu, Andrei</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  -Molecular simulations allow the study of properties and interactions of
molecular systems. This article presents an improved version of the Adaptive
Resolution Scheme that links two systems having atomistic (also called
fine-grained) and coarse-grained resolutions using a force interpolation
scheme. Interactions forces are obtained based on the Hamiltonian derivation
for a given molecular system. The new algorithm was implemented in GROMACS
molecular dynamics software package and tested on a butane system. The MARTINI
coarse-grained force field is applied between the coarse-grained particles of
the butane system. The molecular dynamics package GROMACS and the Message
Passing Interface allow the simulation of such a system in a reasonable amount
of time.
</dc:description>
 <dc:description>Comment: International Conference on Engineering,Technology and Innovation,
  Jun 2017, Madeira, Portugal</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09378</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Topology of Statistical Verifiability</dc:title>
 <dc:creator>Genin, Konstantin</dc:creator>
 <dc:creator>Kelly, Kevin T.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Topological models of empirical and formal inquiry are increasingly
prevalent. They have emerged in such diverse fields as domain theory [1, 16],
formal learning theory [18], epistemology and philosophy of science [10, 15, 8,
9, 2], statistics [6, 7] and modal logic [17, 4]. In those applications, open
sets are typically interpreted as hypotheses deductively verifiable by true
propositional information that rules out relevant possibilities. However, in
statistical data analysis, one routinely receives random samples logically
compatible with every statistical hypothesis. We bridge the gap between
propositional and statistical data by solving for the unique topology on
probability measures in which the open sets are exactly the statistically
verifiable hypotheses. Furthermore, we extend that result to a topological
characterization of learnability in the limit from statistical data.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09378</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 236-250</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.17</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09383</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Independent Feedback Vertex Sets for Graphs of Bounded Diameter</dc:title>
 <dc:creator>Bonamy, Marthe</dc:creator>
 <dc:creator>Dabrowski, Konrad K.</dc:creator>
 <dc:creator>Feghali, Carl</dc:creator>
 <dc:creator>Johnson, Matthew</dc:creator>
 <dc:creator>Paulusma, Daniel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  The Near-Bipartiteness problem is that of deciding whether or not the
vertices of a graph can be partitioned into sets $A$ and $B$, where $A$ is an
independent set and $B$ induces a forest. The set $A$ in such a partition is
said to be an independent feedback vertex set. Yang and Yuan proved that
Near-Bipartiteness is polynomial-time solvable for graphs of diameter 2 and
NP-complete for graphs of diameter 4. We show that Near-Bipartiteness is
NP-complete for graphs of diameter 3, resolving their open problem. We also
generalise their result for diameter 2 by proving that even the problem of
computing a minimum independent feedback vertex is polynomial-time solvable for
graphs of diameter 2.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09391</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interference Modeling in Cognitive Radio Networks: A Survey</dc:title>
 <dc:creator>Manesh, Mohsen Riahi</dc:creator>
 <dc:creator>Kaabouch, Naima</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  One of the fundamental elements impacting the performance of a wireless
system is interference, which has been a long-term issue in wireless networks.
In the case of cognitive radio (CR) networks, the problem of interference is
tremendously crucial. In other words, CR keeps the important promise of not
producing any harmful interference to the primary user (PU) system. Thus, it is
essential to investigate the impact of interference caused to the PUs so that
its detrimental effect on the performance of the PU system performance is
reduced. Study of cognitive interference generally includes developing a model
to statistically demonstrate the power of cognitive interference at the PUs,
which then can be utilized to examine different performance measures. Having
inspected the different models for channel interference present in the
literature, it can be obviously seen that interference models have been
gradually evolved in terms of complication and sophistication. Although
numerous papers can be found in the literature that have investigated different
models for interference, to the best of our knowledge, very few publications
are available that provide a review of all models and their comparisons. This
paper is a collection of state-of-the-art in interference modeling which
overviews and compares different models in the literature to provide the
valuable insights for researchers when modeling the interference in a specific
scenario.
</dc:description>
 <dc:description>Comment: 14 pages, 6 figures</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09393</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Inverse Reinforcement Learning via Bellman Gradient Iteration</dc:title>
 <dc:creator>Li, Kun</dc:creator>
 <dc:creator>Burdick, Joel W.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper develops an online inverse reinforcement learning algorithm aimed
at efficiently recovering a reward function from ongoing observations of an
agent's actions. To reduce the computation time and storage space in reward
estimation, this work assumes that each observed action implies a change of the
Q-value distribution, and relates the change to the reward function via the
gradient of Q-value with respect to reward function parameter. The gradients
are computed with a novel Bellman Gradient Iteration method that allows the
reward function to be updated whenever a new observation is available. The
method's convergence to a local optimum is proved.
  This work tests the proposed method in two simulated environments, and
evaluates the algorithm's performance under a linear reward function and a
non-linear reward function. The results show that the proposed algorithm only
requires a limited computation time and storage space, but achieves an
increasing accuracy as the number of observations grows. We also present a
potential application to robot cleaners at home.
</dc:description>
 <dc:description>Comment: The code and video are available at
  https://github.com/mestoking/BellmanGradientIteration/ . arXiv admin note:
  substantial text overlap with arXiv:1707.07767</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09394</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inverse Reinforcement Learning in Large State Spaces via Function
  Approximation</dc:title>
 <dc:creator>Li, Kun</dc:creator>
 <dc:creator>Burdick, Joel W.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper introduces a new method for inverse reinforcement learning in
large-scale and high-dimensional state spaces. To avoid solving the
computationally expensive reinforcement learning problems in reward learning,
we propose a function approximation method to ensure that the Bellman
Optimality Equation always holds, and then estimate a function to maximize the
likelihood of the observed motion. The time complexity of the proposed method
is linearly proportional to the cardinality of the action set, thus it can
handle large state spaces efficiently. We test the proposed method in a
simulated environment, and show that it is more accurate than existing methods
and significantly better in scalability. We also show that the proposed method
can extend many existing methods to high-dimensional state spaces. We then
apply the method to evaluating the effect of rehabilitative stimulations on
patients with spinal cord injuries based on the observed patient motions.
</dc:description>
 <dc:description>Comment: Experiment updated</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09394</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09400</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bipartite spanning sub(di)graphs induced by 2-partitions</dc:title>
 <dc:creator>Bang-Jensen, J&#xf8;rgen</dc:creator>
 <dc:creator>Bessy, St&#xe9;phane</dc:creator>
 <dc:creator>Havet, Fr&#xe9;d&#xe9;ric</dc:creator>
 <dc:creator>Yeo, Anders</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C20</dc:subject>
 <dc:description>  For a given $2$-partition $(V_1,V_2)$ of the vertices of a (di)graph $G$, we
study properties of the spanning bipartite subdigraph $B_G(V_1,V_2)$ of $G$
induced by those arcs/edges that have one end in each $V_i$. We determine, for
all pairs of non-negative integers $k_1,k_2$, the complexity of deciding
whether $G$ has a 2-partition $(V_1,V_2)$ such that each vertex in $V_i$ has at
least $k_i$ (out-)neighbours in $V_{3-i}$. We prove that it is ${\cal
NP}$-complete to decide whether a digraph $D$ has a 2-partition $(V_1,V_2)$
such that each vertex in $V_1$ has an out-neighbour in $V_2$ and each vertex in
$V_2$ has an in-neighbour in $V_1$. The problem becomes polynomially solvable
if we require $D$ to be strongly connected. We give a characterisation, based
on the so-called strong component digraph of a non-strong digraph of the
structure of ${\cal NP}$-complete instances in terms of their strong component
digraph. When we want higher in-degree or out-degree to/from the other set the
problem becomes ${\cal NP}$-complete even for strong digraphs. A further result
is that it is ${\cal NP}$-complete to decide whether a given digraph $D$ has a
$2$-partition $(V_1,V_2)$ such that $B_D(V_1,V_2)$ is strongly connected. This
holds even if we require the input to be a highly connected eulerian digraph.
</dc:description>
 <dc:description>Comment: 17 pages, 4 figures</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09402</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Independent Feedback Vertex Set for $P_5$-free Graphs</dc:title>
 <dc:creator>Bonamy, Marthe</dc:creator>
 <dc:creator>Dabrowski, Konrad K.</dc:creator>
 <dc:creator>Feghali, Carl</dc:creator>
 <dc:creator>Johnson, Matthew</dc:creator>
 <dc:creator>Paulusma, Daniel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  The NP-complete problem Feedback Vertex Set is that of deciding whether or
not it is possible, for a given integer $k\geq 0$, to delete at most $k$
vertices from a given graph so that what remains is a forest. The variant in
which the deleted vertices must form an independent set is called Independent
Feedback Vertex Set and is also NP-complete. In fact, even deciding if an
independent feedback vertex set exists is NP-complete and this problem is
closely related to the $3$-Colouring problem, or equivalently, to the problem
of deciding whether or not a graph has an independent odd cycle transversal,
that is, an independent set of vertices whose deletion makes the graph
bipartite. We initiate a systematic study of the complexity of Independent
Feedback Vertex Set for $H$-free graphs. We prove that it is NP-complete if $H$
contains a claw or cycle. Tamura, Ito and Zhou proved that it is
polynomial-time solvable for $P_4$-free graphs. We show that it remains
polynomial-time solvable for $P_5$-free graphs. We prove analogous results for
the Independent Odd Cycle Transversal problem, which asks whether or not a
graph has an independent odd cycle transversal of size at most $k$ for a given
integer $k\geq 0$. Finally, in line with our underlying research aim, we
compare the complexity of Independent Feedback Vertex Set for $H$-free graphs
with the complexity of $3$-Colouring, Independent Odd Cycle Transversal and
other related problems.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09405</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Photographic Image Synthesis with Cascaded Refinement Networks</dc:title>
 <dc:creator>Chen, Qifeng</dc:creator>
 <dc:creator>Koltun, Vladlen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present an approach to synthesizing photographic images conditioned on
semantic layouts. Given a semantic label map, our approach produces an image
with photographic appearance that conforms to the input layout. The approach
thus functions as a rendering engine that takes a two-dimensional semantic
specification of the scene and produces a corresponding photographic image.
Unlike recent and contemporaneous work, our approach does not rely on
adversarial training. We show that photographic images can be synthesized from
semantic layouts by a single feedforward network with appropriate structure,
trained end-to-end with a direct regression objective. The presented approach
scales seamlessly to high resolutions; we demonstrate this by synthesizing
photographic images at 2-megapixel resolution, the full resolution of our
training data. Extensive perceptual experiments on datasets of outdoor and
indoor scenes demonstrate that images synthesized by the presented approach are
considerably more realistic than alternative approaches. The results are shown
in the supplementary video at https://youtu.be/0fhUJT21-bs
</dc:description>
 <dc:description>Comment: Published at the International Conference on Computer Vision (ICCV
  2017)</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09406</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Deception Detection Refueled by Real World Data Collection</dc:title>
 <dc:creator>Yao, Wenlin</dc:creator>
 <dc:creator>Dai, Zeyu</dc:creator>
 <dc:creator>Huang, Ruihong</dc:creator>
 <dc:creator>Caverlee, James</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The lack of large realistic datasets presents a bottleneck in online
deception detection studies. In this paper, we apply a data collection method
based on social network analysis to quickly identify high-quality deceptive and
truthful online reviews from Amazon. The dataset contains more than 10,000
deceptive reviews and is diverse in product domains and reviewers. Using this
dataset, we explore effective general features for online deception detection
that perform well across domains. We demonstrate that with generalized features
- advertising speak and writing complexity scores - deception detection
performance can be further improved by adding additional deceptive reviews from
assorted domains in training. Finally, reviewer level evaluation gives an
interesting insight into different deceptive reviewers' writing styles.
</dc:description>
 <dc:description>Comment: 10 pages, Accepted to Recent Advances in Natural Language Processing
  (RANLP) 2017</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09406</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09410</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Weakly Supervised Approach to Train Temporal Relation Classifiers and
  Acquire Regular Event Pairs Simultaneously</dc:title>
 <dc:creator>Yao, Wenlin</dc:creator>
 <dc:creator>Nettyam, Saipravallika</dc:creator>
 <dc:creator>Huang, Ruihong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Capabilities of detecting temporal relations between two events can benefit
many applications. Most of existing temporal relation classifiers were trained
in a supervised manner. Instead, we explore the observation that regular event
pairs show a consistent temporal relation despite of their various contexts,
and these rich contexts can be used to train a contextual temporal relation
classifier, which can further recognize new temporal relation contexts and
identify new regular event pairs. We focus on detecting after and before
temporal relations and design a weakly supervised learning approach that
extracts thousands of regular event pairs and learns a contextual temporal
relation classifier simultaneously. Evaluation shows that the acquired regular
event pairs are of high quality and contain rich commonsense knowledge and
domain specific knowledge. In addition, the weakly supervised trained temporal
relation classifier achieves comparable performance with the state-of-the-art
supervised systems.
</dc:description>
 <dc:description>Comment: 10 pages, Recent Advances in Natural Language Processing (RANLP),
  2017</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09410</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09411</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of mandatory and discretionary lane change behaviors for heavy
  trucks</dc:title>
 <dc:creator>Zhao, Ding</dc:creator>
 <dc:creator>Peng, Huei</dc:creator>
 <dc:creator>Nobukawa, Kazutoshi</dc:creator>
 <dc:creator>Bao, Shan</dc:creator>
 <dc:creator>LeBlanc, David J</dc:creator>
 <dc:creator>Pan, Christopher S</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The behaviors of heavy vehicles drivers in mandatory and discretionary lane
changes are analyzed in this paper. 640 mandatory and 2,035 discretionary lane
change events were extracted from a naturalistic driving database. Variations
in gap acceptance and lane change duration were investigated. Statistical
analysis showed that mandatory lane changes are more aggressive in gap
acceptance and lane change execution than discretionary lane changes. The
results can be used for microscopic simulations, and design and evaluation of
driver-assistant systems.
</dc:description>
 <dc:description>Comment: Published in the 12th International Symposium on Advanced Vehicle
  Control, AVEC'14</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09414</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimized Broadcast for Deep Learning Workloads on Dense-GPU InfiniBand
  Clusters: MPI or NCCL?</dc:title>
 <dc:creator>Awan, Ammar Ahmad</dc:creator>
 <dc:creator>Chu, Ching-Hsiang</dc:creator>
 <dc:creator>Subramoni, Hari</dc:creator>
 <dc:creator>Panda, Dhabaleswar K.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Dense Multi-GPU systems have recently gained a lot of attention in the HPC
arena. Traditionally, MPI runtimes have been primarily designed for clusters
with a large number of nodes. However, with the advent of MPI+CUDA applications
and CUDA-Aware MPI runtimes like MVAPICH2 and OpenMPI, it has become important
to address efficient communication schemes for such dense Multi-GPU nodes. This
coupled with new application workloads brought forward by Deep Learning
frameworks like Caffe and Microsoft CNTK pose additional design constraints due
to very large message communication of GPU buffers during the training phase.
In this context, special-purpose libraries like NVIDIA NCCL have been proposed
for GPU-based collective communication on dense GPU systems. In this paper, we
propose a pipelined chain (ring) design for the MPI_Bcast collective operation
along with an enhanced collective tuning framework in MVAPICH2-GDR that enables
efficient intra-/inter-node multi-GPU communication. We present an in-depth
performance landscape for the proposed MPI_Bcast schemes along with a
comparative analysis of NVIDIA NCCL Broadcast and NCCL-based MPI_Bcast. The
proposed designs for MVAPICH2-GDR enable up to 14X and 16.6X improvement,
compared to NCCL-based solutions, for intra- and inter-node broadcast latency,
respectively. In addition, the proposed designs provide up to 7% improvement
over NCCL-based solutions for data parallel training of the VGG network on 128
GPUs using Microsoft CNTK.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09415</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gap Acceptance During Lane Changes by Large-Truck Drivers-An Image-Based
  Analysis</dc:title>
 <dc:creator>Nobukawa, Kazutoshi</dc:creator>
 <dc:creator>Bao, Shan</dc:creator>
 <dc:creator>LeBlanc, David J.</dc:creator>
 <dc:creator>Zhao, Ding</dc:creator>
 <dc:creator>Peng, Huei</dc:creator>
 <dc:creator>Pan, Christopher S.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents an analysis of rearward gap acceptance characteristics of
drivers of large trucks in highway lane change scenarios. The range between the
vehicles was inferred from camera images using the estimated lane width
obtained from the lane tracking camera as the reference. Six-hundred lane
change events were acquired from a large-scale naturalistic driving data set.
The kinematic variables from the image-based gap analysis were filtered by the
weighted linear least squares in order to extrapolate them at the lane change
time. In addition, the time-to-collision and required deceleration were
computed, and potential safety threshold values are provided. The resulting
range and range rate distributions showed directional discrepancies, i.e., in
left lane changes, large trucks are often slower than other vehicles in the
target lane, whereas they are usually faster in right lane changes. Video
observations have confirmed that major motivations for changing lanes are
different depending on the direction of move, i.e., moving to the left (faster)
lane occurs due to a slower vehicle ahead or a merging vehicle on the
right-hand side, whereas right lane changes are frequently made to return to
the original lane after passing.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09415</dc:identifier>
 <dc:identifier>IEEE Transactions on Intelligent Transportation Systems ( Volume:
  17, Issue: 3, March 2016 )</dc:identifier>
 <dc:identifier>doi:10.1109/TITS.2015.2482821</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09416</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vision-Based Assessment of Parkinsonism and Levodopa-Induced Dyskinesia
  with Deep Learning Pose Estimation</dc:title>
 <dc:creator>Li, Michael H.</dc:creator>
 <dc:creator>Mestre, Tiago A.</dc:creator>
 <dc:creator>Fox, Susan H.</dc:creator>
 <dc:creator>Taati, Babak</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Objective: To apply deep learning pose estimation algorithms for vision-based
assessment of parkinsonism and levodopa-induced dyskinesia (LID). Methods: Nine
participants with Parkinson's disease (PD) and LID completed a levodopa
infusion protocol, where symptoms were assessed at regular intervals using the
Unified Dyskinesia Rating Scale (UDysRS) and Unified Parkinson's Disease Rating
Scale (UPDRS). A state-of-the-art deep learning pose estimation method was used
to extract movement trajectories from videos of PD assessments. Features of the
movement trajectories were used to detect and estimate the severity of
parkinsonism and LID using random forest. Communication and drinking tasks were
used to assess LID, while leg agility and toe tapping tasks were used to assess
parkinsonism. Feature sets from tasks were also combined to predict total
UDysRS and UPDRS Part III scores. Results: For LID, the communication task
yielded the best results for dyskinesia (severity estimation: r = 0.661,
detection: AUC = 0.930). For parkinsonism, leg agility had better results for
severity estimation (r = 0.618), while toe tapping was better for detection
(AUC = 0.773). UDysRS and UPDRS Part III scores were predicted with r = 0.741
and 0.530, respectively. Conclusion: This paper presents the first application
of deep learning for vision-based assessment of parkinsonism and LID and
demonstrates promising performance for the future translation of deep learning
to PD clinical practices. Significance: The proposed system provides insight
into the potential of computer vision and deep learning for clinical
application in PD.
</dc:description>
 <dc:description>Comment: 8 pages, 1 figure. Under review</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09417</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Invitation to Polynomiography via Exponential Series</dc:title>
 <dc:creator>Kalantari, Bahman</dc:creator>
 <dc:subject>Mathematics - History and Overview</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>12D10, 97U30, 97N80, 97H30, 97N80</dc:subject>
 <dc:subject>G.1.5</dc:subject>
 <dc:description>  The subject of Polynomiography deals with algorithmic visualization of
polynomial equations, having many applications in STEM and art, see [Kal04].
Here we consider the polynomiography of the partial sums of the exponential
series. While the exponential function is taught in standard calculus courses,
it is unlikely that properties of zeros of its partial sums are considered in
such courses, let alone their visualization as science or art. The Monthly
article Zemyan discusses some mathematical properties of these zeros. Here we
exhibit some fractal and non-fractal polynomiographs of the partial sums while
also presenting a brief introduction of the underlying concepts.
Polynomiography establishes a different kind of appreciation of the
significance of polynomials in STEM, as well as in art. It helps in the
teaching of various topics at diverse levels. It also leads to new discoveries
on polynomials and inspires new applications. We also present a link for the
educator to get access to a demo polynomiography software together with a
module that helps teach basic topics to middle and high school students, as
well as undergraduates.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures, 27 color images</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09418</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FontCode: Embedding Information in Text Documents using Glyph
  Perturbation</dc:title>
 <dc:creator>Xiao, Chang</dc:creator>
 <dc:creator>Zhang, Cheng</dc:creator>
 <dc:creator>Zheng, Changxi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce FontCode, an information embedding technique for text documents.
Provided a text document with specific fonts, our method embeds user-specified
information in the text by perturbing the glyphs of text characters while
preserving the text content. We devise an algorithm to chooses unobtrusive yet
machine-recognizable glyph perturbations, leveraging a recently developed
generative model that alters the glyphs of each character continuously on a
font manifold. We then introduce an algorithm that embeds a user-provided
message in the text document and produces an encoded document whose appearance
is minimally perturbed from the original document. We also present a glyph
recognition method that recovers the embedded information from an encoded
document stored as a vector graphic or pixel image, or even on a printed paper.
In addition, we introduce a new error-correction coding scheme that rectifies a
certain number of recognition errors. Lastly, we demonstrate that our technique
enables a wide array of applications, using it as a text document metadata
holder, an unobtrusive optical barcode, a cryptographic message embedding
scheme, and a text document signature.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09418</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09422</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hyperprofile-based Computation Offloading for Mobile Edge Networks</dc:title>
 <dc:creator>Crutcher, Andrew</dc:creator>
 <dc:creator>Koch, Caleb</dc:creator>
 <dc:creator>Coleman, Kyle</dc:creator>
 <dc:creator>Patman, Jon</dc:creator>
 <dc:creator>Esposito, Flavio</dc:creator>
 <dc:creator>Calyam, Prasad</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In recent studies, researchers have developed various computation offloading
frameworks for bringing cloud services closer to the user via edge networks.
Specifically, an edge device needs to offload computationally intensive tasks
because of energy and processing constraints. These constraints present the
challenge of identifying which edge nodes should receive tasks to reduce
overall resource consumption. We propose a unique solution to this problem
which incorporates elements from Knowledge-Defined Networking (KDN) to make
intelligent predictions about offloading costs based on historical data. Each
server instance can be represented in a multidimensional feature space where
each dimension corresponds to a predicted metric. We compute features for a
&quot;hyperprofile&quot; and position nodes based on the predicted costs of offloading a
particular task. We then perform a k-Nearest Neighbor (kNN) query within the
hyperprofile to select nodes for offloading computation. This paper formalizes
our hyperprofile-based solution and explores the viability of using machine
learning (ML) techniques to predict metrics useful for computation offloading.
We also investigate the effects of using different distance metrics for the
queries. Our results show various network metrics can be modeled accurately
with regression, and there are circumstances where kNN queries using Euclidean
distance as opposed to rectilinear distance is more favorable.
</dc:description>
 <dc:description>Comment: 5 pages, NSF REU Site publication</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09422</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09423</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Relationship Detection with Internal and External Linguistic
  Knowledge Distillation</dc:title>
 <dc:creator>Yu, Ruichi</dc:creator>
 <dc:creator>Li, Ang</dc:creator>
 <dc:creator>Morariu, Vlad I.</dc:creator>
 <dc:creator>Davis, Larry S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Understanding visual relationships involves identifying the subject, the
object, and a predicate relating them. We leverage the strong correlations
between the predicate and the (subj,obj) pair (both semantically and spatially)
to predict the predicates conditioned on the subjects and the objects. Modeling
the three entities jointly more accurately reflects their relationships, but
complicates learning since the semantic space of visual relationships is huge
and the training data is limited, especially for the long-tail relationships
that have few instances. To overcome this, we use knowledge of linguistic
statistics to regularize visual model learning. We obtain linguistic knowledge
by mining from both training annotations (internal knowledge) and publicly
available text, e.g., Wikipedia (external knowledge), computing the conditional
probability distribution of a predicate given a (subj,obj) pair. Then, we
distill the knowledge into a deep model to achieve better generalization. Our
experimental results on the Visual Relationship Detection (VRD) and Visual
Genome datasets suggest that with this linguistic knowledge distillation, our
model outperforms the state-of-the-art methods significantly, especially when
predicting unseen relationships (e.g., recall improved from 8.45% to 19.17% on
VRD zero-shot testing set).
</dc:description>
 <dc:description>Comment: ICCV 2017</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09425</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings of the IJCAI 2017 Workshop on Learning in the Presence of
  Class Imbalance and Concept Drift (LPCICD'17)</dc:title>
 <dc:creator>Wang, Shuo</dc:creator>
 <dc:creator>Minku, Leandro L.</dc:creator>
 <dc:creator>Chawla, Nitesh</dc:creator>
 <dc:creator>Yao, Xin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  With the wide application of machine learning algorithms to the real world,
class imbalance and concept drift have become crucial learning issues. Class
imbalance happens when the data categories are not equally represented, i.e.,
at least one category is minority compared to other categories. It can cause
learning bias towards the majority class and poor generalization. Concept drift
is a change in the underlying distribution of the problem, and is a significant
issue specially when learning from data streams. It requires learners to be
adaptive to dynamic changes.
  Class imbalance and concept drift can significantly hinder predictive
performance, and the problem becomes particularly challenging when they occur
simultaneously. This challenge arises from the fact that one problem can affect
the treatment of the other. For example, drift detection algorithms based on
the traditional classification error may be sensitive to the imbalanced degree
and become less effective; and class imbalance techniques need to be adaptive
to changing imbalance rates, otherwise the class receiving the preferential
treatment may not be the correct minority class at the current moment.
Therefore, the mutual effect of class imbalance and concept drift should be
considered during algorithm design.
  The aim of this workshop is to bring together researchers from the areas of
class imbalance learning and concept drift in order to encourage discussions
and new collaborations on solving the combined issue of class imbalance and
concept drift. It provides a forum for international researchers and
practitioners to share and discuss their original work on addressing new
challenges and research issues in class imbalance learning, concept drift, and
the combined issues of class imbalance and concept drift. The proceedings
include 8 papers on these topics.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09428</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A unified method for super-resolution recovery and real exponential-sum
  separation</dc:title>
 <dc:creator>Chui, Charles K.</dc:creator>
 <dc:creator>Mhaskar, Hrushikesh N.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, motivated by diffraction of traveling light waves, a simple
mathematical model is proposed, both for the multivariate super-resolution
problem and the problem of blind-source separation of real-valued exponential
sums. This model facilitates the development of a unified theory and a unified
solution of both problems in this paper. Our consideration of the
super-resolution problem is aimed at applications to fluorescence microscopy
and observational astronomy, and the motivation for our consideration of the
second problem is the current need of extracting multivariate exponential
features in magnetic resonance spectroscopy (MRS) for the neurologist and
radiologist as well as for providing a mathematical tool for isotope separation
in Nuclear Chemistry. The unified method introduced in this paper can be easily
realized by processing only finitely many data, sampled at locations that are
not necessarily prescribed in advance, with computational scheme consisting
only of matrix - vector multiplication, peak finding, and clustering.
</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09428</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09430</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human in the Loop: Interactive Passive Automata Learning via
  Evidence-Driven State-Merging Algorithms</dc:title>
 <dc:creator>Hammerschmidt, Christian A.</dc:creator>
 <dc:creator>State, Radu</dc:creator>
 <dc:creator>Verwer, Sicco</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present an interactive version of an evidence-driven state-merging (EDSM)
algorithm for learning variants of finite state automata. Learning these
automata often amounts to recovering or reverse engineering the model
generating the data despite noisy, incomplete, or imperfectly sampled data
sources rather than optimizing a purely numeric target function. Domain
expertise and human knowledge about the target domain can guide this process,
and typically is captured in parameter settings. Often, domain expertise is
subconscious and not expressed explicitly. Directly interacting with the
learning algorithm makes it easier to utilize this knowledge effectively.
</dc:description>
 <dc:description>Comment: 4 pages, presented at the Human in the Loop workshop at ICML 2017</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09430</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09432</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generation of concept-representative symbols</dc:title>
 <dc:creator>Cunha, Jo&#xe3;o Miguel</dc:creator>
 <dc:creator>Martins, Pedro</dc:creator>
 <dc:creator>Cardoso, Am&#xed;lcar</dc:creator>
 <dc:creator>Machado, Penousal</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  The visual representation of concepts or ideas through the use of simple
shapes has always been explored in the history of Humanity, and it is believed
to be the origin of writing. We focus on computational generation of visual
symbols to represent concepts. We aim to develop a system that uses background
knowledge about the world to find connections among concepts, with the goal of
generating symbols for a given concept. We are also interested in exploring the
system as an approach to visual dissociation and visual conceptual blending.
This has a great potential in the area of Graphic Design as a tool to both
stimulate creativity and aid in brainstorming in projects such as logo,
pictogram or signage design.
</dc:description>
 <dc:description>Comment: cite as &quot;Cunha, J. M., Martins, P., Cardoso, A., &amp; Machado, P.
  (2015). Generation of Concept-Representative Symbols. In ICCBR (Workshops).&quot;,
  Computational creativity, Computational generation, Concept representation,
  Visual representation</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09432</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09440</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Refuting Feder, Kinne and Rafiey</dc:title>
 <dc:creator>Willard, Ross</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  I give an example showing that the recent claimed solution by Feder, Kinne
and Rafiey to the CSP Dichotomy Conjecture is not correct.
</dc:description>
 <dc:description>Comment: This note is in response to arXiv:1701.02409 versions (v1)-(v3) by T.
  Feder, J. Kinne, and A. Rafiey</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09440</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09441</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A compressive channel estimation technique robust to synchronization
  impairments</dc:title>
 <dc:creator>Myers, Nitin Jonathan</dc:creator>
 <dc:creator>Heath Jr, Robert W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Initial access at millimeter wave frequencies is a challenging problem due to
hardware non-idealities and low SNR measurements prior to beamforming. Prior
work has exploited the observation that mmWave MIMO channels are sparse in the
spatial angle domain and has used compressed sensing based algorithms for
channel estimation. Most of them, however, ignore hardware impairments like
carrier frequency offset and phase noise, and fail to perform well when such
impairments are considered. In this paper, we develop a compressive channel
estimation algorithm for narrowband mmWave systems, which is robust to such non
idealities. We address this problem by constructing a tensor that models both
the mmWave channel and CFO, and estimate the tensor while still exploiting the
sparsity of the mmWave channel. Simulation results show that under the same
settings, our method performs better than comparable algorithms that are robust
to phase errors.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, To appear in the proceedings of the 18th IEEE
  International Workshop on Signal Processing Advances in Wireless
  Communications</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09441</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09443</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bilingual Document Alignment with Latent Semantic Indexing</dc:title>
 <dc:creator>Germann, Ulrich</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We apply cross-lingual Latent Semantic Indexing to the Bilingual Document
Alignment Task at WMT16. Reduced-rank singular value decomposition of a
bilingual term-document matrix derived from known English/French page pairs in
the training data allows us to map monolingual documents into a joint semantic
space. Two variants of cosine similarity between the vectors that place each
document into the joint semantic space are combined with a measure of string
similarity between corresponding URLs to produce 1:1 alignments of
English/French web pages in a variety of domains. The system achieves a recall
of ca. 88% if no in-domain data is used for building the latent semantic model,
and 93% if such data is included.
  Analysing the system's errors on the training data, we argue that evaluating
aligner performance based on exact URL matches under-estimates their true
performance and propose an alternative that is able to account for duplicates
and near-duplicates in the underlying data.
</dc:description>
 <dc:description>Comment: Proceedings of the First Conference on Machine Translation (2016),
  Volume 2: Shared Task Papers</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09443</dc:identifier>
 <dc:identifier>doi:10.5281/zenodo.834343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09445</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint CFO and Channel Estimation in Millimeter Wave Systems with One-Bit
  ADCs</dc:title>
 <dc:creator>Myers, Nitin Jonathan</dc:creator>
 <dc:creator>Heath Jr, Robert W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We develop a method to jointly estimate the carrier frequency offset (CFO)
and the narrowband channel in millimeter wave (mmWave) MIMO systems operating
with one-bit analog-to-digital converters (ADCs). We assume perfect timing
synchronization and transform the underlying CFO-channel optimization problem
to a higher dimensional space using lifting techniques. Exploiting the sparsity
of mmWave MIMO channels in the angle domain, we perform joint estimation by
solving a noisy quantized compressed sensing problem of the lifted version,
using generalized approximate message passing. Simulation results show that our
method is able to recover both the channel and the CFO using one-bit
measurements.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures, submitted to the 7th IEEE International Workshop
  on Computational Advances in Multi-Sensor Adaptive Processing</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09445</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09448</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sentiment Analysis on Financial News Headlines using Training Dataset
  Augmentation</dc:title>
 <dc:creator>John, Vineet</dc:creator>
 <dc:creator>Vechtomova, Olga</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>68T50</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This paper discusses the approach taken by the UWaterloo team to arrive at a
solution for the Fine-Grained Sentiment Analysis problem posed by Task 5 of
SemEval 2017. The paper describes the document vectorization and sentiment
score prediction techniques used, as well as the design and implementation
decisions taken while building the system for this task. The system uses text
vectorization models, such as N-gram, TF-IDF and paragraph embeddings, coupled
with regression model variants to predict the sentiment scores. Amongst the
methods examined, unigrams and bigrams coupled with simple linear regression
obtained the best baseline accuracy. The paper also explores data augmentation
methods to supplement the training dataset. This system was designed for
Subtask 2 (News Statements and Headlines).
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09448</dc:identifier>
 <dc:identifier>Association for Computational Linguistics, Proceedings of the 11th
  International Workshop on Semantic Evaluation (SemEval-2017), 869-873</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09450</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Address Translation Design Tradeoffs for Heterogeneous Systems</dc:title>
 <dc:creator>Kim, Yunsung</dc:creator>
 <dc:creator>Cox, Guilherme</dc:creator>
 <dc:creator>Kim, Martha A.</dc:creator>
 <dc:creator>Bhattacharjee, Abhishek</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  This paper presents a broad, pathfinding design space exploration of memory
management units (MMUs) for heterogeneous systems. We consider a variety of
designs, ranging from accelerators tightly coupled with CPUs (and using their
MMUs) to fully independent accelerators that have their own MMUs. We find that
regardless of the CPU-accelerator communication, accelerators should not rely
on the CPU MMU for any aspect of address translation, and instead must have its
own, local, fully-fledged MMU. That MMU, however, can and should be as
application-specific as the accelerator itself, as our data indicates that even
a 100% hit rate in a small, standard L1 Translation Lookaside Buffer (TLB)
presents a substantial accelerator performance overhead. Furthermore, we
isolate the benefits of individual MMU components (e.g., TLBs versus page table
walkers) and discover that their relative performance, area, and energy are
workload dependent, with their interplay resulting in different area-optimal
and energy-optimal configurations.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09450</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09455</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Transfer Optimization Based on Offline Knowledge Discovery and
  Adaptive Real-time Sampling</dc:title>
 <dc:creator>Nine, MD S Q Zulkar</dc:creator>
 <dc:creator>Guner, Kemal</dc:creator>
 <dc:creator>Huang, Ziyun</dc:creator>
 <dc:creator>Wang, Xiangyu</dc:creator>
 <dc:creator>Xu, Jinhui</dc:creator>
 <dc:creator>Kosar, Tevfik</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The amount of data moved over dedicated and non-dedicated network links
increases much faster than the increase in the network capacity, but the
current solutions fail to guarantee even the promised achievable transfer
throughputs. In this paper, we propose a novel dynamic throughput optimization
model based on mathematical modeling with offline knowledge discovery/analysis
and adaptive online decision making. In offline analysis, we mine historical
transfer logs to perform knowledge discovery about the transfer
characteristics. Online phase uses the discovered knowledge from the offline
analysis along with real-time investigation of the network condition to
optimize the protocol parameters. As real-time investigation is expensive and
provides partial knowledge about the current network status, our model uses
historical knowledge about the network and data to reduce the real-time
investigation overhead while ensuring near optimal throughput for each
transfer. Our network and data agnostic solution is tested over different
networks and achieved up to 93% accuracy compared with the optimal achievable
throughput possible on those networks.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:date>2017-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09455</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09457</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Men Also Like Shopping: Reducing Gender Bias Amplification using
  Corpus-level Constraints</dc:title>
 <dc:creator>Zhao, Jieyu</dc:creator>
 <dc:creator>Wang, Tianlu</dc:creator>
 <dc:creator>Yatskar, Mark</dc:creator>
 <dc:creator>Ordonez, Vicente</dc:creator>
 <dc:creator>Chang, Kai-Wei</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Language is increasingly being used to define rich visual recognition
problems with supporting image collections sourced from the web. Structured
prediction models are used in these tasks to take advantage of correlations
between co-occurring labels and visual input but risk inadvertently encoding
social biases found in web corpora. In this work, we study data and models
associated with multilabel object classification and visual semantic role
labeling. We find that (a) datasets for these tasks contain significant gender
bias and (b) models trained on these datasets further amplify existing bias.
For example, the activity cooking is over 33% more likely to involve females
than males in a training set, and a trained model further amplifies the
disparity to 68% at test time. We propose to inject corpus-level constraints
for calibrating existing structured prediction models and design an algorithm
based on Lagrangian relaxation for collective inference. Our method results in
almost no performance loss for the underlying recognition task but decreases
the magnitude of bias amplification by 47.5% and 40.5% for multilabel
classification and visual semantic role labeling, respectively.
</dc:description>
 <dc:description>Comment: 11 pages, published in EMNLP 2017</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09457</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09465</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Curriculum Domain Adaptation for Semantic Segmentation of Urban Scenes</dc:title>
 <dc:creator>Zhang, Yang</dc:creator>
 <dc:creator>David, Philip</dc:creator>
 <dc:creator>Gong, Boqing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  During the last half decade, convolutional neural networks (CNNs) have
triumphed over semantic segmentation, which is a core task of various emerging
industrial applications such as autonomous driving and medical imaging.
However, to train CNNs requires a huge amount of data, which is difficult to
collect and laborious to annotate. Recent advances in computer graphics make it
possible to train CNN models on photo-realistic synthetic data with
computer-generated annotations. Despite this, the domain mismatch between the
real images and the synthetic data significantly decreases the models'
performance. Hence we propose a curriculum-style learning approach to minimize
the domain gap in semantic segmentation. The curriculum domain adaptation
solves easy tasks first in order to infer some necessary properties about the
target domain; in particular, the first task is to learn global label
distributions over images and local distributions over landmark superpixels.
These are easy to estimate because images of urban traffic scenes have strong
idiosyncrasies (e.g., the size and spatial relations of buildings, streets,
cars, etc.). We then train the segmentation network in such a way that the
network predictions in the target domain follow those inferred properties. In
experiments, our method significantly outperforms the baselines as well as the
only known existing approach to the same problem.
</dc:description>
 <dc:description>Comment: This is the extended version of the ICCV 2017 paper &quot;Curriculum
  Domain Adaptation for Semantic Segmentation of Urban Scenes&quot;</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09465</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09467</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Model Counting with Short XORs</dc:title>
 <dc:creator>Achlioptas, Dimitris</dc:creator>
 <dc:creator>Theodoropoulos, Panos</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:description>  The idea of counting the number of satisfying truth assignments (models) of a
formula by adding random parity constraints can be traced back to the seminal
work of Valiant and Vazirani, showing that NP is as easy as detecting unique
solutions. While theoretically sound, the random parity constraints in that
construction have the following drawback: each constraint, on average, involves
half of all variables. As a result, the branching factor associated with
searching for models that also satisfy the parity constraints quickly gets out
of hand. In this work we prove that one can work with much shorter parity
constraints and still get rigorous mathematical guarantees, especially when the
number of models is large so that many constraints need to be added. Our work
is based on the realization that the essential feature for random systems of
parity constraints to be useful in probabilistic model counting is that the
geometry of their set of solutions resembles an error-correcting code.
</dc:description>
 <dc:description>Comment: To appear in SAT 17</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09467</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09468</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zero-Shot Activity Recognition with Verb Attribute Induction</dc:title>
 <dc:creator>Zellers, Rowan</dc:creator>
 <dc:creator>Choi, Yejin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we investigate large-scale zero-shot activity recognition by
modeling the visual and linguistic attributes of action verbs. For example, the
verb &quot;salute&quot; has several properties, such as being a light movement, a social
act, and short in duration. We use these attributes as the internal mapping
between visual and textual representations to reason about a previously unseen
action. In contrast to much prior work that assumes access to gold standard
attributes for zero-shot classes and focuses primarily on object attributes,
our model uniquely learns to infer action attributes from dictionary
definitions and distributed word representations. Experimental results confirm
that action attributes inferred from language can provide a predictive signal
for zero-shot prediction of previously unseen activities.
</dc:description>
 <dc:description>Comment: accepted to EMNLP 2017</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:date>2017-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09468</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09472</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly-supervised learning of visual relations</dc:title>
 <dc:creator>Peyre, Julia</dc:creator>
 <dc:creator>Laptev, Ivan</dc:creator>
 <dc:creator>Schmid, Cordelia</dc:creator>
 <dc:creator>Sivic, Josef</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper introduces a novel approach for modeling visual relations between
pairs of objects. We call relation a triplet of the form (subject, predicate,
object) where the predicate is typically a preposition (eg. 'under', 'in front
of') or a verb ('hold', 'ride') that links a pair of objects (subject, object).
Learning such relations is challenging as the objects have different spatial
configurations and appearances depending on the relation in which they occur.
Another major challenge comes from the difficulty to get annotations,
especially at box-level, for all possible triplets, which makes both learning
and evaluation difficult. The contributions of this paper are threefold. First,
we design strong yet flexible visual features that encode the appearance and
spatial configuration for pairs of objects. Second, we propose a
weakly-supervised discriminative clustering model to learn relations from
image-level labels only. Third we introduce a new challenging dataset of
unusual relations (UnRel) together with an exhaustive annotation, that enables
accurate evaluation of visual relation retrieval. We show experimentally that
our model results in state-of-the-art results on the visual relationship
dataset significantly improving performance on previously unseen relations
(zero-shot learning), and confirm this observation on our newly introduced
UnRel dataset.
</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09476</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FCN-rLSTM: Deep Spatio-Temporal Neural Networks for Vehicle Counting in
  City Cameras</dc:title>
 <dc:creator>Zhang, Shanghang</dc:creator>
 <dc:creator>Wu, Guanhang</dc:creator>
 <dc:creator>Costeira, Jo&#xe3;o P.</dc:creator>
 <dc:creator>Moura, Jos&#xe9; M. F.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we develop deep spatio-temporal neural networks to
sequentially count vehicles from low quality videos captured by city cameras
(citycams). Citycam videos have low resolution, low frame rate, high occlusion
and large perspective, making most existing methods lose their efficacy. To
overcome limitations of existing methods and incorporate the temporal
information of traffic video, we design a novel FCN-rLSTM network to jointly
estimate vehicle density and vehicle count by connecting fully convolutional
neural networks (FCN) with long short term memory networks (LSTM) in a residual
learning fashion. Such design leverages the strengths of FCN for pixel-level
prediction and the strengths of LSTM for learning complex temporal dynamics.
The residual learning connection reformulates the vehicle count regression as
learning residual functions with reference to the sum of densities in each
frame, which significantly accelerates the training of networks. To preserve
feature map resolution, we propose a Hyper-Atrous combination to integrate
atrous convolution in FCN and combine feature maps of different convolution
layers. FCN-rLSTM enables refined feature representation and a novel end-to-end
trainable mapping from pixels to vehicle count. We extensively evaluated the
proposed method on different counting tasks with three datasets, with
experimental results demonstrating their effectiveness and robustness. In
particular, FCN-rLSTM reduces the mean absolute error (MAE) from 5.31 to 4.21
on TRANCOS, and reduces the MAE from 2.74 to 1.53 on WebCamT. Training process
is accelerated by 5 times on average.
</dc:description>
 <dc:description>Comment: Accepted by International Conference on Computer Vision (ICCV), 2017</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09482</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Feature Consistent Deep Image Transformations: Downscaling,
  Decolorization and HDR Tone Mapping</dc:title>
 <dc:creator>Hou, Xianxu</dc:creator>
 <dc:creator>Duan, Jiang</dc:creator>
 <dc:creator>Qiu, Guoping</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Building on crucial insights into the determining factors of the visual
integrity of an image and the property of deep convolutional neural network
(CNN), we have developed the Deep Feature Consistent Deep Image Transformation
(DFC-DIT) framework which unifies challenging one-to-many mapping image
processing problems such as image downscaling, decolorization (colour to
grayscale conversion) and high dynamic range (HDR) image tone mapping. We train
one CNN as a non-linear mapper to transform an input image to an output image
following what we term the deep feature consistency principle which is enforced
through another pretrained and fixed deep CNN. This is the first work that uses
deep learning to solve and unify these three common image processing tasks. We
present experimental results to demonstrate the effectiveness of the DFC-DIT
technique and its state of the art performances.
</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:date>2017-09-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09487</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Method and apparatus for automatic text input insertion in digital
  devices with a restricted number of keys</dc:title>
 <dc:creator>Tselios, Nikolaos</dc:creator>
 <dc:creator>Maragoudakis, Manolis</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  A device which contains number of symbol input keys, where the number of
available keys is less than the number of symbols of an alphabet of any given
language, screen, and dynamic reordering table of the symbols which are mapped
onto those keys, according to a disambiguation method based on the previously
entered symbols. The device incorporates a previously entered keystrokes
tracking mechanism, and the key selected by the user detector, as well as a
mechanism to select the dynamic symbol reordering mapped onto this key
according to the information contained to the reordering table. The reordering
table occurs from a disambiguation method which reorders the symbol appearance.
The reordering information occurs from Bayesian Belief network construction and
training from text corpora of the specific language.
</dc:description>
 <dc:description>Comment: European patent office</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09487</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09488</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cloud Computing - Architecture and Applications</dc:title>
 <dc:creator>Sen, Jaydip</dc:creator>
 <dc:creator>Zhao, Shanrong</dc:creator>
 <dc:creator>Wang, Xiaoying</dc:creator>
 <dc:creator>Zhang, Guojing</dc:creator>
 <dc:creator>Yang, Mengqin</dc:creator>
 <dc:creator>Wang, Jian</dc:creator>
 <dc:creator>Long, Yun</dc:creator>
 <dc:creator>Andreev, Sergey</dc:creator>
 <dc:creator>Florea, Roman</dc:creator>
 <dc:creator>Ometov, Aleksandr</dc:creator>
 <dc:creator>Surak, Adam</dc:creator>
 <dc:creator>Koucheryavy, Yevgeni</dc:creator>
 <dc:creator>Ashraf, Muhammad Ahmad</dc:creator>
 <dc:creator>Sethi, Waleed Tariq</dc:creator>
 <dc:creator>Alfakhri, Abdullah</dc:creator>
 <dc:creator>Alshebeili, Saleh</dc:creator>
 <dc:creator>Alasaad, Amr</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In the era of Internet of Things and with the explosive worldwide growth of
electronic data volume, and associated need of processing, analysis, and
storage of such humongous volume of data, it has now become mandatory to
exploit the power of massively parallel architecture for fast computation.
Cloud computing provides a cheap source of such computing framework for large
volume of data for real-time applications. It is, therefore, not surprising to
see that cloud computing has become a buzzword in the computing fraternity over
the last decade. This book presents some critical applications in cloud
frameworks along with some innovation design of algorithms and architecture for
deployment in cloud environment. It is a valuable source of knowledge for
researchers, engineers, practitioners, and graduate and doctoral students
working in the field of cloud computing. It will also be useful for faculty
members of graduate schools and universities.
</dc:description>
 <dc:description>Comment: Edited Volume published by Intech Publishers, Croatia, June 2017. 138
  pages. ISBN 978-953-51-3244-8, Print ISBN 978-953-51-3243-1. Link:
  https://www.intechopen.com/books/cloud-computing-architecture-and-applications</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09488</dc:identifier>
 <dc:identifier>doi:10.5772/62794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09489</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CitizenGrid: An Online Middleware for Crowdsourcing Scientific Research</dc:title>
 <dc:creator>Yadav, Poonam</dc:creator>
 <dc:creator>Cohen, Jeremy</dc:creator>
 <dc:creator>Darlington, John</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.4.3</dc:subject>
 <dc:description>  In the last few years, contributions of the general public in scientific
projects has increased due to the advancement of communication and computing
technologies. Internet played an important role in connecting scientists and
volunteers who are interested in participating in their scientific projects.
However, despite potential benefits, only a limited number of crowdsourcing
based large-scale science (citizen science) projects have been deployed due to
the complexity involved in setting them up and running them. In this paper, we
present CitizenGrid - an online middleware platform which addresses security
and deployment complexity issues by making use of cloud computing and
virtualisation technologies. CitizenGrid incentivises scientists to make their
small-to-medium scale applications available as citizen science projects by: 1)
providing a directory of projects through a web-based portal that makes
applications easy to discover; 2) providing flexibility to participate in,
monitor, and control multiple citizen science projects from a common interface;
3) supporting diverse categories of citizen science projects. The paper
describes the design, development and evaluation of CitizenGrid and its use
cases.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09491</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topology Analysis of International Networks Based on Debates in the
  United Nations</dc:title>
 <dc:creator>Gurciullo, Stefano</dc:creator>
 <dc:creator>Mikhaylov, Slava</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  In complex, high dimensional and unstructured data it is often difficult to
extract meaningful patterns. This is especially the case when dealing with
textual data. Recent studies in machine learning, information theory and
network science have developed several novel instruments to extract the
semantics of unstructured data, and harness it to build a network of relations.
Such approaches serve as an efficient tool for dimensionality reduction and
pattern detection. This paper applies semantic network science to extract
ideological proximity in the international arena, by focusing on the data from
General Debates in the UN General Assembly on the topics of high salience to
international community. UN General Debate corpus (UNGDC) covers all high-level
debates in the UN General Assembly from 1970 to 2014, covering all UN member
states. The research proceeds in three main steps. First, Latent Dirichlet
Allocation (LDA) is used to extract the topics of the UN speeches, and
therefore semantic information. Each country is then assigned a vector
specifying the exposure to each of the topics identified. This intermediate
output is then used in to construct a network of countries based on information
theoretical metrics where the links capture similar vectorial patterns in the
topic distributions. Topology of the networks is then analyzed through network
properties like density, path length and clustering. Finally, we identify
specific topological features of our networks using the map equation framework
to detect communities in our networks of countries.
</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09496</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local-ring network automata and the impact of hyperbolic geometry in
  complex network link-prediction</dc:title>
 <dc:creator>Muscoloni, Alessandro</dc:creator>
 <dc:creator>Cannistraci, Carlo Vittorio</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Topological link-prediction can exploit the entire network topology (global
methods) or only the neighbourhood (local methods) of the link to predict.
Global methods are believed the best. Is this common belief well-founded?
Stochastic-Block-Model (SBM) is a global method believed as one of the best
link-predictors, therefore it is considered a reference for comparison. But,
our results suggest that SBM, whose computational time is high, cannot in
general overcome the Cannistraci-Hebb (CH) network automaton model that is a
simple local-learning-rule of topological self-organization proved as the
current best local-based and parameter-free deterministic rule for
link-prediction. To elucidate the reasons of this unexpected result, we
formally introduce the notion of local-ring network automata models and their
relation with the nature of common-neighbours' definition in complex network
theory. After extensive tests, we recommend Structural-Perturbation-Method
(SPM) as the new best global method baseline. However, even SPM overall does
not outperform CH and in several evaluation frameworks we astonishingly found
the opposite. In particular, CH was the best predictor for synthetic networks
generated by the Popularity-Similarity-Optimization (PSO) model, and its
performance in PSO networks with community structure was even better than using
the original internode-hyperbolic-distance as link-predictor. Interestingly,
when tested on non-hyperbolic synthetic networks the performance of CH
significantly dropped down indicating that this rule of network
self-organization could be strongly associated to the rise of hyperbolic
geometry in complex networks. The superiority of global methods seems a
&quot;misleading belief&quot; caused by a latent geometry bias of the few small networks
used as benchmark in previous studies. We propose to found a latent geometry
theory of link-prediction in complex networks.
</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09504</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Expanding Visibility Polygons by Mirrors upto at least K units</dc:title>
 <dc:creator>Vaezi, Arash</dc:creator>
 <dc:creator>Roy, Bodhayan</dc:creator>
 <dc:creator>Ghodsi, Mohammad</dc:creator>
 <dc:creator>Maheshwari, Anil</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We consider extending visibility polygon $(VP)$ of a given point $q$
$(VP(q))$, inside a simple polygon $\P$ by converting some edges of $\P$ to
mirrors. We will show that several variations of the problem of finding
mirror-edges to add at least $k$ units of area to $VP(q)$ are NP-complete, or
NP-hard. Which $k$ is a given value.
  We deal with both single and multiple reflecting mirrors, and also specular
or diffuse types of reflections.
  In specular reflection, a single incoming direction is reflected into a
single outgoing direction. In this paper diffuse reflection is regarded as
reflecting lights at all possible angles from a given surface.
  The paper deals with finding mirror-edges to add \emph{at least} $k$ units of
area to $VP(q)$. In the case of specular type of reflections we only consider
single reflections, and the multiple case is still open.
  Specular case of the problem is more tricky. We construct a simple polygon
for every given instance of a 3-SAT problem. There are some specific spikes
which are visible only by some particular mirror-edges. Consequently, to have
minimum number of mirror-edges it is required to choose only one of these
mirrors to see a particular spike. There is a reduction polygon which contains
a clause-gadget corresponding to every clause, and a variable-gadget
corresponding to every variable.
  3-SAT formula has $n$ variables and $m$ clauses, so the minimum number of
mirrors required to add an area of at least $k$ to $V P(q)$ is $l = 3m+n+1$ if
and only if the 3-SAT formula is satisfiable.
  This reduction works in these two cases: adding at least $k$ vertex of $\P$
to $VP(q)$, and expanding $VP(q)$ at least $k$ units of area.
</dc:description>
 <dc:description>Comment: The writing is not well and I should rewrite the paper</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09504</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09520</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Orthogonal Recurrent Neural Networks with Scaled Cayley Transform</dc:title>
 <dc:creator>Helfrich, Kyle</dc:creator>
 <dc:creator>Willmott, Devin</dc:creator>
 <dc:creator>Ye, Qiang</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recurrent Neural Networks (RNNs) are designed to handle sequential data but
suffer from vanishing or exploding gradients. Recent work on Unitary Recurrent
Neural Networks (uRNNs) have been used to address this issue and in some cases,
exceed the capabilities of Long Short-Term Memory networks (LSTMs). We propose
a simpler and novel update scheme to maintain orthogonal recurrent weight
matrices without using complex valued matrices. This is done by parametrizing
with a skew-symmetric matrix using the Cayley transform. Such a parametrization
is unable to represent matrices with negative one eigenvalues, but this
limitation is overcome by scaling the recurrent weight matrix by a diagonal
matrix consisting of ones and negative ones. The proposed training scheme
involves a straightforward gradient calculation and update step. In several
experiments, the proposed scaled Cayley orthogonal recurrent neural network
(scoRNN) achieves superior results with fewer trainable parameters than other
unitary RNNs.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09526</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Advances in Security in Computing and Communications</dc:title>
 <dc:creator>Sen, Jaydip</dc:creator>
 <dc:creator>Franco-Contreras, Javier</dc:creator>
 <dc:creator>Coatrieux, Gouenou</dc:creator>
 <dc:creator>Sangani, Nilay K</dc:creator>
 <dc:creator>Zarger, Haroot</dc:creator>
 <dc:creator>Jaidi, Faouzi</dc:creator>
 <dc:creator>Duncan, Bob</dc:creator>
 <dc:creator>Bratterud, Alfred</dc:creator>
 <dc:creator>Happe, Andreas</dc:creator>
 <dc:creator>Lin, Chin-Feng</dc:creator>
 <dc:creator>Liu, Che-Wei</dc:creator>
 <dc:creator>Elgeanidi, Walid</dc:creator>
 <dc:creator>Fraifer, Muftah</dc:creator>
 <dc:creator>Newe, Thomas</dc:creator>
 <dc:creator>OConnell, Eoin</dc:creator>
 <dc:creator>Mathur, Avijit</dc:creator>
 <dc:creator>Zhang, Ruolin</dc:creator>
 <dc:creator>Filiol, Eric</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In the era of Internet of Things (IoT) and with the explosive worldwide
growth of electronic data volume, and associated need of processing, analysis,
and storage of such humongous volume of data, several new challenges are faced
in protect-ing privacy of sensitive data and securing systems by designing
novel schemes for secure authentication, integrity protection, encryption, and
non-repudiation. Lightweight symmetric key cryptography and adaptive network
security algo-rithms are in demand for mitigating these challenges. This book
presents some of the state-of-the-art research work in the field of
cryptography and security in computing and communications. It is a valuable
source of knowledge for re-searchers, engineers, practitioners, graduates, and
doctoral students who are working in the field of cryptography, network
security, and security and privacy issues in the Internet of Things (IoT). It
will also be useful for faculty members of graduate schools and universities.
</dc:description>
 <dc:description>Comment: 190 pages, 8 Chapters. Published by Intech Open Publishers, Croatia,
  July 2017</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09526</dc:identifier>
 <dc:identifier>doi:10.5772/65228</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09531</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Scale Approximation for Object Detection in CNN</dc:title>
 <dc:creator>Liu, Yu</dc:creator>
 <dc:creator>Li, Hongyang</dc:creator>
 <dc:creator>Yan, Junjie</dc:creator>
 <dc:creator>Wei, Fangyin</dc:creator>
 <dc:creator>Wang, Xiaogang</dc:creator>
 <dc:creator>Tang, Xiaoou</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Since convolutional neural network (CNN) lacks an inherent mechanism to
handle large scale variations, we always need to compute feature maps multiple
times for multi-scale object detection, which has the bottleneck of
computational cost in practice. To address this, we devise a recurrent scale
approximation (RSA) to compute feature map once only, and only through this map
can we approximate the rest maps on other levels. At the core of RSA is the
recursive rolling out mechanism: given an initial map on a particular scale, it
generates the prediction on a smaller scale that is half the size of input. To
further increase efficiency and accuracy, we (a): design a scale-forecast
network to globally predict potential scales in the image since there is no
need to compute maps on all levels of the pyramid. (b): propose a landmark
retracing network (LRN) to retrace back locations of the regressed landmarks
and generate a confidence score for each landmark; LRN can effectively
alleviate false positives due to the accumulated error in RSA. The whole system
could be trained end-to-end in a unified CNN framework. Experiments demonstrate
that our proposed algorithm is superior against state-of-the-arts on face
detection benchmarks and achieves comparable results for generic proposal
generation. The source code of RSA is available at
github.com/sciencefans/RSA-for-object-detection.
</dc:description>
 <dc:description>Comment: Accepted in ICCV 2017</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09531</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09533</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Curriculum Learning and Minibatch Bucketing in Neural Machine
  Translation</dc:title>
 <dc:creator>Kocmi, Tom</dc:creator>
 <dc:creator>Bojar, Ondrej</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We examine the effects of particular orderings of sentence pairs on the
on-line training of neural machine translation (NMT). We focus on two types of
such orderings: (1) ensuring that each minibatch contains sentences similar in
some aspect and (2) gradual inclusion of some sentence types as the training
progresses (so called &quot;curriculum learning&quot;). In our English-to-Czech
experiments, the internal homogeneity of minibatches has no effect on the
training but some of our &quot;curricula&quot; achieve a small improvement over the
baseline.
</dc:description>
 <dc:description>Comment: Accepted to RANLP 2017</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09533</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09538</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Benchmarking Multimodal Sentiment Analysis</dc:title>
 <dc:creator>Cambria, Erik</dc:creator>
 <dc:creator>Hazarika, Devamanyu</dc:creator>
 <dc:creator>Poria, Soujanya</dc:creator>
 <dc:creator>Hussain, Amir</dc:creator>
 <dc:creator>Subramaanyam, R. B. V.</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We propose a framework for multimodal sentiment analysis and emotion
recognition using convolutional neural network-based feature extraction from
text and visual modalities. We obtain a performance improvement of 10% over the
state of the art by combining visual, text and audio features. We also discuss
some major issues frequently ignored in multimodal sentiment analysis research:
the role of speaker-independent models, importance of the modalities and
generalizability. The paper thus serve as a new benchmark for further research
in multimodal sentiment analysis and also demonstrates the different facets of
analysis to be considered while performing such tasks.
</dc:description>
 <dc:description>Comment: Accepted in CICLing 2017</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09543</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthetic Database for Evaluation of General, Fundamental Biometric
  Principles</dc:title>
 <dc:creator>Friedman, Lee</dc:creator>
 <dc:creator>Komogortsev, Oleg</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We create synthetic biometric databases to study general, fundamental,
biometric principles. First, we check the validity of the synthetic database
design by comparing it to real data in terms of biometric performance. The real
data used for this validity check was from an eye-movement related biometric
database. Next, we employ our database to evaluate the impact of variations of
temporal persistence of features on biometric performance. We index temporal
persistence with the intraclass correlation coefficient (ICC). We find that
variations in temporal persistence are extremely highly correlated with
variations in biometric performance. Finally, we use our synthetic database
strategy to determine how many features are required to achieve particular
levels of performance as the number of subjects in the database increases from
100 to 10,000. An important finding is that the number of features required to
achieve various EER values (2%, 0.3%, 0.15%) is essentially constant in the
database sizes that we studied. We hypothesize that the insights obtained from
our study would be applicable to many biometric modalities where extracted
feature properties resemble the properties of the synthetic features we discuss
in this work.
</dc:description>
 <dc:description>Comment: 8 pages, 8 figures</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09543</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09545</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Balanced Stable Marriage: How Close is Close Enough?</dc:title>
 <dc:creator>Gupta, Sushmita</dc:creator>
 <dc:creator>Roy, Sanjukta</dc:creator>
 <dc:creator>Saurabh, Saket</dc:creator>
 <dc:creator>Zehavi, Meirav</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The Balanced Stable Marriage problem is a central optimization version of the
classic Stable Marriage problem. Here, the output cannot be an arbitrary stable
matching, but one that balances between the dissatisfaction of the two parties,
men and women. We study Balanced Stable Marriage from the viewpoint of
Parameterized Complexity. Our &quot;above guarantee parameterizations&quot; are arguably
the most natural parameterizations of the problem at hand. Indeed, our
parameterizations precisely fit the scenario where there exists a stable
marriage that both parties would accept, that is, where the satisfaction of
each party is &quot;close&quot; to the best it can hope for. Furthermore, our
parameterizations accurately draw the line between tractability and
intractability with respect to the target value.
</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09545</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09553</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extreme Quantum Advantage for Rare-Event Sampling</dc:title>
 <dc:creator>Aghamohammadi, C.</dc:creator>
 <dc:creator>Loomis, S. P.</dc:creator>
 <dc:creator>Mahoney, J. R.</dc:creator>
 <dc:creator>Crutchfield, J. P.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We introduce a quantum algorithm for efficient biased sampling of the rare
events generated by classical memoryful stochastic processes. We show that this
quantum algorithm gives an extreme advantage over known classical biased
sampling algorithms in terms of the memory resources required. The quantum
memory advantage ranges from polynomial to exponential and when sampling the
rare equilibrium configurations of spin systems the quantum advantage diverges.
</dc:description>
 <dc:description>Comment: 11 pages, 9 figures;
  http://csc.ucdavis.edu/~cmg/compmech/pubs/eqafbs.htm</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09553</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09557</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Adversarial Systems for 3D Object Generation and Reconstruction</dc:title>
 <dc:creator>Smith, Edward</dc:creator>
 <dc:creator>Meger, David</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper describes a new approach for training generative adversarial
networks (GAN) to understand the detailed 3D shape of objects. While GANs have
been used in this domain previously, they are notoriously hard to train,
especially for the complex joint data distribution over 3D objects of many
categories and orientations. Our method extends previous work by employing the
Wasserstein distance normalized with gradient penalization as a training
objective. This enables improved generation from the joint object shape
distribution. Our system can also reconstruct 3D shape from 2D images and
perform shape completion from occluded 2.5D range scans. We achieve notable
quantitative improvements in comparison to existing baselines
</dc:description>
 <dc:description>Comment: 10 pages, accepted at CORL. Figures are best view in color, and
  details only appear when zoomed in</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09558</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lessons learnt from the NetIDE project: Taking SDN programming to the
  next level</dc:title>
 <dc:creator>Gutierrez, Pedro A. Aranda</dc:creator>
 <dc:creator>Doriguzzi-Corin, Roberto</dc:creator>
 <dc:creator>Rojas, Elisa</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:description>  SDN promises to overcome vendor lock-in by enabling a multi-vendor hardware
and software ecosystem in operator networks. However, we observe that this is
currently not happening. A framework allowing to compose SDN applications
combining different frameworks can help revert the trend. In this paper, we
analyze the challenges in the current SDN landscape and then present the
multi-controller SDN framework developed by the NetIDE project. Our
architecture supports different SDN southbound protocols and we have
implemented a proof of concept using the OpenFlow protocol, which has given us
a greater insight on its shortcomings.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09562</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MLBench: How Good Are Machine Learning Clouds for Binary Classification
  Tasks on Structured Data?</dc:title>
 <dc:creator>Liu, Yu</dc:creator>
 <dc:creator>Zhang, Hantian</dc:creator>
 <dc:creator>Zeng, Luyuan</dc:creator>
 <dc:creator>Wu, Wentao</dc:creator>
 <dc:creator>Zhang, Ce</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We conduct an empirical study of machine learning functionalities provided by
major cloud service providers, which we call machine learning clouds. Machine
learning clouds hold the promise of hiding all the sophistication of running
large-scale machine learning: Instead of specifying how to run a machine
learning task, users only specify what machine learning task to run and the
cloud figures out the rest. Raising the level of abstraction, however, rarely
comes free - a performance penalty is possible. How good, then, are current
machine learning clouds on real-world machine learning workloads?
  We study this question with a focus on binary classication problems. We
present mlbench, a novel benchmark constructed by harvesting datasets from
Kaggle competitions. We then compare the performance of the top winning code
available from Kaggle with that of running machine learning clouds from both
Azure and Amazon on mlbench. Our comparative study reveals the strength and
weakness of existing machine learning clouds and points out potential future
directions for improvement.
</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:date>2017-10-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09562</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09564</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for
  Neural Networks</dc:title>
 <dc:creator>Neyshabur, Behnam</dc:creator>
 <dc:creator>Bhojanapalli, Srinadh</dc:creator>
 <dc:creator>McAllester, David</dc:creator>
 <dc:creator>Srebro, Nathan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a generalization bound for feedforward neural networks in terms of
the product of the spectral norm of the layers and the Frobenius norm of the
weights. The generalization bound is derived using a PAC-Bayes analysis.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09566</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A collaborative citizen science platform for real-time volunteer
  computing and games</dc:title>
 <dc:creator>Yadav, Poonam</dc:creator>
 <dc:creator>Charalampidis, Ioannis</dc:creator>
 <dc:creator>Cohen, Jeremy</dc:creator>
 <dc:creator>Darlington, John</dc:creator>
 <dc:creator>Grey, Francois</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Volunteer computing (VC) or distributed computing projects are common in the
citizen cyberscience (CCS) community and present extensive opportunities for
scientists to make use of computing power donated by volunteers to undertake
large-scale scientific computing tasks. Volunteer computing is generally a
non-interactive process for those contributing computing resources to a project
whereas volunteer thinking (VT) or distributed thinking, which allows
volunteers to participate interactively in citizen cyberscience projects to
solve human computation tasks. In this paper we describe the integration of
three tools, the Virtual Atom Smasher (VAS) game developed by CERN, LiveQ, a
job distribution middleware, and CitizenGrid, an online platform for hosting
and providing computation to CCS projects. This integration demonstrates the
combining of volunteer computing and volunteer thinking to help address the
scientific and educational goals of games like VAS. The paper introduces the
three tools and provides details of the integration process along with further
potential usage scenarios for the resulting platform.
</dc:description>
 <dc:description>Comment: 12 pages, 13 figures</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09567</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Successive Refinement of Abstract Sources</dc:title>
 <dc:creator>Kostina, Victoria</dc:creator>
 <dc:creator>Tuncel, Ertem</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In successive refinement of information, the decoder refines its
representation of the source progressively as it receives more encoded bits.
The rate-distortion region of successive refinement describes the minimum rates
required to attain the target distortions at each decoding stage. In this
paper, we derive a parametric characterization of the rate-distortion region
for successive refinement of abstract sources. Our characterization extends
Csisz\'ar's result to successive refinement, and generalizes a result by Tuncel
and Rose, applicable for finite alphabet sources, to abstract sources. This
characterization spawns a family of outer bounds to the rate-distortion region.
It also enables an iterative algorithm for computing the rate-distortion
region, which generalizes Blahut's algorithm to successive refinement. Finally,
it leads a new nonasymptotic converse bound. In all the scenarios where the
dispersion is known, this bound is second-order optimal.
  In our proof technique, we avoid Karush-Kuhn-Tucker conditions of optimality,
and we use basic tools of probability theory. We leverage the Donsker-Varadhan
lemma for the minimization of relative entropy on abstract probability spaces.
</dc:description>
 <dc:description>Comment: Extended version of a paper presented at ISIT 2017</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09569</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Language Representations for Typology Prediction</dc:title>
 <dc:creator>Malaviya, Chaitanya</dc:creator>
 <dc:creator>Neubig, Graham</dc:creator>
 <dc:creator>Littell, Patrick</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  One central mystery of neural NLP is what neural models &quot;know&quot; about their
subject matter. When a neural machine translation system learns to translate
from one language to another, does it learn the syntax or semantics of the
languages? Can this knowledge be extracted from the system to fill holes in
human scientific knowledge? Existing typological databases contain relatively
full feature specifications for only a few hundred languages. Exploiting the
existence of parallel texts in more than a thousand languages, we build a
massive many-to-one neural machine translation (NMT) system from 1017 languages
into English, and use this to predict information missing from typological
databases. Experiments show that the proposed method is able to infer not only
syntactic, but also phonological and phonetic inventory features, and improves
over a baseline that has access to information about the languages' geographic
and phylogenetic neighbors.
</dc:description>
 <dc:description>Comment: EMNLP 2017</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09570</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mapping the Curricular Structure and Contents of Network Science Courses</dc:title>
 <dc:creator>Sayama, Hiroki</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  As network science has matured as an established field of research, there are
already a number of courses on this topic developed and offered at various
higher education institutions, often at postgraduate levels. In those courses,
instructors adopted different approaches with different focus areas and
curricular designs. We collected information about 30 existing network science
courses from various online sources, and analyzed the contents of their syllabi
or course schedules. The topics and their curricular sequences were extracted
from the course syllabi/schedules and represented as a directed weighted graph,
which we call the topic network. Community detection in the topic network
revealed seven topic clusters, which matched reasonably with the concept list
previously generated by students and educators through the Network Literacy
initiative. The minimum spanning tree of the topic network revealed typical
flows of curricular contents, starting with examples of networks, moving onto
random networks and small-world networks, then branching off to various
subtopics from there. These results illustrate the current state of consensus
formation (including variations and disagreements) among the network science
community on what should be taught about networks and how, which may also be
informative for K--12 education and informal education.
</dc:description>
 <dc:description>Comment: 17 pages, 11 figures, 2 tables; to appear in Cramer, C. et al.
  (eds.), Network Science in Education -- Tools and Techniques for Transforming
  Teaching and Learning (Springer, 2017, in press)</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:date>2017-10-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09570</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09571</identifier>
 <datestamp>2017-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Potential Molecular Dynamics: a scalable model with the accuracy of
  quantum mechanics</dc:title>
 <dc:creator>Zhang, Linfeng</dc:creator>
 <dc:creator>Han, Jiequn</dc:creator>
 <dc:creator>Wang, Han</dc:creator>
 <dc:creator>Car, Roberto</dc:creator>
 <dc:creator>E, Weinan</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:description>  We introduce a scheme for molecular simulations, the Deep Potential Molecular
Dynamics (DeePMD) method, based on a many-body potential and interatomic forces
generated by a carefully crafted deep neural network trained with ab initio
data. The neural network model preserves all the natural symmetries in the
problem. It is &quot;first principle-based&quot; in the sense that there are no ad hoc
components aside from the network model. We show that the proposed scheme
provides an efficient and accurate protocol in a variety of systems, including
bulk materials and molecules. In all these cases, DeePMD gives results that are
essentially indistinguishable from the original data, at a cost that scales
linearly with system size.
</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:date>2017-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09585</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Virtual PET Images from CT Data Using Deep Convolutional Networks:
  Initial Results</dc:title>
 <dc:creator>Ben-Cohen, Avi</dc:creator>
 <dc:creator>Klang, Eyal</dc:creator>
 <dc:creator>Raskin, Stephen P.</dc:creator>
 <dc:creator>Amitai, Michal Marianne</dc:creator>
 <dc:creator>Greenspan, Hayit</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this work we present a novel system for PET estimation using CT scans. We
explore the use of fully convolutional networks (FCN) and conditional
generative adversarial networks (GAN) to export PET data from CT data. Our
dataset includes 25 pairs of PET and CT scans where 17 were used for training
and 8 for testing. The system was tested for detection of malignant tumors in
the liver region. Initial results look promising showing high detection
performance with a TPR of 92.3% and FPR of 0.25 per case. Future work entails
expansion of the current system to the entire body using a much larger dataset.
Such a system can be used for tumor detection and drug treatment evaluation in
a CT-only environment instead of the expansive and radioactive PET-CT scan.
</dc:description>
 <dc:description>Comment: To be presented at SASHIMI2017: Simulation and Synthesis in Medical
  Imaging, MICCAI 2017</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09592</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary Hypothesis Testing with Byzantine Sensors: Fundamental Trade-off
  Between Security and Efficiency</dc:title>
 <dc:creator>Ren, Xiaoqiang</dc:creator>
 <dc:creator>Yan, Jiaqi</dc:creator>
 <dc:creator>Mo, Yilin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  This paper studies binary hypothesis testing based on measurements from a set
of sensors, a subset of which can be compromised by an attacker. The
measurements from a compromised sensor can be manipulated arbitrarily by the
adversary. The asymptotic exponential rate, with which the probability of error
goes to zero, is adopted to indicate the detection performance of a detector.
In practice, we expect the attack on sensors to be sporadic, and therefore the
system may operate with all the sensors being benign for extended period of
time. This motivates us to consider the trade-off between the detection
performance of a detector, i.e., the probability of error, when the attacker is
absent (defined as efficiency) and the worst-case detection performance when
the attacker is present (defined as security). We first provide the fundamental
limits of this trade-off, and then propose a detection strategy that achieves
these limits. We then consider a special case, where there is no trade-off
between security and efficiency. In other words, our detection strategy can
achieve the maximal efficiency and the maximal security simultaneously. Two
extensions of the secure hypothesis testing problem are also studied and
fundamental limits and achievability results are provided: 1) a subset of
sensors, namely &quot;secure&quot; sensors, are assumed to be equipped with better
security countermeasures and hence are guaranteed to be benign, 2) detection
performance with unknown number of compromised sensors. Numerical examples are
given to illustrate the main results.
</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09592</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2788420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09593</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discover and Learn New Objects from Documentaries</dc:title>
 <dc:creator>Chen, Kai</dc:creator>
 <dc:creator>Song, Hang</dc:creator>
 <dc:creator>Loy, Chen Change</dc:creator>
 <dc:creator>Lin, Dahua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Despite the remarkable progress in recent years, detecting objects in a new
context remains a challenging task. Detectors learned from a public dataset can
only work with a fixed list of categories, while training from scratch usually
requires a large amount of training data with detailed annotations. This work
aims to explore a novel approach -- learning object detectors from documentary
films in a weakly supervised manner. This is inspired by the observation that
documentaries often provide dedicated exposition of certain object categories,
where visual presentations are aligned with subtitles. We believe that object
detectors can be learned from such a rich source of information. Towards this
goal, we develop a joint probabilistic framework, where individual pieces of
information, including video frames and subtitles, are brought together via
both visual and linguistic links. On top of this formulation, we further derive
a weakly supervised learning algorithm, where object model learning and
training set mining are unified in an optimization procedure. Experimental
results on a real world dataset demonstrate that this is an effective approach
to learning new object detectors.
</dc:description>
 <dc:description>Comment: Published on CVPR 2017 (spotlight)</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09593</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09597</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ScanNet: A Fast and Dense Scanning Framework for Metastatic Breast
  Cancer Detection from Whole-Slide Images</dc:title>
 <dc:creator>Lin, Huangjing</dc:creator>
 <dc:creator>Chen, Hao</dc:creator>
 <dc:creator>Dou, Qi</dc:creator>
 <dc:creator>Wang, Liansheng</dc:creator>
 <dc:creator>Qin, Jing</dc:creator>
 <dc:creator>Heng, Pheng-Ann</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Lymph node metastasis is one of the most significant diagnostic indicators in
breast cancer, which is traditionally observed under the microscope by
pathologists. In recent years, computerized histology diagnosis has become one
of the most rapidly expanding fields in medical image computing, which
alleviates pathologists' workload and reduces misdiagnosis rate. However,
automatic detection of lymph node metastases from whole slide images remains a
challenging problem, due to the large-scale data with enormous resolutions and
existence of hard mimics. In this paper, we propose a novel framework by
leveraging fully convolutional networks for efficient inference to meet the
speed requirement for clinical practice, while reconstructing dense predictions
under different offsets for ensuring accurate detection on both micro- and
macro-metastases. Incorporating with the strategies of asynchronous sample
prefetching and hard negative mining, the network can be effectively trained.
Extensive experiments on the benchmark dataset of 2016 Camelyon Grand Challenge
corroborated the efficacy of our method. Compared with the state-of-the-art
methods, our method achieved superior performance with a faster speed on the
tumor localization task and surpassed human performance on the WSI
classification task.
</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09597</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09599</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dimensional Affect and Expression in Natural and Mediated Interaction</dc:title>
 <dc:creator>Lyons, Michael J.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.1.2</dc:subject>
 <dc:description>  There is a perceived controversy as to whether the cognitive representation
of affect is better modelled using a dimensional or categorical theory. This
paper first suggests that these views are, in fact, compatible. The paper then
discusses this theme and related issues in reference to a commonly stated
application domain of research on human affect and expression: human computer
interaction (HCI). The novel suggestion here is that a more realistic framing
of studies of human affect in expression with reference to HCI and,
particularly HCHI (Human-Computer-Human Interaction) entails some
re-formulation of the approach to the basic phenomena themselves. This theme is
illustrated with several examples from several recent research projects.
</dc:description>
 <dc:description>Comment: Invited article presented at the 23rd Annual Meeting of the
  International Society for Psychophysics, Tokyo, Japan, 20-23 October, 2007,
  Proceedings of Fechner Day vol. 23 (2007)</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09599</dc:identifier>
 <dc:identifier>doi:10.6084/m9.figshare.5258983</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09602</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust stability conditions for feedback interconnections of
  distributed-parameter negative imaginary systems</dc:title>
 <dc:creator>Khong, Sei Zhen</dc:creator>
 <dc:creator>Petersen, Ian R.</dc:creator>
 <dc:creator>Rantzer, Anders</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Sufficient and necessary conditions for the stability of positive feedback
interconnections of negative imaginary systems are derived via an integral
quadratic constraint (IQC) approach. The IQC framework accommodates
distributed-parameter systems with irrational transfer function
representations, while generalising existing results in the literature and
allowing exploitation of flexibility at zero and infinite frequencies to reduce
conservatism in the analysis. The main results manifest the important property
that the negative imaginariness of systems gives rise to a certain form of IQCs
on positive frequencies that are bounded away from zero and infinity. Two
additional sets of IQCs on the DC and instantaneous gains of the systems are
shown to be sufficient and necessary for closed-loop stability along a homotopy
of systems.
</dc:description>
 <dc:description>Comment: Submitted to Automatica, A preliminary version of this paper appeared
  in the Proceedings of the 2015 European Control Conference</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09602</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09603</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Occlusion Handling using Semantic Segmentation and Visibility-Based
  Rendering for Mixed Reality</dc:title>
 <dc:creator>Roxas, Menandro</dc:creator>
 <dc:creator>Hori, Tomoki</dc:creator>
 <dc:creator>Fukiage, Taiki</dc:creator>
 <dc:creator>Okamoto, Yasuhide</dc:creator>
 <dc:creator>Oishi, Takeshi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Real-time occlusion handling is a major problem in outdoor mixed reality
system because it requires great computational cost mainly due to the
complexity of the scene. Using only segmentation, it is difficult to accurately
render a virtual object occluded by complex objects such as trees, bushes etc.
In this paper, we propose a novel occlusion handling method for real-time,
outdoor, and omni-directional mixed reality system using only the information
from a monocular image sequence. We first present a semantic segmentation
scheme for predicting the amount of visibility for different type of objects in
the scene. We also simultaneously calculate a foreground probability map using
depth estimation derived from optical flow. Finally, we combine the
segmentation result and the probability map to render the computer generated
object and the real scene using a visibility-based rendering method. Our
results show great improvement in handling occlusions compared to existing
blending based methods.
</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09605</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CNN-based Cascaded Multi-task Learning of High-level Prior and Density
  Estimation for Crowd Counting</dc:title>
 <dc:creator>Sindagi, Vishwanath A.</dc:creator>
 <dc:creator>Patel, Vishal M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Estimating crowd count in densely crowded scenes is an extremely challenging
task due to non-uniform scale variations. In this paper, we propose a novel
end-to-end cascaded network of CNNs to jointly learn crowd count classification
and density map estimation. Classifying crowd count into various groups is
tantamount to coarsely estimating the total count in the image thereby
incorporating a high-level prior into the density estimation network. This
enables the layers in the network to learn globally relevant discriminative
features which aid in estimating highly refined density maps with lower count
error. The joint training is performed in an end-to-end fashion. Extensive
experiments on highly challenging publicly available datasets show that the
proposed method achieves lower count error and better quality density maps as
compared to the recent state-of-the-art methods.
</dc:description>
 <dc:description>Comment: Accepted at AVSS 2017 (14th International Conference on Advanced
  Video and Signal Based Surveillance)</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09605</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09611</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Named Entity Recognition and Stance Detection in Tweets</dc:title>
 <dc:creator>K&#xfc;&#xe7;&#xfc;k, Dilek</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Named entity recognition (NER) is a well-established task of information
extraction which has been studied for decades. More recently, studies reporting
NER experiments on social media texts have emerged. On the other hand, stance
detection is a considerably new research topic usually considered within the
scope of sentiment analysis. Stance detection studies are mostly applied to
texts of online debates where the stance of the text owner for a particular
target, either explicitly or implicitly mentioned in text, is explored. In this
study, we investigate the possible contribution of named entities to the stance
detection task in tweets. We report the evaluation results of NER experiments
as well as that of the subsequent stance detection experiments using named
entities, on a publicly-available stance-annotated data set of tweets. Our
results indicate that named entities obtained with a high-performance NER
system can contribute to stance detection performance on tweets.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09611</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09613</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Vector Recovery: Bernoulli-Gaussian Message Passing</dc:title>
 <dc:creator>Liu, Lei</dc:creator>
 <dc:creator>Huang, Chongwen</dc:creator>
 <dc:creator>Chi, Yuhao</dc:creator>
 <dc:creator>Yuen, Chau</dc:creator>
 <dc:creator>Guan, Yong Liang</dc:creator>
 <dc:creator>Li, Ying</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Low-cost message passing (MP) algorithm has been recognized as a promising
technique for sparse vector recovery. However, the existing MP algorithms
either focus on mean square error (MSE) of the value recovery while ignoring
the sparsity requirement, or support error rate (SER) of the sparse support
(non-zero position) recovery while ignoring its value. A novel low-complexity
Bernoulli-Gaussian MP (BGMP) is proposed to perform the value recovery as well
as the support recovery. Particularly, in the proposed BGMP, support-related
Bernoulli messages and value-related Gaussian messages are jointly processed
and assist each other. In addition, a strict lower bound is developed for the
MSE of BGMP via the genie-aided minimum mean-square-error (GA-MMSE) method. The
GA-MMSE lower bound is shown to be tight in high signal-to-noise ratio.
Numerical results are provided to verify the advantage of BGMP in terms of
final MSE, SER and convergence speed.
</dc:description>
 <dc:description>Comment: Conference, 6 pages, 7 figures, accepted by IEEE Globecom 2017</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09616</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Owl: A General-Purpose Numerical Library in OCaml</dc:title>
 <dc:creator>Wang, Liang</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Owl is a new numerical library developed in the OCaml language. It focuses on
providing a comprehensive set of high-level numerical functions so that
developers can quickly build up data analytical applications. In this abstract,
we will present Owl's design, core components, and its key functionality.
</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:date>2017-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09616</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09627</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Infer Graphics Programs from Hand-Drawn Images</dc:title>
 <dc:creator>Ellis, Kevin</dc:creator>
 <dc:creator>Ritchie, Daniel</dc:creator>
 <dc:creator>Solar-Lezama, Armando</dc:creator>
 <dc:creator>Tenenbaum, Joshua B.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>68T05</dc:subject>
 <dc:description>  We introduce a model that learns to convert simple hand drawings into
graphics programs written in a subset of \LaTeX. The model combines techniques
from deep learning and program synthesis. We learn a convolutional neural
network that proposes plausible drawing primitives that explain an image. These
drawing primitives are like a trace of the set of primitive commands issued by
a graphics program. We learn a model that uses program synthesis techniques to
recover a graphics program from that trace. These programs have constructs like
variable bindings, iterative loops, or simple kinds of conditionals. With a
graphics program in hand, we can correct errors made by the deep network,
measure similarity between drawings by use of similar high-level geometric
structures, and extrapolate drawings. Taken together these results are a step
towards agents that induce useful, human-readable programs from perceptual
input.
</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09629</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kernel Projection of Latent Structures Regression for Facial Animation
  Retargeting</dc:title>
 <dc:creator>Ouzounis, Christos</dc:creator>
 <dc:creator>Kilias, Alex</dc:creator>
 <dc:creator>Mousas, Christos</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>I.3.7</dc:subject>
 <dc:description>  Inspired by kernel methods that have been used extensively in achieving
efficient facial animation retargeting, this paper presents a solution to
retargeting facial animation in virtual character's face model based on the
kernel projection of latent structure (KPLS) regression between semantically
similar facial expressions. Specifically, a given number of corresponding
semantically similar facial expressions are projected into the latent space. By
using the Nonlinear Iterative Partial Least Square method, decomposition of the
latent variables is achieved. Finally, the KPLS is achieved by solving a
kernalized version of the eigenvalue problem. By evaluating our methodology
with other kernel-based solutions, the efficiency of the presented methodology
in transferring facial animation to face models with different morphological
variations is demonstrated.
</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09636</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learned Experts' Assessment-based Reconstruction Network (&quot;LEARN&quot;) for
  Sparse-data CT</dc:title>
 <dc:creator>Chen, Hu</dc:creator>
 <dc:creator>Zhang, Yi</dc:creator>
 <dc:creator>Chen, Yunjin</dc:creator>
 <dc:creator>Zhang, Weihua</dc:creator>
 <dc:creator>Sun, Huaiqiaing</dc:creator>
 <dc:creator>Lv, Yang</dc:creator>
 <dc:creator>Liao, Peixi</dc:creator>
 <dc:creator>Zhou, Jiliu</dc:creator>
 <dc:creator>Wang, Ge</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Compressive sensing (CS) has proved effective for tomographic reconstruction
from sparsely collected data or under-sampled measurements, which are
practically important for few-view CT, tomosynthesis, interior tomography, and
so on. To perform sparse-data CT, the iterative reconstruction commonly use
regularizers in the CS framework. Currently, how to choose the parameters
adaptively for regularization is a major open problem. In this paper, inspired
by the idea of machine learning especially deep learning, we unfold a
state-of-the-art &quot;fields of experts&quot; based iterative reconstruction scheme up
to a number of iterations for data-driven training, construct a Learned
Experts' Assessment-based Reconstruction Network (&quot;LEARN&quot;) for sparse-data CT,
and demonstrate the feasibility and merits of our LEARN network. The
experimental results with our proposed LEARN network produces a competitive
performance with the well-known Mayo Clinic Low-Dose Challenge Dataset relative
to several state-of-the-art methods, in terms of artifact reduction, feature
preservation, and computational speed. This is consistent to our insight that
because all the regularization terms and parameters used in the iterative
reconstruction are now learned from the training data, our LEARN network
utilizes application-oriented knowledge more effectively and recovers
underlying images more favorably than competing algorithms. Also, the number of
layers in the LEARN network is only 12, reducing the computational complexity
of typical iterative algorithms by orders of magnitude.
</dc:description>
 <dc:description>Comment: 20 pages, 8 figures</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09641</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Visual Explanations for Convolutional Neural Networks via Input
  Resampling</dc:title>
 <dc:creator>Lengerich, Benjamin J.</dc:creator>
 <dc:creator>Konam, Sandeep</dc:creator>
 <dc:creator>Xing, Eric P.</dc:creator>
 <dc:creator>Rosenthal, Stephanie</dc:creator>
 <dc:creator>Veloso, Manuela</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The predictive power of neural networks often costs model interpretability.
Several techniques have been developed for explaining model outputs in terms of
input features; however, it is difficult to translate such interpretations into
actionable insight. Here, we propose a framework to analyze predictions in
terms of the model's internal features by inspecting information flow through
the network. Given a trained network and a test image, we select neurons by two
metrics, both measured over a set of images created by perturbations to the
input image: (1) magnitude of the correlation between the neuron activation and
the network output and (2) precision of the neuron activation. We show that the
former metric selects neurons that exert large influence over the network
output while the latter metric selects neurons that activate on generalizable
features. By comparing the sets of neurons selected by these two metrics, our
framework suggests a way to investigate the internal attention mechanisms of
convolutional neural networks.
</dc:description>
 <dc:description>Comment: Presented at ICML 2017 Workshop on Visualization for Deep Learning</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09642</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Performance Optimization under Power Constraint in Multi-thread
  Applications with Diverse Scalability</dc:title>
 <dc:creator>Conoci, Stefano</dc:creator>
 <dc:creator>Di Sanzo, Pierangelo</dc:creator>
 <dc:creator>Ciciani, Bruno</dc:creator>
 <dc:creator>Quaglia, Francesco</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>68M20</dc:subject>
 <dc:description>  In modern data centers, energy usage represents one of the major factors
affecting operational costs. Power capping is a technique that limits the power
consumption of individual systems, which allows reducing the overall power
demand at both cluster and data center levels. However, literature power
capping approaches do not fit well the nature of important applications based
on first-class multi-thread technology. For these applications performance may
not grow linearly as a function of the thread-level parallelism because of the
need for thread synchronization while accessing shared resources, such as
shared data. In this paper we consider the problem of maximizing the
application performance under a power cap by dynamically tuning the
thread-level parallelism and the power state of the CPU-cores. Based on
experimental observations, we design an adaptive technique that selects in
linear time the optimal combination of thread-level parallelism and CPU-core
power state for the specific workload profile of the multi-threaded
application. We evaluate our proposal by relying on different benchmarks,
configured to use different thread synchronization methods, and compare its
effectiveness to different state-of-the-art techniques.
</dc:description>
 <dc:description>Comment: 11 pages, 18 figures</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:date>2017-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09643</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Approach for Image Segmentation based on Histograms computed
  from Hue-data</dc:title>
 <dc:creator>Mavani, Viraj</dc:creator>
 <dc:creator>Gurnani, Ayesha</dc:creator>
 <dc:creator>Shah, Jhanvi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Computer Vision is growing day by day in terms of user specific applications.
The first step of any such application is segmenting an image. In this paper,
we propose a novel and grass-root level image segmentation algorithm for cases
in which the background has uniform color distribution. This algorithm can be
used for images of flowers, birds, insects and many more where such background
conditions occur. By image segmentation, the visualization of a computer
increases manifolds and it can even attain near-human accuracy during
classification.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09643</dc:identifier>
 <dc:identifier>International Journal for Scientific Research and Development
  [Conference 10 : NCACSET 2017] (2017): pg. 176-179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09646</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correct Composition of Dephased Behavioural Models</dc:title>
 <dc:creator>Bowles, Juliana</dc:creator>
 <dc:creator>Caminati, Marco B.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Scenarios of execution are commonly used to specify partial behaviour and
interactions between different objects and components in a system. To avoid
overall inconsistency in specifications, various automated methods have emerged
in the literature to compose (behavioural) models. In recent work, we have
shown how the theorem prover Isabelle can be combined with the constraint
solver Z3 to efficiently detect inconsistencies in two or more behavioural
models and, in their absence, generate the composition. Here, we extend our
approach further and show how to generate the correct composition (as a set of
valid traces) of dephased models. This work has been inspired by a problem from
a medical domain where different care pathways (for chronic conditions) may be
applied to the same patient with different starting points.
</dc:description>
 <dc:description>Comment: Accepted for FACS 2017</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09646</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09661</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Vision For Continuous Automated Game Design</dc:title>
 <dc:creator>Cook, Michael</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  ANGELINA is an automated game design system which has previously been built
as a single software block which designs games from start to finish. In this
paper we outline a roadmap for the development of a new version of ANGELINA,
designed to iterate on games in different ways to produce a continuous creative
process that will improve the quality of its work, but more importantly improve
the perception of the software as being an independently creative piece of
software. We provide an initial report of the system's structure here as well
as results from the first working module of the system.
</dc:description>
 <dc:description>Comment: Published in the proceedings of the Experimental AI in Games workshop
  at AIIDE 2017</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09662</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Delivery in Caching Networks</dc:title>
 <dc:creator>Saberali, Seyed Ali</dc:creator>
 <dc:creator>Saffar, Hamidreza Ebrahimzadeh</dc:creator>
 <dc:creator>Lampe, Lutz</dc:creator>
 <dc:creator>Blake, Ian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The problem of content delivery in caching networks is investigated for
scenarios where multiple users request identical files. Redundant user demands
are likely when the file popularity distribution is highly non-uniform or the
user demands are positively correlated. An adaptive method is proposed for the
delivery of redundant demands in caching networks. Based on the redundancy
pattern in the current demand vector, the proposed method decides between the
transmission of uncoded messages or the coded messages of [1] for delivery.
Moreover, a lower bound on the delivery rate of redundant requests is derived
based on a cutset bound argument. The performance of the adaptive method is
investigated through numerical examples of the delivery rate of several
specific demand vectors as well as the average delivery rate of a caching
network with correlated requests. The adaptive method is shown to considerably
reduce the gap between the non-adaptive delivery rate and the lower bound. In
some specific cases, using the adaptive method, this gap shrinks by almost 50%
for the average rate.
</dc:description>
 <dc:description>Comment: 8 pages,8 figures. Submitted to IEEE transaction on Communications in
  2015. A short version of this article was published as an IEEE Communications
  Letter with DOI: 10.1109/LCOMM.2016.2558144</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09668</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Handling Nested Parallelism and Extreme Load Imbalance in an Orbital
  Analysis Code</dc:title>
 <dc:creator>Gaska, Benjamin James</dc:creator>
 <dc:creator>Jothi, Neha</dc:creator>
 <dc:creator>Mohammadi, Mahdi Soltan</dc:creator>
 <dc:creator>Volk, Kat</dc:creator>
 <dc:creator>Strout, Michelle Mills</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Nested parallelism exists in scientific codes that are searching
multi-dimensional spaces. However, implementations of nested parallelism often
have overhead and load balance issues. The Orbital Analysis code we present
exhibits a sparse search space, significant load imbalances, and stopping when
the first solution is reached. All these aspects of the algorithm exacerbate
the problem of using nested parallelism effectively. In this paper, we present
an inspector/executor strategy for chunking such computations into parallel
wavefronts. The presented shared memory parallelization is no longer nested and
exhibits significantly less load imbalance. We evaluate this approach on an
Orbital analysis code, and we improve the execution time from the original
implementation by an order of magnitude. As part of a Graduate Computer Science
course in Parallel Programming models, we show how the approach can be
implemented in parallel Perl, Python, Chapel, Pthreads, and OpenMP. Future work
includes investigating how to automate and generalize the parallelization
approach.
</dc:description>
 <dc:description>Comment: 11 pages, 14 figures</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09668</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09669</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Multi-View Learning with Stochastic Decorrelation Loss</dc:title>
 <dc:creator>Chang, Xiaobin</dc:creator>
 <dc:creator>Xiang, Tao</dc:creator>
 <dc:creator>Hospedales, Timothy M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Multi-view learning aims to learn an embedding space where multiple views are
either maximally correlated for cross-view recognition, or decorrelated for
latent factor disentanglement. A key challenge for deep multi-view
representation learning is scalability. To correlate or decorrelate multi-view
signals, the covariance of the whole training set should be computed which does
not fit well with the mini-batch based training strategy, and moreover
(de)correlation should be done in a way that is free of SVD-based computation
in order to scale to contemporary layer sizes. In this work, a unified approach
is proposed for efficient and scalable deep multi-view learning. Specifically,
a mini-batch based Stochastic Decorrelation Loss (SDL) is proposed which can be
applied to any network layer to provide soft decorrelation of the layer's
activations. This reveals the connection between deep multi-view learning
models such as Deep Canonical Correlation Analysis (DCCA) and Factorisation
Autoencoder (FAE), and allows them to be easily implemented. We further show
that SDL is superior to other decorrelation losses in terms of efficacy and
scalability.
</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09669</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09676</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model-Free Renewable Scenario Generation Using Generative Adversarial
  Networks</dc:title>
 <dc:creator>Chen, Yize</dc:creator>
 <dc:creator>Wang, Yishen</dc:creator>
 <dc:creator>Kirschen, Daniel</dc:creator>
 <dc:creator>Zhang, Baosen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Scenario generation is an important step in the operation and planning of
power systems with high renewable penetrations. In this work, we proposed a
data-driven approach for scenario generation using generative adversarial
networks, which is based on two interconnected deep neural networks. Compared
with existing methods based on probabilistic models that are often hard to
scale or sample from, our method is data-driven, and captures renewable energy
production patterns in both temporal and spatial dimensions for a large number
of correlated resources. For validation, we use wind and solar times-series
data from NREL integration data sets. We demonstrate that the proposed method
is able to generate realistic wind and photovoltaic power profiles with full
diversity of behaviors. We also illustrate how to generate scenarios based on
different conditions of interest by using labeled data during training. For
example, scenarios can be conditioned on weather events~(e.g. high wind day) or
time of the year~(e,g. solar generation for a day in July). Because of the
feedforward nature of the neural networks, scenarios can be generated extremely
efficiently without sophisticated sampling techniques.
</dc:description>
 <dc:description>Comment: submitted to IEEE Transactions on Power Systems; code available at
  https://github.com/chennnnnyize/Renewables_Scenario_Gen_GAN</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09676</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09678</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Match</dc:title>
 <dc:creator>Ekman, Philip</dc:creator>
 <dc:creator>Bellevik, Sebastian</dc:creator>
 <dc:creator>Dimitrakakis, Christos</dc:creator>
 <dc:creator>Tossou, Aristide</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Outsourcing tasks to previously unknown parties is becoming more common. One
specific such problem involves matching a set of workers to a set of tasks.
Even if the latter have precise requirements, the quality of individual workers
is usually unknown. The problem is thus a version of matching under
uncertainty. We believe that this type of problem is going to be increasingly
important.
  When the problem involves only a single skill or type of job, it is
essentially a type of bandit problem, and can be solved with standard
algorithms. However, we develop an algorithm that can perform matching for
workers with multiple skills hired for multiple jobs with multiple
requirements. We perform an experimental evaluation in both single-task and
multi-task problems, comparing with the bounded $\epsilon$-first algorithm, as
well as an oracle that knows the true skills of workers. One of the algorithms
we developed gives results approaching 85\% of oracle's performance. We invite
the community to take a closer look at this problem and develop real-world
benchmarks.
</dc:description>
 <dc:description>Comment: 5 pages. This version will be presented at the VAMS Recsys workshop
  2017</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09680</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Microgrid Value of Ramping</dc:title>
 <dc:creator>Majzoobi, Alireza</dc:creator>
 <dc:creator>Mahoor, Mohsen</dc:creator>
 <dc:creator>Khodaei, Amin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The growing penetration of renewable generation in distribution networks,
primarily deployed by end-use electricity customers, is changing the
traditional load profile and inevitably makes supply-load balancing more
challenging for grid operators. Leveraging the potential flexibility of
existing microgrids, that is to help with supply-load balance locally, is a
viable solution to cope with this challenge and mitigate existing net load
variability and intermittency in distribution networks. This paper discusses
this timely topic and determines the microgrid value of ramping based on its
available reserve using a cost-benefit analysis. To this end, a microgrid
ramping-oriented optimal scheduling model is developed and tested through
numerical simulations to prove the effectiveness and the merits of the proposed
approach in microgrid ramping valuation.
</dc:description>
 <dc:description>Comment: 2017 IEEE International Conference on Smart Grid Communications (IEEE
  SmartGridComm), Dresden, Germany, 23-26 Oct. 2017</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09680</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09681</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stable Throughput of Cooperative Cognitive Networks with Energy
  Harvesting: Finite Relay Buffer and Finite Battery Capacity</dc:title>
 <dc:creator>Abd-Elmagid, Mohamed A.</dc:creator>
 <dc:creator>ElBatt, Tamer</dc:creator>
 <dc:creator>Seddik, Karim G.</dc:creator>
 <dc:creator>Ercetin, Ozgur</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies a generic model for cooperative cognitive radio networks
where the secondary user is equipped with a finite length relaying queue as
well as a finite length battery queue. Our prime objective is to characterize
the stable throughput region. Nevertheless, the complete characterization of
stable throughput region is notoriously difficult, since the computation of the
steady state distribution of the two-dimensional Markov Chain (MC) model for
both finite queues is prohibitively complex. We first propose an algorithm to
characterize the stable throughput region numerically, and show its sheer
computational complexity for large queue lengths. Hence, we next focus on two
simpler systems, namely, finite battery queue with infinite relay queue and
finite relay queue with infinite battery queue. The motivation behind the
relaxation of having two finite queues at the same time is to lend
tractability, explore the nature of design parameters optimization at the
cognitive node and provide efficient lower computational complexity algorithms
for stable throughput region characterization. For each proposed system, we
investigate the maximum service rate of the cognitive node subject to stability
conditions. Despite the complexity of the formulated optimization problems due
to their non-convexity, we exploit the problems' structure to transform them
into linear programs. Thus, we are able to solve them efficiently using
standard linear programming solvers. Our numerical results demonstrate that, in
practical systems, finite battery and relaying queues achieve the same level of
benefits of a system with infinite queue sizes when their sizes are
sufficiently large. They also reveal that the achievable stable throughput
region significantly expands when the arrival rate of the energy harvesting
process increases.
</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09683</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CUDAMPF++: A Proactive Resource Exhaustion Scheme for Accelerating
  Homologous Sequence Search on CUDA-enabled GPU</dc:title>
 <dc:creator>Jiang, Hanyu</dc:creator>
 <dc:creator>Ganesan, Narayan</dc:creator>
 <dc:creator>Yao, Yu-Dong</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Genomic sequence alignment is an important research topic in bioinformatics
and continues to attract significant efforts. As genomic data grow
exponentially, however, most of alignment methods face challenges due to their
huge computational costs. HMMER, a suite of bioinformatics tools, is widely
used for the analysis of homologous protein and nucleotide sequences with high
sensitivity, based on profile hidden Markov models (HMMs). Its latest version,
HMMER3, introdues a heuristic pipeline to accelerate the alignment process,
which is carried out on central processing units (CPUs) with the support of
streaming SIMD extensions (SSE) instructions. Few acceleration results have
since been reported based on HMMER3. In this paper, we propose a five-tiered
parallel framework, CUDAMPF++, to accelerate the most computationally intensive
stages of HMMER3's pipeline, multiple/single segment Viterbi (MSV/SSV), on a
single graphics processing unit (GPU). As an architecture-aware design, the
proposed framework aims to fully utilize hardware resources via exploiting
finer-grained parallelism (multi-sequence alignment) compared with its
predecessor (CUDAMPF). In addition, we propose a novel method that proactively
sacrifices L1 Cache Hit Ratio (CHR) to get improved performance and scalability
in return. A comprehensive evaluation shows that the proposed framework
outperfroms all existig work and exhibits good consistency in performance
regardless of the variation of query models or protein sequence datasets. For
MSV (SSV) kernels, the peak performance of the CUDAMPF++ is 283.9 (471.7) GCUPS
on a single K40 GPU, and impressive speedups ranging from 1.x (1.7x) to 168.3x
(160.7x) are achieved over the CPU-based implementation (16 cores, 32 threads).
</dc:description>
 <dc:description>Comment: 15 pages, submitted to academic journal</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09695</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent 3D Pose Sequence Machines</dc:title>
 <dc:creator>Lin, Mude</dc:creator>
 <dc:creator>Lin, Liang</dc:creator>
 <dc:creator>Liang, Xiaodan</dc:creator>
 <dc:creator>Wang, Keze</dc:creator>
 <dc:creator>Cheng, Hui</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  3D human articulated pose recovery from monocular image sequences is very
challenging due to the diverse appearances, viewpoints, occlusions, and also
the human 3D pose is inherently ambiguous from the monocular imagery. It is
thus critical to exploit rich spatial and temporal long-range dependencies
among body joints for accurate 3D pose sequence prediction. Existing approaches
usually manually design some elaborate prior terms and human body kinematic
constraints for capturing structures, which are often insufficient to exploit
all intrinsic structures and not scalable for all scenarios. In contrast, this
paper presents a Recurrent 3D Pose Sequence Machine(RPSM) to automatically
learn the image-dependent structural constraint and sequence-dependent temporal
context by using a multi-stage sequential refinement. At each stage, our RPSM
is composed of three modules to predict the 3D pose sequences based on the
previously learned 2D pose representations and 3D poses: (i) a 2D pose module
extracting the image-dependent pose representations, (ii) a 3D pose recurrent
module regressing 3D poses and (iii) a feature adaption module serving as a
bridge between module (i) and (ii) to enable the representation transformation
from 2D to 3D domain. These three modules are then assembled into a sequential
prediction framework to refine the predicted poses with multiple recurrent
stages. Extensive evaluations on the Human3.6M dataset and HumanEva-I dataset
show that our RPSM outperforms all state-of-the-art approaches for 3D pose
estimation.
</dc:description>
 <dc:description>Comment: Published in CVPR 2017</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09696</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bitwise Retransmission Schemes for Resources Constrained Uplink Sensor
  Networks</dc:title>
 <dc:creator>Hassanien, Mohamed A. M.</dc:creator>
 <dc:creator>Loskot, Pavel</dc:creator>
 <dc:creator>Al-Shehri, Salman M.</dc:creator>
 <dc:creator>Numanoglu, Tolga</dc:creator>
 <dc:creator>Mert, Mehmet</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Novel bitwise retransmission schemes are devised which retransmit only the
bits received with small reliability. The retransmissions are used to
accumulate the reliabilities of individual bits. Unlike the conventional
automatic repeat request (ARQ) schemes, the proposed scheme does not require a
checksum for the error detection. The bits to be retransmitted are reported as
a combination number, or two synchronized random number generators (RNGs) at
the transmitter and receiver are used to greatly compress the feedback message.
The bitwise retransmission decisions and/or combining can be performed after
the demodulation or after the channel decoding at the receiver. The bit-error
rate (BER) expressions are derived for the case of one and two retransmissions,
and verified by computer simulations. Assuming three specific retransmission
strategies, the scheme parameters are optimized to minimize the overall BER.
For the same number of retransmissions and packet length, the proposed schemes
always outperform the frequently used stop-and-wait ARQ. The impact of feedback
errors is also considered. Finally, practical designs of the bitwise
retransmissions for data fusion from sensor nodes in Zigbee, Wifi and Bluetooth
networks are presented.
</dc:description>
 <dc:description>Comment: 14 pages, 17 figures, 3 tables</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09700</identifier>
 <datestamp>2017-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scene Graph Generation from Objects, Phrases and Region Captions</dc:title>
 <dc:creator>Li, Yikang</dc:creator>
 <dc:creator>Ouyang, Wanli</dc:creator>
 <dc:creator>Zhou, Bolei</dc:creator>
 <dc:creator>Wang, Kun</dc:creator>
 <dc:creator>Wang, Xiaogang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Object detection, scene graph generation and region captioning, which are
three scene understanding tasks at different semantic levels, are tied
together: scene graphs are generated on top of objects detected in an image
with their pairwise relationship predicted, while region captioning gives a
language description of the objects, their attributes, relations, and other
context information. In this work, to leverage the mutual connections across
semantic levels, we propose a novel neural network model, termed as Multi-level
Scene Description Network (denoted as MSDN), to solve the three vision tasks
jointly in an end-to-end manner. Objects, phrases, and caption regions are
first aligned with a dynamic graph based on their spatial and semantic
connections. Then a feature refining structure is used to pass messages across
the three levels of semantic tasks through the graph. We benchmark the learned
model on three tasks, and show the joint learning across three tasks with our
proposed method can bring mutual improvements over previous models.
Particularly, on the scene graph generation task, our proposed method
outperforms the state-of-art method with more than 3% margin.
</dc:description>
 <dc:description>Comment: accepted by ICCV 2017</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:date>2017-09-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09700</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09704</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cost and Actual Causation</dc:title>
 <dc:creator>Zhou, Liang</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  I propose the purpose our concept of actual causation serves is minimizing
various cost in intervention practice. Actual causation has three features:
nonredundant sufficiency, continuity and abnormality; these features correspond
to the minimization of exploitative cost, exploratory cost and risk cost in
intervention practice. Incorporating these three features, a definition of
actual causation is given. I test the definition in 66 causal cases from actual
causation literature and show that this definition's application fit intuition
better than some other causal modelling based definitions.
</dc:description>
 <dc:description>Comment: 37 pages, 2 Appendixes</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09704</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09706</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Developing Knowledge-enhanced Chronic Disease Risk Prediction Models
  from Regional EHR Repositories</dc:title>
 <dc:creator>Mei, Jing</dc:creator>
 <dc:creator>Xia, Eryu</dc:creator>
 <dc:creator>Li, Xiang</dc:creator>
 <dc:creator>Xie, Guotong</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Precision medicine requires the precision disease risk prediction models. In
literature, there have been a lot well-established (inter-)national risk
models, but when applying them into the local population, the prediction
performance becomes unsatisfactory. To address the localization issue, this
paper exploits the way to develop knowledge-enhanced localized risk models. On
the one hand, we tune models by learning from regional Electronic Health Record
(EHR) repositories, and on the other hand, we propose knowledge injection into
the EHR data learning process. For experiments, we leverage the Pooled Cohort
Equations (PCE, as recommended in ACC/AHA guidelines to estimate the risk of
ASCVD) to develop a localized ASCVD risk prediction model in diabetes. The
experimental results show that, if directly using the PCE algorithm on our
cohort, the AUC is only 0.653, while our knowledge-enhanced localized risk
model can achieve higher prediction performance with AUC of 0.723 (improved by
10.7%).
</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09706</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09708</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Some Exponential Sums Related to the Coulter's Polynomial</dc:title>
 <dc:creator>Qi, Minglong</dc:creator>
 <dc:creator>Xiong, Shengwu</dc:creator>
 <dc:creator>Yuan, Jingling</dc:creator>
 <dc:creator>Rao, Wenbi</dc:creator>
 <dc:creator>Zhong, Luo</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper, the formulas of some exponential sums over finite field,
related to the Coulter's polynomial, are settled based on the Coulter's
theorems on Weil sums, which may have potential application in the construction
of linear codes with few weights.
</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09708</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09713</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numerical analysis of shell-based geometric image inpainting algorithms
  and their semi-implicit extension</dc:title>
 <dc:creator>Hocking, L. Robert</dc:creator>
 <dc:creator>Holding, Thomas</dc:creator>
 <dc:creator>Schoenlieb, Carola-Bibiane</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>68U10, 65M12, 65M15, 65F10, 60G50, 60G40, 35F15, 60G42, 65M15, 35Q68</dc:subject>
 <dc:description>  In this paper we study a class of fast geometric image inpainting methods
based on the idea of filling the inpainting domain in successive shells from
its boundary inwards. Image pixels are filled by assigning them a color equal
to a weighted average of their already filled neighbors. However, there is
flexibility in terms of the order in which pixels are filled, the weights used
for averaging, and the neighborhood that is averaged over. Varying these
degrees of freedom leads to different algorithms, and indeed the literature
contains several methods falling into this general class. All of them are very
fast, but at the same time all of them leave undesirable artifacts such as
&quot;kinking&quot; (bending) or blurring of extrapolated isophotes. Our objective in
this paper is to build a theoretical model, based on a continuum limit and a
connection to stopped random walks, in order to understand why these artifacts
occur and what, if anything, can be done about them. At the same time, we
consider a semi-implicit extension in which pixels in a given shell are solved
for simultaneously by solving a linear system. We prove (within the continuum
limit) that this extension is able to completely eliminate kinking artifacts,
which we also prove must always be present in the direct method. Although our
analysis makes the strong assumption of a square inpainting domain, it makes
weak smoothness assumptions and is thus applicable to the low regularity
inherent in images.
</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09713</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09715</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Crack Detection in Built Infrastructure Using Unmanned Aerial
  Vehicles</dc:title>
 <dc:creator>Phung, Manh Duong</dc:creator>
 <dc:creator>Hoang, Van Truong</dc:creator>
 <dc:creator>Dinh, Tran Hiep</dc:creator>
 <dc:creator>Ha, Quang</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper addresses the problem of crack detection which is essential for
health monitoring of built infrastructure. Our approach includes two stages,
data collection using unmanned aerial vehicles (UAVs) and crack detection using
histogram analysis. For the data collection, a 3D model of the structure is
first created by using laser scanners. Based on the model, geometric properties
are extracted to generate way points necessary for navigating the UAV to take
images of the structure. Then, our next step is to stick together those
obtained images from the overlapped field of view. The resulting image is then
clustered by histogram analysis and peak detection. Potential cracks are
finally identified by using locally adaptive thresholds. The whole process is
automatically carried out so that the inspection time is significantly improved
while safety hazards can be minimised. A prototypical system has been developed
for evaluation and experimental results are included.
</dc:description>
 <dc:description>Comment: In proceeding of The 34th International Symposium on Automation and
  Robotics in Construction (ISARC), pp. 823-829, Taipei, Taiwan, 2017</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09715</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09716</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coordination of Dynamic Software Components with JavaBIP</dc:title>
 <dc:creator>Mavridou, Anastasia</dc:creator>
 <dc:creator>Rutz, Valentin</dc:creator>
 <dc:creator>Bliudze, Simon</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  JavaBIP allows the coordination of software components by clearly separating
the functional and coordination aspects of the system behavior. JavaBIP
implements the principles of the BIP component framework rooted in rigorous
operational semantics. Recent work both on BIP and JavaBIP allows the
coordination of static components defined prior to system deployment, i.e., the
architecture of the coordinated system is fixed in terms of its component
instances. Nevertheless, modern systems, often make use of components that can
register and deregister dynamically during system execution. In this paper, we
present an extension of JavaBIP that can handle this type of dynamicity. We use
first-order interaction logic to define synchronization constraints based on
component types. Additionally, we use directed graphs with edge coloring to
model dependencies among components that determine the validity of an online
system. We present the software architecture of our implementation, provide and
discuss performance evaluation results.
</dc:description>
 <dc:description>Comment: Technical report that accompanies the paper accepted at the 14th
  International Conference on Formal Aspects of Component Software</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09718</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Second-order Sliding Mode Control of UAVs for Civil
  Applications</dc:title>
 <dc:creator>Hoang, Van Truong</dc:creator>
 <dc:creator>Singh, Ansu Man</dc:creator>
 <dc:creator>Phung, Manh Duong</dc:creator>
 <dc:creator>Ha, Quang</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Quadcopters, as unmanned aerial vehicles (UAVs), have great potential in
civil applications such as surveying, building monitoring, and infrastructure
condition assessment. Quadcopters, however, are relatively sensitive to noises
and disturbances so that their performance may be quickly downgraded in the
case of inadequate control, system uncertainties and/or external disturbances.
In this study, we deal with the quadrotor low-level control by proposing a
robust scheme named the adaptive second-order quasi-continuous sliding mode
control (adaptive 2-QCSM). The ultimate objective is for robust attitude
control of the UAV in monitoring and inspection of built infrastructure. First,
the mathematical model of the quadcopter is derived considering nonlinearity,
strong coupling, uncertain dynamics and external disturbances. The control
design includes the selection of the sliding manifold and the development of
quasi-continuous second-order sliding mode controller with an adaptive gain.
Stability of the overall control system is analysed by using a global Lyapunov
function for convergence of both the sliding dynamics and adaptation scheme.
Extensive simulations have been carried out for evaluation. Results show that
the proposed controller can achieve robustness against disturbances or
parameter variations and has better tracking performance in comparison with
experimental responses of a UAV in a real-time monitoring task.
</dc:description>
 <dc:description>Comment: in Proceeding of The 34th International Symposium on Automation and
  Robotics in Construction (ISARC), pp. 823-829, Taipei, Taiwan, 2017</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09720</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Efficient Resource Allocation for Ultra-reliable and Low-latency
  Communications</dc:title>
 <dc:creator>Sun, Chengjian</dc:creator>
 <dc:creator>She, Changyang</dc:creator>
 <dc:creator>Yang, Chenyang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Ultra-reliable and low-latency communications (URLLC) is expected to be
supported without compromising the resource usage efficiency. In this paper, we
study how to maximize energy efficiency (EE) for URLLC under the stringent
quality of service (QoS) requirement imposed on the end-to-end (E2E) delay and
overall packet loss, where the E2E delay includes queueing delay and
transmission delay, and the overall packet loss consists of queueing delay
violation, transmission error with finite blocklength channel codes, and
proactive packet dropping in deep fading. Transmit power, bandwidth and number
of active antennas are jointly optimized to maximize the system EE under the
QoS constraints. Since the achievable rate with finite blocklength channel
codes is not convex in radio resources, it is challenging to optimize resource
allocation. By analyzing the properties of the optimization problem, the global
optimal solution is obtained. Simulation and numerical results validate the
analysis and show that the proposed policy can improve EE significantly
compared with existing policy.
</dc:description>
 <dc:description>Comment: This paper has been accepted by IEEE Globecom 2017</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09720</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09725</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis and Optimization of Convolutional Neural Network Architectures</dc:title>
 <dc:creator>Thoma, Martin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional Neural Networks (CNNs) dominate various computer vision tasks
since Alex Krizhevsky showed that they can be trained effectively and reduced
the top-5 error from 26.2 % to 15.3 % on the ImageNet large scale visual
recognition challenge. Many aspects of CNNs are examined in various
publications, but literature about the analysis and construction of neural
network architectures is rare. This work is one step to close this gap. A
comprehensive overview over existing techniques for CNN analysis and topology
construction is provided. A novel way to visualize classification errors with
confusion matrices was developed. Based on this method, hierarchical
classifiers are described and evaluated. Additionally, some results are
confirmed and quantified for CIFAR-100. For example, the positive impact of
smaller batch sizes, averaging ensembles, data augmentation and test-time
transformations on the accuracy. Other results, such as the positive impact of
learned color transformation on the test accuracy could not be confirmed. A
model which has only one million learned parameters for an input size of
32x32x3 and 100 classes and which beats the state of the art on the benchmark
dataset Asirra, GTSRB, HASYv2 and STL-10 was developed.
</dc:description>
 <dc:description>Comment: Master's thesis. 73 pages + 24 pages appendix; 39 figures; 33 tables</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09727</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Taming Non-stationary Bandits: A Bayesian Approach</dc:title>
 <dc:creator>Raj, Vishnu</dc:creator>
 <dc:creator>Kalyani, Sheetal</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the multi armed bandit problem in non-stationary environments.
Based on the Bayesian method, we propose a variant of Thompson Sampling which
can be used in both rested and restless bandit scenarios. Applying discounting
to the parameters of prior distribution, we describe a way to systematically
reduce the effect of past observations. Further, we derive the exact expression
for the probability of picking sub-optimal arms. By increasing the exploitative
value of Bayes' samples, we also provide an optimistic version of the
algorithm. Extensive empirical analysis is conducted under various scenarios to
validate the utility of proposed algorithms. A comparison study with various
state-of-the-arm algorithms is also included.
</dc:description>
 <dc:description>Comment: Submitted to NIPS 2017</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09727</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09728</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interaction Methods for Smart Glasses</dc:title>
 <dc:creator>Lee, Lik-Hang</dc:creator>
 <dc:creator>Hui, Pan</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Since the launch of Google Glass in 2014, smart glasses have mainly been
designed to support micro-interactions. The ultimate goal for them to become an
augmented reality interface has not yet been attained due to an encumbrance of
controls. Augmented reality involves superimposing interactive computer
graphics images onto physical objects in the real world. This survey reviews
current research issues in the area of human computer interaction for smart
glasses. The survey first studies the smart glasses available in the market and
afterwards investigates the interaction methods proposed in the wide body of
literature. The interaction methods can be classified into hand-held, touch,
and touchless input. This paper mainly focuses on the touch and touchless
input. Touch input can be further divided into on-device and on-body, while
touchless input can be classified into hands-free and freehand. Next, we
summarize the existing research efforts and trends, in which touch and
touchless input are evaluated by a total of eight interaction goals. Finally,
we discuss several key design challenges and the possibility of multi-modal
input for smart glasses.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09728</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09733</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Camera Relocalization by Computing Pairwise Relative Poses Using
  Convolutional Neural Network</dc:title>
 <dc:creator>Laskar, Zakaria</dc:creator>
 <dc:creator>Melekhov, Iaroslav</dc:creator>
 <dc:creator>Kalia, Surya</dc:creator>
 <dc:creator>Kannala, Juho</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a new deep learning based approach for camera relocalization. Our
approach localizes a given query image by using a convolutional neural network
(CNN) for first retrieving similar database images and then predicting the
relative pose between the query and the database images, whose poses are known.
The camera location for the query image is obtained via triangulation from two
relative translation estimates using a RANSAC based approach. Each relative
pose estimate provides a hypothesis for the camera orientation and they are
fused in a second RANSAC scheme. The neural network is trained for relative
pose estimation in an end-to-end manner using training image pairs. In contrast
to previous work, our approach does not require scene-specific training of the
network, which improves scalability, and it can also be applied to scenes which
are not available during the training of the network. As another main
contribution, we release a challenging indoor localisation dataset covering 5
different scenes registered to a common coordinate frame. We evaluate our
approach using both our own dataset and the standard 7 Scenes benchmark. The
results show that the proposed approach generalizes well to previously unseen
scenes and compares favourably to other recent CNN-based methods.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09733</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09734</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Random Matrix Models for Generalized Fading MIMO Channels</dc:title>
 <dc:creator>Srinivasan, Muralikrishnan</dc:creator>
 <dc:creator>Kalyani, Sheetal</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Approximate random matrix models for $\kappa-\mu$ and $\eta-\mu$ faded
multiple input multiple output (MIMO) communication channels are derived in
terms of a complex Wishart matrix by keeping the degree of freedom constrained
to the number of transmitting antennas and by matching matrix variate moments.
The utility of the result is demonstrated in a) computing the average
capacity/rate of $\kappa-\mu$/$\eta-\mu$ MIMO systems b) computing Symbol Error
Rate (SER) for optimum combining with Rayleigh faded users and an arbitrary
number of $\kappa-\mu$ and $\eta-\mu$ faded interferers. These approximate
expressions are compared with Monte-Carlo simulations and a close match is
observed.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09735</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Sum Rate And Error Probability Optimization: Finite Blocklength
  Analysis</dc:title>
 <dc:creator>Haghifam, Mahdi</dc:creator>
 <dc:creator>Mili, Mohammad Robat</dc:creator>
 <dc:creator>Makki, Behrooz</dc:creator>
 <dc:creator>Nasiri-Kenari, Masoumeh</dc:creator>
 <dc:creator>Svensson, Tommy</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the tradeoff between the sum rate and the error probability in
downlink of wireless networks. Using the recent results on the achievable rates
of finite-length codewords, the problem is cast as a joint optimization of the
network sum rate and the per-user error probability. Moreover, we develop an
efficient algorithm based on the divide-and-conquer technique to simultaneously
maximize the network sum rate and minimize the maximum users' error probability
and to evaluate the effect of the codewords length on the system performance.
The results show that, in delay-constrained scenarios, optimizing the per-user
error probability plays a key role in achieving high throughput.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Wireless Communications Letters</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09735</dc:identifier>
 <dc:identifier>IEEE Wireless Communications Letters ( Volume: 6, Issue: 6, Dec.
  2017 )</dc:identifier>
 <dc:identifier>doi:10.1109/LWC.2017.2736539</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09740</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Modeling of Propagation Channels for Terahertz Band</dc:title>
 <dc:creator>Ekti, Ali R&#x131;za</dc:creator>
 <dc:creator>Boyac&#x131;, Ali</dc:creator>
 <dc:creator>Alparslan, Altan</dc:creator>
 <dc:creator>Unal, Ilhami</dc:creator>
 <dc:creator>Yarkan, Serhan</dc:creator>
 <dc:creator>Gorcin, Ali</dc:creator>
 <dc:creator>Arslan, Huseyin</dc:creator>
 <dc:creator>Uysal, Murat</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Digital revolution and recent advances in telecommunications technology
enable to design communication systems which operate within the regions close
to the theoretical capacity limits. Ever-increasing demand for wireless
communications and emerging numerous high-capacity services, data rates and
applications mandate providers to employ more bandwidth-oriented solutions to
meet the requirements. It is clear that such rates could only be achieved by
employing more bandwidth with the state-of-the- art technology. Considering the
fact that bands in the range of 275GHz-3000GHz, which are known as Terahertz
(THz) bands, are not allocated yet for specific active services around the
globe, there is an enormous potential to achieve the desired data rates.
Although THz bands look promising to achieve data rates on the order of several
tens of Gbps, realization of fully operational THz communications systems
obliges to carry out a multi- disciplinary effort including statistical
propagation and channel characterizations, adaptive transceiver designs,
reconfigurable platforms, advanced signal processing algorithms and techniques
along with upper layer protocols equipped with various security and privacy
levels. Therefore, in this study, several important statistical parameters for
line-of-sight (LOS) channels are measured. High resolution frequency domain
measurements are carried out at single-sweep within a span of 60GHz. Impact of
antenna misalignment under LOS conditions is also investigated. By validating
exponential decay of the received power in both time and frequency domain, path
loss exponent is examined for different frequencies along with the
frequency-dependent path loss phenomenon. Furthermore, impact of humidity is
also tested under LOS scenario. Measurement results are presented along with
relevant discussions and future directions are provided as well.
</dc:description>
 <dc:description>Comment: Terahertz Communication, Channel Modeling, 7 pages, 6 figures, This
  paper is accepted for publication in 2017 IEEE Conference on Standards for
  Communications &amp; Networking (CSCN 2017)</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09747</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthesis of Positron Emission Tomography (PET) Images via Multi-channel
  Generative Adversarial Networks (GANs)</dc:title>
 <dc:creator>Bi, Lei</dc:creator>
 <dc:creator>Kim, Jinman</dc:creator>
 <dc:creator>Kumar, Ashnil</dc:creator>
 <dc:creator>Feng, Dagan</dc:creator>
 <dc:creator>Fulham, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Positron emission tomography (PET) image synthesis plays an important role,
which can be used to boost the training data for computer aided diagnosis
systems. However, existing image synthesis methods have problems in
synthesizing the low resolution PET images. To address these limitations, we
propose multi-channel generative adversarial networks (M-GAN) based PET image
synthesis method. Different to the existing methods which rely on using
low-level features, the proposed M-GAN is capable to represent the features in
a high-level of semantic based on the adversarial learning concept. In
addition, M-GAN enables to take the input from the annotation (label) to
synthesize the high uptake regions e.g., tumors and from the computed
tomography (CT) images to constrain the appearance consistency and output the
synthetic PET images directly. Our results on 50 lung cancer PET-CT studies
indicate that our method was much closer to the real PET images when compared
with the existing methods.
</dc:description>
 <dc:description>Comment: 9 pages, 2 figures</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09751</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Skill2vec: Machine Learning Approaches for Determining the Relevant
  Skill from Job Description</dc:title>
 <dc:creator>Le, Van-Duyet</dc:creator>
 <dc:creator>Quan, Vo Minh</dc:creator>
 <dc:creator>An, Dang Quang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Un-supervise learned word embeddings have seen tremendous success in numerous
Natural Language Processing (NLP) tasks in recent years. The main contribution
of this paper is to develop a technique called Skill2vec, which applies machine
learning techniques in recruitment to enhance the search strategy to find the
candidates who possess the right skills. Skill2vec is a neural network
architecture which inspired by Word2vec, developed by Mikolov et al. in 2013,
to transform a skill to a new vector space. This vector space has the
characteristics of calculation and present their relationship. We conducted an
experiment using AB testing in a recruitment company to demonstrate the
effectiveness of our approach.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09751</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09753</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polar Code Construction for List Decoding</dc:title>
 <dc:creator>Yuan, Peihong</dc:creator>
 <dc:creator>Prinz, Tobias</dc:creator>
 <dc:creator>B&#xf6;cherer, Georg</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A heuristic construction of polar codes for successive cancellation list
(SCL) decoding with a given list size is proposed to balance the trade-off
between performance measured in frame error rate (FER) and decoding complexity.
Furthermore, a construction based on dynamically frozen bits with constraints
among the &quot;low weight bits&quot; (LWB) is presented. Simulation results show that
the LWB-polar codes outperform the CRC-polar codes and the eBCH-polar codes
under SCL decoding.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09753</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09754</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Delay Analysis of Multichannel Parallel Contention Tree Algorithms
  (MP-CTA)</dc:title>
 <dc:creator>G&#xfc;rsu, Murat</dc:creator>
 <dc:creator>Alba, Alberto Mart&#xed;nez</dc:creator>
 <dc:creator>Kellerer, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A05</dc:subject>
 <dc:description>  Contention tree algorithm is initially invented as a solution to improve the
stable throughput problem of Slotted ALOHA in multiple access schemes. Even
though the throughput is stabilized in tree algorithms, the delay of requests
may grow to infinity with respect to the arrival rate of the system. Delay
depends heavily on the exploration of the tree structure, i.e., breadth search,
or depth search. Breadth search is necessary for faster exploration of tree.
The analytical probability distribution of delay, which is available mostly for
depth search, is not generalizable to all breadth search. In this paper we fill
this gap through though arbitrary grouping of branches and including this in
the delay analysis. This enables obtaining the delay analysis of any contention
tree algorithm that runs a breadth first search exploration. We show through
simulations that the analysis is in agreement with the realizations.
</dc:description>
 <dc:description>Comment: 38 pages, 6 figures, submitted to Transactions on Information Theory
  with id IT-17-0597</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09757</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coded Load Balancing in Cache Networks</dc:title>
 <dc:creator>Siavoshani, Mahdi Jafari</dc:creator>
 <dc:creator>Parvaresh, Farzad</dc:creator>
 <dc:creator>Pourmiri, Ali</dc:creator>
 <dc:creator>Shariatpanahi, Seyed Pooya</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We consider a cache network consisting of storage-enabled servers forming a
distributed content delivery scenario. Each incoming content request, arriving
uniformly at random to these servers, will be redirected to one or more
responsible servers for that request. While assigning each request to its
nearest available replica seems to be a reasonable solution, specifically in
terms of communication cost, it will result in overloaded servers. Thus,
alternatively, we investigate a coded scheme which will address this problem.
In this scheme, coded chunks of original files are stored in servers based on
the files popularity distribution, which we consider to be Zipf. Then, upon
each request arrival, by delivering enough coded chunks to the request origin,
the request can be decoded.
  Specifically, we show that if $n$ requests are assigned to $n$ servers based
on the proposed coded scheme, the maximum load of servers will be $\Theta(1)$,
while in the nearest replica strategy the maximum load is $\Theta(\log n)$.
More surprisingly, this coded scheme will have the same communication cost
performance as the nearest replica strategy, asymptotically. Finally, our
numerical results show that the coded scheme surpasses the uncoded one even in
non-asymptotic regimes.
</dc:description>
 <dc:description>Comment: The paper is 15 pages and contains 4 figures</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09769</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Resource Neural Headline Generation</dc:title>
 <dc:creator>Tilk, Ottokar</dc:creator>
 <dc:creator>Alum&#xe4;e, Tanel</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recent neural headline generation models have shown great results, but are
generally trained on very large datasets. We focus our efforts on improving
headline quality on smaller datasets by the means of pretraining. We propose
new methods that enable pre-training all the parameters of the model and
utilize all available text, resulting in improvements by up to 32.4% relative
in perplexity and 2.84 points in ROUGE.
</dc:description>
 <dc:description>Comment: Accepted to EMNLP 2017 Workshop on New Frontiers in Summarization</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09769</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09770</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GPS Multipath Detection in the Frequency Domain</dc:title>
 <dc:creator>Amani, Elie</dc:creator>
 <dc:creator>Djouani, Karim</dc:creator>
 <dc:creator>Kurien, Anish</dc:creator>
 <dc:creator>De Boer, Jean-R&#xe9;mi</dc:creator>
 <dc:creator>Vigneau, Willy</dc:creator>
 <dc:creator>Ries, Lionel</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Multipath is among the major sources of errors in precise positioning using
GPS and continues to be extensively studied. Two Fast Fourier Transform
(FFT)-based detectors are presented in this paper as GPS multipath detection
techniques. The detectors are formulated as binary hypothesis tests under the
assumption that the multipath exists for a sufficient time frame that allows
its detection based on the quadrature arm of the coherent Early-minus-Late
discriminator (Q EmL) for a scalar tracking loop (STL) or on the quadrature (Q
EmL) and/or in-phase arm (I EmL) for a vector tracking loop (VTL), using an
observation window of N samples. Performance analysis of the suggested
detectors is done on multipath signal data acquired from the multipath
environment simulator developed by the German Aerospace Centre (DLR) as well as
on multipath data from real GPS signals. Application of the detection tests to
correlator outputs of scalar and vector tracking loops shows that they may be
used to exclude multipath contaminated satellites from the navigation solution.
These detection techniques can be extended to other Global Navigation Satellite
Systems (GNSS) such as GLONASS, Galileo and Beidou.
</dc:description>
 <dc:description>Comment: 2016 European Navigation Conference (ENC 2016), May 2016, Helsinki,
  Finland. Proceedings of the 2016 European Navigation Conference (ENC 2016)</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09770</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09775</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity limitations of visual search in deep convolutional neural
  network</dc:title>
 <dc:creator>Poder, Endel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Deep convolutional neural networks follow roughly the architecture of
biological visual systems, and have shown a performance comparable to human
observers in object recognition tasks. In this study, I test a pre-trained deep
neural network in some classic visual search tasks. The results reveal a
qualitative difference from human performance. It appears that there is no
difference between searches for simple features that pop out in experiments
with humans, and for feature configurations that exhibit strict capacity
limitations in human vision. Both types of stimuli reveal moderate capacity
limitations in the neural network tested here.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09775</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09783</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulation of high temperature superconductors and experimental
  validation</dc:title>
 <dc:creator>Olm, Marc</dc:creator>
 <dc:creator>Badia, Santiago</dc:creator>
 <dc:creator>Mart&#xed;n, Alberto F.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  In this work, we present a numerical framework to simulate high temperature
superconductor devices. We select the so-called $H$-formulation, which uses the
magnetic field as a state variable, in order to develop an augmented
formulation that guarantees the divergence-free condition. However, nodal
elements fail in the $H-$formulation modelling of electromagnetic fields along
interfaces between regions with high contrast medium properties, thus
N\'ed\'elec elements (of arbitrary order) are preferred. The composition of a
customized, robust, nonlinear solver completes the exposition of the developed
tools to tackle the problem. A set of detailed numerical experiments in 2D/3D
shows the availability of the finite element approximation to model the
phenomena, including a validation against experimental data.
</dc:description>
 <dc:description>Comment: 26 pages</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09789</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relations Between Greedy and Bit-Optimal LZ77 Encodings</dc:title>
 <dc:creator>Kosolobov, Dmitry</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  This paper investigates the size in bits of the LZ77 encoding, which is the
most popular and efficient variant of the Lempel-Ziv encodings used in data
compression. We prove that, for a wide natural class of variable-length
encoders for LZ77 phrases, the size of the greedily constructed LZ77 encoding
on constant alphabets is within a factor $O(\frac{\log n}{\log\log\log n})$ of
the optimal LZ77 encoding, where $n$ is the length of the processed string. We
describe a series of examples showing that, surprisingly, this bound is tight,
thus improving both the previously known upper and lower bounds. Further, we
obtain a more detailed bound $O(\min\{z, \frac{\log n}{\log\log z}\})$, which
uses the number $z$ of phrases in the greedy LZ77 encoding as a parameter, and
construct a series of examples showing that this bound is tight even for binary
alphabet. We then investigate the problem on non-constant alphabets: we show
that the known $O(\log n)$ bound is tight even for alphabets of logarithmic
size, and provide tight bounds for some other important cases.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2018-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09789</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09790</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating Music Recommender Systems for Groups</dc:title>
 <dc:creator>Mezei, Zsolt</dc:creator>
 <dc:creator>Eickhoff, Carsten</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Recommendation to groups of users is a challenging and currently only
passingly studied task. Especially the evaluation aspect often appears ad-hoc
and instead of truly evaluating on groups of users, synthesizes groups by
merging individual preferences.
  In this paper, we present a user study, recording the individual and shared
preferences of actual groups of participants, resulting in a robust,
standardized evaluation benchmark. Using this benchmarking dataset, that we
share with the research community, we compare the respective performance of a
wide range of music group recommendation techniques proposed in the
</dc:description>
 <dc:description>Comment: Presented at the 2017 Workshop on Value-Aware and Multistakeholder
  Recommendation</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09790</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09791</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intra Prediction Using In-Loop Residual Coding for the post-HEVC
  Standard</dc:title>
 <dc:creator>Abdoli, Mohsen</dc:creator>
 <dc:creator>Henry, F&#xe9;lix</dc:creator>
 <dc:creator>Brault, Patric</dc:creator>
 <dc:creator>Duhamel, Pierre</dc:creator>
 <dc:creator>Dufaux, Fr&#xe9;d&#xe9;ric</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  A few years after standardization of the High Efficiency Video Coding (HEVC),
now the Joint Video Exploration Team (JVET) group is exploring post-HEVC video
compression technologies. In the intra prediction domain, this effort has
resulted in an algorithm with 67 internal modes, new filters and tools which
significantly improve HEVC. However, the improved algorithm still suffers from
the long distance prediction inaccuracy problem. In this paper, we propose an
In-Loop Residual coding Intra Prediction (ILR-IP) algorithm which utilizes
inner-block reconstructed pixels as references to reduce the distance from
predicted pixels. This is done by using the ILR signal for partially
reconstructing each pixel, right after its prediction and before its
block-level out-loop residual calculation. The ILR signal is decided in the
rate-distortion sense, by a brute-force search on a QP-dependent finite
codebook that is known to the decoder. Experiments show that the proposed
ILR-IP algorithm improves the existing method in the Joint Exploration Model
(JEM) up to 0.45% in terms of bit rate saving, without complexity overhead at
the decoder side.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figure, Conference: IEEE 19th International Workshop on
  Multimedia Signal Processing, Luton, UK</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09791</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09792</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectrum Access In Cognitive Radio Using A Two Stage Reinforcement
  Learning Approach</dc:title>
 <dc:creator>Raj, Vishnu</dc:creator>
 <dc:creator>Dias, Irene</dc:creator>
 <dc:creator>Tholeti, Thulasi</dc:creator>
 <dc:creator>Kalyani, Sheetal</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  With the advent of the 5th generation of wireless standards and an increasing
demand for higher throughput, methods to improve the spectral efficiency of
wireless systems have become very important. In the context of cognitive radio,
a substantial increase in throughput is possible if the secondary user can make
smart decisions regarding which channel to sense and when or how often to
sense. Here, we propose an algorithm to not only select a channel for data
transmission but also to predict how long the channel will remain unoccupied so
that the time spent on channel sensing can be minimized. Our algorithm learns
in two stages - a reinforcement learning approach for channel selection and a
Bayesian approach to determine the optimal duration for which sensing can be
skipped. Comparisons with other learning methods are provided through extensive
simulations. We show that the number of sensing is minimized with negligible
increase in primary interference; this implies that lesser energy is spent by
the secondary user in sensing and also higher throughput is achieved by saving
on sensing.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09793</identifier>
 <datestamp>2017-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Results on Monoids as Memory</dc:title>
 <dc:creator>Salehi, &#xd6;zlem</dc:creator>
 <dc:creator>D'Alessandro, Flavio</dc:creator>
 <dc:creator>Say, A. C. Cem</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We show that some results from the theory of group automata and monoid
automata still hold for more general classes of monoids and models. Extending
previous work for finite automata over commutative groups, we demonstrate a
context-free language that can not be recognized by any rational monoid
automaton over a finitely generated permutable monoid. We show that the class
of languages recognized by rational monoid automata over finitely generated
completely simple or completely 0-simple permutable monoids is a semi-linear
full trio. Furthermore, we investigate valence pushdown automata, and prove
that they are only as powerful as (finite) valence automata. We observe that
certain results proven for monoid automata can be easily lifted to the case of
context-free valence grammars.
</dc:description>
 <dc:description>Comment: In Proceedings AFL 2017, arXiv:1708.06226</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09793</dc:identifier>
 <dc:identifier>EPTCS 252, 2017, pp. 234-247</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.252.22</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09796</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance analysis of FSO communications under LOS blockage</dc:title>
 <dc:creator>Garrido-Balsells, Jose Maria</dc:creator>
 <dc:creator>Lopez-Martinez, F. Javier</dc:creator>
 <dc:creator>Castillo-Vazquez, Miguel</dc:creator>
 <dc:creator>Jurado-Navas, Antonio</dc:creator>
 <dc:creator>Puerta-Notario, Antonio</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We analyze the performance of a free-space optical (FSO) link affected by
atmospheric turbulence and line-of-sight (LOS) blockage. For this purpose, the
atmospheric turbulence induced fading is modeled by the M-distribution, which
includes the Gamma-Gamma distribution as special case. We exploit the fact that
the physical interpretation of the M-distribution allows to split the optical
energy through the propagation link into three different components: two
coherent components and one incoherent scatter component. Based on this
separation, we derive novel analytical expressions for the probability density
function (PDF), for the cumulative distribution function (CDF) and for the
moment generating function (MGF) of the M-distribution under the temporary
blockage of the coherent components, hereinafter referred to as LOS blockage.
Further, a new closed-form expression for the outage probability (OP) under LOS
blockage is derived in terms of the turbulence model parameters and the LOS
blockage probability. By means of an asymptotic analysis, this expression is
simplified in the high-SNR regime and the OP in terms of the diversity order
and diversity gain is then deduced. Obtained results show that the impact of
the LOS blockage on the OP strongly depends on the intensity of the turbulence
and on the LOS blockage probability.
</dc:description>
 <dc:description>Comment: This work has been submitted to for journal publication. Copyright
  may be transferred without notice, after which this version may no longer be
  accesible</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09796</dc:identifier>
 <dc:identifier>doi:10.1364/OE.25.025278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09798</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Visual Attribute Transfer with Reconfigurable Generative
  Adversarial Networks</dc:title>
 <dc:creator>Kim, Taeksoo</dc:creator>
 <dc:creator>Kim, Byoungjip</dc:creator>
 <dc:creator>Cha, Moonsu</dc:creator>
 <dc:creator>Kim, Jiwon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learning to transfer visual attributes requires supervision dataset.
Corresponding images with varying attribute values with the same identity are
required for learning the transfer function. This largely limits their
applications, because capturing them is often a difficult task. To address the
issue, we propose an unsupervised method to learn to transfer visual attribute.
The proposed method can learn the transfer function without any corresponding
images. Inspecting visualization results from various unsupervised attribute
transfer tasks, we verify the effectiveness of the proposed method.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09800</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Principled Approximation Framework for Optimal Control of Semi-Markov
  Jump Linear Systems</dc:title>
 <dc:creator>Jafari, Saeid</dc:creator>
 <dc:creator>Savla, Ketan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We consider continuous-time, finite-horizon, optimal quadratic control of
semi-Markov jump linear systems (S-MJLS), and develop principled approximations
through Markov-like representations for the holding-time distributions. We
adopt a phase-type approximation for holding times, which is known to be
consistent, and translates a S-MJLS into a specific MJLS with partially
observable modes (MJLSPOM), where the modes in a cluster have the same dynamic,
the same cost weighting matrices and the same control policy. For a general
MJLSPOM, we give necessary and sufficient conditions for optimal (switched)
linear controllers. When specialized to our particular MJLSPOM, we additionally
establish the existence of optimal linear controller, as well as its optimality
within the class of general controllers satisfying standard smoothness
conditions. The known equivalence between phase-type distributions and positive
linear systems allows to leverage existing modeling tools, but possibly with
large computational costs. Motivated by this, we propose matrix exponential
approximation of holding times, resulting in pseudo-MJLSPOM representation,
i.e., where the transition rates could be negative. Such a representation is of
relatively low order, and maintains the same optimality conditions as for the
MJLSPOM representation, but could violate non-negativity of holding-time
density functions. A two-step procedure consisting of a local pulling-up
modification and a filtering technique is constructed to enforce
non-negativity.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09808</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical Aspects of Autonomous Exploration with a Kinect2 sensor</dc:title>
 <dc:creator>Kulich, Miroslav</dc:creator>
 <dc:creator>Lhotsk&#xfd;, Vojt&#x11b;ch</dc:creator>
 <dc:creator>P&#x159;eu&#x10d;il, Libor</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Exploration of an unknown environment by a mobile robot is a complex task
involving solution of many fundamental problems from data processing,
localization to high-level planning and decision making. The exploration
framework we developed is based on processing of RGBD data provided by a MS
Kinect2 sensor, which allows to take advantage of state-of-the-art SLAM
(Simultaneous Localization and Mapping) algorithms and to autonomously build a
realistic 3D map of the environment with projected visual information about the
scene. In this paper, we describe practical issues that appeared during
deployment of the framework in real indoor and outdoor environments and discuss
especially properties of SLAM algorithms processing MS Kinect2 data on an
embedded computer.
</dc:description>
 <dc:description>Comment: The 2016 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS 2016) Workshop on State Estimation and Terrain Perception for
  All Terrain Mobile Robots</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09808</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09809</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Speed-up of Self-Organizing Networks for Routing Problems in a Polygonal
  Domain</dc:title>
 <dc:creator>Kulich, Miroslav</dc:creator>
 <dc:creator>Sushkov, Roman</dc:creator>
 <dc:creator>P&#x159;eu&#x10d;il, Libor</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Routing problems are optimization problems that consider a set of goals in a
graph to be visited by a vehicle (or a fleet of them) in an optimal way, while
numerous constraints have to be satisfied. We present a solution based on
multidimensional scaling which significantly reduces computational time of a
self-organizing neural network solving a typical routing problem -- the
Travelling Salesman Problem (TSP) in a polygonal domain, i.e. in a space where
obstacles are represented by polygons. The preliminary results show feasibility
of the proposed approach and although the results are presented only for TSP,
the method is general so it can be used also for other variants of routing
problems.
</dc:description>
 <dc:description>Comment: The 2016 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS 2016), 10th International Cognitive Robotics Workshop</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09811</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Resource Dedication in Grouped Random Access for Massive
  Machine-Type Communications</dc:title>
 <dc:creator>Han, Bin</dc:creator>
 <dc:creator>Habibi, Mohammad Asif</dc:creator>
 <dc:creator>Schotten, Hans D.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The high risk of random access collisions leads to huge challenge for the
deployment massive Machine-Type Communications (mMTC), which cannot be
sufficiently overcome by current solutions in LTE/LTE-A networks such as the
extended access barring (EAB) scheme. The recently studied approaches of
grouped random access have shown a great potential in simultaneously reducing
the collision rate and the power consumption in mMTC applications, and exhibit
a good compatibility with the concept of random access resource separation. In
this work, we propose an optimized resource dedication strategy for grouped
random access approaches, which inherits the advantage of resource separation
to isolate device classes from each other, while providing an optional class
preference with high flexibility and accuracy, which has been usually
implemented with access class barring.
</dc:description>
 <dc:description>Comment: Accepted by the 2017 IEEE Conference on Standards for Communications
  &amp; Networking (CSCN)</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09811</dc:identifier>
 <dc:identifier>2017 IEEE Conference on Standards for Communications and
  Networking (CSCN), Helsinki, 2017, pp. 72-77</dc:identifier>
 <dc:identifier>doi:10.1109/CSCN.2017.8088601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09813</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>2D-3D Fully Convolutional Neural Networks for Cardiac MR Segmentation</dc:title>
 <dc:creator>Patravali, Jay</dc:creator>
 <dc:creator>Jain, Shubham</dc:creator>
 <dc:creator>Chilamkurthy, Sasank</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we develop a 2D and 3D segmentation pipelines for fully
automated cardiac MR image segmentation using Deep Convolutional Neural
Networks (CNN). Our models are trained end-to-end from scratch using the ACD
Challenge 2017 dataset comprising of 100 studies, each containing Cardiac MR
images in End Diastole and End Systole phase. We show that both our
segmentation models achieve near state-of-the-art performance scores in terms
of distance metrics and have convincing accuracy in terms of clinical
parameters. A comparative analysis is provided by introducing a novel dice loss
function and its combination with cross entropy loss. By exploring different
network structures and comprehensive experiments, we discuss several key
insights to obtain optimal model performance, which also is central to the
theme of this challenge.
</dc:description>
 <dc:description>Comment: Accepted in STACOM '17</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09816</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Thesaurus Knowledge and Probabilistic Topic Models</dc:title>
 <dc:creator>Loukachevitch, Natalia</dc:creator>
 <dc:creator>Nokel, Michael</dc:creator>
 <dc:creator>Ivanov, Kirill</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper we present the approach of introducing thesaurus knowledge into
probabilistic topic models. The main idea of the approach is based on the
assumption that the frequencies of semantically related words and phrases,
which are met in the same texts, should be enhanced: this action leads to their
larger contribution into topics found in these texts. We have conducted
experiments with several thesauri and found that for improving topic models, it
is useful to utilize domain-specific knowledge. If a general thesaurus, such as
WordNet, is used, the thesaurus-based improvement of topic models can be
achieved with excluding hyponymy relations in combined topic models.
</dc:description>
 <dc:description>Comment: Accepted to AIST-2017 conference (http://aistconf.ru/). The final
  publication will be available at link.springer.com</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09817</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recognizing Graphs Close to Bipartite Graphs with an Application to
  Colouring Reconfiguration</dc:title>
 <dc:creator>Bonamy, Marthe</dc:creator>
 <dc:creator>Dabrowski, Konrad K.</dc:creator>
 <dc:creator>Feghali, Carl</dc:creator>
 <dc:creator>Johnson, Matthew</dc:creator>
 <dc:creator>Paulusma, Daniel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We continue research into a well-studied family of problems that ask whether
the vertices of a graph can be partitioned into sets $A$ and~$B$, where $A$ is
an independent set and $B$ induces a graph from some specified graph class
${\cal G}$. We let ${\cal G}$ be the class of $k$-degenerate graphs. This
problem is known to be polynomial-time solvable if $k=0$ (bipartite graphs) and
NP-complete if $k=1$ (near-bipartite graphs) even for graphs of maximum degree
$4$. Yang and Yuan [DM, 2006] showed that the $k=1$ case is polynomial-time
solvable for graphs of maximum degree $3$. This also follows from a result of
Catlin and Lai [DM, 1995]. We consider graphs of maximum degree $k+2$ on $n$
vertices. We show how to find $A$ and $B$ in $O(n)$ time for $k=1$, and in
$O(n^2)$ time for $k\geq 2$. Together, these results provide an algorithmic
version of a result of Catlin [JCTB, 1979] and also provide an algorithmic
version of a generalization of Brook's Theorem, which was proven in a more
general way by Borodin, Kostochka and Toft [DM, 2000] and Matamala [JGT, 2007].
Moreover, the two results enable us to complete the complexity classification
of an open problem of Feghali et al. [JGT, 2016]: finding a path in the vertex
colouring reconfiguration graph between two given $\ell$-colourings of a graph
of maximum degree $k$.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09819</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lossy kernels for connected distance-$r$ domination on nowhere dense
  graph classes</dc:title>
 <dc:creator>Siebertz, Sebastian</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  For $\alpha\colon\mathbb{N}\rightarrow\mathbb{R}$, an $\alpha$-approximate
bi-kernel is a polynomial-time algorithm that takes as input an instance $(I,
k)$ of a problem $Q$ and outputs an instance $(I',k')$ of a problem $Q'$ of
size bounded by a function of $k$ such that, for every $c\geq 1$, a
$c$-approximate solution for the new instance can be turned into a
$c\cdot\alpha(k)$-approximate solution of the original instance in polynomial
time. This framework of \emph{lossy kernelization} was recently introduced by
Lokshtanov et al.
  We prove that for every nowhere dense class of graphs, every $\alpha&gt;1$ and
$r\in\mathbb{N}$ there exists a polynomial $p$ (whose degree depends only on
$r$ while its coefficients depend on $\alpha$) such that the connected
distance-$r$ dominating set problem with parameter $k$ admits an
$\alpha$-approximate bi-kernel of size $p(k)$.
  Furthermore, we show that this result cannot be extended to more general
classes of graphs which are closed under taking subgraphs by showing that if a
class $C$ is somewhere dense and closed under taking subgraphs, then for some
value of $r\in\mathbb{N}$ there cannot exist an $\alpha$-approximate bi-kernel
for the (connected) distance-$r$ dominating set problem on $C$ for any function
$\alpha\colon\mathbb{N}\rightarrow\mathbb{R}$ (assuming the Gap Exponential
Time Hypothesis).
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09823</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Familia: An Open-Source Toolkit for Industrial Topic Modeling</dc:title>
 <dc:creator>Jiang, Di</dc:creator>
 <dc:creator>Chen, Zeyu</dc:creator>
 <dc:creator>Lian, Rongzhong</dc:creator>
 <dc:creator>Bao, Siqi</dc:creator>
 <dc:creator>Li, Chen</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Familia is an open-source toolkit for pragmatic topic modeling in industry.
Familia abstracts the utilities of topic modeling in industry as two paradigms:
semantic representation and semantic matching. Efficient implementations of the
two paradigms are made publicly available for the first time. Furthermore, we
provide off-the-shelf topic models trained on large-scale industrial corpora,
including Latent Dirichlet Allocation (LDA), SentenceLDA and Topical Word
Embedding (TWE). We further describe typical applications which are
successfully powered by topic modeling, in order to ease the confusions and
difficulties of software engineers during topic model selection and
utilization.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09823</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09827</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bias Estimation for Decentralized Sensor Fusion -- Multi-Agent Based
  Bias Estimation Method</dc:title>
 <dc:creator>Furukawa, Hidetoshi</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  In multi-sensor data fusion (or sensor fusion), sensor biases (or offsets)
often affect the accuracy of the correlation and integration results of the
tracking targets. Therefore, to estimate and compensate the bias, several
methods are proposed. However, most methods involve bias estimation and sensor
fusion simultaneously by using Kalman filter after collecting the plot data
together. Hence, these methods cannot support to fuse the track data prepared
by tracking filter at each sensor node. This report proposes the new bias
estimation method based on multi-agent model, in order to estimate and
compensate the bias for decentralized sensor fusion.
</dc:description>
 <dc:description>Comment: Technical Report, 6 pages, in Japanese, Copyright(C)2017 IEICE</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09827</dc:identifier>
 <dc:identifier>IEICE Technical Report, vol.117, no.43, SANE2017-7, pp.35-40, May
  2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09835</identifier>
 <datestamp>2017-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Meta-SGD: Learning to Learn Quickly for Few-Shot Learning</dc:title>
 <dc:creator>Li, Zhenguo</dc:creator>
 <dc:creator>Zhou, Fengwei</dc:creator>
 <dc:creator>Chen, Fei</dc:creator>
 <dc:creator>Li, Hang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Few-shot learning is challenging for learning algorithms that learn each task
in isolation and from scratch. In contrast, meta-learning learns from many
related tasks a meta-learner that can learn a new task more accurately and
faster with fewer examples, where the choice of meta-learners is crucial. In
this paper, we develop Meta-SGD, an SGD-like, easily trainable meta-learner
that can initialize and adapt any differentiable learner in just one step, on
both supervised learning and reinforcement learning. Compared to the popular
meta-learner LSTM, Meta-SGD is conceptually simpler, easier to implement, and
can be learned more efficiently. Compared to the latest meta-learner MAML,
Meta-SGD has a much higher capacity by learning to learn not just the learner
initialization, but also the learner update direction and learning rate, all in
a single meta-learning process. Meta-SGD shows highly competitive performance
for few-shot learning on regression, classification, and reinforcement
learning.
</dc:description>
 <dc:description>Comment: reinforcement learning included, 20-way classification on
  MiniImagenet included</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09837</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Review of Machine Learning Algorithms in Differential Expression
  Analysis</dc:title>
 <dc:creator>Kuznetsova, Irina</dc:creator>
 <dc:creator>Karpievitch, Yuliya V</dc:creator>
 <dc:creator>Filipovska, Aleksandra</dc:creator>
 <dc:creator>Lugmayr, Artur</dc:creator>
 <dc:creator>Holzinger, Andreas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  In biological research machine learning algorithms are part of nearly every
analytical process. They are used to identify new insights into biological
phenomena, interpret data, provide molecular diagnosis for diseases and develop
personalized medicine that will enable future treatments of diseases. In this
paper we (1) illustrate the importance of machine learning in the analysis of
large scale sequencing data, (2) present an illustrative standardized workflow
of the analysis process, (3) perform a Differential Expression (DE) analysis of
a publicly available RNA sequencing (RNASeq) data set to demonstrate the
capabilities of various algorithms at each step of the workflow, and (4) show a
machine learning solution in improving the computing time, storage
requirements, and minimize utilization of computer memory in analyses of
RNA-Seq datasets. The source code of the analysis pipeline and associated
scripts are presented in the paper appendix to allow replication of
experiments.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09837</dc:identifier>
 <dc:identifier>Proc. of the 9th Workshop on Semantic Ambient Media Experiences
  (SAME'2016/2), Visualisation - Emerging Media - and User-Experience, Int.
  Series on Information Systems and Management in Creative eMedia (CreMedia),
  No. 2016/2, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09839</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Superposition de calques monochromes d'opacit\'es variables</dc:title>
 <dc:creator>Bali, Alexandre</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  For a monochrome layer $x$ of opacity $0\le o_x\le1 $ placed on another
monochrome layer of opacity 1, the result given by the standard formula is
$$\small\Pi\left({\bf
C}_\varphi\right)=1+\sum_{n=1}^2\left(2-n-(-1)^no_{\chi(\varphi+1)}\right)\left(\chi(n+\varphi-1)-o_{\chi(n+\varphi-1)}\right),$$
the formula being of course explained in detail in this paper. We will
eventually deduce a very simple theorem, generalize it and then see its
validity with alternative formulas to this standard containing the same main
properties here exposed.
</dc:description>
 <dc:description>Comment: WARNING : Paper written entirely in french. 3 pages</dc:description>
 <dc:date>2017-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09839</dc:identifier>
 <dc:language>fr</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09842</identifier>
 <datestamp>2017-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Domain Adaptation by Geodesic Distance Minimization</dc:title>
 <dc:creator>Wang, Yifei</dc:creator>
 <dc:creator>Li, Wen</dc:creator>
 <dc:creator>Dai, Dengxin</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a new approach called Deep LogCORAL for
unsupervised visual domain adaptation. Our work builds on the recently proposed
Deep CORAL method, which proposed to train a convolutional neural network and
simultaneously minimize the Euclidean distance of convariance matrices between
the source and target domains. We propose to use the Riemannian distance,
approximated by Log-Euclidean distance, to replace the naive Euclidean distance
in Deep CORAL. We also consider first-order information, and minimize the
distance of mean vectors between two domains. We build an end-to-end model, in
which we minimize both the classification loss, and the domain difference based
on the first and second order information between two domains. Our experiments
on the benchmark Office dataset demonstrate the improvements of our newly
proposed Deep LogCORAL approach over the Deep CORAL method, as well as further
improvement when optimizing both orders of information.
</dc:description>
 <dc:date>2017-07-13</dc:date>
 <dc:date>2017-10-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09848</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lempel-Zip Complexity Reference</dc:title>
 <dc:creator>Ruffini, Giulio</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The aim of this note is to provide some reference facts for LZW---mostly from
Thomas and Cover \cite{Cover:2006aa} and provide a reference for some metrics
that can be derived from it. LZW is an algorithm to compute a Kolmogorov
Complexity estimate derived from a limited programming language that only
allows copy and insertion in strings (not Turing complete set). Despite its
delightful simplicity, it is rather powerful and fast. We then focus on
definitions of LZW derived complexity metrics consistent with the notion of
descriptive length, and discuss different normalizations, which result in a set
of metrics we call $\rho_0$, $\rho_1$ and $\rho_2$, in addition to the
Description Length $l_{LZW}$ and the Entropy Rate.
</dc:description>
 <dc:description>Comment: For the Luminous Project (FET Open); Zip file includes Python code
  and Jupiter notebook</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09849</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Classification Approach for Robotic Surgical Tasks Recognition</dc:title>
 <dc:creator>Bani, Mehrdad J.</dc:creator>
 <dc:creator>Jamali, Shoele</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Automatic recognition and classification of tasks in robotic surgery is an
important stepping stone toward automated surgery and surgical training.
Recently, technical breakthroughs in gathering data make data-driven model
development possible. In this paper, we propose a framework for high-level
robotic surgery task recognition using motion data. We present a novel
classification technique that is used to classify three important surgical
tasks through quantitative analyses of motion: knot tying, needle passing and
suturing. The proposed technique integrates state-of-the-art data mining and
time series analysis methods. The first step of this framework consists of
developing a time series distance-based similarity measure using derivative
dynamic time warping (DDTW). The distance-weighted k-nearest neighbor algorithm
was then used to classify task instances. The framework was validated using an
extensive dataset. Our results demonstrate the strength of the proposed
framework in recognizing fundamental robotic surgery tasks.
</dc:description>
 <dc:description>Comment: Submitted to Proceedings of the World Congress on Engineering and
  Computer Science 2017</dc:description>
 <dc:date>2017-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09849</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09850</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CODE-RADE - Community Infrastructure for the Delivery of Physics
  Applications</dc:title>
 <dc:creator>Becker, Bruce</dc:creator>
 <dc:creator>Murray, Sean</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Scientific computing can in some sense be distilled to the execution of an
application - or rather sets of applications which are combined into complex
workflows. Due to the complexity and number both of scientific packages as well
as computing platforms, delivering these applications to end users has always
been a significant challenge through the grid era, and remains so in the cloud
era. In this contribution we describe a platform for user-driven, continuous
integration and delivery of research applications in a distributed environment
- project CODE-RADE. Starting with 6 hypotheses describing the problem at hand,
we put forward technical and social solutions to these. Combining widely-used
and thoroughly-tested tools, we show how it is possible to manage the
dependencies and configurations of a wide range of scientific applications, in
an almost fully-automated way. The CODE-RADE platform is a means for developing
trust between public computing and data infrastructures on the one hand and
various developer and scientific communities on the other hand. Predefined
integration tests are specified for any new application, allowing the system to
be user-driven. This greatly accelerates time-to-production for scientific
applications, while reducing the workload for administrators of HPC, grid and
cloud installations. Finally, we will give some insight into how this platform
could be extended to address issues of reproducibility and collaboration in
scientific research in Africa.
</dc:description>
 <dc:description>Comment: Article submitted to SAIP 2016</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09850</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09855</identifier>
 <datestamp>2017-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolution with Logarithmic Filter Groups for Efficient Shallow CNN</dc:title>
 <dc:creator>Lee, Tae Kwan</dc:creator>
 <dc:creator>Baddar, Wissam J.</dc:creator>
 <dc:creator>Kim, Seong Tae</dc:creator>
 <dc:creator>Ro, Yong Man</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In convolutional neural networks (CNNs), the filter grouping in convolution
layers is known to be useful to reduce the network parameter size. In this
paper, we propose a new logarithmic filter grouping which can capture the
nonlinearity of filter distribution in CNNs. The proposed logarithmic filter
grouping is installed in shallow CNNs applicable in a mobile application.
Experiments were performed with the shallow CNNs for classification tasks. Our
classification results on Multi-PIE dataset for facial expression recognition
and CIFAR-10 dataset for object classification reveal that the compact CNN with
the proposed logarithmic filter grouping scheme outperforms the same network
with the uniform filter grouping in terms of accuracy and parameter efficiency.
Our results indicate that the efficiency of shallow CNNs can be improved by the
proposed logarithmic filter grouping.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures, 3 tables. Changes in abstract, result
  representations and typo corrections</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09858</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatially variant PSF modeling in confocal macroscopy</dc:title>
 <dc:creator>Jezierska, Anna</dc:creator>
 <dc:creator>Talbot, Hugues</dc:creator>
 <dc:creator>Pesquet, Jean-Christophe</dc:creator>
 <dc:creator>Engler, Gilbert</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Point spread function (PSF) plays an essential role in image reconstruction.
In the context of confocal microscopy, optical performance degrades towards the
edge of the field of view as astigmatism, coma and vignetting. Thus, one should
expect the related artifacts to be even stronger in macroscopy, where the field
of view is much larger. The field aberrations in macroscopy fluorescence
imaging system was observed to be symmetrical and to increase with the distance
from the center of the field of view. In this paper we propose an experiment
and an optimization method for assessing the center of the field of view. The
obtained results constitute a step towards reducing the number of parameters in
macroscopy PSF model.
</dc:description>
 <dc:date>2017-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09858</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09861</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reporting Score Distributions Makes a Difference: Performance Study of
  LSTM-networks for Sequence Tagging</dc:title>
 <dc:creator>Reimers, Nils</dc:creator>
 <dc:creator>Gurevych, Iryna</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper we show that reporting a single performance score is
insufficient to compare non-deterministic approaches. We demonstrate for common
sequence tagging tasks that the seed value for the random number generator can
result in statistically significant (p &lt; 10^-4) differences for
state-of-the-art systems. For two recent systems for NER, we observe an
absolute difference of one percentage point F1-score depending on the selected
seed value, making these systems perceived either as state-of-the-art or
mediocre. Instead of publishing and reporting single performance scores, we
propose to compare score distributions based on multiple executions. Based on
the evaluation of 50.000 LSTM-networks for five sequence tagging tasks, we
present network architectures that produce both superior performance as well as
are more stable with respect to the remaining hyperparameters.
</dc:description>
 <dc:description>Comment: Accepted at EMNLP 2017</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09862</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Iterative Manifold Embedding Layer Learned by Incomplete Data for
  Large-scale Image Retrieval</dc:title>
 <dc:creator>Xu, Jian</dc:creator>
 <dc:creator>Wang, Chunheng</dc:creator>
 <dc:creator>Qi, Chengzuo</dc:creator>
 <dc:creator>Shi, Cunzhao</dc:creator>
 <dc:creator>Xiao, Baihua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Existing manifold learning methods are not appropriate for image retrieval
task, because most of them are unable to process query image and they have much
additional computational cost especially for large scale database. Therefore,
we propose the iterative manifold embedding (IME) layer, of which the weights
are learned off-line by unsupervised strategy, to explore the intrinsic
manifolds by incomplete data. On the large scale database that contains 27000
images, IME layer is more than 120 times faster than other manifold learning
methods to embed the original representations at query time. We embed the
original descriptors of database images which lie on manifold in a high
dimensional space into manifold-based representations iteratively to generate
the IME representations in off-line learning stage. According to the original
descriptors and the IME representations of database images, we estimate the
weights of IME layer by ridge regression. In on-line retrieval stage, we employ
the IME layer to map the original representation of query image with ignorable
time cost (2 milliseconds). We experiment on five public standard datasets for
image retrieval. The proposed IME layer significantly outperforms related
dimension reduction methods and manifold learning methods. Without
post-processing, Our IME layer achieves a boost in performance of
state-of-the-art image retrieval methods with post-processing on most datasets,
and needs less computational cost.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures</dc:description>
 <dc:date>2017-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09862</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09863</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dimensionality reduction of SDPs through sketching</dc:title>
 <dc:creator>Bluhm, Andreas</dc:creator>
 <dc:creator>Franca, Daniel Stilck</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We show how to sketch semidefinite programs (SDPs) using positive maps in
order to reduce their dimension. More precisely, we use Johnson-Lindenstrauss
transforms to produce a smaller SDP whose solution preserves feasibility or
approximates the value of the original problem with high probability. These
techniques allow to improve both complexity and storage space requirements.
They apply to problems in which the Schatten 1-norm of the matrices specifying
the SDP and of a solution to the problem is constant in the problem size.
Furthermore, we provide some no-go results which clarify the limitations of
positive, linear sketches in this setting. Finally, we discuss numerical
examples to benchmark our methods.
</dc:description>
 <dc:description>Comment: 32 pages, 2 tables</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09863</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09864</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalizing the Convolution Operator in Convolutional Neural Networks</dc:title>
 <dc:creator>Ghiasi-Shirazi, Kamaledin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural networks have become a main tool for solving many
machine vision and machine learning problems. A major element of these networks
is the convolution operator which essentially computes the inner product
between a weight vector and the vectorized image patches extracted by sliding a
window in the image planes of the previous layer. In this paper, we propose two
classes of surrogate functions for the inner product operation inherent in the
convolution operator and so attain two generalizations of the convolution
operator. The first one is the class of positive definite kernel functions
where their application is justified by the kernel trick. The second one is the
class of similarity measures defined based on a distance function. We justify
this by tracing back to the basic idea behind the neocognitron which is the
ancestor of CNNs. Both methods are then further generalized by allowing a
monotonically increasing function to be applied subsequently. Like any
trainable parameter in a neural network, the template pattern and the
parameters of the kernel/distance function are trained with the
back-propagation algorithm. As an aside, we use the proposed framework to
justify the use of sine activation function in CNNs. Our experiments on the
MNIST dataset show that the performance of ordinary CNNs can be achieved by
generalized CNNs based on weighted L1/L2 distances, proving the applicability
of the proposed generalization of the convolutional neural networks.
</dc:description>
 <dc:date>2017-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09865</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Remote sensing of forests using discrete return airborne LiDAR</dc:title>
 <dc:creator>Hamraz, Hamid</dc:creator>
 <dc:creator>Contreras, Marco A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Airborne discrete return light detection and ranging (LiDAR) point clouds
covering forested areas can be processed to segment individual trees and
retrieve their morphological attributes. Segmenting individual trees in natural
deciduous forests however remained a challenge because of the complex and
multi-layered canopy. In this chapter, we present (i) a robust segmentation
method that avoids a priori assumptions about the canopy structure, (ii) a
vertical canopy stratification procedure that improves segmentation of
understory trees, (iii) an occlusion model for estimating the point density of
each canopy stratum, and (iv) a distributed computing approach for efficient
processing at the forest level. When applied to the University of Kentucky
Robinson Forest, the segmentation method detected about 90% of overstory and
47% of understory trees with over-segmentation rates of 14% and 2%. Stratifying
the canopy improved the detection rate of understory trees to 68% at the cost
of increasing their over-segmentations to 16%. According to our occlusion
model, a point density of ~170 pt/m-sqr is needed to segment understory trees
as accurately as overstory trees. Lastly, using the distributed approach, we
segmented about two million trees in the 7,440-ha forest in 2.5 hours using 192
processors, which is 167 times faster than using a single processor. Keywords:
individual tree segmentation, multi-layered stand, vertical canopy
stratification, segmentation evaluation, point density, canopy occlusion
effect, big data, distributed computing.
</dc:description>
 <dc:description>Comment: This manuscript is a book chapter that has provisionally been
  accepted to be published in &quot;Recent Advances and Applications in Remote
  Sensing&quot;, ISBN 978-953-51-5564-5. Ed.: Hung, Ming Cheh. InTechOpen. The
  chapter summarizes novel methods from four recently published journal ppapers
  by the authors in a concise and cohesive manner</dc:description>
 <dc:date>2017-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09865</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09866</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guided Co-training for Large-Scale Multi-View Spectral Clustering</dc:title>
 <dc:creator>Liu, Tyng-Luh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In many real-world applications, we have access to multiple views of the
data, each of which characterizes the data from a distinct aspect. Several
previous algorithms have demonstrated that one can achieve better clustering
accuracy by integrating information from all views appropriately than using
only an individual view. Owing to the effectiveness of spectral clustering,
many multi-view clustering methods are based on it. Unfortunately, they have
limited applicability to large-scale data due to the high computational
complexity of spectral clustering. In this work, we propose a novel multi-view
spectral clustering method for large-scale data. Our approach is structured
under the guided co-training scheme to fuse distinct views, and uses the
sampling technique to accelerate spectral clustering. More specifically, we
first select $p$ ($\ll n$) landmark points and then approximate the
eigen-decomposition accordingly. The augmented view, which is essential to
guided co-training process, can then be quickly determined by our method. The
proposed algorithm scales linearly with the number of given data. Extensive
experiments have been performed and the results support the advantage of our
method for handling the large-scale multi-view situation.
</dc:description>
 <dc:date>2017-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09867</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unmixing dynamic PET images with variable specific binding kinetics</dc:title>
 <dc:creator>Cavalcanti, Yanna Cruz</dc:creator>
 <dc:creator>Oberlin, Thomas</dc:creator>
 <dc:creator>Dobigeon, Nicolas</dc:creator>
 <dc:creator>Stute, Simon</dc:creator>
 <dc:creator>Ribeiro, Maria</dc:creator>
 <dc:creator>Tauber, Clovis</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  To analyze dynamic positron emission tomography (PET) images, various generic
multivariate data analysis techniques have been considered in the literature,
such as principal component analysis (PCA), independent component analysis
(ICA), factor analysis and nonnegative matrix factorization (NMF).
Nevertheless, these conventional approaches neglect any possible nonlinear
variations in the time activity curves describing the kinetic behavior of
tissues with specific binding, which limits their ability to recover a
reliable, understandable and interpretable description of the data. This paper
proposes an alternative analysis paradigm that accounts for spatial
fluctuations in the exchange rate of the tracer between a free compartment and
a specifically bound ligand compartment. The method relies on the concept of
linear unmixing, usually applied on the hyperspectral domain, which combines
NMF with a sum-to-one constraint that ensures an exhaustive description of the
mixtures. The spatial variability of the signature corresponding to the
specific binding tissue is explicitly modeled through a perturbed component.
The performance of the method is assessed on both synthetic and real data and
is shown to compete favorably when compared to other conventional analysis
methods. The proposed method improved both factor estimation and proportions
extraction for specific binding. Modeling the variability of the specific
binding factor has a strong potential impact for dynamic PET image analysis.
</dc:description>
 <dc:date>2017-07-19</dc:date>
 <dc:date>2017-12-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09869</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A comment on the paper Prediction of Kidney Function from Biopsy Images
  using Convolutional Neural Networks</dc:title>
 <dc:creator>dos-Santos, Washington LC</dc:creator>
 <dc:creator>Duarte, Angelo A</dc:creator>
 <dc:creator>de Freitas, Luiz AR</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This letter presente a comment on the paper Prediction of Kidney Function
from Biopsy Images using Convolutional Neural Networks by Ledbetter et al.
(2017)
</dc:description>
 <dc:description>Comment: 2 pages, 1 figure</dc:description>
 <dc:date>2017-07-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09869</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09870</identifier>
 <datestamp>2017-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extremely Low Bit Neural Network: Squeeze the Last Bit Out with ADMM</dc:title>
 <dc:creator>Leng, Cong</dc:creator>
 <dc:creator>Li, Hao</dc:creator>
 <dc:creator>Zhu, Shenghuo</dc:creator>
 <dc:creator>Jin, Rong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Although deep learning models are highly effective for various learning
tasks, their high computational costs prohibit the deployment to scenarios
where either memory or computational resources are limited. In this paper, we
focus on compressing and accelerating deep models with network weights
represented by very small numbers of bits, referred to as extremely low bit
neural network. We model this problem as a discretely constrained optimization
problem. Borrowing the idea from Alternating Direction Method of Multipliers
(ADMM), we decouple the continuous parameters from the discrete constraints of
network, and cast the original hard problem into several subproblems. We
propose to solve these subproblems using extragradient and iterative
quantization algorithms that lead to considerably faster convergency compared
to conventional optimization methods. Extensive experiments on image
recognition and object detection verify that the proposed algorithm is more
effective than state-of-the-art approaches when coming to extremely low bit
neural network.
</dc:description>
 <dc:date>2017-07-24</dc:date>
 <dc:date>2017-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09870</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09871</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Extraction via Recurrent Random Deep Ensembles and its
  Application in Gruop-level Happiness Estimation</dc:title>
 <dc:creator>Tang, Shitao</dc:creator>
 <dc:creator>Pan, Yichen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper presents a novel ensemble framework to extract highly
discriminative feature representation of image and its application for
group-level happpiness intensity prediction in wild. In order to generate
enough diversity of decisions, n convolutional neural networks are trained by
bootstrapping the training set and extract n features for each image from them.
A recurrent neural network (RNN) is then used to remember which network
extracts better feature and generate the final feature representation for one
individual image. Several group emotion models (GEM) are used to aggregate face
fea- tures in a group and use parameter-optimized support vector regressor
(SVR) to get the final results. Through extensive experiments, the great
effectiveness of the proposed recurrent random deep ensembles (RRDE) is
demonstrated in both structural and decisional ways. The best result yields a
0.55 root-mean-square error (RMSE) on validation set of HAPPEI dataset,
significantly better than the baseline of 0.78.
</dc:description>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09871</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09872</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Full-Network Embedding in a Multimodal Embedding Pipeline</dc:title>
 <dc:creator>Vilalta, Armand</dc:creator>
 <dc:creator>Garcia-Gasulla, Dario</dc:creator>
 <dc:creator>Par&#xe9;s, Ferran</dc:creator>
 <dc:creator>Ayguad&#xe9;, Eduard</dc:creator>
 <dc:creator>Labarta, Jesus</dc:creator>
 <dc:creator>Cort&#xe9;s, Ulises</dc:creator>
 <dc:creator>Suzumura, Toyotaro</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The current state-of-the-art for image annotation and image retrieval tasks
is obtained through deep neural networks, which combine an image representation
and a text representation into a shared embedding space. In this paper we
evaluate the impact of using the Full-Network embedding in this setting,
replacing the original image representation in a competitive multimodal
embedding generation scheme. Unlike the one-layer image embeddings typically
used by most approaches, the Full-Network embedding provides a multi-scale
representation of images, which results in richer characterizations. To measure
the influence of the Full-Network embedding, we evaluate its performance on
three different datasets, and compare the results with the original multimodal
embedding generation scheme when using a one-layer image embedding, and with
the rest of the state-of-the-art. Results for image annotation and image
retrieval tasks indicate that the Full-Network embedding is consistently
superior to the one-layer embedding. These results motivate the integration of
the Full-Network embedding on any multimodal embedding generation scheme,
something feasible thanks to the flexibility of the approach.
</dc:description>
 <dc:description>Comment: In 2nd Workshop on Semantic Deep Learning (SemDeep-2) at the 12th
  International Conference on Computational Semantics (IWCS) 2017</dc:description>
 <dc:date>2017-07-24</dc:date>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09873</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representation Learning on Large and Small Data</dc:title>
 <dc:creator>Chou, Chun-Nan</dc:creator>
 <dc:creator>Shie, Chuen-Kai</dc:creator>
 <dc:creator>Chang, Fu-Chieh</dc:creator>
 <dc:creator>Chang, Jocelyn</dc:creator>
 <dc:creator>Chang, Edward Y.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning owes its success to three key factors: scale of data, enhanced
models to learn representations from data, and scale of computation. This book
chapter presented the importance of the data-driven approach to learn good
representations from both big data and small data. In terms of big data, it has
been widely accepted in the research community that the more data the better
for both representation and classification improvement. The question is then
how to learn representations from big data, and how to perform representation
learning when data is scarce. We addressed the first question by presenting CNN
model enhancements in the aspects of representation, optimization, and
generalization. To address the small data challenge, we showed transfer
representation learning to be effective. Transfer representation learning
transfers the learned representation from a source domain where abundant
training data is available to a target domain where training data is scarce.
Transfer representation learning gave the OM and melanoma diagnosis modules of
our XPRIZE Tricorder device (which finished $2^{nd}$ out of $310$ competing
teams) a significant boost in diagnosis accuracy.
</dc:description>
 <dc:description>Comment: Book chapter</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09873</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09875</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SAR Target Recognition Using the Multi-aspect-aware Bidirectional LSTM
  Recurrent Neural Networks</dc:title>
 <dc:creator>Zhang, Fan</dc:creator>
 <dc:creator>Hu, Chen</dc:creator>
 <dc:creator>Yin, Qiang</dc:creator>
 <dc:creator>Li, Wei</dc:creator>
 <dc:creator>Li, Hengchao</dc:creator>
 <dc:creator>Hong, Wen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The outstanding pattern recognition performance of deep learning brings new
vitality to the synthetic aperture radar (SAR) automatic target recognition
(ATR). However, there is a limitation in current deep learning based ATR
solution that each learning process only handle one SAR image, namely learning
the static scattering information, while missing the space-varying information.
It is obvious that multi-aspect joint recognition introduced space-varying
scattering information should improve the classification accuracy and
robustness. In this paper, a novel multi-aspect-aware method is proposed to
achieve this idea through the bidirectional Long Short-Term Memory (LSTM)
recurrent neural networks based space-varying scattering information learning.
Specifically, we first select different aspect images to generate the
multi-aspect space-varying image sequences. Then, the Gabor filter and
three-patch local binary pattern (TPLBP) are progressively implemented to
extract a comprehensive spatial features, followed by dimensionality reduction
with the Multi-layer Perceptron (MLP) network. Finally, we design a
bidirectional LSTM recurrent neural network to learn the multi-aspect features
with further integrating the softmax classifier to achieve target recognition.
Experimental results demonstrate that the proposed method can achieve 99.9%
accuracy for 10-class recognition. Besides, its anti-noise and anti-confusion
performance are also better than the conventional deep learning based methods.
</dc:description>
 <dc:description>Comment: 11 pages, 10 figures</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09875</dc:identifier>
 <dc:identifier>IEEE Access, vol.5, 2017</dc:identifier>
 <dc:identifier>doi:10.1109/ACCESS.2017.2773363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09879</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linguistically Motivated Vocabulary Reduction for Neural Machine
  Translation from Turkish to English</dc:title>
 <dc:creator>Ataman, Duygu</dc:creator>
 <dc:creator>Negri, Matteo</dc:creator>
 <dc:creator>Turchi, Marco</dc:creator>
 <dc:creator>Federico, Marcello</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The necessity of using a fixed-size word vocabulary in order to control the
model complexity in state-of-the-art neural machine translation (NMT) systems
is an important bottleneck on performance, especially for morphologically rich
languages. Conventional methods that aim to overcome this problem by using
sub-word or character-level representations solely rely on statistics and
disregard the linguistic properties of words, which leads to interruptions in
the word structure and causes semantic and syntactic losses. In this paper, we
propose a new vocabulary reduction method for NMT, which can reduce the
vocabulary of a given input corpus at any rate while also considering the
morphological properties of the language. Our method is based on unsupervised
morphology learning and can be, in principle, used for pre-processing any
language pair. We also present an alternative word segmentation method based on
supervised morphological analysis, which aids us in measuring the accuracy of
our model. We evaluate our method in Turkish-to-English NMT task where the
input language is morphologically rich and agglutinative. We analyze different
representation methods in terms of translation accuracy as well as the semantic
and syntactic properties of the generated output. Our method obtains a
significant improvement of 2.3 BLEU points over the conventional vocabulary
reduction technique, showing that it can provide better accuracy in open
vocabulary translation of morphologically rich languages.
</dc:description>
 <dc:description>Comment: The 20th Annual Conference of the European Association for Machine
  Translation (EAMT), Research Paper, 12 pages</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09879</dc:identifier>
 <dc:identifier>The Prague Bulletin of Mathematical Linguistics. No. 108, 2017,
  pp. 331-342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09887</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Audio - Sheet Music Correspondences for Score Identification
  and Offline Alignment</dc:title>
 <dc:creator>Dorfer, Matthias</dc:creator>
 <dc:creator>Arzt, Andreas</dc:creator>
 <dc:creator>Widmer, Gerhard</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  This work addresses the problem of matching short excerpts of audio with
their respective counterparts in sheet music images. We show how to employ
neural network-based cross-modality embedding spaces for solving the following
two sheet music-related tasks: retrieving the correct piece of sheet music from
a database when given a music audio as a search query; and aligning an audio
recording of a piece with the corresponding images of sheet music. We
demonstrate the feasibility of this in experiments on classical piano music by
five different composers (Bach, Haydn, Mozart, Beethoven and Chopin), and
additionally provide a discussion on why we expect multi-modal neural networks
to be a fruitful paradigm for dealing with sheet music and audio at the same
time.
</dc:description>
 <dc:description>Comment: In Proceedings of the 18th International Society for Music
  Information Retrieval Conference (ISMIR 2017)</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09890</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bearing fault diagnosis under varying working condition based on domain
  adaptation</dc:title>
 <dc:creator>Zhang, Bo</dc:creator>
 <dc:creator>Li, Wei</dc:creator>
 <dc:creator>Tong, Zhe</dc:creator>
 <dc:creator>Zhang, Meng</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Traditional intelligent fault diagnosis of rolling bearings work well only
under a common assumption that the labeled training data (source domain) and
unlabeled testing data (target domain) are drawn from the same distribution.
When the distribution changes, most fault diagnosis models need to be rebuilt
from scratch using newly recollected labeled training data. However, it is
expensive or impossible to annotate huge amount of training data to rebuild
such new model. Meanwhile, large amounts of labeled training data have not been
fully utilized yet, which is apparently a waste of resources. As one of the
important research directions of transfer learning, domain adaptation (DA)
typically aims at minimizing the differences between distributions of different
domains in order to minimize the cross-domain prediction error by taking full
advantage of information coming from both source and target domains. In this
paper, we present one of the first studies on unsupervised DA in the field of
fault diagnosis of rolling bearings under varying working conditions and a
novel diagnosis strategy based on unsupervised DA using subspace alignment (SA)
is proposed. After processed by unsupervised DA with SA, the distributions of
training data and testing data become close and the classifier trained on
training data can be used to classify the testing data. Experimental results on
the 60 domain adaptation diagnosis problems under varying working condition in
Case Western Reserve benchmark data and 12 domain adaptation diagnosis problems
under varying working conditions in our new data are given to demonstrate the
effectiveness of the proposed method. The proposed methods can effectively
distinguish not only bearing faults categories but also fault severities.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09890</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09893</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Privacy-Preserving Perceptron</dc:title>
 <dc:creator>Ying, Shenggang</dc:creator>
 <dc:creator>Ying, Mingsheng</dc:creator>
 <dc:creator>Feng, Yuan</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  With the extensive applications of machine learning, the issue of private or
sensitive data in the training examples becomes more and more serious: during
the training process, personal information or habits may be disclosed to
unexpected persons or organisations, which can cause serious privacy problems
or even financial loss. In this paper, we present a quantum privacy-preserving
algorithm for machine learning with perceptron. There are mainly two steps to
protect original training examples. Firstly when checking the current
classifier, quantum tests are employed to detect data user's possible
dishonesty. Secondly when updating the current classifier, private random noise
is used to protect the original data. The advantages of our algorithm are: (1)
it protects training examples better than the known classical methods; (2) it
requires no quantum database and thus is easy to implement.
</dc:description>
 <dc:description>Comment: 30 pages,5 figures</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09893</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09899</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fashioning with Networks: Neural Style Transfer to Design Clothes</dc:title>
 <dc:creator>Date, Prutha</dc:creator>
 <dc:creator>Ganesan, Ashwinkumar</dc:creator>
 <dc:creator>Oates, Tim</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Convolutional Neural Networks have been highly successful in performing a
host of computer vision tasks such as object recognition, object detection,
image segmentation and texture synthesis. In 2015, Gatys et. al [7] show how
the style of a painter can be extracted from an image of the painting and
applied to another normal photograph, thus recreating the photo in the style of
the painter. The method has been successfully applied to a wide range of images
and has since spawned multiple applications and mobile apps. In this paper, the
neural style transfer algorithm is applied to fashion so as to synthesize new
custom clothes. We construct an approach to personalize and generate new custom
clothes based on a users preference and by learning the users fashion choices
from a limited set of clothes from their closet. The approach is evaluated by
analyzing the generated images of clothes and how well they align with the
users fashion style.
</dc:description>
 <dc:description>Comment: ML4Fashion 2017</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09899</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09904</identifier>
 <datestamp>2017-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Hierarchical Clustering</dc:title>
 <dc:creator>Dey, Tamal K.</dc:creator>
 <dc:creator>Rossi, Alfred</dc:creator>
 <dc:creator>Sidiropoulos, Anastasios</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.5.3</dc:subject>
 <dc:description>  We study hierarchical clusterings of metric spaces that change over time.
This is a natural geometric primitive for the analysis of dynamic data sets.
Specifically, we introduce and study the problem of finding a temporally
coherent sequence of hierarchical clusterings from a sequence of unlabeled
point sets. We encode the clustering objective by embedding each point set into
an ultrametric space, which naturally induces a hierarchical clustering of the
set of points. We enforce temporal coherence among the embeddings by finding
correspondences between successive pairs of ultrametric spaces which exhibit
small distortion in the Gromov-Hausdorff sense. We present both upper and lower
bounds on the approximability of the resulting optimization problems.
</dc:description>
 <dc:description>Comment: 14 pages, 4 figures</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-10-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09905</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Discrete Supervised Hashing</dc:title>
 <dc:creator>Jiang, Qing-Yuan</dc:creator>
 <dc:creator>Cui, Xue</dc:creator>
 <dc:creator>Li, Wu-Jun</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Hashing has been widely used for large-scale search due to its low storage
cost and fast query speed. By using supervised information, supervised hashing
can significantly outperform unsupervised hashing. Recently, discrete
supervised hashing and deep hashing are two representative progresses in
supervised hashing. On one hand, hashing is essentially a discrete optimization
problem. Hence, utilizing supervised information to directly guide discrete
(binary) coding procedure can avoid sub-optimal solution and improve the
accuracy. On the other hand, deep hashing, which integrates deep feature
learning and hash-code learning into an end-to-end architecture, can enhance
the feedback between feature learning and hash-code learning. The key in
discrete supervised hashing is to adopt supervised information to directly
guide the discrete coding procedure in hashing. The key in deep hashing is to
adopt the supervised information to directly guide the deep feature learning
procedure. However, there have not existed works which can use the supervised
information to directly guide both discrete coding procedure and deep feature
learning procedure in the same framework. In this paper, we propose a novel
deep hashing method, called deep discrete supervised hashing (DDSH), to address
this problem. DDSH is the first deep hashing method which can utilize
supervised information to directly guide both discrete coding procedure and
deep feature learning procedure, and thus enhance the feedback between these
two important procedures. Experiments on three real datasets show that DDSH can
outperform other state-of-the-art baselines, including both discrete hashing
and deep hashing baselines, for image retrieval.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09916</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Private Information Retrieval on Coded Data</dc:title>
 <dc:creator>Tajeddine, Razane</dc:creator>
 <dc:creator>Rouayheb, Salim El</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of designing PIR scheme on coded data when certain
nodes are unresponsive. We provide the construction of $\nu$-robust PIR schemes
that can tolerate up to $\nu$ unresponsive nodes. These schemes are adaptive
and universally optimal in the sense of achieving (asymptotically) optimal
download cost for any number of unresponsive nodes up to $\nu$.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09917</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A breakthrough in Speech emotion recognition using Deep Retinal
  Convolution Neural Networks</dc:title>
 <dc:creator>Niu, Yafeng</dc:creator>
 <dc:creator>Zou, Dongsheng</dc:creator>
 <dc:creator>Niu, Yadong</dc:creator>
 <dc:creator>He, Zhongshi</dc:creator>
 <dc:creator>Tan, Hua</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Speech emotion recognition (SER) is to study the formation and change of
speaker's emotional state from the speech signal perspective, so as to make the
interaction between human and computer more intelligent. SER is a challenging
task that has encountered the problem of less training data and low prediction
accuracy. Here we propose a data augmentation algorithm based on the imaging
principle of the retina and convex lens, to acquire the different sizes of
spectrogram and increase the amount of training data by changing the distance
between the spectrogram and the convex lens. Meanwhile, with the help of deep
learning to get the high-level features, we propose the Deep Retinal
Convolution Neural Networks (DRCNNs) for SER and achieve the average accuracy
over 99%. The experimental results indicate that DRCNNs outperforms the
previous studies in terms of both the number of emotions and the accuracy of
recognition. Predictably, our results will dramatically improve human-computer
interaction.
</dc:description>
 <dc:date>2017-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09917</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09920</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regularization techniques for fine-tuning in neural machine translation</dc:title>
 <dc:creator>Barone, Antonio Valerio Miceli</dc:creator>
 <dc:creator>Haddow, Barry</dc:creator>
 <dc:creator>Germann, Ulrich</dc:creator>
 <dc:creator>Sennrich, Rico</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We investigate techniques for supervised domain adaptation for neural machine
translation where an existing model trained on a large out-of-domain dataset is
adapted to a small in-domain dataset. In this scenario, overfitting is a major
challenge. We investigate a number of techniques to reduce overfitting and
improve transfer learning, including regularization techniques such as dropout
and L2-regularization towards an out-of-domain prior. In addition, we introduce
tuneout, a novel regularization technique inspired by dropout. We apply these
techniques, alone and in combination, to neural machine translation, obtaining
improvements on IWSLT datasets for English-&gt;German and English-&gt;Russian. We
also investigate the amounts of in-domain training data needed for domain
adaptation in NMT, and find a logarithmic relationship between the amount of
training data and gain in BLEU score.
</dc:description>
 <dc:description>Comment: EMNLP 2017 short paper; for bibtex, see
  http://homepages.inf.ed.ac.uk/rsennric/bib.html#micelibarone2017b</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09926</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for Super-Resolution of Scalable Video via Sparse
  Reconstruction of Residual Frames</dc:title>
 <dc:creator>Moghaddam, Mohammad Hossein</dc:creator>
 <dc:creator>Azizipour, Mohammad Javad</dc:creator>
 <dc:creator>Vahidian, Saeed</dc:creator>
 <dc:creator>Smida, Besma</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper introduces a framework for super-resolution of scalable video
based on compressive sensing and sparse representation of residual frames in
reconnaissance and surveillance applications. We exploit efficient compressive
sampling and sparse reconstruction algorithms to super-resolve the video
sequence with respect to different compression rates. We use the sparsity of
residual information in residual frames as the key point in devising our
framework. Moreover, a controlling factor as the compressibility threshold to
control the complexity-performance trade-off is defined. Numerical experiments
confirm the efficiency of the proposed framework in terms of the compression
rate as well as the quality of reconstructed video sequence in terms of PSNR
measure. The framework leads to a more efficient compression rate and higher
video quality compared to other state-of-the-art algorithms considering
performance-complexity trade-offs.
</dc:description>
 <dc:description>Comment: IEEE Military Communications Conference, MILCOM, 2017</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09926</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09930</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Debugging Transactions and Tracking their Provenance with Reenactment</dc:title>
 <dc:creator>Niu, Xing</dc:creator>
 <dc:creator>Arab, Bahareh Sadat</dc:creator>
 <dc:creator>Lee, Seokki</dc:creator>
 <dc:creator>Feng, Su</dc:creator>
 <dc:creator>Zou, Xun</dc:creator>
 <dc:creator>Gawlick, Dieter</dc:creator>
 <dc:creator>Krishnaswamy, Vasudha</dc:creator>
 <dc:creator>Liu, Zhen Hua</dc:creator>
 <dc:creator>Glavic, Boris</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>H.2</dc:subject>
 <dc:description>  Debugging transactions and understanding their execution are of immense
importance for developing OLAP applications, to trace causes of errors in
production systems, and to audit the operations of a database. However,
debugging transactions is hard for several reasons: 1) after the execution of a
transaction, its input is no longer available for debugging, 2) internal states
of a transaction are typically not accessible, and 3) the execution of a
transaction may be affected by concurrently running transactions. We present a
debugger for transactions that enables non-invasive, post-mortem debugging of
transactions with provenance tracking and supports what-if scenarios (changes
to transaction code or data). Using reenactment, a declarative replay technique
we have developed, a transaction is replayed over the state of the DB seen by
its original execution including all its interactions with concurrently
executed transactions from the history. Importantly, our approach uses the
temporal database and audit logging capabilities available in many DBMS and
does not require any modifications to the underlying database system nor
transactional workload.
</dc:description>
 <dc:description>Comment: to appear as &quot;Debugging Transactions and Tracking their Provenance
  with Reenactment&quot; in PVDLB 2017, vol 10., nr. 12</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09930</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09933</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Neural Network Classifiers with Low Model Complexity</dc:title>
 <dc:creator>Jayadeva</dc:creator>
 <dc:creator>Pant, Himanshu</dc:creator>
 <dc:creator>Sharma, Mayank</dc:creator>
 <dc:creator>Dubey, Abhimanyu</dc:creator>
 <dc:creator>Soman, Sumit</dc:creator>
 <dc:creator>Tripathi, Suraj</dc:creator>
 <dc:creator>Guruju, Sai</dc:creator>
 <dc:creator>Goalla, Nihal</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>68T05, 68T10, 68Q32</dc:subject>
 <dc:description>  Modern neural network architectures for large-scale learning tasks have
substantially higher model complexities, which makes understanding, visualizing
and training these architectures difficult. Recent contributions to deep
learning techniques have focused on architectural modifications to improve
parameter efficiency and performance. In this paper, we derive a continuous and
differentiable error functional for a neural network that minimizes its
empirical error as well as a measure of the model complexity. The latter
measure is obtained by deriving a differentiable upper bound on the
Vapnik-Chervonenkis (VC) dimension of the classifier layer of a class of deep
networks. Using standard backpropagation, we realize a training rule that tries
to minimize the error on training samples, while improving generalization by
keeping the model complexity low. We demonstrate the effectiveness of our
formulation (the Low Complexity Neural Network - LCNN) across several deep
learning algorithms, and a variety of large benchmark datasets. We show that
hidden layer neurons in the resultant networks learn features that are crisp,
and in the case of image datasets, quantitatively sharper. Our proposed
approach yields benefits across a wide range of architectures, in comparison to
and in conjunction with methods such as Dropout and Batch Normalization, and
our results strongly suggest that deep learning techniques can benefit from
model complexity control methods such as the LCNN learning rule.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2018-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09933</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09938</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wavelet Residual Network for Low-Dose CT via Deep Convolutional
  Framelets</dc:title>
 <dc:creator>Kang, Eunhee</dc:creator>
 <dc:creator>Yoo, Jaejun</dc:creator>
 <dc:creator>Ye, Jong Chul</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Model based iterative reconstruction (MBIR) algorithms for low-dose X-ray CT
are computationally expensive. To address this problem, we recently proposed
the world-first deep convolutional neural network (CNN) for low-dose X-ray CT
and won the second place in 2016 AAPM Low-Dose CT Grand Challenge. However,
some of the texture were not fully recovered. To cope with this problem, here
we propose a deep residual learning approach in directional wavelet domain. The
proposed method is motivated by an observation that a deep convolutional neural
network can be interpreted as a multilayer convolutional framelets expansion
using non-local basis convolved with data-driven local basis. We further extend
the idea to derive a deep convolutional framelet expansion by combining global
redundant transforms and signal boosting from multiple signal representations.
Extensive experimental results confirm that the proposed network has
significantly improved performance and preserves the detail texture of the
original images
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09938</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09939</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Analysis of the Twitter Discussion on the 2016 Austrian Presidential
  Elections</dc:title>
 <dc:creator>Ku&#x161;en, Ema</dc:creator>
 <dc:creator>Strembeck, Mark</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  In this paper, we provide a systematic analysis of the Twitter discussion on
the 2016 Austrian presidential elections. In particular, we extracted and
analyzed a data-set consisting of 343645 Twitter messages related to the 2016
Austrian presidential elections. Our analysis combines methods from network
science, sentiment analysis, as well as bot detection. Among other things, we
found that: a) the winner of the election (Alexander Van der Bellen) was
considerably more popular and influential on Twitter than his opponent, b) the
Twitter followers of Van der Bellen substantially participated in the spread of
misinformation about him, c) there was a clear polarization in terms of the
sentiments spread by Twitter followers of the two presidential candidates, d)
the in-degree and out-degree distributions of the underlying communication
network are heavy-tailed, and e) compared to other recent events, such as the
2016 Brexit referendum or the 2016 US presidential elections, only a very small
number of bots participated in the Twitter discussion on the 2016 Austrian
presidential election.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09940</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Generalized Matched Filter Framework for Massive MIMO Systems</dc:title>
 <dc:creator>Neumann, David</dc:creator>
 <dc:creator>Wiese, Thomas</dc:creator>
 <dc:creator>Joham, Michael</dc:creator>
 <dc:creator>Utschick, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present a novel framework for low-complexity precoder design well-suited
for cellular massive MIMO systems. Our framework allows to exploit the channel
structure in terms of covariance matrices to improve the performance in the
face of interference during the channel training, while basically keeping the
complexity of a matched filter precoder. The proposed design generalizes
previous approaches to precoder design for massive MIMO and exhibits
significant performance gains in numerical simulations. We further show by
asymptotic analysis that with the proposed precoder design the capacity grows
without bound for growing numbers of antennas even in the presence of
pilot-contamination.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09941</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal Analysis of Continuous-time Systems using Fourier Transform</dc:title>
 <dc:creator>Rashid, Adnan</dc:creator>
 <dc:creator>Hasan, Osman</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  To study the dynamical behaviour of the engineering and physical systems, we
often need to capture their continuous behaviour, which is modeled using
differential equations, and perform the frequency-domain analysis of these
systems. Traditionally, Fourier transform methods are used to perform this
frequency domain analysis using paper-and-pencil based analytical techniques or
computer simulations. However, both of these methods are error prone and thus
are not suitable for analyzing systems used in safety-critical domains, like
medicine and transportation. In order to provide an accurate alternative, we
propose to use higher-order-logic theorem proving to conduct the frequency
domain analysis of these systems. For this purpose, the paper presents a
higher-order-logic formalization of Fourier transform using the HOL-Light
theorem prover. In particular, we use the higher-order-logic based
formalizations of differential, integral, transcendental and topological
theories of multivariable calculus to formally define Fourier transform and
reason about the correctness of its classical properties, such as existence,
linearity, time shifting, frequency shifting, modulation, time scaling, time
reversal and differentiation in time domain, and its relationships with Fourier
Cosine, Fourier Sine and Laplace transforms. We use our proposed formalization
for the formal verification of the frequency response of a generic n-order
linear system, an audio equalizer and a MEMs accelerometer, using the HOL-Light
theorem prover.
</dc:description>
 <dc:description>Comment: Journal of Symbolic Computation</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09948</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaussian Process-Based Model Predictive Control of Blood Glucose for
  Patients with Type 1 Diabetes Mellitus</dc:title>
 <dc:creator>Ortmann, Lukas</dc:creator>
 <dc:creator>Shi, Dawei</dc:creator>
 <dc:creator>Dassau, Eyal</dc:creator>
 <dc:creator>Doyle III, Francis J.</dc:creator>
 <dc:creator>Leonhardt, Steffen</dc:creator>
 <dc:creator>Misgeld, Berno J. E.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The insulin sensitivity (IS) of the human body changes with a circadian
rhythm. This adds to the time-varying feature of the glucose metabolism process
and places challenges on the blood glucose (BG) control of patients with Type 1
Diabetes Mellitus. This paper presents a Model Predictive Controller that takes
the periodic IS into account, in order to enhance BG control. The future effect
of the IS is predicted using a machine learning technique, namely, a customized
Gaussian Process (GP), based on historical training data. The training data for
the GP is continuously updated during closed-loop control, which enables the
control scheme to learn and adapt to intra-individual and inter-individual
changes of the circadian IS rhythm. The necessary state information is provided
by an Unscented Kalman Filter. The closed-loop performance of the proposed
control scheme is evaluated for different scenarios (including fasting,
announced meals and skipped meals) through in silico studies on simulation
models of G\&quot;ottingen Minipigs.
</dc:description>
 <dc:description>Comment: Submitted to Asian Control Conference (ASCC) 2017</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09952</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiscale Co-Design Analysis of Energy, Latency, Area, and Accuracy of
  a ReRAM Analog Neural Training Accelerator</dc:title>
 <dc:creator>Marinella, Matthew J.</dc:creator>
 <dc:creator>Agarwal, Sapan</dc:creator>
 <dc:creator>Hsia, Alexander</dc:creator>
 <dc:creator>Richter, Isaac</dc:creator>
 <dc:creator>Jacobs-Gedrim, Robin</dc:creator>
 <dc:creator>Niroula, John</dc:creator>
 <dc:creator>Plimpton, Steven J.</dc:creator>
 <dc:creator>Ipek, Engin</dc:creator>
 <dc:creator>James, Conrad D.</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Neural networks are an increasingly attractive algorithm for natural language
processing and pattern recognition applications. Deep networks with &gt;50M
parameters made possible by modern GPU clusters operating at &lt;50 pJ per op and
more recently, production accelerators capable of &lt;5pJ per operation at the
board level. However, with the slowing of CMOS scaling, new paradigms will be
required to achieve the next several orders of magnitude in performance per
watt gains. Using an analog resistive memory (ReRAM) crossbar to perform key
matrix operations in an accelerator is an attractive option that is gaining
significant interest. This work presents a detailed design using a state of the
art 14/16 nm PDK for of an analog crossbar circuit block designed to process
three key kernels required in training and inference of neural networks. A
detailed circuit and device-level analysis of energy, latency, area, and
accuracy are given and compared to relevant designs using standard digital
ReRAM and SRAM operations. It is shown that the analog accelerator has a 310x
energy and 270x latency advantage over a similar block utilizing only digital
ReRAM and takes only 11 fJ per multiply and accumulate (MAC). Although training
accuracy is degraded in the analog accelerator, several options to improve this
are presented. The possible gains over a similar digital-only version of this
accelerator block suggest that continued optimization of analog resistive
memories is valuable. This detailed circuit and device analysis of a training
accelerator may serve as a foundation for further architecture-level studies.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09952</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09955</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparing People with Bibliometrics</dc:title>
 <dc:creator>Kurtz, Michael J.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Bibliometric indicators, citation counts and/or download counts are
increasingly being used to inform personnel decisions such as hiring or
promotions. These statistics are very often misused. Here we provide a guide to
the factors which should be considered when using these so-called quantitative
measures to evaluate people. Rules of thumb are given for when begin to use
bibliometric measures when comparing otherwise similar candidates.
</dc:description>
 <dc:description>Comment: to appear in Proceedings of Library and Information Science in
  Astronomy VIII (LISA-8)</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09955</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09958</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>(k,q)-Compressed Sensing for dMRI with Joint Spatial-Angular Sparsity
  Prior</dc:title>
 <dc:creator>Schwab, Evan</dc:creator>
 <dc:creator>Vidal, Ren&#xe9;</dc:creator>
 <dc:creator>Charon, Nicolas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Advanced diffusion magnetic resonance imaging (dMRI) techniques, like
diffusion spectrum imaging (DSI) and high angular resolution diffusion imaging
(HARDI), remain underutilized compared to diffusion tensor imaging because the
scan times needed to produce accurate estimations of fiber orientation are
significantly longer. To accelerate DSI and HARDI, recent methods from
compressed sensing (CS) exploit a sparse underlying representation of the data
in the spatial and angular domains to undersample in the respective k- and
q-spaces. State-of-the-art frameworks, however, impose sparsity in the spatial
and angular domains separately and involve the sum of the corresponding sparse
regularizers. In contrast, we propose a unified (k,q)-CS formulation which
imposes sparsity jointly in the spatial-angular domain to further increase
sparsity of dMRI signals and reduce the required subsampling rate. To
efficiently solve this large-scale global reconstruction problem, we introduce
a novel adaptation of the FISTA algorithm that exploits dictionary
separability. We show on phantom and real HARDI data that our approach achieves
significantly more accurate signal reconstructions than the state of the art
while sampling only 2-4% of the (k,q)-space, allowing for the potential of new
levels of dMRI acceleration.
</dc:description>
 <dc:description>Comment: To be published in the 2017 Computational Diffusion MRI Workshop of
  MICCAI</dc:description>
 <dc:date>2017-07-20</dc:date>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09959</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correction of &quot;Cloud Removal By Fusing Multi-Source and Multi-Temporal
  Images&quot;</dc:title>
 <dc:creator>Zhang, Chengyue</dc:creator>
 <dc:creator>Li, Zhiwei</dc:creator>
 <dc:creator>Cheng, Qing</dc:creator>
 <dc:creator>Li, Xinghua</dc:creator>
 <dc:creator>Shen, Huanfeng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Remote sensing images often suffer from cloud cover. Cloud removal is
required in many applications of remote sensing images. Multitemporal-based
methods are popular and effective to cope with thick clouds. This paper
contributes to a summarization and experimental comparation of the existing
multitemporal-based methods. Furthermore, we propose a spatiotemporal-fusion
with poisson-adjustment method to fuse multi-sensor and multi-temporal images
for cloud removal. The experimental results show that the proposed method has
potential to address the problem of accuracy reduction of cloud removal in
multi-temporal images with significant changes.
</dc:description>
 <dc:description>Comment: This is a correction version of the accepted IGARSS 2017 conference
  paper</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09959</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09965</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tuning MPI Collectives by Verifying Performance Guidelines</dc:title>
 <dc:creator>Hunold, Sascha</dc:creator>
 <dc:creator>Carpen-Amarie, Alexandra</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  MPI collective operations provide a standardized interface for performing
data movements within a group of processes. The efficiency of collective
communication operations depends on the actual algorithm, its implementation,
and the specific communication problem (type of communication, message size,
number of processes). Many MPI libraries provide numerous algorithms for
specific collective operations. The strategy for selecting an efficient
algorithm is often times predefined (hard-coded) in MPI libraries, but some of
them, such as Open MPI, allow users to change the algorithm manually. Finding
the best algorithm for each case is a hard problem, and several approaches to
tune these algorithmic parameters have been proposed. We use an orthogonal
approach to the parameter-tuning of MPI collectives, that is, instead of
testing individual algorithmic choices provided by an MPI library, we compare
the latency of a specific MPI collective operation to the latency of
semantically equivalent functions, which we call the mock-up implementations.
The structure of the mock-up implementations is defined by self-consistent
performance guidelines. The advantage of this approach is that tuning using
mock-up implementations is always possible, whether or not an MPI library
allows users to select a specific algorithm at run-time. We implement this
concept in a library called PGMPITuneLib, which is layered between the user
code and the actual MPI implementation. This library selects the
best-performing algorithmic pattern of an MPI collective by intercepting MPI
calls and redirecting them to our mock-up implementations. Experimental results
show that PGMPITuneLib can significantly reduce the latency of MPI collectives,
and also equally important, that it can help identifying the tuning potential
of MPI libraries.
</dc:description>
 <dc:description>Comment: 16 pages, 14 figures</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09965</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09971</identifier>
 <datestamp>2017-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral Method and Regularized MLE Are Both Optimal for Top-$K$ Ranking</dc:title>
 <dc:creator>Chen, Yuxin</dc:creator>
 <dc:creator>Fan, Jianqing</dc:creator>
 <dc:creator>Ma, Cong</dc:creator>
 <dc:creator>Wang, Kaizheng</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  This paper is concerned with the problem of top-$K$ ranking from pairwise
comparisons. Given a collection of $n$ items and a few pairwise binary
comparisons across them, one wishes to identify the set of $K$ items that
receive the highest ranks. To tackle this problem, we adopt the logistic
parametric model---the Bradley-Terry-Luce model, where each item is assigned a
latent preference score, and where the outcome of each pairwise comparison
depends solely on the relative scores of the two items involved. Recent works
have made significant progress towards characterizing the performance (e.g. the
mean square error for estimating the scores) of several classical methods,
including the spectral method and the maximum likelihood estimator (MLE).
However, where they stand regarding top-$K$ ranking remains unsettled.
  We demonstrate that under a random sampling model, the spectral method alone,
or the regularized MLE alone, is minimax optimal in terms of the sample
complexity---the number of paired comparisons needed to ensure exact top-$K$
identification. This is accomplished via optimal control of the entrywise error
of the score estimates. We complement our theoretical studies by numerical
experiments, confirming that both methods yield low entrywise errors for
estimating the underlying scores. Our theory is established based on a novel
leave-one-out trick, which proves effective for analyzing both iterative and
non-iterative optimization procedures. Along the way, we derive an elementary
eigenvector perturbation bound for probability transition matrices, which
parallels the Davis-Kahan $\sin\Theta$ theorem for symmetric matrices. This
further allows us to close the gap between the $\ell_2$ error upper bound for
the spectral method and the minimax lower limit.
</dc:description>
 <dc:description>Comment: Improve the $\ell_2$ error upper bound for the spectral method</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-09-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09972</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vehicular Communications: A Network Layer Perspective</dc:title>
 <dc:creator>Peng, Haixia</dc:creator>
 <dc:creator>Liang, Le</dc:creator>
 <dc:creator>Shen, Xuemin</dc:creator>
 <dc:creator>Li, Geoffrey Ye</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Vehicular communications, referring to information exchange among vehicles,
pedestrians, and infrastructures, have become very popular and been widely
studied recently due to its great potential to support intelligent
transportation and various safety applications. Via vehicular communications,
manually driving vehicles and autonomous vehicles can collect useful
information to improve traffic safety and support infotainment services. In
this paper, we provide a comprehensive overview of recent research on enabling
efficient vehicular communications from the network layer perspective. First,
we introduce general applications and unique characteristics of vehicular
networks and the corresponding classifications. Based on different driving
patterns of vehicles, we divide vehicular networks into two categories, i.e.,
manually driving vehicular networks and automated driving vehicular networks,
and then discuss the available communication techniques, network structures,
routing protocols, and handoff strategies applied in these vehicular networks.
Finally, we identify the challenges confronted by the current vehicular
communications and present the corresponding research opportunities.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09978</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Logic and Topology for Knowledge, Knowability, and Belief - Extended
  Abstract</dc:title>
 <dc:creator>Bjorndahl, Adam</dc:creator>
 <dc:creator>&#xd6;zg&#xfc;n, Ayb&#xfc;ke</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In recent work, Stalnaker proposes a logical framework in which belief is
realized as a weakened form of knowledge. Building on Stalnaker's core
insights, and using frameworks developed by Bjorndahl and Baltag et al., we
employ topological tools to refine and, we argue, improve on this analysis. The
structure of topological subset spaces allows for a natural distinction between
what is known and (roughly speaking) what is knowable; we argue that the
foundational axioms of Stalnaker's system rely intuitively on both of these
notions. More precisely, we argue that the plausibility of the principles
Stalnaker proposes relating knowledge and belief relies on a subtle
equivocation between an &quot;evidence-in-hand&quot; conception of knowledge and a weaker
&quot;evidence-out-there&quot; notion of what could come to be known. Our analysis leads
to a trimodal logic of knowledge, knowability, and belief interpreted in
topological subset spaces in which belief is definable in terms of knowledge
and knowability. We provide a sound and complete axiomatization for this logic
as well as its uni-modal belief fragment. We then consider weaker logics that
preserve suitable translations of Stalnaker's postulates, yet do not allow for
any reduction of belief. We propose novel topological semantics for these
irreducible notions of belief, generalizing our previous semantics, and provide
sound and complete axiomatizations for the corresponding logics.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250. The full version of this
  paper, including the longer proofs, is at arXiv:1612.02055</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09978</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 88-101</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1707.09979</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rational invariants of ternary forms under the orthogonal group</dc:title>
 <dc:creator>G&#xf6;rlach, Paul</dc:creator>
 <dc:creator>Hubert, Evelyne</dc:creator>
 <dc:creator>Papadopoulo, Th&#xe9;o</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  In this article we determine a generating set of rational invariants of
minimal cardinality for the action of the orthogonal group $\mathrm{O}_3$ on
the space $\mathbb{R}[x,y,z]_{2d}$ of ternary forms of even degree $2d$. The
construction relies on two key ingredients: On one hand, the Slice Lemma allows
us to reduce the problem to dermining the invariants for the action on a
subspace of the finite subgroup $\mathrm{B}_3$ of signed permutations. On the
other hand, our construction relies in a fundamental way on specific bases of
harmonic polynomials. These bases provide maps with prescribed
$\mathrm{B}_3$-equivariance properties. Our explicit construction of these
bases should be relevant well beyond the scope of this paper. The expression of
the $\mathrm{B}_3$-invariants can then be given in a compact form as the
composition of two equivariant maps. Instead of providing (cumbersome) explicit
expressions for the $\mathrm{O}_3$-invariants, we provide efficient algorithms
for their evaluation and rewriting. We also use the constructed
$\mathrm{B}_3$-invariants to determine the $\mathrm{O}_3$-orbit locus and
provide an algorithm for the inverse problem of finding an element in
$\mathbb{R}[x,y,z]_{2d}$ with prescribed values for its invariants. These are
the computational issues relevant in brain imaging.
</dc:description>
 <dc:description>Comment: Typos and references corrected. 34 pages, 5 figures</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1707.09979</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00002</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Which Distribution Distances are Sublinearly Testable?</dc:title>
 <dc:creator>Daskalakis, Constantinos</dc:creator>
 <dc:creator>Kamath, Gautam</dc:creator>
 <dc:creator>Wright, John</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  Given samples from an unknown distribution $p$ and a description of a
distribution $q$, are $p$ and $q$ close or far? This question of &quot;identity
testing&quot; has received significant attention in the case of testing whether $p$
and $q$ are equal or far in total variation distance. However, in recent work,
the following questions have been been critical to solving problems at the
frontiers of distribution testing:
  -Alternative Distances: Can we test whether $p$ and $q$ are far in other
distances, say Hellinger?
  -Tolerance: Can we test when $p$ and $q$ are close, rather than equal? And if
so, close in which distances?
  Motivated by these questions, we characterize the complexity of distribution
testing under a variety of distances, including total variation, $\ell_2$,
Hellinger, Kullback-Leibler, and $\chi^2$. For each pair of distances $d_1$ and
$d_2$, we study the complexity of testing if $p$ and $q$ are close in $d_1$
versus far in $d_2$, with a focus on identifying which problems allow strongly
sublinear testers (i.e., those with complexity $O(n^{1 - \gamma})$ for some
$\gamma &gt; 0$ where $n$ is the size of the support of the distributions $p$ and
$q$). We provide matching upper and lower bounds for each case. We also study
these questions in the case where we only have samples from $q$ (equivalence
testing), showing qualitative differences from identity testing in terms of
when tolerance can be achieved. Our algorithms fall into the classical paradigm
of $\chi^2$-statistics, but require crucial changes to handle the challenges
introduced by each distance we consider. Finally, we survey other recent
results in an attempt to serve as a reference for the complexity of various
distribution testing problems.
</dc:description>
 <dc:description>Comment: To appear in SODA 2018</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00023</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gate scheduling for quantum algorithms</dc:title>
 <dc:creator>Guerreschi, Gian Giacomo</dc:creator>
 <dc:creator>Park, Jongsoo</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  As the effort to scale up existing quantum hardware proceeds, the necessity
of effective methods to schedule quantum gates and minimize the number of
operations becomes more compelling. Three are the constraints that have to be
taken into account: The order or dependency of the quantum gates in the
specific algorithm, the fact that any qubit may be involved in at most one gate
at a time, and the restriction that two-qubit gates are implementable only
between connected qubits. The last aspect implies that the compilation depends
not only on the algorithm, but also on hardware properties like its
connectivity. Here we suggest a two-step approach in which logical gates are
initially scheduled neglecting the limited connectivity, while routing
operations are added at a later step and their number is empirically minimized.
In the context of the two-step approach, we propose a solution of the routing
problem that is optimal for an one dimensional array of qubits. As a practical
application, we schedule the Quantum Approximate Optimization Algorithm in a
linear geometry and quantify the reduction in the number of gates and circuit
depth by increasing the efficacy of the scheduling strategies.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00033</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An efficient MPI/OpenMP parallelization of the Hartree-Fock method for
  the second generation of Intel Xeon Phi processor</dc:title>
 <dc:creator>Mironov, Vladimir</dc:creator>
 <dc:creator>Alexeev, Yuri</dc:creator>
 <dc:creator>Keipert, Kristopher</dc:creator>
 <dc:creator>D'mello, Michael</dc:creator>
 <dc:creator>Moskovsky, Alexander</dc:creator>
 <dc:creator>Gordon, Mark S.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:description>  Modern OpenMP threading techniques are used to convert the MPI-only
Hartree-Fock code in the GAMESS program to a hybrid MPI/OpenMP algorithm. Two
separate implementations that differ by the sharing or replication of key data
structures among threads are considered, density and Fock matrices. All
implementations are benchmarked on a super-computer of 3,000 Intel Xeon Phi
processors. With 64 cores per processor, scaling numbers are reported on up to
192,000 cores. The hybrid MPI/OpenMP implementation reduces the memory
footprint by approximately 200 times compared to the legacy code. The
MPI/OpenMP code was shown to run up to six times faster than the original for a
range of molecular system sizes.
</dc:description>
 <dc:description>Comment: SC17 conference paper, 12 pages, 7 figures</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00033</dc:identifier>
 <dc:identifier>doi:10.1145/3126908.3126956</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00042</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatio-Temporal Action Detection with Cascade Proposal and Location
  Anticipation</dc:title>
 <dc:creator>Yang, Zhenheng</dc:creator>
 <dc:creator>Gao, Jiyang</dc:creator>
 <dc:creator>Nevatia, Ram</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we address the problem of spatio-temporal action detection in
temporally untrimmed videos. It is an important and challenging task as finding
accurate human actions in both temporal and spatial space is important for
analyzing large-scale video data. To tackle this problem, we propose a cascade
proposal and location anticipation (CPLA) model for frame-level action
detection. There are several salient points of our model: (1) a cascade region
proposal network (casRPN) is adopted for action proposal generation and shows
better localization accuracy compared with single region proposal network
(RPN); (2) action spatio-temporal consistencies are exploited via a location
anticipation network (LAN) and thus frame-level action detection is not
conducted independently. Frame-level detections are then linked by solving an
linking score maximization problem, and temporally trimmed into spatio-temporal
action tubes. We demonstrate the effectiveness of our model on the challenging
UCF101 and LIRIS-HARL datasets, both achieving state-of-the-art performance.
</dc:description>
 <dc:description>Comment: Accepted at BMVC 2017 (oral)</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00043</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pricing for Online Resource Allocation: Beyond Subadditive Values</dc:title>
 <dc:creator>Chawla, Shuchi</dc:creator>
 <dc:creator>Miller, J. Benjamin</dc:creator>
 <dc:creator>Paparas, Dimitris</dc:creator>
 <dc:creator>Teng, Yifeng</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider the problem of truthful online resource allocation to maximize
social welfare in a stochastic setting. Sequential posted pricing has emerged
as a desirable mechanism for this problem that is at once simple, easy to
implement in practice, as well as approximately optimal in several cases. In
this mechanism, the seller uses his knowledge of the demand distribution to
determine and announce prices for individual resources or bundles of resources.
Buyers then arrive in sequence and can purchase their favorite bundles while
supplies last. Previous work shows that sequential posted pricing achieves good
approximations when buyers' values exhibit subadditivity. We consider settings
where buyers desire bundles, that is, their values exhibit complementarities,
and the seller faces a cost function for supplying the resource. We present
both upper and lower bounds for the approximation factors achieved by
sequential posted pricing in these settings.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00045</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistics on the (compact) Stiefel manifold: Theory and Applications</dc:title>
 <dc:creator>Chakraborty, Rudrasis</dc:creator>
 <dc:creator>Vemuri, Baba</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A Stiefel manifold of the compact type is often encountered in many fields of
Engineering including, signal and image processing, machine learning, numerical
optimization and others. The Stiefel manifold is a Riemannian homogeneous space
but not a symmetric space. In previous work, researchers have defined
probability distributions on symmetric spaces and performed statistical
analysis of data residing in these spaces. In this paper, we present original
work involving definition of Gaussian distributions on a homogeneous space and
show that the maximum-likelihood estimate of the location parameter of a
Gaussian distribution on the homogeneous space yields the Fr\'echet mean (FM)
of the samples drawn from this distribution. Further, we present an algorithm
to sample from the Gaussian distribution on the Stiefel manifold and
recursively compute the FM of these samples. We also prove the weak consistency
of this recursive FM estimator. Several synthetic and real data experiments are
then presented, demonstrating the superior computational performance of this
estimator over the gradient descent based non-recursive counter part as well as
the stochastic gradient descent based method prevalent in literature.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00045</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00049</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpretable Active Learning</dc:title>
 <dc:creator>Phillips, Richard L.</dc:creator>
 <dc:creator>Chang, Kyu Hyun</dc:creator>
 <dc:creator>Friedler, Sorelle A.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Active learning has long been a topic of study in machine learning. However,
as increasingly complex and opaque models have become standard practice, the
process of active learning, too, has become more opaque. There has been little
investigation into interpreting what specific trends and patterns an active
learning strategy may be exploring. This work expands on the Local
Interpretable Model-agnostic Explanations framework (LIME) to provide
explanations for active learning recommendations. We demonstrate how LIME can
be used to generate locally faithful explanations for an active learning
strategy, and how these explanations can be used to understand how different
models and datasets explore a problem space over time. In order to quantify the
per-subgroup differences in how an active learning strategy queries spatial
regions, we introduce a notion of uncertainty bias (based on disparate impact)
to measure the discrepancy in the confidence for a model's predictions between
one subgroup and another. Using the uncertainty bias measure, we show that our
query explanations accurately reflect the subgroup focus of the active learning
queries, allowing for an interpretable explanation of what is being learned as
points with similar sources of uncertainty have their uncertainty bias
resolved. We demonstrate that this technique can be applied to track
uncertainty bias over user-defined clusters or automatically generated clusters
based on the source of uncertainty.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, presented at 2017 ICML Workshop on Human
  Interpretability in Machine Learning (WHI 2017), Sydney, NSW, Australia</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00052</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Streaming Architecture for Large-Scale Quantized Neural Networks on an
  FPGA-Based Dataflow Platform</dc:title>
 <dc:creator>Baskin, Chaim</dc:creator>
 <dc:creator>Liss, Natan</dc:creator>
 <dc:creator>Mendelson, Avi</dc:creator>
 <dc:creator>Zheltonozhskii, Evgenii</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep neural networks (DNNs) are used by different applications that are
executed on a range of computer architectures, from IoT devices to
supercomputers. The footprint of these networks is huge as well as their
computational and communication needs. In order to ease the pressure on
resources, research indicates that in many cases a low precision representation
(1-2 bit per parameter) of weights and other parameters can achieve similar
accuracy while requiring less resources. Using quantized values enables the use
of FPGAs to run NNs, since FPGAs are well fitted to these primitives; e.g.,
FPGAs provide efficient support for bitwise operations and can work with
arbitrary-precision representation of numbers.
  This paper presents a new streaming architecture for running QNNs on FPGAs.
The proposed architecture scales out better than alternatives, allowing us to
take advantage of systems with multiple FPGAs. We also included support for
skip connections, that are used in state-of-the art NNs, and shown that our
architecture allows to add those connections almost for free. All this allowed
us to implement an 18-layer ResNet for $224\times224$ images classification,
achieving $57.5\%$ top-1 accuracy.
  In addition, we implemented a full-sized quantized AlexNet. In contrast to
previous works, we use 2-bit activations instead of 1-bit ones, which improves
AlexNet's top-1 accuracy from $41.8\%$ to $51.03\%$ for the ImageNet
classification. Both AlexNet and ResNet can handle 1000-class real-time
classification on an FPGA.
  Our implementation of ResNet-18 consumes $5\times$ less power and is
$4\times$ slower for ImageNet, when compared to the same NN on the latest
Nvidia GPUs. Smaller NNs, that fit a single FPGA, are running faster then on
GPUs on small ($32\times32$) inputs, while consuming up to $20\times$ less
energy and power.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00055</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SemEval-2017 Task 1: Semantic Textual Similarity - Multilingual and
  Cross-lingual Focused Evaluation</dc:title>
 <dc:creator>Cer, Daniel</dc:creator>
 <dc:creator>Diab, Mona</dc:creator>
 <dc:creator>Agirre, Eneko</dc:creator>
 <dc:creator>Lopez-Gazpio, I&#xf1;igo</dc:creator>
 <dc:creator>Specia, Lucia</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>68T50</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Semantic Textual Similarity (STS) measures the meaning similarity of
sentences. Applications include machine translation (MT), summarization,
generation, question answering (QA), short answer grading, semantic search,
dialog and conversational systems. The STS shared task is a venue for assessing
the current state-of-the-art. The 2017 task focuses on multilingual and
cross-lingual pairs with one sub-track exploring MT quality estimation (MTQE)
data. The task obtained strong participation from 31 teams, with 17
participating in all language tracks. We summarize performance and review a
selection of well performing methods. Analysis highlights common errors,
providing insight into the limitations of existing models. To support ongoing
work on semantic representations, the STS Benchmark is introduced as a new
shared training and evaluation set carefully selected from the corpus of
English STS shared task data (2012-2017).
</dc:description>
 <dc:description>Comment: To appear in proceedings of the SemEval workshop at ACL 2017; 14
  pages, 14 Tables, 1 Figure</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00055</dc:identifier>
 <dc:identifier>doi:10.18653/v1/S17-2001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00059</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotically optimal private estimation under mean square loss</dc:title>
 <dc:creator>Ye, Min</dc:creator>
 <dc:creator>Barg, Alexander</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the minimax estimation problem of a discrete distribution with
support size $k$ under locally differential privacy constraints. A
privatization scheme is applied to each raw sample independently, and we need
to estimate the distribution of the raw samples from the privatized samples. A
positive number $\epsilon$ measures the privacy level of a privatization
scheme.
  In our previous work (arXiv:1702.00610), we proposed a family of new
privatization schemes and the corresponding estimator. We also proved that our
scheme and estimator are order optimal in the regime $e^{\epsilon} \ll k$ under
both $\ell_2^2$ and $\ell_1$ loss. In other words, for a large number of
samples the worst-case estimation loss of our scheme was shown to differ from
the optimal value by at most a constant factor. In this paper, we eliminate
this gap by showing asymptotic optimality of the proposed scheme and estimator
under the $\ell_2^2$ (mean square) loss. More precisely, we show that for any
$k$ and $\epsilon,$ the ratio between the worst-case estimation loss of our
scheme and the optimal value approaches $1$ as the number of samples tends to
infinity.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00065</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time-Dependent Representation for Neural Event Sequence Prediction</dc:title>
 <dc:creator>Li, Yang</dc:creator>
 <dc:creator>Du, Nan</dc:creator>
 <dc:creator>Bengio, Samy</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Existing sequence prediction methods are mostly concerned with
time-independent sequences, in which the actual time span between events is
irrelevant and the distance between events is simply the difference between
their order positions in the sequence. While this time-independent view of
sequences is applicable for data such as natural languages, e.g., dealing with
words in a sentence, it is inappropriate and inefficient for many real world
events that are observed and collected at unequally spaced points of time as
they naturally arise, e.g., when a person goes to a grocery store or makes a
phone call. The time span between events can carry important information about
the sequence dependence of human behaviors. In this work, we propose a set of
methods for using time in sequence prediction. Because neural sequence models
such as RNN are more amenable for handling token-like input, we propose two
methods for time-dependent event representation, based on the intuition on how
time is tokenized in everyday life and previous work on embedding
contextualization. We also introduce two methods for using next event duration
as regularization for training a sequence prediction model. We discuss these
methods based on recurrent neural nets. We evaluate these methods as well as
baseline models on five datasets that resemble a variety of sequence prediction
tasks. The experiments revealed that the proposed methods offer accuracy gain
over baseline models in a range of settings.
</dc:description>
 <dc:description>Comment: 9 pages and 2 pages of references</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00069</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Robust Representations for Computer Vision</dc:title>
 <dc:creator>Zheng, Peng</dc:creator>
 <dc:creator>Aravkin, Aleksandr Y.</dc:creator>
 <dc:creator>Ramamurthy, Karthikeyan Natesan</dc:creator>
 <dc:creator>Thiagarajan, Jayaraman Jayaraman</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Unsupervised learning techniques in computer vision often require learning
latent representations, such as low-dimensional linear and non-linear
subspaces. Noise and outliers in the data can frustrate these approaches by
obscuring the latent spaces.
  Our main goal is deeper understanding and new development of robust
approaches for representation learning. We provide a new interpretation for
existing robust approaches and present two specific contributions: a new robust
PCA approach, which can separate foreground features from dynamic background,
and a novel robust spectral clustering method, that can cluster facial images
with high accuracy. Both contributions show superior performance to standard
methods on real-world test sets.
</dc:description>
 <dc:description>Comment: 8 pages, 7 pages</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00072</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Component-oriented Framework for Autonomous Agents</dc:title>
 <dc:creator>Kapp&#xe9;, Tobias</dc:creator>
 <dc:creator>Arbab, Farhad</dc:creator>
 <dc:creator>Talcott, Carolyn</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The design of a complex system warrants a compositional methodology, i.e.,
composing simple components to obtain a larger system that exhibits their
collective behavior in a meaningful way. We propose an automaton-based paradigm
for compositional design of such systems where an action is accompanied by one
or more preferences. At run-time, these preferences provide a natural fallback
mechanism for the component, while at design-time they can be used to reason
about the behavior of the component in an uncertain physical world. Using
structures that tell us how to compose preferences and actions, we can compose
formal representations of individual components or agents to obtain a
representation of the composed system. We extend Linear Temporal Logic with two
unary connectives that reflect the compositional structure of the actions, and
show how it can be used to diagnose undesired behavior by tracing the
falsification of a specification back to one or more culpable components.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00072</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-68034-7_2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00075</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Regret Minimization in Non-Convex Games</dc:title>
 <dc:creator>Hazan, Elad</dc:creator>
 <dc:creator>Singh, Karan</dc:creator>
 <dc:creator>Zhang, Cyril</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider regret minimization in repeated games with non-convex loss
functions. Minimizing the standard notion of regret is computationally
intractable. Thus, we define a natural notion of regret which permits efficient
optimization and generalizes offline guarantees for convergence to an
approximate local optimum. We give gradient-based methods that achieve optimal
regret, which in turn guarantee convergence to equilibrium in this framework.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICML 2017</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00075</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00076</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capturing the Connections: Unboxing Internet of Things Devices</dc:title>
 <dc:creator>Vaniea, Kami</dc:creator>
 <dc:creator>Tallyn, Ella</dc:creator>
 <dc:creator>Speed, Chris</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Based upon a study of how to capture data from Internet of Things (IoT)
devices, this paper explores the challenges for data centric design
ethnography. Often purchased to perform specific tasks, IoT devices exist in a
complex ecosystem. This paper describes a study that used a variety of methods
to capture the interactions an IoT device engaged in when it was first setup.
The complexity of the study that is explored through the annotated
documentation across video and router activity, presents the ethnographic
challenges that designers face in an age of connected things.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00077</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Sparsification of Recurrent Neural Networks</dc:title>
 <dc:creator>Lobacheva, Ekaterina</dc:creator>
 <dc:creator>Chirkova, Nadezhda</dc:creator>
 <dc:creator>Vetrov, Dmitry</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recurrent neural networks show state-of-the-art results in many text analysis
tasks but often require a lot of memory to store their weights. Recently
proposed Sparse Variational Dropout eliminates the majority of the weights in a
feed-forward neural network without significant loss of quality. We apply this
technique to sparsify recurrent neural networks. To account for recurrent
specifics we also rely on Binary Variational Dropout for RNN. We report 99.5%
sparsity level on sentiment analysis task without a quality drop and up to 87%
sparsity level on language modeling task with slight loss of accuracy.
</dc:description>
 <dc:description>Comment: Published in Workshop on Learning to Generate Natural Language, ICML,
  2017</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00077</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00079</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards the Success Rate of One: Real-time Unconstrained Salient Object
  Detection</dc:title>
 <dc:creator>Najibi, Mahyar</dc:creator>
 <dc:creator>Yang, Fan</dc:creator>
 <dc:creator>Wang, Qiaosong</dc:creator>
 <dc:creator>Piramuthu, Robinson</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we propose an efficient and effective approach for
unconstrained salient object detection in images using deep convolutional
neural networks. Instead of generating thousands of candidate bounding boxes
and refining them, our network directly learns to generate the saliency map
containing the exact number of salient objects. During training, we convert the
ground-truth rectangular boxes to Gaussian distributions that better capture
the ROI regarding individual salient objects. During inference, the network
predicts Gaussian distributions centered at salient objects with an appropriate
covariance, from which bounding boxes are easily inferred. Notably, our network
performs saliency map prediction without pixel-level annotations, salient
object detection without object proposals, and salient object subitizing
simultaneously, all in a single pass within a unified framework. Extensive
experiments show that our approach outperforms existing methods on various
datasets by a large margin, and achieves more than 100 fps with VGG16 network
on a single GPU during inference.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00079</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00083</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Beamforming with Selection for Multi-user Massive MIMO Systems</dc:title>
 <dc:creator>Ratnam, Vishnu V.</dc:creator>
 <dc:creator>Molisch, Andreas F.</dc:creator>
 <dc:creator>Bursalioglu, Ozgun Y.</dc:creator>
 <dc:creator>Papadopoulos, Haralabos C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This work studies a variant of hybrid beamforming, namely, hybrid beamforming
with selection (HBwS), as an attractive solution to reduce the hardware cost of
multi-user Massive Multiple-Input-Multiple-Output systems, while retaining good
performance. In a transceiver with HBwS, the antenna array is fed by an
analogue beamforming matrix with $L$ input ports. Unlike conventional hybrid
beamforming, a bank of switches connects the instantaneously best $K$ out of
the $L$ input ports to $K$ up/down-conversion chains, where $K \leq L$. The
analogue beamformer is designed based on average channel statistics and
therefore needs to be updated only infrequently, while the switches operate
based on instantaneous channel knowledge; this allows for a higher
diversity-order, better user separability and/or simpler hardware than some
conventional hybrid schemes. In this work, a novel design for the analogue
beamformer is derived and approaches to reduce the hardware and computational
cost of a multi-user HBwS system are explored. In addition, we study how $L$,
the switch bank architecture, the number of data-streams, and the apriori
estimated rank of the transmit spatial correlation matrix, impact system
performance. Simulations suggest that HBwS enables linear coding schemes like
Zero-Forcing, achieve performance comparable to Dirty Paper Coding.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00087</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigating quantum wireless multihop teleportation in amplitude
  damping channel</dc:title>
 <dc:creator>Ram&#xed;rez, Marlon David Gonz&#xe1;lez</dc:creator>
 <dc:creator>Nwachioma, Christian</dc:creator>
 <dc:creator>Adepoju, Adenike Grace</dc:creator>
 <dc:creator>Falaye, Babatunde James</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper scrutinizes quantum routing protocol with multihop teleportation
for wireless mesh backbone networks, in an amplitude damping channel. After
analyzing the quantum multihop protocol, we select a four-qubit cluster state
as the quantum channel for the protocol. The quantum channel linking the
intermediate nodes has been established via entanglement swapping based on
four-qubit cluster state. Also, we established the classical and the quantum
route in a distributed manner. We show that from the source node to the
destination node, quantum information can be teleported hop-by-hop through an
amplitude damping channel. We show that the quantum teleportation could be
successful if the sender node performs Bell state measurements (BSM), and the
receiver introduces auxiliary particles, applies positive operative value
measure and then utilizes corresponding unitary transformation to recover the
transmitted state. We scrutinize the success probability of transferring the
quantum state through a noisy channel. We found that optimum probability would
be attained if decoherence rate of amplitude damping channel ($\xi_a$) is zero
or the number of hops ($N$) is above $75$. Our numerical results evince
susceptibility of success probability to $\xi_a$ and $N$. It has been shown
that as the decoherence increases, the fidelity exponentially decays until it
vanishes. This decay is as a consequence of information loss from the system to
the surrounding. However, the fidelity can be enhanced by considering fewer
hops.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00087</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00088</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Algorithms for Active Learning</dc:title>
 <dc:creator>Bachman, Philip</dc:creator>
 <dc:creator>Sordoni, Alessandro</dc:creator>
 <dc:creator>Trischler, Adam</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce a model that learns active learning algorithms via metalearning.
For a distribution of related tasks, our model jointly learns: a data
representation, an item selection heuristic, and a method for constructing
prediction functions from labeled training sets. Our model uses the item
selection heuristic to gather labeled training sets from which to construct
prediction functions. Using the Omniglot and MovieLens datasets, we test our
model in synthetic and practical settings.
</dc:description>
 <dc:description>Comment: Accepted for publication at ICML 2017</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00088</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00098</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Code2Text Challenge: Text Generation in Source Code Libraries</dc:title>
 <dc:creator>Richardson, Kyle</dc:creator>
 <dc:creator>Zarrie&#xdf;, Sina</dc:creator>
 <dc:creator>Kuhn, Jonas</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We propose a new shared task for tactical data-to-text generation in the
domain of source code libraries. Specifically, we focus on text generation of
function descriptions from example software projects. Data is drawn from
existing resources used for studying the related problem of semantic parser
induction (Richardson and Kuhn, 2017b; Richardson and Kuhn, 2017a), and spans a
wide variety of both natural languages and programming languages. In this
paper, we describe these existing resources, which will serve as training and
development data for the task, and discuss plans for building new independent
test sets.
</dc:description>
 <dc:description>Comment: Proceedings of INLG 2017, shared task track</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00098</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00102</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Advantages and Limitations of using Successor Features for Transfer in
  Reinforcement Learning</dc:title>
 <dc:creator>Lehnert, Lucas</dc:creator>
 <dc:creator>Tellex, Stefanie</dc:creator>
 <dc:creator>Littman, Michael L.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  One question central to Reinforcement Learning is how to learn a feature
representation that supports algorithm scaling and re-use of learned
information from different tasks. Successor Features approach this problem by
learning a feature representation that satisfies a temporal constraint. We
present an implementation of an approach that decouples the feature
representation from the reward function, making it suitable for transferring
knowledge between domains. We then assess the advantages and limitations of
using Successor Features for transfer.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00106</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Material Editing Using a Physically Based Rendering Network</dc:title>
 <dc:creator>Liu, Guilin</dc:creator>
 <dc:creator>Ceylan, Duygu</dc:creator>
 <dc:creator>Yumer, Ersin</dc:creator>
 <dc:creator>Yang, Jimei</dc:creator>
 <dc:creator>Lien, Jyh-Ming</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The ability to edit materials of objects in images is desirable by many
content creators. However, this is an extremely challenging task as it requires
to disentangle intrinsic physical properties of an image. We propose an
end-to-end network architecture that replicates the forward image formation
process to accomplish this task. Specifically, given a single image, the
network first predicts intrinsic properties, i.e. shape, illumination, and
material, which are then provided to a rendering layer. This layer performs
in-network image synthesis, thereby enabling the network to understand the
physics behind the image formation process. The proposed rendering layer is
fully differentiable, supports both diffuse and specular materials, and thus
can be applicable in a variety of problem settings. We demonstrate a rich set
of visually plausible material editing examples and provide an extensive
comparative study.
</dc:description>
 <dc:description>Comment: 14 pages, ICCV 2017</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00107</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learned in Translation: Contextualized Word Vectors</dc:title>
 <dc:creator>McCann, Bryan</dc:creator>
 <dc:creator>Bradbury, James</dc:creator>
 <dc:creator>Xiong, Caiming</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Computer vision has benefited from initializing multiple deep layers with
weights pretrained on large supervised training sets like ImageNet. Natural
language processing (NLP) typically sees initialization of only the lowest
layer of deep models with pretrained word vectors. In this paper, we use a deep
LSTM encoder from an attentional sequence-to-sequence model trained for machine
translation (MT) to contextualize word vectors. We show that adding these
context vectors (CoVe) improves performance over using only unsupervised word
and character vectors on a wide variety of common NLP tasks: sentiment analysis
(SST, IMDb), question classification (TREC), entailment (SNLI), and question
answering (SQuAD). For fine-grained sentiment analysis and entailment, CoVe
improves performance of our baseline models to the state of the art.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00109</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Labelling Framework for Probabilistic Argumentation</dc:title>
 <dc:creator>Riveret, Regis</dc:creator>
 <dc:creator>Baroni, Pietro</dc:creator>
 <dc:creator>Gao, Yang</dc:creator>
 <dc:creator>Governatori, Guido</dc:creator>
 <dc:creator>Rotolo, Antonino</dc:creator>
 <dc:creator>Sartor, Giovanni</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The combination of argumentation and probability paves the way to new
accounts of qualitative and quantitative uncertainty, thereby offering new
theoretical and applicative opportunities. Due to a variety of interests,
probabilistic argumentation is approached in the literature with different
frameworks, pertaining to structured and abstract argumentation, and with
respect to diverse types of uncertainty, in particular the uncertainty on the
credibility of the premises, the uncertainty about which arguments to consider,
and the uncertainty on the acceptance status of arguments or statements.
Towards a general framework for probabilistic argumentation, we investigate a
labelling-oriented framework encompassing a basic setting for rule-based
argumentation and its (semi-) abstract account, along with diverse types of
uncertainty. Our framework provides a systematic treatment of various kinds of
uncertainty and of their relationships and allows us to retrieve (by
derivation) multiple statements (sometimes assumed) or results from the
literature.
</dc:description>
 <dc:description>Comment: 44 pages</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00111</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Continuous Relaxation of Beam Search for End-to-end Training of Neural
  Sequence Models</dc:title>
 <dc:creator>Goyal, Kartik</dc:creator>
 <dc:creator>Neubig, Graham</dc:creator>
 <dc:creator>Dyer, Chris</dc:creator>
 <dc:creator>Berg-Kirkpatrick, Taylor</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Beam search is a desirable choice of test-time decoding algorithm for neural
sequence models because it potentially avoids search errors made by simpler
greedy methods. However, typical cross entropy training procedures for these
models do not directly consider the behaviour of the final decoding method. As
a result, for cross-entropy trained models, beam decoding can sometimes yield
reduced test performance when compared with greedy decoding. In order to train
models that can more effectively make use of beam search, we propose a new
training procedure that focuses on the final loss metric (e.g. Hamming loss)
evaluated on the output of beam search. While well-defined, this &quot;direct loss&quot;
objective is itself discontinuous and thus difficult to optimize. Hence, in our
approach, we form a sub-differentiable surrogate objective by introducing a
novel continuous approximation of the beam search decoding procedure. In
experiments, we show that optimizing this new training objective yields
substantially better results on two sequence tasks (Named Entity Recognition
and CCG Supertagging) when compared with both cross entropy trained greedy
decoding and cross entropy trained beam decoding baselines.
</dc:description>
 <dc:description>Comment: Updated for clarity and notational consistency</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-10-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00111</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00112</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Retrofitting Distributional Embeddings to Knowledge Graphs with
  Functional Relations</dc:title>
 <dc:creator>Lengerich, Benjamin J.</dc:creator>
 <dc:creator>Maas, Andrew L.</dc:creator>
 <dc:creator>Potts, Christopher</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Knowledge graphs are a versatile framework to encode richly structured data
relationships, but it not always apparent how to combine these with existing
entity representations. Methods for retrofitting pre-trained entity
representations to the structure of a knowledge graph typically assume that
entities are embedded in a connected space and that relations imply similarity.
However, useful knowledge graphs often contain diverse entities and relations
(with potentially disjoint underlying corpora) which do not accord with these
assumptions. To overcome these limitations, we present Functional Retrofitting,
a framework that generalizes current retrofitting methods by explicitly
modeling pairwise relations. Our framework can directly incorporate a variety
of pairwise penalty functions previously developed for knowledge graph
completion. We present both linear and neural instantiations of the framework.
Functional Retrofitting significantly outperforms existing retrofitting methods
on complex knowledge graphs and loses no accuracy on simpler graphs (in which
relations do imply similarity). Finally, we demonstrate the utility of the
framework by predicting new drug--disease treatment pairs in a large, complex
health knowledge graph.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00113</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prediction and Generation of Binary Markov Processes: Can a Finite-State
  Fox Catch a Markov Mouse?</dc:title>
 <dc:creator>Ruebeck, J.</dc:creator>
 <dc:creator>James, R. G.</dc:creator>
 <dc:creator>Mahoney, J. R.</dc:creator>
 <dc:creator>Crutchfield, J. P.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  Understanding the generative mechanism of a natural system is a vital
component of the scientific method. Here, we investigate one of the fundamental
steps toward this goal by presenting the minimal generator of an arbitrary
binary Markov process. This is a class of processes whose predictive model is
well known. Surprisingly, the generative model requires three distinct
topologies for different regions of parameter space. We show that a previously
proposed generator for a particular set of binary Markov processes is, in fact,
not minimal. Our results shed the first quantitative light on the relative
(minimal) costs of prediction and generation. We find, for instance, that the
difference between prediction and generation is maximized when the process is
approximately independently, identically distributed.
</dc:description>
 <dc:description>Comment: 12 pages, 12 figures;
  http://csc.ucdavis.edu/~cmg/compmech/pubs/gmc.htm</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00113</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00117</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compiling Deep Learning Models for Custom Hardware Accelerators</dc:title>
 <dc:creator>Chang, Andre Xian Ming</dc:creator>
 <dc:creator>Zaidy, Aliasger</dc:creator>
 <dc:creator>Gokhale, Vinayak</dc:creator>
 <dc:creator>Culurciello, Eugenio</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Convolutional neural networks (CNNs) are the core of most state-of-the-art
deep learning algorithms specialized for object detection and classification.
CNNs are both computationally complex and embarrassingly parallel. Two
properties that leave room for potential software and hardware optimizations
for embedded systems. Given a programmable hardware accelerator with a CNN
oriented custom instructions set, the compiler's task is to exploit the
hardware's full potential, while abiding with the hardware constraints and
maintaining generality to run different CNN models with varying workload
properties. Snowflake is an efficient and scalable hardware accelerator
implemented on programmable logic devices. It implements a control pipeline for
a custom instruction set. The goal of this paper is to present Snowflake's
compiler that generates machine level instructions from Torch7 model
description files. The main software design points explored in this work are:
model structure parsing, CNN workload breakdown, loop rearrangement for memory
bandwidth optimizations and memory access balancing. The performance achieved
by compiler generated instructions matches against hand optimized code for
convolution layers. Generated instructions also efficiently execute AlexNet and
ResNet18 inference on Snowflake. Snowflake with $256$ processing units was
synthesized on Xilinx's Zynq XC7Z045 FPGA. At $250$ MHz, AlexNet achieved in
$93.6$ frames/s and $1.2$ GB/s of off-chip memory bandwidth, and $21.4$
frames/s and $2.2$ GB/s for ResNet18. Total on-chip power is $5$ W.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00118</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anomaly Detection Using Optimally-Placed Micro-PMU Sensors in
  Distribution Grids</dc:title>
 <dc:creator>Jamei, Mahdi</dc:creator>
 <dc:creator>Scaglione, Anna</dc:creator>
 <dc:creator>Roberts, Ciaran</dc:creator>
 <dc:creator>Stewart, Emma</dc:creator>
 <dc:creator>Peisert, Sean</dc:creator>
 <dc:creator>McParland, Chuck</dc:creator>
 <dc:creator>McEachern, Alex</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  As the distribution grid moves toward a tightly-monitored network, it is
important to automate the analysis of the enormous amount of data produced by
the sensors to increase the operators situational awareness about the system.
In this paper, focusing on Micro-Phasor Measurement Unit ($\mu$PMU) data, we
propose a hierarchical architecture for monitoring the grid and establish a set
of analytics and sensor fusion primitives for the detection of abnormal
behavior in the control perimeter. Due to the key role of the $\mu$PMU devices
in our architecture, a source-constrained optimal $\mu$PMU placement is also
described that finds the best location of the devices with respect to our
rules. The effectiveness of the proposed methods are tested through the
synthetic and real $\mu$PMU data.
</dc:description>
 <dc:description>Comment: This article is submitted to IEEE Transaction on Power System and is
  currently under the review process</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00120</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple Stakeholders in Music Recommender Systems</dc:title>
 <dc:creator>Abdollahpouri, Himan</dc:creator>
 <dc:creator>Essinger, Steve</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Music recommendation services collectively spin billions of songs for
millions of listeners on a daily basis. Users can typically listen to a variety
of songs tailored to their personal tastes and preferences. Music is not the
only type of content encountered in these services, however. Advertisements are
generally interspersed throughout the music stream to generate revenue for the
business. Additional content may include artist messaging, ticketing, sports,
news and weather. In this paper, we discuss issues that arise when multiple
content providers are stakeholders in the recommendation process. These
stakeholders each have their own objectives and must work in concert to sustain
a healthy music recommendation service.
</dc:description>
 <dc:description>Comment: Included in the 2017 Workshop on Value-Aware and Multistakeholder
  Recommendation</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00121</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing the Margin of Victory in Preferential Parliamentary Elections</dc:title>
 <dc:creator>Blom, Michelle</dc:creator>
 <dc:creator>Stuckey, Peter J.</dc:creator>
 <dc:creator>Teague, Vanessa</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We show how to use automated computation of election margins to assess the
number of votes that would need to change in order to alter a parliamentary
outcome for single-member preferential electorates. In the context of
increasing automation of Australian electoral processes, and accusations of
deliberate interference in elections in Europe and the USA, this work forms the
basis of a rigorous statistical audit of the parliamentary election outcome.
Our example is the New South Wales Legislative Council election of 2015, but
the same process could be used for any similar parliament for which data was
available, such as the Australian House of Representatives given the proposed
automatic scanning of ballots.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00129</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Generative Adversarial Neural Networks for Realistic Prostate
  Lesion MRI Synthesis</dc:title>
 <dc:creator>Kitchen, Andy</dc:creator>
 <dc:creator>Seah, Jarrel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4.10</dc:subject>
 <dc:subject>I.4.7</dc:subject>
 <dc:description>  Generative Adversarial Neural Networks (GANs) are applied to the synthetic
generation of prostate lesion MRI images. GANs have been applied to a variety
of natural images, is shown show that the same techniques can be used in the
medical domain to create realistic looking synthetic lesion images. 16mm x 16mm
patches are extracted from 330 MRI scans from the SPIE ProstateX Challenge 2016
and used to train a Deep Convolutional Generative Adversarial Neural Network
(DCGAN) utilizing cutting edge techniques. Synthetic outputs are compared to
real images and the implicit latent representations induced by the GAN are
explored. Training techniques and successful neural network architectures are
explained in detail.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, 2 tables</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00129</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00130</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Session Length in Media Streaming</dc:title>
 <dc:creator>Vasiloudis, Theodore</dc:creator>
 <dc:creator>Vahabi, Hossein</dc:creator>
 <dc:creator>Kravitz, Ross</dc:creator>
 <dc:creator>Rashkov, Valery</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Session length is a very important aspect in determining a user's
satisfaction with a media streaming service. Being able to predict how long a
session will last can be of great use for various downstream tasks, such as
recommendations and ad scheduling. Most of the related literature on user
interaction duration has focused on dwell time for websites, usually in the
context of approximating post-click satisfaction either in search results, or
display ads. In this work we present the first analysis of session length in a
mobile-focused online service, using a real world data-set from a major music
streaming service. We use survival analysis techniques to show that the
characteristics of the length distributions can differ significantly between
users, and use gradient boosted trees with appropriate objectives to predict
the length of a session using only information available at its beginning. Our
evaluation on real world data illustrates that our proposed technique
outperforms the considered baseline.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00130</dc:identifier>
 <dc:identifier>Proceedings of the 40th International ACM SIGIR Conference on
  Research and Development in Information Retrieval (SIGIR 2017). ACM, New
  York, NY, USA, 977-980</dc:identifier>
 <dc:identifier>doi:10.1145/3077136.3080695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00133</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Transfer in Reinforcement Learning by Language Grounding</dc:title>
 <dc:creator>Narasimhan, Karthik</dc:creator>
 <dc:creator>Barzilay, Regina</dc:creator>
 <dc:creator>Jaakkola, Tommi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we explore the utilization of natural language to drive
transfer for reinforcement learning (RL). Despite the wide-spread application
of deep RL techniques, learning generalized policy representations that work
across domains remains a challenging problem. We demonstrate that textual
descriptions of environments provide a compact intermediate channel to
facilitate effective policy transfer. We employ a model-based RL approach
consisting of a differentiable planning module, a model-free component and a
factorized representation to effectively utilize entity descriptions. Our model
outperforms prior work on both transfer and multi-task scenarios in a variety
of different environments.
</dc:description>
 <dc:description>Comment: 12 pages (incl. references)</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00140</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Digit Serial Methods with Applications to Division and Square Root (with
  mechanically checked correctness proofs)</dc:title>
 <dc:creator>Ferguson Jr, Warren E.</dc:creator>
 <dc:creator>Bingham, Jesse</dc:creator>
 <dc:creator>Erk&#xf6;k, Levent</dc:creator>
 <dc:creator>Harrison, John R.</dc:creator>
 <dc:creator>Leslie-Hurd, Joe</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  We present a generic digit serial method (DSM) to compute the digits of a
real number $V$ . Bounds on these digits, and on the errors in the associated
estimates of $V$ formed from these digits, are derived. To illustrate our
results, we derive such bounds for a parameterized family of high-radix
algorithms for division and square root. These bounds enable a DSM designer to
determine, for example, whether a given choice of parameters allows rapid
formation and rounding of its approximation to $V$. All our claims are
mechanically verified using the HOL-Light theorem prover, and are included in
the appendix with commentary.
</dc:description>
 <dc:description>Comment: 32 pages</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00140</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00143</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Algorithms for Scheduling Unsplittable Flows on Paths</dc:title>
 <dc:creator>Jahanjou, Hamidreza</dc:creator>
 <dc:creator>Kantor, Erez</dc:creator>
 <dc:creator>Rajaraman, Rajmohan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we investigate offline and online algorithms for rufpp, the
problem of minimizing the number of rounds required to schedule a set of
unsplittable flows of non-uniform sizes on a given path with non-uniform edge
capacities. rufpp is NP-hard and constant-factor approximation algorithms are
known under the no bottleneck assumption (NBA), which stipulates that maximum
size of a flow is at most the minimum edge capacity. We study rufpp without the
NBA, and present improved online and offline algorithms. We first study offline
rufpp for a restricted class of instances called $\alpha$-small, where the size
of each flow is at most $\alpha$ times the capacity of its bottleneck edge, and
present an $O(\log(1/(1-\alpha)))$-approximation algorithm. Our main result is
an online $O(\log\log c_{\max})$-competitive algorithm for rufpp for general
instances, where $c_{\max}$ is the largest edge capacities, improving upon the
previous best bound of $O(\log c_{\max})$ due to Epstein et al. Our result
leads to an offline $O(\min(\log n, \log m, \log\log c_{\max}))$-approximation
algorithm and an online $O(\min(\log m, \log\log c_{\max}))$-competitive
algorithm for rufpp, where $n$ is the number of flows and $m$ is the number of
edges.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00143</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00146</identifier>
 <datestamp>2017-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-Scale Low-Rank Matrix Learning with Nonconvex Regularizers</dc:title>
 <dc:creator>Yao, Quanming</dc:creator>
 <dc:creator>Kwok, James T.</dc:creator>
 <dc:creator>Wang, Taifeng</dc:creator>
 <dc:creator>Liu, Tie-Yan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Low-rank modeling has many important applications in computer vision and
machine learning. While the matrix rank is often approximated by the convex
nuclear norm, the use of nonconvex low-rank regularizers has demonstrated
better empirical performance. However, the resulting optimization problem is
much more challenging. Recent state-of-the-art requires an expensive full SVD
in each iteration. In this paper, we show that for many commonly-used nonconvex
low-rank regularizers, a cutoff can be derived to automatically threshold the
singular values obtained from the proximal operator. This allows such operator
being efficiently approximated by power method. Based on it, we develop a
proximal gradient algorithm (and its accelerated variant) with inexact proximal
splitting and prove that a convergence rate of O(1/T) where T is the number of
iterations is guaranteed. Furthermore, we show the proposed algorithm can be
well parallelized, which achieves nearly linear speedup w.r.t the number of
threads. Extensive experiments are performed on matrix completion and robust
principal component analysis, which shows a significant speedup over the
state-of-the-art. Moreover, the matrix solution obtained is more accurate and
has a lower rank than that of the nuclear norm regularizer.
</dc:description>
 <dc:description>Comment: Extension of ICDM-2015 conference paper. arXiv admin note: text
  overlap with arXiv:1512.00984</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00148</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model-theoretic dividing lines in least fixed-point logic over finite
  structures</dc:title>
 <dc:creator>Bhaskar, Siddharth</dc:creator>
 <dc:creator>Kruckman, Alex</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We explore classical model-theoretic dividing lines for first-order logic
(the order property, the strict order property, the independence property, and
the tree property 2) in the context of FO[LFP] definability over families of
finite structures. We show that the strict order property allows us to
interpret initial segments of arithmetic. As a consequence, contrary to the
first-order setting, the order property and the independence property are
equivalent. On the other hand, we show that the order property, the tree
property 2, and the strict order property remain distinct.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00149</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Hierarchical Clustering Using Ordinal Queries</dc:title>
 <dc:creator>Emamjomeh-Zadeh, Ehsan</dc:creator>
 <dc:creator>Kempe, David</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In many applications of clustering (for example, ontologies or clusterings of
animal or plant species), hierarchical clusterings are more descriptive than a
flat clustering. A hierarchical clustering over $n$ elements is represented by
a rooted binary tree with $n$ leaves, each corresponding to one element. The
subtrees rooted at interior nodes capture the clusters. In this paper, we study
active learning of a hierarchical clustering using only ordinal queries. An
ordinal query consists of a set of three elements, and the response to a query
reveals the two elements (among the three elements in the query) which are
&quot;closer&quot; to each other than to the third one. We say that elements $x$ and $x'$
are closer to each other than $x''$ if there exists a cluster containing $x$
and $x'$, but not $x''$.
  When all the query responses are correct, there is a deterministic algorithm
that learns the underlying hierarchical clustering using at most $n \log_2 n$
adaptive ordinal queries. We generalize this algorithm to be robust in a model
in which each query response is correct independently with probability $p &gt;
\frac{1}{2}$, and adversarially incorrect with probability $1 - p$. We show
that in the presence of noise, our algorithm outputs the correct hierarchical
clustering with probability at least $1 - \delta$, using $O(n \log n + n
\log(1/\delta))$ adaptive ordinal queries. For our results, adaptivity is
crucial: we prove that even in the absence of noise, every non-adaptive
algorithm requires $\Omega(n^3)$ ordinal queries in the worst case.
</dc:description>
 <dc:description>Comment: In SODA 2018</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00151</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal design of three-planetary-gear power-split hybrid powertrains</dc:title>
 <dc:creator>Zhuang, Weichao</dc:creator>
 <dc:creator>Zhang, Xiaowu</dc:creator>
 <dc:creator>Zhao, Ding</dc:creator>
 <dc:creator>Peng, Huei</dc:creator>
 <dc:creator>Wang, Lianmou</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Many of today's power-split hybrid electric vehicles (HEVs) utilize planetary
gears (PGs) to connect the powertrain elements together. Recent power-split
HEVs tend to use two PGs and some of them have multiple modes to achieve better
fuel economy and driving performance. Looking to the future, hybrid powertrain
technologies must be enhanced to design hybrid light trucks. For light trucks,
the need for multi-mode and more PGs is stronger, to achieve the required
performance. To systematically explore all the possible designs of multi-mode
HEVs with three PGs, an efficient searching and optimization methodology is
proposed. All possible clutch topology and modes for one existing configuration
that uses three PGs were exhaustively searched. The launching performance is
first used to screen out designs that fail to satisfy the required launching
performance. A near-optimal and computationally efficient energy management
strategy was then employed to identify designs that achieve good fuel economy.
The proposed design process successfully identify 8 designs that achieve better
launching performance and better fuel economy, while using fewer number of
clutches than the benchmark and a patented design.
</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00151</dc:identifier>
 <dc:identifier>International Journal of Automotive Technology, April 2016, Volume
  17, Issue 2, pp 299-309</dc:identifier>
 <dc:identifier>doi:10.1007/s12239-016-0030-0</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00153</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Tracking and Verifying: A Framework for Real-Time and High
  Accuracy Visual Tracking</dc:title>
 <dc:creator>Fan, Heng</dc:creator>
 <dc:creator>Ling, Haibin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Being intensively studied, visual tracking has seen great recent advances in
either speed (e.g., with correlation filters) or accuracy (e.g., with deep
features). Real-time and high accuracy tracking algorithms, however, remain
scarce. In this paper we study the problem from a new perspective and present a
novel parallel tracking and verifying (PTAV) framework, by taking advantage of
the ubiquity of multi-thread techniques and borrowing from the success of
parallel tracking and mapping in visual SLAM. Our PTAV framework typically
consists of two components, a tracker T and a verifier V, working in parallel
on two separate threads. The tracker T aims to provide a super real-time
tracking inference and is expected to perform well most of the time; by
contrast, the verifier V checks the tracking results and corrects T when
needed. The key innovation is that, V does not work on every frame but only
upon the requests from T; on the other end, T may adjust the tracking according
to the feedback from V. With such collaboration, PTAV enjoys both the high
efficiency provided by T and the strong discriminative power by V. In our
extensive experiments on popular benchmarks including OTB2013, OTB2015, TC128
and UAV20L, PTAV achieves the best tracking accuracy among all real-time
trackers, and in fact performs even better than many deep learning based
solutions. Moreover, as a general framework, PTAV is very flexible and has
great rooms for improvement and generalization.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00153</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00154</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Rating Regression with Abstractive Tips Generation for
  Recommendation</dc:title>
 <dc:creator>Li, Piji</dc:creator>
 <dc:creator>Wang, Zihao</dc:creator>
 <dc:creator>Ren, Zhaochun</dc:creator>
 <dc:creator>Bing, Lidong</dc:creator>
 <dc:creator>Lam, Wai</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Recently, some E-commerce sites launch a new interaction box called Tips on
their mobile apps. Users can express their experience and feelings or provide
suggestions using short texts typically several words or one sentence. In
essence, writing some tips and giving a numerical rating are two facets of a
user's product assessment action, expressing the user experience and feelings.
Jointly modeling these two facets is helpful for designing a better
recommendation system. While some existing models integrate text information
such as item specifications or user reviews into user and item latent factors
for improving the rating prediction, no existing works consider tips for
improving recommendation quality. We propose a deep learning based framework
named NRT which can simultaneously predict precise ratings and generate
abstractive tips with good linguistic quality simulating user experience and
feelings. For abstractive tips generation, gated recurrent neural networks are
employed to &quot;translate&quot; user and item latent representations into a concise
sentence. Extensive experiments on benchmark datasets from different domains
show that NRT achieves significant improvements over the state-of-the-art
methods. Moreover, the generated tips can vividly predict the user experience
and feelings.
</dc:description>
 <dc:description>Comment: SIGIR 2017</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00154</dc:identifier>
 <dc:identifier>doi:10.1145/3077136.3080822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00157</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Stable Coin with Pro-rated Rebasement and Price Manipulation
  Protection</dc:title>
 <dc:creator>Orlicki, Jose I.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  An existing pseudo-commodity and a smart contracts framework allow the
creation of a purely automatic and self-sufficient price-stable cryptocurrency,
without human intervention. This new currency, we denominated Toroid or TRD,
can be used more extensively for commerce than pseudo commodity
cryptocurrencies due to its lower volatility. Also, is suitable for investment,
as the tokens in each account multiply, return interest, when the market grows.
Like the controlled fiat money of a central bank plus the benefits of an
inflation-adjusted perpetuity bond. Collateral in base coin, for example BTC or
ETH, can be added to bootstrap your own Toroid investment or withdrawed after a
very small investment period. So, the Toroids are not created from nothing nor
have a limited monetary base. The minimum investment period can be very small,
for example one day, and you keep the interest but you can return the Toroids
and refund your collateral. That is a one-side only peg to a deflationary
crypto-commodity. The stability is guaranteed by endogenous measurements of
number of transactions and wallet pro-rated rebasement of balance to reduce
volatility of price. Each account has its own rebasement due to the account
creation timestamp. Rebasement control mechanism is progressive during initial
bootstrap period because price manipulation protection is more severe when the
capital involved is smaller. Rebasement has a quick positive start to
incentivize early adopters that see only big growth in their TRD account during
bootstrap period. Finally, the new rebasement control makes it economically
infeasible for an attacker targeting the coin with manipulated transaction
volume if we set the minimum rebasement greater than profits from massive
currency manipulation.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures, draft</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00157</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00159</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Denoising via CNNs: An Adversarial Approach</dc:title>
 <dc:creator>Divakar, Nithish</dc:creator>
 <dc:creator>Babu, R. Venkatesh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Is it possible to recover an image from its noisy version using convolutional
neural networks? This is an interesting problem as convolutional layers are
generally used as feature detectors for tasks like classification, segmentation
and object detection. We present a new CNN architecture for blind image
denoising which synergically combines three architecture components, a
multi-scale feature extraction layer which helps in reducing the effect of
noise on feature maps, an l_p regularizer which helps in selecting only the
appropriate feature maps for the task of reconstruction, and finally a three
step training approach which leverages adversarial training to give the final
performance boost to the model. The proposed model shows competitive denoising
performance when compared to the state-of-the-art approaches.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00160</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing the Input Representation: From Complexity to Simplicity</dc:title>
 <dc:creator>Moosavi, Nafise Sadat</dc:creator>
 <dc:creator>Strube, Michael</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We introduce an efficient algorithm for mining informative combinations of
attribute-values for a given task. We use informative attribute-values to
enhance the input representation of data. We apply our approach to coreference
resolution using a simple set of attributes like syntactic roles and string
match. With the enhanced representation, a simple coreference model outperforms
more complex state-of-the-art models by a large margin. The use of the enhanced
representation results in robust improvements in both in-domain and
out-of-domain evaluations.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00160</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00163</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Vision-Based Smart Hospitals: A System for Tracking and
  Monitoring Hand Hygiene Compliance</dc:title>
 <dc:creator>Haque, Albert</dc:creator>
 <dc:creator>Guo, Michelle</dc:creator>
 <dc:creator>Alahi, Alexandre</dc:creator>
 <dc:creator>Yeung, Serena</dc:creator>
 <dc:creator>Luo, Zelun</dc:creator>
 <dc:creator>Rege, Alisha</dc:creator>
 <dc:creator>Jopling, Jeffrey</dc:creator>
 <dc:creator>Downing, Lance</dc:creator>
 <dc:creator>Beninati, William</dc:creator>
 <dc:creator>Singh, Amit</dc:creator>
 <dc:creator>Platchek, Terry</dc:creator>
 <dc:creator>Milstein, Arnold</dc:creator>
 <dc:creator>Fei-Fei, Li</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  One in twenty-five patients admitted to a hospital will suffer from a
hospital acquired infection. If we can intelligently track healthcare staff,
patients, and visitors, we can better understand the sources of such
infections. We envision a smart hospital capable of increasing operational
efficiency and improving patient care with less spending. In this paper, we
propose a non-intrusive vision-based system for tracking people's activity in
hospitals. We evaluate our method for the problem of measuring hand hygiene
compliance. Empirically, our method outperforms existing solutions such as
proximity-based techniques and covert in-person observational studies. We
present intuitive, qualitative results that analyze human movement patterns and
conduct spatial analytics which convey our method's interpretability. This work
is a first step towards a computer-vision based smart hospital and demonstrates
promising results for reducing hospital acquired infections.
</dc:description>
 <dc:description>Comment: Machine Learning in Health Care Conference (MLHC 2017)</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00163</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00169</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Locally Weighted Fixation Density-Based Metric for Assessing the
  Quality of Visual Saliency Predictions</dc:title>
 <dc:creator>Gide, Milind S.</dc:creator>
 <dc:creator>Karam, Lina J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With the increased focus on visual attention (VA) in the last decade, a large
number of computational visual saliency methods have been developed over the
past few years. These models are traditionally evaluated by using performance
evaluation metrics that quantify the match between predicted saliency and
fixation data obtained from eye-tracking experiments on human observers. Though
a considerable number of such metrics have been proposed in the literature,
there are notable problems in them. In this work, we discuss shortcomings in
existing metrics through illustrative examples and propose a new metric that
uses local weights based on fixation density which overcomes these flaws. To
compare the performance of our proposed metric at assessing the quality of
saliency prediction with other existing metrics, we construct a ground-truth
subjective database in which saliency maps obtained from 17 different VA models
are evaluated by 16 human observers on a 5-point categorical scale in terms of
their visual resemblance with corresponding ground-truth fixation density maps
obtained from eye-tracking data. The metrics are evaluated by correlating
metric scores with the human subjective ratings. The correlation results show
that the proposed evaluation metric outperforms all other popular existing
metrics. Additionally, the constructed database and corresponding subjective
ratings provide an insight into which of the existing metrics and future
metrics are better at estimating the quality of saliency prediction and can be
used as a benchmark.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00169</dc:identifier>
 <dc:identifier>IEEE Transactions on Image Processing, vol. 25, no. 8, pp.
  3852-3861, Aug. 2016</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2016.2577498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00171</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PROBE-GK: Predictive Robust Estimation using Generalized Kernels</dc:title>
 <dc:creator>Peretroukhin, Valentin</dc:creator>
 <dc:creator>Vega-Brown, William</dc:creator>
 <dc:creator>Roy, Nicholas</dc:creator>
 <dc:creator>Kelly, Jonathan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Many algorithms in computer vision and robotics make strong assumptions about
uncertainty, and rely on the validity of these assumptions to produce accurate
and consistent state estimates. In practice, dynamic environments may degrade
sensor performance in predictable ways that cannot be captured with static
uncertainty parameters. In this paper, we employ fast nonparametric Bayesian
inference techniques to more accurately model sensor uncertainty. By setting a
prior on observation uncertainty, we derive a predictive robust estimator, and
show how our model can be learned from sample images, both with and without
knowledge of the motion used to generate the data. We validate our approach
through Monte Carlo simulations, and report significant improvements in
localization accuracy relative to a fixed noise model in several settings,
including on synthetic data, the KITTI dataset, and our own experimental
platform.
</dc:description>
 <dc:description>Comment: In Proceedings of the IEEE International Conference on Robotics and
  Automation (ICRA'16), Stockholm, Sweden, May 16-21, 2016</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00171</dc:identifier>
 <dc:identifier>doi:10.1109/ICRA.2016.7487212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00174</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PROBE: Predictive Robust Estimation for Visual-Inertial Navigation</dc:title>
 <dc:creator>Peretroukhin, Valentin</dc:creator>
 <dc:creator>Clement, Lee</dc:creator>
 <dc:creator>Giamou, Matthew</dc:creator>
 <dc:creator>Kelly, Jonathan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Navigation in unknown, chaotic environments continues to present a
significant challenge for the robotics community. Lighting changes,
self-similar textures, motion blur, and moving objects are all considerable
stumbling blocks for state-of-the-art vision-based navigation algorithms. In
this paper we present a novel technique for improving localization accuracy
within a visual-inertial navigation system (VINS). We make use of training data
to learn a model for the quality of visual features with respect to
localization error in a given environment. This model maps each visual
observation from a predefined prediction space of visual-inertial predictors
onto a scalar weight, which is then used to scale the observation covariance
matrix. In this way, our model can adjust the influence of each observation
according to its quality. We discuss our choice of predictors and report
substantial reductions in localization error on 4 km of data from the KITTI
dataset, as well as on experimental datasets consisting of 700 m of indoor and
outdoor driving on a small ground rover equipped with a Skybotix VI-Sensor.
</dc:description>
 <dc:description>Comment: In Proceedings of the 2015 IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS'15), Hamburg, Germany, Sep. 28-Oct. 2,
  2015</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00174</dc:identifier>
 <dc:identifier>doi:10.1109/IROS.2015.7353890</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00179</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Investigation into the Pedagogical Features of Documents</dc:title>
 <dc:creator>Sheng, Emily</dc:creator>
 <dc:creator>Natarajan, Prem</dc:creator>
 <dc:creator>Gordon, Jonathan</dc:creator>
 <dc:creator>Burns, Gully</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Characterizing the content of a technical document in terms of its learning
utility can be useful for applications related to education, such as generating
reading lists from large collections of documents. We refer to this learning
utility as the &quot;pedagogical value&quot; of the document to the learner. While
pedagogical value is an important concept that has been studied extensively
within the education domain, there has been little work exploring it from a
computational, i.e., natural language processing (NLP), perspective. To allow a
computational exploration of this concept, we introduce the notion of
&quot;pedagogical roles&quot; of documents (e.g., Tutorial and Survey) as an intermediary
component for the study of pedagogical value. Given the lack of available
corpora for our exploration, we create the first annotated corpus of
pedagogical roles and use it to test baseline techniques for automatic
prediction of such roles.
</dc:description>
 <dc:description>Comment: 12th Workshop on Innovative Use of NLP for Building Educational
  Applications (BEA) at EMNLP 2017; 12 pages</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00180</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model-based learning of local image features for unsupervised texture
  segmentation</dc:title>
 <dc:creator>Kiechle, Martin</dc:creator>
 <dc:creator>Storath, Martin</dc:creator>
 <dc:creator>Weinmann, Andreas</dc:creator>
 <dc:creator>Kleinsteuber, Martin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Features that capture well the textural patterns of a certain class of images
are crucial for the performance of texture segmentation methods. The manual
selection of features or designing new ones can be a tedious task. Therefore,
it is desirable to automatically adapt the features to a certain image or class
of images. Typically, this requires a large set of training images with similar
textures and ground truth segmentation. In this work, we propose a framework to
learn features for texture segmentation when no such training data is
available. The cost function for our learning process is constructed to match a
commonly used segmentation model, the piecewise constant Mumford-Shah model.
This means that the features are learned such that they provide an
approximately piecewise constant feature image with a small jump set. Based on
this idea, we develop a two-stage algorithm which first learns suitable
convolutional features and then performs a segmentation. We note that the
features can be learned from a small set of images, from a single image, or
even from image patches. The proposed method achieves a competitive rank in the
Prague texture segmentation benchmark, and it is effective for segmenting
histological images.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00180</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00183</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DROP: Dimensionality Reduction Optimization for Time Series</dc:title>
 <dc:creator>Suri, Sahaana</dc:creator>
 <dc:creator>Bailis, Peter</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Dimensionality reduction is critical in analyzing increasingly high-volume,
high-dimensional time series. In this paper, we revisit a now-classic study of
time series dimensionality reduction operators and find that for a given
quality constraint, Principal Component Analysis (PCA) uncovers representations
that are over 2x smaller than those obtained via alternative techniques favored
in the literature. However, as classically implemented via Singular Value
Decomposition (SVD), PCA is incredibly expensive for large datasets. Therefore,
we present DROP, a dimensionality reduction optimizer for high-dimensional
analytics pipelines that greatly reduces the cost of the PCA operation over
time series datasets. We show that many time series are highly structured,
hence a small number of data points are sufficient to characterize the data
set, which permits aggressive sampling during dimensionality reduction. This
sampling allows DROP to uncover high quality low-dimensional bases in running
time proportional to the dataset's intrinsic dimensionality, independent of the
actual dataset size, without requiring the user to specify this intrinsic
dimensionality a priori. DROP further enables downstream-operation-aware
optimization by coupling sampling with online progress estimation, trading-off
degree of dimensionality reduction with the combined runtime of DROP and
downstream analytics tasks. By progressively sampling its input, computing a
candidate basis for transformation, and terminating once it finds a
sufficiently high quality basis in a reasonable running time, DROP provides
speedups of up to 50x over PCA via SVD and 33x in end-to-end high-dimensional
analytics pipelines.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00183</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00185</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tensorial Recurrent Neural Networks for Longitudinal Data Analysis</dc:title>
 <dc:creator>Bai, Mingyuan</dc:creator>
 <dc:creator>Zhang, Boyan</dc:creator>
 <dc:creator>Gao, Junbin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Traditional Recurrent Neural Networks assume vectorized data as inputs.
However many data from modern science and technology come in certain structures
such as tensorial time series data. To apply the recurrent neural networks for
this type of data, a vectorisation process is necessary, while such a
vectorisation leads to the loss of the precise information of the spatial or
longitudinal dimensions. In addition, such a vectorized data is not an optimum
solution for learning the representation of the longitudinal data. In this
paper, we propose a new variant of tensorial neural networks which directly
take tensorial time series data as inputs. We call this new variant as
Tensorial Recurrent Neural Network (TRNN). The proposed TRNN is based on tensor
Tucker decomposition.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00185</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00186</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling and Analysis of Network Dynamics in Complex Communication
  Networks Using Social Network Methods</dc:title>
 <dc:creator>Khan, Bisma S.</dc:creator>
 <dc:creator>Niazi, Muaz A.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>E.1, G.2.2, I.6.5</dc:subject>
 <dc:description>  Modern communication networks are inherently complex in nature. First of all,
they have a large number of heterogeneous components. Secondly, their
connectivity is extremely dynamic. Nodes can come and go, links can be removed
and added over time. Traditional modeling and simulation techniques amalgamate
or ignore such dynamics and therefore, are unable to represent them. Complex
communication networks are therefore better modeled as mathematical structures
called graphs. Modeling as graphs allows for the application of complex
techniques such as various network based analysis techniques. While this is a
very important and much needed skill for communication networks researchers and
engineers, to the best of our knowledge, currently there is no resource
describing these details. In this paper, we give a concise but comprehensive
review of modeling complex communication networks as graphs. We also show how
to apply complex social network analysis on these models besides a
demonstration of formal modeling network dynamics.
</dc:description>
 <dc:description>Comment: 15 pages, 3 figures</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00187</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-time Deep Video Deinterlacing</dc:title>
 <dc:creator>Zhu, Haichao</dc:creator>
 <dc:creator>Liu, Xueting</dc:creator>
 <dc:creator>Mao, Xiangyu</dc:creator>
 <dc:creator>Wong, Tien-Tsin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Interlacing is a widely used technique, for television broadcast and video
recording, to double the perceived frame rate without increasing the bandwidth.
But it presents annoying visual artifacts, such as flickering and silhouette
&quot;serration,&quot; during the playback. Existing state-of-the-art deinterlacing
methods either ignore the temporal information to provide real-time performance
but lower visual quality, or estimate the motion for better deinterlacing but
with a trade-off of higher computational cost. In this paper, we present the
first and novel deep convolutional neural networks (DCNNs) based method to
deinterlace with high visual quality and real-time performance. Unlike existing
models for super-resolution problems which relies on the translation-invariant
assumption, our proposed DCNN model utilizes the temporal information from both
the odd and even half frames to reconstruct only the missing scanlines, and
retains the given odd and even scanlines for producing the full deinterlaced
frames. By further introducing a layer-sharable architecture, our system can
achieve real-time performance on a single GPU. Experiments shows that our
method outperforms all existing methods, in terms of reconstruction accuracy
and computational performance.
</dc:description>
 <dc:description>Comment: 9 pages, 11 figures</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00187</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00188</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On outer-connected domination for graph products</dc:title>
 <dc:creator>Hashemipour, M.</dc:creator>
 <dc:creator>Hooshmandasl, M. R.</dc:creator>
 <dc:creator>Shakiba, A.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  An outer-connected dominating set for an arbitrary graph $G$ is a set
$\tilde{D} \subseteq V$ such that $\tilde{D}$ is a dominating set and the
induced subgraph $G [V \setminus \tilde{D}]$ be connected. In this paper, we
focus on the outer-connected domination number of the product of graphs. We
investigate the existence of outer-connected dominating set in lexicographic
product and Corona of two arbitrary graphs, and we present upper bounds for
outer-connected domination number in lexicographic and Cartesian product of
graphs. Also, we establish an equivalent form of the Vizing's conjecture for
outer-connected domination number in lexicographic and Cartesian product as
$\tilde{\gamma_c}(G \circ K)\tilde{\gamma_c}(H \circ K) \leq
\tilde{\gamma_c}(G\Box H)\circ K$. Furthermore, we study the outer-connected
domination number of the direct product of finitely many complete graphs.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00192</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Visual Query Systems in the Web Era (extended version)</dc:title>
 <dc:creator>Lloret-Gazo, Jorge</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  As more and more collections of data are becoming available on the web to
everyone, non expert users demand easy ways to retrieve data from these
collections. One solution is the so called Visual Query Systems (VQS) where
queries are represented visually and users do not have to understand query
languages such as SQL or XQuery. In 1996, a paper by Catarci reviewed the
Visual Query Systems available until that year. In this paper, we review VQSs
from 1997 until now and try to determine whether they have been the solution
for non expert users. The short answer is no because very few systems have in
fact been used in real environments or as commercial tools. We have also
gathered basic features of VQSs such as the visual representation adopted to
present the reality of interest or the visual representation adopted to express
queries.
</dc:description>
 <dc:description>Comment: 34 pages. 32 figures</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00192</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00194</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed multi-agent Gaussian regression via Karhunen-Lo\`eve
  expansions</dc:title>
 <dc:creator>Pillonetto, Gianluigi</dc:creator>
 <dc:creator>Schenato, Luca</dc:creator>
 <dc:creator>Varagnolo, Damiano</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  We consider the problem of distributedly estimating Gaussian random fields in
multi-agent frameworks. Each sensor collects few measurements and aims to
collaboratively reconstruct a common estimate based on all data. Agents are
assumed to have limited computational and communication capabilities and to
gather $M$ noisy measurements in total on input locations independently drawn
from a known common probability density. The optimal solution would require
agents to exchange all the $M$ input locations and measurements and then invert
an $M\times M$ matrix, a non-scalable task. Differently, we propose two
suboptimal approaches using the first $E$ orthonormal eigenfunctions obtained
from the KL expansion of the chosen kernel, where typically $E\ll M$. The
benefit is twofold: first, the computation and communication complexities scale
with $E$ and not with $M$. Second, computing the required sufficient statistics
can be performed via standard average consensus algorithms. We obtain
probabilistic non-asymptotic bounds for both approaches, useful to determine a
priori the desired level of estimation accuracy. Furthermore, we also derive
new distributed strategies to tune the regularization parameter which rely on
the Stein's unbiased risk estimate (SURE) paradigm and can again be implemented
via standard average consensus algorithms. The proposed estimators and bounds
are finally tested on both synthetic and real field data.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00197</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video Object Segmentation with Re-identification</dc:title>
 <dc:creator>Li, Xiaoxiao</dc:creator>
 <dc:creator>Qi, Yuankai</dc:creator>
 <dc:creator>Wang, Zhe</dc:creator>
 <dc:creator>Chen, Kai</dc:creator>
 <dc:creator>Liu, Ziwei</dc:creator>
 <dc:creator>Shi, Jianping</dc:creator>
 <dc:creator>Luo, Ping</dc:creator>
 <dc:creator>Tang, Xiaoou</dc:creator>
 <dc:creator>Loy, Chen Change</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Conventional video segmentation methods often rely on temporal continuity to
propagate masks. Such an assumption suffers from issues like drifting and
inability to handle large displacement. To overcome these issues, we formulate
an effective mechanism to prevent the target from being lost via adaptive
object re-identification. Specifically, our Video Object Segmentation with
Re-identification (VS-ReID) model includes a mask propagation module and a ReID
module. The former module produces an initial probability map by flow warping
while the latter module retrieves missing instances by adaptive matching. With
these two modules iteratively applied, our VS-ReID records a global mean
(Region Jaccard and Boundary F measure) of 0.699, the best performance in 2017
DAVIS Challenge.
</dc:description>
 <dc:description>Comment: Published in CVPR 2017 Workshop, DAVIS Challenge on Video Object
  Segmentation 2017 (Winning Entry)</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00199</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Switching Convolutional Neural Network for Crowd Counting</dc:title>
 <dc:creator>Sam, Deepak Babu</dc:creator>
 <dc:creator>Surya, Shiv</dc:creator>
 <dc:creator>Babu, R. Venkatesh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel crowd counting model that maps a given crowd scene to its
density. Crowd analysis is compounded by myriad of factors like inter-occlusion
between people due to extreme crowding, high similarity of appearance between
people and background elements, and large variability of camera view-points.
Current state-of-the art approaches tackle these factors by using multi-scale
CNN architectures, recurrent networks and late fusion of features from
multi-column CNN with different receptive fields. We propose switching
convolutional neural network that leverages variation of crowd density within
an image to improve the accuracy and localization of the predicted crowd count.
Patches from a grid within a crowd scene are relayed to independent CNN
regressors based on crowd count prediction quality of the CNN established
during training. The independent CNN regressors are designed to have different
receptive fields and a switch classifier is trained to relay the crowd scene
patch to the best CNN regressor. We perform extensive experiments on all major
crowd counting datasets and evidence better performance compared to current
state-of-the-art methods. We provide interpretable representations of the
multichotomy of space of crowd scene patches inferred from the switch. It is
observed that the switch relays an image patch to a particular CNN column based
on density of crowd.
</dc:description>
 <dc:description>Comment: Version 2: Added references. Corrected Typos. Published at CVPR 2017,
  Honolulu, Hawaii. The first two authors contributed equally. For Project Page
  see http://val.serc.iisc.ernet.in/crowdcnn/</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00199</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00200</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anytime, Anywhere Anomaly Recovery through an Online Robot Introspection
  Framework</dc:title>
 <dc:creator>Wu, Hongmin</dc:creator>
 <dc:creator>Lin, Hongbin</dc:creator>
 <dc:creator>Luo, Shuangqi</dc:creator>
 <dc:creator>Duan, Shuangda</dc:creator>
 <dc:creator>Xiang, Chen</dc:creator>
 <dc:creator>Zhao, Bo</dc:creator>
 <dc:creator>Rojas, Juan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Robotic introspection and online decision making have been an area of
increased focus. The goal is to endow robots with the ability to understand
their actions and make timely decisions to reach their goals. Particularly, in
unstructured environments, external perturbations are hard to model in
low-level control systems and often lead to failure. Robots must then
understand nominal and anomalous conditions and trigger timely responses to
behaviors that allow the robot to recover and even learn from them and prevent
them. Our contribution is the implementation of a fast and robust robot
introspection system that allows recovery from (one or multiple) anomalous
situations at any point in the task. The system handles both internal modeling
errors as well as external perturbations. The robustness of the system is
demonstrated across multiple manipulation tasks. The system assumes tasks are
decomposed into a sequence of nodes, where each node performs a dual role: one
of motion generation and one of introspection. Motion generation is flexible
and can be done with any type of accessible approach. Introspection is done by
modeling the robots multimodal signals using a range of HMMs including
nonparametric Bayesian hidden Markov models. Such models yield strong
expressive power to discriminate both nominal and anomalous situations. We made
use of a generic strategy for recovery that is easy and flexible to design
across different tasks. A new metric for anomaly detection, critical in the
proper assessment of the system after recovery has taken place was also
designed. We show how the system recovers from both pose estimation errors that
lead to collisions in pick tasks as well as external human collisions.
Furthermore, the system is able to robustly recover from collisions that occur
at multiple points in the task; even, when anomalies repeatedly appear at a
specific point in the task.
</dc:description>
 <dc:description>Comment: 8 pages, 8 figures, 1 table. As submitted to humanoids 2017</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00200</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00214</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Natural Language Processing with Small Feed-Forward Networks</dc:title>
 <dc:creator>Botha, Jan A.</dc:creator>
 <dc:creator>Pitler, Emily</dc:creator>
 <dc:creator>Ma, Ji</dc:creator>
 <dc:creator>Bakalov, Anton</dc:creator>
 <dc:creator>Salcianu, Alex</dc:creator>
 <dc:creator>Weiss, David</dc:creator>
 <dc:creator>McDonald, Ryan</dc:creator>
 <dc:creator>Petrov, Slav</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>68T50</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We show that small and shallow feed-forward neural networks can achieve near
state-of-the-art results on a range of unstructured and structured language
processing tasks while being considerably cheaper in memory and computational
requirements than deep recurrent models. Motivated by resource-constrained
environments like mobile phones, we showcase simple techniques for obtaining
such small neural network models, and investigate different tradeoffs when
deciding how to allocate a small memory budget.
</dc:description>
 <dc:description>Comment: EMNLP 2017 short paper</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00219</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Some Results on [1, k]-sets of Lexicographic Products of Graphs</dc:title>
 <dc:creator>Sharifani, P.</dc:creator>
 <dc:creator>Hooshmandasl, M. R.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A subset $S \subseteq V$ in a graph $G = (V,E)$ is called a $[1, k]$-set, if
for every vertex $v \in V \setminus S$, $1 \leq | N_G(v) \cap S | \leq k$. The
$[1,k]$-domination number of $G$, denoted by $\gamma_{[1, k]}(G)$ is the size
of the smallest $[1,k]$-sets of $G$. A set $S'\subseteq V(G)$ is called a total
$[1,k]$-set, if for every vertex $v \in V$, $1 \leq | N_G(v) \cap S | \leq k$.
If a graph $G$ has at least one total $[1, k]$-set then the cardinality of the
smallest such set is denoted by $\gamma_{t[1, k]}(G)$. We consider $[1,
k]$-sets that are also independent. Note that not every graph has an
independent $[1, k]$-set. For graphs having an independent $[1, k]$-set, we
define $[1, k]$-independence numbers which is denoted by $\gamma_{i[1, k]}(G)$.
In this paper, we investigate the existence of $[1,k]$-sets in lexicographic
products $G\circ H$. Furthermore, we completely characterize graphs which their
lexicographic product has at least one total $[1,k]$-set. Also, we determine
$\gamma_{[1, k]}(G\circ H)$, $\gamma_{t[1, k]}(G\circ H)$ and $\gamma_{i[1,
k]}(G\circ H)$. Finally, we show that finding smallest total $[1, k]$-set is
$NP$-complete.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00219</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00221</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Efficient Data Collection in UAV Enabled Wireless Sensor Network</dc:title>
 <dc:creator>Zhan, Cheng</dc:creator>
 <dc:creator>Zeng, Yong</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In wireless sensor networks (WSNs), utilizing the unmanned aerial vehicle
(UAV) as a mobile data collector for the ground sensor nodes (SNs) is an
energy-efficient technique to prolong the network lifetime. Specifically, since
the UAV can sequentially move close to each of the SNs when collecting data
from them and thus reduce the link distance for saving the SNs' transmission
energy. In this letter, considering a general fading channel model for the
SN-UAV links, we jointly optimize the SNs' wake-up schedule and UAV's
trajectory to minimize the maximum energy consumption of all SNs, while
ensuring that the required amount of data is collected reliably from each SN.
We formulate our design as a mixed-integer non-convex optimization problem. By
applying the successive convex optimization technique, an efficient iterative
algorithm is proposed to find a sub-optimal solution. Numerical results show
that the proposed scheme achieves significant network energy saving as compared
to benchmark schemes.
</dc:description>
 <dc:description>Comment: Submitted for possible journal publication</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00221</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00223</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Hallucinate Face Images via Component Generation and
  Enhancement</dc:title>
 <dc:creator>Song, Yibing</dc:creator>
 <dc:creator>Zhang, Jiawei</dc:creator>
 <dc:creator>He, Shengfeng</dc:creator>
 <dc:creator>Bao, Linchao</dc:creator>
 <dc:creator>Yang, Qingxiong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  We propose a two-stage method for face hallucination. First, we generate
facial components of the input image using CNNs. These components represent the
basic facial structures. Second, we synthesize fine-grained facial structures
from high resolution training images. The details of these structures are
transferred into facial components for enhancement. Therefore, we generate
facial components to approximate ground truth global appearance in the first
stage and enhance them through recovering details in the second stage. The
experiments demonstrate that our method performs favorably against
state-of-the-art methods
</dc:description>
 <dc:description>Comment: IJCAI 2017. Project page:
  http://www.cs.cityu.edu.hk/~yibisong/ijcai17_sr/index.html</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00224</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Preprocessing for Robust Face Sketch Synthesis</dc:title>
 <dc:creator>Song, Yibing</dc:creator>
 <dc:creator>Zhang, Jiawei</dc:creator>
 <dc:creator>Bao, Linchao</dc:creator>
 <dc:creator>Yang, Qingxiong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Exemplar-based face sketch synthesis methods usually meet the challenging
problem that input photos are captured in different lighting conditions from
training photos. The critical step causing the failure is the search of similar
patch candidates for an input photo patch. Conventional illumination invariant
patch distances are adopted rather than directly relying on pixel intensity
difference, but they will fail when local contrast within a patch changes. In
this paper, we propose a fast preprocessing method named Bidirectional
Luminance Remapping (BLR), which interactively adjust the lighting of training
and input photos. Our method can be directly integrated into state-of-the-art
exemplar-based methods to improve their robustness with ignorable computational
cost.
</dc:description>
 <dc:description>Comment: IJCAI 2017. Project page:
  http://www.cs.cityu.edu.hk/~yibisong/ijcai17_sketch/index.html</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00225</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CREST: Convolutional Residual Learning for Visual Tracking</dc:title>
 <dc:creator>Song, Yibing</dc:creator>
 <dc:creator>Ma, Chao</dc:creator>
 <dc:creator>Gong, Lijun</dc:creator>
 <dc:creator>Zhang, Jiawei</dc:creator>
 <dc:creator>Lau, Rynson</dc:creator>
 <dc:creator>Yang, Ming-Hsuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Discriminative correlation filters (DCFs) have been shown to perform
superiorly in visual tracking. They only need a small set of training samples
from the initial frame to generate an appearance model. However, existing DCFs
learn the filters separately from feature extraction, and update these filters
using a moving average operation with an empirical weight. These DCF trackers
hardly benefit from the end-to-end training. In this paper, we propose the
CREST algorithm to reformulate DCFs as a one-layer convolutional neural
network. Our method integrates feature extraction, response map generation as
well as model update into the neural networks for an end-to-end training. To
reduce model degradation during online update, we apply residual learning to
take appearance changes into account. Extensive experiments on the benchmark
datasets demonstrate that our CREST tracker performs favorably against
state-of-the-art trackers.
</dc:description>
 <dc:description>Comment: ICCV 2017. Project page:
  http://www.cs.cityu.edu.hk/~yibisong/iccv17/index.html</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00227</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HMM-based Indic Handwritten Word Recognition using Zone Segmentation</dc:title>
 <dc:creator>Roy, Partha Pratim</dc:creator>
 <dc:creator>Bhunia, Ayan Kumar</dc:creator>
 <dc:creator>Das, Ayan</dc:creator>
 <dc:creator>Dey, Prasenjit</dc:creator>
 <dc:creator>Pal, Umapada</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a novel approach towards Indic handwritten word
recognition using zone-wise information. Because of complex nature due to
compound characters, modifiers, overlapping and touching, etc., character
segmentation and recognition is a tedious job in Indic scripts (e.g.
Devanagari, Bangla, Gurumukhi, and other similar scripts). To avoid character
segmentation in such scripts, HMM-based sequence modeling has been used earlier
in holistic way. This paper proposes an efficient word recognition framework by
segmenting the handwritten word images horizontally into three zones (upper,
middle and lower) and recognize the corresponding zones. The main aim of this
zone segmentation approach is to reduce the number of distinct component
classes compared to the total number of classes in Indic scripts. As a result,
use of this zone segmentation approach enhances the recognition performance of
the system. The components in middle zone where characters are mostly touching
are recognized using HMM. After the recognition of middle zone, HMM based
Viterbi forced alignment is applied to mark the left and right boundaries of
the characters. Next, the residue components, if any, in upper and lower zones
in their respective boundary are combined to achieve the final word level
recognition. Water reservoir feature has been integrated in this framework to
improve the zone segmentation and character alignment defects while
segmentation. A novel sliding window-based feature, called Pyramid Histogram of
Oriented Gradient (PHOG) is proposed for middle zone recognition. An exhaustive
experiment is performed on two Indic scripts namely, Bangla and Devanagari for
the performance evaluation. From the experiment, it has been noted that
proposed zone-wise recognition improves accuracy with respect to the
traditional way of Indic word recognition.
</dc:description>
 <dc:description>Comment: Published in Pattern Recognition(2016)</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00227</dc:identifier>
 <dc:identifier>Pattern Recognition, Volume 60, December 2016, Pages 1057-1075</dc:identifier>
 <dc:identifier>doi:10.1016/j.patcog.2016.04.012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00232</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pulse-Based Control Using Koopman Operator Under Parametric Uncertainty</dc:title>
 <dc:creator>Sootla, Aivar</dc:creator>
 <dc:creator>Ernst, Damien</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In applications, such as biomedicine and systems/synthetic biology, technical
limitations in actuation complicate implementation of time-varying control
signals. In order to alleviate some of these limitations, it may be desirable
to derive simple control policies, such as step functions with fixed magnitude
and length (or temporal pulses). In this technical note, we further develop a
recently proposed pulse-based solution to the convergence problem, i.e.,
minimizing the convergence time to the target exponentially stable equilibrium,
for monotone systems. In particular, we extend this solution to monotone
systems with parametric uncertainty. Our solutions also provide worst-case
estimates on convergence times. Furthermore, we indicate how our tools can be
used for a class of non-monotone systems, and more importantly how these tools
can be extended to other control problems. We illustrate our approach on
switching under parametric uncertainty and regulation around a saddle point
problems in a genetic toggle switch system.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00239</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolutionary game of N competing AIMD connections</dc:title>
 <dc:creator>Ignatenko, Oleksii</dc:creator>
 <dc:creator>Synetskyi, Oleksandr</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  This paper deals with modeling of network's dynamic using evolutionary games
approach. Today there are many different protocols for data transmission
through the Internet, providing users with better or worse service. The process
of choosing better protocol could be considered as a dynamic game with players
(users), trying to maximize their payoffs (eg throughput). In this work we
presented the model of network's dynamic using differential equations with
discontinuous right side and proved existence and uniqueness of the solution,
formulated payoff matrix for a network game and found conditions of equilibrium
existence depending on loss sensitivity parameter. The results are illustrated
by simulations
</dc:description>
 <dc:description>Comment: International Conference on Information and Communication
  Technologies in Education, Research, and Industrial Applications. Springer,
  Cham, 2014</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00239</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00240</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Algorithm for Mixed Domination on Generalized
  Series-Parallel Graphs</dc:title>
 <dc:creator>Rajaati, M.</dc:creator>
 <dc:creator>Sharifani, P.</dc:creator>
 <dc:creator>Shakiba, A.</dc:creator>
 <dc:creator>Hooshmandasl, M. R.</dc:creator>
 <dc:creator>Dinneen, M. J.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A mixed dominating set $S$ of a graph $G=(V,E)$ is a subset $ S \subseteq V
\cup E$ such that each element $v\in (V \cup E) \setminus S$ is adjacent or
incident to at least one element in $S$. The mixed domination number
$\gamma_m(G)$ of a graph $G$ is the minimum cardinality among all mixed
dominating sets in $G$. The problem of finding $\gamma_{m}(G)$ is know to be
NP-complete. In this paper, we present an explicit polynomial-time algorithm to
construct a mixed dominating set of size $\gamma_{m}(G)$ by a parse tree when
$G$ is a generalized series-parallel graph.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00241</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Part-of-Speech Tagging for NLP Pipelines</dc:title>
 <dc:creator>Jatav, Vishaal</dc:creator>
 <dc:creator>Teja, Ravi</dc:creator>
 <dc:creator>Bharadwaj, Srini</dc:creator>
 <dc:creator>Srinivasan, Venkat</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper outlines the results of sentence level linguistics based rules for
improving part-of-speech tagging. It is well known that the performance of
complex NLP systems is negatively affected if one of the preliminary stages is
less than perfect. Errors in the initial stages in the pipeline have a
snowballing effect on the pipeline's end performance. We have created a set of
linguistics based rules at the sentence level which adjust part-of-speech tags
from state-of-the-art taggers. Comparison with state-of-the-art taggers on
widely used benchmarks demonstrate significant improvements in tagging accuracy
and consequently in the quality and accuracy of NLP systems.
</dc:description>
 <dc:description>Comment: Computational Linguistics, Natural Language Understanding, RAGE AI,
  Part-of-Speech Tagging, Evaluation</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00241</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00247</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Query Expansion Techniques for Information Retrieval: a Survey</dc:title>
 <dc:creator>Azad, Hiteshwar Kumar</dc:creator>
 <dc:creator>Deepak, Akshay</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  With the ever increasing size of web, relevant information extraction on the
Internet with a query formed by a few keywords has become a big challenge. To
overcome this, query expansion (QE) plays a crucial role in improving the
Internet searches, where the user's initial query is reformulated to a new
query by adding new meaningful terms with similar significance. QE -- as part
of information retrieval (IR) -- has long attracted researchers' attention. It
has also become very influential in the field of personalized social document,
Question Answering over Linked Data (QALD), and, Text Retrieval Conference
(TREC) and REAL sets. This paper surveys QE techniques in IR from 1960 to 2017
with respect to core techniques, data sources used, weighting and ranking
methodologies, user participation and applications (of QE techniques) --
bringing out similarities and differences.
</dc:description>
 <dc:description>Comment: 43 pages, 5 figures, 10 tables</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00251</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CNN Cascades for Segmenting Whole Slide Images of the Kidney</dc:title>
 <dc:creator>Gadermayr, Michael</dc:creator>
 <dc:creator>Dombrowski, Ann-Kathrin</dc:creator>
 <dc:creator>Klinkhammer, Barbara Mara</dc:creator>
 <dc:creator>Boor, Peter</dc:creator>
 <dc:creator>Merhof, Dorit</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Due to the increasing availability of whole slide scanners facilitating
digitization of histopathological tissue, there is a strong demand for the
development of computer based image analysis systems. In this work, the focus
is on the segmentation of the glomeruli constituting a highly relevant
structure in renal histopathology, which has not been investigated before in
combination with CNNs. We propose two different CNN cascades for segmentation
applications with sparse objects. These approaches are applied to the problem
of glomerulus segmentation and compared with conventional fully-convolutional
networks. Overall, with the best performing cascade approach, single CNNs are
outperformed and a pixel-level Dice similarity coefficient of 0.90 is obtained.
Combined with qualitative and further object-level analyses the obtained
results are assessed as excellent also compared to recent approaches. In
conclusion, we can state that especially one of the proposed cascade networks
proved to be a highly powerful tool for segmenting the renal glomeruli
providing best segmentation accuracies and also keeping the computing time at a
low level.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00251</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00255</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MM2RTB: Bringing Multimedia Metrics to Real-Time Bidding</dc:title>
 <dc:creator>Chen, Xiang</dc:creator>
 <dc:creator>Chen, Bowei</dc:creator>
 <dc:creator>Kankanhalli, Mohan</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  In display advertising, users' online ad experiences are important for the
advertising effectiveness. However, users have not been well accommodated in
real-time bidding (RTB). This further influences their site visits and
perception of the displayed banner ads. In this paper, we propose a novel
computational framework which brings multimedia metrics, like the contextual
relevance, the visual saliency and the ad memorability into RTB to improve the
users' ad experiences as well as maintain the benefits of the publisher and the
advertiser. We aim at developing a vigorous ecosystem by optimizing the
trade-offs among all stakeholders. The framework considers the scenario of a
webpage with multiple ad slots. Our experimental results show that the benefits
of the advertiser and the user can be significantly improved if the publisher
would slightly sacrifice his short-term revenue. The improved benefits will
increase the advertising requests (demand) and the site visits (supply), which
can further boost the publisher's revenue in the long run.
</dc:description>
 <dc:description>Comment: In Proceedings of AdKDD and TargetAd, Halifax, NS, Canada, August,
  14, 2017, 6 pages</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00260</identifier>
 <datestamp>2017-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Asymmetric Multi-task Feature Learning</dc:title>
 <dc:creator>Lee, Hae Beom</dc:creator>
 <dc:creator>Yang, Eunho</dc:creator>
 <dc:creator>Hwang, Sung Ju</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose Deep Asymmetric Multitask Feature Learning (Deep-AMTFL) which can
learn deep representations shared across multiple tasks while effectively
preventing negative transfer that may happen in the feature sharing process.
Specifically, we introduce an asymmetric autoencoder term that allows reliable
predictors for the easy tasks to have high contribution to the feature learning
while suppressing the influences of unreliable predictors for more difficult
tasks. This allows the learning of less noisy representations, and enables
unreliable predictors to exploit knowledge from the reliable predictors via the
shared latent features. Such asymmetric knowledge transfer through shared
features is also more scalable and efficient than inter-task asymmetric
transfer. We validate our Deep-AMTFL model on multiple benchmark datasets for
multitask learning and image classification, on which it significantly
outperforms existing symmetric and asymmetric multitask learning models, by
effectively preventing negative transfer in deep feature learning.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00275</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Is Task Board Customization Beneficial? - An Eye Tracking Study</dc:title>
 <dc:creator>Karras, Oliver</dc:creator>
 <dc:creator>Kl&#xfc;nder, Jil</dc:creator>
 <dc:creator>Schneider, Kurt</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The task board is an essential artifact in many agile development approaches.
It provides a good overview of the project status. Teams often customize their
task boards according to the team members' needs. They modify the structure of
boards, define colored codings for different purposes, and introduce different
card sizes. Although the customizations are intended to improve the task
board's usability and effectiveness, they may also complicate its comprehension
and use. The increased effort impedes the work of both the team and team
externals. Hence, task board customization is in conflict with the agile
practice of fast and easy overview for everyone. In an eye tracking study with
30 participants, we compared an original task board design with three
customized ones to investigate which design shortened the required time to
identify a particular story card. Our findings yield that only the customized
task board design with modified structures reduces the required time. The
original task board design is more beneficial than individual colored codings
and changed card sizes. According to our findings, agile teams should rethink
their current task board design. They may be better served by focusing on the
original task board design and by applying only carefully selected adjustments.
In case of customization, a task board's structure should be adjusted since
this is the only beneficial kind of customization, that additionally complies
more precisely with the concept of fast and easy project overview.
</dc:description>
 <dc:description>Comment: 16 pages, 18th International Conference on Product-Focused Software
  Process Improvement (Profes 2017)</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00276</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Approximation of Maximum Independent Set and Maximum
  Matching</dc:title>
 <dc:creator>Bar-Yehuda, Reuven</dc:creator>
 <dc:creator>Censor-Hillel, Keren</dc:creator>
 <dc:creator>Ghaffari, Mohsen</dc:creator>
 <dc:creator>Schwartzman, Gregory</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present a simple distributed $\Delta$-approximation algorithm for maximum
weight independent set (MaxIS) in the $\mathsf{CONGEST}$ model which completes
in $O(\texttt{MIS}(G)\cdot \log W)$ rounds, where $\Delta$ is the maximum
degree, $\texttt{MIS}(G)$ is the number of rounds needed to compute a maximal
independent set (MIS) on $G$, and $W$ is the maximum weight of a node. %Whether
our algorithm is randomized or deterministic depends on the \texttt{MIS}
algorithm used as a black-box.
  Plugging in the best known algorithm for MIS gives a randomized solution in
$O(\log n \log W)$ rounds, where $n$ is the number of nodes.
  We also present a deterministic $O(\Delta +\log^* n)$-round algorithm based
on coloring.
  We then show how to use our MaxIS approximation algorithms to compute a
$2$-approximation for maximum weight matching without incurring any additional
round penalty in the $\mathsf{CONGEST}$ model. We use a known reduction for
simulating algorithms on the line graph while incurring congestion, but we show
our algorithm is part of a broad family of \emph{local aggregation algorithms}
for which we describe a mechanism that allows the simulation to run in the
$\mathsf{CONGEST}$ model without an additional overhead.
  Next, we show that for maximum weight matching, relaxing the approximation
factor to ($2+\varepsilon$) allows us to devise a distributed algorithm
requiring $O(\frac{\log \Delta}{\log\log\Delta})$ rounds for any constant
$\varepsilon&gt;0$. For the unweighted case, we can even obtain a
$(1+\varepsilon)$-approximation in this number of rounds. These algorithms are
the first to achieve the provably optimal round complexity with respect to
dependency on $\Delta$.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00277</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Deep Convolutional Embeddings for Face Representation Using
  Joint Sample- and Set-based Supervision</dc:title>
 <dc:creator>Gecer, Baris</dc:creator>
 <dc:creator>Balntas, Vassileios</dc:creator>
 <dc:creator>Kim, Tae-Kyun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we investigate several methods and strategies to learn deep
embeddings for face recognition, using joint sample- and set-based
optimization. We explain our framework that expands traditional learning with
set-based supervision together with the strategies used to maintain set
characteristics. We, then, briefly review the related set-based loss functions,
and subsequently propose a novel Max-Margin Loss which maximizes maximum
possible inter-class margin with assistance of Support Vector Machines (SVMs).
It implicitly pushes all the samples towards correct side of the margin with a
vector perpendicular to the hyperplane and a strength exponentially growing
towards to negative side of the hyperplane. We show that the introduced loss
outperform the previous sample-based and set-based ones in terms verification
of faces on two commonly used benchmarks.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, 2 tables, workshop paper</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00277</dc:identifier>
 <dc:identifier>The IEEE International Conference on Computer Vision (ICCV) 2017,
  p.1665-1672</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00278</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video as a By-Product of Digital Prototyping: Capturing the Dynamic
  Aspect of Interaction</dc:title>
 <dc:creator>Karras, Oliver</dc:creator>
 <dc:creator>Unger-Windeler, Carolin</dc:creator>
 <dc:creator>Glauer, Lennart</dc:creator>
 <dc:creator>Schneider, Kurt</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Requirements engineering provides several practices to analyze how a user
wants to interact with a future software. Mockups, prototypes, and scenarios
are suitable to understand usability issues and user requirements early.
Nevertheless, users are often dissatisfied with the usability of a resulting
software. Apparently, previously explored information was lost or no longer
accessible during the development phase. Scenarios are one effective practice
to describe behavior. However, they are commonly notated in natural language
which is often improper to capture and communicate interaction knowledge
comprehensible to developers and users. The dynamic aspect of interaction is
lost if only static descriptions are used. Digital prototyping enables the
creation of interactive prototypes by adding responsive controls to hand- or
digitally drawn mockups. We propose to capture the events of these controls to
obtain a representation of the interaction. From this data, we generate videos,
which demonstrate interaction sequences, as additional support for textual
scenarios. Variants of scenarios can be created by modifying the captured event
sequences and mockups. Any change is unproblematic since videos only need to be
regenerated. Thus, we achieve video as a by-product of digital prototyping.
This reduces the effort compared to video recording such as screencasts. A
first evaluation showed that such a generated video supports a faster
understanding of a textual scenario compared to static mockups.
</dc:description>
 <dc:description>Comment: 7 pages, IEEE International Requirements Engineering Conference
  Workshops (REW'17)</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00279</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reframing Societal Discourse as Requirements Negotiation: Vision
  Statement</dc:title>
 <dc:creator>Schneider, Kurt</dc:creator>
 <dc:creator>Karras, Oliver</dc:creator>
 <dc:creator>Finger, Anne</dc:creator>
 <dc:creator>Zibell, Barbara</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Challenges in spatial planning include adjusting settlement patterns to
increasing or shrinking populations; it also includes organizing food delivery
in rural and peripheral environments. Discourse typically starts with an open
problem and the search for a holistic and innovative solution. Software will
often be needed to implement the innovation. Spatial planning problems are
characterized by large and heterogeneous groups of stakeholders, such as
municipalities, companies, interest groups, citizens, women and men, young
people and children. Current techniques for participation are slow, laborious
and costly, and they tend to miss out on many stakeholders or interest groups.
We propose a triple shift in perspective: (1) Discourse is reframed as a
requirements process with the explicit goal to state software, hardware, and
organizational requirements. (2) Due to the above-mentioned characteristics of
spatial planning problems, we suggest using techniques of requirements
engineering (RE) and CrowdRE for getting stakeholders (e.g. user groups)
involved. (3) We propose video as a medium for communicating problems, solution
alternatives, and arguments effectively within a mixed crowd of officials,
citizens, children and elderly people. Although few spatial planning problems
can be solved by software alone, this new perspective helps to focus
discussions anyway. RE techniques can assist in finding common ground despite
the heterogeneous group of stakeholders, e.g. citizens. Digital requirements
and video are well-suited for facilitating distribution, feedback, and
discourse via the internet. In this paper, we propose this new perspective as a
timely opportunity for the spatial planning domain - and as an increasingly
important application domain of CrowdRE.
</dc:description>
 <dc:description>Comment: 6 pages, IEEE International Requirements Engineering Conference
  Workshops (REW'17)</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00284</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual Motion GAN for Future-Flow Embedded Video Prediction</dc:title>
 <dc:creator>Liang, Xiaodan</dc:creator>
 <dc:creator>Lee, Lisa</dc:creator>
 <dc:creator>Dai, Wei</dc:creator>
 <dc:creator>Xing, Eric P.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Future frame prediction in videos is a promising avenue for unsupervised
video representation learning. Video frames are naturally generated by the
inherent pixel flows from preceding frames based on the appearance and motion
dynamics in the video. However, existing methods focus on directly
hallucinating pixel values, resulting in blurry predictions. In this paper, we
develop a dual motion Generative Adversarial Net (GAN) architecture, which
learns to explicitly enforce future-frame predictions to be consistent with the
pixel-wise flows in the video through a dual-learning mechanism. The primal
future-frame prediction and dual future-flow prediction form a closed loop,
generating informative feedback signals to each other for better video
prediction. To make both synthesized future frames and flows indistinguishable
from reality, a dual adversarial training method is proposed to ensure that the
future-flow prediction is able to help infer realistic future-frames, while the
future-frame prediction in turn leads to realistic optical flows. Our dual
motion GAN also handles natural motion uncertainty in different pixel locations
with a new probabilistic motion encoder, which is based on variational
autoencoders. Extensive experiments demonstrate that the proposed dual motion
GAN significantly outperforms state-of-the-art approaches on synthesizing new
video frames and predicting future flows. Our model generalizes well across
diverse visual scenes and shows superiority in unsupervised video
representation learning.
</dc:description>
 <dc:description>Comment: ICCV 17 camera ready</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00284</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00300</identifier>
 <datestamp>2017-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Best Viewpoint Tracking for Camera Mounted on Robotic Arm with Dynamic
  Obstacles</dc:title>
 <dc:creator>Maniatis, Christos</dc:creator>
 <dc:creator>Saval-Calvo, Marcelo</dc:creator>
 <dc:creator>Tylecek, Radim</dc:creator>
 <dc:creator>Fisher, Robert B.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The problem of finding a next best viewpoint for 3D modeling or scene mapping
has been explored in computer vision over the last decade. This paper tackles a
similar problem, but with different characteristics. It proposes a method for
dynamic next best viewpoint recovery of a target point while avoiding possible
occlusions. Since the environment can change, the method has to iteratively
find the next best view with a global understanding of the free and occupied
parts.
  We model the problem as a set of possible viewpoints which correspond to the
centers of the facets of a virtual tessellated hemisphere covering the scene.
Taking into account occlusions, distances between current and future
viewpoints, quality of the viewpoint and joint constraints (robot arm joint
distances or limits), we evaluate the next best viewpoint. The proposal has
been evaluated on 8 different scenarios with different occlusions and a short
3D video sequence to validate its dynamic performance.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures, poster in 3DV conference</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00300</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00306</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Design of Reversible Full Adder/Subtractor using $R$ gate</dc:title>
 <dc:creator>Montaser, Rasha</dc:creator>
 <dc:creator>Younes, Ahmed</dc:creator>
 <dc:creator>Abdel-Aty, Mahmoud</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Quantum computers require quantum processors. An important part of the
processor of any computer is the arithmetic unit, which performs binary
addition, subtraction, division and multiplication, however multiplication can
be performed using repeated addition, while division can be performed using
repeated subtraction. In this paper we present two designs using the reversible
$R^3$ gate to perform the quantum half adder/ subtractor and the quantum full
adder/subtractor. The proposed half adder/subtractor design can be used to
perform different logical operations, such as $AND$, $XOR$, $NAND$, $XNOR$,
$NOT$ and copy of basis. The proposed design is compared with the other
previous designs in terms of the number of gates used, the number of constant
bits, the garbage bits, the quantum cost and the delay. The proposed designs
are implemented and tested using GAP software.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00308</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SenGen: Sentence Generating Neural Variational Topic Model</dc:title>
 <dc:creator>Nallapati, Ramesh</dc:creator>
 <dc:creator>Melnyk, Igor</dc:creator>
 <dc:creator>Kumar, Abhishek</dc:creator>
 <dc:creator>Zhou, Bowen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a new topic model that generates documents by sampling a topic for
one whole sentence at a time, and generating the words in the sentence using an
RNN decoder that is conditioned on the topic of the sentence. We argue that
this novel formalism will help us not only visualize and model the topical
discourse structure in a document better, but also potentially lead to more
interpretable topics since we can now illustrate topics by sampling
representative sentences instead of bag of words or phrases. We present a
variational auto-encoder approach for learning in which we use a factorized
variational encoder that independently models the posterior over topical
mixture vectors of documents using a feed-forward network, and the posterior
over topic assignments to sentences using an RNN. Our preliminary experiments
on two different datasets indicate early promise, but also expose many
challenges that remain to be addressed.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00315</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Semantic Manipulation with Contrasting GAN</dc:title>
 <dc:creator>Liang, Xiaodan</dc:creator>
 <dc:creator>Zhang, Hao</dc:creator>
 <dc:creator>Xing, Eric P.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Generative Adversarial Networks (GANs) have recently achieved significant
improvement on paired/unpaired image-to-image translation, such as
photo$\rightarrow$ sketch and artist painting style transfer. However, existing
models can only be capable of transferring the low-level information (e.g.
color or texture changes), but fail to edit high-level semantic meanings (e.g.,
geometric structure or content) of objects. On the other hand, while some
researches can synthesize compelling real-world images given a class label or
caption, they cannot condition on arbitrary shapes or structures, which largely
limits their application scenarios and interpretive capability of model
results. In this work, we focus on a more challenging semantic manipulation
task, which aims to modify the semantic meaning of an object while preserving
its own characteristics (e.g. viewpoints and shapes), such as
cow$\rightarrow$sheep, motor$\rightarrow$ bicycle, cat$\rightarrow$dog. To
tackle such large semantic changes, we introduce a contrasting GAN
(contrast-GAN) with a novel adversarial contrasting objective. Instead of
directly making the synthesized samples close to target data as previous GANs
did, our adversarial contrasting objective optimizes over the distance
comparisons between samples, that is, enforcing the manipulated data be
semantically closer to the real data with target category than the input data.
Equipped with the new contrasting objective, a novel mask-conditional
contrast-GAN architecture is proposed to enable disentangle image background
with object semantic changes. Experiments on several semantic manipulation
tasks on ImageNet and MSCOCO dataset show considerable performance gain by our
contrast-GAN over other conditional GANs. Quantitative results further
demonstrate the superiority of our model on generating manipulated results with
high visual fidelity and reasonable object semantics.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00316</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Framework for Sampling, Clustering and Embedding Data Points
  in Semi-Metric Spaces</dc:title>
 <dc:creator>Chang, Chia-Tai</dc:creator>
 <dc:creator>Chang, Cheng-Shang</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this paper, we propose a unified framework for sampling, clustering and
embedding data points in semi-metric spaces. For a set of data points
$\Omega=\{x_1, x_2, \ldots, x_n\}$ in a semi-metric space, we consider a
complete graph with $n$ nodes and $n$ self edges and then map each data point
in $\Omega$ to a node in the graph with the edge weight between two nodes being
the distance between the corresponding two points in $\Omega$. By doing so,
several well-known sampling techniques can be applied for clustering data
points in a semi-metric space. One particularly interesting sampling technique
is the exponentially twisted sampling in which one can specify the desired
average distance from the sampling distribution to detect clusters with various
resolutions.
  We also propose a softmax clustering algorithm that can perform a clustering
and embed data points in a semi-metric space to a low dimensional Euclidean
space. Our experimental results show that after a certain number of iterations
of &quot;training&quot;, our softmax algorithm can reveal the &quot;topology&quot; of the data from
a high dimensional Euclidean. We also show that the eigendecomposition of a
covariance matrix is equivalent to the principal component analysis (PCA).
  To deal with the hierarchical structure of clusters, our softmax clustering
algorithm can also be used with a hierarchical clustering algorithm. For this,
we propose a partitional-hierarchical algorithm, called $i$PHD, in this paper.
Our experimental results show that those algorithms based on the maximization
of normalized modularity tend to balance the sizes of detected clusters and
thus do not perform well when the ground-truth clusters are different in sizes.
Also, using a metric is better than using a semi-metric as the triangular
inequality is not satisfied for a semi-metric and that is more prone to
clustering errors.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00319</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy Protection Cache Policy on Hybrid Main Memory</dc:title>
 <dc:creator>Ahn, Na-Young</dc:creator>
 <dc:creator>Lee, Donghoon</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  We firstly suggest privacy protection cache policy applying the duty to
delete personal information on a hybrid main memory system. This cache policy
includes generating random data and overwriting the random data into the
personal information. Proposed cache policy is more economical and effective
regarding perfect deletion of data.
</dc:description>
 <dc:description>Comment: 2 pages, 3 figures, IEEE Transactions on Very Large Scale Integration
  Systems. arXiv admin note: text overlap with arXiv:1707.02842</dc:description>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00329</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Graph Analytics Framework for Ranking Authors, Papers and Venues</dc:title>
 <dc:creator>Pal, Arindam</dc:creator>
 <dc:creator>Ruj, Sushmita</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  A lot of scientific works are published in different areas of science,
technology, engineering and mathematics. It is not easy, even for experts, to
judge the quality of authors, papers and venues (conferences and journals). An
objective measure to assign scores to these entities and to rank them is very
useful. Although, several metrics and indexes have been proposed earlier, they
suffer from various problems. In this paper, we propose a graph-based analytics
framework to assign scores and to rank authors, papers and venues. Our
algorithm considers only the link structures of the underlying graphs. It does
not take into account other aspects, such as the associated texts and the
reputation of these entities. In the limit of large number of iterations, the
solution of the iterative equations gives the unique entity scores. This
framework can be easily extended to other interdependent networks.
</dc:description>
 <dc:description>Comment: International Workshop on Mining and Learning with Graphs, ACM KDD
  2016. arXiv admin note: text overlap with arXiv:1501.04894</dc:description>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00331</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact Approaches for the Travelling Thief Problem</dc:title>
 <dc:creator>Wu, Junhua</dc:creator>
 <dc:creator>Wagner, Markus</dc:creator>
 <dc:creator>Polyakovskiy, Sergey</dc:creator>
 <dc:creator>Neumann, Frank</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>90C27</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  Many evolutionary and constructive heuristic approaches have been introduced
in order to solve the Traveling Thief Problem (TTP). However, the accuracy of
such approaches is unknown due to their inability to find global optima. In
this paper, we propose three exact algorithms and a hybrid approach to the TTP.
We compare these with state-of-the-art approaches to gather a comprehensive
overview on the accuracy of heuristic methods for solving small TTP instances.
</dc:description>
 <dc:description>Comment: 13 pages, 1 figures</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00331</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00335</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding tree: a tool for estimating an individual's understanding
  of conceptual knowledge</dc:title>
 <dc:creator>Liu, Gangli</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  People learn whenever and wherever possible, and whatever they like or
encounter--Mathematics, Drama, Art, Languages, Physics, Philosophy, and so on.
With the bursting of knowledge, evaluation of one's understanding of conceptual
knowledge becomes increasingly difficult. There are a lot of demands for
evaluating one's understanding of a piece of knowledge, e.g., facilitating
personalized recommendations; discovering one's expertises and deficiencies in
a field; recommending topics for a conversation between people with different
educational or cultural backgrounds in their first encounter; recommending a
learning material to practice a meaningful learning etc. Assessment of
understanding of knowledge is conventionally practiced through tests or
interviews, but they have some limitations such as low-efficiency and
not-comprehensive. We propose a method to estimate one's understanding of
conceptual knowledge, by keeping track of his/her learning activities. It
overcomes some limitations of traditional methods, hence complements
traditional methods.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1612.07714</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00339</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attend and Predict: Understanding Gene Regulation by Selective Attention
  on Chromatin</dc:title>
 <dc:creator>Singh, Ritambhara</dc:creator>
 <dc:creator>Lanchantin, Jack</dc:creator>
 <dc:creator>Sekhon, Arshdeep</dc:creator>
 <dc:creator>Qi, Yanjun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The past decade has seen a revolution in genomic technologies that enable a
flood of genome-wide profiling of chromatin marks. Recent literature tried to
understand gene regulation by predicting gene expression from large-scale
chromatin measurements. Two fundamental challenges exist for such learning
tasks: (1) genome-wide chromatin signals are spatially structured,
high-dimensional and highly modular; and (2) the core aim is to understand what
are the relevant factors and how they work together? Previous studies either
failed to model complex dependencies among input signals or relied on separate
feature analysis to explain the decisions. This paper presents an
attention-based deep learning approach; we call AttentiveChrome, that uses a
unified architecture to model and to interpret dependencies among chromatin
factors for controlling gene regulation. AttentiveChrome uses a hierarchy of
multiple Long short-term memory (LSTM) modules to encode the input signals and
to model how various chromatin marks cooperate automatically. AttentiveChrome
trains two levels of attention jointly with the target prediction, enabling it
to attend differentially to relevant marks and to locate important positions
per mark. We evaluate the model across 56 different cell types (tasks) in
human. Not only is the proposed architecture more accurate, but its attention
scores also provide a better interpretation than state-of-the-art feature
visualization methods such as saliency map.
  Code and data are shared at www.deepchrome.org
</dc:description>
 <dc:description>Comment: 12 pages; At NIPS 2017</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00350</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Experimental Demonstration of Dual Polarization Nonlinear Frequency
  Division Multiplexed Optical Transmission System</dc:title>
 <dc:creator>Gaiarin, Simone</dc:creator>
 <dc:creator>Perego, Auro Michele</dc:creator>
 <dc:creator>da Silva, Edson Porto</dc:creator>
 <dc:creator>Da Ros, Francesco</dc:creator>
 <dc:creator>Zibar, Darko</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Multi-eigenvalues transmission with information encoded simultaneously in
both orthogonal polarizations is experimentally demonstrated. Performance below
the HD-FEC limit is demonstrated for 8-bits/symbol 1-GBd signals after
transmission up to 207 km of SSMF.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00352</identifier>
 <datestamp>2017-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implementing an Edge-Fog-Cloud architecture for stream data management</dc:title>
 <dc:creator>Hernandez, Lilian</dc:creator>
 <dc:creator>Cao, Hung</dc:creator>
 <dc:creator>Wachowicz, Monica</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The Internet of Moving Things (IoMT) requires support for a data life cycle
process ranging from sorting, cleaning and monitoring data streams to more
complex tasks such as querying, aggregation, and analytics. Current solutions
for stream data management in IoMT have been focused on partial aspects of a
data life cycle process, with special emphasis on sensor networks. This paper
aims to address this problem by developing streaming data life cycle process
that incorporates an edge/fog/cloud architecture that is needed for handling
heterogeneous, streaming and geographically-dispersed IoMT devices. We propose
a 3-tier architecture to support an instant intra-layer communication that
establishes a stream data flow in real-time to respond to immediate data life
cycle tasks in the system. Communication and process are thus the defining
factors in the design of our stream data management solution for IoMT. We
describe and evaluate our prototype implementation using real-time transit data
feeds. Preliminary results are showing the advantages of running data life
cycle tasks for reducing the volume of data streams that are redundant and
should not be transported to the cloud.
</dc:description>
 <dc:description>Comment: stream data life cycle, edge computing, cloud computing, fog
  computing, Internet of Moving Things, will be published in OpenFog Congress
  2017</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-09-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00352</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00354</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Watershed Delineation Algorithm for 2D Flow Direction Grids</dc:title>
 <dc:creator>Haag, Scott</dc:creator>
 <dc:creator>Shokoufandeh, Ali</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper we propose an algorithm and associated data model for creating
a watershed boundary using a 2D Flow Direction Grid. Flow Direction Grids
(FDGs) are common abstractions for hydrodynamic models and are utilized for
delineating physical systems (e.g. watersheds, fluvial, and non-fluvial flow
paths). The proposed algorithm and associated data model provides geometric
speed increases in watershed boundary retrieval while keeping storage
constraints linear in comparison to existing techniques. The algorithm called
Haag Shokoufandehs' March (HSM) relies on an existing data structure, the
modified nested set model, originally described by Celko and applied to
hydrodynamic models by Haag and Shokoufandeh in 2017. The proposed algorithm
creates watershed boundaries by marching around the edges of its' corresponding
region, never entering the internal area. In contrast to existing algorithms
that scales in proportional to the area of the underlying region, the
complexity of the HSM algorithm is proportional to the boundary length. Results
for a group of tested watersheds (n = 14,718) in the approximately 36,000 km^2
Delaware River Watershed show a reduction of between 0 and 99% in computational
complexity using a 30 m DEM vs. existing techniques. Larger watersheds have a
consistent reduction in the number of (read) operation complexity, with the
largest watershed resulting in approximately 35 million reads using traditional
techniques compared to approximately 45 thousand using the HSM algorithm,
respectively. Modelled estimates of the complexity for the approximately 6.1
million km^2 Amazon River basin show a reduction from 6.7 billion to 1.4
million reads.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00363</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Analytical Study of Large SPARQL Query Logs</dc:title>
 <dc:creator>Bonifati, Angela</dc:creator>
 <dc:creator>Martens, Wim</dc:creator>
 <dc:creator>Timm, Thomas</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  With the adoption of RDF as the data model for Linked Data and the Semantic
Web, query specification from end- users has become more and more common in
SPARQL end- points. In this paper, we conduct an in-depth analytical study of
the queries formulated by end-users and harvested from large and up-to-date
query logs from a wide variety of RDF data sources. As opposed to previous
studies, ours is the first assessment on a voluminous query corpus, span- ning
over several years and covering many representative SPARQL endpoints. Apart
from the syntactical structure of the queries, that exhibits already
interesting results on this generalized corpus, we drill deeper in the
structural char- acteristics related to the graph- and hypergraph represen-
tation of queries. We outline the most common shapes of queries when visually
displayed as pseudographs, and char- acterize their (hyper-)tree width.
Moreover, we analyze the evolution of queries over time, by introducing the
novel con- cept of a streak, i.e., a sequence of queries that appear as
subsequent modifications of a seed query. Our study offers several fresh
insights on the already rich query features of real SPARQL queries formulated
by real users, and brings us to draw a number of conclusions and pinpoint
future di- rections for SPARQL query evaluation, query optimization, tuning,
and benchmarking.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00365</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning the kernel matrix by resampling</dc:title>
 <dc:creator>Zhang, Xiao-Lei</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this abstract paper, we introduce a new kernel learning method by a
nonparametric density estimator. The estimator consists of a group of
k-centroids clusterings. Each clustering randomly selects data points with
randomly selected features as its centroids, and learns a one-hot encoder by
one-nearest-neighbor optimization. The estimator generates a sparse
representation for each data point. Then, we construct a nonlinear kernel
matrix from the sparse representation of data. One major advantage of the
proposed kernel method is that it is relatively insensitive to its free
parameters, and therefore, it can produce reasonable results without parameter
tuning. Another advantage is that it is simple. We conjecture that the proposed
method can find its applications in many learning tasks or methods where sparse
representation or kernel matrix is explored. In this preliminary study, we have
applied the kernel matrix to spectral clustering. Our experimental results
demonstrate that the kernel generated by the proposed method outperforms the
well-tuned Gaussian RBF kernel. This abstract paper is used to protect the
idea, full versions will be updated later.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00366</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of RAN Virtualization on Fronthaul Latency Budget: An
  Experimental Evaluation</dc:title>
 <dc:creator>Giannone, F.</dc:creator>
 <dc:creator>Gupta, H.</dc:creator>
 <dc:creator>Manicone, D.</dc:creator>
 <dc:creator>Kondepu, K.</dc:creator>
 <dc:creator>Franklin, A.</dc:creator>
 <dc:creator>Castoldi, P.</dc:creator>
 <dc:creator>Valcarenghi, L.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In 3GPP the architecture of a New Radio Access Network (New RAN) has been
defined where the evolved NodeB (eNB) functions can be split between a
Distributed Unit (DU) and Central Unit (CU). Furthermore, in the virtual RAN
(VRAN) approach, such functions can be virtualized (e.g., in simple terms,
deployed in virtual machines). Based on the split type, different performance
in terms of capacity and latency are requested to the network (i.e., fronthaul)
connecting DU and CU.
  This study experimentally evaluates, in the 5G segment of the Advanced
Research on NetwOrking (ARNO) testbed (ARNO-5G), the fronthaul latency
requirements specified by Standard Developing Organizations (SDO) (3GPP in this
specific case). Moreover it evaluates how much virtualization impacts the
fronthaul latency budget for the the Option 7-1 functional split.
  The obtained results show that, in the considered Option 7-1 functional
split, the fronthaul latency requirements are about 250us but they depend on
the radio channel bandwidth and the number of the connected UEs. Finally
virtualization further decreases the latency budget.
</dc:description>
 <dc:description>Comment: publication rights achieved typos fixed</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00367</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Supervised Learning for Spinal MRIs</dc:title>
 <dc:creator>Jamaludin, Amir</dc:creator>
 <dc:creator>Kadir, Timor</dc:creator>
 <dc:creator>Zisserman, Andrew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A significant proportion of patients scanned in a clinical setting have
follow-up scans. We show in this work that such longitudinal scans alone can be
used as a form of 'free' self-supervision for training a deep network. We
demonstrate this self-supervised learning for the case of T2-weighted sagittal
lumbar Magnetic Resonance Images (MRIs). A Siamese convolutional neural network
(CNN) is trained using two losses: (i) a contrastive loss on whether the scan
is of the same person (i.e. longitudinal) or not, together with (ii) a
classification loss on predicting the level of vertebral bodies. The
performance of this pre-trained network is then assessed on a grading
classification task. We experiment on a dataset of 1016 subjects, 423
possessing follow-up scans, with the end goal of learning the disc degeneration
radiological gradings attached to the intervertebral discs. We show that the
performance of the pre-trained CNN on the supervised classification task is (i)
superior to that of a network trained from scratch; and (ii) requires far fewer
annotated training samples to reach an equivalent performance to that of the
network trained from scratch.
</dc:description>
 <dc:description>Comment: 3rd Workshop on Deep Learning in Medical Image Analysis</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00370</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hand2Face: Automatic Synthesis and Recognition of Hand Over Face
  Occlusions</dc:title>
 <dc:creator>Nojavanasghari, Behnaz</dc:creator>
 <dc:creator>Hughes, Charles. E.</dc:creator>
 <dc:creator>Baltrusaitis, Tadas</dc:creator>
 <dc:creator>Morency, Louis-philippe</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A person's face discloses important information about their affective state.
Although there has been extensive research on recognition of facial
expressions, the performance of existing approaches is challenged by facial
occlusions. Facial occlusions are often treated as noise and discarded in
recognition of affective states. However, hand over face occlusions can provide
additional information for recognition of some affective states such as
curiosity, frustration and boredom. One of the reasons that this problem has
not gained attention is the lack of naturalistic occluded faces that contain
hand over face occlusions as well as other types of occlusions. Traditional
approaches for obtaining affective data are time demanding and expensive, which
limits researchers in affective computing to work on small datasets. This
limitation affects the generalizability of models and deprives researchers from
taking advantage of recent advances in deep learning that have shown great
success in many fields but require large volumes of data. In this paper, we
first introduce a novel framework for synthesizing naturalistic facial
occlusions from an initial dataset of non-occluded faces and separate images of
hands, reducing the costly process of data collection and annotation. We then
propose a model for facial occlusion type recognition to differentiate between
hand over face occlusions and other types of occlusions such as scarves, hair,
glasses and objects. Finally, we present a model to localize hand over face
occlusions and identify the occluded regions of the face.
</dc:description>
 <dc:description>Comment: Accepted to International Conference on Affective Computing and
  Intelligent Interaction (ACII), 2017</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00376</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Program Induction to Interpret Transition System Dynamics</dc:title>
 <dc:creator>Penkov, Svetlin</dc:creator>
 <dc:creator>Ramamoorthy, Subramanian</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Explaining and reasoning about processes which underlie observed black-box
phenomena enables the discovery of causal mechanisms, derivation of suitable
abstract representations and the formulation of more robust predictions. We
propose to learn high level functional programs in order to represent abstract
models which capture the invariant structure in the observed data. We introduce
the $\pi$-machine (program-induction machine) -- an architecture able to induce
interpretable LISP-like programs from observed data traces. We propose an
optimisation procedure for program learning based on backpropagation, gradient
descent and A* search. We apply the proposed method to two problems: system
identification of dynamical systems and explaining the behaviour of a DQN
agent. Our results show that the $\pi$-machine can efficiently induce
interpretable programs from individual data traces.
</dc:description>
 <dc:description>Comment: Presented at 2017 ICML Workshop on Human Interpretability in Machine
  Learning (WHI 2017), Sydney, NSW, Australia. arXiv admin note: substantial
  text overlap with arXiv:1705.08320</dc:description>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00377</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Segmentation of Glioma Tumors in Brain Using Deep Convolutional Neural
  Network</dc:title>
 <dc:creator>Hussain, Saddam</dc:creator>
 <dc:creator>Anwar, Syed Muhammad</dc:creator>
 <dc:creator>Majid, Muhammad</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Detection of brain tumor using a segmentation based approach is critical in
cases, where survival of a subject depends on an accurate and timely clinical
diagnosis. Gliomas are the most commonly found tumors having irregular shape
and ambiguous boundaries, making them one of the hardest tumors to detect. The
automation of brain tumor segmentation remains a challenging problem mainly due
to significant variations in its structure. An automated brain tumor
segmentation algorithm using deep convolutional neural network (DCNN) is
presented in this paper. A patch based approach along with an inception module
is used for training the deep network by extracting two co-centric patches of
different sizes from the input images. Recent developments in deep neural
networks such as drop-out, batch normalization, non-linear activation and
inception module are used to build a new ILinear nexus architecture. The module
overcomes the over-fitting problem arising due to scarcity of data using
drop-out regularizer. Images are normalized and bias field corrected in the
pre-processing step and then extracted patches are passed through a DCNN, which
assigns an output label to the central pixel of each patch. Morphological
operators are used for post-processing to remove small false positives around
the edges. A two-phase weighted training method is introduced and evaluated
using BRATS 2013 and BRATS 2015 datasets, where it improves the performance
parameters of state-of-the-art techniques under similar settings.
</dc:description>
 <dc:description>Comment: Submitted to Neurocomputing</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00378</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Topology-Free Construction of the Universal Type Structure for
  Conditional Probability Systems</dc:title>
 <dc:creator>Guarino, Pierfrancesco</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We construct the universal type structure for conditional probability systems
without any topological assumption, namely a type structure that is terminal,
belief-complete, and non-redundant. In particular, in order to obtain the
belief-completeness in a constructive way, we extend the work of Meier [An
Infinitary Probability Logic for Type Spaces. Israel Journal of Mathematics,
192, 1-58] by proving strong soundness and strong completeness of an infinitary
conditional probability logic with truthful and non-epistemic conditioning
events.
</dc:description>
 <dc:description>Comment: In Proceedings TARK 2017, arXiv:1707.08250</dc:description>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00378</dc:identifier>
 <dc:identifier>EPTCS 251, 2017, pp. 285-305</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.251.20</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00379</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exponentially Twisted Sampling: a Unified Approach for Centrality
  Analysis in Attributed Networks</dc:title>
 <dc:creator>Chang, Cheng-Hsun</dc:creator>
 <dc:creator>Chang, Cheng-Shang</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In our recent works, we developed a probabilistic framework for structural
analysis in undirected networks and directed networks. The key idea of that
framework is to sample a network by a symmetric and asymmetric bivariate
distribution and then use that bivariate distribution to formerly defining
various notions, including centrality, relative centrality, community, and
modularity. The main objective of this paper is to extend the probabilistic
definition to attributed networks, where sampling bivariate distributions by
exponentially twisted sampling. Our main finding is that we find a way to deal
with the sampling of the attributed network including signed network. By using
the sampling method, we define the various centralities in attributed networks.
The influence centralities and trust centralities correctly show that how to
identify centralities in signed network. The advertisement-specific influence
centralities also perfectly define centralities when the attributed networks
that have node attribute. Experimental results on real-world dataset
demonstrate the different centralities with changing the temperature. Further
experiments are conducted to gain a deeper understanding of the importance of
the temperature.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00391</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Continuously Growing Dataset of Sentential Paraphrases</dc:title>
 <dc:creator>Lan, Wuwei</dc:creator>
 <dc:creator>Qiu, Siyu</dc:creator>
 <dc:creator>He, Hua</dc:creator>
 <dc:creator>Xu, Wei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  A major challenge in paraphrase research is the lack of parallel corpora. In
this paper, we present a new method to collect large-scale sentential
paraphrases from Twitter by linking tweets through shared URLs. The main
advantage of our method is its simplicity, as it gets rid of the classifier or
human in the loop needed to select data before annotation and subsequent
application of paraphrase identification algorithms in the previous work. We
present the largest human-labeled paraphrase corpus to date of 51,524 sentence
pairs and the first cross-domain benchmarking for automatic paraphrase
identification. In addition, we show that more than 30,000 new sentential
paraphrases can be easily and continuously captured every month at ~70%
precision, and demonstrate their utility for downstream NLP tasks through
phrasal paraphrase extraction. We make our code and data freely available.
</dc:description>
 <dc:description>Comment: 11 pages, accepted to EMNLP 2017</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00397</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Momo: Monocular Motion Estimation on Manifolds</dc:title>
 <dc:creator>Graeter, Johannes</dc:creator>
 <dc:creator>Strauss, Tobias</dc:creator>
 <dc:creator>Lauer, Martin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Knowledge about the location of a vehicle is indispensable for autonomous
driving. In order to apply global localisation methods, a pose prior must be
known which can be obtained from visual odometry. The quality and robustness of
that prior determine the success of localisation. Momo is a monocular
frame-to-frame motion estimation methodology providing a high quality visual
odometry for that purpose. By taking into account the motion model of the
vehicle, reliability and accuracy of the pose prior are significantly improved.
We show that especially in low-structure environments Momo outperforms the
state of the art. Moreover, the method is designed so that multiple cameras
with or without overlap can be integrated. The evaluation on the KITTI-dataset
and on a proper multi-camera dataset shows that even with only 100--300 feature
matches the prior is estimated with high accuracy and in real-time.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00400</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recursive Online Enumeration of All Minimal Unsatisfiable Subsets</dc:title>
 <dc:creator>Bendik, Jaroslav</dc:creator>
 <dc:creator>Benes, Nikola</dc:creator>
 <dc:creator>Cerna, Ivana</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In various areas of computer science, e.g. requirements analysis, software
development, or formal verification, we deal with a set of
constraints/requirements. If the constraints cannot be satisfied
simultaneously, it is desirable to identify the core problems among them. Such
cores are called minimal unsatisfiable subsets (MUSes). The more MUSes are
identified, the more information about the conflicts among the constraints is
obtained. However, a full enumeration of all MUSes is in general intractable
due to the combinatorial explosion. We therefore search for algorithms that
enumerate MUSes in an online manner, i.e. algorithms that produce MUSes one by
one and can be terminated anytime. Furthermore, as the list of constraint
domains is quite long and new applications still arise, it is desirable to have
algorithms that are applicable in arbitrary constraint domain.
  The problem of online MUS enumeration in a general constraint domains has
been studied before and several algorithms were developed. However, the
majority of these algorithms were evaluated only in the domain of Boolean
logic. In this work, we provide a novel recursive algorithm for online MUS
enumeration that is applicable to an arbitrary constraint domain and that
outperforms the state-of-the-art algorithms. We evaluate the algorithm on a
variety of benchmarks taken from three different constraint domains: Boolean
constraints, SMT constraints, and LTL constraints.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00411</identifier>
 <datestamp>2017-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Depth Super-Resolution Meets Uncalibrated Photometric Stereo</dc:title>
 <dc:creator>Peng, Songyou</dc:creator>
 <dc:creator>Haefner, Bjoern</dc:creator>
 <dc:creator>Qu&#xe9;au, Yvain</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A novel depth super-resolution approach for RGB-D sensors is presented. It
disambiguates depth super-resolution through high-resolution photometric clues
and, symmetrically, it disambiguates uncalibrated photometric stereo through
low-resolution depth cues. To this end, an RGB-D sequence is acquired from the
same viewing angle, while illuminating the scene from various uncalibrated
directions. This sequence is handled by a variational framework which fits
high-resolution shape and reflectance, as well as lighting, to both the
low-resolution depth measurements and the high-resolution RGB ones. The key
novelty consists in a new PDE-based photometric stereo regularizer which
implicitly ensures surface regularity. This allows to carry out depth
super-resolution in a purely data-driven manner, without the need for any
ad-hoc prior or material calibration. Real-world experiments are carried out
using an out-of-the-box RGB-D sensor and a hand-held LED light source.
</dc:description>
 <dc:description>Comment: International Conference on Computer Vision (ICCV) Workshop, 2017</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00415</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Generative Parser with a Discriminative Recognition Algorithm</dc:title>
 <dc:creator>Cheng, Jianpeng</dc:creator>
 <dc:creator>Lopez, Adam</dc:creator>
 <dc:creator>Lapata, Mirella</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Generative models defining joint distributions over parse trees and sentences
are useful for parsing and language modeling, but impose restrictions on the
scope of features and are often outperformed by discriminative models. We
propose a framework for parsing and language modeling which marries a
generative model with a discriminative recognition model in an encoder-decoder
setting. We provide interpretations of the framework based on expectation
maximization and variational inference, and show that it enables parsing and
language modeling within a single implementation. On the English Penn
Treen-bank, our framework obtains competitive performance on constituency
parsing while matching the state-of-the-art single-model language modeling
score.
</dc:description>
 <dc:description>Comment: ACL 2017</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00415</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00416</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deriving Verb Predicates By Clustering Verbs with Arguments</dc:title>
 <dc:creator>Sedoc, Joao</dc:creator>
 <dc:creator>Wijaya, Derry</dc:creator>
 <dc:creator>Rouhizadeh, Masoud</dc:creator>
 <dc:creator>Schwartz, Andy</dc:creator>
 <dc:creator>Ungar, Lyle</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Hand-built verb clusters such as the widely used Levin classes (Levin, 1993)
have proved useful, but have limited coverage. Verb classes automatically
induced from corpus data such as those from VerbKB (Wijaya, 2016), on the other
hand, can give clusters with much larger coverage, and can be adapted to
specific corpora such as Twitter. We present a method for clustering the
outputs of VerbKB: verbs with their multiple argument types, e.g.
&quot;marry(person, person)&quot;, &quot;feel(person, emotion).&quot; We make use of a novel
low-dimensional embedding of verbs and their arguments to produce high quality
clusters in which the same verb can be in different clusters depending on its
argument type. The resulting verb clusters do a better job than hand-built
clusters of predicting sarcasm, sentiment, and locus of control in tweets.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00417</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Investigation on Social Network Recommender Systems and Collaborative
  Filtering Techniques</dc:title>
 <dc:creator>Nayebzadeh, Maryam</dc:creator>
 <dc:creator>Moazzam, Akbar</dc:creator>
 <dc:creator>Saba, Amir Mohammad</dc:creator>
 <dc:creator>Abdolrahimpour, Hadi</dc:creator>
 <dc:creator>Shahab, Elham</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Nowadays, with the remarkable expansion of the information through the
internet, users prefer to receive the exact information that they need through
some suggestions from their friends or profiles to save their time and money.
Recommend systems based on different algorithms as one of the basic ways to
reach this goal through the internet have been proposed but each of them has
their own advantages and disadvantages. In this study, we have selected and
implemented two approaches which are Collaborative Filtering (CF) and Social
Network Recommendations System (SNRS). Based on some limitations to finding a
dataset which covers friendship, rating and item categories we generated it for
10 categories, 10 items, and 100 users and compared two approaches. We used
Mean Absolute Error (MAE) and accuracy to compare the result of two mentioned
approaches and found that the SNRS method as it is claimed to be improved
version of CF works more efficiency.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00420</identifier>
 <datestamp>2017-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of different time series aggregation methods on optimal energy
  system design</dc:title>
 <dc:creator>Kotzur, Leander</dc:creator>
 <dc:creator>Markewitz, Peter</dc:creator>
 <dc:creator>Robinius, Martin</dc:creator>
 <dc:creator>Stolten, Detlef</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Modelling renewable energy systems is a computationally-demanding task due to
the high fluctuation of supply and demand time series. To reduce the scale of
these, this paper discusses different methods for their aggregation into
typical periods. Each aggregation method is applied to a different type of
energy system model, making the methods fairly incomparable. To overcome this,
the different aggregation methods are first extended so that they can be
applied to all types of multidimensional time series and then compared by
applying them to different energy system configurations and analyzing their
impact on the cost optimal design. It was found that regardless of the method,
time series aggregation allows for significantly reduced computational
resources. Nevertheless, averaged values lead to underestimation of the real
system cost in comparison to the use of representative periods from the
original time series. The aggregation method itself, e.g. k means clustering,
plays a minor role. More significant is the system considered: Energy systems
utilizing centralized resources require fewer typical periods for a feasible
system design in comparison to systems with a higher share of renewable
feed-in. Furthermore, for energy systems based on seasonal storage, currently
existing models integration of typical periods is not suitable.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00420</dc:identifier>
 <dc:identifier>doi:10.1016/j.renene.2017.10.017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00422</identifier>
 <datestamp>2017-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wiretap Channels with Causal State Information: Strong Secrecy</dc:title>
 <dc:creator>Han, Te Sun</dc:creator>
 <dc:creator>Sasaki, Masahide</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The coding problem for wiretap channels with causal channel state information
available at the encoder and/or the decoder is studied under the strong secrecy
criterion. This problem consists of two aspects: one is due to naive wiretap
channel coding and the other is due to one-time pad cipher based on the secret
key agreement between Alice and Bob using the channel state information. These
two aspects are closely related to each other and investigated in details from
the viewpoint of achievable rates with strong secrecy. The general wiretap
channel with various directions of channel state informations among Alice, Bob
and Eve (called the multi-way channel state information) is also studied, which
includes the above systems as special cases. We provide a unified view about
wiretap channel coding with causal multi-way channel state information.
</dc:description>
 <dc:description>Comment: 28 pages, 7 figures, 1 style file</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00422</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00430</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Breaking the curse of dimensionality in regression</dc:title>
 <dc:creator>Zhu, Yinchu</dc:creator>
 <dc:creator>Bradic, Jelena</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Models with many signals, high-dimensional models, often impose structures on
the signal strengths. The common assumption is that only a few signals are
strong and most of the signals are zero or close (collectively) to zero.
However, such a requirement might not be valid in many real-life applications.
In this article, we are interested in conducting large-scale inference in
models that might have signals of mixed strengths. The key challenge is that
the signals that are not under testing might be collectively non-negligible
(although individually small) and cannot be accurately learned. This article
develops a new class of tests that arise from a moment matching formulation. A
virtue of these moment-matching statistics is their ability to borrow strength
across features, adapt to the sparsity size and exert adjustment for testing
growing number of hypothesis. GRoup-level Inference of Parameter, GRIP, test
harvests effective sparsity structures with hypothesis formulation for an
efficient multiple testing procedure. Simulated data showcase that GRIPs error
control is far better than the alternative methods. We develop a minimax
theory, demonstrating optimality of GRIP for a broad range of models, including
those where the model is a mixture of a sparse and high-dimensional dense
signals.
</dc:description>
 <dc:description>Comment: 51 pages</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00430</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00433</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Composable security in relativistic quantum cryptography</dc:title>
 <dc:creator>Vilasini, V.</dc:creator>
 <dc:creator>Portmann, Christopher</dc:creator>
 <dc:creator>del Rio, Lidia</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Relativistic protocols have been proposed to overcome some impossibility
results in classical and quantum cryptography. In such a setting, one takes the
location of honest players into account, and uses the fact that information
cannot travel faster than the speed of light to limit the abilities of
dishonest agents. For example, various relativistic bit commitment protocols
have been proposed. Although it has been shown that bit commitment is
sufficient to construct oblivious transfer and thus multiparty computation,
composing specific relativistic protocols in this way is known to be insecure.
A composable framework is required to perform such a modular security analysis
of construction schemes, but no known frameworks can handle models of
computation in Minkowski space.
  By instantiating the systems model from the Abstract Cryptography framework
with causal boxes, we obtain such a composable framework, in which messages are
assigned a location in Minkowski space (or superpositions thereof). This allows
us to analyze relativistic protocols, and derive novel possibility and
impossibility results. We show that (1) coin flipping can be constructed from
the primitive channel with delay, (2) biased coin flipping, bit commitment and
channel with delay are all impossible without further assumptions, and (3) it
is impossible to improve a channel with delay. This implies in particular
non-composability of all proposed relativistic bit commitment protocols, as
well as non-composability of (quantum, but non-relativistic) biased coin
flipping protocols.
</dc:description>
 <dc:description>Comment: 17 pages + appendix, many pictures</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00433</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00463</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Subtask Discovery With Non-Negative Matrix Factorization</dc:title>
 <dc:creator>Earle, Adam C.</dc:creator>
 <dc:creator>Saxe, Andrew M.</dc:creator>
 <dc:creator>Rosman, Benjamin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Hierarchical reinforcement learning methods offer a powerful means of
planning flexible behavior in complicated domains. However, learning an
appropriate hierarchical decomposition of a domain into subtasks remains a
substantial challenge. We present a novel algorithm for subtask discovery,
based on the recently introduced multitask linearly-solvable Markov decision
process (MLMDP) framework. The MLMDP can perform never-before-seen tasks by
representing them as a linear combination of a previously learned basis set of
tasks. In this setting, the subtask discovery problem can naturally be posed as
finding an optimal low-rank approximation of the set of tasks the agent will
face in a domain. We use non-negative matrix factorization to discover this
minimal basis set of tasks, and show that the technique learns intuitive
decompositions in a variety of domains. Our method has several qualitatively
desirable features: it is not limited to learning subtasks with single goal
states, instead learning distributed patterns of preferred states; it learns
qualitatively different hierarchical decompositions in the same domain
depending on the ensemble of tasks the agent will face; and it may be
straightforwardly iterated to obtain deeper hierarchical decompositions.
</dc:description>
 <dc:description>Comment: 7 pages, Accepted at Lifelong Learning: A Reinforcement Learning
  Approach Workshop, ICML, Sydney, Australia, 2017</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00463</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00465</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intrinsic Frequency Analysis and Fast Algorithms</dc:title>
 <dc:creator>Tavallali, Peyman</dc:creator>
 <dc:creator>Koorehdavoudi, Hana</dc:creator>
 <dc:creator>Krupa, Joanna</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Intrinsic Frequency (IF) has recently been introduced as an ample signal
processing method for analyzing carotid and aortic pulse pressure tracings. The
IF method has also been introduced as an effective approach for the analysis of
cardiovascular system dynamics. The physiological significance, convergence and
accuracy of the IF algorithm has been established in prior works. In this
paper, we show that the IF method could be derived by appropriate mathematical
approximations from the Navier-Stokes and elasticity equations. We further
introduce a fast algorithm for the IF method based on the mathematical analysis
of this method. In particular, we demonstrate that the IF algorithm can be made
faster, by a factor or more than 100 times, using a proper set of initial
guesses based on the topology of the problem, fast analytical solution at each
point iteration, and substituting the brute force algorithm with a pattern
search method. Statistically, we observe that the algorithm presented in this
article complies well with its brute-force counterpart. Furthermore, we will
show that on a real dataset, the fast IF method can draw correlations between
the extracted intrinsic frequency features and the infusion of certain drugs.
In general, this paper aims at a mathematical analysis of the IF method to show
its possible origins and also to present faster algorithms.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00465</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00481</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Lightweight Front-end Tool for Interactive Entity Population</dc:title>
 <dc:creator>Oiwa, Hidekazu</dc:creator>
 <dc:creator>Suhara, Yoshihiko</dc:creator>
 <dc:creator>Komiya, Jiyu</dc:creator>
 <dc:creator>Lopatenko, Andrei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Entity population, a task of collecting entities that belong to a particular
category, has attracted attention from vertical domains. There is still a high
demand for creating entity dictionaries in vertical domains, which are not
covered by existing knowledge bases. We develop a lightweight front-end tool
for facilitating interactive entity population. We implement key components
necessary for effective interactive entity population: 1) GUI-based dashboards
to quickly modify an entity dictionary, and 2) entity highlighting on documents
for quickly viewing the current progress. We aim to reduce user cost from
beginning to end, including package installation and maintenance. The
implementation enables users to use this tool on their web browsers without any
additional packages --- users can focus on their missions to create entity
dictionaries. Moreover, an entity expansion module is implemented as external
APIs. This design makes it easy to continuously improve interactive entity
population pipelines. We are making our demo publicly available
(http://bit.ly/luwak-demo).
</dc:description>
 <dc:description>Comment: ICML Workshop on Interactive Machine Learning</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00483</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The effect of an information system on the learning of the space
  structure</dc:title>
 <dc:creator>Molaei, MohammadReza</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this essay, a general case of information systems contains quantum
information systems is considered. By presenting an algorithmic method a new
kind of information topology is defined and considered. Continuous maps between
two information topological spaces are studied. Moreover, open and compact
information systems are taken into consideration. It is also proved that a
finite product of compact information systems is a compact information system.
Following that, two methods for constructing new open covers for a class of
compact information systems are presented, and information topological entropy
for continuous self maps of an information topological space is considered. We
show that information topological entropy is an invariant object under a
conjugate relation. Finally, as an applied example, a mathematical model for
knowledge spread is introduced.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00489</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Learning for Convolutional Neural Networks: A Core-Set Approach</dc:title>
 <dc:creator>Sener, Ozan</dc:creator>
 <dc:creator>Savarese, Silvio</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Convolutional neural networks (CNNs) have been successfully applied to many
recognition and learning tasks using a universal recipe; training a deep model
on a very large dataset of supervised examples. However, this approach is
rather restrictive in practice since collecting a large set of labeled images
is very expensive. One way to ease this problem is coming up with smart ways
for choosing images to be labelled from a very large collection (ie. active
learning).
  Our empirical study suggests that many of the active learning heuristics in
the literature are not effective when applied to CNNs in batch setting.
Inspired by these limitations, we define the problem of active learning as
core-set selection, ie. choosing set of points such that a model learned over
the selected subset is competitive for the remaining data points. We further
present a theoretical result characterizing the performance of any selected
subset using the geometry of the datapoints. As an active learning algorithm,
we choose the subset which is expected to yield best result according to our
characterization. Our experiments show that the proposed method significantly
outperforms existing approaches in image classification experiments by a large
margin.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00495</identifier>
 <datestamp>2017-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;I can assure you [$\ldots$] that it's going to be all right&quot; -- A
  definition, case for, and survey of algorithmic assurances in human-autonomy
  trust relationships</dc:title>
 <dc:creator>Israelsen, Brett W</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  As technology become more advanced, those who design, use and are otherwise
affected by it want to know that it will perform correctly, and understand why
it does what it does, and how to use it appropriately. In essence they want to
be able to trust the systems that are being designed. In this survey we present
assurances that are the method by which users can understand how to trust this
technology. Trust between humans and autonomy is reviewed, and the implications
for the design of assurances are highlighted. A survey of research that has
been performed with respect to assurances is presented, and several key ideas
are extracted in order to refine the definition of assurances. Several
directions for future research are identified and discussed.
</dc:description>
 <dc:description>Comment: Copy submitted to area exam committee</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00497</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Car sharing through the data analysis lens</dc:title>
 <dc:creator>Boldrini, Chiara</dc:creator>
 <dc:creator>Bruno, Raffaele</dc:creator>
 <dc:creator>Laarabi, Haitam</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Car sharing is one the pillars of a smart transportation infrastructure, as
it is expected to reduce traffic congestion, parking demands and pollution in
our cities. From the point of view of demand modelling, car sharing is a weak
signal in the city landscape: only a small percentage of the population uses
it, and thus it is difficult to study reliably with traditional techniques such
as households travel diaries. In this work, we depart from these traditional
approaches and we rely on web-based, digital records about vehicle availability
in 10 European cities for one of the major active car sharing operators. We
discuss how vehicles are used, what are the main characteristics of car sharing
trips, whether events happening in certain areas are predictable or not, and
how the spatio-temporal information about vehicle availability can be used to
infer how different zones in a city are used by customers. We conclude the
paper by presenting a direct application of the analysis of the dataset, aimed
at identifying where to locate maintenance facilities within the car sharing
operational area.
</dc:description>
 <dc:description>Comment: Accepted for KNOWMe: 1st International Workshop on Knowledge
  Discovery from Mobility and Transportation Systems (colocated with PKDD 2017)</dc:description>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00510</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on the size of query trees</dc:title>
 <dc:creator>Vardi, Shai</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider query trees of graphs with degree bounded by a constant, $d$. We
give simple proofs that the size of a query tree is constant in expectation and
$2^{O(d)}\log{n}$ w.h.p.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00510</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00514</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dense Piecewise Planar RGB-D SLAM for Indoor Environments</dc:title>
 <dc:creator>Le, Phi-Hung</dc:creator>
 <dc:creator>Kosecka, Jana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The paper exploits weak Manhattan constraints to parse the structure of
indoor environments from RGB-D video sequences in an online setting. We extend
the previous approach for single view parsing of indoor scenes to video
sequences and formulate the problem of recovering the floor plan of the
environment as an optimal labeling problem solved using dynamic programming.
The temporal continuity is enforced in a recursive setting, where labeling from
previous frames is used as a prior term in the objective function. In addition
to recovery of piecewise planar weak Manhattan structure of the extended
environment, the orthogonality constraints are also exploited by visual
odometry and pose graph optimization. This yields reliable estimates in the
presence of large motions and absence of distinctive features to track. We
evaluate our method on several challenging indoors sequences demonstrating
accurate SLAM and dense mapping of low texture environments. On existing TUM
benchmark we achieve competitive results with the alternative approaches which
fail in our environments.
</dc:description>
 <dc:description>Comment: International Conference on Intelligent Robots and Systems (IROS)
  2017</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00514</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00521</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rational Proofs with Non-Cooperative Provers</dc:title>
 <dc:creator>Chen, Jing</dc:creator>
 <dc:creator>McCauley, Samuel</dc:creator>
 <dc:creator>Singh, Shikha</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Interactive-proof-based approaches are widely used in verifiable computation
outsourcing. The verifier models a computationally-constrained client and the
provers model powerful service providers. In classical interactive-proof models
with multiple provers, the provers' interests either perfectly align (e.g. MIP)
or directly conflict (e.g. refereed games). However, service providers
participating in outsourcing applications may not meet such extremes. Instead,
each provider may be paid for his service, while he acts solely in his own best
interest. An active research area in this context is rational interactive
proofs (RIP), in which the provers try to maximize their payment. However,
existing works consider either a single prover, or multiple provers who
cooperate to maximize their total payment. None of them truly capture the
strategic nature of multiple service providers. How to define and design
non-cooperative rational interactive proofs is a well-known open problem.
  We introduce a multi-prover interactive-proof model in which the provers are
rational and non-cooperative. That is, each prover acts individually so as to
maximize his own payment in the resulting game. This model generalizes
single-prover rational interactive proofs as well as cooperative multi-prover
rational proofs. This new model better reflects the strategic nature of service
providers from a game-theoretic viewpoint.
  To design and analyze non-cooperative rational interactive proofs (ncRIP), we
define a new solution concept for extensive-form games with imperfect
information, strong sequential equilibrium. Our technical results focus on
protocols which give strong guarantees on utility gap, which is analogous to
soundness gap in classical interactive proofs. We give tight characterizations
of the class of ncRIP protocols with constant, noticeable, and negligible gap.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00523</identifier>
 <datestamp>2017-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gradient Descent using Duality Structures</dc:title>
 <dc:creator>Flynn, Thomas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In most applications of gradient-based optimization to complex problems the
choice of step size is based on trial-and-error and other heuristics. A case
when it is easy to choose the step sizes is when the function has a Lipschitz
continuous gradient. Many functions of interest do not appear at first sight to
have this property, but often it can be established with the right choice of
underlying metric. We find a simple recipe for choosing step sizes when a
function has a Lipschitz gradient with respect to any Finsler structure that
verifies an exponential bound. These step sizes are guaranteed to give
convergence, but they may be conservative since they rely on an exponential
bound. However, when relevant problem structure can be encoded in the metric to
yield a significantly tighter bound while keeping optimization tractable, this
may lead to rigorous and efficient algorithms. In particular, our general
result can be applied to yield an optimization algorithm with non-asymptotic
performance guarantees for batch optimization of multilayer neural networks.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00524</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using millions of emoji occurrences to learn any-domain representations
  for detecting sentiment, emotion and sarcasm</dc:title>
 <dc:creator>Felbo, Bjarke</dc:creator>
 <dc:creator>Mislove, Alan</dc:creator>
 <dc:creator>S&#xf8;gaard, Anders</dc:creator>
 <dc:creator>Rahwan, Iyad</dc:creator>
 <dc:creator>Lehmann, Sune</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  NLP tasks are often limited by scarcity of manually annotated data. In social
media sentiment analysis and related tasks, researchers have therefore used
binarized emoticons and specific hashtags as forms of distant supervision. Our
paper shows that by extending the distant supervision to a more diverse set of
noisy labels, the models can learn richer representations. Through emoji
prediction on a dataset of 1246 million tweets containing one of 64 common
emojis we obtain state-of-the-art performance on 8 benchmark datasets within
sentiment, emotion and sarcasm detection using a single pretrained model. Our
analyses confirm that the diversity of our emotional labels yield a performance
improvement over previous distant supervision approaches.
</dc:description>
 <dc:description>Comment: Accepted at EMNLP 2017. Please include EMNLP in any citations. Minor
  changes from the EMNLP camera-ready version. 9 pages + references and
  supplementary material</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-10-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00531</identifier>
 <datestamp>2017-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-End Neural Segmental Models for Speech Recognition</dc:title>
 <dc:creator>Tang, Hao</dc:creator>
 <dc:creator>Lu, Liang</dc:creator>
 <dc:creator>Kong, Lingpeng</dc:creator>
 <dc:creator>Gimpel, Kevin</dc:creator>
 <dc:creator>Livescu, Karen</dc:creator>
 <dc:creator>Dyer, Chris</dc:creator>
 <dc:creator>Smith, Noah A.</dc:creator>
 <dc:creator>Renals, Steve</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Segmental models are an alternative to frame-based models for sequence
prediction, where hypothesized path weights are based on entire segment scores
rather than a single frame at a time. Neural segmental models are segmental
models that use neural network-based weight functions. Neural segmental models
have achieved competitive results for speech recognition, and their end-to-end
training has been explored in several studies. In this work, we review neural
segmental models, which can be viewed as consisting of a neural network-based
acoustic encoder and a finite-state transducer decoder. We study end-to-end
segmental models with different weight functions, including ones based on
frame-level neural classifiers and on segmental recurrent neural networks. We
study how reducing the search space size impacts performance under different
weight functions. We also compare several loss functions for end-to-end
training. Finally, we explore training approaches, including multi-stage vs.
end-to-end training and multitask training that combines segmental and
frame-level losses.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00531</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00543</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Balancing Explicability and Explanation in Human-Aware Planning</dc:title>
 <dc:creator>Sreedharan, Sarath</dc:creator>
 <dc:creator>Chakraborti, Tathagata</dc:creator>
 <dc:creator>Kambhampati, Subbarao</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Human aware planning requires an agent to be aware of the intentions,
capabilities and mental model of the human in the loop during its decision
process. This can involve generating plans that are explicable to a human
observer as well as the ability to provide explanations when such plans cannot
be generated. This has led to the notion &quot;multi-model planning&quot; which aim to
incorporate effects of human expectation in the deliberative process of a
planner - either in the form of explicable task planning or explanations
produced thereof. In this paper, we bring these two concepts together and show
how a planner can account for both these needs and achieve a trade-off during
the plan generation process itself by means of a model-space search method
MEGA. This in effect provides a comprehensive perspective of what it means for
a decision making agent to be &quot;human-aware&quot; by bringing together existing
principles of planning under the umbrella of a single plan generation process.
We situate our discussion specifically keeping in mind the recent work on
explicable planning and explanation generation, and illustrate these concepts
in modified versions of two well known planning domains, as well as a
demonstration on a robot involved in a typical search and reconnaissance task
with an external supervisor.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00543</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00544</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Measurements of Supercomputing and Cloud Storage Solutions</dc:title>
 <dc:creator>Jones, Michael</dc:creator>
 <dc:creator>Kepner, Jeremy</dc:creator>
 <dc:creator>Arcand, William</dc:creator>
 <dc:creator>Bestor, David</dc:creator>
 <dc:creator>Bergeron, Bill</dc:creator>
 <dc:creator>Gadepally, Vijay</dc:creator>
 <dc:creator>Houle, Michael</dc:creator>
 <dc:creator>Hubbell, Matthew</dc:creator>
 <dc:creator>Michaleas, Peter</dc:creator>
 <dc:creator>Prout, Andrew</dc:creator>
 <dc:creator>Reuther, Albert</dc:creator>
 <dc:creator>Samsi, Siddharth</dc:creator>
 <dc:creator>Monticiollo, Paul</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Increasing amounts of data from varied sources, particularly in the fields of
machine learning and graph analytics, are causing storage requirements to grow
rapidly. A variety of technologies exist for storing and sharing these data,
ranging from parallel file systems used by supercomputers to distributed block
storage systems found in clouds. Relatively few comparative measurements exist
to inform decisions about which storage systems are best suited for particular
tasks. This work provides these measurements for two of the most popular
storage technologies: Lustre and Amazon S3. Lustre is an open-source, high
performance, parallel file system used by many of the largest supercomputers in
the world. Amazon's Simple Storage Service, or S3, is part of the Amazon Web
Services offering, and offers a scalable, distributed option to store and
retrieve data from anywhere on the Internet. Parallel processing is essential
for achieving high performance on modern storage systems. The performance tests
used span the gamut of parallel I/O scenarios, ranging from single-client,
single-node Amazon S3 and Lustre performance to a large-scale, multi-client
test designed to demonstrate the capabilities of a modern storage appliance
under heavy load. These results show that, when parallel I/O is used correctly
(i.e., many simultaneous read or write processes), full network bandwidth
performance is achievable and ranged from 10 gigabits/s over a 10 GigE S3
connection to 0.35 terabits/s using Lustre on a 1200 port 10 GigE switch. These
results demonstrate that S3 is well-suited to sharing vast quantities of data
over the Internet, while Lustre is well-suited to processing large quantities
of data locally.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures, to appear in IEEE HPEC 2017</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00544</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00549</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Representation Learning for Predicting Commonsense Ontologies</dc:title>
 <dc:creator>Li, Xiang</dc:creator>
 <dc:creator>Vilnis, Luke</dc:creator>
 <dc:creator>McCallum, Andrew</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recent work in learning ontologies (hierarchical and partially-ordered
structures) has leveraged the intrinsic geometry of spaces of learned
representations to make predictions that automatically obey complex structural
constraints. We explore two extensions of one such model, the order-embedding
model for hierarchical relation learning, with an aim towards improved
performance on text data for commonsense knowledge representation. Our first
model jointly learns ordering relations and non-hierarchical knowledge in the
form of raw text. Our second extension exploits the partial order structure of
the training data to find long-distance triplet constraints among embeddings
which are poorly enforced by the pairwise training procedure. We find that both
incorporating free text and augmented training constraints improve over the
original order-embedding model and other strong baselines.
</dc:description>
 <dc:description>Comment: 4 pages, ICML 2017 DeepStruct Workshop</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00551</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bonsai: Synthesis-Based Reasoning for Type Systems</dc:title>
 <dc:creator>Chandra, Kartik</dc:creator>
 <dc:creator>Bodik, Rastislav</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We describe algorithms for symbolic reasoning about executable models of type
systems, supporting three queries intended for designers of type systems.
First, we check for type soundness bugs and synthesize a counterexample program
if such a bug is found. Second, we compare two versions of a type system,
synthesizing a program accepted by one but rejected by the other. Third, we
minimize the size of synthesized counterexample programs.
  These algorithms symbolically evaluate typecheckers and interpreters,
producing formulas that characterize the set of programs that fail or succeed
in the typechecker and the interpreter. However, symbolically evaluating
interpreters poses efficiency challenges, which are caused by having to merge
execution paths of the various possible input programs. Our main contribution
is the Bonsai tree, a novel symbolic representation of programs and program
states which addresses these challenges. Bonsai trees encode complex syntactic
information in terms of logical constraints, enabling more efficient merging.
  We implement these algorithms in the Bonsai tool, an assistant for type
system designers. We perform case studies on how Bonsai helps test and explore
a variety of type systems. Bonsai efficiently synthesizes counterexamples for
soundness bugs that have been inaccessible to automatic tools, and is the first
automated tool to find a counterexample for the recently discovered Scala
soundness bug SI-9633.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00551</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00552</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimal Sum Labeling of Graphs</dc:title>
 <dc:creator>Kone&#x10d;n&#xfd;, Mat&#x11b;j</dc:creator>
 <dc:creator>Ku&#x10d;era, Stanislav</dc:creator>
 <dc:creator>Novotn&#xe1;, Jana</dc:creator>
 <dc:creator>Pek&#xe1;rek, Jakub</dc:creator>
 <dc:creator>&#x160;imsa, &#x160;t&#x11b;p&#xe1;n</dc:creator>
 <dc:creator>T&#xf6;pfer, Martin</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A graph $G$ is called a sum graph if there is a so-called sum labeling of
$G$, i.e. an injective function $\ell: V(G) \rightarrow \mathbb{N}$ such that
for every $u,v\in V(G)$ it holds that $uv\in E(G)$ if and only if there exists
a vertex $w\in V(G)$ such that $\ell(u)+\ell(v) = \ell(w)$. We say that sum
labeling $\ell$ is minimal if there is a vertex $u\in V(G)$ such that
$\ell(u)=1$. In this paper, we show that if we relax the conditions (either
allow non-injective labelings or consider graphs with loops) then there are sum
graphs without a minimal labeling, which partially answers the question posed
by Miller, Ryan and Smyth in 1998.
</dc:description>
 <dc:description>Comment: IWOCA 2017</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00553</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Rank Hidden State Embeddings for Viterbi Sequence Labeling</dc:title>
 <dc:creator>Thai, Dung</dc:creator>
 <dc:creator>Murty, Shikhar</dc:creator>
 <dc:creator>Bansal, Trapit</dc:creator>
 <dc:creator>Vilnis, Luke</dc:creator>
 <dc:creator>Belanger, David</dc:creator>
 <dc:creator>McCallum, Andrew</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In textual information extraction and other sequence labeling tasks it is now
common to use recurrent neural networks (such as LSTM) to form rich embedded
representations of long-term input co-occurrence patterns. Representation of
output co-occurrence patterns is typically limited to a hand-designed graphical
model, such as a linear-chain CRF representing short-term Markov dependencies
among successive labels. This paper presents a method that learns embedded
representations of latent output structure in sequence data. Our model takes
the form of a finite-state machine with a large number of latent states per
label (a latent variable CRF), where the state-transition matrix is
factorized---effectively forming an embedded representation of
state-transitions capable of enforcing long-term label dependencies, while
supporting exact Viterbi inference over output labels. We demonstrate accuracy
improvements and interpretable latent structure in a synthetic but complex task
based on CoNLL named entity recognition.
</dc:description>
 <dc:description>Comment: 4 pages, ICML 2017 DeepStruct Workshop</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00553</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00562</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unique One-Time Password Table Sequence Pattern Authentication:
  Application to Bicol University Union of Federated Faculty Association, Inc.
  (BUUFFAI) eVoting System</dc:title>
 <dc:creator>Balilo Jr., Benedicto B.</dc:creator>
 <dc:creator>Gerardo, Bobby D.</dc:creator>
 <dc:creator>Medina, Ruji P.</dc:creator>
 <dc:creator>Byun, Yungcheol</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Electronic Voting System (EVS) is a type of voting program that deals
primarily with the selection, the casting of votes with embedded security
mechanism that detects errors, and the tamper-proof election of results done
through the use of an electronic system. It can include optical scan,
specialized voting kiosks and Internet voting approach. Most organizations have
difficulties when it comes to voting and the Bicol University Union of
Federated Faculty Association Incorporated (BUUFFAI) is not an exception. Some
of the problems involved include convenience, cost, geographical location of
the polling precinct, and voting turnouts. This study extends the scope of the
current BUUFFAI eVoting system to address such issues and to eliminate
inconvenience both to the faculty voters and the facilitators. This voting
scheme used an algorithmic OTP scheme based on table sequence pattern schedule
that randomly generates an XY coordinate unique to voters that will be sent to
voter registered email address. This study addressed the security requirements
and maintained election procedures with confidentiality, integrity and
availability.
</dc:description>
 <dc:description>Comment: Vol. 1, No. 1, pp. 1-10 https://stepacademic.net</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00562</dc:identifier>
 <dc:identifier>International Journal of Computing Sciences Research (ISSN
  (print): 2546-0552)2017</dc:identifier>
 <dc:identifier>doi:10.25147/ijcsr.2017.001.1.03</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00563</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analyzing Neural MT Search and Model Performance</dc:title>
 <dc:creator>Niehues, Jan</dc:creator>
 <dc:creator>Cho, Eunah</dc:creator>
 <dc:creator>Ha, Thanh-Le</dc:creator>
 <dc:creator>Waibel, Alex</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we offer an in-depth analysis about the modeling and search
performance. We address the question if a more complex search algorithm is
necessary. Furthermore, we investigate the question if more complex models
which might only be applicable during rescoring are promising.
  By separating the search space and the modeling using $n$-best list
reranking, we analyze the influence of both parts of an NMT system
independently. By comparing differently performing NMT systems, we show that
the better translation is already in the search space of the translation
systems with less performance. This results indicate that the current search
algorithms are sufficient for the NMT systems. Furthermore, we could show that
even a relatively small $n$-best list of $50$ hypotheses already contain
notably better translations.
</dc:description>
 <dc:description>Comment: 7 pages, First Workshop on Neural Machine Translation</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00568</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On $w$-mixtures: Finite convex combinations of prescribed component
  distributions</dc:title>
 <dc:creator>Nielsen, Frank</dc:creator>
 <dc:creator>Nock, Richard</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the space of $w$-mixtures that is the set of finite statistical
mixtures sharing the same prescribed component distributions. The geometry
induced by the Kullback-Leibler (KL) divergence on this family of $w$-mixtures
is a dually flat space in information geometry called the mixture family
manifold. It follows that the KL divergence between two $w$-mixtures is
equivalent to a Bregman Divergence (BD) defined for the negative Shannon
entropy generator. Thus the KL divergence between two Gaussian Mixture Models
(GMMs) sharing the same components is (theoretically) a Bregman divergence.
This KL-BD equivalence implies that we can perform optimal KL-averaging
aggregation of $w$-mixtures without information loss. More generally, we prove
that the skew Jensen-Shannon divergence between $w$-mixtures is equivalent to a
skew Jensen divergence on their parameters. Finally, we state several
divergence identity and inequalities relating $w$-mixtures.
</dc:description>
 <dc:description>Comment: 25 pages</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00568</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00573</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic 3D Cardiovascular MR Segmentation with Densely-Connected
  Volumetric ConvNets</dc:title>
 <dc:creator>Yu, Lequan</dc:creator>
 <dc:creator>Cheng, Jie-Zhi</dc:creator>
 <dc:creator>Dou, Qi</dc:creator>
 <dc:creator>Yang, Xin</dc:creator>
 <dc:creator>Chen, Hao</dc:creator>
 <dc:creator>Qin, Jing</dc:creator>
 <dc:creator>Heng, Pheng-Ann</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatic and accurate whole-heart and great vessel segmentation from 3D
cardiac magnetic resonance (MR) images plays an important role in the
computer-assisted diagnosis and treatment of cardiovascular disease. However,
this task is very challenging due to ambiguous cardiac borders and large
anatomical variations among different subjects. In this paper, we propose a
novel densely-connected volumetric convolutional neural network, referred as
DenseVoxNet, to automatically segment the cardiac and vascular structures from
3D cardiac MR images. The DenseVoxNet adopts the 3D fully convolutional
architecture for effective volume-to-volume prediction. From the learning
perspective, our DenseVoxNet has three compelling advantages. First, it
preserves the maximum information flow between layers by a densely-connected
mechanism and hence eases the network training. Second, it avoids learning
redundant feature maps by encouraging feature reuse and hence requires fewer
parameters to achieve high performance, which is essential for medical
applications with limited training data. Third, we add auxiliary side paths to
strengthen the gradient propagation and stabilize the learning process. We
demonstrate the effectiveness of DenseVoxNet by comparing it with the
state-of-the-art approaches from HVSMR 2016 challenge in conjunction with
MICCAI, and our network achieves the best dice coefficient. We also show that
our network can achieve better performance than other 3D ConvNets but with
fewer parameters.
</dc:description>
 <dc:description>Comment: Accepted at MICCAI 2017</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00573</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00576</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Line Segment Covering of Cells in Arrangements</dc:title>
 <dc:creator>Korman, Matias</dc:creator>
 <dc:creator>Poon, Sheung-Hung</dc:creator>
 <dc:creator>Roeloffzen, Marcel</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Given a collection $L$ of line segments, we consider its arrangement and
study the problem of covering all cells with line segments of $L$. That is, we
want to find a minimum-size set $L'$ of line segments such that every cell in
the arrangement has a line from $L'$ defining its boundary. We show that the
problem is NP-hard, even when all segments are axis-aligned. In fact, the
problem is still NP-hard when we only need to cover rectangular cells of the
arrangement. For the latter problem we also show that it is fixed parameter
tractable with respect to the size of the optimal solution. Finally we provide
a linear time algorithm for the case where cells of the arrangement are created
by recursively subdividing a rectangle using horizontal and vertical cutting
segments.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00577</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kernalised Multi-resolution Convnet for Visual Tracking</dc:title>
 <dc:creator>Wu, Di</dc:creator>
 <dc:creator>Zou, Wenbin</dc:creator>
 <dc:creator>Li, Xia</dc:creator>
 <dc:creator>Zhao, Yong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual tracking is intrinsically a temporal problem. Discriminative
Correlation Filters (DCF) have demonstrated excellent performance for
high-speed generic visual object tracking. Built upon their seminal work, there
has been a plethora of recent improvements relying on convolutional neural
network (CNN) pretrained on ImageNet as a feature extractor for visual
tracking. However, most of their works relying on ad hoc analysis to design the
weights for different layers either using boosting or hedging techniques as an
ensemble tracker. In this paper, we go beyond the conventional DCF framework
and propose a Kernalised Multi-resolution Convnet (KMC) formulation that
utilises hierarchical response maps to directly output the target movement.
When directly deployed the learnt network to predict the unseen challenging UAV
tracking dataset without any weight adjustment, the proposed model consistently
achieves excellent tracking performance. Moreover, the transfered
multi-reslution CNN renders it possible to be integrated into the RNN temporal
learning framework, therefore opening the door on the end-to-end temporal deep
learning (TDL) for visual tracking.
</dc:description>
 <dc:description>Comment: CVPRW 2017</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00578</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Emerging Topics in Internet Technology: A Complex Networks Approach</dc:title>
 <dc:creator>Khan, Bisma S.</dc:creator>
 <dc:creator>Niazi, Muaz A.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>C.2.5</dc:subject>
 <dc:subject>I.6.5</dc:subject>
 <dc:subject>H.1</dc:subject>
 <dc:description>  Communication networks, in general, and internet technology, in particular,
is a fast-evolving area of research. While it is important to keep track of
emerging trends in this domain, it is such a fast-growing area that it can be
very difficult to keep track of literature. The problem is compounded by the
fast-growing number of citation databases. While other databases are gradually
indexing a large set of reliable content, currently the Web of Science
represents one of the most highly valued databases. Research indexed in this
database is known to highlight key advancements in any domain. In this paper,
we present a Complex Network-based analytical approach to analyze recent data
from the Web of Science in communication networks. Taking bibliographic records
from the recent period of 2014 to 2017, we model and analyze complex
scientometric networks. Using bibliometric coupling applied over complex
citation data we present answers to co-citation patterns of documents,
co-occurrence patterns of terms, as well as the most influential articles,
among others, We also present key pivot points and intellectual turning points.
Complex network analysis of the data demonstrates a considerably high level of
interest in two key clusters labeled descriptively as &quot;social networks&quot; and
&quot;computer networks&quot;. In addition, key themes in highly cited literature were
clearly identified as &quot;communication networks,&quot; &quot;social networks,&quot; and &quot;complex
networks&quot;.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures, 3 tables</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00580</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Neural Network Model Specified for Representing Logical
  Relations</dc:title>
 <dc:creator>Wang, Gang</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  With computers to handle more and more complicated things in variable
environments, it becomes an urgent requirement that the artificial intelligence
has the ability of automatic judging and deciding according to numerous
specific conditions so as to deal with the complicated and variable cases. ANNs
inspired by brain is a good candidate. However, most of current numeric ANNs
are not good at representing logical relations because these models still try
to represent logical relations in the form of ratio based on functional
approximation. On the other hand, researchers have been trying to design novel
neural network models to make neural network model represent logical relations.
In this work, a novel neural network model specified for representing logical
relations is proposed and applied. New neurons and multiple kinds of links are
defined. Inhibitory links are introduced besides exciting links. Different from
current numeric ANNs, one end of an inhibitory link connects an exciting link
rather than a neuron. Inhibitory links inhibit the connected exciting links
conditionally to make this neural network model represent logical relations
correctly. This model can simulate the operations of Boolean logic gates, and
construct complex logical relations with the advantages of simpler neural
network structures than recent works in this area. This work provides some
ideas to make neural networks represent logical relations more directly and
efficiently, and the model could be used as the complement to current numeric
ANN to deal with logical issues and expand the application areas of ANN.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00580</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00581</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Transmission Map Estimation and Dehazing using Deep Networks</dc:title>
 <dc:creator>Zhang, He</dc:creator>
 <dc:creator>Sindagi, Vishwanath</dc:creator>
 <dc:creator>Patel, Vishal M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Single image haze removal is an extremely challenging problem due to its
inherent ill-posed nature. Several prior-based and learning-based methods have
been proposed in the literature to solve this problem and they have achieved
superior results. However, most of the existing methods assume constant
atmospheric light model and tend to follow a two- step procedure involving
prior-based methods for estimating transmission map followed by calculation of
dehazed image using the closed form solution. In this paper, we relax the
constant atmospheric light assumption and propose a novel unified single image
dehazing network that jointly estimates the transmission map and performs
dehazing. In other words, our new approach provides an end-to-end learning
framework, where the inherent transmission map and dehazed result are learned
directly from the loss function. Extensive experiments on synthetic and real
datasets with challenging hazy images demonstrate that the proposed method
achieves significant improvements over the state-of-the-art methods.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00582</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Excluded $t$-factors in Bipartite Graphs: Unified Framework for
  Nonbipartite Matchings, Restricted 2-matchings, and Matroids</dc:title>
 <dc:creator>Takazawa, Kenjiro</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We propose a framework for optimal $t$-matchings excluding the prescribed
$t$-factors in bipartite graphs. The proposed framework is a generalization of
the nonbipartite matching problem and includes several problems, such as the
triangle-free $2$-matching, square-free $2$-matching, even factor, and
arborescence problems. In this paper, we demonstrate a unified understanding of
these problems by commonly extending previous important results. We solve our
problem under a reasonable assumption, which is sufficiently broad to include
the specific problems listed above. We first present a min-max theorem and a
combinatorial algorithm for the unweighted version. We then provide a linear
programming formulation with dual integrality and a primal-dual algorithm for
the weighted version. A key ingredient of the proposed algorithm is a technique
to shrink forbidden structures, which corresponds to the techniques of
shrinking odd cycles, triangles, squares, and directed cycles in Edmonds'
blossom algorithm, a triangle-free $2$-matching algorithm, a square-free
$2$-matching algorithm, and an arborescence algorithm, respectively.
</dc:description>
 <dc:description>Comment: 23 pages, 7 figures, A preliminary version of this paper appears in
  Proceedings of the 19th IPCO (2017)</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00582</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00583</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Learning-based Framework for Hybrid Depth-from-Defocus and Stereo
  Matching</dc:title>
 <dc:creator>Chen, Zhang</dc:creator>
 <dc:creator>Guo, Xinqing</dc:creator>
 <dc:creator>Li, Siyuan</dc:creator>
 <dc:creator>Cao, Xuan</dc:creator>
 <dc:creator>Yu, Jingyi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Depth from defocus (DfD) and stereo matching are two most studied passive
depth sensing schemes. The techniques are essentially complementary: DfD can
robustly handle repetitive textures that are problematic for stereo matching
whereas stereo matching is insensitive to defocus blurs and can handle large
depth range. In this paper, we present a unified learning-based technique to
conduct hybrid DfD and stereo matching. Our input is image triplets: a stereo
pair and a defocused image of one of the stereo views. We first apply
depth-guided light field rendering to construct a comprehensive training
dataset for such hybrid sensing setups. Next, we adopt the hourglass network
architecture to separately conduct depth inference from DfD and stereo.
Finally, we exploit different connection methods between the two separate
networks for integrating them into a unified solution to produce high fidelity
3D disparity maps. Comprehensive experiments on real and synthetic data show
that our new learning-based hybrid 3D sensing technique can significantly
improve accuracy and robustness in 3D reconstruction.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00584</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple Loss Function for Improving the Convergence and Accuracy of
  Visual Question Answering Models</dc:title>
 <dc:creator>Ilievski, Ilija</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual question answering as recently proposed multimodal learning task has
enjoyed wide attention from the deep learning community. Lately, the focus was
on developing new representation fusion methods and attention mechanisms to
achieve superior performance. On the other hand, very little focus has been put
on the models' loss function, arguably one of the most important aspects of
training deep learning models. The prevailing practice is to use cross entropy
loss function that penalizes the probability given to all the answers in the
vocabulary except the single most common answer for the particular question.
However, the VQA evaluation function compares the predicted answer with all the
ground-truth answers for the given question and if there is a matching, a
partial point is given. This causes a discrepancy between the model's cross
entropy loss and the model's accuracy as calculated by the VQA evaluation
function. In this work, we propose a novel loss, termed as soft cross entropy,
that considers all ground-truth answers and thus reduces the loss-accuracy
discrepancy. The proposed loss leads to an improved training convergence of VQA
models and an increase in accuracy as much as 1.6%.
</dc:description>
 <dc:description>Comment: accepted at CVPR 2017 VQA workshop</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00584</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00586</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Software-Defined Multi-Element VLC Architecture</dc:title>
 <dc:creator>Mushfique, Sifat Ibne</dc:creator>
 <dc:creator>Palathingal, Prabath</dc:creator>
 <dc:creator>Eroglu, Yusuf Said</dc:creator>
 <dc:creator>Yuksel, Murat</dc:creator>
 <dc:creator>Guvenc, Ismail</dc:creator>
 <dc:creator>Pala, Nezih</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In the modern era of radio frequency (RF) spectrum crunch, visible light
communication (VLC) is a recent and promising alternative technology that
operates at the visible light spectrum. Thanks to its unlicensed and large
bandwidth, VLC can deliver high throughput, better energy efficiency, and low
cost data communications. In this article, a hybrid RF/VLC architecture is
considered that can simultaneously provide light- ing and communication
coverage across a room. Considered architecture involves a novel multi-element
hemispherical bulb design, which can transmit multiple data streams over light
emitting diode (LED) modules. Simulations considering various VLC transmitter
configurations and topologies show that good link quality and high spatial
reuse can be maintained in typical indoor communication scenarios.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00587</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometric Convolutional Neural Network for Analyzing Surface-Based
  Neuroimaging Data</dc:title>
 <dc:creator>Seong, Si-Baek</dc:creator>
 <dc:creator>Pae, Chongwon</dc:creator>
 <dc:creator>Park, Hae-Jeong</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>68T10</dc:subject>
 <dc:description>  The conventional CNN, widely used for two-dimensional images, however, is not
directly applicable to non-regular geometric surface, such as a cortical
thickness. We propose Geometric CNN (gCNN) that deals with data representation
over a spherical surface and renders pattern recognition in a multi-shell mesh
structure. The classification accuracy for sex was significantly higher than
that of SVM and image based CNN. It only uses MRI thickness data to classify
gender but this method can expand to classify disease from other MRI or fMRI
data
</dc:description>
 <dc:description>Comment: 29 pages</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00588</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hidden Physics Models: Machine Learning of Nonlinear Partial
  Differential Equations</dc:title>
 <dc:creator>Raissi, Maziar</dc:creator>
 <dc:creator>Karniadakis, George Em</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  While there is currently a lot of enthusiasm about &quot;big data&quot;, useful data is
usually &quot;small&quot; and expensive to acquire. In this paper, we present a new
paradigm of learning partial differential equations from {\em small} data. In
particular, we introduce \emph{hidden physics models}, which are essentially
data-efficient learning machines capable of leveraging the underlying laws of
physics, expressed by time dependent and nonlinear partial differential
equations, to extract patterns from high-dimensional data generated from
experiments. The proposed methodology may be applied to the problem of
learning, system identification, or data-driven discovery of partial
differential equations. Our framework relies on Gaussian processes, a powerful
tool for probabilistic inference over functions, that enables us to strike a
balance between model complexity and data fitting. The effectiveness of the
proposed approach is demonstrated through a variety of canonical problems,
spanning a number of scientific domains, including the Navier-Stokes,
Schr\&quot;odinger, Kuramoto-Sivashinsky, and time dependent linear fractional
equations. The methodology provides a promising new direction for harnessing
the long-standing developments of classical methods in applied mathematics and
mathematical physics to design learning machines with the ability to operate in
complex domains without requiring large quantities of data.
</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00588</dc:identifier>
 <dc:identifier>doi:10.1016/j.jcp.2017.11.039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00598</identifier>
 <datestamp>2017-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Controllable Generative Adversarial Network</dc:title>
 <dc:creator>Lee, Minhyeok</dc:creator>
 <dc:creator>Seok, Junhee</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Although it is recently introduced, in last few years, generative adversarial
network (GAN) has been shown many promising results to generate realistic
samples. However, it is hardly able to control generated samples since input
variables for a generator are from a random distribution. Some attempts have
been made to control generated samples from GAN, but they have not shown good
performances with difficult problems. Furthermore, it is hardly possible to
control the generator to concentrate on reality or distinctness. For example,
with existing models, a generator for face image generation cannot be set to
concentrate on one of the two objectives, i.e. generating realistic face and
generating difference face according to input labels. Here, we propose
controllable GAN (CGAN) in this paper. CGAN shows powerful performance to
control generated samples; in addition, it can control the generator to
concentrate on reality or distinctness. In this paper, CGAN is evaluated with
CelebA datasets. We believe that CGAN can contribute to the research in
generative neural network models.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:date>2017-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00598</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00601</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact Tensor Completion from Sparsely Corrupted Observations via Convex
  Optimization</dc:title>
 <dc:creator>Jiang, Jonathan Q.</dc:creator>
 <dc:creator>Ng, Michael K.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper conducts a rigorous analysis for provable estimation of
multidimensional arrays, in particular third-order tensors, from a random
subset of its corrupted entries. Our study rests heavily on a recently proposed
tensor algebraic framework in which we can obtain tensor singular value
decomposition (t-SVD) that is similar to the SVD for matrices, and define a new
notion of tensor rank referred to as the tubal rank. We prove that by simply
solving a convex program, which minimizes a weighted combination of tubal
nuclear norm, a convex surrogate for the tubal rank, and the $\ell_1$-norm, one
can recover an incoherent tensor exactly with overwhelming probability,
provided that its tubal rank is not too large and that the corruptions are
reasonably sparse. Interestingly, our result includes the recovery guarantees
for the problems of tensor completion (TC) and tensor principal component
analysis (TRPCA) under the same algebraic setup as special cases. An
alternating direction method of multipliers (ADMM) algorithm is presented to
solve this optimization problem. Numerical experiments verify our theory and
real-world applications demonstrate the effectiveness of our algorithm.
</dc:description>
 <dc:description>Comment: 36 pages, 9 figures</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00602</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase Retrieval From Binary Measurements</dc:title>
 <dc:creator>Mukherjee, Subhadip</dc:creator>
 <dc:creator>Seelamantula, Chandra Sekhar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of signal reconstruction from quadratic measurements
that are encoded as +1 or -1 depending on whether they exceed a predetermined
positive threshold or not. Binary measurements are fast to acquire and
inexpensive in terms of hardware. We formulate the problem of signal
reconstruction using a consistency criterion, wherein one seeks to find a
signal that is in agreement with the measurements. To enforce consistency, we
construct a convex cost using a one-sided quadratic penalty and minimize it
using an iterative accelerated projected gradient-descent (APGD) technique. The
PGD scheme reduces the cost function in each iteration, whereas incorporating
momentum into PGD, notwithstanding the lack of such a descent property,
exhibits faster convergence than PGD empirically. We refer to the resulting
algorithm as binary phase retrieval (BPR). Considering additive white noise
contamination prior to quantization, we also derive the Cramer-Rao Bound (CRB)
for the binary encoding model. Experimental results demonstrate that the BPR
algorithm yields a signal-to- reconstruction error ratio (SRER) of
approximately 25 dB in the absence of noise. In the presence of noise prior to
quantization, the SRER is within 2 to 3 dB of the CRB.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00602</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00606</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Task Scheduling in Communication-Constrained Mobile Edge
  Computing Systems for Wireless Virtual Reality</dc:title>
 <dc:creator>Yang, Xiao</dc:creator>
 <dc:creator>Chen, Zhiyong</dc:creator>
 <dc:creator>Li, Kuikui</dc:creator>
 <dc:creator>Sun, Yaping</dc:creator>
 <dc:creator>Zheng, Hongming</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Mobile edge computing (MEC) is expected to be an effective solution to
deliver 360-degree virtual reality (VR) videos over wireless networks. In
contrast to previous computation-constrained MEC framework, which reduces the
computation-resource consumption at the mobile VR device by increasing the
communication-resource consumption, we develop a communications-constrained MEC
framework to reduce communication-resource consumption by increasing the
computation-resource consumption and exploiting the caching resources at the
mobile VR device in this paper. Specifically, according to the task
modularization, the MEC server can only deliver the components which have not
been stored in the VR device, and then the VR device uses the received
components and the corresponding cached components to construct the task,
resulting in low communication-resource consumption but high delay. The MEC
server can also compute the task by itself to reduce the delay, however, it
consumes more communication-resource due to the delivery of entire task.
Therefore, we then propose a task scheduling strategy to decide which
computation model should the MEC server operates, in order to minimize the
communication-resource consumption under the delay constraint. Finally, we
discuss the tradeoffs between communications, computing, and caching in the
proposed system.
</dc:description>
 <dc:description>Comment: submitted to APCC 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00607</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CT sinogram-consistency learning for metal-induced beam hardening
  correction</dc:title>
 <dc:creator>Park, Hyung Suk</dc:creator>
 <dc:creator>Lee, Sung Min</dc:creator>
 <dc:creator>Kim, Hwa Pyung</dc:creator>
 <dc:creator>Seo, Jin Keun</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a sinogram consistency learning method to deal with
beam-hardening related artifacts in polychromatic computerized tomography (CT).
The presence of highly attenuating materials in the scan field causes an
inconsistent sinogram, that does not match the range space of the Radon
transform. When the mismatched data are entered into the range space during CT
reconstruction, streaking and shading artifacts are generated owing to the
inherent nature of the inverse Radon transform. The proposed learning method
aims to repair inconsistent sinograms by removing the primary metal-induced
beam-hardening factors along the metal trace in the sinogram. Taking account of
the fundamental difficulty in obtaining sufficient training data in a medical
environment, the learning method is designed to use simulated training data and
a patient-type specific learning model is used to simplify the learning
process. The feasibility of the proposed method is investigated using a
dataset, consisting of real CT scan of pelvises containing hip prostheses. The
anatomical areas in training and test data are different, in order to
demonstrate that the proposed method extracts the beam hardening features,
selectively. The results show that our method successfully corrects sinogram
inconsistency by extracting beam-hardening sources by means of deep learning.
This paper proposed a deep learning method of sinogram correction for beam
hardening reduction in CT for the first time. Conventional methods for beam
hardening reduction are based on regularizations, and have the fundamental
drawback of being not easily able to use manifold CT images, while a deep
learning approach has the potential to do so.
</dc:description>
 <dc:description>Comment: 17 pages, 8 figures</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00611</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Targeting and Signaling in Ad Auctions</dc:title>
 <dc:creator>Badanidiyuru, Ashwinkumar</dc:creator>
 <dc:creator>Bhawalkar, Kshipra</dc:creator>
 <dc:creator>Xu, Haifeng</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Modern ad auctions allow advertisers to target more specific segments of the
user population. Unfortunately, this is not always in the best interest of the
ad platform. In this paper, we examine the following basic question in the
context of second-price ad auctions: how should an ad platform optimally reveal
information about the ad opportunity to the advertisers in order to maximize
revenue? We consider a model in which bidders' valuations depend on a random
state of the ad opportunity. Different from previous work, we focus on a more
practical, and challenging, situation where the space of possible realizations
of ad opportunities is extremely large. We thus focus on developing algorithms
whose running time is independent of the number of ad opportunity realizations.
  We examine the auctioneer's algorithmic question of designing the optimal
signaling scheme. When the auctioneer is restricted to send a public signal to
all bidders, we focus on a well-motivated Bayesian valuation setting in which
the auctioneer and bidders both have private information, and present two main
results: 1. we exhibit a characterization result regarding approximately
optimal schemes and prove that any constant-approximate public signaling scheme
must use exponentially many signals; 2. we present a &quot;simple&quot; public signaling
scheme that serves as a constant approximation under mild assumptions. We then
initiate an exploration on the power of being able to send different signals
privately to different bidders. Here we examine a basic setting where the
auctioneer knows bidders' valuations, and exhibit a polynomial-time private
scheme that extracts almost full surplus even in the worst Bayes Nash
equilibrium. This illustrates the surprising power of private signaling schemes
in extracting revenue.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00611</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00617</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stabilizer codes from modified symplectic form</dc:title>
 <dc:creator>Gandhi, Tejas</dc:creator>
 <dc:creator>Kurur, Piyush</dc:creator>
 <dc:creator>Mittal, Rajat</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Stabilizer codes form an important class of quantum error correcting codes
which have an elegant theory, efficient error detection, and many known
examples. Constructing stabilizer codes of length $n$ is equivalent to
constructing subspaces of $\mathbb{F}_p^n \times \mathbb{F}_p^n$ which are
&quot;isotropic&quot; under the symplectic bilinear form defined by $\left\langle
(\mathbf{a},\mathbf{b}),(\mathbf{c},\mathbf{d}) \right\rangle =
\mathbf{a}^{\mathrm{T}} \mathbf{d} - \mathbf{b}^{\mathrm{T}} \mathbf{c}$. As a
result, many, but not all, ideas from the theory of classical error correction
can be translated to quantum error correction. One of the main theoretical
contribution of this article is to study stabilizer codes starting with a
different symplectic form.
  In this paper, we concentrate on cyclic codes. Modifying the symplectic form
allows us to generalize the previous known construction for linear cyclic
stabilizer codes, and in the process, circumvent some of the Galois theoretic
no-go results proved there. More importantly, this tweak in the symplectic form
allows us to make use of well known error correcting algorithms for cyclic
codes to give efficient quantum error correcting algorithms. Cyclicity of error
correcting codes is a &quot;basis dependent&quot; property. Our codes are no more
&quot;cyclic&quot; when they are derived using the standard symplectic forms (if we
ignore the error correcting properties like distance, all such symplectic forms
can be converted to each other via a basis transformation). Hence this change
of perspective is crucial from the point of view of designing efficient
decoding algorithm for these family of codes. In this context, recall that for
general codes, efficient decoding algorithms do not exist if some widely
believed complexity theoretic assumptions are true.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00617</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00622</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Parameterized Complexity of Contraction to Generalization of
  Trees</dc:title>
 <dc:creator>Agrawal, Akanksha</dc:creator>
 <dc:creator>Saurabh, Saket</dc:creator>
 <dc:creator>Tale, Prafullkumar</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  For a family of graphs $\cal F$, the $\mathcal{F}$-Contraction problem takes
as an input a graph $G$ and an integer $k$, and the goal is to decide if there
exists $S \subseteq E(G)$ of size at most $k$ such that $G/S$ belongs to $\cal
F$. Here, $G/S$ is the graph obtained from $G$ by contracting all the edges in
$S$. Heggernes et al.~[Algorithmica (2014)] were the first to study edge
contraction problems in the realm of Parameterized Complexity. They studied
$\cal F$-Contraction when $\cal F$ is a simple family of graphs such as trees
and paths. In this paper, we study the $\mathcal{F}$-Contraction problem, where
$\cal F$ generalizes the family of trees. In particular, we define this
generalization in a &quot;parameterized way&quot;. Let $\mathbb{T}_\ell$ be the family of
graphs such that each graph in $\mathbb{T}_\ell$ can be made into a tree by
deleting at most $\ell$ edges. Thus, the problem we study is
$\mathbb{T}_\ell$-Contraction. We design an FPT algorithm for
$\mathbb{T}_\ell$-Contraction running in time
$\mathcal{O}((2\sqrt(\ell))^{\mathcal{O}(k + \ell)} \cdot n^{\mathcal{O}(1)})$.
Furthermore, we show that the problem does not admit a polynomial kernel when
parameterized by $k$. Inspired by the negative result for the kernelization, we
design a lossy kernel for $\mathbb{T}_\ell$-Contraction of size $
\mathcal{O}([k(k + 2\ell)] ^{(\lceil {\frac{\alpha}{\alpha-1}\rceil + 1)}})$.
</dc:description>
 <dc:description>Comment: Full version of paper appeared in IPEC 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00622</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00625</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Recurrent Generative Decoder for Abstractive Text Summarization</dc:title>
 <dc:creator>Li, Piji</dc:creator>
 <dc:creator>Lam, Wai</dc:creator>
 <dc:creator>Bing, Lidong</dc:creator>
 <dc:creator>Wang, Zihao</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We propose a new framework for abstractive text summarization based on a
sequence-to-sequence oriented encoder-decoder model equipped with a deep
recurrent generative decoder (DRGN).
  Latent structure information implied in the target summaries is learned based
on a recurrent latent random model for improving the summarization quality.
  Neural variational inference is employed to address the intractable posterior
inference for the recurrent latent variables.
  Abstractive summaries are generated based on both the generative latent
variables and the discriminative deterministic states.
  Extensive experiments on some benchmark datasets in different languages show
that DRGN achieves improvements over the state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 10 pages, EMNLP 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00625</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00630</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ProjectionNet: Learning Efficient On-Device Deep Networks Using Neural
  Projections</dc:title>
 <dc:creator>Ravi, Sujith</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deep neural networks have become ubiquitous for applications related to
visual recognition and language understanding tasks. However, it is often
prohibitive to use typical neural networks on devices like mobile phones or
smart watches since the model sizes are huge and cannot fit in the limited
memory available on such devices. While these devices could make use of machine
learning models running on high-performance data centers with CPUs or GPUs,
this is not feasible for many applications because data can be privacy
sensitive and inference needs to be performed directly &quot;on&quot; device.
  We introduce a new architecture for training compact neural networks using a
joint optimization framework. At its core lies a novel objective that jointly
trains using two different types of networks--a full trainer neural network
(using existing architectures like Feed-forward NNs or LSTM RNNs) combined with
a simpler &quot;projection&quot; network that leverages random projections to transform
inputs or intermediate representations into bits. The simpler network encodes
lightweight and efficient-to-compute operations in bit space with a low memory
footprint. The two networks are trained jointly using backpropagation, where
the projection network learns from the full network similar to apprenticeship
learning. Once trained, the smaller network can be used directly for inference
at low memory and computation cost. We demonstrate the effectiveness of the new
approach at significantly shrinking the memory requirements of different types
of neural networks while preserving good accuracy on visual recognition and
text classification tasks. We also study the question &quot;how many neural bits are
required to solve a given task?&quot; using the new framework and show empirical
results contrasting model predictive capacity (in bits) versus accuracy on
several datasets.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00630</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00631</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Importance of Consistency in Training Deep Neural Networks</dc:title>
 <dc:creator>Ye, Chengxi</dc:creator>
 <dc:creator>Yang, Yezhou</dc:creator>
 <dc:creator>Fermuller, Cornelia</dc:creator>
 <dc:creator>Aloimonos, Yiannis</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We explain that the difficulties of training deep neural networks come from a
syndrome of three consistency issues. This paper describes our efforts in their
analysis and treatment. The first issue is the training speed inconsistency in
different layers. We propose to address it with an intuitive,
simple-to-implement, low footprint second-order method. The second issue is the
scale inconsistency between the layer inputs and the layer residuals. We
explain how second-order information provides favorable convenience in removing
this roadblock. The third and most challenging issue is the inconsistency in
residual propagation. Based on the fundamental theorem of linear algebra, we
provide a mathematical characterization of the famous vanishing gradient
problem. Thus, an important design principle for future optimization and neural
network design is derived. We conclude this paper with the construction of a
novel contractive neural network.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00631</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00634</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual-Glance Model for Deciphering Social Relationships</dc:title>
 <dc:creator>Li, Junnan</dc:creator>
 <dc:creator>Wong, Yongkang</dc:creator>
 <dc:creator>Zhao, Qi</dc:creator>
 <dc:creator>Kankanhalli, Mohan S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Since the beginning of early civilizations, social relationships derived from
each individual fundamentally form the basis of social structure in our daily
life. In the computer vision literature, much progress has been made in scene
understanding, such as object detection and scene parsing. Recent research
focuses on the relationship between objects based on its functionality and
geometrical relations. In this work, we aim to study the problem of social
relationship recognition, in still images. We have proposed a dual-glance model
for social relationship recognition, where the first glance fixates at the
individual pair of interest and the second glance deploys attention mechanism
to explore contextual cues. We have also collected a new large scale People in
Social Context (PISC) dataset, which comprises of 22,670 images and 76,568
annotated samples from 9 types of social relationship. We provide benchmark
results on the PISC dataset, and qualitatively demonstrate the efficacy of the
proposed model.
</dc:description>
 <dc:description>Comment: IEEE International Conference on Computer Vision (ICCV), 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00634</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00635</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of LMS Filters for Estimation of Cyclostationary
  Signals</dc:title>
 <dc:creator>Shlezinger, Nir</dc:creator>
 <dc:creator>Todros, Koby</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The least mean-square (LMS) filter is one of the most common adaptive linear
estimation algorithms. In many practical scenarios, and particularly in digital
communications systems, the signal of interest (SOI) and the input signal are
jointly wide-sense cyclostationary. Previous works analyzing the performance of
LMS filters for this important case assume specific probability distributions
of the considered signals or specific models that relate the input signal and
the SOI. In this work, we provide a general transient and steady-state
performance analysis that is free of specific distributional or model
assumptions. We obtain conditions for convergence and derive analytical
expressions for the non-asymptotic and steady-state mean-squared error. The
accuracy of our analysis is demonstrated in simulation studies that correspond
to practical communications scenarios.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00635</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00636</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generation of High Dynamic Range Illumination from a Single Image for
  the Enhancement of Undesirably Illuminated Images</dc:title>
 <dc:creator>Park, Jae Sung</dc:creator>
 <dc:creator>Cho, Nam Ik</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  This paper presents an algorithm that enhances undesirably illuminated images
by generating and fusing multi-level illuminations from a single image.The
input image is first decomposed into illumination and reflectance components by
using an edge-preserving smoothing filter. Then the reflectance component is
scaled up to improve the image details in bright areas. The illumination
component is scaled up and down to generate several illumination images that
correspond to certain camera exposure values different from the original. The
virtual multi-exposure illuminations are blended into an enhanced illumination,
where we also propose a method to generate appropriate weight maps for the tone
fusion. Finally, an enhanced image is obtained by multiplying the equalized
illumination and enhanced reflectance. Experiments show that the proposed
algorithm produces visually pleasing output and also yields comparable
objective results to the conventional enhancement methods, while requiring
modest computational loads.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00639</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distinct Squares in Circular Words</dc:title>
 <dc:creator>Amit, Mika</dc:creator>
 <dc:creator>Gawrychowski, Pawe&#x142;</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  A circular word, or a necklace, is an equivalence class under conjugation of
a word. A fundamental question concerning regularities in standard words is
bounding the number of distinct squares in a word of length $n$. The famous
conjecture attributed to Fraenkel and Simpson is that there are at most $n$
such distinct squares, yet the best known upper bound is $1.84n$ by Deza et al.
[Discr. Appl. Math. 180, 52-69 (2015)]. We consider a natural generalization of
this question to circular words: how many distinct squares can there be in all
cyclic rotations of a word of length $n$? We prove an upper bound of $3.14n$.
This is complemented with an infinite family of words implying a lower bound of
$1.25n$.
</dc:description>
 <dc:description>Comment: to appear in SPIRE 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00651</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multi-Objective Learning to re-Rank Approach to Optimize Online
  Marketplaces for Multiple Stakeholders</dc:title>
 <dc:creator>Nguyen, Phong</dc:creator>
 <dc:creator>Dines, John</dc:creator>
 <dc:creator>Krasnodebski, Jan</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Multi-objective recommender systems address the difficult task of
recommending items that are relevant to multiple, possibly conflicting,
criteria. However these systems are most often designed to address the
objective of one single stakeholder, typically, in online commerce, the
consumers whose input and purchasing decisions ultimately determine the success
of the recommendation systems. In this work, we address the multi-objective,
multi-stakeholder, recommendation problem involving one or more objective(s)
per stakeholder. In addition to the consumer stakeholder, we also consider two
other stakeholders; the suppliers who provide the goods and services for sale
and the intermediary who is responsible for helping connect consumers to
suppliers via its recommendation algorithms. We analyze the multi-objective,
multi-stakeholder, problem from the point of view of the online marketplace
intermediary whose objective is to maximize its commission through its
recommender system. We define a multi-objective problem relating all our three
stakeholders which we solve with a novel learning-to-re-rank approach that
makes use of a novel regularization function based on the Kendall tau
correlation metric and its kernel version; given an initial ranking of item
recommendations built for the consumer, we aim to re-rank it such that the new
ranking is also optimized for the secondary objectives while staying close to
the initial ranking. We evaluate our approach on a real-world dataset of hotel
recommendations provided by Expedia where we show the effectiveness of our
approach against a business-rules oriented baseline model.
</dc:description>
 <dc:description>Comment: Presented at the 2017 Workshop on Value-Aware and Multistakeholder
  Recommendation</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00665</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to Compute Modulo Prime-Power Sums ?</dc:title>
 <dc:creator>Heidari, Mohsen</dc:creator>
 <dc:creator>Shirani, Farhad</dc:creator>
 <dc:creator>Pradhan, Sandeep</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A new class of structured codes called Quasi Group Codes (QGC) is introduced.
A QGC is a subset of a group code. In contrast with group codes, QGCs are not
closed under group addition. The parameters of the QGC can be chosen such that
the size of $\mathcal{C}+\mathcal{C}$ is equal to any number between
$|\mathcal{C}|$ and $|\mathcal{C}|^2$ . We analyze the performance of a
specific class of QGCs. This class of QGCs is constructed by assigning
single-letter distributions to the indices of the codewords in a group code.
Then, the QGC is defined as the set of codewords whose index is in the typical
set corresponding to these single-letter distributions. The asymptotic
performance limits of this class of QGCs is characterized using single-letter
information quantities. Corresponding covering and packing bounds are derived.
It is shown that the point-to-point channel capacity and optimal
rate-distortion function are achievable using QGCs. Coding strategies based on
QGCs are introduced for three fundamental multi-terminal problems: the
K\&quot;orner-Marton problem for modulo prime-power sums, computation over the
multiple access channel (MAC), and MAC with distributed states. For each
problem a single-letter achievable rate-region is derived. It is shown, through
examples, that the coding strategies improve upon the previous strategies based
on unstructured codes, linear codes and group codes.
</dc:description>
 <dc:description>Comment: 52 pages, Submitted to IEEE Transaction on Information Theory</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00666</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Dynamic Graph LSTM for Action-driven Video Object Detection</dc:title>
 <dc:creator>Yuan, Yuan</dc:creator>
 <dc:creator>Liang, Xiaodan</dc:creator>
 <dc:creator>Wang, Xiaolong</dc:creator>
 <dc:creator>Yeung, Dit-Yan</dc:creator>
 <dc:creator>Gupta, Abhinav</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we investigate a weakly-supervised object detection framework.
Most existing frameworks focus on using static images to learn object
detectors. However, these detectors often fail to generalize to videos because
of the existing domain shift. Therefore, we investigate learning these
detectors directly from boring videos of daily activities. Instead of using
bounding boxes, we explore the use of action descriptions as supervision since
they are relatively easy to gather. A common issue, however, is that objects of
interest that are not involved in human actions are often absent in global
action descriptions known as &quot;missing label&quot;. To tackle this problem, we
propose a novel temporal dynamic graph Long Short-Term Memory network (TD-Graph
LSTM). TD-Graph LSTM enables global temporal reasoning by constructing a
dynamic graph that is based on temporal correlations of object proposals and
spans the entire video. The missing label issue for each individual frame can
thus be significantly alleviated by transferring knowledge across correlated
objects proposals in the whole video. Extensive evaluations on a large-scale
daily-life action dataset (i.e., Charades) demonstrates the superiority of our
proposed method. We also release object bounding-box annotations for more than
5,000 frames in Charades. We believe this annotated data can also benefit other
research on video-based object recognition in the future.
</dc:description>
 <dc:description>Comment: To appear in ICCV 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00667</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Reinforcement Learning for Inquiry Dialog Policies with Logical
  Formula Embeddings</dc:title>
 <dc:creator>Hiraoka, Takuya</dc:creator>
 <dc:creator>Tsuchida, Masaaki</dc:creator>
 <dc:creator>Watanabe, Yotaro</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper is the first attempt to learn the policy of an inquiry dialog
system (IDS) by using deep reinforcement learning (DRL). Most IDS frameworks
represent dialog states and dialog acts with logical formulae. In order to make
learning inquiry dialog policies more effective, we introduce a logical formula
embedding framework based on a recursive neural network. The results of
experiments to evaluate the effect of 1) the DRL and 2) the logical formula
embedding framework show that the combination of the two are as effective or
even better than existing rule-based methods for inquiry dialog policies.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00667</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00670</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Quantifying Knowledge Segregation in Society</dc:title>
 <dc:creator>Chakraborty, Abhijnan</dc:creator>
 <dc:creator>Ali, Muhammad</dc:creator>
 <dc:creator>Ghosh, Saptarshi</dc:creator>
 <dc:creator>Ganguly, Niloy</dc:creator>
 <dc:creator>Gummadi, Krishna P.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  With rapid increase in online information consumption, especially via social
media sites, there have been concerns on whether people are getting selective
exposure to a biased subset of the information space, where a user is receiving
more of what she already knows, and thereby potentially getting trapped in echo
chambers or filter bubbles. Even though such concerns are being debated for
some time, it is not clear how to quantify such echo chamber effect. In this
position paper, we introduce Information Segregation (or Informational
Segregation) measures, which follow the long lines of work on residential
segregation. We believe that information segregation nicely captures the notion
of exposure to different information by different population in a society, and
would help in quantifying the extent of social media sites offering selective
(or diverse) information to their users.
</dc:description>
 <dc:description>Comment: Accepted for publication in the proceedings of FATREC Workshop on
  Responsible Recommendation at RecSys 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00670</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00672</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Action recognition by learning pose representations</dc:title>
 <dc:creator>Saggese, Alessia</dc:creator>
 <dc:creator>Strisciuglio, Nicola</dc:creator>
 <dc:creator>Vento, Mario</dc:creator>
 <dc:creator>Petkov, Nicolai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Pose detection is one of the fundamental steps for the recognition of human
actions. In this paper we propose a novel trainable detector for recognizing
human poses based on the analysis of the skeleton. The main idea is that a
skeleton pose can be described by the spatial arrangements of its joints.
Starting from this consideration, we propose a trainable pose detector, that
can be configured on a prototype skeleton in an automatic configuration
process. The result of the configuration is a model of the position of the
joints in the concerned skeleton. In the application phase, the joint positions
contained in the model are compared with the ones of their homologous joints in
the skeleton under test. The similarity of two skeletons is computed as a
combination of the position scores achieved by homologous joints. In this paper
we describe an action classification method based on the use of the proposed
trainable detectors to extract features from the skeletons. We performed
experiments on the publicly available MSDRA data set and the achieved results
confirm the effectiveness of the proposed approach.
</dc:description>
 <dc:description>Comment: Accepted at REACTS workshop (CAIP conference 2017)</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00672</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00674</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Detection of People and their Mobility Aids for a Hospital Robot</dc:title>
 <dc:creator>Vasquez, Andres</dc:creator>
 <dc:creator>Kollmitz, Marina</dc:creator>
 <dc:creator>Eitel, Andreas</dc:creator>
 <dc:creator>Burgard, Wolfram</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Robots operating in populated environments encounter many different types of
people, some of whom might have an advanced need for cautious interaction,
because of physical impairments or their advanced age. Robots therefore need to
recognize such advanced demands to provide appropriate assistance, guidance or
other forms of support. In this paper, we propose a depth-based perception
pipeline that estimates the position and velocity of people in the environment
and categorizes them according to the mobility aids they use: pedestrian,
person in wheelchair, person in a wheelchair with a person pushing them, person
with crutches and person using a walker. We present a fast region proposal
method that feeds a Region-based Convolutional Network (Fast R-CNN). With this,
we speed up the object detection process by a factor of seven compared to a
dense sliding window approach. We furthermore propose a probabilistic position,
velocity and class estimator to smooth the CNN's detections and account for
occlusions and misclassifications. In addition, we introduce a new hospital
dataset with over 17,000 annotated RGB-D images. Extensive experiments confirm
that our pipeline successfully keeps track of people and their mobility aids,
even in challenging situations with multiple people from different categories
and frequent occlusions. Videos of our experiments and the dataset are
available at http://www2.informatik.uni-freiburg.de/~kollmitz/MobilityAids
</dc:description>
 <dc:description>Comment: 7 pages, ECMR 2017, dataset and videos:
  http://www2.informatik.uni-freiburg.de/~kollmitz/MobilityAids/</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00675</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optical Target Tracking by Scheduled Range Measurements</dc:title>
 <dc:creator>Ferdowsi, Mohammad Hossein</dc:creator>
 <dc:creator>Sabzikar, Ebrahim</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, optical target tracking, by regular target bearing
measurements and target range in a lower and scheduled measurement rate is
considered. Variance of the target range estimation error is used as scheduling
criterion. For this purpose, target dynamic state vector in modified spherical
coordinates is stated in such a way that all target states be decoupled from
range-related target state. Target state dynamic equations in modified
spherical coordinates for nearly constant velocity, nearly constant
acceleration and coordinated turn rate kinematic models, are analytically
derived. For resulted state dynamic equations, a UKF-IMM filter with range
measurement scheduling is utilized as a tracking filter. It is shown that
target states are estimated properly and applied filter has high performance in
maneuvering target tracking.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00675</dc:identifier>
 <dc:identifier>Optical Engineering 54.4 (2015): 044101-044101</dc:identifier>
 <dc:identifier>doi:10.1117/1.OE.54.4.044101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00681</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximum-Area Quadrilateral in a Convex Polygon, Revisited</dc:title>
 <dc:creator>Keikha, Vahideh</dc:creator>
 <dc:creator>L&#xf6;ffler, Maarten</dc:creator>
 <dc:creator>Mohades, Ali</dc:creator>
 <dc:creator>Urhausen, J&#xe9;r&#xf4;me</dc:creator>
 <dc:creator>van der Hoog, Ivor</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  In this note we show by example that the algorithm presented in 1979 by
Dobkin and Snyder for finding the largest-area k-gon that is inscribed in a
convex polygon fails to find the optimal solution for k=4. This question, posed
by Keikha et al. where they showed that the Dobkin Snyder algorithm fails for
k=3.
</dc:description>
 <dc:description>Comment: 6 pages. arXiv admin note: substantial text overlap with
  arXiv:1705.11035</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00684</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OmniArt: Multi-task Deep Learning for Artistic Data Analysis</dc:title>
 <dc:creator>Strezoski, Gjorgji</dc:creator>
 <dc:creator>Worring, Marcel</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Vast amounts of artistic data is scattered on-line from both museums and art
applications. Collecting, processing and studying it with respect to all
accompanying attributes is an expensive process. With a motivation to speed up
and improve the quality of categorical analysis in the artistic domain, in this
paper we propose an efficient and accurate method for multi-task learning with
a shared representation applied in the artistic domain. We continue to show how
different multi-task configurations of our method behave on artistic data and
outperform handcrafted feature approaches as well as convolutional neural
networks. In addition to the method and analysis, we propose a challenge like
nature to the new aggregated data set with almost half a million samples and
structured meta-data to encourage further research and societal engagement.
</dc:description>
 <dc:description>Comment: 9 pages, 6 figures, 4 tables</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00699</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VLDL Satisfiability and Model Checking via Tree Automata</dc:title>
 <dc:creator>Weinert, Alexander</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  We present novel algorithms solving the satisfiability problem and the model
checking problem for Visibly Linear Dynamic Logic (VLDL) in asymptotically
optimal time via a reduction to the emptiness problem for tree automata with
B\&quot;uchi acceptance. Since VLDL allows for the specification of important
properties of recursive systems, this reduction enables the efficient analysis
of such systems.
  Furthermore, as the problem of tree automata emptiness is well-studied, this
reduction enables leveraging the mature algorithms and tools for that problem
in order to solve the satisfiability problem and the model checking problem for
VLDL.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00699</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00700</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Super-activating Quantum Memory with Entanglement</dc:title>
 <dc:creator>Guan, Ji</dc:creator>
 <dc:creator>Feng, Yuan</dc:creator>
 <dc:creator>Ying, Mingsheng</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Noiseless subsystems were proved to be an efficient and faithful approach to
preserve fragile information against decoherence in quantum information
processing and quantum computation. They were employed to design a general
(hybrid) quantum memory cell model that can store both quantum and classical
information. In this Letter, we find an interesting new phenomenon that the
purely classical memory cell can be super-activated to preserve quantum states,
whereas the null memory cell can only be super-activated to encode classical
information. Furthermore, necessary and sufficient conditions for this
phenomenon are discovered so that the super-activation can be easily checked by
examining certain eigenvalues of the quantum memory cell without computing the
noiseless subsystems explicitly. In particular, it is found that entangled and
separable stationary states are responsible for the super-activation of storing
quantum and classical information, respectively.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00700</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00707</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ELFI: Engine for Likelihood Free Inference</dc:title>
 <dc:creator>Lintusaari, Jarno</dc:creator>
 <dc:creator>Vuollekoski, Henri</dc:creator>
 <dc:creator>Kangasr&#xe4;&#xe4;si&#xf6;, Antti</dc:creator>
 <dc:creator>Skyt&#xe9;n, Kusti</dc:creator>
 <dc:creator>J&#xe4;rvenp&#xe4;&#xe4;, Marko</dc:creator>
 <dc:creator>Gutmann, Michael</dc:creator>
 <dc:creator>Vehtari, Aki</dc:creator>
 <dc:creator>Corander, Jukka</dc:creator>
 <dc:creator>Kaski, Samuel</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  The Engine for Likelihood-Free Inference (ELFI) is a Python software library
for performing likelihood-free inference (LFI). ELFI provides a convenient
syntax for specifying LFI models commonly composed of priors, simulators,
summaries, distances and other custom operations. These can be implemented in a
wide variety of languages. Separating the modelling task from the inference
makes it possible to use the same model with any of the available inference
methods without modifications. A central method implemented in ELFI is Bayesian
Optimization for Likelihood-Free Inference (BOLFI), which has recently been
shown to accelerate likelihood-free inference up to several orders of
magnitude. ELFI also has an inbuilt support for output data storing for reuse
and analysis, and supports parallelization of computation from multiple cores
up to a cluster environment. ELFI is designed to be extensible and provides
interfaces for widening its functionality. This makes addition of new inference
methods to ELFI straightforward and automatically compatible with the inbuilt
features.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00707</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00710</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accurate Lung Segmentation via Network-Wise Training of Convolutional
  Networks</dc:title>
 <dc:creator>Hwang, Sangheum</dc:creator>
 <dc:creator>Park, Sunggyun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce an accurate lung segmentation model for chest radiographs based
on deep convolutional neural networks. Our model is based on atrous
convolutional layers to increase the field-of-view of filters efficiently. To
improve segmentation performances further, we also propose a multi-stage
training strategy, network-wise training, which the current stage network is
fed with both input images and the outputs from pre-stage network. It is shown
that this strategy has an ability to reduce falsely predicted labels and
produce smooth boundaries of lung fields. We evaluate the proposed model on a
common benchmark dataset, JSRT, and achieve the state-of-the-art segmentation
performances with much fewer model parameters.
</dc:description>
 <dc:description>Comment: Accepted to the 3rd Workshop on Deep Learning in Medical Image
  Analysis (DLMIA 2017), MICCAI 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00712</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Data Selection for Neural Machine Translation</dc:title>
 <dc:creator>van der Wees, Marlies</dc:creator>
 <dc:creator>Bisazza, Arianna</dc:creator>
 <dc:creator>Monz, Christof</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Intelligent selection of training data has proven a successful technique to
simultaneously increase training efficiency and translation performance for
phrase-based machine translation (PBMT). With the recent increase in popularity
of neural machine translation (NMT), we explore in this paper to what extent
and how NMT can also benefit from data selection. While state-of-the-art data
selection (Axelrod et al., 2011) consistently performs well for PBMT, we show
that gains are substantially lower for NMT. Next, we introduce dynamic data
selection for NMT, a method in which we vary the selected subset of training
data between different training epochs. Our experiments show that the best
results are achieved when applying a technique we call gradual fine-tuning,
with improvements up to +2.6 BLEU over the original data selection approach and
up to +3.1 BLEU over a general baseline.
</dc:description>
 <dc:description>Comment: Accepted at EMNLP2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00720</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bifrost: a Python/C++ Framework for High-Throughput Stream Processing in
  Astronomy</dc:title>
 <dc:creator>Cranmer, Miles D.</dc:creator>
 <dc:creator>Barsdell, Benjamin R.</dc:creator>
 <dc:creator>Price, Danny C.</dc:creator>
 <dc:creator>Dowell, Jayce</dc:creator>
 <dc:creator>Garsden, Hugh</dc:creator>
 <dc:creator>Dike, Veronica</dc:creator>
 <dc:creator>Eftekhari, Tarraneh</dc:creator>
 <dc:creator>Hegedus, Alexander M.</dc:creator>
 <dc:creator>Malins, Joseph</dc:creator>
 <dc:creator>Obenberger, Kenneth S.</dc:creator>
 <dc:creator>Schinzel, Frank</dc:creator>
 <dc:creator>Stovall, Kevin</dc:creator>
 <dc:creator>Taylor, Gregory B.</dc:creator>
 <dc:creator>Greenhill, Lincoln J.</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Instrumentation and Detectors</dc:subject>
 <dc:description>  Radio astronomy observatories with high throughput back end instruments
require real-time data processing. While computing hardware continues to
advance rapidly, development of real-time processing pipelines remains
difficult and time-consuming, which can limit scientific productivity.
Motivated by this, we have developed Bifrost: an open-source software framework
for rapid pipeline development. Bifrost combines a high-level Python interface
with highly efficient reconfigurable data transport and a library of computing
blocks for CPU and GPU processing. The framework is generalizable, but
initially it emphasizes the needs of high-throughput radio astronomy pipelines,
such as the ability to process data buffers as if they were continuous streams,
the capacity to partition processing into distinct data sequences (e.g.,
separate observations), and the ability to extract specific intervals from
buffered data. Computing blocks in the library are designed for applications
such as interferometry, pulsar dedispersion and timing, and transient search
pipelines. We describe the design and implementation of the Bifrost framework
and demonstrate its use as the backbone in the correlation and beamforming back
end of the Long Wavelength Array station in the Sevilleta National Wildlife
Refuge, NM.
</dc:description>
 <dc:description>Comment: 25 pages, 13 figures, submitted to JAI. For the code, see
  https://github.com/ledatelescope/bifrost</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00720</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00726</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The University of Edinburgh's Neural MT Systems for WMT17</dc:title>
 <dc:creator>Sennrich, Rico</dc:creator>
 <dc:creator>Birch, Alexandra</dc:creator>
 <dc:creator>Currey, Anna</dc:creator>
 <dc:creator>Germann, Ulrich</dc:creator>
 <dc:creator>Haddow, Barry</dc:creator>
 <dc:creator>Heafield, Kenneth</dc:creator>
 <dc:creator>Barone, Antonio Valerio Miceli</dc:creator>
 <dc:creator>Williams, Philip</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper describes the University of Edinburgh's submissions to the WMT17
shared news translation and biomedical translation tasks. We participated in 12
translation directions for news, translating between English and Czech, German,
Latvian, Russian, Turkish and Chinese. For the biomedical task we submitted
systems for English to Czech, German, Polish and Romanian. Our systems are
neural machine translation systems trained with Nematus, an attentional
encoder-decoder. We follow our setup from last year and build BPE-based models
with parallel and back-translated monolingual training data. Novelties this
year include the use of deep architectures, layer normalization, and more
compact models due to weight tying and improvements in BPE segmentations. We
perform extensive ablative experiments, reporting on the effectivenes of layer
normalization, deep architectures, and different ensembling techniques.
</dc:description>
 <dc:description>Comment: WMT 2017 shared task track; for Bibtex, see
  http://homepages.inf.ed.ac.uk/rsennric/bib.html#uedin-nmt:2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00726</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00728</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal regulation of flow networks with transient constraints</dc:title>
 <dc:creator>Trip, Sebastian</dc:creator>
 <dc:creator>Scholten, Tjardo</dc:creator>
 <dc:creator>De Persis, Claudio</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper investigates the control of flow networks, where the control
objective is to regulate the measured output (e.g storage levels) towards a
desired value. We present a distributed controller that dynamically adjusts the
inputs and flows, to achieve output regulation in the presence of unknown
disturbances, while satisfying given input and flow constraints. Optimal
coordination among the inputs, minimizing a suitable cost function, is achieved
by exchanging information over a communication network. Exploiting an
incremental passivity property, the desired steady state is proven to be
globally asymptotically attractive under the closed loop dynamics. Two case
studies (a district heating system and a multi-terminal HVDC network) show the
effectiveness of the proposed solution.
</dc:description>
 <dc:description>Comment: 19 pages</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00728</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00730</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Helping AI to Play Hearthstone: AAIA'17 Data Mining Challenge</dc:title>
 <dc:creator>Janusz, Andrzej</dc:creator>
 <dc:creator>&#x15a;wiechowski, Maciej</dc:creator>
 <dc:creator>Tajmajer, Tomasz</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  This paper summarizes the AAIA'17 Data Mining Challenge: Helping AI to Play
Hearthstone which was held between March 23, and May 15, 2017 at the Knowledge
Pit platform. We briefly describe the scope and background of this competition
in the context of a more general project related to the development of an AI
engine for video games, called Grail. We also discuss the outcomes of this
challenge and demonstrate how predictive models for the assessment of player's
winning chances can be utilized in a construction of an intelligent agent for
playing Hearthstone. Finally, we show a few selected machine learning
approaches for modeling state and action values in Hearthstone. We provide
evaluation for a few promising solutions that may be used to create more
advanced types of agents, especially in conjunction with Monte Carlo Tree
Search algorithms.
</dc:description>
 <dc:description>Comment: Federated Conference on Computer Science and Information Systems,
  Prague (FedCSIS-2017) (Prague, Czech Republic)</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00733</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Piece Identification in Classical Piano Music Without Reference Scores</dc:title>
 <dc:creator>Arzt, Andreas</dc:creator>
 <dc:creator>Widmer, Gerhard</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In this paper we describe an approach to identify the name of a piece of
piano music, based on a short audio excerpt of a performance. Given only a
description of the pieces in text format (i.e. no score information is
provided), a reference database is automatically compiled by acquiring a number
of audio representations (performances of the pieces) from internet sources.
These are transcribed, preprocessed, and used to build a reference database via
a robust symbolic fingerprinting algorithm, which in turn is used to identify
new, incoming queries. The main challenge is the amount of noise that is
introduced into the identification process by the music transcription algorithm
and the automatic (but possibly suboptimal) choice of performances to represent
a piece in the reference database. In a number of experiments we show how to
improve the identification performance by increasing redundancy in the
reference database and by using a preprocessing step to rate the reference
performances regarding their suitability as a representation of the pieces in
question. As the results show this approach leads to a robust system that is
able to identify piano music with high accuracy -- without any need for data
annotation or manual data preparation.
</dc:description>
 <dc:description>Comment: In Proceedings of the 18th International Society for Music
  Information Retrieval Conference (ISMIR 2017)</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00733</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00739</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for Frequency Stability Assessment of Future Power Systems:
  An Australian Case Study</dc:title>
 <dc:creator>Ahmadyar, Ahmad Shabir</dc:creator>
 <dc:creator>Riaz, Shariq</dc:creator>
 <dc:creator>Verbic, Gregor</dc:creator>
 <dc:creator>Chapman, Archie</dc:creator>
 <dc:creator>Hill, David J.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The increasing penetration of non-synchronous renewable energy sources
(NS-RES) alters the dynamic characteristic, and consequently, the frequency
behaviour of a power system. To accurately identify these changing trends and
address them in a systematic way, it is necessary to assess a large number of
scenarios. Given this, we propose a frequency stability assessment framework
based on a time-series approach that facilitates the analysis of a large number
of future power system scenarios. We use this framework to assess the frequency
stability of the Australian future power system by considering a large number
of future scenarios and sensitivity of different parameters. By doing this, we
identify a maximum non-synchronous instantaneous penetration range from the
frequency stability point of view. Further, to reduce the detrimental impacts
of high NS-RES penetration on system frequency stability, a dynamic inertia
constraint is derived and incorporated in the market dispatch model. The
results show that such a constraint guarantees frequency stability of the
system for all credible contingencies. Also, we assess and quantify the
contribution of synchronous condensers, synthetic inertia of wind farms and a
governor-like response from de-loaded wind farms on system frequency stability.
The results show that the last option is the most effective one.
</dc:description>
 <dc:description>Comment: This paper is uploaded here just for reference. It is not published
  yet</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00739</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00741</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relat\'orio T\'ecnico: Controle Distribu\'ido de Tr\'afego Baseado em
  Ve\'iculos Conectados e Comunica\c{c}\~oes Veiculares Centradas em Interesses</dc:title>
 <dc:creator>Gon&#xe7;alves, Fabr&#xed;cio Barros</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Although advanced traffic management systems can deal with the heterogeneous
traffic flows approaching of intersections, their performances are compromised,
when the traffic volume is not distributed uniformly. To evenly distribute the
traffic flow, an advanced driver information system should be aware of the
traffic control operations. However, such requirement can not ultimately be
satisfied due to the gaps in state of the art in advanced traffic management
systems. Therefore, this study proposes a distributed traffic control system,
in which agents embedded in connected vehicles, traffic signals, urban elements
and a traffic control center interact with each other to provide a greater
traffic fluidity. Therefore, the agents depend strongly on a heterogeneous
vehicular network. In this sense, this study also proposes a heterogeneous
vehicular network whose communication protocol can satisfy the communication
requirements of intelligent transportation systems service applications.
According to the results obtained from simulations, the distributed traffic
control system was able to maximize the flow of vehicles and the mean speed of
the vehicles, and minimize the wait time, travel time, fuel consume and
emissions (CO, CO$_2$, HC, NOx and PMx).
</dc:description>
 <dc:description>Comment: in Portuguese</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00741</dc:identifier>
 <dc:language>pt</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00742</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multipair Massive MIMO Two-Way Full-Duplex Relay Systems with Hardware
  Impairments</dc:title>
 <dc:creator>Liu, Ying</dc:creator>
 <dc:creator>Xue, Xipeng</dc:creator>
 <dc:creator>Zhang, Jiayi</dc:creator>
 <dc:creator>Li, Xu</dc:creator>
 <dc:creator>Dai, Linglong</dc:creator>
 <dc:creator>Jin, Shi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Hardware impairments, such as phase noise, quantization errors,
non-linearities, and noise amplification, have baneful effects on wireless
communications. In this paper, we investigate the effect of hardware
impairments on multipair massive multiple-input multiple-output (MIMO) two-way
full-duplex relay systems with amplify-and-forward scheme. More specifically,
novel closed-form approximate expressions for the spectral efficiency are
derived to obtain some important insights into the practical design of the
considered system. When the number of relay antennas $N$ increases without
bound, we propose a hardware scaling law, which reveals that the level of
hardware impairments that can be tolerated is roughly proportional to
$\sqrt{N}$. This new result inspires us to design low-cost and practical
multipair massive MIMO two-way full-duplex relay systems. Moreover, the optimal
number of relay antennas is derived to maximize the energy efficiency. Finally,
Motor-Carlo simulation results are provided to validate our analytical results.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, accepted by IEEE Globecom 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00743</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuous Average Straightness in Spatial Graphs</dc:title>
 <dc:creator>Labatut, Vincent</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  The Straightness is a measure designed to characterize a pair of vertices in
a spatial graph. It is defined as the ratio of the Euclidean distance to the
graph distance between these vertices. It is often used as an average, for
instance to describe the accessibility of a single vertex relatively to all the
other vertices in the graph, or even to summarize the graph as a whole. In some
cases, one needs to process the Straightness between not only vertices, but
also any other points constituting the graph of interest. Suppose for instance
that our graph represents a road network and we do not want to limit ourselves
to crossroad-to-crossroad itineraries, but allow any street number to be a
starting point or destination. In this situation, the standard approach
consists in: 1) discretizing the graph edges, 2) processing the
vertex-to-vertex Straightness considering the additional vertices resulting
from this discretization, and 3) performing the appropriate average on the
obtained values. However, this discrete approximation can be computationally
expensive on large graphs, and its precision has not been clearly assessed. In
this article, we adopt a continuous approach to average the Straightness over
the edges of spatial graphs. This allows us to derive 5 distinct measures able
to characterize precisely the accessibility of the whole graph, as well as
individual vertices and edges. Our method is generic and could be applied to
other measures designed for spatial graphs. We perform an experimental
evaluation of our continuous average Straightness measures, and show how they
behave differently from the traditional vertex-to-vertex ones. Moreover, we
also study their discrete approximations, and show that our approach is
globally less demanding in terms of both processing time and memory usage. Our
R source code is publicly available under an open source license.
</dc:description>
 <dc:description>Comment: Journal of Complex Networks, Oxford, 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00743</dc:identifier>
 <dc:identifier>doi:10.1093/comnet/cnx033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00745</identifier>
 <datestamp>2017-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Inversion of Multiple-Scattering Model for Optical Diffraction
  Tomography</dc:title>
 <dc:creator>Soubies, Emmanuel</dc:creator>
 <dc:creator>Pham, Thanh-An</dc:creator>
 <dc:creator>Unser, Michael</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:description>  Optical diffraction tomography relies on solving an inverse scattering
problem governed by the wave equation. Classical reconstruction algorithms are
based on linear approximations of the forward model (Born or Rytov), which
limits their applicability to thin samples with low refractive-index contrasts.
More recent works have shown the benefit of adopting nonlinear models. They
account for multiple scattering and reflections, improving the quality of
reconstruction. To reduce the complexity and memory requirements of these
methods, we derive an explicit formula for the Jacobian matrix of the nonlinear
Lippmann-Schwinger model which lends itself to an efficient evaluation of the
gradient of the data- fidelity term. This allows us to deploy efficient methods
to solve the corresponding inverse problem subject to sparsity constraints.
</dc:description>
 <dc:date>2017-07-11</dc:date>
 <dc:date>2017-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00745</dc:identifier>
 <dc:identifier>Opt. Express 25, 21786-21800 (2017)</dc:identifier>
 <dc:identifier>doi:10.1364/OE.25.021786</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00747</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feasibility Study of Enabling V2X Communications by LTE-Uu Radio
  Interface</dc:title>
 <dc:creator>Lianghai, Ji</dc:creator>
 <dc:creator>Weinand, Andreas</dc:creator>
 <dc:creator>Han, Bin</dc:creator>
 <dc:creator>Schotten, Hans D.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Compared with the legacy wireless networks, the next generation of wireless
network targets at different services with divergent QoS requirements, ranging
from bandwidth consuming video service to moderate and low date rate machine
type services, and supporting as well as strict latency requirements. One
emerging new service is to exploit wireless network to improve the efficiency
of vehicular traffic and public safety. However, the stringent packet
end-to-end (E2E) latency and ultra-low transmission failure rates pose
challenging requirements on the legacy networks. In other words, the next
generation wireless network needs to support ultra-reliable low latency
communications (URLLC) involving new key performance indicators (KPIs) rather
than the conventional metric, such as cell throughput in the legacy systems. In
this paper, a feasibility study on applying today's LTE network infrastructure
and LTE-Uu air interface to provide the URLLC type of services is performed,
where the communication takes place between two traffic participants (e.g.,
vehicle-to-vehicle and vehicle-to-pedestrian). To carry out this study, an
evaluation methodology of the cellular vehicle-to-anything (V2X) communication
is proposed, where packet E2E latency and successful transmission rate are
considered as the key performance indicators (KPIs). Then, we describe the
simulation assumptions for the evaluation. Based on them, simulation results
are depicted that demonstrate the performance of the LTE network in fulfilling
new URLLC requirements. Moreover, sensitivity analysis is also conducted
regarding how to further improve system performance, in order to enable new
emerging URLLC services.
</dc:description>
 <dc:description>Comment: Accepted by IEEE/CIC ICCC 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00754</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fairness-aware machine learning: a perspective</dc:title>
 <dc:creator>Zliobaite, Indre</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Algorithms learned from data are increasingly used for deciding many aspects
in our life: from movies we see, to prices we pay, or medicine we get. Yet
there is growing evidence that decision making by inappropriately trained
algorithms may unintentionally discriminate people. For example, in automated
matching of candidate CVs with job descriptions, algorithms may capture and
propagate ethnicity related biases. Several repairs for selected algorithms
have already been proposed, but the underlying mechanisms how such
discrimination happens from the computational perspective are not yet
scientifically understood. We need to develop theoretical understanding how
algorithms may become discriminatory, and establish fundamental machine
learning principles for prevention. We need to analyze machine learning process
as a whole to systematically explain the roots of discrimination occurrence,
which will allow to devise global machine learning optimization criteria for
guaranteed prevention, as opposed to pushing empirical constraints into
existing algorithms case-by-case. As a result, the state-of-the-art will
advance from heuristic repairing, to proactive and theoretically supported
prevention. This is needed not only because law requires to protect vulnerable
people. Penetration of big data initiatives will only increase, and computer
science needs to provide solid explanations and accountability to the public,
before public concerns lead to unnecessarily restrictive regulations against
machine learning.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00758</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact values for three domination-like problems in circular and infinite
  grid graphs of small height</dc:title>
 <dc:creator>Bouznif, Marwane</dc:creator>
 <dc:creator>Darlay, Julien</dc:creator>
 <dc:creator>Moncel, Julien</dc:creator>
 <dc:creator>Preissmann, Myriam</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  In this paper we study three domination-like problems, namely identifying
codes, locating-dominating codes, and locating-total-dominating codes. We are
interested in finding the minimum cardinality of such codes in circular and
infinite grid graphs of given height. We provide an alternate proof for already
known results, as well as new results. These were obtained by a computer search
based on a generic framework, that we developed earlier, for the search of a
minimum labeling satisfying a pseudo-d-local property in rotagraphs.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00758</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00759</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Population Density-based Hospital Recommendation with Mobile LBS Big
  Data</dc:title>
 <dc:creator>Chao, Hanqing</dc:creator>
 <dc:creator>Cao, Yuan</dc:creator>
 <dc:creator>Zhang, Junping</dc:creator>
 <dc:creator>Xia, Fen</dc:creator>
 <dc:creator>Zhou, Ye</dc:creator>
 <dc:creator>Shan, Hongming</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The difficulty of getting medical treatment is one of major livelihood issues
in China. Since patients lack prior knowledge about the spatial distribution
and the capacity of hospitals, some hospitals have abnormally high or sporadic
population densities. This paper presents a new model for estimating the
spatiotemporal population density in each hospital based on location-based
service (LBS) big data, which would be beneficial to guiding and dispersing
outpatients. To improve the estimation accuracy, several approaches are
proposed to denoise the LBS data and classify people by detecting their various
behaviors. In addition, a long short-term memory (LSTM) based deep learning is
presented to predict the trend of population density. By using Baidu
large-scale LBS logs database, we apply the proposed model to 113 hospitals in
Beijing, P. R. China, and constructed an online hospital recommendation system
which can provide users with a hospital rank list basing the real-time
population density information and the hospitals' basic information such as
hospitals' levels and their distances. We also mine several interesting
patterns from these LBS logs by using our proposed system.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00759</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00768</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Streaming kernel regression with provably adaptive mean, variance, and
  regularization</dc:title>
 <dc:creator>Durand, Audrey</dc:creator>
 <dc:creator>Maillard, Odalric-Ambrym</dc:creator>
 <dc:creator>Pineau, Joelle</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the problem of streaming kernel regression, when the observations
arrive sequentially and the goal is to recover the underlying mean function,
assumed to belong to an RKHS. The variance of the noise is not assumed to be
known. In this context, we tackle the problem of tuning the regularization
parameter adaptively at each time step, while maintaining tight confidence
bounds estimates on the value of the mean function at each point. To this end,
we first generalize existing results for finite-dimensional linear regression
with fixed regularization and known variance to the kernel setup with a
regularization parameter allowed to be a measurable function of past
observations. Then, using appropriate self-normalized inequalities we build
upper and lower bound estimates for the variance, leading to Bersntein-like
concentration bounds. The later is used in order to define the adaptive
regularization. The bounds resulting from our technique are valid uniformly
over all observation points and all time steps, and are compared against the
literature with numerical experiments. Finally, the potential of these tools is
illustrated by an application to kernelized bandits, where we revisit the
Kernel UCB and Kernel Thompson Sampling procedures, and show the benefits of
the novel adaptive kernel tuning strategy.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00768</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00774</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate solution of length-bounded maximum multicommodity flow with
  unit edge-lengths</dc:title>
 <dc:creator>Borisovsky, Pavel</dc:creator>
 <dc:creator>Eremeev, Anton</dc:creator>
 <dc:creator>Hrushev, Sergei</dc:creator>
 <dc:creator>Teplyakov, Vadim</dc:creator>
 <dc:creator>Vorozhtsov, Mikhail</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  An improved fully polynomial-time approximation scheme and a greedy heuristic
for the fractional length-bounded maximum multicommodity flow problem with unit
edge-lengths are proposed. Computational experiments are carried out on
benchmark graphs and on graphs that model software defined satellite networks
to compare the proposed algorithms and an exact linear programming solver. The
results of experiments demonstrate a trade-off between the computing time and
the precision of algorithms under consideration.
</dc:description>
 <dc:description>Comment: 17-th Baikal International Triannual School-Seminar &quot;Methods of
  Optimization and Their Applications&quot;</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00774</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00777</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Modeling Energy Consumption of Cloud Applications:
  Deconstruction, State of the Art, and Trade-off Debates</dc:title>
 <dc:creator>Li, Zheng</dc:creator>
 <dc:creator>Tesfatsion, Selome</dc:creator>
 <dc:creator>Bastani, Saeed</dc:creator>
 <dc:creator>Ali-Eldin, Ahmed</dc:creator>
 <dc:creator>Elmroth, Erik</dc:creator>
 <dc:creator>Kihl, Maria</dc:creator>
 <dc:creator>Ranjan, Rajiv</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Given the complexity and heterogeneity in Cloud computing scenarios, the
modeling approach has widely been employed to investigate and analyze the
energy consumption of Cloud applications, by abstracting real-world objects and
processes that are difficult to observe or understand directly. It is clear
that the abstraction sacrifices, and usually does not need, the complete
reflection of the reality to be modeled. Consequently, current energy
consumption models vary in terms of purposes, assumptions, application
characteristics and environmental conditions, with possible overlaps between
different research works. Therefore, it would be necessary and valuable to
reveal the state-of-the-art of the existing modeling efforts, so as to weave
different models together to facilitate comprehending and further investigating
application energy consumption in the Cloud domain. By systematically
selecting, assessing and synthesizing 76 relevant studies, we rationalized and
organized over 30 energy consumption models with unified notations. To help
investigate the existing models and facilitate future modeling work, we
deconstructed the runtime execution and deployment environment of Cloud
applications, and identified 18 environmental factors and 12 workload factors
that would be influential on the energy consumption. In particular, there are
complicated trade-offs and even debates when dealing with the combinational
impacts of multiple factors.
</dc:description>
 <dc:description>Comment: in press</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00777</dc:identifier>
 <dc:identifier>IEEE Transactions on Sustainable Computing, 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TSUSC.2017.2722822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00781</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Entity Representations in Neural Language Models</dc:title>
 <dc:creator>Ji, Yangfeng</dc:creator>
 <dc:creator>Tan, Chenhao</dc:creator>
 <dc:creator>Martschat, Sebastian</dc:creator>
 <dc:creator>Choi, Yejin</dc:creator>
 <dc:creator>Smith, Noah A.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Understanding a long document requires tracking how entities are introduced
and evolve over time. We present a new type of language model, EntityNLM, that
can explicitly model entities, dynamically update their representations, and
contextually generate their mentions. Our model is generative and flexible; it
can model an arbitrary number of entities in context while generating each
entity mention at an arbitrary length. In addition, it can be used for several
different tasks such as language modeling, coreference resolution, and entity
prediction. Experimental results with all these tasks demonstrate that our
model consistently outperforms strong baselines and prior work.
</dc:description>
 <dc:description>Comment: EMNLP 2017 camera-ready version</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00781</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00783</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>InfiniTAM v3: A Framework for Large-Scale 3D Reconstruction with Loop
  Closure</dc:title>
 <dc:creator>Prisacariu, Victor Adrian</dc:creator>
 <dc:creator>K&#xe4;hler, Olaf</dc:creator>
 <dc:creator>Golodetz, Stuart</dc:creator>
 <dc:creator>Sapienza, Michael</dc:creator>
 <dc:creator>Cavallari, Tommaso</dc:creator>
 <dc:creator>Torr, Philip H S</dc:creator>
 <dc:creator>Murray, David W</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Volumetric models have become a popular representation for 3D scenes in
recent years. One breakthrough leading to their popularity was KinectFusion,
which focuses on 3D reconstruction using RGB-D sensors. However, monocular SLAM
has since also been tackled with very similar approaches. Representing the
reconstruction volumetrically as a TSDF leads to most of the simplicity and
efficiency that can be achieved with GPU implementations of these systems.
However, this representation is memory-intensive and limits applicability to
small-scale reconstructions. Several avenues have been explored to overcome
this. With the aim of summarizing them and providing for a fast, flexible 3D
reconstruction pipeline, we propose a new, unifying framework called InfiniTAM.
The idea is that steps like camera tracking, scene representation and
integration of new data can easily be replaced and adapted to the user's needs.
  This report describes the technical implementation details of InfiniTAM v3,
the third version of our InfiniTAM system. We have added various new features,
as well as making numerous enhancements to the low-level code that
significantly improve our camera tracking performance. The new features that we
expect to be of most interest are (i) a robust camera tracking module; (ii) an
implementation of Glocker et al.'s keyframe-based random ferns camera
relocaliser; (iii) a novel approach to globally-consistent TSDF-based
reconstruction, based on dividing the scene into rigid submaps and optimising
the relative poses between them; and (iv) an implementation of Keller et al.'s
surfel-based reconstruction approach.
</dc:description>
 <dc:description>Comment: This article largely supersedes arxiv:1410.0925 (it describes version
  3 of the InfiniTAM framework)</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00786</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structure-measure: A New Way to Evaluate Foreground Maps</dc:title>
 <dc:creator>Fan, Deng-Ping</dc:creator>
 <dc:creator>Cheng, Ming-Ming</dc:creator>
 <dc:creator>Liu, Yun</dc:creator>
 <dc:creator>Li, Tao</dc:creator>
 <dc:creator>Borji, Ali</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Foreground map evaluation is crucial for gauging the progress of object
segmentation algorithms, in particular in the filed of salient object detection
where the purpose is to accurately detect and segment the most salient object
in a scene. Several widely-used measures such as Area Under the Curve (AUC),
Average Precision (AP) and the recently proposed Fbw have been utilized to
evaluate the similarity between a non-binary saliency map (SM) and a
ground-truth (GT) map. These measures are based on pixel-wise errors and often
ignore the structural similarities. Behavioral vision studies, however, have
shown that the human visual system is highly sensitive to structures in scenes.
Here, we propose a novel, efficient, and easy to calculate measure known an
structural similarity measure (Structure-measure) to evaluate non-binary
foreground maps. Our new measure simultaneously evaluates region-aware and
object-aware structural similarity between a SM and a GT map. We demonstrate
superiority of our measure over existing ones using 5 meta-measures on 5
benchmark datasets.
</dc:description>
 <dc:description>Comment: Accepted by ICCV 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00786</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00790</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Generative and Discriminative Approaches to Unsupervised
  Dependency Parsing via Dual Decomposition</dc:title>
 <dc:creator>Jiang, Yong</dc:creator>
 <dc:creator>Han, Wenjuan</dc:creator>
 <dc:creator>Tu, Kewei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Unsupervised dependency parsing aims to learn a dependency parser from
unannotated sentences. Existing work focuses on either learning generative
models using the expectation-maximization algorithm and its variants, or
learning discriminative models using the discriminative clustering algorithm.
In this paper, we propose a new learning strategy that learns a generative
model and a discriminative model jointly based on the dual decomposition
method. Our method is simple and general, yet effective to capture the
advantages of both models and improve their learning results. We tested our
method on the UD treebank and achieved a state-of-the-art performance on thirty
languages.
</dc:description>
 <dc:description>Comment: In EMNLP 2017. A typo fixed in Algo 2</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:date>2017-09-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00790</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00801</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dependency Grammar Induction with Neural Lexicalization and Big Training
  Data</dc:title>
 <dc:creator>Han, Wenjuan</dc:creator>
 <dc:creator>Jiang, Yong</dc:creator>
 <dc:creator>Tu, Kewei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We study the impact of big models (in terms of the degree of lexicalization)
and big data (in terms of the training corpus size) on dependency grammar
induction. We experimented with L-DMV, a lexicalized version of Dependency
Model with Valence and L-NDMV, our lexicalized extension of the Neural
Dependency Model with Valence. We find that L-DMV only benefits from very small
degrees of lexicalization and moderate sizes of training corpora. L-NDMV can
benefit from big training data and lexicalization of greater degrees,
especially when enhanced with good model initialization, and it achieves a
result that is competitive with the current state-of-the-art.
</dc:description>
 <dc:description>Comment: EMNLP 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00801</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00805</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Generative Stochastic Networks with Collaborative Shaping</dc:title>
 <dc:creator>Bachman, Philip</dc:creator>
 <dc:creator>Precup, Doina</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We develop an approach to training generative models based on unrolling a
variational auto-encoder into a Markov chain, and shaping the chain's
trajectories using a technique inspired by recent work in Approximate Bayesian
computation. We show that the global minimizer of the resulting objective is
achieved when the generative model reproduces the target distribution. To allow
finer control over the behavior of the models, we add a regularization term
inspired by techniques used for regularizing certain types of policy search in
reinforcement learning. We present empirical results on the MNIST and TFD
datasets which show that our approach offers state-of-the-art performance, both
quantitatively and from a qualitative point of view.
</dc:description>
 <dc:description>Comment: Old paper, from ICML 2015</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00807</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial-Playground: A Visualization Suite Showing How Adversarial
  Examples Fool Deep Learning</dc:title>
 <dc:creator>Norton, Andrew P.</dc:creator>
 <dc:creator>Qi, Yanjun</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.6, K.6.5</dc:subject>
 <dc:description>  Recent studies have shown that attackers can force deep learning models to
misclassify so-called &quot;adversarial examples&quot;: maliciously generated images
formed by making imperceptible modifications to pixel values. With growing
interest in deep learning for security applications, it is important for
security experts and users of machine learning to recognize how learning
systems may be attacked. Due to the complex nature of deep learning, it is
challenging to understand how deep models can be fooled by adversarial
examples. Thus, we present a web-based visualization tool,
Adversarial-Playground, to demonstrate the efficacy of common adversarial
methods against a convolutional neural network (CNN) system.
Adversarial-Playground is educational, modular and interactive. (1) It enables
non-experts to compare examples visually and to understand why an adversarial
example can fool a CNN-based image classifier. (2) It can help security experts
explore more vulnerability of deep learning as a software module. (3) Building
an interactive visualization is challenging in this domain due to the large
feature space of image classification (generating adversarial examples is slow
in general and visualizing images are costly). Through multiple novel design
choices, our tool can provide fast and accurate responses to user requests.
Empirically, we find that our client-server division strategy reduced the
response time by an average of 1.5 seconds per sample. Our other innovation, a
faster variant of JSMA evasion algorithm, empirically performed twice as fast
as JSMA and yet maintains a comparable evasion rate.
  Project source code and data from our experiments available at:
https://github.com/QData/AdversarialDNN-Playground
</dc:description>
 <dc:description>Comment: 5 pages. {I.2.6}{Artificial Intelligence} ; {K.6.5}{Management of
  Computing and Information Systems}{Security and Protection}. arXiv admin
  note: substantial text overlap with arXiv:1706.01763</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00812</identifier>
 <datestamp>2017-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predictive Coding for Dynamic Visual Processing: Development of
  Functional Hierarchy in a Multiple Spatio-Temporal Scales RNN Model</dc:title>
 <dc:creator>Choi, Minkyu</dc:creator>
 <dc:creator>Tani, Jun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The current paper proposes a novel predictive coding type neural network
model, the predictive multiple spatio-temporal scales recurrent neural network
(P-MSTRNN). The P-MSTRNN learns to predict visually perceived human whole-body
cyclic movement patterns by exploiting multiscale spatio-temporal constraints
imposed on network dynamics by using differently sized receptive fields as well
as different time constant values for each layer. After learning, the network
becomes able to proactively imitate target movement patterns by inferring or
recognizing corresponding intentions by means of the regression of prediction
error. Results show that the network can develop a functional hierarchy by
developing a different type of dynamic structure at each layer. The paper
examines how model performance during pattern generation as well as predictive
imitation varies depending on the stage of learning. The number of limit cycle
attractors corresponding to target movement patterns increases as learning
proceeds. And, transient dynamics developing early in the learning process
successfully perform pattern generation and predictive imitation tasks. The
paper concludes that exploitation of transient dynamics facilitates successful
task performance during early learning periods.
</dc:description>
 <dc:description>Comment: Accepted in Neural Computation (MIT press)</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:date>2017-09-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00812</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00813</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Land Cover Classification from Multi-temporal, Multi-spectral Remotely
  Sensed Imagery using Patch-Based Recurrent Neural Networks</dc:title>
 <dc:creator>Sharma, Atharva</dc:creator>
 <dc:creator>Liu, Xiuwen</dc:creator>
 <dc:creator>Yang, Xiaojun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Sustainability of the global environment is dependent on the accurate land
cover information over large areas. Even with the increased number of satellite
systems and sensors acquiring data with improved spectral, spatial, radiometric
and temporal characteristics and the new data distribution policy, most
existing land cover datasets were derived from a pixel-based single-date
multi-spectral remotely sensed image with low accuracy. To improve the
accuracy, the bottleneck is how to develop an accurate and effective image
classification technique. By incorporating and utilizing the complete
multi-spectral, multi-temporal and spatial information in remote sensing images
and considering their inherit spatial and sequential interdependence, we
propose a new patch-based RNN (PB-RNN) system tailored for multi-temporal
remote sensing data. The system is designed by incorporating distinctive
characteristics in multi-temporal remote sensing data. In particular, it uses
multi-temporal-spectral-spatial samples and deals with pixels contaminated by
clouds/shadow present in the multi-temporal data series. Using a Florida
Everglades ecosystem study site covering an area of 771 square kilo-meters, the
proposed PB-RNN system has achieved a significant improvement in the
classification accuracy over pixel-based RNN system, pixel-based single-imagery
NN system, pixel-based multi-images NN system, patch-based single-imagery NN
system and patch-based multi-images NN system. For example, the proposed system
achieves 97.21% classification accuracy while a pixel-based single-imagery NN
system achieves 64.74%. By utilizing methods like the proposed PB-RNN one, we
believe that much more accurate land cover datasets can be produced over large
areas efficiently.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00814</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Time-Space Trade-offs for Computing Voronoi Diagrams</dc:title>
 <dc:creator>Banyassady, Bahareh</dc:creator>
 <dc:creator>Korman, Matias</dc:creator>
 <dc:creator>Mulzer, Wolfgang</dc:creator>
 <dc:creator>van Renssen, Andr&#xe9;</dc:creator>
 <dc:creator>Roeloffzen, Marcel</dc:creator>
 <dc:creator>Seiferth, Paul</dc:creator>
 <dc:creator>Stein, Yannik</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Let $P$ be a planar set of $n$ sites in general position. For $k\in
\{1,\dots,n-1\}$, the Voronoi diagram of order $k$} for $P$ is obtained by
subdividing the plane into cells such that points in the same cell have the
same set of nearest $k$ neighbors in $P$. The nearest site Voronoi diagram
(NVD) and the farthest site Voronoi diagram (FVD) are the particular cases of
$k=1$ and $k=n-1$, respectively. For any given $K\in \{1,\dots,n-1\}$, the
family of all higher-order Voronoi diagrams of order $k = 1, \dots, K$ for $P$
can be computed in total time $O(nK^2+ n\log n)$ using $O(K^2(n-K))$ space
[Aggarwal et al., DCG'89; Lee, TC'82]. Moreover, NVD($P$) and FVD($P$) can be
computed in $O(n\log n)$ time using $O(n)$ space [Preparata, Shamos,
Springer'85].
  For $s\in \{1,\dots,n\}$, an $s$-workspace algorithm has random access to a
read-only array with the sites of $P$ in arbitrary order. Additionally, the
algorithm may use $O(s)$ words, of $\Theta(\log n)$ bits each, for reading and
writing intermediate data. The output can be written only once and cannot be
accessed or modified afterwards.
  We describe a deterministic $s$-workspace algorithm for computing NVD($P$)
and FVD($P$) that runs in $O((n^2/s)\log s)$ time. Moreover, we generalize our
$s$-workspace algorithm so that for any given $K\in \{1,\dots,O(\sqrt{s})\}$,
we can compute the family of all higher-order Voronoi diagrams of order $k = 1,
\dots, K$ for $P$ in total time $O\bigl(\frac{n^2 K^5}{s}(\log s+K\log
K)\bigr)$. Previously, for Voronoi diagrams, the only known $s$-workspace
algorithm runs in expected time $O((n^2/s) \log s + n\log s \log^*s)$ [Korman
et al., WADS'15] and only works for NVD($P$) (i.e., $k=1$). Unlike the previous
algorithm, our new method is very simple and does not rely on advanced data
structures or random sampling techniques.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00817</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting Exception Handling Practices with Exception Flow Analysis</dc:title>
 <dc:creator>de P&#xe1;dua, Guilherme B.</dc:creator>
 <dc:creator>Shang, Weiyi</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Modern programming languages, such as Java and C#, typically provide features
that handle exceptions. These features separate error-handling code from
regular source code and aim to assist in the practice of software comprehension
and maintenance. Having acknowledged the advantages of exception handling
features, their misuse can still cause reliability degradation or even
catastrophic software failures. Prior studies on exception handling aim to
understand the practices of exception handling in its different components,
such as the origin of the exceptions and the handling code of the exceptions.
Yet, the observed findings were scattered and diverse. In this paper, to
complement prior research findings on exception handling, we study its features
by enriching the knowledge of handling code with a flow analysis of exceptions.
Our case study is conducted with over 10K exception handling blocks, and over
77K related exception flows from 16 open-source Java and C# (.NET) libraries
and applications. Our case study results show that each try block has up to 12
possible potentially recoverable yet propagated exceptions. More importantly,
22% of the distinct possible exceptions can be traced back to multiple methods
(average of 1.39 and max of 34). Such results highlight the additional
challenge of composing quality exception handling code. To make it worse, we
confirm that there is a lack of documentation of the possible exceptions and
their sources. However, such critical information can be identified by
exception flow analysis on well- documented API calls (e.g., JRE and .NET
documentation). Finally, we observe different strategies in exception handling
code between Java and C#. Our findings highlight the opportunities of
leveraging automated software analysis to assist in exception handling
practices and signify the need of more further in-depth studies on exception
handling practice.
</dc:description>
 <dc:description>Comment: Pre-print for SCAM 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00818</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enterprise to Computer: Star Trek chatbot</dc:title>
 <dc:creator>Jena, Grishma</dc:creator>
 <dc:creator>Vashisht, Mansi</dc:creator>
 <dc:creator>Basu, Abheek</dc:creator>
 <dc:creator>Ungar, Lyle</dc:creator>
 <dc:creator>Sedoc, Jo&#xe3;o</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Human interactions and human-computer interactions are strongly influenced by
style as well as content. Adding a persona to a chatbot makes it more
human-like and contributes to a better and more engaging user experience. In
this work, we propose a design for a chatbot that captures the &quot;style&quot; of Star
Trek by incorporating references from the show along with peculiar tones of the
fictional characters therein. Our Enterprise to Computer bot (E2Cbot) treats
Star Trek dialog style and general dialog style differently, using two
recurrent neural network Encoder-Decoder models. The Star Trek dialog style
uses sequence to sequence (SEQ2SEQ) models (Sutskever et al., 2014; Bahdanau et
al., 2014) trained on Star Trek dialogs. The general dialog style uses Word
Graph to shift the response of the SEQ2SEQ model into the Star Trek domain. We
evaluate the bot both in terms of perplexity and word overlap with Star Trek
vocabulary and subjectively using human evaluators.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00818</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00822</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quadratically Tight Relations for Randomized Query Complexity</dc:title>
 <dc:creator>Gavinsky, Dmitry</dc:creator>
 <dc:creator>Jain, Rahul</dc:creator>
 <dc:creator>Klauck, Hartmut</dc:creator>
 <dc:creator>Kundu, Srijita</dc:creator>
 <dc:creator>Lee, Troy</dc:creator>
 <dc:creator>Santha, Miklos</dc:creator>
 <dc:creator>Sanyal, Swagato</dc:creator>
 <dc:creator>Vihrovs, Jevgenijs</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Let $f:\{0,1\}^n \rightarrow \{0,1\}$ be a Boolean function. The certificate
complexity $C(f)$ is a complexity measure that is quadratically tight for the
zero-error randomized query complexity $R_0(f)$: $C(f) \leq R_0(f) \leq
C(f)^2$. In this paper we study a new complexity measure that we call
expectational certificate complexity $EC(f)$, which is also a quadratically
tight bound on $R_0(f)$: $EC(f) \leq R_0(f) = O(EC(f)^2)$. We prove that $EC(f)
\leq C(f) \leq EC(f)^2$ and show that there is a quadratic separation between
the two, thus $EC(f)$ gives a tighter upper bound for $R_0(f)$. The measure is
also related to the fractional certificate complexity $FC(f)$ as follows:
$FC(f) \leq EC(f) = O(FC(f)^{3/2})$. This also connects to an open question by
Aaronson whether $FC(f)$ is a quadratically tight bound for $R_0(f)$, as
$EC(f)$ is in fact a relaxation of $FC(f)$.
  In the second part of the work, we upper bound the distributed query
complexity $D^\mu_\epsilon(f)$ for product distributions $\mu$ by the square of
the query corruption bound ($\mathrm{corr}_\epsilon(f)$) which improves upon a
result of Harsha, Jain and Radhakrishnan [2015]. A similar statement for
communication complexity is open.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00838</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An End-to-End Compression Framework Based on Convolutional Neural
  Networks</dc:title>
 <dc:creator>Jiang, Feng</dc:creator>
 <dc:creator>Tao, Wen</dc:creator>
 <dc:creator>Liu, Shaohui</dc:creator>
 <dc:creator>Ren, Jie</dc:creator>
 <dc:creator>Guo, Xun</dc:creator>
 <dc:creator>Zhao, Debin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning, e.g., convolutional neural networks (CNNs), has achieved great
success in image processing and computer vision especially in high level vision
applications such as recognition and understanding. However, it is rarely used
to solve low-level vision problems such as image compression studied in this
paper. Here, we move forward a step and propose a novel compression framework
based on CNNs. To achieve high-quality image compression at low bit rates, two
CNNs are seamlessly integrated into an end-to-end compression framework. The
first CNN, named compact convolutional neural network (ComCNN), learns an
optimal compact representation from an input image, which preserves the
structural information and is then encoded using an image codec (e.g., JPEG,
JPEG2000 or BPG). The second CNN, named reconstruction convolutional neural
network (RecCNN), is used to reconstruct the decoded image with high-quality in
the decoding end. To make two CNNs effectively collaborate, we develop a
unified end-to-end learning algorithm to simultaneously learn ComCNN and
RecCNN, which facilitates the accurate reconstruction of the decoded image
using RecCNN. Such a design also makes the proposed compression framework
compatible with existing image coding standards. Experimental results validate
that the proposed compression framework greatly outperforms several compression
frameworks that use existing image coding standards with state-of-the-art
deblocking or denoising post-processing methods.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Circuits and Systems for Video
  Technology</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00842</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Latent Parameter Estimation in Fusion Networks Using Separable
  Likelihoods</dc:title>
 <dc:creator>Uney, Murat</dc:creator>
 <dc:creator>Mulgrew, Bernard</dc:creator>
 <dc:creator>Clark, Daniel E</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  Multi-sensor state space models underpin fusion applications in networks of
sensors. Estimation of latent parameters in these models has the potential to
provide highly desirable capabilities such as network self-calibration.
Conventional solutions to the problem pose difficulties in scaling with the
number of sensors due to the joint multi-sensor filtering involved when
evaluating the parameter likelihood. In this article, we propose a separable
pseudo-likelihood which is a more accurate approximation compared to a
previously proposed alternative under typical operating conditions. In
addition, we consider using separable likelihoods in the presence of many
objects and ambiguity in associating measurements with objects that originated
them. To this end, we use a state space model with a hypothesis based
parameterisation, and, develop an empirical Bayesian perspective in order to
evaluate separable likelihoods on this model using local filtering. Bayesian
inference with this likelihood is carried out using belief propagation on the
associated pairwise Markov random field. We specify a particle algorithm for
latent parameter estimation in a linear Gaussian state space model and
demonstrate its efficacy for network self-calibration using measurements from
non-cooperative targets in comparison with alternatives.
</dc:description>
 <dc:description>Comment: accepted with minor revisions, IEEE Transactions on Signal and
  Information Processing Over Networks</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:date>2018-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00850</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Semantic Modeling of Contradictions and Disagreements: A Case
  Study of Medical Guidelines</dc:title>
 <dc:creator>Zadrozny, Wlodek</dc:creator>
 <dc:creator>Hematialam, Hossein</dc:creator>
 <dc:creator>Garbayo, Luciana</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We introduce a formal distinction between contradictions and disagreements in
natural language texts, motivated by the need to formally reason about
contradictory medical guidelines. This is a novel and potentially very useful
distinction, and has not been discussed so far in NLP and logic. We also
describe a NLP system capable of automated finding contradictory medical
guidelines; the system uses a combination of text analysis and information
retrieval modules. We also report positive evaluation results on a small corpus
of contradictory medical recommendations.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure, accepted at 12th International Conference on
  Computational Semantics (IWCS-2017)</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00850</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00852</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intercell Interference-Aware Scheduling for Delay Sensitive Applications
  in C-RAN</dc:title>
 <dc:creator>Li, Yi</dc:creator>
 <dc:creator>Gursoy, M. Cenk</dc:creator>
 <dc:creator>Velipasalar, Senem</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Cloud radio access network (C-RAN) architecture is a new mobile network
architecture that enables cooperative baseband processing and information
sharing among multiple cells and achieves high adaptability to nonuniform
traffic by centralizing the baseband processing resources in a virtualized
baseband unit (BBU) pool. In this work, we formulate the utility of each user
using a convex delay cost function, and design a two-step scheduling algorithm
with good delay performance for the C-RAN architecture. In the first step, all
users in multiple cells are grouped into small user groups, according to their
interference levels and estimated utilities. In the second step, channels are
matched to the user groups to maximize the system utility. The performance of
our algorithm is further studied via simulations, and the advantages of C-RAN
architecture is verified.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00852</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00853</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Audio Super Resolution using Neural Networks</dc:title>
 <dc:creator>Kuleshov, Volodymyr</dc:creator>
 <dc:creator>Enam, S. Zayd</dc:creator>
 <dc:creator>Ermon, Stefano</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce a new audio processing technique that increases the sampling
rate of signals such as speech or music using deep convolutional neural
networks. Our model is trained on pairs of low and high-quality audio examples;
at test-time, it predicts missing samples within a low-resolution signal in an
interpolation process similar to image super-resolution. Our method is simple
and does not involve specialized audio processing techniques; in our
experiments, it outperforms baselines on standard speech and music benchmarks
at upscaling ratios of 2x, 4x, and 6x. The method has practical applications in
telephony, compression, and text-to-speech generation; it demonstrates the
effectiveness of feed-forward convolutional architectures on an audio
generation task.
</dc:description>
 <dc:description>Comment: Presented at the 5th International Conference on Learning
  Representations (ICLR) 2017, Workshop Track, Toulon, France</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00854</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Average-case reconstruction for the deletion channel: subpolynomially
  many traces suffice</dc:title>
 <dc:creator>Peres, Yuval</dc:creator>
 <dc:creator>Zhai, Alex</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>62B10</dc:subject>
 <dc:description>  The deletion channel takes as input a bit string $\mathbf{x} \in \{0,1\}^n$,
and deletes each bit independently with probability $q$, yielding a shorter
string. The trace reconstruction problem is to recover an unknown string
$\mathbf{x}$ from many independent outputs (called &quot;traces&quot;) of the deletion
channel applied to $\mathbf{x}$. We show that if $\mathbf{x}$ is drawn
uniformly at random and $q &lt; 1/2$, then $e^{O(\log^{1/2} n)}$ traces suffice to
reconstruct $\mathbf{x}$ with high probability. The previous best bound,
established in 2008 by Holenstein-Mitzenmacher-Panigrahy-Wieder, uses
$n^{O(1)}$ traces and only applies for $q$ less than a smaller threshold (it
seems that $q &lt; 0.07$ is needed). Our algorithm combines several ideas: 1) an
alignment scheme for &quot;greedily&quot; fitting the output of the deletion channel as a
subsequence of the input; 2) a version of the idea of &quot;anchoring&quot; used by
Holenstein-Mitzenmacher-Panigrahy-Wieder; and 3) complex analysis techniques
from recent work of Nazarov-Peres and De-O'Donnell-Servedio.
</dc:description>
 <dc:description>Comment: 28 pages, 4 figures</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00854</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00856</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ontology-based Classification and Analysis of non- emergency Smart-city
  Events</dc:title>
 <dc:creator>Rani, Monika</dc:creator>
 <dc:creator>Alekh, Sanchit</dc:creator>
 <dc:creator>Bhardwaj, Aditya</dc:creator>
 <dc:creator>Gupta, Abhinav</dc:creator>
 <dc:creator>Vyas, O. P.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Several challenges are faced by citizens of urban centers while dealing with
day-to-day events, and the absence of a centralised reporting mechanism makes
event-reporting and redressal a daunting task. With the push on information
technology to adapt to the needs of smart-cities and integrate urban civic
services, the use of Open311 architecture presents an interesting solution. In
this paper, we present a novel approach that uses an existing Open311 ontology
to classify and report non-emergency city-events, as well as to guide the
citizen to the points of redressal. The use of linked open data and the
semantic model serves to provide contextual meaning and make vast amounts of
content hyper-connected and easily-searchable. Such a one-size-fits-all model
also ensures reusability and effective visualisation and analysis of data
across several cities. By integrating urban services across various civic
bodies, the proposed approach provides a single endpoint to the citizen, which
is imperative for smooth functioning of smart cities.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00856</dc:identifier>
 <dc:identifier>doi:10.1109/ICCTICT.2016.7514633</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00872</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Mode Selection and Resource Allocation for D2D Communications via
  Vertex Coloring</dc:title>
 <dc:creator>Li, Yi</dc:creator>
 <dc:creator>Gursoy, M. Cenk</dc:creator>
 <dc:creator>Velipasalar, Senem</dc:creator>
 <dc:creator>Tang, Jian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Device-to-device (D2D) communication underlaid with cellular networks is a
new paradigm, proposed to enhance the performance of cellular networks. By
allowing a pair of D2D users to communicate directly and share the same
spectral resources with the cellular users, D2D communication can achieve
higher spectral efficiency, improve the energy efficiency, and lower the
traffic delay. In this paper, we propose a novel joint mode selection and
channel resource allocation algorithm via the vertex coloring approach. We
decompose the problem into three subproblems and design algorithms for each of
them. In the first step, we divide the users into groups using a vertex
coloring algorithm. In the second step, we solve the power optimization problem
using the interior-point method for each group and conduct mode selection
between the cellular mode and D2D mode for D2D users, and we assign channel
resources to these groups in the final step. Numerical results show that our
algorithm achieves higher sum rate and serves more users with relatively small
time consumption compared with other algorithms. Also, the influence of system
parameters and the tradeoff between sum rate and the number of served users are
studied through simulation results.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00884</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fingerprint Extraction Using Smartphone Camera</dc:title>
 <dc:creator>Gupta, Saksham</dc:creator>
 <dc:creator>Anand, Sukhad</dc:creator>
 <dc:creator>Rai, Atul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In the previous decade, there has been a considerable rise in the usage of
smartphones.Due to exorbitant advancement in technology, computational speed
and quality of image capturing has increased considerably. With an increase in
the need for remote fingerprint verification, smartphones can be used as a
powerful alternative for fingerprint authentication instead of conventional
optical sensors. In this research, wepropose a technique to capture
finger-images from the smartphones and pre-process them in such a way that it
can be easily matched with the optical sensor images.Effective finger-image
capturing, image enhancement, fingerprint pattern extraction, core point
detection and image alignment techniques have been discussed. The proposed
approach has been validated on FVC 2004 DB1 &amp; DB2 dataset and the results show
the efficacy of the methodology proposed. The method can be deployed for
real-time commercial usage.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00884</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00885</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proc. of the 9th Workshop on Semantic Ambient Media Experiences
  (SAME'2016/2): Visualisation, Emerging Media, and User-Experience:
  International Series on Information Systems and Management in Creative eMedia
  (CreMedia)</dc:title>
 <dc:creator>Lugmayr, Artur</dc:creator>
 <dc:creator>Seale, Richard</dc:creator>
 <dc:creator>Woods, Andrew</dc:creator>
 <dc:creator>Sari, Eunice</dc:creator>
 <dc:creator>Tedjasaputra, Adi</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  The 9th Semantic Ambient Media Experience (SAME) proceedings where based on
the academic contributions to a two day workshop that was held at Curtin
University, Perth, WA, Australia. The symposium was held to discuss
visualisation, emerging media, and user-experience from various angles. The
papers of this workshop are freely available through
http://www.ambientmediaassociation.org/Journal under open access as provided by
the International Ambient Media Association (iAMEA) Ry. iAMEA is hosting the
international open access journal entitled &quot;International Journal on
Information Systems and Management in Creative eMedia&quot;, and the series entitled
&quot;International Series on Information Systems and Management in Creative
eMedia&quot;. For any further information, please visit the website of the
Association: http://www.ambientmediaassociation.org.
</dc:description>
 <dc:date>2017-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00885</dc:identifier>
 <dc:identifier>Proc. of the 9th Workshop on Semantic Ambient Media Experiences,
  Visualisation, Emerging Media, and User-Experience, International Series on
  Information Systems and Management in Creative eMedia (CreMedia), No. 2016/2,
  2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00894</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PIVO: Probabilistic Inertial-Visual Odometry for Occlusion-Robust
  Navigation</dc:title>
 <dc:creator>Solin, Arno</dc:creator>
 <dc:creator>Cortes, Santiago</dc:creator>
 <dc:creator>Rahtu, Esa</dc:creator>
 <dc:creator>Kannala, Juho</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a novel method for visual-inertial odometry. The method
is based on an information fusion framework employing low-cost IMU sensors and
the monocular camera in a standard smartphone. We formulate a sequential
inference scheme, where the IMU drives the dynamical model and the camera
frames are used in coupling trailing sequences of augmented poses. The novelty
in the model is in taking into account all the cross-terms in the updates, thus
propagating the inter-connected uncertainties throughout the model. Stronger
coupling between the inertial and visual data sources leads to robustness
against occlusion and feature-poor environments. We demonstrate results on data
collected with an iPhone and provide comparisons against the Tango device and
using the EuRoC data set.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures. Paper to be published in WACV 2018</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00894</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00897</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Domain Aware Neural Dialog System</dc:title>
 <dc:creator>Choudhary, Sajal</dc:creator>
 <dc:creator>Srivastava, Prerna</dc:creator>
 <dc:creator>Ungar, Lyle</dc:creator>
 <dc:creator>Sedoc, Jo&#xe3;o</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We investigate the task of building a domain aware chat system which
generates intelligent responses in a conversation comprising of different
domains. The domain, in this case, is the topic or theme of the conversation.
To achieve this, we present DOM-Seq2Seq, a domain aware neural network model
based on the novel technique of using domain-targeted sequence-to-sequence
models (Sutskever et al., 2014) and a domain classifier. The model captures
features from current utterance and domains of the previous utterances to
facilitate the formation of relevant responses. We evaluate our model on
automatic metrics and compare our performance with the Seq2Seq model.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00897</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00898</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Seating Assignment Using Constrained Signed Spectral Clustering</dc:title>
 <dc:creator>Sedoc, Jo&#xe3;o</dc:creator>
 <dc:creator>Normoyle, Aline</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this paper, we present a novel method for constrained cluster size signed
spectral clustering which allows us to subdivide large groups of people based
on their relationships. In general, signed clustering only requires K hard
clusters and does not constrain the cluster sizes. We extend signed clustering
to include cluster size constraints. Using an example of seating assignment, we
efficiently find groups of people with high social affinity while mitigating
awkward social interaction between people who dislike each other.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00898</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00905</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Covert Communication Achieved by A Greedy Relay in Wireless Networks</dc:title>
 <dc:creator>Hu, Jinsong</dc:creator>
 <dc:creator>Yan, Shihao</dc:creator>
 <dc:creator>Zhou, Xiangyun</dc:creator>
 <dc:creator>Shu, Feng</dc:creator>
 <dc:creator>Li, Jun</dc:creator>
 <dc:creator>Wang, Jiangzhou</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Covert communication aims to hide the very existence of wireless
transmissions in order to guarantee a strong security in wireless networks. In
this work, we examine the possibility and achievable performance of covert
communication in one-way relay networks. Specifically, the relay is greedy and
opportunistically transmits its own information to the destination covertly on
top of forwarding the source's message, while the source tries to detect this
covert transmission to discover the illegitimate usage of the resource (e.g.,
power, spectrum) allocated only for the purpose of forwarding source's
information. We propose two strategies for the relay to transmit its covert
information, namely fixed-rate and fixed-power transmission schemes, for which
the source's detection limits are analysed in terms of the false alarm and miss
detection rates and the achievable effective covert rates from the relay to
destination are derived. Our examination determines the conditions under which
the fixed-rate transmission scheme outperforms the fixed-power transmission
scheme, and vice versa, which enables the relay to achieve the maximum
effective covert rate. Our analysis indicates that the relay has to forward the
source's message to shield its covert transmission and the effective covert
rate increases with its forwarding ability (e.g., its maximum transmit power).
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1704.04946</dc:description>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00908</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Noninvasive Corneal Image-Based Gaze Measurement System</dc:title>
 <dc:creator>Chong, Eunji</dc:creator>
 <dc:creator>Nitschke, Christian</dc:creator>
 <dc:creator>Nakazawa, Atsushi</dc:creator>
 <dc:creator>Rozga, Agata</dc:creator>
 <dc:creator>Rehg, James M.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Gaze tracking is an important technology as the system can give information
about a person from what and where the person is seeing. There have been many
attempts to make robust and accurate gaze trackers using either monitor or
wearable devices. However, those contraptions often require fine individual
calibration per session and/or require a person wearing a device, which may not
be suitable for certain situations. In this paper, we propose a robust and a
completely noninvasive gaze tracking system that involves neither complex
calibrations nor the use of wearable devices. We achieve this via direct eye
reflection analysis by building a real-time system that effectively enables it.
We also show several interesting applications for our system including
experiments with young children.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00909</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine learning for neural decoding</dc:title>
 <dc:creator>Glaser, Joshua I.</dc:creator>
 <dc:creator>Chowdhury, Raeed H.</dc:creator>
 <dc:creator>Perich, Matthew G.</dc:creator>
 <dc:creator>Miller, Lee E.</dc:creator>
 <dc:creator>Kording, Konrad P.</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  While machine learning tools have been rapidly advancing, the majority of
neural decoding approaches still use last century's methods. Improving the
performance of neural decoding algorithms allows us to better understand what
information is contained in the brain, and can help advance engineering
applications such as brain machine interfaces. Here, we apply modern machine
learning techniques, including neural networks and gradient boosting, to decode
from spiking activity in 1) motor cortex, 2) somatosensory cortex, and 3)
hippocampus. We compare the predictive ability of these modern methods with
traditional decoding methods such as Wiener and Kalman filters. Modern methods,
in particular neural networks and ensembles, significantly outperformed the
traditional approaches. For instance, for all of the three brain areas, an LSTM
decoder explained over 40% of the unexplained variance from a Wiener filter.
These results suggest that modern machine learning techniques should become the
standard methodology for neural decoding. We provide code to facilitate wider
implementation of these methods.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00909</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00917</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Periodic Isoperimetric Problem Related to the Unique Games Conjecture</dc:title>
 <dc:creator>Heilman, Steven</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We prove the endpoint case of a conjecture of Khot and Moshkovitz related to
the Unique Games Conjecture, less a small error.
  Let $n\geq2$. Suppose a subset $\Omega$ of $n$-dimensional Euclidean space
$\mathbb{R}^{n}$ satisfies $-\Omega=\Omega^{c}$ and $\Omega+v=\Omega^{c}$ for
any standard basis vector $v\in\mathbb{R}^{n}$. For any
$x=(x_{1},\ldots,x_{n})\in\mathbb{R}^{n}$ and for any $q\geq1$, let
$\|x\|_{q}^{q}=|x_{1}|^{q}+\cdots+|x_{n}|^{q}$ and let
$\gamma_{n}(x)=(2\pi)^{-n/2}e^{-\|x\|_{2}^{2}/2}$ . For any
$x\in\partial\Omega$, let $N(x)$ denote the exterior normal vector at $x$ such
that $\|N(x)\|_{2}=1$. Let $B=\{x\in\mathbb{R}^{n}\colon
\sin(\pi(x_{1}+\cdots+x_{n}))\geq0\}$. Our main result shows that $B$ has the
smallest Gaussian surface area among all such subsets $\Omega$, less a small
error: $$ \int_{\partial\Omega}\gamma_{n}(x)dx\geq(1-6\cdot
10^{-9})\int_{\partial
B}\gamma_{n}(x)dx+\int_{\partial\Omega}\Big(1-\frac{\|N(x)\|_{1}}{\sqrt{n}}\Big)\gamma_{n}(x)dx.
$$ In particular, $$ \int_{\partial\Omega}\gamma_{n}(x)dx\geq(1-6\cdot
10^{-9})\int_{\partial B}\gamma_{n}(x)dx. $$ Standard arguments extend these
results to a corresponding weak inequality for noise stability. Removing the
factor $6\cdot 10^{-9}$ would prove the endpoint case of the Khot-Moshkovitz
conjecture. Lastly, we prove a Euclidean analogue of the Khot and Moshkovitz
conjecture.
  The full conjecture of Khot and Moshkovitz provides strong evidence for the
truth of the Unique Games Conjecture, a central conjecture in theoretical
computer science that is closely related to the P versus NP problem. So, our
results also provide evidence for the truth of the Unique Games Conjecture.
Nevertheless, this paper does not prove any case of the Unique Games
conjecture.
</dc:description>
 <dc:description>Comment: 13 pages, 1 figure</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00917</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00919</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flat2Sphere: Learning Spherical Convolution for Fast Features from
  360{\deg} Imagery</dc:title>
 <dc:creator>Su, Yu-Chuan</dc:creator>
 <dc:creator>Grauman, Kristen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While 360{\deg} cameras offer tremendous new possibilities in vision,
graphics, and augmented reality, the spherical images they produce make core
feature extraction non-trivial. Convolutional neural networks (CNNs) trained on
images from perspective cameras yield &quot;flat&quot; filters, yet 360{\deg} images
cannot be projected to a single plane without significant distortion. A naive
solution that repeatedly projects the viewing sphere to all tangent planes is
accurate, but much too computationally intensive for real problems. We propose
to learn a spherical convolutional network that translates a planar CNN to
process 360{\deg} imagery directly in its equirectangular projection. Our
approach learns to reproduce the flat filter outputs on 360{\deg} data,
sensitive to the varying distortion effects across the viewing sphere. The key
benefits are 1) efficient feature extraction for 360{\deg} images and video,
and 2) the ability to leverage powerful pre-trained networks researchers have
carefully honed (together with massive labeled image training sets) for
perspective images. We validate our approach compared to several alternative
methods in terms of both raw CNN output accuracy as well as applying a
state-of-the-art &quot;flat&quot; object detector to 360{\deg} data. Our method yields
the most accurate results while saving orders of magnitude in computation
versus the existing exact reprojection solution.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00921</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Echo State Learning for Wireless Virtual Reality Resource Allocation in
  UAV-enabled LTE-U Networks</dc:title>
 <dc:creator>Chen, Mingzhe</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Yin, Changchuan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, the problem of resource management is studied for a network of
wireless virtual reality (VR) users communicating using an unmanned aerial
vehicle (UAV)-enabled LTE-U network. In the studied model, the UAVs act as VR
control centers that collect tracking information from the VR users over the
wireless uplink and, then, send the constructed VR images to the VR users over
an LTE-U downlink. Therefore, resource allocation in such a UAV-enabled LTE-U
network must jointly consider the uplink and downlink links over both licensed
and unlicensed bands. In such a VR setting, the UAVs can dynamically adjust the
image quality and format of each VR image to change the data size of each VR
image, then meet the delay requirement. Therefore, resource allocation must
also take into account the image quality and format. This VR-centric resource
allocation problem is formulated as a noncooperative game that enables a joint
allocation of licensed and unlicensed spectrum bands, as well as a dynamic
adaptation of VR image quality and format. To solve this game, a learning
algorithm based on the machine learning tools of echo state networks (ESNs)
with leaky integrator neurons is proposed. Unlike conventional ESN based
learning algorithms that are suitable for discrete-time systems, the proposed
algorithm can dynamically adjust the update speed of the ESN's state and,
hence, it can enable the UAVs to learn the continuous dynamics of their
associated VR users. Simulation results show that the proposed algorithm
achieves up to 14% and 27.1% gains in terms of total VR QoE for all users
compared to Q-learning using LTE-U and Q-learning using LTE.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00922</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved GelSight Tactile Sensor for Measuring Geometry and Slip</dc:title>
 <dc:creator>Dong, Siyuan</dc:creator>
 <dc:creator>Yuan, Wenzhen</dc:creator>
 <dc:creator>Adelson, Edward</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  A GelSight sensor uses an elastomeric slab covered with a reflective membrane
to measure tactile signals. It measures the 3D geometry and contact force
information with high spacial resolution, and successfully helped many
challenging robot tasks. A previous sensor, based on a semi-specular membrane,
produces high resolution but with limited geometry accuracy. In this paper, we
describe a new design of GelSight for robot gripper, using a Lambertian
membrane and new illumination system, which gives greatly improved geometric
accuracy while retaining the compact size. We demonstrate its use in measuring
surface normals and reconstructing height maps using photometric stereo. We
also use it for the task of slip detection, using a combination of information
about relative motions on the membrane surface and the shear distortions. Using
a robotic arm and a set of 37 everyday objects with varied properties, we find
that the sensor can detect translational and rotational slip in general cases,
and can be used to improve the stability of the grasp.
</dc:description>
 <dc:description>Comment: IEEE/RSJ International Conference on Intelligent Robots and Systems</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00930</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aligned and Non-Aligned Double JPEG Detection Using Convolutional Neural
  Networks</dc:title>
 <dc:creator>Barni, Mauro</dc:creator>
 <dc:creator>Bondi, Luca</dc:creator>
 <dc:creator>Bonettini, Nicol&#xf2;</dc:creator>
 <dc:creator>Bestagini, Paolo</dc:creator>
 <dc:creator>Costanzo, Andrea</dc:creator>
 <dc:creator>Maggini, Marco</dc:creator>
 <dc:creator>Tondi, Benedetta</dc:creator>
 <dc:creator>Tubaro, Stefano</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Due to the wide diffusion of JPEG coding standard, the image forensic
community has devoted significant attention to the development of double JPEG
(DJPEG) compression detectors through the years. The ability of detecting
whether an image has been compressed twice provides paramount information
toward image authenticity assessment. Given the trend recently gained by
convolutional neural networks (CNN) in many computer vision tasks, in this
paper we propose to use CNNs for aligned and non-aligned double JPEG
compression detection. In particular, we explore the capability of CNNs to
capture DJPEG artifacts directly from images. Results show that the proposed
CNN-based detectors achieve good performance even with small size images (i.e.,
64x64), outperforming state-of-the-art solutions, especially in the non-aligned
case. Besides, good results are also achieved in the commonly-recognized
challenging case in which the first quality factor is larger than the second
one.
</dc:description>
 <dc:description>Comment: Submitted to Journal of Visual Communication and Image Representation
  (first submission: March 20, 2017; second submission: August 2, 2017)</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00930</dc:identifier>
 <dc:identifier>doi:10.1016/j.jvcir.2017.09.003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00931</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Keystroke Dynamics and Face Recognition for User Verification</dc:title>
 <dc:creator>Gupta, Abhinav</dc:creator>
 <dc:creator>Khanna, Agrim</dc:creator>
 <dc:creator>Jagetia, Anmol</dc:creator>
 <dc:creator>Sharma, Devansh</dc:creator>
 <dc:creator>Alekh, Sanchit</dc:creator>
 <dc:creator>Choudhary, Vaibhav</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The massive explosion and ubiquity of computing devices and the outreach of
the web have been the most defining events of the century so far. As more and
more people gain access to the internet, traditional know-something and
have-something authentication methods such as PINs and passwords are proving to
be insufficient for prohibiting unauthorized access to increasingly personal
data on the web. Therefore, the need of the hour is a user-verification system
that is not only more reliable and secure, but also unobtrusive and
minimalistic. Keystroke Dynamics is a novel Biometric Technique; it is not only
unobtrusive, but also transparent and inexpensive. The fusion of keystroke
dynamics and Face Recognition engenders the most desirable characteristics of a
verification system. Our implementation uses Hidden Markov Models (HMM) for
modelling the Keystroke Dynamics, with the help of two widely used Feature
Vectors: Keypress Latency and Keypress Duration. On the other hand, Face
Recognition makes use of the traditional Eigenfaces approach.The results show
that the system has a high precision, with a False Acceptance Rate of 5.4% and
a False Rejection Rate of 9.2%. Moreover, it is also future-proof, as the
hardware requirements, i.e. camera and keyboard (physical or on-screen), have
become an indispensable part of modern computing.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00931</dc:identifier>
 <dc:identifier>doi:10.1109/CSE.2015.37</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00938</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Associative Domain Adaptation</dc:title>
 <dc:creator>Haeusser, Philip</dc:creator>
 <dc:creator>Frerix, Thomas</dc:creator>
 <dc:creator>Mordvintsev, Alexander</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose associative domain adaptation, a novel technique for end-to-end
domain adaptation with neural networks, the task of inferring class labels for
an unlabeled target domain based on the statistical properties of a labeled
source domain. Our training scheme follows the paradigm that in order to
effectively derive class labels for the target domain, a network should produce
statistically domain invariant embeddings, while minimizing the classification
error on the labeled source domain. We accomplish this by reinforcing
associations between source and target data directly in embedding space. Our
method can easily be added to any existing classification network with no
structural and almost no computational overhead. We demonstrate the
effectiveness of our approach on various benchmarks and achieve
state-of-the-art results across the board with a generic convolutional neural
network architecture not specifically tuned to the respective tasks. Finally,
we show that the proposed association loss produces embeddings that are more
effective for domain adaptation compared to methods employing maximum mean
discrepancy as a similarity measure in embedding space.
</dc:description>
 <dc:description>Comment: In IEEE International Conference on Computer Vision (ICCV), 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00938</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00939</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Reference Implementation of WECC Composite Load Model in Matlab and
  GridPACK</dc:title>
 <dc:creator>Huang, Qiuhua</dc:creator>
 <dc:creator>Huang, Renke</dc:creator>
 <dc:creator>Palmer, Bruce J.</dc:creator>
 <dc:creator>Liu, Yuan</dc:creator>
 <dc:creator>Jin, Shuangshuang</dc:creator>
 <dc:creator>Diao, Ruisheng</dc:creator>
 <dc:creator>Chen, Yousu</dc:creator>
 <dc:creator>Zhang, Yu</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The composite load model (CLM) proposed by the Western Electricity
Coordinating Council (WECC) is gaining increasing traction in industry,
particularly in North America. At the same time, it has been recognized that
further improvements in structure, initialization and aggregation methods are
needed to enhance model accuracy. However, the lack of an open-source
implementation of the WECC CLM has become a roadblock for many researchers for
further improvement. To bridge this gap, this paper presents the first open
reference implementation of the WECC CLM. Individual load components and the
CLM are first developed and tested in Matlab, then translated to the high
performance computing (HPC) based, parallel simulation framework - GridPACK.
The main contributions of the paper include: 1) presenting important yet
undocumented details of modeling and initializing the CLM, particularly for a
parallel simulation frame-work like GridPACK; 2) implementation details of the
load components such as the single-phase air conditioner motor; 3) implementing
the CLM in a modular and extensible manner. The implementation has been tested
at both the component as well as system levels and benchmarked against
commercial simulation programs, with satisfactory accuracy.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00940</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Energy Minimization Approach to 3D Non-Rigid Deformable Surface
  Estimation Using RGBD Data</dc:title>
 <dc:creator>Willimon, Bryan</dc:creator>
 <dc:creator>Hickson, Steven</dc:creator>
 <dc:creator>Walker, Ian</dc:creator>
 <dc:creator>Birchfield, Stan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We propose an algorithm that uses energy mini- mization to estimate the
current configuration of a non-rigid object. Our approach utilizes an RGBD
image to calculate corresponding SURF features, depth, and boundary informa-
tion. We do not use predetermined features, thus enabling our system to operate
on unmodified objects. Our approach relies on a 3D nonlinear energy
minimization framework to solve for the configuration using a semi-implicit
scheme. Results show various scenarios of dynamic posters and shirts in
different configurations to illustrate the performance of the method. In
particular, we show that our method is able to estimate the configuration of a
textureless nonrigid object with no correspondences available.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00945</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Human Activities Using Stochastic Grammar</dc:title>
 <dc:creator>Qi, Siyuan</dc:creator>
 <dc:creator>Huang, Siyuan</dc:creator>
 <dc:creator>Wei, Ping</dc:creator>
 <dc:creator>Zhu, Song-Chun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a novel method to predict future human activities from
partially observed RGB-D videos. Human activity prediction is generally
difficult due to its non-Markovian property and the rich context between human
and environments.
  We use a stochastic grammar model to capture the compositional structure of
events, integrating human actions, objects, and their affordances. We represent
the event by a spatial-temporal And-Or graph (ST-AOG). The ST-AOG is composed
of a temporal stochastic grammar defined on sub-activities, and spatial graphs
representing sub-activities that consist of human actions, objects, and their
affordances. Future sub-activities are predicted using the temporal grammar and
Earley parsing algorithm. The corresponding action, object, and affordance
labels are then inferred accordingly. Extensive experiments are conducted to
show the effectiveness of our model on both semantic event parsing and future
activity prediction.
</dc:description>
 <dc:description>Comment: ICCV 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00946</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Instance Labeling Leveraging Hierarchical Segmentation</dc:title>
 <dc:creator>Hickson, Steven</dc:creator>
 <dc:creator>Essa, Irfan</dc:creator>
 <dc:creator>Christensen, Henrik</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Most of the approaches for indoor RGBD semantic la- beling focus on using
pixels or superpixels to train a classi- fier. In this paper, we implement a
higher level segmentation using a hierarchy of superpixels to obtain a better
segmen- tation for training our classifier. By focusing on meaningful segments
that conform more directly to objects, regardless of size, we train a random
forest of decision trees as a clas- sifier using simple features such as the 3D
size, LAB color histogram, width, height, and shape as specified by a his-
togram of surface normals. We test our method on the NYU V2 depth dataset, a
challenging dataset of cluttered indoor environments. Our experiments using the
NYU V2 depth dataset show that our method achieves state of the art re- sults
on both a general semantic labeling introduced by the dataset (floor,
structure, furniture, and objects) and a more object specific semantic
labeling. We show that training a classifier on a segmentation from a hierarchy
of super pixels yields better results than training directly on super pixels,
patches, or pixels as in previous work.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00953</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating High-Quality Crowd Density Maps using Contextual Pyramid CNNs</dc:title>
 <dc:creator>Sindagi, Vishwanath A.</dc:creator>
 <dc:creator>Patel, Vishal M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a novel method called Contextual Pyramid CNN (CP-CNN) for
generating high-quality crowd density and count estimation by explicitly
incorporating global and local contextual information of crowd images. The
proposed CP-CNN consists of four modules: Global Context Estimator (GCE), Local
Context Estimator (LCE), Density Map Estimator (DME) and a Fusion-CNN (F-CNN).
GCE is a VGG-16 based CNN that encodes global context and it is trained to
classify input images into different density classes, whereas LCE is another
CNN that encodes local context information and it is trained to perform
patch-wise classification of input images into different density classes. DME
is a multi-column architecture-based CNN that aims to generate high-dimensional
feature maps from the input image which are fused with the contextual
information estimated by GCE and LCE using F-CNN. To generate high resolution
and high-quality density maps, F-CNN uses a set of convolutional and
fractionally-strided convolutional layers and it is trained along with the DME
in an end-to-end fashion using a combination of adversarial loss and
pixel-level Euclidean loss. Extensive experiments on highly challenging
datasets show that the proposed method achieves significant improvements over
the state-of-the-art methods.
</dc:description>
 <dc:description>Comment: Accepted at ICCV 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00953</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00961</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low Dose CT Image Denoising Using a Generative Adversarial Network with
  Wasserstein Distance and Perceptual Loss</dc:title>
 <dc:creator>Yang, Qingsong</dc:creator>
 <dc:creator>Yan, Pingkun</dc:creator>
 <dc:creator>Zhang, Yanbo</dc:creator>
 <dc:creator>Yu, Hengyong</dc:creator>
 <dc:creator>Shi, Yongyi</dc:creator>
 <dc:creator>Mou, Xuanqin</dc:creator>
 <dc:creator>Kalra, Mannudeep K.</dc:creator>
 <dc:creator>Wang, Ge</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we introduce a new CT image denoising method based on the
generative adversarial network (GAN) with Wasserstein distance and perceptual
similarity. The Wasserstein distance is a key concept of the optimal transform
theory, and promises to improve the performance of the GAN. The perceptual loss
compares the perceptual features of a denoised output against those of the
ground truth in an established feature space, while the GAN helps migrate the
data noise distribution from strong to weak. Therefore, our proposed method
transfers our knowledge of visual perception to the image denoising task, is
capable of not only reducing the image noise level but also keeping the
critical information at the same time. Promising results have been obtained in
our experiments with clinical CT images.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00961</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00964</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient hybrid search algorithm on ordered datasets</dc:title>
 <dc:creator>Mohammed, Adnan Saher</dc:creator>
 <dc:creator>Amrahov, &#x15e;ahin Emrah</dc:creator>
 <dc:creator>&#xc7;elebi, Fatih V.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The increase in the rate of data is much higher than the increase in the
speed of computers, which results in a heavy emphasis on search algorithms in
research literature. Searching an item in ordered list is an efficient
operation in data processing. Binary and interpolation search algorithms
commonly are used for searching ordered dataset in many applications. In this
paper, we present a hybrid algorithm to search ordered datasets based on the
idea of interpolation and binary search. The proposed algorithm called Hybrid
Search (HS), which is designed to work efficiently on unknown distributed
ordered datasets, experimental results showed that our proposed algorithm has
better performance when compared with other algorithms that use a similar
approach.
</dc:description>
 <dc:description>Comment: 13 pages full-length article</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00964</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00965</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual Quadrics from Object Detection BoundingBoxes as Landmark
  Representations in SLAM</dc:title>
 <dc:creator>S&#xfc;nderhauf, Niko</dc:creator>
 <dc:creator>Milford, Michael</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Research in Simultaneous Localization And Mapping (SLAM) is increasingly
moving towards richer world representations involving objects and high level
features that enable a semantic model of the world for robots, potentially
leading to a more meaningful set of robot-world interactions. Many of these
advances are grounded in state-of-the-art computer vision techniques primarily
developed in the context of image-based benchmark datasets, leaving several
challenges to be addressed in adapting them for use in robotics. In this paper,
we derive a formulation for Simultaneous Localization And Mapping (SLAM) that
uses dual quadrics as 3D landmark representations, and show how 2D bounding
boxes (such as those typically obtained from visual object detection systems)
can directly constrain the quadric parameters. Our paper demonstrates how to
jointly estimate the robot pose and dual quadric parameters in factor graph
based SLAM with a general perspective camera, and covers the use-cases of a
robot moving with a monocular camera with and without the availability of
additional depth information.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00965</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00969</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling the Propagation of Trojan Malware in Online Social Networks</dc:title>
 <dc:creator>Faghani, Mohammad Reza</dc:creator>
 <dc:creator>Nugyen, Uyen Trang</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The popularity and widespread usage of online social networks (OSN) have
attracted cyber criminals who have used OSNs as a platform to spread malware.
Among different types of malware in OSNs, Trojan is the most popular type with
hundreds of attacks on OSN users in the past few years. Trojans infecting a
user's computer have the ability to steal confidential information, install
ransomware and infect other computers in the network. Therefore, it is
important to understand propagation dynamics of Trojans in OSNs in order to
detect, contain and remove them as early as possible. In this article, we
present an analytical model to study propagation characteristics of Trojans and
factors that impact their propagation in an online social network. The proposed
model assumes all the topological characteristics of real online social
networks. Moreover, the model takes into account attacking trends of modern
Trojans, the role of anti-virus (AV) products, and security practices of OSN
users and AV software providers. By taking into account these factors, the
proposed model can accurately and realistically estimate the infection rate
caused by a Trojan malware in an OSN as well as the recovery rate of the user
population.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00973</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attention Transfer from Web Images for Video Recognition</dc:title>
 <dc:creator>Li, Junnan</dc:creator>
 <dc:creator>Wong, Yongkang</dc:creator>
 <dc:creator>Zhao, Qi</dc:creator>
 <dc:creator>Kankanhalli, Mohan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Training deep learning based video classifiers for action recognition
requires a large amount of labeled videos. The labeling process is
labor-intensive and time-consuming. On the other hand, large amount of
weakly-labeled images are uploaded to the Internet by users everyday. To
harness the rich and highly diverse set of Web images, a scalable approach is
to crawl these images to train deep learning based classifier, such as
Convolutional Neural Networks (CNN). However, due to the domain shift problem,
the performance of Web images trained deep classifiers tend to degrade when
directly deployed to videos. One way to address this problem is to fine-tune
the trained models on videos, but sufficient amount of annotated videos are
still required. In this work, we propose a novel approach to transfer knowledge
from image domain to video domain. The proposed method can adapt to the target
domain (i.e. video data) with limited amount of training data. Our method maps
the video frames into a low-dimensional feature space using the
class-discriminative spatial attention map for CNNs. We design a novel Siamese
EnergyNet structure to learn energy functions on the attention maps by jointly
optimizing two loss functions, such that the attention map corresponding to a
ground truth concept would have higher energy. We conduct extensive experiments
on two challenging video recognition datasets (i.e. TVHI and UCF101), and
demonstrate the efficacy of our proposed method.
</dc:description>
 <dc:description>Comment: ACM Multimedia, 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00973</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00975</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ORGB: Offset Correction in RGB Color Space for Illumination-Robust Image
  Processing</dc:title>
 <dc:creator>Ying, Zhenqiang</dc:creator>
 <dc:creator>Li, Ge</dc:creator>
 <dc:creator>Wen, Sixin</dc:creator>
 <dc:creator>Tan, Guozhen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Single materials have colors which form straight lines in RGB space. However,
in severe shadow cases, those lines do not intersect the origin, which is
inconsistent with the description of most literature. This paper is concerned
with the detection and correction of the offset between the intersection and
origin. First, we analyze the reason for forming that offset via an optical
imaging model. Second, we present a simple and effective way to detect and
remove the offset. The resulting images, named ORGB, have almost the same
appearance as the original RGB images while are more illumination-robust for
color space conversion. Besides, image processing using ORGB instead of RGB is
free from the interference of shadows. Finally, the proposed offset correction
method is applied to road detection task, improving the performance both in
quantitative and qualitative evaluations.
</dc:description>
 <dc:description>Comment: Project website: https://baidut.github.io/ORGB/</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00975</dc:identifier>
 <dc:identifier>doi:10.1109/ICASSP.2017.7952418</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00977</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Community Detection: A Review and Visual Survey</dc:title>
 <dc:creator>Khan, Bisma S.</dc:creator>
 <dc:creator>Niazi, Muaz A.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:description>  Community structure is an important area of research. It has received a
considerable attention from the scientific community. Despite its importance,
one of the key problems in locating information about community detection is
the diverse spread of related articles across various disciplines. To the best
of our knowledge, there is no current comprehensive review of recent literature
which uses a scientometric analysis using complex networks analysis covering
all relevant articles from the Web of Science (WoS). Here we present a visual
survey of key literature using CiteSpace. The idea is to identify emerging
trends besides using network techniques to examine the evolution of the domain.
Towards that end, we identify the most influential, central, as well as active
nodes using scientometric analyses. We examine authors, key articles, cited
references, core subject categories, key journals, institutions, as well as
countries. The exploration of the scientometric literature of the domain
reveals that Yong Wang is a pivot node with the highest centrality.
Additionally, we have observed that Mark Newman is the most highly cited author
in the network. We have also identified that the journal, &quot;Reviews of Modern
Physics&quot; has the strongest citation burst. In terms of cited documents, an
article by Andrea Lancichinetti has the highest centrality score. We have also
discovered that the origin of the key publications in this domain is from the
United States. Whereas Scotland has the strongest and longest citation burst.
Additionally, we have found that the categories of &quot;Computer Science&quot; and
&quot;Engineering&quot; lead other categories based on frequency and centrality
respectively.
</dc:description>
 <dc:description>Comment: 39 pages, 17 figures, 24 tables</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00977</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00979</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Results on the DMC Capacity and Renyi's Divergence</dc:title>
 <dc:creator>Lu, Yi Janet</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This work is part of a project &quot;Walsh Spectrum Analysis and the Cryptographic
Applications&quot;. The project initiates the study of finding the largest (and/or
significantly large) Walsh coefficients as well as the index positions of an
unknown distribution by random sampling. This proposed problem has great
significance in cryptography and communications.
  In early 2015, Yi JANET Lu first constructed novel imaginary channel
transition matrices and introduced Shannon's channel coding problem to
statistical cryptanalysis. For the first time, the channel capacity results of
well-chosen transition matrices, which might be impossible to calculate
traditionally, become of hottest research focus. For a few Discrete Memoryless
Channels (DMCs), it is known that the capacity can be computed analytically; in
general, there is no closed-form solution. This work is concerned with
analytical results of channel capacity in the new setting. We study both the
Blahut-Arimoto algorithm (which gave the first numerical solution historically)
and the most recent results [Sutter et al'2014] for the transition matrix of
$N\times M$. For an $\epsilon$-approximation (i.e., the desired absolute
accuracy of the approximate solution) of the capacity, the former has the
computational complexity $ O(MN^2 \log N/\epsilon) $, while the latter has the
complexity $ O(M^2N\sqrt{\log N}/\epsilon) $. We also study the relation of
Renyi's divergence of degree $1/2$ and the generalized channel capacity of
degree $1/2$.
</dc:description>
 <dc:description>Comment: Part of the material was presented at the 2nd International Workshop
  on Boolean Functions and their Applications (BFA), Sosltrand, Norway, July
  3-8, 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00979</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00980</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3DFaceNet: Real-time Dense Face Reconstruction via Synthesizing
  Photo-realistic Face Images</dc:title>
 <dc:creator>Guo, Yudong</dc:creator>
 <dc:creator>Zhang, Juyong</dc:creator>
 <dc:creator>Cai, Jianfei</dc:creator>
 <dc:creator>Jiang, Boyi</dc:creator>
 <dc:creator>Zheng, Jianmin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With the powerfulness of convolution neural networks (CNN), CNN based face
reconstruction has recently shown promising performance in reconstructing
detailed face shape from 2D face images. The success of CNN-based methods
relies on a large number of labeled data. The state-of-the-art synthesizes such
data using a coarse morphable face model, which however has difficulty to
generate detailed photo-realistic images of faces (with wrinkles). This paper
presents a novel face data generation method. Specifically, we render a large
number of photo-realistic face images with different attributes based on
inverse rendering. Furthermore, we construct a fine-detailed face image dataset
by transferring different scales of details from one image to another. We also
construct a large number of video-type adjacent frame pairs by simulating the
distribution of real video data. With these nicely constructed datasets, we
propose a coarse-to-fine learning framework consisting of three convolutional
networks. The networks are trained for real-time detailed 3D face
reconstruction from monocular video as well as from a single image. Extensive
experimental results demonstrate that our framework can produce high-quality
reconstruction but with much less computation time compared to the
state-of-the-art. Moreover, our method is robust to pose, expression and
lighting due to the diversity of data.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:date>2017-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00980</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00983</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Planar Deep Segmentation Networks for Cardiac Substructures from
  MRI and CT</dc:title>
 <dc:creator>Mortazi, Aliasghar</dc:creator>
 <dc:creator>Burt, Jeremy</dc:creator>
 <dc:creator>Bagci, Ulas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Non-invasive detection of cardiovascular disorders from radiology scans
requires quantitative image analysis of the heart and its substructures. There
are well-established measurements that radiologists use for diseases assessment
such as ejection fraction, volume of four chambers, and myocardium mass. These
measurements are derived as outcomes of precise segmentation of the heart and
its substructures. The aim of this paper is to provide such measurements
through an accurate image segmentation algorithm that automatically delineates
seven substructures of the heart from MRI and/or CT scans. Our proposed method
is based on multi-planar deep convolutional neural networks (CNN) with an
adaptive fusion strategy where we automatically utilize complementary
information from different planes of the 3D scans for improved delineations.
For CT and MRI, we have separately designed three CNNs (the same architectural
configuration) for three planes, and have trained the networks from scratch for
voxel-wise labeling for the following cardiac structures: myocardium of left
ventricle (Myo), left atrium (LA), left ventricle (LV), right atrium (RA),
right ventricle (RV), ascending aorta (Ao), and main pulmonary artery (PA). We
have evaluated the proposed method with 4-fold-cross validation on the
multi-modality whole heart segmentation challenge (MM-WHS 2017) dataset. The
precision and dice index of 0.93 and 0.90, and 0.87 and 0.85 were achieved for
CT and MR images, respectively. While a CT volume was segmented about 50
seconds, an MRI scan was segmented around 17 seconds with the GPUs/CUDA
implementation.
</dc:description>
 <dc:description>Comment: The paper is accepted to STACOM 2017</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00983</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00989</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Participation of an Energy Storage Aggregator in Electricity Markets</dc:title>
 <dc:creator>Contreras-Ocana, Jesus E.</dc:creator>
 <dc:creator>Ortega-Vazquez, Miguel A.</dc:creator>
 <dc:creator>Zhang, Baosen</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  An important function of aggregators is to enable the participation of small
energy storage units in electricity markets. This paper studies two generally
overlooked aspects related to aggregators of energy storage: i) the
relationship between the aggregator and its constituent storage units and ii)
the aggregator's effect on system welfare. Regarding i), we show that
short-term outcomes can be Pareto-inefficient: all players could be better-off.
In practice, however, aggregators and storage units are likely to engage in
long rather than short-term relationships. Using Nash Bargaining Theory, we
show that aggregators and storage units are likely to cooperate in the
long-term. A rigorous understanding of the aggregator-storage unit relationship
is fundamental to model the aggregator's participation in the market. Regarding
ii), we first show that a profit-seeking energy storage aggregator is always
beneficial to the system when compared to a system without storage, regardless
of size or market power the aggregator may have. However, due to market power,
a monopolist aggregator may act in a socially suboptimal manner. We propose a
pricing scheme designed to mitigate market power abuse by the aggregator. This
pricing scheme has several important characteristics: its formulation requires
no private information, it incentivizes a rational aggregator to behave in a
socially optimal manner, and allows for regulation of the aggregator's profit.
</dc:description>
 <dc:description>Comment: Appears in IEEE Transaction on Smart Grid</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00991</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trust Implications of DDoS Protection in Online Elections</dc:title>
 <dc:creator>Culnane, Chris</dc:creator>
 <dc:creator>Eldridge, Mark</dc:creator>
 <dc:creator>Essex, Aleksander</dc:creator>
 <dc:creator>Teague, Vanessa</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Online elections make a natural target for distributed denial of service
attacks. Election agencies wary of disruptions to voting may procure DDoS
protection services from a cloud provider. However, current DDoS detection and
mitigation methods come at the cost of significantly increased trust in the
cloud provider. In this paper we examine the security implications of
denial-of-service prevention in the context of the 2017 state election in
Western Australia, revealing a complex interaction between actors and
infrastructure extending far beyond its borders.
  Based on the publicly observable properties of this deployment, we outline
several attack scenarios including one that could allow a nation state to
acquire the credentials necessary to man-in-the-middle a foreign election in
the context of an unrelated domestic law enforcement or national security
operation, and we argue that a fundamental tension currently exists between
trust and availability in online elections.
</dc:description>
 <dc:description>Comment: Published in E-Vote-ID 2017</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00992</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Testing as an Investment</dc:title>
 <dc:creator>Xu, Xiaoran</dc:creator>
 <dc:creator>Fang, Chunrong</dc:creator>
 <dc:creator>Wu, Qing</dc:creator>
 <dc:creator>Liu, Jia</dc:creator>
 <dc:creator>Chen, Zhenyu</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Software testing is an expensive and important task. Plenty of researches and
industrial efforts have been invested on improving software testing techniques,
including criteria, tools, etc. These studies can provide guidelines to select
suitable test techniques for software engineers. However, in some engineering
projects, business issues may be more important than technical ones, hence we
need to lobby non-technical members to support our decisions. In this paper, a
well-known investment model, Nelson-Siegel model, is introduced to evaluate and
forecast the processes of testing with different testing criteria. Through this
model, we provide a new perspective to understand short-term, medium-term, and
long-term returns of investments throughout the process of testing. A
preliminary experiment is conducted to investigate three testing criteria from
the viewpoint of investments. The results show that statement-coverage
criterion performs best in gaining long-term yields; the short-term and
medium-term yields of testing depend on the scale of programs and the number of
faults they contain.
</dc:description>
 <dc:description>Comment: 6 pages, The 26th International Conference on Software Engineering
  and Knowledge Engineering (SEKE 2014)</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00993</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Linguistic Resources for Neural Machine Translation Using
  Multi-task Learning</dc:title>
 <dc:creator>Niehues, Jan</dc:creator>
 <dc:creator>Cho, Eunah</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Linguistic resources such as part-of-speech (POS) tags have been extensively
used in statistical machine translation (SMT) frameworks and have yielded
better performances. However, usage of such linguistic annotations in neural
machine translation (NMT) systems has been left under-explored.
  In this work, we show that multi-task learning is a successful and a easy
approach to introduce an additional knowledge into an end-to-end neural
attentional model. By jointly training several natural language processing
(NLP) tasks in one system, we are able to leverage common information and
improve the performance of the individual task.
  We analyze the impact of three design decisions in multi-task learning: the
tasks used in training, the training schedule, and the degree of parameter
sharing across the tasks, which is defined by the network architecture. The
experiments are conducted for an German to English translation task. As
additional linguistic resources, we exploit POS information and named-entities
(NE). Experiments show that the translation quality can be improved by up to
1.5 BLEU points under the low-resource condition. The performance of the POS
tagger is also improved using the multi-task learning scheme.
</dc:description>
 <dc:description>Comment: 9 pages, Second Conference on Machine Translation(WMT17)</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00994</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement learning techniques for Outer Loop Link Adaptation in
  4G/5G systems</dc:title>
 <dc:creator>Pulliyakode, Saishankar Katri</dc:creator>
 <dc:creator>Kalyani, Sheetal</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Wireless systems perform rate adaptation to transmit at highest possible
instantaneous rates. Rate adaptation has been increasingly granular over
generations of wireless systems. The base-station uses SINR and packet decode
feedback called acknowledgement/no acknowledgement (ACK/NACK) to perform rate
adaptation. SINR is used for rate anchoring called inner look adaptation and
ACK/NACK is used for fine offset adjustments called Outer Loop Link Adaptation
(OLLA). We cast the OLLA as a reinforcement learning problem of the class of
Multi-Armed Bandits (MAB) where the different offset values are the arms of the
bandit. In OLLA, as the offset values increase, the probability of packet error
also increase, and every user equipment (UE) has a desired Block Error Rate
(BLER) to meet certain Quality of Service (QoS) requirements. For this MAB we
propose a binary search based algorithm which achieves a Probably Approximately
Correct (PAC) solution making use of bounds from large deviation theory and
confidence bounds. In addition to this we also discuss how a Thompson sampling
or UCB based method will not help us meet the target objectives. Finally,
simulation results are provided on an LTE system simulator and thereby prove
the efficacy of our proposed algorithm.
</dc:description>
 <dc:description>Comment: There is a patent submission based on this work</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00994</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00997</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rank-metric LCD codes</dc:title>
 <dc:creator>Liu, Xiusheng</dc:creator>
 <dc:creator>Liu, Hualu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate the rank-metric codes which are proposed by
Delsarte and Gabidulin to be complementary dual codes. We point out the
relationship between Delsarte complementary dual codes and Gabidulin
complementary dual codes. In finite field $\mathbb{F}_{q}^{m}$, we construct
two classes of Gabidulin LCD MRD codes by self-dual basis (or almost self-dual
basis) of $\mathbb{F}_{q}^{m}$ over $\mathbb{F}_{q}$. Under a suitable
condition, we determine a sufficient condition for Delsarte optimal anticodes
to be LCD codes over $\mathbb{F}_{q}$.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.00999</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extreme Low Resolution Activity Recognition with Multi-Siamese Embedding
  Learning</dc:title>
 <dc:creator>Ryoo, Michael S.</dc:creator>
 <dc:creator>Kim, Kiyoon</dc:creator>
 <dc:creator>Yang, Hyun Jong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents an approach for recognition of human activities from
extreme low resolution (e.g., 16x12) videos. Extreme low resolution recognition
is not only necessary for analyzing actions at a distance but also is crucial
for enabling privacy-preserving recognition of human activities. We propose a
new approach to learn an embedding (i.e., representation) optimized for low
resolution (LR) videos by taking advantage of their inherent property: two
images originated from the exact same scene often have totally different pixel
(i.e., RGB) values dependent on their LR transformations. We designed a new
two-stream multi-Siamese convolutional neural network that learns the embedding
space to be shared by low resolution videos created with different LR
transforms, thereby enabling learning of transform-robust activity classifiers.
We experimentally confirm that our approach of jointly learning the optimal LR
video representation and the classifier outperforms the previous
state-of-the-art low resolution recognition approaches on two public standard
datasets by a meaningful margin.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.00999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01001</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Accurate Low-Bit Deep Neural Networks with Stochastic
  Quantization</dc:title>
 <dc:creator>Dong, Yinpeng</dc:creator>
 <dc:creator>Ni, Renkun</dc:creator>
 <dc:creator>Li, Jianguo</dc:creator>
 <dc:creator>Chen, Yurong</dc:creator>
 <dc:creator>Zhu, Jun</dc:creator>
 <dc:creator>Su, Hang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Low-bit deep neural networks (DNNs) become critical for embedded applications
due to their low storage requirement and computing efficiency. However, they
suffer much from the non-negligible accuracy drop. This paper proposes the
stochastic quantization (SQ) algorithm for learning accurate low-bit DNNs. The
motivation is due to the following observation. Existing training algorithms
approximate the real-valued elements/filters with low-bit representation all
together in each iteration. The quantization errors may be small for some
elements/filters, while are remarkable for others, which lead to inappropriate
gradient direction during training, and thus bring notable accuracy drop.
Instead, SQ quantizes a portion of elements/filters to low-bit with a
stochastic probability inversely proportional to the quantization error, while
keeping the other portion unchanged with full-precision. The quantized and
full-precision portions are updated with corresponding gradients separately in
each iteration. The SQ ratio is gradually increased until the whole network is
quantized. This procedure can greatly compensate the quantization error and
thus yield better accuracy for low-bit DNNs. Experiments show that SQ can
consistently and significantly improve the accuracy for different low-bit DNNs
on various datasets and various network structures.
</dc:description>
 <dc:description>Comment: BMVC 2017 Oral</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01008</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Low Rank: A Data-Adaptive Tensor Completion Method</dc:title>
 <dc:creator>Zhang, Lei</dc:creator>
 <dc:creator>Wei, Wei</dc:creator>
 <dc:creator>Shi, Qinfeng</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Hengel, Anton van den</dc:creator>
 <dc:creator>Zhang, Yanning</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Low rank tensor representation underpins much of recent progress in tensor
completion. In real applications, however, this approach is confronted with two
challenging problems, namely (1) tensor rank determination; (2) handling real
tensor data which only approximately fulfils the low-rank requirement. To
address these two issues, we develop a data-adaptive tensor completion model
which explicitly represents both the low-rank and non-low-rank structures in a
latent tensor. Representing the non-low-rank structure separately from the
low-rank one allows priors which capture the important distinctions between the
two, thus enabling more accurate modelling, and ultimately, completion. Through
defining a new tensor rank, we develop a sparsity induced prior for the
low-rank structure, with which the tensor rank can be automatically determined.
The prior for the non-low-rank structure is established based on a mixture of
Gaussians which is shown to be flexible enough, and powerful enough, to inform
the completion process for a variety of real tensor data. With these two
priors, we develop a Bayesian minimum mean squared error estimate (MMSE)
framework for inference which provides the posterior mean of missing entries as
well as their uncertainty. Compared with the state-of-the-art methods in
various applications, the proposed model produces more accurate completion
results.
</dc:description>
 <dc:description>Comment: 14 pages, 5 figures</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01009</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting Activation Regularization for Language RNNs</dc:title>
 <dc:creator>Merity, Stephen</dc:creator>
 <dc:creator>McCann, Bryan</dc:creator>
 <dc:creator>Socher, Richard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Recurrent neural networks (RNNs) serve as a fundamental building block for
many sequence tasks across natural language processing. Recent research has
focused on recurrent dropout techniques or custom RNN cells in order to improve
performance. Both of these can require substantial modifications to the machine
learning model or to the underlying RNN configurations. We revisit traditional
regularization techniques, specifically L2 regularization on RNN activations
and slowness regularization over successive hidden states, to improve the
performance of RNNs on the task of language modeling. Both of these techniques
require minimal modification to existing RNN architectures and result in
performance improvements comparable or superior to more complicated
regularization techniques or custom cell architectures. These regularization
techniques can be used without any modification on optimized LSTM
implementations such as the NVIDIA cuDNN LSTM.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01011</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Deterministic Distributed Construction of Spanners</dc:title>
 <dc:creator>Grossman, Ofer</dc:creator>
 <dc:creator>Parter, Merav</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Graph spanners are fundamental graph structures with a wide range of
applications in distributed networks. We consider a standard synchronous
message passing model where in each round $O(\log n)$ bits can be transmitted
over every edge (the CONGEST model).
  The state of the art of deterministic distributed spanner constructions
suffers from large messages. The only exception is the work of Derbel et al.
'10, which computes an optimal-sized $(2k-1)$-spanner but uses $O(n^{1-1/k})$
rounds.
  In this paper, we significantly improve this bound. We present a
deterministic distributed algorithm that given an unweighted $n$-vertex graph
$G = (V, E)$ and a parameter $k &gt; 2$, constructs a $(2k-1)$-spanner with $O(k
\cdot n^{1+1/k})$ edges within $O(2^{k} \cdot n^{1/2 - 1/k})$ rounds for every
even $k$. For odd $k$, the number of rounds is $O(2^{k} \cdot n^{1/2 -
1/(2k)})$. For the weighted case, we provide the first deterministic
construction of a $3$-spanner with $O(n^{3/2})$ edges that uses $O(\log
n)$-size messages and $\widetilde{O}(1)$ rounds. If the nodes have IDs in $[1,
\Theta(n)]$, then the algorithm works in only $2$ rounds!
</dc:description>
 <dc:description>Comment: To appear in DISC'17</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01012</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the convergence properties of a $K$-step averaging stochastic
  gradient descent algorithm for nonconvex optimization</dc:title>
 <dc:creator>Zhou, Fan</dc:creator>
 <dc:creator>Cong, Guojing</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Despite their popularity, the practical performance of asynchronous
stochastic gradient descent methods (ASGD) for solving large scale machine
learning problems are not as good as theoretical results indicate. We adopt and
analyze a synchronous K-step averaging stochastic gradient descent algorithm
which we call K-AVG. We establish the convergence results of K-AVG for
nonconvex objectives and explain why the K-step delay is necessary and leads to
better performance than traditional parallel stochastic gradient descent which
is a special case of K-AVG with $K=1$. We also show that K-AVG scales better
than ASGD. Another advantage of K-AVG over ASGD is that it allows larger
stepsizes. On a cluster of $128$ GPUs, K-AVG is faster than ASGD
implementations and achieves better accuracies and faster convergence for
\cifar dataset.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01015</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sensor Transformation Attention Networks</dc:title>
 <dc:creator>Braun, Stefan</dc:creator>
 <dc:creator>Neil, Daniel</dc:creator>
 <dc:creator>Ceolini, Enea</dc:creator>
 <dc:creator>Anumula, Jithendar</dc:creator>
 <dc:creator>Liu, Shih-Chii</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent work on encoder-decoder models for sequence-to-sequence mapping has
shown that integrating both temporal and spatial attention mechanisms into
neural networks increases the performance of the system substantially. In this
work, we report on the application of an attentional signal not on temporal and
spatial regions of the input, but instead as a method of switching among inputs
themselves. We evaluate the particular role of attentional switching in the
presence of dynamic noise in the sensors, and demonstrate how the attentional
signal responds dynamically to changing noise levels in the environment to
achieve increased performance on both audio and visual tasks in three
commonly-used datasets: TIDIGITS, Wall Street Journal, and GRID. Moreover, the
proposed sensor transformation network architecture naturally introduces a
number of advantages that merit exploration, including ease of adding new
sensors to existing architectures, attentional interpretability, and increased
robustness in a variety of noisy environments not seen during training.
Finally, we demonstrate that the sensor selection attention mechanism of a
model trained only on the small TIDIGITS dataset can be transferred directly to
a pre-existing larger network trained on the Wall Street Journal dataset,
maintaining functionality of switching between sensors to yield a dramatic
reduction of error in the presence of noise.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, 3 tables</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01018</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CRF Autoencoder for Unsupervised Dependency Parsing</dc:title>
 <dc:creator>Cai, Jiong</dc:creator>
 <dc:creator>Jiang, Yong</dc:creator>
 <dc:creator>Tu, Kewei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Unsupervised dependency parsing, which tries to discover linguistic
dependency structures from unannotated data, is a very challenging task. Almost
all previous work on this task focuses on learning generative models. In this
paper, we develop an unsupervised dependency parsing model based on the CRF
autoencoder. The encoder part of our model is discriminative and globally
normalized which allows us to use rich features as well as universal linguistic
priors. We propose an exact algorithm for parsing as well as a tractable
learning algorithm. We evaluated the performance of our model on eight
multilingual treebanks and found that our model achieved comparable performance
with state-of-the-art approaches.
</dc:description>
 <dc:description>Comment: EMNLP 2017</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01020</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Direct Vehicle-to-Vehicle Communication with Infrastructure Assistance
  in 5G Network</dc:title>
 <dc:creator>Lianghai, Ji</dc:creator>
 <dc:creator>Liu, Man</dc:creator>
 <dc:creator>Weinand, Andreas</dc:creator>
 <dc:creator>Schotten, Hans D.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Compared with today's 4G wireless communication network, the next generation
of wireless system should be able to provide a wider range of services with
different QoS requirements. One emerging new service is to exploit cooperative
driving to actively avoid accidents and improve traffic efficiency. A key
challenge for cooperative driving is on vehicle-to-vehicle (V2V) communication
which requires a high reliability and a low end-to-end (E2E) latency. In order
to meet these requirements, 5G should be evaluated by new key performance
indicators (KPIs) rather than the conventional metric, as throughput in the
legacy cellular networks. In this work, we exploit network controlled direct
V2V communication for information exchange among vehicles. This communication
process refers to packet transmission directly among vehicles without the
involvement of network infrastructure in U-plane. In order to have a network
architecture to enable direct V2V communication, the architecture of the 4G
network is enhanced by deploying a new central entity with specific
functionality for V2V communication. Moreover, a resource allocation scheme is
also specifically designed to adapt to traffic model and service requirements
of V2V communication. Last but not least, different technologies are considered
and simulated in this work to improve the performance of direct V2V
communication.
</dc:description>
 <dc:description>Comment: Accepted by IEEE 16th Annual Mediterranean Ad Hoc Networking Workshop</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01020</dc:identifier>
 <dc:identifier>2017 16th Annual Mediterranean Ad Hoc Networking Workshop
  (Med-Hoc-Net), Budva, Montenegro, pp. 1-5 (2017)</dc:identifier>
 <dc:identifier>doi:10.1109/MedHocNet.2017.8001639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01022</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When Kernel Methods meet Feature Learning: Log-Covariance Network for
  Action Recognition from Skeletal Data</dc:title>
 <dc:creator>Cavazza, Jacopo</dc:creator>
 <dc:creator>Morerio, Pietro</dc:creator>
 <dc:creator>Murino, Vittorio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Human action recognition from skeletal data is a hot research topic and
important in many open domain applications of computer vision, thanks to
recently introduced 3D sensors. In the literature, naive methods simply
transfer off-the-shelf techniques from video to the skeletal representation.
However, the current state-of-the-art is contended between to different
paradigms: kernel-based methods and feature learning with (recurrent) neural
networks. Both approaches show strong performances, yet they exhibit heavy, but
complementary, drawbacks. Motivated by this fact, our work aims at combining
together the best of the two paradigms, by proposing an approach where a
shallow network is fed with a covariance representation. Our intuition is that,
as long as the dynamics is effectively modeled, there is no need for the
classification network to be deep nor recurrent in order to score favorably. We
validate this hypothesis in a broad experimental analysis over 6 publicly
available datasets.
</dc:description>
 <dc:description>Comment: 2017 IEEE Computer Vision and Pattern Recognition (CVPR) Workshops</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01022</dc:identifier>
 <dc:identifier>doi:10.1109/CVPRW.2017.165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01023</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collusion-Secure Watermarking for Sequential Data</dc:title>
 <dc:creator>Yilmaz, Arif</dc:creator>
 <dc:creator>Ayday, Erman</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this work, we address the liability issues that may arise due to
unauthorized sharing of personal data. We consider a scenario in which an
individual shares his sequential data (such as genomic data or location
patterns) with several service providers (SPs). In such a scenario, if his data
is shared with other third parties without his consent, the individual wants to
determine the service provider that is responsible for this unauthorized
sharing. To provide this functionality, we propose a novel optimization-based
watermarking scheme for sharing of sequential data. Thus, in the case of an
unauthorized sharing of sensitive data, the proposed scheme can find the source
of the leakage by checking the watermark inside the leaked data. In particular,
the proposed schemes guarantees with a high probability that (i) the malicious
SP that receives the data cannot understand the watermarked data points, (ii)
when more than one malicious SPs aggregate their data, they still cannot
determine the watermarked data points, (iii) even if the unauthorized sharing
involves only a portion of the original data or modified data (to damage the
watermark), the corresponding malicious SP can be kept responsible for the
leakage, and (iv) the added watermark is compliant with the nature of the
corresponding data. That is, if there are inherent correlations in the data,
the added watermark still preserves such correlations. Watermarking typically
means changing certain parts of the data, and hence it may have negative
effects on data utility. The proposed scheme also minimizes such utility loss
while it provides the aforementioned security guarantees. Furthermore, we
conduct a case study of the proposed scheme on genomic data and show the
security and utility guarantees of the proposed scheme.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01034</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Will I Do Next? The Intention from Motion Experiment</dc:title>
 <dc:creator>Zunino, Andrea</dc:creator>
 <dc:creator>Cavazza, Jacopo</dc:creator>
 <dc:creator>Koul, Atesh</dc:creator>
 <dc:creator>Cavallo, Andrea</dc:creator>
 <dc:creator>Becchio, Cristina</dc:creator>
 <dc:creator>Murino, Vittorio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In computer vision, video-based approaches have been widely explored for the
early classification and the prediction of actions or activities. However, it
remains unclear whether this modality (as compared to 3D kinematics) can still
be reliable for the prediction of human intentions, defined as the overarching
goal embedded in an action sequence. Since the same action can be performed
with different intentions, this problem is more challenging but yet affordable
as proved by quantitative cognitive studies which exploit the 3D kinematics
acquired through motion capture systems. In this paper, we bridge cognitive and
computer vision studies, by demonstrating the effectiveness of video-based
approaches for the prediction of human intentions. Precisely, we propose
Intention from Motion, a new paradigm where, without using any contextual
information, we consider instantaneous grasping motor acts involving a bottle
in order to forecast why the bottle itself has been reached (to pass it or to
place in a box, or to pour or to drink the liquid inside). We process only the
grasping onsets casting intention prediction as a classification framework.
Leveraging on our multimodal acquisition (3D motion capture data and 2D optical
videos), we compare the most commonly used 3D descriptors from cognitive
studies with state-of-the-art video-based techniques. Since the two analyses
achieve an equivalent performance, we demonstrate that computer vision tools
are effective in capturing the kinematics and facing the cognitive problem of
human intention prediction.
</dc:description>
 <dc:description>Comment: 2017 IEEE Conference on Computer Vision and Pattern Recognition
  Workshops</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01034</dc:identifier>
 <dc:identifier>doi:10.1109/CVPRW.2017.7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01035</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection of Abnormal Input-Output Associations</dc:title>
 <dc:creator>Hong, Charmgil</dc:creator>
 <dc:creator>Liu, Siqi</dc:creator>
 <dc:creator>Hauskrecht, Milos</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We study a novel outlier detection problem that aims to identify abnormal
input-output associations in data, whose instances consist of multi-dimensional
input (context) and output (responses) pairs. We present our approach that
works by analyzing data in the conditional (input--output) relation space,
captured by a decomposable probabilistic model. Experimental results
demonstrate the ability of our approach in identifying multivariate conditional
outliers.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01060</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph-based Features for Automatic Online Abuse Detection</dc:title>
 <dc:creator>Papegnies, Etienne</dc:creator>
 <dc:creator>Labatut, Vincent</dc:creator>
 <dc:creator>Dufour, Richard</dc:creator>
 <dc:creator>Linares, Georges</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  While online communities have become increasingly important over the years,
the moderation of user-generated content is still performed mostly manually.
Automating this task is an important step in reducing the financial cost
associated with moderation, but the majority of automated approaches strictly
based on message content are highly vulnerable to intentional obfuscation. In
this paper, we discuss methods for extracting conversational networks based on
raw multi-participant chat logs, and we study the contribution of graph
features to a classification system that aims to determine if a given message
is abusive. The conversational graph-based system yields unexpectedly high
performance , with results comparable to those previously obtained with a
content-based approach.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01060</dc:identifier>
 <dc:identifier>5th International Conference on Statistical Language and Speech
  Processing (SLSP), 2017, Le Mans (FR), Lecture Notes in Artificial
  Intelligence vol.10583, p.70-81</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-68456-7_6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01065</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reader-Aware Multi-Document Summarization: An Enhanced Model and The
  First Dataset</dc:title>
 <dc:creator>Li, Piji</dc:creator>
 <dc:creator>Bing, Lidong</dc:creator>
 <dc:creator>Lam, Wai</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We investigate the problem of reader-aware multi-document summarization
(RA-MDS) and introduce a new dataset for this problem. To tackle RA-MDS, we
extend a variational auto-encodes (VAEs) based MDS framework by jointly
considering news documents and reader comments. To conduct evaluation for
summarization performance, we prepare a new dataset. We describe the methods
for data collection, aspect annotation, and summary writing as well as
scrutinizing by experts. Experimental results show that reader comments can
improve the summarization performance, which also demonstrates the usefulness
of the proposed dataset. The annotated dataset for RA-MDS is available online.
</dc:description>
 <dc:description>Comment: EMNLP 2017 Workshop on New Frontiers in Summarization; Dataset:
  http://www.se.cuhk.edu.hk/~textmine/dataset/ra-mds/</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01066</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Amplitude- and Frequency-based Dispersion Patterns and Entropy</dc:title>
 <dc:creator>Azami, Hamed</dc:creator>
 <dc:creator>Escudero, Javier</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Permutation patterns-based approaches, such as permutation entropy (PerEn),
have been widely and successfully used to analyze data. However, these methods
have two main shortcomings. First, when a series is symbolized based on
permutation patterns, repetition as an unavoidable phenomenon in data is not
took in to account. Second, they consider only the order of amplitude values
and so, some information regarding the amplitude values themselves may be
ignored. To address these deficiencies, we have very recently introduced
dispersion patterns and subsequently, dispersion entropy (DispEn). In this
paper, we investigate the effect of different linear and non-linear mapping
approaches, used in the algorithm of DispEn, on the characterization of
signals. We also inspect the sensitivity of different parameters of DispEn to
noise. Moreover, we introduce frequency-based DispEn (FDispEn) as a measure to
deal with only the frequency of time series. The results suggest that DispEn
and FDispEn with the log-sigmoid mapping approach, unlike PerEn, can detect
outliers. Furthermore, the original and frequency-based forbidden dispersion
patterns are introduced to discriminate deterministic from stochastic time
series. The computation times show that DispEn and FDispEn are considerably
faster than PerEn. Finally, we find that DispEn and FDispEn outperform PerEn to
distinguish various dynamics of biomedical signals. Due to their advantages
over existing entropy methods, DispEn and FDispEn are expected to be widely
used for the characterization of a wide variety of real-world time series.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01070</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal rate list decoding over bounded alphabets using
  algebraic-geometric codes</dc:title>
 <dc:creator>Guruswami, Venkatesan</dc:creator>
 <dc:creator>Xing, Chaoping</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:description>  We give new constructions of two classes of algebraic code families which are
efficiently list decodable with small output list size from a fraction
$1-R-\epsilon$ of adversarial errors where $R$ is the rate of the code, for any
desired positive constant $\epsilon$. The alphabet size depends only $\epsilon$
and is nearly-optimal.
  The first class of codes are obtained by folding algebraic-geometric codes
using automorphisms of the underlying function field. The list decoding
algorithm is based on a linear-algebraic approach, which pins down the
candidate messages to a subspace with a nice &quot;periodic&quot; structure. The list is
pruned by precoding into a special form of &quot;subspace-evasive&quot; sets, which are
constructed pseudorandomly. Instantiating this construction with the
Garcia-Stichtenoth function field tower yields codes list-decodable up to a
$1-R-\epsilon$ error fraction with list size bounded by $O(1/\epsilon)$,
matching the existential bound up to constant factors. The parameters we
achieve are thus quite close to the existential bounds in all three aspects:
error-correction radius, alphabet size, and list-size.
  The second class of codes are obtained by restricting evaluation points of an
algebraic-geometric code to rational points from a subfield. Once again, the
linear-algebraic approach to list decoding to pin down candidate messages to a
periodic subspace. We develop an alternate approach based on &quot;subspace designs&quot;
to precode messages. Together with the subsequent explicit constructions of
subspace designs, this yields a deterministic construction of an algebraic code
family of rate $R$ with efficient list decoding from $1-R-\epsilon$ fraction of
errors over a constant-sized alphabet. The list size is bounded by a very
slowly growing function of the block length $N$; in particular, it is at most
$O(\log^{(r)} N)$ (the $r$'th iterated logarithm) for any fixed integer $r$.
</dc:description>
 <dc:description>Comment: 47 pages. Extended abstracts with these results were presented at the
  2012 &amp; 2013 ACM Symposia on Theory of Computing (STOC). This is a merged and
  revised version of these conference papers, that accounts for the subsequent
  constructions of explicit subspace designs, and simplifies the construction
  of h.s.e sets. Overlaps with arXiv:1204.4209 which was the expanded version
  of the STOC'12 results</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01072</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Sparse Completely Positive Relaxation of the Modularity Maximization
  for Community Detection</dc:title>
 <dc:creator>Zhang, Junyu</dc:creator>
 <dc:creator>Liu, Haoyang</dc:creator>
 <dc:creator>Wen, Zaiwen</dc:creator>
 <dc:creator>Zhang, Shuzhong</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this paper, we consider the community detection problem under either the
stochastic block model (SBM) assumption or the degree-correlated stochastic
block model (DCSBM) assumption. The modularity maximization formulation for the
community detection problem is NP-hard in general. In this paper, we propose a
sparse and low-rank completely positive relaxation for the modularity
maximization problem, we then develop an efficient row-by-row (RBR) type block
coordinate descent (BCD) algorithm to solve the relaxation and prove an
$\mathcal{O}(1/\sqrt{N})$ convergence rate to a stationary point where $N$ is
the number of iterations. A fast rounding scheme is constructed to retrieve the
community structure from the solution. Non-asymptotic high probability bounds
on the misclassification rate are established to justify our approach. We
further develop an asynchronous parallel RBR algorithm to speed up the
convergence. Extensive numerical experiments on both synthetic and real world
networks show that the proposed approach enjoys advantages in both clustering
accuracy and numerical efficiency. Our numerical results indicate that the
newly proposed method is a quite competitive alternative for community
detection on sparse networks with over 50 million nodes.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01079</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Gram-Schmidt Walk: A Cure for the Banaszczyk Blues</dc:title>
 <dc:creator>Bansal, Nikhil</dc:creator>
 <dc:creator>Dadush, Daniel</dc:creator>
 <dc:creator>Garg, Shashwat</dc:creator>
 <dc:creator>Lovett, Shachar</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  An important result in discrepancy due to Banaszczyk states that for any set
of $n$ vectors in $\mathbb{R}^m$ of $\ell_2$ norm at most $1$ and any convex
body $K$ in $\mathbb{R}^m$ of Gaussian measure at least half, there exists a
$\pm 1$ combination of these vectors which lies in $5K$. This result implies
the best known bounds for several problems in discrepancy. Banaszczyk's proof
of this result is non-constructive and a major open problem has been to give an
efficient algorithm to find such a $\pm 1$ combination of the vectors.
  In this paper, we resolve this question and give an efficient randomized
algorithm to find a $\pm 1$ combination of the vectors which lies in $cK$ for
$c&gt;0$ an absolute constant. This leads to new efficient algorithms for several
problems in discrepancy theory.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01079</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01089</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using the SLEUTH urban growth model to simulate the impacts of future
  policy scenarios on urban land use in the Tehran metropolitan area in Iran</dc:title>
 <dc:creator>Nahavandya, Shaghayegh Kargozar</dc:creator>
 <dc:creator>Kumar, Lalit</dc:creator>
 <dc:creator>Ghamisi, Pedram</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The SLEUTH model, based on the Cellular Automata (CA), can be applied to city
development simulation in metropolitan areas. In this study the SLEUTH model
was used to model the urban expansion and predict the future possible behavior
of the urban growth in Tehran. The fundamental data were five Landsat TM and
ETM images of 1988, 1992, 1998, 2001 and 2010. Three scenarios were designed to
simulate the spatial pattern. The first scenario assumed historical
urbanization mode would persist and the only limitations for development were
height and slope. The second one was a compact scenario which makes the growth
mostly internal and limited the expansion of suburban areas. The last scenario
proposed a polycentric urban structure which let the little patches grow
without any limitation and would not consider the areas beyond the specific
buffer zone from the larger patches for development. Results showed that the
urban growth rate was greater in the first scenario in comparison with the
other two scenarios. Also it was shown that the third scenario was more
suitable for Tehran since it could avoid undesirable effects such as congestion
and pollution and was more in accordance with the conditions of Tehran city.
</dc:description>
 <dc:description>Comment: 27 pages, 6 figures, and 6 tables</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01101</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Feature Pyramids for Human Pose Estimation</dc:title>
 <dc:creator>Yang, Wei</dc:creator>
 <dc:creator>Li, Shuang</dc:creator>
 <dc:creator>Ouyang, Wanli</dc:creator>
 <dc:creator>Li, Hongsheng</dc:creator>
 <dc:creator>Wang, Xiaogang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Articulated human pose estimation is a fundamental yet challenging task in
computer vision. The difficulty is particularly pronounced in scale variations
of human body parts when camera view changes or severe foreshortening happens.
Although pyramid methods are widely used to handle scale changes at inference
time, learning feature pyramids in deep convolutional neural networks (DCNNs)
is still not well explored. In this work, we design a Pyramid Residual Module
(PRMs) to enhance the invariance in scales of DCNNs. Given input features, the
PRMs learn convolutional filters on various scales of input features, which are
obtained with different subsampling ratios in a multi-branch network. Moreover,
we observe that it is inappropriate to adopt existing methods to initialize the
weights of multi-branch networks, which achieve superior performance than plain
networks in many tasks recently. Therefore, we provide theoretic derivation to
extend the current weight initialization scheme to multi-branch network
structures. We investigate our method on two standard benchmarks for human pose
estimation. Our approach obtains state-of-the-art results on both benchmarks.
Code is available at https://github.com/bearpaw/PyraNet.
</dc:description>
 <dc:description>Comment: Submitted to ICCV 2017</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01104</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A glass-box interactive machine learning approach for solving NP-hard
  problems with the human-in-the-loop</dc:title>
 <dc:creator>Holzinger, Andreas</dc:creator>
 <dc:creator>Plass, Markus</dc:creator>
 <dc:creator>Holzinger, Katharina</dc:creator>
 <dc:creator>Crisan, Gloria Cerasela</dc:creator>
 <dc:creator>Pintea, Camelia-M.</dc:creator>
 <dc:creator>Palade, Vasile</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The goal of Machine Learning to automatically learn from data, extract
knowledge and to make decisions without any human intervention. Such automatic
(aML) approaches show impressive success. Recent results even demonstrate
intriguingly that deep learning applied for automatic classification of skin
lesions is on par with the performance of dermatologists, yet outperforms the
average. As human perception is inherently limited, such approaches can
discover patterns, e.g. that two objects are similar, in arbitrarily
high-dimensional spaces what no human is able to do. Humans can deal only with
limited amounts of data, whilst big data is beneficial for aML; however, in
health informatics, we are often confronted with a small number of data sets,
where aML suffer of insufficient training samples and many problems are
computationally hard. Here, interactive machine learning (iML) may be of help,
where a human-in-the-loop contributes to reduce the complexity of NP-hard
problems. A further motivation for iML is that standard black-box approaches
lack transparency, hence do not foster trust and acceptance of ML among
end-users. Rising legal and privacy aspects, e.g. with the new European General
Data Protection Regulations, make black-box approaches difficult to use,
because they often are not able to explain why a decision has been made. In
this paper, we present some experiments to demonstrate the effectiveness of the
human-in-the-loop approach, particularly in opening the black-box to a
glass-box and thus enabling a human directly to interact with an learning
algorithm. We selected the Ant Colony Optimization framework, and applied it on
the Traveling Salesman Problem, which is a good example, due to its relevance
for health informatics, e.g. for the study of protein folding. From studies of
how humans extract so much from so little data, fundamental ML-research also
may benefit.
</dc:description>
 <dc:description>Comment: 26 pages, 5 figures</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01106</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numerical properties of Koszul connections</dc:title>
 <dc:creator>Boyom, Michel Nguiffo</dc:creator>
 <dc:subject>Mathematics - Differential Geometry</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:subject>Mathematics - Geometric Topology</dc:subject>
 <dc:subject>Primaries 53B05, 53C12, 53C16, 22F50 . Secondaries 54U15, 55R10,
  57R22, 22E55, 18G60</dc:subject>
 <dc:description>  We use the notation EX(S&gt;M), EXF(S&gt;M) and DL(S&gt;M), where M is a smooth
manifold and S is a geometric structure. EX(S&gt;M) is the question whether S
exists in M. EXF(S&gt;M) is the question whether M admits S-foliations. DL(S&gt;M) is
the search of an invariant measuring how M is far from admitting S. For many
major geometric structures, those questions are widly open. In this paper, we
address EX(S&gt;M), EXF(S&gt;M) and DL(S&gt;M) for affine structure and symplectic
structure, left invariant affine structure, left invariant symplectic structure
and bi-invariant riemanniann structure in Lie groups
</dc:description>
 <dc:description>Comment: 115 pages, 4 figures, an appendix on information geometry. Grateful
  thanks to both Harish Chandra Research Institute (Allahabad) and Tata
  Institute of Fondamental Research (Bombai) for their hospitality</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01122</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving and Sampling with Many Solutions: Satisfiability and Other Hard
  Problems</dc:title>
 <dc:creator>Cardinal, Jean</dc:creator>
 <dc:creator>Nummenpalo, Jerri</dc:creator>
 <dc:creator>Welzl, Emo</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  We investigate parameterizing hard combinatorial problems by the size of the
solution set compared to all solution candidates. Our main result is a uniform
sampling algorithm for satisfying assignments of 2-CNF formulas that runs in
expected time $O^*(\varepsilon^{-0.617})$ where $\varepsilon$ is the fraction
of assignments that are satisfying. This improves significantly over the
trivial sampling bound of expected $\Theta^*(\varepsilon^{-1})$, and on all
previous algorithms whenever $\varepsilon = \Omega(0.708^n)$. We also consider
algorithms for 3-SAT with an $\varepsilon$ fraction of satisfying assignments,
and prove that it can be solved in $O^*(\varepsilon^{-2.27})$ deterministic
time, and in $O^*(\varepsilon^{-0.936})$ randomized time. Finally, to further
demonstrate the applicability of this framework, we also explore how similar
techniques can be used for vertex cover problems.
</dc:description>
 <dc:description>Comment: 18 pages, 1 figure</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01125</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified View-Graph Selection Framework for Structure from Motion</dc:title>
 <dc:creator>Shah, Rajvi</dc:creator>
 <dc:creator>Chari, Visesh</dc:creator>
 <dc:creator>Narayanan, P J</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  View-graph is an essential input to large-scale structure from motion (SfM)
pipelines. Accuracy and efficiency of large-scale SfM is crucially dependent on
the input view-graph. Inconsistent or inaccurate edges can lead to inferior or
wrong reconstruction. Most SfM methods remove `undesirable' images and pairs
using several, fixed heuristic criteria, and propose tailor-made solutions to
achieve specific reconstruction objectives such as efficiency, accuracy, or
disambiguation. In contrast to these disparate solutions, we propose a single
optimization framework that can be used to achieve these different
reconstruction objectives with task-specific cost modeling. We also construct a
very efficient network-flow based formulation for its approximate solution. The
abstraction brought on by this selection mechanism separates the challenges
specific to datasets and reconstruction objectives from the standard SfM
pipeline and improves its generalization. This paper demonstrates the
application of the proposed view-graph framework with standard SfM pipeline for
two particular use-cases, (i) accurate and ghost-free reconstructions of highly
ambiguous datasets using costs based on disambiguation priors, and (ii)
accurate and efficient reconstruction of large-scale Internet datasets using
costs based on commonly used priors.
</dc:description>
 <dc:description>Comment: Submitted to CVPR 2018</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01130</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient pattern matching in degenerate strings with the
  Burrows-Wheeler transform</dc:title>
 <dc:creator>Daykin, Jacqueline W.</dc:creator>
 <dc:creator>Groult, Richard</dc:creator>
 <dc:creator>Guesnet, Yannick</dc:creator>
 <dc:creator>Lecroq, Thierry</dc:creator>
 <dc:creator>Lefebvre, Arnaud</dc:creator>
 <dc:creator>L&#xe9;onard, Martine</dc:creator>
 <dc:creator>Mouchard, Laurent</dc:creator>
 <dc:creator>Prieur-Gaston, &#xc9;lise</dc:creator>
 <dc:creator>Watson, Bruce</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A degenerate or indeterminate string on an alphabet $\Sigma$ is a sequence of
non-empty subsets of $\Sigma$. Given a degenerate string $t$ of length $n$, we
present a new method based on the Burrows--Wheeler transform for searching for
a degenerate pattern of length $m$ in $t$ running in $O(mn)$ time on a constant
size alphabet $\Sigma$. Furthermore, it is a hybrid pattern-matching technique
that works on both regular and degenerate strings. A degenerate string is said
to be conservative if its number of non-solid letters is upper-bounded by a
fixed positive constant $q$; in this case we show that the search complexity
time is $O(qm^2)$. Experimental results show that our method performs well in
practice.
</dc:description>
 <dc:description>Comment: 7 pages, 1 figure</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01130</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01131</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A computer simulation of the Volga River hydrological regime: a problem
  of water-retaining dam optimal location</dc:title>
 <dc:creator>Agafonnikova, E. O.</dc:creator>
 <dc:creator>Klikunova, A. Yu.</dc:creator>
 <dc:creator>Khoperskov, A. V.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>82D15, 76A20, 76M25</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:description>  We investigate of a special dam optimal location at the Volga river in area
of the Akhtuba left sleeve beginning (7 \, km to the south of the Volga
Hydroelectric Power Station dam). We claim that a new water-retaining dam can
resolve the key problem of the Volga-Akhtuba floodplain related to insufficient
water amount during the spring flooding due to the overregulation of the Lower
Volga. By using a numerical integration of Saint-Vacant equations we study the
water dynamics across the northern part of the Volga-Akhtuba floodplain with
taking into account its actual topography. As the result we found an amount of
water $V_A$ passing to the Akhtuba during spring period for a given water flow
through the Volga Hydroelectric Power Station (so-called hydrograph which
characterises the water flow per unit of time). By varying the location of the
water-retaining dam $ x_d, y_d $ we obtained various values of $V_A (x_d, y_d)
$ as well as various flow spatial structure on the territory during the flood
period. Gradient descent method provide us the dam coordinated with the maximum
value of ${V_A}$. Such approach to the dam location choice let us to find the
best solution, that the value $V_A$ increases by a factor of 2. Our analysis
demonstrate a good potential of the numerical simulations in the field of
hydraulic works.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01131</dc:identifier>
 <dc:identifier>Bulletin of the South Ural State University, Series: Mathematical
  Modelling, Programming and Computer Software, 2017, vol.10, no.3, 148-155</dc:identifier>
 <dc:identifier>doi:10.14529/mmp170313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01135</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Long range forces in a performance portable Molecular Dynamics framework</dc:title>
 <dc:creator>Saunders, William R.</dc:creator>
 <dc:creator>Grant, James</dc:creator>
 <dc:creator>M&#xfc;ller, Eike H.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>D.2.11</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:description>  Molecular Dynamics (MD) codes predict the fundamental properties of matter by
following the trajectories of a collection of interacting model particles. To
exploit diverse modern manycore hardware, efficient codes must use all
available parallelism. At the same time they need to be portable and easily
extendible by the domain specialist (physicist/chemist) without detailed
knowledge of this hardware. To address this challenge, we recently described a
new Domain Specific Language (DSL) for the development of performance portable
MD codes based on a &quot;Separation of Concerns&quot;: a Python framework automatically
generates efficient parallel code for a range of target architectures.
  Electrostatic interactions between charged particles are important in many
physical systems and often dominate the runtime. Here we discuss the inclusion
of long-range interaction algorithms in our code generation framework. These
algorithms require global communications and careful consideration has to be
given to any impact on parallel scalability. We implemented an Ewald summation
algorithm for electrostatic forces, present scaling comparisons for different
system sizes and compare to the performance of existing codes. We also report
on further performance optimisations delivered with OpenMP shared memory
parallelism.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures, submitted to ParCo 2017 Parallel Computing
  Conference</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01135</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01139</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feedback computability on Cantor space</dc:title>
 <dc:creator>Ackerman, Nathanael L.</dc:creator>
 <dc:creator>Freer, Cameron E.</dc:creator>
 <dc:creator>Lubarsky, Robert S.</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Primary 03D65, Secondary 03C57, 03D30, 03E15</dc:subject>
 <dc:description>  We introduce the notion of feedback computable functions from $2^\omega$ to
$2^\omega$, extending feedback Turing computation in analogy with the standard
notion of computability for functions from $2^\omega$ to $2^\omega$. We then
show that the feedback computable functions are precisely the effectively Borel
functions. With this as motivation we define the notion of a feedback
computable function on a structure, independent of any coding of the structure
as a real. We show that this notion is absolute, and as an example characterize
those functions that are computable from a Gandy ordinal with some finite
subset distinguished.
</dc:description>
 <dc:description>Comment: 19 pages</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01141</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Segmentation and Disease Classification Using Cardiac Cine MR
  Images</dc:title>
 <dc:creator>Wolterink, Jelmer M.</dc:creator>
 <dc:creator>Leiner, Tim</dc:creator>
 <dc:creator>Viergever, Max A.</dc:creator>
 <dc:creator>Isgum, Ivana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Segmentation of the heart in cardiac cine MR is clinically used to quantify
cardiac function. We propose a fully automatic method for segmentation and
disease classification using cardiac cine MR images. A convolutional neural
network (CNN) was designed to simultaneously segment the left ventricle (LV),
right ventricle (RV) and myocardium in end-diastole (ED) and end-systole (ES)
images. Features derived from the obtained segmentations were used in a Random
Forest classifier to label patients as suffering from dilated cardiomyopathy,
hypertrophic cardiomyopathy, heart failure following myocardial infarction,
right ventricular abnormality, or no cardiac disease. The method was developed
and evaluated using a balanced dataset containing images of 100 patients, which
was provided in the MICCAI 2017 automated cardiac diagnosis challenge (ACDC).
The segmentation and classification pipeline were evaluated in a four-fold
stratified cross-validation. Average Dice scores between reference and
automatically obtained segmentations were 0.94, 0.88 and 0.87 for the LV, RV
and myocardium. The classifier assigned 91% of patients to the correct disease
category. Segmentation and disease classification took 5 s per patient. The
results of our study suggest that image-based diagnosis using cine MR cardiac
scans can be performed automatically with high accuracy.
</dc:description>
 <dc:description>Comment: Accepted in STACOM Automated Cardiac Diagnosis Challenge 2017</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01142</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase-error estimation and image reconstruction from digital-holography
  data using a Bayesian framework</dc:title>
 <dc:creator>Pellizzari, Casey J.</dc:creator>
 <dc:creator>Spencer, Mark F.</dc:creator>
 <dc:creator>Bouman, Charles A.</dc:creator>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The estimation of phase errors from digital-holography data is critical for
applications such as imaging or wave-front sensing. Conventional techniques
require multiple i.i.d. data and perform poorly in the presence of high noise
or large phase errors. In this paper we propose a method to estimate
isoplanatic phase errors from a single data realization. We develop a
model-based iterative reconstruction algorithm which computes the maximum a
posteriori estimate of the phase and the speckle-free object reflectance. Using
simulated data, we show that the algorithm is robust against high noise and
strong phase errors.
</dc:description>
 <dc:description>Comment: 10 pages, 8 figures</dc:description>
 <dc:date>2017-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01142</dc:identifier>
 <dc:identifier>doi:10.1364/JOSAA.34.001659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01143</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Three-dimensional planar model estimation using multi-constraint
  knowledge based on k-means and RANSAC</dc:title>
 <dc:creator>Saval-Calvo, Marcelo</dc:creator>
 <dc:creator>Azorin-Lopez, Jorge</dc:creator>
 <dc:creator>Fuster-Guillo, Andres</dc:creator>
 <dc:creator>Garcia-Rodriguez, Jose</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Plane model extraction from three-dimensional point clouds is a necessary
step in many different applications such as planar object reconstruction,
indoor mapping and indoor localization. Different RANdom SAmple Consensus
(RANSAC)-based methods have been proposed for this purpose in recent years. In
this study, we propose a novel method-based on RANSAC called Multiplane Model
Estimation, which can estimate multiple plane models simultaneously from a
noisy point cloud using the knowledge extracted from a scene (or an object) in
order to reconstruct it accurately. This method comprises two steps: first, it
clusters the data into planar faces that preserve some constraints defined by
knowledge related to the object (e.g., the angles between faces); and second,
the models of the planes are estimated based on these data using a novel
multi-constraint RANSAC. We performed experiments in the clustering and RANSAC
stages, which showed that the proposed method performed better than
state-of-the-art methods.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01143</dc:identifier>
 <dc:identifier>Applied Soft Computing, Vol. 34, p. 572-586 (2015)</dc:identifier>
 <dc:identifier>doi:10.1016/j.asoc.2015.05.007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01146</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preselection via Classification: A Case Study on Evolutionary
  Multiobjective Optimization</dc:title>
 <dc:creator>Zhang, Jinyuan</dc:creator>
 <dc:creator>Zhou, Aimin</dc:creator>
 <dc:creator>Tang, Ke</dc:creator>
 <dc:creator>Zhang, Guixu</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In evolutionary algorithms, a preselection operator aims to select the
promising offspring solutions from a candidate offspring set. It is usually
based on the estimated or real objective values of the candidate offspring
solutions. In a sense, the preselection can be treated as a classification
procedure, which classifies the candidate offspring solutions into promising
ones and unpromising ones. Following this idea, we propose a classification
based preselection (CPS) strategy for evolutionary multiobjective optimization.
When applying classification based preselection, an evolutionary algorithm
maintains two external populations (training data set) that consist of some
selected good and bad solutions found so far; then it trains a classifier based
on the training data set in each generation. Finally it uses the classifier to
filter the unpromising candidate offspring solutions and choose a promising one
from the generated candidate offspring set for each parent solution. In such
cases, it is not necessary to estimate or evaluate the objective values of the
candidate offspring solutions. The classification based preselection is applied
to three state-of-the-art multiobjective evolutionary algorithms (MOEAs) and is
empirically studied on two sets of test instances. The experimental results
suggest that classification based preselection can successfully improve the
performance of these MOEAs.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01155</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep MR to CT Synthesis using Unpaired Data</dc:title>
 <dc:creator>Wolterink, Jelmer M.</dc:creator>
 <dc:creator>Dinkla, Anna M.</dc:creator>
 <dc:creator>Savenije, Mark H. F.</dc:creator>
 <dc:creator>Seevinck, Peter R.</dc:creator>
 <dc:creator>Berg, Cornelis A. T. van den</dc:creator>
 <dc:creator>Isgum, Ivana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  MR-only radiotherapy treatment planning requires accurate MR-to-CT synthesis.
Current deep learning methods for MR-to-CT synthesis depend on pairwise aligned
MR and CT training images of the same patient. However, misalignment between
paired images could lead to errors in synthesized CT images. To overcome this,
we propose to train a generative adversarial network (GAN) with unpaired MR and
CT images. A GAN consisting of two synthesis convolutional neural networks
(CNNs) and two discriminator CNNs was trained with cycle consistency to
transform 2D brain MR image slices into 2D brain CT image slices and vice
versa. Brain MR and CT images of 24 patients were analyzed. A quantitative
evaluation showed that the model was able to synthesize CT images that closely
approximate reference CT images, and was able to outperform a GAN model trained
with paired MR and CT images.
</dc:description>
 <dc:description>Comment: MICCAI 2017 Workshop on Simulation and Synthesis in Medical Imaging</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01155</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01159</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Graph Properties to Speed-up GPU-based Graph Traversal: A
  Model-driven Approach</dc:title>
 <dc:creator>Verstraaten, Merijn</dc:creator>
 <dc:creator>Varbanescu, Ana Lucia</dc:creator>
 <dc:creator>de Laat, Cees</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  While it is well-known and acknowledged that the performance of graph
algorithms is heavily dependent on the input data, there has been surprisingly
little research to quantify and predict the impact the graph structure has on
performance. Parallel graph algorithms, running on many-core systems such as
GPUs, are no exception: most research has focused on how to efficiently
implement and tune different graph operations on a specific GPU. However, the
performance impact of the input graph has only been taken into account
indirectly as a result of the graphs used to benchmark the system.
  In this work, we present a case study investigating how to use the properties
of the input graph to improve the performance of the breadth-first search (BFS)
graph traversal. To do so, we first study the performance variation of 15
different BFS implementations across 248 graphs. Using this performance data,
we show that significant speed-up can be achieved by combining the best
implementation for each level of the traversal. To make use of this
data-dependent optimization, we must correctly predict the relative performance
of algorithms per graph level, and enable dynamic switching to the optimal
algorithm for each level at runtime.
  We use the collected performance data to train a binary decision tree, to
enable high-accuracy predictions and fast switching. We demonstrate empirically
that our decision tree is both fast enough to allow dynamic switching between
implementations, without noticeable overhead, and accurate enough in its
prediction to enable significant BFS speedup. We conclude that our model-driven
approach (1) enables BFS to outperform state of the art GPU algorithms, and (2)
can be adapted for other BFS variants, other algorithms, or more specific
datasets.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01162</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Good Applications for Crummy Entity Linkers? The Case of Corpus
  Selection in Digital Humanities</dc:title>
 <dc:creator>Olieman, Alex</dc:creator>
 <dc:creator>Beelen, Kaspar</dc:creator>
 <dc:creator>van Lange, Milan</dc:creator>
 <dc:creator>Kamps, Jaap</dc:creator>
 <dc:creator>Marx, Maarten</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Over the last decade we have made great progress in entity linking (EL)
systems, but performance may vary depending on the context and, arguably, there
are even principled limitations preventing a &quot;perfect&quot; EL system. This also
suggests that there may be applications for which current &quot;imperfect&quot; EL is
already very useful, and makes finding the &quot;right&quot; application as important as
building the &quot;right&quot; EL system. We investigate the Digital Humanities use case,
where scholars spend a considerable amount of time selecting relevant source
texts. We developed WideNet; a semantically-enhanced search tool which
leverages the strengths of (imperfect) EL without getting in the way of its
expert users. We evaluate this tool in two historical case-studies aiming to
collect a set of references to historical periods in parliamentary debates from
the last two decades; the first targeted the Dutch Golden Age, and the second
World War II. The case-studies conclude with a critical reflection on the
utility of WideNet for this kind of research, after which we outline how such a
real-world application can help to improve EL technology in general.
</dc:description>
 <dc:description>Comment: Accepted for presentation at SEMANTiCS '17</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01165</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Constructions of Permutation Polynomials of the Form
  $x^rh\left(x^{q-1}\right)$ over $\mathbb{F}_{q^2}$</dc:title>
 <dc:creator>Li, Kangquan</dc:creator>
 <dc:creator>Qu, Longjiang</dc:creator>
 <dc:creator>Wang, Qiang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>06E30, 11T06, 94A60</dc:subject>
 <dc:description>  Permutation polynomials over finite fields have been studied extensively
recently due to their wide applications in cryptography, coding theory,
communication theory, among others. Recently, several authors have studied
permutation trinomials of the form $x^rh\left(x^{q-1}\right)$ over
$\mathbb{F}_{q^2}$, where $q=2^k$, $h(x)=1+x^s+x^t$ and $r, s, t, k&gt;0$ are
integers. Their methods are essentially usage of a multiplicative version of
AGW Criterion because they all transformed the problem of proving permutation
polynomials over $\mathbb{F}_{q^2}$ into that of showing the corresponding
fractional polynomials permute a smaller set $\mu_{q+1}$, where
$\mu_{q+1}:=\{x\in\mathbb{F}_{q^2} : x^{q+1}=1\}$. Motivated by these results,
we characterize the permutation polynomials of the form
$x^rh\left(x^{q-1}\right)$ over $\mathbb{F}_{q^2}$ such that
$h(x)\in\mathbb{F}_q[x]$ is arbitrary and $q$ is also an arbitrary prime power.
Using AGW Criterion twice, one is multiplicative and the other is additive, we
reduce the problem of proving permutation polynomials over $\mathbb{F}_{q^2}$
into that of showing permutations over a small subset $S$ of a proper subfield
$\mathbb{F}_{q}$, which is significantly different from previously known
methods. In particular, we demonstrate our method by constructing many new
explicit classes of permutation polynomials of the form
$x^rh\left(x^{q-1}\right)$ over $\mathbb{F}_{q^2}$. Moreover, we can explain
most of the known permutation trinomials, which are in [6, 13, 14, 16, 20, 29],
over finite field with even characteristic.
</dc:description>
 <dc:description>Comment: 29 pages. An early version of this paper was presented at Fq13 in
  Naples, Italy</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01167</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applying advanced machine learning models to classify
  electro-physiological activity of human brain for use in biometric
  identification</dc:title>
 <dc:creator>Omelianenko, Iaroslav</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this article we present the results of our research related to the study
of correlations between specific visual stimulation and the elicited brain's
electro-physiological response collected by EEG sensors from a group of
participants. We will look at how the various characteristics of visual
stimulation affect the measured electro-physiological response of the brain and
describe the optimal parameters found that elicit a steady-state visually
evoked potential (SSVEP) in certain parts of the cerebral cortex where it can
be reliably perceived by the electrode of the EEG device. After that, we
continue with a description of the advanced machine learning pipeline model
that can perform confident classification of the collected EEG data in order to
(a) reliably distinguish signal from noise (about 85% validation score) and (b)
reliably distinguish between EEG records collected from different human
participants (about 80% validation score). Finally, we demonstrate that the
proposed method works reliably even with an inexpensive (less than $100)
consumer-grade EEG sensing device and with participants who do not have
previous experience with EEG technology (EEG illiterate). All this in
combination opens up broad prospects for the development of new types of
consumer devices, [e.g.] based on virtual reality helmets or augmented reality
glasses where EEG sensor can be easily integrated. The proposed method can be
used to improve an online user experience by providing [e.g.] password-less
user identification for VR / AR applications. It can also find a more advanced
application in intensive care units where collected EEG data can be used to
classify the level of conscious awareness of patients during anesthesia or to
automatically detect hardware failures by classifying the input signal as
noise.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01171</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Betrayal, Distrust, and Rationality: Smart Counter-Collusion Contracts
  for Verifiable Cloud Computing</dc:title>
 <dc:creator>Dong, Changyu</dc:creator>
 <dc:creator>Wang, Yilei</dc:creator>
 <dc:creator>Aldweesh, Amjad</dc:creator>
 <dc:creator>McCorry, Patrick</dc:creator>
 <dc:creator>van Moorsel, Aad</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Cloud computing has become an irreversible trend. Together comes the pressing
need for verifiability, to assure the client the correctness of computation
outsourced to the cloud. Existing verifiable computation techniques all have a
high overhead, thus if being deployed in the clouds, would render cloud
computing more expensive than the on-premises counterpart. To achieve
verifiability at a reasonable cost, we leverage game theory and propose a smart
contract based solution. In a nutshell, a client lets two clouds compute the
same task, and uses smart contracts to stimulate tension, betrayal and distrust
between the clouds, so that rational clouds will not collude and cheat. In the
absence of collusion, verification of correctness can be done easily by
crosschecking the results from the two clouds. We provide a formal analysis of
the games induced by the contracts, and prove that the contracts will be
effective under certain reasonable assumptions. By resorting to game theory and
smart contracts, we are able to avoid heavy cryptographic protocols. The client
only needs to pay two clouds to compute in the clear, and a small transaction
fee to use the smart contracts. We also conducted a feasibility study that
involves implementing the contracts in Solidity and running them on the
official Ethereum network.
</dc:description>
 <dc:description>Comment: Published in ACM CCS 2017, this is the full version with all
  appendices</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01171</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01179</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Patch-based adaptive weighting with segmentation and scale (PAWSS) for
  visual tracking</dc:title>
 <dc:creator>Du, Xiaofei</dc:creator>
 <dc:creator>Dore, Alessio</dc:creator>
 <dc:creator>Stoyanov, Danail</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Tracking-by-detection algorithms are widely used for visual tracking, where
the problem is treated as a classification task where an object model is
updated over time using online learning techniques. In challenging conditions
where an object undergoes deformation or scale variations, the update step is
prone to include background information in the model appearance or to lack the
ability to estimate the scale change, which degrades the performance of the
classifier. In this paper, we incorporate a Patch-based Adaptive Weighting with
Segmentation and Scale (PAWSS) tracking framework that tackles both the scale
and background problems. A simple but effective colour-based segmentation model
is used to suppress background information and multi-scale samples are
extracted to enrich the training pool, which allows the tracker to handle both
incremental and abrupt scale variations between frames. Experimentally, we
evaluate our approach on the online tracking benchmark (OTB) dataset and Visual
Object Tracking (VOT) challenge datasets. The results show that our approach
outperforms recent state-of-the-art trackers, and it especially improves the
successful rate score on the OTB dataset, while on the VOT datasets, PAWSS
ranks among the top trackers while operating at real-time frame rates.
</dc:description>
 <dc:description>Comment: 10 pages, 8 figures. The paper is under consideration at Pattern
  Recognition Letters</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01183</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Power Allocation Scheme for Non-Orthogonal Multiple Access with
  $\alpha$-Fairness</dc:title>
 <dc:creator>Xu, Peng</dc:creator>
 <dc:creator>Cumanan, Kanapathippillai</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates the optimal power allocation scheme for sum
throughput maximization of non-orthogonal multiple access (NOMA) system with
$\alpha$-fairness. In contrast to the existing fairness NOMA models,
$\alpha$-fairness can only utilize a single scalar to achieve different user
fairness levels. Two different channel state information at the transmitter
(CSIT) assumptions are considered, namely, statistical and perfect CSIT. For
statistical CSIT, fixed target data rates are predefined, and the power
allocation problem is solved for sum throughput maximization with
$\alpha$-fairness, through characterizing several properties of the optimal
power allocation solution. For perfect CSIT, the optimal power allocation is
determined to maximize the instantaneous sum rate with $\alpha$-fairness, where
user rates are adapted according to the instantaneous channel state information
(CSI). In particular, a simple alternate optimization (AO) algorithm is
proposed, which is demonstrated to yield the optimal solution. Numerical
results reveal that, at the same fairness level, NOMA significantly outperforms
the conventional orthogonal multiple access (MA) for both the scenarios with
statistical and perfect CSIT.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01183</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01191</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Video Understanding by Reconciliation of Posture
  Similarities</dc:title>
 <dc:creator>Milbich, Timo</dc:creator>
 <dc:creator>Bautista, Miguel</dc:creator>
 <dc:creator>Sutter, Ekaterina</dc:creator>
 <dc:creator>Ommer, Bjorn</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Understanding human activity and being able to explain it in detail surpasses
mere action classification by far in both complexity and value. The challenge
is thus to describe an activity on the basis of its most fundamental
constituents, the individual postures and their distinctive transitions.
Supervised learning of such a fine-grained representation based on elementary
poses is very tedious and does not scale. Therefore, we propose a completely
unsupervised deep learning procedure based solely on video sequences, which
starts from scratch without requiring pre-trained networks, predefined body
models, or keypoints. A combinatorial sequence matching algorithm proposes
relations between frames from subsets of the training data, while a CNN is
reconciling the transitivity conflicts of the different subsets to learn a
single concerted pose embedding despite changes in appearance across sequences.
Without any manual annotation, the model learns a structured representation of
postures and their temporal development. The model not only enables retrieval
of similar postures but also temporal super-resolution. Additionally, based on
a recurrent formulation, next frames can be synthesized.
</dc:description>
 <dc:description>Comment: Accepted by ICCV 2017</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01198</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating speech from lip dynamics</dc:title>
 <dc:creator>George, Jithin Donny</dc:creator>
 <dc:creator>Keane, Ronan</dc:creator>
 <dc:creator>Zellmer, Conor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The goal of this project is to develop a limited lip reading algorithm for a
subset of the English language. We consider a scenario in which no audio
information is available. The raw video is processed and the position of the
lips in each frame is extracted. We then prepare the lip data for processing
and classify the lips into visemes and phonemes. Hidden Markov Models are used
to predict the words the speaker is saying based on the sequences of classified
phonemes and visemes. The GRID audiovisual sentence corpus [10][11] database is
used for our study.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01204</identifier>
 <datestamp>2017-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Speech Reconstruction from Silent Video</dc:title>
 <dc:creator>Ephrat, Ariel</dc:creator>
 <dc:creator>Halperin, Tavi</dc:creator>
 <dc:creator>Peleg, Shmuel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Speechreading is the task of inferring phonetic information from visually
observed articulatory facial movements, and is a notoriously difficult task for
humans to perform. In this paper we present an end-to-end model based on a
convolutional neural network (CNN) for generating an intelligible and
natural-sounding acoustic speech signal from silent video frames of a speaking
person. We train our model on speakers from the GRID and TCD-TIMIT datasets,
and evaluate the quality and intelligibility of reconstructed speech using
common objective measurements. We show that speech predictions from the
proposed model attain scores which indicate significantly improved quality over
existing models. In addition, we show promising results towards reconstructing
speech from an unconstrained dictionary.
</dc:description>
 <dc:description>Comment: Accepted to ICCV 2017 Workshop on Computer Vision for Audio-Visual
  Media. Supplementary video: https://www.youtube.com/watch?v=Xjbn7h7tpg0.
  arXiv admin note: text overlap with arXiv:1701.00495</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:date>2017-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01208</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Augmented Reality Environment with Material-Aware Physical
  Interactions</dc:title>
 <dc:creator>Chen, Long</dc:creator>
 <dc:creator>Francis, Karl</dc:creator>
 <dc:creator>Tang, Wen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In Augmented Reality (AR) environment, realistic interactions between the
virtual and real objects play a crucial role in user experience. Much of recent
advances in AR has been largely focused on developing geometry-aware
environment, but little has been done in dealing with interactions at the
semantic level. High-level scene understanding and semantic descriptions in AR
would allow effective design of complex applications and enhanced user
experience. In this paper, we present a novel approach and a prototype system
that enables the deeper understanding of semantic properties of the real world
environment, so that realistic physical interactions between the real and the
virtual objects can be generated. A material-aware AR environment has been
created based on the deep material learning using a fully convolutional network
(FCN). The state-of-the-art dense Simultaneous Localisation and Mapping (SLAM)
has been used for the semantic mapping. Together with efficient accelerated 3D
ray casting, natural and realistic physical interactions are generated for
interactive AR games. Our approach has significant impact on the future
development of advanced AR systems and applications.
</dc:description>
 <dc:description>Comment: ISMAR 2017 Poster</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01208</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01212</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polynomial tuning of multiparametric combinatorial samplers</dc:title>
 <dc:creator>Bendkowski, Maciej</dc:creator>
 <dc:creator>Bodini, Olivier</dc:creator>
 <dc:creator>Dovgal, Sergey</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Boltzmann samplers and the recursive method are prominent algorithmic
frameworks for the approximate-size and exact-size random generation of large
combinatorial structures, such as maps, tilings, RNA sequences or various
tree-like structures. In their multiparametric variants, these samplers allow
to control the profile of expected values corresponding to multiple
combinatorial parameters. One can control, for instance, the number of leaves,
profile of node degrees in trees or the number of certain subpatterns in
strings. However, such a flexible control requires an additional non-trivial
tuning procedure. In this paper, we propose an efficient polynomial-time, with
respect to the number of tuned parameters, tuning algorithm based on convex
optimisation techniques. Finally, we illustrate the efficiency of our approach
using several applications of rational, algebraic and P\'olya structures
including polyomino tilings with prescribed tile frequencies, planar trees with
a given specific node degree distribution, and weighted partitions.
</dc:description>
 <dc:description>Comment: Extended abstract, accepted to ANALCO2018. 20 pages, 6 figures,
  colours. Implementation and examples are available at [1]
  https://github.com/maciej-bendkowski/boltzmann-brain [2]
  https://github.com/maciej-bendkowski/multiparametric-combinatorial-samplers</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01225</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recent Developments and Future Challenges in Medical Mixed Reality</dc:title>
 <dc:creator>Chen, Long</dc:creator>
 <dc:creator>Day, Thomas</dc:creator>
 <dc:creator>Tang, Wen</dc:creator>
 <dc:creator>John, Nigel W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Mixed Reality (MR) is of increasing interest within technology-driven modern
medicine but is not yet used in everyday practice. This situation is changing
rapidly, however, and this paper explores the emergence of MR technology and
the importance of its utility within medical applications. A classification of
medical MR has been obtained by applying an unbiased text mining method to a
database of 1,403 relevant research papers published over the last two decades.
The classification results reveal a taxonomy for the development of medical MR
research during this period as well as suggesting future trends. We then use
the classification to analyse the technology and applications developed in the
last five years. Our objective is to aid researchers to focus on the areas
where technology advancements in medical MR are most needed, as well as
providing medical practitioners with a useful source of reference.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01226</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting LTE-Advanced HetNets and FeICIC for UAV-assisted Public
  Safety Communications</dc:title>
 <dc:creator>Kumbhar, Abhaykumar</dc:creator>
 <dc:creator>Guvenc, Ismail</dc:creator>
 <dc:creator>Singh, Simran</dc:creator>
 <dc:creator>Tuncer, Adem</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Ensuring ubiquitous mission-critical public safety communications (PSC) to
all the first responders in the public safety network (PSN) is crucial at an
emergency site. Recently, the use of unmanned aerial vehicles (UAVs) has
received extensive interest for PSC to fill the coverage holes and establish
reliable connectivity. The UAVs can be deployed as unmanned aerial base
stations (UABSs) as part of a heterogeneous network (HetNet) PSC
infrastructure. In this article, we address the inter-cell interference
limiting factor in LTE-Advanced HetNets by applying 3GPP Release-11
further-enhanced inter-cell interference coordination (FeICIC) and cell range
expansion (CRE) to enhance the system-wide spectral efficiency (SE). Through
simulation with different path-loss models, we compare the system-wide 5th
percentile SE when UABSs are deployed in a hexagonal grid and when their
locations are optimized using a genetic algorithm, while also jointly
optimizing the CRE and the FeICIC parameters. Our results show that at
optimized UABS locations, the 3GPP Release-11 FeICIC with reduced power
subframes can provide considerably better 5th percentile SE than the 3GPP
Release-10 with almost blank subframes
</dc:description>
 <dc:description>Comment: IEEE Access Mission Critical Public-Safety Communications:
  Architectures, Enabling Technologies, and Future Applications 2017</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01226</dc:identifier>
 <dc:identifier>doi:10.1109/ACCESS.2017.2776120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01227</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Autoencoder based Domain Adaptation for Speaker Recognition under
  Insufficient Channel Information</dc:title>
 <dc:creator>Shon, Suwon</dc:creator>
 <dc:creator>Mun, Seongkyu</dc:creator>
 <dc:creator>Kim, Wooil</dc:creator>
 <dc:creator>Ko, Hanseok</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  In real-life conditions, mismatch between development and test domain
degrades speaker recognition performance. To solve the issue, many researchers
explored domain adaptation approaches using matched in-domain dataset. However,
adaptation would be not effective if the dataset is insufficient to estimate
channel variability of the domain. In this paper, we explore the problem of
performance degradation under such a situation of insufficient channel
information. In order to exploit limited in-domain dataset effectively, we
propose an unsupervised domain adaptation approach using Autoencoder based
Domain Adaptation (AEDA). The proposed approach combines an autoencoder with a
denoising autoencoder to adapt resource-rich development dataset to test
domain. The proposed technique is evaluated on the Domain Adaptation Challenge
13 experimental protocols that is widely used in speaker recognition for domain
mismatched condition. The results show significant improvements over baselines
and results from other prior studies.
</dc:description>
 <dc:description>Comment: Interspeech 2017, pp 1014-1018</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01227</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01232</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recursive Whitening Transformation for Speaker Recognition on Language
  Mismatched Condition</dc:title>
 <dc:creator>Shon, Suwon</dc:creator>
 <dc:creator>Mun, Seongkyu</dc:creator>
 <dc:creator>Ko, Hanseok</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Recently in speaker recognition, performance degradation due to the channel
domain mismatched condition has been actively addressed. However, the
mismatches arising from language is yet to be sufficiently addressed. This
paper proposes an approach which employs recursive whitening transformation to
mitigate the language mismatched condition. The proposed method is based on the
multiple whitening transformation, which is intended to remove un-whitened
residual components in the dataset associated with i-vector length
normalization. The experiments were conducted on the Speaker Recognition
Evaluation 2016 trials of which the task is non-English speaker recognition
using development dataset consist of both a large scale out-of-domain (English)
dataset and an extremely low-quantity in-domain (non-English) dataset. For
performance comparison, we develop a state-of- the-art system using deep neural
network and bottleneck feature, which is based on a phonetically aware model.
From the experimental results, along with other prior studies, effectiveness of
the proposed method on language mismatched condition is validated.
</dc:description>
 <dc:description>Comment: Interspeech 2017, pp 2869-2873</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01233</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Equidistant Polarizing Transforms</dc:title>
 <dc:creator>Kahraman, Sinan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents a non-binary polar coding scheme that can reach the
equidistant distant spectrum bound for discrete memoryless channels. This is
the best that can be reached up to now and is tight for additive white Gaussian
channels. To do this, we first define the equidistant property for the
polarizing transforms. We have designed transforms that have better distance
characteristics using a simple procedure for signal sets. Furthermore, we
designed a new four-component signal set in two dimensions to define the
equidistant transform for q = 4. We follow Sasoglu's work, which introduces
polarizing transforms of all channels for any input alphabet size and defines
some constraints to avoid a polarization anomaly. Alternatively, we removed the
negative effect of the anomaly on polarization by using transforms with
appropriate distance properties. Finally, the speed of polarization is
significantly increased by using the proposed transforms with better distance
characteristics. Moreover, we show improvement in error performance.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01234</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-time Geometry-Aware Augmented Reality in Minimally Invasive Surgery</dc:title>
 <dc:creator>Chen, Long</dc:creator>
 <dc:creator>Tang, Wen</dc:creator>
 <dc:creator>John, Nigel W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The potential of Augmented Reality (AR) technology to assist minimally
invasive surgeries (MIS) lies in its computational performance and accuracy in
dealing with challenging MIS scenes. Even with the latest hardware and software
technologies, achieving both real-time and accurate augmented information
overlay in MIS is still a formidable task. In this paper, we present a novel
real-time AR framework for MIS that achieves interactive geometric aware
augmented reality in endoscopic surgery with stereo views. Our framework tracks
the movement of the endoscopic camera and simultaneously reconstructs a dense
geometric mesh of the MIS scene. The movement of the camera is predicted by
minimising the re-projection error to achieve a fast tracking performance,
while the 3D mesh is incrementally built by a dense zero mean normalised cross
correlation stereo matching method to improve the accuracy of the surface
reconstruction. Our proposed system does not require any prior template or
pre-operative scan and can infer the geometric information intra-operatively in
real-time. With the geometric information available, our proposed AR framework
is able to interactively add annotations, localisation of tumours and vessels,
and measurement labelling with greater precision and accuracy compared with the
state of the art approaches.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01236</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiscale mixing patterns in networks</dc:title>
 <dc:creator>Peel, Leto</dc:creator>
 <dc:creator>Delvenne, Jean-Charles</dc:creator>
 <dc:creator>Lambiotte, Renaud</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Assortative mixing in networks is the tendency for nodes with the same
attributes, or metadata, to link to each other. It is a property often found in
social networks manifesting as a higher tendency of links occurring between
people with the same age, race, or political belief. Quantifying the level of
assortativity or disassortativity (the preference of linking to nodes with
different attributes) can shed light on the factors involved in the formation
of links and contagion processes in complex networks. It is common practice to
measure the level of assortativity according to the assortativity coefficient,
or modularity in the case of discrete-valued metadata. This global value is the
average level of assortativity across the network and may not be a
representative statistic when mixing patterns are heterogeneous. For example, a
social network spanning the globe may exhibit local differences in mixing
patterns as a consequence of differences in cultural norms. Here, we introduce
an approach to localise this global measure so that we can describe the
assortativity, across multiple scales, at the node level. Consequently we are
able to capture and qualitatively evaluate the distribution of mixing patterns
in the network. We find that for many real-world networks the distribution of
assortativity is skewed, overdispersed and multimodal. Our method provides a
clearer lens through which we can more closely examine mixing patterns in
networks.
</dc:description>
 <dc:description>Comment: 11 pages, 7 figures</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01236</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01241</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DSOD: Learning Deeply Supervised Object Detectors from Scratch</dc:title>
 <dc:creator>Shen, Zhiqiang</dc:creator>
 <dc:creator>Liu, Zhuang</dc:creator>
 <dc:creator>Li, Jianguo</dc:creator>
 <dc:creator>Jiang, Yu-Gang</dc:creator>
 <dc:creator>Chen, Yurong</dc:creator>
 <dc:creator>Xue, Xiangyang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present Deeply Supervised Object Detector (DSOD), a framework that can
learn object detectors from scratch. State-of-the-art object objectors rely
heavily on the off-the-shelf networks pre-trained on large-scale classification
datasets like ImageNet, which incurs learning bias due to the difference on
both the loss functions and the category distributions between classification
and detection tasks. Model fine-tuning for the detection task could alleviate
this bias to some extent but not fundamentally. Besides, transferring
pre-trained models from classification to detection between discrepant domains
is even more difficult (e.g. RGB to depth images). A better solution to tackle
these two critical problems is to train object detectors from scratch, which
motivates our proposed DSOD. Previous efforts in this direction mostly failed
due to much more complicated loss functions and limited training data in object
detection. In DSOD, we contribute a set of design principles for training
object detectors from scratch. One of the key findings is that deep
supervision, enabled by dense layer-wise connections, plays a critical role in
learning a good detector. Combining with several other principles, we develop
DSOD following the single-shot detection (SSD) framework. Experiments on PASCAL
VOC 2007, 2012 and MS COCO datasets demonstrate that DSOD can achieve better
results than the state-of-the-art solutions with much more compact models. For
instance, DSOD outperforms SSD on all three benchmarks with real-time detection
speed, while requires only 1/2 parameters to SSD and 1/10 parameters to Faster
RCNN. Our code and models are available at: https://github.com/szq0214/DSOD .
</dc:description>
 <dc:description>Comment: ICCV 2017. Code and models are available at:
  https://github.com/szq0214/DSOD</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01241</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01244</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image reconstruction with imperfect forward models and applications in
  deblurring</dc:title>
 <dc:creator>Korolev, Yury</dc:creator>
 <dc:creator>Lellmann, Jan</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>65J20, 94A08, 49N45, 49N30</dc:subject>
 <dc:description>  We present and analyse an approach to image reconstruction problems with
imperfect forward models based on partially ordered spaces - Banach lattices.
In this approach, errors in the data and in the forward models are described
using order intervals. The method can be characterised as the lattice analogue
of the residual method, where the feasible set is defined by linear inequality
constraints. The study of this feasible set is the main contribution of this
paper. Convexity of this feasible set is examined in several settings and
modifications for introducing additional information about the forward operator
are considered. Numerical examples demonstrate the performance of the method in
deblurring with errors in the blurring kernel.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-10-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01246</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Representation Learning by Sorting Sequences</dc:title>
 <dc:creator>Lee, Hsin-Ying</dc:creator>
 <dc:creator>Huang, Jia-Bin</dc:creator>
 <dc:creator>Singh, Maneesh</dc:creator>
 <dc:creator>Yang, Ming-Hsuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present an unsupervised representation learning approach using videos
without semantic labels. We leverage the temporal coherence as a supervisory
signal by formulating representation learning as a sequence sorting task. We
take temporally shuffled frames (i.e., in non-chronological order) as inputs
and train a convolutional neural network to sort the shuffled sequences.
Similar to comparison-based sorting algorithms, we propose to extract features
from all frame pairs and aggregate them to predict the correct order. As
sorting shuffled image sequence requires an understanding of the statistical
temporal structure of images, training with such a proxy task allows us to
learn rich and generalizable visual representation. We validate the
effectiveness of the learned representation using our method as pre-training on
high-level recognition problems. The experimental results show that our method
compares favorably against state-of-the-art methods on action recognition,
image classification and object detection tasks.
</dc:description>
 <dc:description>Comment: ICCV 2017. Project page: http://vllab1.ucmerced.edu/~hylee/OPN/</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01246</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01249</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>L1-norm Principal-Component Analysis of Complex Data</dc:title>
 <dc:creator>Tsagkarakis, Nicholas</dc:creator>
 <dc:creator>Markopoulos, Panos P.</dc:creator>
 <dc:creator>Pados, Dimitris A.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  L1-norm Principal-Component Analysis (L1-PCA) of real-valued data has
attracted significant research interest over the past decade. However, L1-PCA
of complex-valued data remains to date unexplored despite the many possible
applications (e.g., in communication systems). In this work, we establish
theoretical and algorithmic foundations of L1-PCA of complex-valued data
matrices. Specifically, we first show that, in contrast to the real-valued case
for which an optimal polynomial-cost algorithm was recently reported by
Markopoulos et al., complex L1-PCA is formally NP-hard in the number of data
points. Then, casting complex L1-PCA as a unimodular optimization problem, we
present the first two suboptimal algorithms in the literature for its solution.
Our experimental studies illustrate the sturdy resistance of complex L1-PCA
against faulty measurements/outliers in the processed data.
</dc:description>
 <dc:description>Comment: This draft is a preprint. In case you identify a typographical error,
  please contact the corresponding author</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01267</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Viewing Robot Navigation in Human Environment as a Cooperative Activity</dc:title>
 <dc:creator>Khambhaita, Harmish</dc:creator>
 <dc:creator>Alami, Rachid</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We claim that navigation in human environments can be viewed as cooperative
activity especially in constrained situations. Humans concurrently aid and
comply with each other while moving in a shared space. Cooperation helps
pedestrians to efficiently reach their own goals and respect conventions such
as the personal space of others. To meet human comparable efficiency, a robot
needs to predict the human trajectories and plan its own trajectory
correspondingly in the same shared space. In this work, we present a navigation
planner that is able to plan such cooperative trajectories, simultaneously
enforcing the robot's kinematic constraints and avoiding other non-human
dynamic obstacles. Using robust social constraints of projected time to a
possible future collision, compatibility of human-robot motion direction, and
proxemics, our planner is able to replicate human-like navigation behavior not
only in open spaces but also in confined areas. Besides adapting the robot
trajectory, the planner is also able to proactively propose co-navigation
solutions by jointly computing human and robot trajectories within the same
optimization framework. We demonstrate richness and performance of the
cooperative planner with simulated and real world experiments on multiple
interactive navigation scenarios.
</dc:description>
 <dc:description>Comment: 18 pages, 6 figures, ISRR 2017 submission</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01285</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proof of Work Without All the Work</dc:title>
 <dc:creator>Gupta, Diksha</dc:creator>
 <dc:creator>Saia, Jared</dc:creator>
 <dc:creator>Young, Maxwell</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Proof-of-work (PoW) is a popular algorithmic tool used to enhance network
security by imposing a computational cost on participating devices.
Unfortunately, traditional PoW schemes require that correct devices work
perpetually in order to remain vigilant against possible malicious behavior. In
other words, computational costs are unbounded regardless of whether the
network is under attack. This shortcoming is highlighted by recent studies
showing that PoW is highly inefficient with respect to operating cost and
ecological footprint.
  We address this issue by designing a general PoW scheme for securing open
distributed systems, whereby the cost to devices grows slowly as a function of
the cost incurred by an attacker. Consequently, if the network is attacked, our
scheme guarantees security, with algorithmic costs that are commensurate with
the cost of the attacker. Conversely, in the absence of attack, algorithmic
costs are small.
  Our results hold in a dynamic system where participants join and depart over
time. We demonstrate how our PoW scheme can be leveraged to address important
security problems in distributed computing including: Sybil attacks, Byzantine
consensus, and Committee election.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01285</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01286</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Metadata in the BioSample Online Repository are Impaired by Numerous
  Anomalies</dc:title>
 <dc:creator>Gon&#xe7;alves, Rafael S.</dc:creator>
 <dc:creator>O'Connor, Martin J.</dc:creator>
 <dc:creator>Mart&#xed;nez-Romero, Marcos</dc:creator>
 <dc:creator>Graybeal, John</dc:creator>
 <dc:creator>Musen, Mark A.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The metadata about scientific experiments are crucial for finding,
reproducing, and reusing the data that the metadata describe. We present a
study of the quality of the metadata stored in BioSample--a repository of
metadata about samples used in biomedical experiments managed by the U.S.
National Center for Biomedical Technology Information (NCBI). We tested whether
6.6 million BioSample metadata records are populated with values that fulfill
the stated requirements for such values. Our study revealed multiple anomalies
in the analyzed metadata. The BioSample metadata field names and their values
are not standardized or controlled--15% of the metadata fields use field names
not specified in the BioSample data dictionary. Only 9 out of 452
BioSample-specified fields ordinarily require ontology terms as values, and the
quality of these controlled fields is better than that of uncontrolled ones, as
even simple binary or numeric fields are often populated with inadequate values
of different data types (e.g., only 27% of Boolean values are valid). Overall,
the metadata in BioSample reveal that there is a lack of principled mechanisms
to enforce and validate metadata requirements. The aberrancies in the metadata
are likely to impede search and secondary use of the associated datasets.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01286</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01289</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Independently Controllable Factors</dc:title>
 <dc:creator>Thomas, Valentin</dc:creator>
 <dc:creator>Pondard, Jules</dc:creator>
 <dc:creator>Bengio, Emmanuel</dc:creator>
 <dc:creator>Sarfati, Marc</dc:creator>
 <dc:creator>Beaudoin, Philippe</dc:creator>
 <dc:creator>Meurs, Marie-Jean</dc:creator>
 <dc:creator>Pineau, Joelle</dc:creator>
 <dc:creator>Precup, Doina</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  It has been postulated that a good representation is one that disentangles
the underlying explanatory factors of variation. However, it remains an open
question what kind of training framework could potentially achieve that.
Whereas most previous work focuses on the static setting (e.g., with images),
we postulate that some of the causal factors could be discovered if the learner
is allowed to interact with its environment. The agent can experiment with
different actions and observe their effects. More specifically, we hypothesize
that some of these factors correspond to aspects of the environment which are
independently controllable, i.e., that there exists a policy and a learnable
feature for each such aspect of the environment, such that this policy can
yield changes in that feature with minimal changes to other features that
explain the statistical variations in the observed data. We propose a specific
objective function to find such factors and verify experimentally that it can
indeed disentangle independently controllable aspects of the environment
without any extrinsic reward signal.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01289</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01292</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What your Facebook Profile Picture Reveals about your Personality</dc:title>
 <dc:creator>Segalin, Cristina</dc:creator>
 <dc:creator>Celli, Fabio</dc:creator>
 <dc:creator>Polonio, Luca</dc:creator>
 <dc:creator>Kosinski, Michal</dc:creator>
 <dc:creator>Stillwell, David</dc:creator>
 <dc:creator>Sebe, Nicu</dc:creator>
 <dc:creator>Cristani, Marco</dc:creator>
 <dc:creator>Lepri, Bruno</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>H.4.m</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  People spend considerable effort managing the impressions they give others.
Social psychologists have shown that people manage these impressions
differently depending upon their personality. Facebook and other social media
provide a new forum for this fundamental process; hence, understanding people's
behaviour on social media could provide interesting insights on their
personality. In this paper we investigate automatic personality recognition
from Facebook profile pictures. We analyze the effectiveness of four families
of visual features and we discuss some human interpretable patterns that
explain the personality traits of the individuals. For example, extroverts and
agreeable individuals tend to have warm colored pictures and to exhibit many
faces in their portraits, mirroring their inclination to socialize; while
neurotic ones have a prevalence of pictures of indoor places. Then, we propose
a classification approach to automatically recognize personality traits from
these visual features. Finally, we compare the performance of our
classification approach to the one obtained by human raters and we show that
computer-based classifications are significantly more accurate than averaged
human-based classifications for Extraversion and Neuroticism.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01292</dc:identifier>
 <dc:identifier>doi:10.1145/3123266.3123331</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01295</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Designing A Questionnaire Based Legacy-UI Honeyword Generation
  Approach For Achieving Flatness</dc:title>
 <dc:creator>Chakraborty, Nilesh</dc:creator>
 <dc:creator>Singh, Shreya</dc:creator>
 <dc:creator>Mondal, Samrat</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Modern trend sees a lot usage of \textit{honeywords} (or fake password) for
protecting the original passwords in the password file. However, the usage of
\textit{honeywords} has strongly been criticized under the different security
and usability parameters. Though many of these issues have been successfully
resolved, research in this domain is still facing difficulties in
\textit{achieving flatness} (or producing the equally probable
\textit{honeywords} with reference to the original password). Though recent
studies have made a significant effort to meet this criterion, we show that
they either fall short or are based on some unrealistic assumptions. To
practically fulfill this flatness criterion, we propose a
questionnaire-oriented authentication system based on the episodic (or long
term) memory of the users. Our study reveals that proposed mechanism is capable
of generating significantly improved flatter list of \textit{honeywords}
compared to the existing protocols. The subsequent discussion shows that the
proposed system also overcomes all the limitations of the existing state of
arts with no lesser than $95\%$ goodness.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01295</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01298</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effective sketching methods for value function approximation</dc:title>
 <dc:creator>Pan, Yangchen</dc:creator>
 <dc:creator>Azer, Erfan Sadeqi</dc:creator>
 <dc:creator>White, Martha</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  High-dimensional representations, such as radial basis function networks or
tile coding, are common choices for policy evaluation in reinforcement
learning. Learning with such high-dimensional representations, however, can be
expensive, particularly for matrix methods, such as least-squares temporal
difference learning or quasi-Newton methods that approximate matrix step-sizes.
In this work, we explore the utility of sketching for these two classes of
algorithms. We highlight issues with sketching the high-dimensional features
directly, which can incur significant bias. As a remedy, we demonstrate how to
use sketching more sparingly, with only a left-sided sketch, that can still
enable significant computational gains and the use of these matrix-based
learning algorithms that are less sensitive to parameters. We empirically
investigate these algorithms, in four domains with a variety of
representations. Our aim is to provide insights into effective use of sketching
in practice.
</dc:description>
 <dc:description>Comment: Conference on Uncertainty in Artificial Intelligence (UAI) 2017</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01298</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01302</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A solution for ARP spoofing: Layer-2 MAC and protocol filtering and
  arpserver</dc:title>
 <dc:creator>Arslan, Yuksel</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Most attacks are launched inside the companies by the employees of the same
company. These kinds of attacks are generally against layer-2, not against
layer-3 or IP. These attacks abuse the switch operation at layer-2. One of the
attacks of this kind is Address Resolution Protocol (ARP) Spoofing (sometimes
it is called ARP poisoning). This attack is classified as the 'man in the
middle' (MITM) attack. The usual security systems such as (personal) firewalls
or virus protection software can not recognize this type of attack. Taping into
the communication between two hosts one can access the confidential data.
Malicious software to run internal attacks on a network is freely available on
the Internet, such as Ettercap. In this paper a solution is proposed and
implemented to prevent ARP Spoofing. In this proposal access control lists
(ACL) for layer-2 Media Access Control (MAC) address and protocol filtering and
an application called ARPserver which will reply all ARP requests are used.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01304</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preparing HPC Applications for the Exascale Era: A Decoupling Strategy</dc:title>
 <dc:creator>Peng, Ivy Bo</dc:creator>
 <dc:creator>Gioiosa, Roberto</dc:creator>
 <dc:creator>Kestor, Gokcen</dc:creator>
 <dc:creator>Laure, Erwin</dc:creator>
 <dc:creator>Markidis, Stefano</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Production-quality parallel applications are often a mixture of diverse
operations, such as computation- and communication-intensive, regular and
irregular, tightly coupled and loosely linked operations. In conventional
construction of parallel applications, each process performs all the
operations, which might result inefficient and seriously limit scalability,
especially at large scale. We propose a decoupling strategy to improve the
scalability of applications running on large-scale systems.
  Our strategy separates application operations onto groups of processes and
enables a dataflow processing paradigm among the groups. This mechanism is
effective in reducing the impact of load imbalance and increases the parallel
efficiency by pipelining multiple operations. We provide a proof-of-concept
implementation using MPI, the de-facto programming system on current
supercomputers. We demonstrate the effectiveness of this strategy by decoupling
the reduce, particle communication, halo exchange and I/O operations in a set
of scientific and data-analytics applications. A performance evaluation on
8,192 processes of a Cray XC40 supercomputer shows that the proposed approach
can achieve up to 4x performance improvement.
</dc:description>
 <dc:description>Comment: The 46th International Conference on Parallel Processing (ICPP-2017)</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01304</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01306</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MPI Streams for HPC Applications</dc:title>
 <dc:creator>Peng, Ivy Bo</dc:creator>
 <dc:creator>Markidis, Stefano</dc:creator>
 <dc:creator>Gioiosa, Roberto</dc:creator>
 <dc:creator>Kestor, Gokcen</dc:creator>
 <dc:creator>Laure, Erwin</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Data streams are a sequence of data flowing between source and destination
processes. Streaming is widely used for signal, image and video processing for
its efficiency in pipelining and effectiveness in reducing demand for memory.
The goal of this work is to extend the use of data streams to support both
conventional scientific applications and emerging data analytic applications
running on HPC platforms. We introduce an extension called MPIStream to the
de-facto programming standard on HPC, MPI. MPIStream supports data streams
either within a single application or among multiple applications. We present
three use cases using MPI streams in HPC applications together with their
parallel performance. We show the convenience of using MPI streams to support
the needs from both traditional HPC and emerging data analytics applications
running on supercomputers.
</dc:description>
 <dc:description>Comment: Advances in Parallel Computing</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01311</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Spatially-aware Fashion Concept Discovery</dc:title>
 <dc:creator>Han, Xintong</dc:creator>
 <dc:creator>Wu, Zuxuan</dc:creator>
 <dc:creator>Huang, Phoenix X.</dc:creator>
 <dc:creator>Zhang, Xiao</dc:creator>
 <dc:creator>Zhu, Menglong</dc:creator>
 <dc:creator>Li, Yuan</dc:creator>
 <dc:creator>Zhao, Yang</dc:creator>
 <dc:creator>Davis, Larry S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes an automatic spatially-aware concept discovery approach
using weakly labeled image-text data from shopping websites. We first fine-tune
GoogleNet by jointly modeling clothing images and their corresponding
descriptions in a visual-semantic embedding space. Then, for each attribute
(word), we generate its spatially-aware representation by combining its
semantic word vector representation with its spatial representation derived
from the convolutional maps of the fine-tuned network. The resulting
spatially-aware representations are further used to cluster attributes into
multiple groups to form spatially-aware concepts (e.g., the neckline concept
might consist of attributes like v-neck, round-neck, etc). Finally, we
decompose the visual-semantic embedding space into multiple concept-specific
subspaces, which facilitates structured browsing and attribute-feedback product
retrieval by exploiting multimodal linguistic regularities. We conducted
extensive experiments on our newly collected Fashion200K dataset, and results
on clustering quality evaluation and attribute-feedback product retrieval task
demonstrate the effectiveness of our automatically discovered spatially-aware
concepts.
</dc:description>
 <dc:description>Comment: ICCV 2017</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01311</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01318</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The UMD Neural Machine Translation Systems at WMT17 Bandit Learning Task</dc:title>
 <dc:creator>Sharaf, Amr</dc:creator>
 <dc:creator>Feng, Shi</dc:creator>
 <dc:creator>Nguyen, Khanh</dc:creator>
 <dc:creator>Brantley, Kiant&#xe9;</dc:creator>
 <dc:creator>Daum&#xe9; III, Hal</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  We describe the University of Maryland machine translation systems submitted
to the WMT17 German-English Bandit Learning Task. The task is to adapt a
translation system to a new domain, using only bandit feedback: the system
receives a German sentence to translate, produces an English sentence, and only
gets a scalar score as feedback. Targeting these two challenges (adaptation and
bandit learning), we built a standard neural machine translation system and
extended it in two ways: (1) robust reinforcement learning techniques to learn
effectively from the bandit feedback, and (2) domain adaptation using data
selection from a large corpus of parallel data.
</dc:description>
 <dc:description>Comment: 7 pages, 1 figure, WMT 2017 Bandit Learning Task</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01318</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01321</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On balanced 4-holes in bichromatic point sets</dc:title>
 <dc:creator>Bereg, S.</dc:creator>
 <dc:creator>D&#xed;az-B&#xe1;&#xf1;ez, J. M.</dc:creator>
 <dc:creator>Fabila-Monroy, R.</dc:creator>
 <dc:creator>P&#xe9;rez-Lantero, P.</dc:creator>
 <dc:creator>Ram&#xed;rez-Vigueras, A.</dc:creator>
 <dc:creator>Sakai, T.</dc:creator>
 <dc:creator>Urrutia, J.</dc:creator>
 <dc:creator>Ventura, I.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Let $S=R\cup B$ be a point set in the plane in general position such that
each of its elements is colored either red or blue, where $R$ and $B$ denote
the points colored red and the points colored blue, respectively. A
quadrilateral with vertices in $S$ is called a $4$-hole if its interior is
empty of elements of $S$. We say that a $4$-hole of $S$ is balanced if it has
$2$ red and $2$ blue points of $S$ as vertices. In this paper, we prove that if
$R$ and $B$ contain $n$ points each then $S$ has at least $\frac{n^2-4n}{12}$
balanced $4$-holes, and this bound is tight up to a constant factor. Since
there are two-colored point sets with no balanced {\em convex} $4$-holes, we
further provide a characterization of the two-colored point sets having this
type of $4$-holes.
</dc:description>
 <dc:description>Comment: this is an arxiv version of our paper</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01321</dc:identifier>
 <dc:identifier>Computational Geometry: Theory and Applications, 48 (3): 169-179
  (2015)</dc:identifier>
 <dc:identifier>doi:10.1016/j.comgeo.2014.09.004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01323</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flare Prediction Using Photospheric and Coronal Image Data</dc:title>
 <dc:creator>Jonas, Eric</dc:creator>
 <dc:creator>Bobra, Monica G.</dc:creator>
 <dc:creator>Shankar, Vaishaal</dc:creator>
 <dc:creator>Hoeksema, J. Todd</dc:creator>
 <dc:creator>Recht, Benjamin</dc:creator>
 <dc:subject>Astrophysics - Solar and Stellar Astrophysics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The precise physical process that triggers solar flares is not currently
understood. Here we attempt to capture the signature of this mechanism in solar
image data of various wavelengths and use these signatures to predict flaring
activity. We do this by developing an algorithm that [1] automatically
generates features in 5.5 TB of image data taken by the Solar Dynamics
Observatory of the solar photosphere, chromosphere, transition region, and
corona during the time period between May 2010 and May 2014, [2] combines these
features with other features based on flaring history and a physical
understanding of putative flaring processes, and [3] classifies these features
to predict whether a solar active region will flare within a time period of $T$
hours, where $T$ = 2 and 24. We find that when optimizing for the True Skill
Score (TSS), photospheric vector magnetic field data combined with flaring
history yields the best performance, and when optimizing for the area under the
precision-recall curve, all the data are helpful. Our model performance yields
a TSS of $0.84 \pm 0.03$ and $0.81 \pm 0.03$ in the $T$ = 2 and 24 hour cases,
respectively, and a value of $0.13 \pm 0.07$ and $0.43 \pm 0.08$ for the area
under the precision-recall curve in the $T$ = 2 and 24 hour cases,
respectively. These relatively high scores are similar to, but not greater
than, other attempts to predict solar flares. Given the similar values of
algorithm performance across various types of models reported in the
literature, we conclude that we can expect a certain baseline predictive
capacity using these data. This is the first attempt to predict solar flares
using photospheric vector magnetic field data as well as multiple wavelengths
of image data from the chromosphere, transition region, and corona.
</dc:description>
 <dc:description>Comment: submitted for publication in the Astrophysical Journal</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01323</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01335</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compact, Provably-Good LPs for Orienteering and Regret-Bounded Vehicle
  Routing</dc:title>
 <dc:creator>Friggstad, Zachary</dc:creator>
 <dc:creator>Swamy, Chaitanya</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>G.2</dc:subject>
 <dc:description>  We develop polynomial-size LP-relaxations for {\em orienteering} and the {\em
regret-bounded vehicle routing problem} (\rvrp) and devise suitable LP-rounding
algorithms that lead to various new insights and approximation results for
these problems. In orienteering, the goal is to find a maximum-reward
$r$-rooted path, possibly ending at a specified node, of length at most some
given budget $B$. In \rvrp, the goal is to find the minimum number of
$r$-rooted paths of {\em regret} at most a given bound $R$ that cover all
nodes, where the regret of an $r$-$v$ path is its length $-$ $c_{rv}$.
  For {\em rooted orienteering}, we introduce a natural bidirected
LP-relaxation and obtain a simple $3$-approximation algorithm via LP-rounding.
This is the {\em first LP-based} guarantee for this problem. We also show that
{\em point-to-point} (\ptp) {\em orienteering} can be reduced to a
regret-version of rooted orienteering at the expense of a factor-2 loss in
approximation. For \rvrp, we propose two compact LPs that lead to significant
improvements, in both approximation ratio and running time, over the approach
in~\cite{FriggstadS14}. One of these is a natural modification of the LP for
rooted orienteering; the other is an unconventional formulation that is
motivated by certain structural properties of an \rvrp-solution, which leads to
a $15$-approximation algorithm for \rvrp.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01336</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MemexQA: Visual Memex Question Answering</dc:title>
 <dc:creator>Jiang, Lu</dc:creator>
 <dc:creator>Liang, Junwei</dc:creator>
 <dc:creator>Cao, Liangliang</dc:creator>
 <dc:creator>Kalantidis, Yannis</dc:creator>
 <dc:creator>Farfade, Sachin</dc:creator>
 <dc:creator>Hauptmann, Alexander</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper proposes a new task, MemexQA: given a collection of photos or
videos from a user, the goal is to automatically answer questions that help
users recover their memory about events captured in the collection. Towards
solving the task, we 1) present the MemexQA dataset, a large, realistic
multimodal dataset consisting of real personal photos and crowd-sourced
questions/answers, 2) propose MemexNet, a unified, end-to-end trainable network
architecture for image, text and video question answering. Experimental results
on the MemexQA dataset demonstrate that MemexNet outperforms strong baselines
and yields the state-of-the-art on this novel and challenging task. The
promising results on TextQA and VideoQA suggest MemexNet's efficacy and
scalability across various QA tasks.
</dc:description>
 <dc:description>Comment: https://memexqa.cs.cmu.edu/</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01341</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AccurateML: Information-aggregation-based Approximate Processing for
  Fast and Accurate Machine Learning on MapReduce</dc:title>
 <dc:creator>Han, Rui</dc:creator>
 <dc:creator>Zhang, Fan</dc:creator>
 <dc:creator>Wang, Zhentao</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The growing demands of processing massive datasets have promoted irresistible
trends of running machine learning applications on MapReduce. When processing
large input data, it is often of greater values to produce fast and accurate
enough approximate results than slow exact results. Existing techniques produce
approximate results by processing parts of the input data, thus incurring large
accuracy losses when using short job execution times, because all the skipped
input data potentially contributes to result accuracy. We address this
limitation by proposing AccurateML that aggregates information of input data in
each map task to create small aggregated data points. These aggregated points
enable all map tasks producing initial outputs quickly to save computation
times and decrease the outputs' size to reduce communication times. Our
approach further identifies the parts of input data most related to result
accuracy, thus first using these parts to improve the produced outputs to
minimize accuracy losses. We evaluated AccurateML using real machine learning
applications and datasets. The results show: (i) it reduces execution times by
30 times with small accuracy losses compared to exact results; (ii) when using
the same execution times, it achieves 2.71 times reductions in accuracy losses
compared to existing approximate processing techniques.
</dc:description>
 <dc:description>Comment: 9 pages, 9 figures</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01347</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Low-rank Spline Approximation of Planar Domains</dc:title>
 <dc:creator>Pan, Maodong</dc:creator>
 <dc:creator>Chen, Falai</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Construction of spline surfaces from given boundary curves is one of the
classical problems in computer aided geometric design, which regains much
attention in isogeometric analysis in recent years and is called domain
parameterization. However, for most of the state-of-the-art parameterization
methods, the rank of the spline parameterization is usually large, which
results in higher computational cost in solving numerical PDEs. In this paper,
we propose a low-rank representation for the spline parameterization of planar
domains using low-rank tensor approximation technique, and apply
quasi-conformal map as the framework of the spline parameterization. Under
given correspondence of boundary curves, a quasi-conformal map with low rank
and low distortion between a unit square and the computational domain can be
modeled as a non-linear optimization problem. We propose an efficient algorithm
to compute the quasi-conformal map by solving two convex optimization problems
alternatively. Experimental results show that our approach can produce a
bijective and low-rank parametric spline representation of planar domains,
which results in better performance than previous approaches in solving
numerical PDEs.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01348</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining guaranteed and spot markets in display advertising: selling
  guaranteed page views with stochastic demand</dc:title>
 <dc:creator>Chen, Bowei</dc:creator>
 <dc:creator>Huang, Jingmin</dc:creator>
 <dc:creator>Huang, Yufei</dc:creator>
 <dc:creator>Kollias, Stefanos</dc:creator>
 <dc:creator>Yue, Shigang</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  This paper proposes an optimal dynamic model for combining guaranteed and
spot markets in display advertising. We assume a media seller can well estimate
the total supply and demand of page views from a specific advertisement (in
short ad) slot in a specific future period. The model helps the seller to
determine how to distribute and price those future page views between
guaranteed contracts and advertising auctions. The former is sold
algorithmically in advance while the latter happens in a few milliseconds after
a user visits the Web page in the future. Therefore, the former is called
programmatic guarantee (PG) and the latter is called real-time bidding (RTB).
This is one of a few studies that investigate the RTB-based posted price PG for
display advertising. The optimization problem is challenging because the
allocation and pricing of PG affect the expected revenue from future RTB
campaigns. Several assumptions are made on media buyers' behavior, such as risk
aversion, stochastic demand arrivals, and effects of time and guaranteed
contract price. We use dynamic programming to solve the optimization problem
and our solution is relatively scalable and efficient. We validate the proposed
model with an RTB dataset and find it increases the seller's expected total
revenue by adopting different pricing and allocation strategies according to
the level of competition in future RTB campaigns.
</dc:description>
 <dc:description>Comment: 13 pages, working paper</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01348</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01349</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ACTS in Need: Automatic Configuration Tuning with Scalability Guarantees</dc:title>
 <dc:creator>Zhu, Yuqing</dc:creator>
 <dc:creator>Liu, Jianxun</dc:creator>
 <dc:creator>Guo, Mengying</dc:creator>
 <dc:creator>Ma, Wenlong</dc:creator>
 <dc:creator>Bao, Yungang</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  To support the variety of Big Data use cases, many Big Data related systems
expose a large number of user-specifiable configuration parameters. Highlighted
in our experiments, a MySQL deployment with well-tuned configuration parameters
achieves a peak throughput as 12 times much as one with the default setting.
However, finding the best setting for the tens or hundreds of configuration
parameters is mission impossible for ordinary users. Worse still, many Big Data
applications require the support of multiple systems co-deployed in the same
cluster. As these co-deployed systems can interact to affect the overall
performance, they must be tuned together. Automatic configuration tuning with
scalability guarantees (ACTS) is in need to help system users. Solutions to
ACTS must scale to various systems, workloads, deployments, parameters and
resource limits. Proposing and implementing an ACTS solution, we demonstrate
that ACTS can benefit users not only in improving system performance and
resource utilization, but also in saving costs and enabling fairer
benchmarking.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01349</dc:identifier>
 <dc:identifier>doi:10.1145/3124680.3124730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01353</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Neural Network-Based Sentence Encoder with Gated Attention for
  Natural Language Inference</dc:title>
 <dc:creator>Chen, Qian</dc:creator>
 <dc:creator>Zhu, Xiaodan</dc:creator>
 <dc:creator>Ling, Zhen-Hua</dc:creator>
 <dc:creator>Wei, Si</dc:creator>
 <dc:creator>Jiang, Hui</dc:creator>
 <dc:creator>Inkpen, Diana</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The RepEval 2017 Shared Task aims to evaluate natural language understanding
models for sentence representation, in which a sentence is represented as a
fixed-length vector with neural networks and the quality of the representation
is tested with a natural language inference task. This paper describes our
system (alpha) that is ranked among the top in the Shared Task, on both the
in-domain test set (obtaining a 74.9% accuracy) and on the cross-domain test
set (also attaining a 74.9% accuracy), demonstrating that the model generalizes
well to the cross-domain data. Our model is equipped with intra-sentence
gated-attention composition which helps achieve a better performance. In
addition to submitting our model to the Shared Task, we have also tested it on
the Stanford Natural Language Inference (SNLI) dataset. We obtain an accuracy
of 85.5%, which is the best reported result on SNLI when cross-sentence
attention is not allowed, the same condition enforced in RepEval 2017.
</dc:description>
 <dc:description>Comment: RepEval 2017 workshop paper at EMNLP 2017, Copenhagen</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01353</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01354</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CASSL: Curriculum Accelerated Self-Supervised Learning</dc:title>
 <dc:creator>Murali, Adithyavairavan</dc:creator>
 <dc:creator>Pinto, Lerrel</dc:creator>
 <dc:creator>Gandhi, Dhiraj</dc:creator>
 <dc:creator>Gupta, Abhinav</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recent self-supervised learning approaches focus on using a few thousand data
points to learn policies for high-level, low-dimensional action spaces.
However, scaling this framework for high-dimensional control require either
scaling up the data collection efforts or using a clever sampling strategy for
training. We present a novel approach - Curriculum Accelerated Self-Supervised
Learning (CASSL) - to train policies that map visual information to high-level,
higher- dimensional action spaces. CASSL orders the sampling of training data
based on control dimensions: the learning and sampling are focused on few
control parameters before other parameters. The right curriculum for learning
is suggested by variance-based global sensitivity analysis of the control
space. We apply our CASSL framework to learning how to grasp using an adaptive,
underactuated multi-fingered gripper, a challenging system to control. Our
experimental results indicate that CASSL provides significant improvement and
generalization compared to baseline methods such as staged curriculum learning
(8% increase) and complete end-to-end learning with random exploration (14%
improvement) tested on a set of novel objects.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01358</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pilot Reuse Among D2D Users in D2D Underlaid Massive MIMO Systems</dc:title>
 <dc:creator>Xu, Hao</dc:creator>
 <dc:creator>Xu, Wei</dc:creator>
 <dc:creator>Yang, Zhaohui</dc:creator>
 <dc:creator>Shi, Jianfeng</dc:creator>
 <dc:creator>Chen, Ming</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In a device-to-device (D2D) underlaid massive MIMO system, D2D transmitters
reuse the uplink spectrum of cellular users (CUs), leading to cochannel
interference. To decrease pilot overhead, we assume pilot reuse (PR) among D2D
pairs. We first derive the minimum-mean-square-error (MMSE) estimation of all
channels and give a lower bound on the ergodic achievable rate of both cellular
and D2D links. To mitigate pilot contamination caused by PR, we then propose a
pilot scheduling and pilot power control algorithm based on the criterion of
minimizing the sum mean-square-error (MSE) of channel estimation of D2D links.
We show that, with an appropriate PR ratio and a well designed pilot scheduling
scheme, each D2D transmitter could transmit its pilot with maximum power. In
addition, we also maximize the sum rate of all D2D links while guaranteeing the
quality of service (QoS) of CUs, and develop an iterative algorithm to obtain a
suboptimal solution. Simulation results show that the effect of pilot
contamination can be greatly decreased by the proposed pilot scheduling
algorithm, and the PR scheme provides significant performance gains over the
conventional orthogonal training scheme in terms of system spectral efficiency.
</dc:description>
 <dc:description>Comment: 15 pages, 9 figures, to appear in IEEE Transactions on Vehicular
  Technology</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01365</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Load Balancing using Hilbert Space-filling Curves for Parallel Reservoir
  Simulations</dc:title>
 <dc:creator>Liu, Hui</dc:creator>
 <dc:creator>Wang, Kun</dc:creator>
 <dc:creator>Yang, Bo</dc:creator>
 <dc:creator>Yang, Min</dc:creator>
 <dc:creator>He, Ruijian</dc:creator>
 <dc:creator>Shen, Lihua</dc:creator>
 <dc:creator>Zhong, He</dc:creator>
 <dc:creator>Chen, Zhangxin</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The goal of load balancing (grid partitioning) is to minimize overall
computations and communications, and to make sure that all processors have a
similar workload. Geometric methods divide a grid by using a location of a cell
while topological methods work with connectivity of cells, which is generally
described as a graph. This paper introduces a Hilbert space-filling curve
method. A space-filling curve is a continuous curve and defines a map between a
one-dimensional space and a multi-dimensional space. A Hilbert space-filling
curve is one special space-filling curve discovered by Hilbert and has many
useful characteristics, such as good locality, which means that two objects
that are close to each other in a multi-dimensional space are also close to
each other in a one dimensional space. This property can model communications
in grid-based parallel applications. The idea of the Hilbert space-filling
curve method is to map a computational domain into a one-dimensional space,
partition the one-dimensional space to certain intervals, and assign all cells
in a same interval to a MPI. To implement a load balancing method, a mapping
kernel is required to convert high-dimensional coordinates to a scalar value
and an efficient one-dimensional partitioning module that divides a
one-dimensional space and makes sure that all intervals have a similar
workload.
  The Hilbert space-filling curve method is compared with ParMETIS, a famous
graph partitioning package. The results show that our Hilbert space-filling
curve method has good partition quality. It has been applied to grids with
billions of cells, and linear scalability has been obtained on IBM Blue Gene/Q.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01368</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A novel metaheuristic method for solving constrained engineering
  optimization problems: Drone Squadron Optimization</dc:title>
 <dc:creator>de Melo, Vin&#xed;cius Veloso</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Several constrained optimization problems have been adequately solved over
the years thanks to advances in the metaheuristics area. In this paper, we
evaluate a novel self-adaptive and auto-constructive metaheuristic called Drone
Squadron Optimization (DSO) in solving constrained engineering design problems.
This paper evaluates DSO with death penalty on three widely tested engineering
design problems. Results show that the proposed approach is competitive with
some very popular metaheuristics.
</dc:description>
 <dc:description>Comment: 3 pages</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01371</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constrained Receiver Scheduling in Flexible Time and Wavelength Division
  Multiplexed Optical</dc:title>
 <dc:creator>Bhar, Chayan</dc:creator>
 <dc:creator>Mitra, Arnab</dc:creator>
 <dc:creator>Das, Goutam</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  An increasing bandwidth demand has mandated a shift to the time and
wavelength division multiplexing (TWDM) techniques in optical access networks
(OAN). Typical TWDM scheduling schemes consider scheduling of the optical line
terminal receiver only. In this paper we have identified an additional
collision domain that is present in TWDM schemes that offer security, in
addition to bandwidth flexibility. Scheduling of the identified collision
domain is termed as group scheduling. We illustrate that consideration of
receiver scheduling only (as done in typical TWDM schemes) severely affects
their throughput when implemented on flexible and secure TWDM architectures. A
novel media access control protocol has been proposed in this paper that
considers the multiple collision domains. Through simulations, we are able to
illustrate that the proposed scheme achieves a high throughput. A theoretical
upper bound of throughput has also been derived to explain the simulation
results. Complexity reduction of the proposed scheme has been illustrated,
thereby making it an attractive proposal.
</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01371</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01372</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hashtag Healthcare: From Tweets to Mental Health Journals Using Deep
  Transfer Learning</dc:title>
 <dc:creator>Shickel, Benjamin</dc:creator>
 <dc:creator>Heesacker, Martin</dc:creator>
 <dc:creator>Benton, Sherry</dc:creator>
 <dc:creator>Rashidi, Parisa</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  As the popularity of social media platforms continues to rise, an
ever-increasing amount of human communication and self- expression takes place
online. Most recent research has focused on mining social media for public user
opinion about external entities such as product reviews or sentiment towards
political news. However, less attention has been paid to analyzing users'
internalized thoughts and emotions from a mental health perspective. In this
paper, we quantify the semantic difference between public Tweets and private
mental health journals used in online cognitive behavioral therapy. We will use
deep transfer learning techniques for analyzing the semantic gap between the
two domains. We show that for the task of emotional valence prediction, social
media can be successfully harnessed to create more accurate, robust, and
personalized mental health models. Our results suggest that the semantic gap
between public and private self-expression is small, and that utilizing the
abundance of available social media is one way to overcome the small sample
sizes of mental health data, which are commonly limited by availability and
privacy concerns.
</dc:description>
 <dc:description>Comment: Under review with Scientific Reports</dc:description>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01377</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VisAR: Bringing Interactivity to Static Data Visualizations through
  Augmented Reality</dc:title>
 <dc:creator>Kim, Taeheon</dc:creator>
 <dc:creator>Saket, Bahador</dc:creator>
 <dc:creator>Endert, Alex</dc:creator>
 <dc:creator>MacIntyre, Blair</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Static visualizations have analytic and expressive value. However, many
interactive tasks cannot be completed using static visualizations. As datasets
grow in size and complexity, static visualizations start losing their analytic
and expressive power for interactive data exploration. Despite this limitation
of static visualizations, there are still many cases where visualizations are
limited to being static (e.g., visualizations on presentation slides or
posters). We believe in many of these cases, static visualizations will benefit
from allowing users to perform interactive tasks on them. Inspired by the
introduction of numerous commercial personal augmented reality (AR) devices, we
propose an AR solution that allows interactive data exploration of datasets on
static visualizations. In particular, we present a prototype system named VisAR
that uses the Microsoft Hololens to enable users to complete interactive tasks
on static visualizations.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01383</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence of Variance-Reduced Stochastic Learning under Random
  Reshuffling</dc:title>
 <dc:creator>Ying, Bicheng</dc:creator>
 <dc:creator>Yuan, Kun</dc:creator>
 <dc:creator>Sayed, Ali H.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Several useful variance-reduced stochastic gradient algorithms, such as SVRG,
SAGA, Finito, and SAG, have been proposed to minimize empirical risks with
linear convergence properties to the exact minimizers. The existing convergence
results assume uniform data sampling with replacement. However, it has been
observed that random reshuffling can deliver superior performance. No formal
proofs or guarantees of exact convergence exist for variance-reduced algorithms
under random reshuffling. This paper resolves this open convergence issue and
provides the first theoretical guarantee of linear convergence under random
reshuffling for SAGA; the argument is also adaptable to other variance-reduced
algorithms. Under random reshuffling, the paper further proposes a new
amortized variance-reduced gradient (AVRG) algorithm with constant storage
requirements compared to SAGA and with balanced gradient computations compared
to SVRG. The balancing in computations are attained by amortizing the full
gradient calculation across all iterations. AVRG is also shown analytically to
converge linearly.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:date>2017-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01384</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variance-Reduced Stochastic Learning by Networked Agents under Random
  Reshuffling</dc:title>
 <dc:creator>Yuan, Kun</dc:creator>
 <dc:creator>Ying, Bicheng</dc:creator>
 <dc:creator>Liu, Jiageng</dc:creator>
 <dc:creator>Sayed, Ali H.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A new amortized variance-reduced gradient (AVRG) algorithm was developed in
[1], which has constant storage requirement in comparison to SAGA and balanced
gradient computations in comparison to SVRG. One key advantage of the AVRG
strategy is its amenability to decentralized implementations. In this work, we
show how AVRG can be extended to the network case where multiple learning
agents are assumed to be connected by a graph topology. In this scenario, each
agent observes data that is spatially distributed and all agents are only
allowed to communicate with direct neighbors. Moreover, the amount of data
observed by the individual agents may differ drastically. For such situations,
the balanced gradient computation property of AVRG becomes a real advantage in
reducing idle time caused by unbalanced local data storage requirements, which
is characteristic of other reduced-variance gradient algorithms. The resulting
diffusion-AVRG algorithm is shown to have linear convergence to the exact
solution, and is much more memory efficient than other alternative algorithms.
In addition, by using a mini-batch strategy, it is shown that diffusion-AVRG is
more computationally efficient than exact diffusion or EXTRA while maintaining
almost the same amount of communications.
</dc:description>
 <dc:description>Comment: 20 pages, 7 figures, submitted for publication</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01384</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01386</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Better Tradeoffs for Exact Distance Oracles in Planar Graphs</dc:title>
 <dc:creator>Gawrychowski, Pawe&#x142;</dc:creator>
 <dc:creator>Mozes, Shay</dc:creator>
 <dc:creator>Weimann, Oren</dc:creator>
 <dc:creator>Wulff-Nilsen, Christian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present an $O(n^{1.5})$-space distance oracle for directed planar graphs
that answers distance queries in $O(\log n)$ time. Our oracle both
significantly simplifies and significantly improves the recent oracle of
Cohen-Addad, Dahlgaard and Wulff-Nilsen [FOCS 2017], which uses
$O(n^{5/3})$-space and answers queries in $O(\log n)$ time. We achieve this by
designing an elegant and efficient point location data structure for Voronoi
diagrams on planar graphs.
  We further show a smooth tradeoff between space and query-time. For any $S\in
[n,n^2]$, we show an oracle of size $S$ that answers queries in $\tilde
O(\max\{1,n^{1.5}/S\})$ time. This new tradeoff is currently the best (up to
polylogarithmic factors) for the entire range of $S$ and improves by polynomial
factors over all the previously known tradeoffs for the range $S \in
[n,n^{5/3}]$.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01387</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Research Activity Classification based on Time Series Bibliometrics</dc:title>
 <dc:creator>Kawamura, Takahiro</dc:creator>
 <dc:creator>Yamashita, Yasuhiro</dc:creator>
 <dc:creator>Matsumura, Katsuji</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Bibliometrics such as the number of papers and times cited are often used to
compare researchers based on specific criteria. The criteria, however, are
different in each research domain and are set by empirical laws. Moreover,
there are arguments, such that the simple sum of metric values works to the
advantage of elders. Therefore, this paper attempts to constitute features from
time series data of bibliometrics, and then classify the researchers according
to the features. In detail, time series patterns are extracted from
bibliographic data sets, and then a model to classify whether the researchers
are &quot;distinguished&quot; or not is created by a machine learning technique. The
experiments achieved an F-measure of 80.0% in the classification of 114
researchers in two research domains based on the data sets of Japan Science and
Technology Agency and Elsevier's Scopus. In the future, we will conduct
verification on a number of researchers in several domains, and then make use
of discovering &quot;distinguished&quot; researchers, who are not widely known.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01387</dc:identifier>
 <dc:identifier>Proceedings of 21st International Conference on Science and
  Technology Indicators (STI 2016), pp. 1456-1460 (2016)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01388</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Overhead Comparison between Hypervisor and Container based
  Virtualization</dc:title>
 <dc:creator>Li, Zheng</dc:creator>
 <dc:creator>Kihl, Maria</dc:creator>
 <dc:creator>Lu, Qinghua</dc:creator>
 <dc:creator>Andersson, Jens A.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The current virtualization solution in the Cloud widely relies on
hypervisor-based technologies. Along with the recent popularity of Docker, the
container-based virtualization starts receiving more attention for being a
promising alternative. Since both of the virtualization solutions are not
resource-free, their performance overheads would lead to negative impacts on
the quality of Cloud services. To help fundamentally understand the performance
difference between these two types of virtualization solutions, we use a
physical machine with &quot;just-enough&quot; resource as a baseline to investigate the
performance overhead of a standalone Docker container against a standalone
virtual machine (VM). With findings contrary to the related work, our
evaluation results show that the virtualization's performance overhead could
vary not only on a feature-by-feature basis but also on a job-to-job basis.
Although the container-based solution is undoubtedly lightweight, the
hypervisor-based technology does not come with higher performance overhead in
every case. For example, Docker containers particularly exhibit lower QoS in
terms of storage transaction speed.
</dc:description>
 <dc:description>Comment: Proceedings of the 31st IEEE International Conference on Advanced
  Information Networking and Application (AINA 2017), pp. 955-962, March 27-29,
  2017</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01388</dc:identifier>
 <dc:identifier>doi:10.1109/AINA.2017.79</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01391</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On a Feedback Control-based Mechanism of Bidding for Cloud Spot Service</dc:title>
 <dc:creator>Li, Zheng</dc:creator>
 <dc:creator>Kihl, Maria</dc:creator>
 <dc:creator>Robertsson, Anders</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  As a cost-effective option for Cloud consumers, spot service has been
considered to be a significant supplement for building a full-fledged market
economy for the Cloud ecosystem. However, unlike the static and straightforward
way of trading on-demand and reserved Cloud services, the market-driven
regulations of employing spot service could be too complicated for Cloud
consumers to comprehensively understand. In particular, it would be both
difficult and tedious for potential consumers to determine suitable bids from
time to time. To reduce the complexity in applying spot resources, we propose
to use a feedback control to help make bidding decisions. Based on an
arccotangent-function-type system model, our novel bidding mechanism imitates
fuzzy and intuitive human activities to refine and issue new bids according to
previous errors. The validation is conducted by using Amazon's historical spot
price trace to perform a set of simulations and comparisons. The result shows
that the feedback control-based mechanism obtains a better trade-off between
bidding rationality and success rate than the other five comparable strategies.
Although this mechanism is only for black-box bidding (price prediction) at
this current stage, it can be conveniently and gradually upgraded to take into
account external constraints in the future.
</dc:description>
 <dc:description>Comment: Proceedings of the 7th International Conference on Cloud Computing
  Technology and Science (CloudCom 2015), pp. 290-297, Vancouver, Canada,
  November 30 - December 03, 2015</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01391</dc:identifier>
 <dc:identifier>doi:10.1109/CloudCom.2015.76</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01397</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using a Predator-Prey Model to Explain Variations of Cloud Spot Price</dc:title>
 <dc:creator>Li, Zheng</dc:creator>
 <dc:creator>Tarneberg, William</dc:creator>
 <dc:creator>Kihl, Maria</dc:creator>
 <dc:creator>Robertsson, Anders</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  The spot pricing scheme has been considered to be resource-efficient for
providers and cost-effective for consumers in the Cloud market. Nevertheless,
unlike the static and straightforward strategies of trading on-demand and
reserved Cloud services, the market-driven mechanism for trading spot service
would be complicated for both implementation and understanding. The largely
invisible market activities and their complex interactions could especially
make Cloud consumers hesitate to enter the spot market. To reduce the
complexity in understanding the Cloud spot market, we decided to reveal the
backend information behind spot price variations. Inspired by the methodology
of reverse engineering, we developed a Predator-Prey model that can simulate
the interactions between demand and resource based on the visible spot price
traces. The simulation results have shown some basic regular patterns of market
activities with respect to Amazon's spot instance type m3.large. Although the
findings of this study need further validation by using practical data, our
work essentially suggests a promising approach (i.e.~using a Predator-Prey
model) to investigate spot market activities.
</dc:description>
 <dc:description>Comment: Proceedings of the 6th International Conference on Cloud Computing
  and Services Science (CLOSER 2016), pp. 51-58, Rome, Italy, April 23-25, 2016</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01397</dc:identifier>
 <dc:identifier>doi:10.5220/0005808600510058</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01398</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Signal Recovery in Perturbed Fourier Compressed Sensing</dc:title>
 <dc:creator>Malhotra, Eeshan</dc:creator>
 <dc:creator>Pandotra, Himanshu</dc:creator>
 <dc:creator>Rajwade, Ajit</dc:creator>
 <dc:creator>Gurumoorthy, Karthik S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In many applications in compressed sensing, the measurement matrix is a
Fourier matrix, \textit{i.e.}, it measures the Fourier transform of the
underlying signal at some specified frequencies $\{u_i\}_{i=1}^M$, where $M$ is
the number of measurements. However due to system calibration errors, the
system may measure the Fourier transform at frequencies $\{u_i +
\delta_i\}_{i=1}^M$ that are different from the specified (known) `base'
frequencies. Ignoring perturbations of this nature can lead to major errors in
signal recovery. In this paper, we present a simple but effective alternating
minimization algorithm to recover the perturbations in the frequencies \emph{in
situ} with the signal, which we assume is sparse or compressible in some known
basis. We demonstrate that assuming that the number of \emph{unique}
perturbations $\{\delta_i\}_{i=1}^M$ is less than $M$, the method leads to
excellent quality results that are several times better than baseline
algorithms and other related algorithms in the literature, besides being robust
to noise in the measurement values. We also analyze a linearized approximation
to the proposed objective function, and prove that it yields a unique solution
in almost all cases.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01398</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01401</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spot Pricing in the Cloud Ecosystem: A Comparative Investigation</dc:title>
 <dc:creator>Li, Zheng</dc:creator>
 <dc:creator>Zhang, He</dc:creator>
 <dc:creator>O'Brien, Liam</dc:creator>
 <dc:creator>Jiang, Shu</dc:creator>
 <dc:creator>Zhou, You</dc:creator>
 <dc:creator>Kihl, Maria</dc:creator>
 <dc:creator>Ranjan, Rajiv</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Background: Spot pricing is considered as a significant supplement for
building a full-fledged market economy for the Cloud ecosystem. However, it
seems that both providers and consumers are still hesitating to enter the Cloud
spot market. The relevant academic community also has conflicting opinions
about Cloud spot pricing in terms of revenue generation. Aim: This work aims to
systematically identify, assess, synthesize and report the published evidence
in favor of or against spot-price scheme compared with fixed-price scheme of
Cloud computing, so as to help relieve the aforementioned conflict. Method: We
employed the systematic literature review (SLR) method to collect and
investigate the empirical studies of Cloud spot pricing indexed by major
electronic libraries. Results: This SLR identified 61 primary studies that
either delivered discussions or conducted experiments to perform comparison
between spot pricing and fixed pricing in the Cloud domain. The reported
benefits and limitations were summarized to facilitate cost-benefit analysis of
being a Cloud spot pricing player, while four types of theories were
distinguished to help both researchers and practitioners better understand the
Cloud spot market. Conclusions: This SLR shows that the academic community
strongly advocates the emerging Cloud spot market. Although there is still a
lack of practical and easily deployable market-driven mechanisms, the overall
findings of our work indicate that spot pricing plays a promising role in the
sustainability of Cloud resource exploitation.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01401</dc:identifier>
 <dc:identifier>Journal of Systems and Software, vol. 114, pp. 1-19 (2016)</dc:identifier>
 <dc:identifier>doi:10.1016/j.jss.2015.10.042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01402</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Redundancy, Recurrence and Parallelism: How to Link Millions
  of Addresses with Ten Lines of Code in Ten Minutes</dc:title>
 <dc:creator>Zhang, Yuhang</dc:creator>
 <dc:creator>Churchill, Tania</dc:creator>
 <dc:creator>Ng, Kee Siong</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Accurate and efficient record linkage is an open challenge of particular
relevance to Australian Government Agencies, who recognise that so-called
wicked social problems are best tackled by forming partnerships founded on
large-scale data fusion. Names and addresses are the most common attributes on
which data from different government agencies can be linked. In this paper, we
focus on the problem of address linking. Linkage is particularly problematic
when the data has significant quality issues. The most common approach for
dealing with quality issues is to standardise raw data prior to linking. If a
mistake is made in standardisation, however, it is usually impossible to
recover from it to perform linkage correctly. This paper proposes a novel
algorithm for address linking that is particularly practical for linking large
disparate sets of addresses, being highly scalable, robust to data quality
issues and simple to implement. It obviates the need for labour intensive and
problematic address standardisation. We demonstrate the efficacy of the
algorithm by matching two large address datasets from two government agencies
with good accuracy and computational efficiency.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01403</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Throughput Fairness Trade-offs for Downlink Non-Orthogonal
  Multiple Access over Fading Channels</dc:title>
 <dc:creator>Xing, Hong</dc:creator>
 <dc:creator>Liu, Yuanwei</dc:creator>
 <dc:creator>Nallanathan, Arumugam</dc:creator>
 <dc:creator>Ding, Zhiguo</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Recently, non-orthogonal multiple access (NOMA) has attracted considerable
interest as one of the 5G-defining techniques. However, as NOMA is
intrinsically in favour of the transmission of strong users who are capable of
carrying out successive decoding, judicious designs are required to guarantee
user fairness. In this paper, a two-user downlink NOMA system over fading
channels is considered. For delay-tolerant transmission, the average sum-rate
is maximized subject to both average and peak power constraints as well as a
minimum average user rate constraint. The optimal resource allocation is
obtained using Lagrangian dual decomposition under full channel state
information at the transmitter (CSIT), while an effective power allocation
policy under partial CSIT is also developed based on analytical results. In
parallel, for delay-limited transmission, the sum of delay-limited throughput
(DLT) is maximized subject to a maximum allowable user outage constraint under
full CSIT, and the analysis for the sum of DLT is performed under partial CSIT.
Furthermore, a sophisticated orthogonal multiple access (OMA) scheme is also
studied as a benchmark to prove the superiority of NOMA over OMA with full
CSIT. Finally, the theoretical analysis is verified via simulations by means of
various trade-offs for the average sum-rate (sum-DLT) versus the minimum
(maximum) user rate (outage) requirement.
</dc:description>
 <dc:description>Comment: 35 pages, 10 figures, submitted for possible journal publication
  (with supplementary materials included)</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01405</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>{\mu}-MAR: Multiplane 3D Marker based Registration for Depth-sensing
  Cameras</dc:title>
 <dc:creator>Saval-Calvo, Marcelo</dc:creator>
 <dc:creator>Azorin-Lopez, Jorge</dc:creator>
 <dc:creator>Fuster-Guillo, Andres</dc:creator>
 <dc:creator>Mora-Mora, Higinio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Many applications including object reconstruction, robot guidance, and scene
mapping require the registration of multiple views from a scene to generate a
complete geometric and appearance model of it. In real situations,
transformations between views are unknown an it is necessary to apply expert
inference to estimate them. In the last few years, the emergence of low-cost
depth-sensing cameras has strengthened the research on this topic, motivating a
plethora of new applications. Although they have enough resolution and accuracy
for many applications, some situations may not be solved with general
state-of-the-art registration methods due to the Signal-to-Noise ratio (SNR)
and the resolution of the data provided. The problem of working with low SNR
data, in general terms, may appear in any 3D system, then it is necessary to
propose novel solutions in this aspect. In this paper, we propose a method,
{\mu}-MAR, able to both coarse and fine register sets of 3D points provided by
low-cost depth-sensing cameras, despite it is not restricted to these sensors,
into a common coordinate system. The method is able to overcome the noisy data
problem by means of using a model-based solution of multiplane registration.
Specifically, it iteratively registers 3D markers composed by multiple planes
extracted from points of multiple views of the scene. As the markers and the
object of interest are static in the scenario, the transformations obtained for
the markers are applied to the object in order to reconstruct it. Experiments
have been performed using synthetic and real data. The synthetic data allows a
qualitative and quantitative evaluation by means of visual inspection and
Hausdorff distance respectively. The real data experiments show the performance
of the proposal using data acquired by a Primesense Carmine RGB-D sensor. The
method has been compared to several state-of-the-art methods. The ...
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01405</dc:identifier>
 <dc:identifier>Expert Systems with Applications, Volume 42, Issue 23, Pages
  9353-9365 (2015)</dc:identifier>
 <dc:identifier>doi:10.1016/j.eswa.2015.08.011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01407</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Power Allocation Strategies in Full-duplex Relay Networks</dc:title>
 <dc:creator>Nordio, Alessandro</dc:creator>
 <dc:creator>Chiasserini, Carla Fabiana</dc:creator>
 <dc:creator>Viterbo, Emanuele</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, we consider a dual-hop, decode-and-forward network where the
relay can operate in full- duplex (FD) or half-duplex (HD) mode. We model the
residual self-interference as an additive Gaussian noise with variance
proportional to the relay transmit power, and we assume a Gaussian input
distribution at the source. Unlike previous work, we assume that the source is
only aware of the transmit power distribution adopted by the relay over a given
time horizon, but not of the symbols that the relay is currently transmitting.
This assumption better reflects the practical situation where the relay node
also forwards signaling traffic, or data originated by other sources. Under
these conditions, we identify the optimal power allocation strategy at the
source and relay, which in some cases coincides with the half duplex
transmission mode. In particular, we prove that such strategy implies either FD
transmissions over an entire frame, or FD/HD transmissions over a variable
fraction of the frame. We determine the optimal transmit power level at the
source and relay for each frame, or fraction thereof. We compare the
performance of the proposed scheme against reference FD and HD techniques,
which assume that the source is aware of the symbols instantaneously
transmitted by the relay. Our results highlight that our scheme closely
approaches or outperforms such reference strategies.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01407</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01410</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The All-Paths and Cycles Graph Kernel</dc:title>
 <dc:creator>Giscard, P. -L.</dc:creator>
 <dc:creator>Wilson, R. C.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  With the recent rise in the amount of structured data available, there has
been considerable interest in methods for machine learning with graphs. Many of
these approaches have been kernel methods, which focus on measuring the
similarity between graphs. These generally involving measuring the similarity
of structural elements such as walks or paths. Borgwardt and Kriegel proposed
the all-paths kernel but emphasized that it is NP-hard to compute and
infeasible in practice, favouring instead the shortest-path kernel. In this
paper, we introduce a new algorithm for computing the all-paths kernel which is
very efficient and enrich it further by including the simple cycles as well. We
demonstrate how it is feasible even on large datasets to compute all the paths
and simple cycles up to a moderate length. We show how to count labelled
paths/simple cycles between vertices of a graph and evaluate a labelled path
and simple cycles kernel. Extensive evaluations on a variety of graph datasets
demonstrate that the all-paths and cycles kernel has superior performance to
the shortest-path kernel and state-of-the-art performance overall.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE for possible publication</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01410</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01412</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Evaluating Commercial Cloud Services: A Systematic Review</dc:title>
 <dc:creator>Li, Zheng</dc:creator>
 <dc:creator>Zhang, He</dc:creator>
 <dc:creator>O'Brien, Liam</dc:creator>
 <dc:creator>Cai, Rainbow</dc:creator>
 <dc:creator>Flint, Shayne</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Background: Cloud Computing is increasingly booming in industry with many
competing providers and services. Accordingly, evaluation of commercial Cloud
services is necessary. However, the existing evaluation studies are relatively
chaotic. There exists tremendous confusion and gap between practices and theory
about Cloud services evaluation. Aim: To facilitate relieving the
aforementioned chaos, this work aims to synthesize the existing evaluation
implementations to outline the state-of-the-practice and also identify research
opportunities in Cloud services evaluation. Method: Based on a conceptual
evaluation model comprising six steps, the Systematic Literature Review (SLR)
method was employed to collect relevant evidence to investigate the Cloud
services evaluation step by step. Results: This SLR identified 82 relevant
evaluation studies. The overall data collected from these studies essentially
represent the current practical landscape of implementing Cloud services
evaluation, and in turn can be reused to facilitate future evaluation work.
Conclusions: Evaluation of commercial Cloud services has become a world-wide
research topic. Some of the findings of this SLR identify several research gaps
in the area of Cloud services evaluation (e.g., the Elasticity and Security
evaluation of commercial Cloud services could be a long-term challenge), while
some other findings suggest the trend of applying commercial Cloud services
(e.g., compared with PaaS, IaaS seems more suitable for customers and is
particularly important in industry). This SLR study itself also confirms some
previous experiences and reveals new Evidence-Based Software Engineering (EBSE)
lessons.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01412</dc:identifier>
 <dc:identifier>Journal of Systems and Software, vol. 86, no. 9, pp. 2371-2393
  (2013)</dc:identifier>
 <dc:identifier>doi:10.1016/j.jss.2013.04.021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01413</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Solution of Large-Scale Linear Systems via Accelerated
  Projection-Based Consensus</dc:title>
 <dc:creator>Azizan-Ruhi, Navid</dc:creator>
 <dc:creator>Lahouti, Farshad</dc:creator>
 <dc:creator>Avestimehr, Salman</dc:creator>
 <dc:creator>Hassibi, Babak</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Solving a large-scale system of linear equations is a key step at the heart
of many algorithms in machine learning, scientific computing, and beyond. When
the problem dimension is large, computational and/or memory constraints make it
desirable, or even necessary, to perform the task in a distributed fashion. In
this paper, we consider a common scenario in which a taskmaster intends to
solve a large-scale system of linear equations by distributing subsets of the
equations among a number of computing machines/cores. We propose an accelerated
distributed consensus algorithm, in which at each iteration every machine
updates its solution by adding a scaled version of the projection of an error
signal onto the nullspace of its system of equations, and where the taskmaster
conducts an averaging over the solutions with momentum. The convergence
behavior of the proposed algorithm is analyzed in detail and analytically shown
to compare favorably with the convergence rate of alternative distributed
methods, namely distributed gradient descent, distributed versions of
Nesterov's accelerated gradient descent and heavy-ball method, the block
Cimmino method, and ADMM. On randomly chosen linear systems, as well as on
real-world data sets, the proposed method offers significant speed-up relative
to all the aforementioned methods. Finally, our analysis suggests a novel
variation of the distributed heavy-ball method, which employs a particular
distributed preconditioning, and which achieves the same theoretical
convergence rate as the proposed consensus-based method.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:date>2017-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01414</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boosting Metrics for Cloud Services Evaluation -- The Last Mile of Using
  Benchmark Suites</dc:title>
 <dc:creator>Li, Zheng</dc:creator>
 <dc:creator>O'Brien, Liam</dc:creator>
 <dc:creator>Cai, Rainbow</dc:creator>
 <dc:creator>Zhang, He</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Benchmark suites are significant for evaluating various aspects of Cloud
services from a holistic view. However, there is still a gap between using
benchmark suites and achieving holistic impression of the evaluated Cloud
services. Most Cloud service evaluation work intended to report individual
benchmarking results without delivering summary measures. As a result, it could
be still hard for customers with such evaluation reports to understand an
evaluated Cloud service from a global perspective. Inspired by the boosting
approaches to machine learning, we proposed the concept Boosting Metrics to
represent all the potential approaches that are able to integrate a suite of
benchmarking results. This paper introduces two types of preliminary boosting
metrics, and demonstrates how the boosting metrics can be used to supplement
primary measures of individual Cloud service features. In particular, boosting
metrics can play a summary Response role in applying experimental design to
Cloud services evaluation. Although the concept Boosting Metrics was refined
based on our work in the Cloud Computing domain, we believe it can be easily
adapted to the evaluation work of other computing paradigms.
</dc:description>
 <dc:description>Comment: Proceedings of the 27th IEEE International Conference on Advanced
  Information Networking and Applications (AINA 2013), pp. 381-388, Barcelona,
  Spain, March 25-28, 2013</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01414</dc:identifier>
 <dc:identifier>doi:10.1109/AINA.2013.99</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01419</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DoKnowMe: Towards a Domain Knowledge-driven Methodology for Performance
  Evaluation</dc:title>
 <dc:creator>Li, Zheng</dc:creator>
 <dc:creator>O'Brien, Liam</dc:creator>
 <dc:creator>Kihl, Maria</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Software engineering considers performance evaluation to be one of the key
portions of software quality assurance. Unfortunately, there seems to be a lack
of standard methodologies for performance evaluation even in the scope of
experimental computer science. Inspired by the concept of &quot;instantiation&quot; in
object-oriented programming, we distinguish the generic performance evaluation
logic from the distributed and ad-hoc relevant studies, and develop an abstract
evaluation methodology (by analogy of &quot;class&quot;) we name Domain Knowledge-driven
Methodology (DoKnowMe). By replacing five predefined domain-specific knowledge
artefacts, DoKnowMe could be instantiated into specific methodologies (by
analogy of &quot;object&quot;) to guide evaluators in performance evaluation of different
software and even computing systems. We also propose a generic validation
framework with four indicators (i.e.~usefulness, feasibility, effectiveness and
repeatability), and use it to validate DoKnowMe in the Cloud services
evaluation domain. Given the positive and promising validation result, we plan
to integrate more common evaluation strategies to improve DoKnowMe and further
focus on the performance evaluation of Cloud autoscaler systems.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01419</dc:identifier>
 <dc:identifier>ACM SIGMETRICS Performance Evaluation Review, vol. 43, no. 4, pp.
  23-32 (2016)</dc:identifier>
 <dc:identifier>doi:10.1145/2897356.2897360</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01420</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Selective and Invariant Representation of DCNN for
  High-Resolution Remote Sensing Image Recognition</dc:title>
 <dc:creator>Chen, Jie</dc:creator>
 <dc:creator>Yuan, Chao</dc:creator>
 <dc:creator>Deng, Min</dc:creator>
 <dc:creator>Tao, Chao</dc:creator>
 <dc:creator>Peng, Jian</dc:creator>
 <dc:creator>Li, Haifeng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Human vision possesses strong invariance in image recognition. The cognitive
capability of deep convolutional neural network (DCNN) is close to the human
visual level because of hierarchical coding directly from raw image. Owing to
its superiority in feature representation, DCNN has exhibited remarkable
performance in scene recognition of high-resolution remote sensing (HRRS)
images and classification of hyper-spectral remote sensing images. In-depth
investigation is still essential for understanding why DCNN can accurately
identify diverse ground objects via its effective feature representation. Thus,
we train the deep neural network called AlexNet on our large scale remote
sensing image recognition benchmark. At the neuron level in each convolution
layer, we analyze the general properties of DCNN in HRRS image recognition by
use of a framework of visual stimulation-characteristic response combined with
feature coding-classification decoding. Specifically, we use histogram
statistics, representational dissimilarity matrix, and class activation mapping
to observe the selective and invariance representations of DCNN in HRRS image
recognition. We argue that selective and invariance representations play
important roles in remote sensing images tasks, such as classification,
detection, and segment. Also selective and invariance representations are
significant to design new DCNN liked models for analyzing and understanding
remote sensing images.
</dc:description>
 <dc:description>Comment: 68 pages, 13 pages</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01422</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring the Function Space of Deep-Learning Machines</dc:title>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Saad, David</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The function space of deep-learning machines is investigated by studying
growth in the entropy of functions of a given error with respect to a reference
function, realized by a deep-learning machine. Using physics-inspired methods
we study both sparsely and densely-connected architectures to discover a
layer-wise convergence of candidate functions, marked by a corresponding
reduction in entropy when approaching the reference function, gain insight into
the importance of having a large number of layers, and observe phase
transitions as the error increases.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01422</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01423</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object-Oriented Sokoban Solver: A Serious Game Project for OOAD and AI
  Education</dc:title>
 <dc:creator>Li, Zheng</dc:creator>
 <dc:creator>O'Brien, Liam</dc:creator>
 <dc:creator>Flint, Shayne</dc:creator>
 <dc:creator>Sankaranarayana, Ramesh</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Serious games are beneficial for education in various computer science areas.
Numerous works have reported the experiences of using games (not only playing
but also development) in teaching and learning. Considering it could be
difficult for teachers/students to prepare/develop a game from scratch during
one semester, assistant educational materials would be crucial in the
corresponding courses. Unfortunately, the literature shows that not many
materials from educational game projects are shared. To help different
educators identify suitable courseware and help students implement game
development, it is worth further investigating and accumulating the educational
resources from individual game projects. Following such an idea, this paper
proposes a game development project of an object-oriented Sokoban solver, and
exposes relevant educational materials. The documented system design can be
viewed as a ready-to-use resource for education in object-oriented analysis and
design (OOAD), while the Sokoban solver itself may be used as an assignment
platform for teaching artificial intelligence (AI). Further documentation,
platform, and APIs will be realized and shared in the future to facilitate
others' educational activities. Overall, this work is supposed to inspire and
encourage other researchers and educators to post available materials of more
game projects for the purpose of sharing and reuse.
</dc:description>
 <dc:description>Comment: Proceedings of the 44th Annual Frontiers in Education Conference (FIE
  2014), pp. 1-4, Madrid, Spain, October 22-25, 2014</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01423</dc:identifier>
 <dc:identifier>doi:10.1109/FIE.2014.7044115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01425</identifier>
 <datestamp>2017-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Argument Reasoning Comprehension Task</dc:title>
 <dc:creator>Habernal, Ivan</dc:creator>
 <dc:creator>Wachsmuth, Henning</dc:creator>
 <dc:creator>Gurevych, Iryna</dc:creator>
 <dc:creator>Stein, Benno</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Reasoning is a crucial part of natural language argumentation. In order to
comprehend an argument, one has to reconstruct and analyze its reasoning. As
arguments are highly contextualized, most reasoning-related content is left
implicit and usually presupposed. Thus, argument comprehension requires not
only language understanding and logic skills, but it also heavily depends on
common sense. In this article we define a new task, argument reasoning
comprehension. Given a natural language argument with a reason and a claim, the
goal is to choose the correct implicit reasoning from two options. The
challenging factor is that both options are plausible and lexically very close
while leading to contradicting claims. To provide an empirical common ground
for the task, we propose a complex, yet scalable crowdsourcing process, and we
create a new freely licensed dataset based on authentic arguments from news
comments. While the resulting 2k high-quality instances are also suitable for
other argumentation-related tasks, such as stance detection, argument component
identification, and abstractive argument summarization, we focus on the
argument reasoning comprehension task and experiment with several systems based
on neural attention and language models. Our results clearly reveal that
current methods lack the capability to solve the task.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:date>2017-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01442</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Theory and Application on Adaptive-Robust Control of Euler-Lagrange
  Systems with Linearly Parametrizable Uncertainty Bound</dc:title>
 <dc:creator>Roy, Spandan</dc:creator>
 <dc:creator>Roy, Sayan Basu</dc:creator>
 <dc:creator>Kar, Indra Narayan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This work proposes a new adaptive-robust control (ARC) architecture for a
class of uncertain Euler-Lagrange (EL) systems where the upper bound of the
uncertainty satisfies linear in parameters (LIP) structure. Conventional ARC
strategies either require structural knowledge of the system or presume that
the overall uncertainties or its time derivative are norm bounded by a
constant. Due to unmodelled dynamics and modelling imperfection, true
structural knowledge of the system is not always available. Further, for the
class of systems under consideration, prior assumption regarding the
uncertainties (or its time derivative) being upper bounded by a constant, puts
a restriction on states beforehand. Conventional ARC laws invite
overestimation-underestimation problem of switching gain. Towards this front,
Adaptive Switching-gain based Robust Control (ASRC) is proposed which
alleviates the overestimation-underestimation problem of switching gain.
Moreover, ASRC avoids any presumption of constant upper bound on the overall
uncertainties and can negotiate uncertainties regardless of being linear or
nonlinear in parameters. Experimental results of ASRC using a wheeled mobile
robot notes improved control performance in comparison to adaptive sliding mode
control.
</dc:description>
 <dc:description>Comment: 10 pages, 9 figures</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01442</dc:identifier>
 <dc:identifier>doi:10.1109/TCST.2017.2739107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01443</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of Line-of-Sight and Unequal Spatial Correlation on Uplink
  MU-MIMO Systems</dc:title>
 <dc:creator>Tataria, Harsh</dc:creator>
 <dc:creator>Smith, Peter J.</dc:creator>
 <dc:creator>Greenstein, Larry J.</dc:creator>
 <dc:creator>Dmochowski, Pawel A.</dc:creator>
 <dc:creator>Matthaiou, Michail</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Closed-form approximations of the expected per-terminal
signal-to-interference-plus-noise-ratio (SINR) and ergodic sum spectral
efficiency of a multiuser multiple-input multiple-output system are presented.
Our analysis assumes spatially correlated Ricean fading channels with
maximum-ratio combining on the uplink. Unlike previous studies, our model
accounts for the presence of unequal correlation matrices, unequal Rice
factors, as well as unequal link gains to each terminal. The derived
approximations lend themselves to useful insights, special cases and
demonstrate the aggregate impact of line-of-sight (LoS) and unequal correlation
matrices. Numerical results show that while unequal correlation matrices
enhance the expected SINR and ergodic sum spectral efficiency, the presence of
strong LoS has an opposite effect. Our approximations are general and remain
insensitive to changes in the system dimensions, signal-to-noise-ratios, LoS
levels and unequal correlation levels.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures, accepted for publication in the IEEE Wireless
  Communications Letters, Vol. 6, 2017</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01443</dc:identifier>
 <dc:identifier>doi:10.1109/LWC.2017.2726062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01444</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast and exact search for the partition with minimal information loss</dc:title>
 <dc:creator>Hidaka, Shohei</dc:creator>
 <dc:creator>Oizumi, Masafumi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  In analysis of multi-component complex systems, such as neural systems,
identifying groups of units that share similar functionality will aid
understanding of the underlying structures of the system. To find such a
grouping, it is useful to evaluate to what extent the units of the system are
separable. Separability or inseparability can be evaluated by quantifying how
much information would be lost if the system were partitioned into subsystems,
and the interactions between the subsystems were hypothetically removed. A
system of two independent subsystems are completely separable without any loss
of information while a system of strongly interacted subsystems cannot be
separated without a large loss of information. Among all the possible
partitions of a system, the partition that minimizes the loss of information,
called the Minimum Information Partition (MIP), can be considered as the
optimal partition for characterizing the underlying structures of the system.
Although the MIP would reveal novel characteristics of the neural system, an
exhaustive search for the MIP is numerically intractable due to the
combinatorial explosion of possible partitions. Here, we propose a
computationally efficient search to precisely identify the MIP among all
possible partitions by exploiting the submodularity of the measure of
information loss. Mutual information is one such submodular information loss
functions, and is a natural choice for measuring the degree of statistical
dependence between paired sets of random variables. By using mutual information
as a loss function, we show that the search for MIP can be performed in a
practical order of computational time for a reasonably large system. We also
demonstrate that MIP search allows for the detection of underlying global
structures in a network of nonlinear oscillators.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:date>2017-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01447</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video Salient Object Detection Using Spatiotemporal Deep Features</dc:title>
 <dc:creator>Le, Trung-Nghia</dc:creator>
 <dc:creator>Sugimoto, Akihiro</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a method for detecting salient objects in videos where
temporal information in addition to spatial information is fully taken into
account. Following recent reports on the advantage of deep features over
conventional hand-crafted features, we propose the SpatioTemporal Deep (STD)
feature that utilizes local and global contexts over frames. We also propose
the SpatioTemporal Conditional Random Field (STCRF) to compute saliency from
STD features. STCRF is our extension of CRF toward the temporal domain and
formulates the relationship between neighboring regions both in a frame and
over frames. STCRF leads to temporally consistent saliency maps over frames,
contributing to the accurate detection of the boundaries of salient objects and
the reduction of noise in detection. Our proposed method first segments an
input video into multiple scales and then computes a saliency map at each scale
level using STD features with STCRF. The final saliency map is computed by
fusing saliency maps at different scale levels. Our intensive experiments using
publicly available benchmark datasets confirm that the proposed method
significantly outperforms state-of-the-art methods. We also applied our
saliency computation to the video object segmentation task, showing that our
method outperforms existing video object segmentation methods.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01448</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correlation and Class Based Block Formation for Improved Structured
  Dictionary Learning</dc:title>
 <dc:creator>Kumar, Nagendra</dc:creator>
 <dc:creator>Sinha, Rohit</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In recent years, the creation of block-structured dictionary has attracted a
lot of interest. Learning such dictionaries involve two step process: block
formation and dictionary update. Both these steps are important in producing an
effective dictionary. The existing works mostly assume that the block structure
is known a priori while learning the dictionary. For finding the unknown block
structure given a dictionary commonly sparse agglomerative clustering (SAC) is
used. It groups atoms based on their consistency in sparse coding with respect
to the unstructured dictionary. This paper explores two innovations towards
improving the reconstruction as well as the classification ability achieved
with the block-structured dictionary. First, we propose a novel block
structuring approach that makes use of the correlation among dictionary atoms.
Unlike the SAC approach, which groups diverse atoms, in the proposed approach
the blocks are formed by grouping the top most correlated atoms in the
dictionary. The proposed block clustering approach is noted to yield
significant reductions in redundancy as well as provides a direct control on
the block size when compared with the existing SAC-based block structuring.
Later, motivated by works using supervised \emph{a priori} known block
structure, we also explore the incorporation of class information in the
proposed block formation approach to further enhance the classification ability
of the block dictionary. For assessment of the reconstruction ability with
proposed innovations is done on synthetic data while the classification ability
has been evaluated in large variability speaker verification task.
</dc:description>
 <dc:description>Comment: 9 pages, Submitted to IEEE Transactions on Signal Processing</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01448</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01457</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometric Embedding of Path and Cycle Graphs in Pseudo-convex Polygons</dc:title>
 <dc:creator>Hoorfar, Hamid</dc:creator>
 <dc:creator>Bagheri, Alireza</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Given a graph $ G $ with $ n $ vertices and a set $ S $ of $ n $ points in
the plane, a point-set embedding of $ G $ on $ S $ is a planar drawing such
that each vertex of $ G $ is mapped to a distinct point of $ S $. A
straight-line point-set embedding is a point-set embedding with no edge bends
or curves. The point-set embeddability problem is NP-complete, even when $ G $
is $ 2 $-connected and $ 2 $-outerplanar. It has been solved polynomially only
for a few classes of planar graphs. Suppose that $ S $ is the set of vertices
of a simple polygon. A straight-line polygon embedding of a graph is a
straight-line point-set embedding of the graph onto the vertices of the polygon
with no crossing between edges of graph and the edges of polygon. In this
paper, we present $ O(n) $-time algorithms for polygon embedding of path and
cycle graphs in simple convex polygon and same time algorithms for polygon
embedding of path and cycle graphs in a large type of simple polygons where $n$
is the number of vertices of the polygon.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01457</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01461</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Linear-time Algorithm for Orthogonal Watchman Route Problem with
  Minimum Bends</dc:title>
 <dc:creator>Hoorfar, Hamid</dc:creator>
 <dc:creator>Bagheri, Alireza</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Given an orthogonal polygon $ P $ with $ n $ vertices, the goal of the
watchman route problem is finding a path $ S $ of the minimum length in $ P $
such that every point of the polygon $ P $ is visible from at least one of the
point of $ S $. In the other words, in the watchman route problem we must
compute a shortest watchman route inside a simple polygon of $ n $ vertices
such that all the points interior to the polygon and on its boundary are
visible to at least one point on the route. If route and polygon be orthogonal,
it is called orthogonal watchman route problem. One of the targets of this
problem is finding the orthogonal path with the minimum number of bends as
possible. We present a linear-time algorithm for the orthogonal watchman route
problem, in which the given polygon is monotone. Our algorithm can be used also
for the problem on simple orthogonal polygons $ P $ for which the dual graph
induced by the vertical decomposition of $ P $ is a path, which is called path
polygon.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01461</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01462</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Amdahl's low restricts supercomputer applications and building ever
  bigger supercomputers</dc:title>
 <dc:creator>V&#xe9;gh, J&#xe1;nos</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This paper reinterprets Amdahl's law in terms of execution time and applies
this simple model to supercomputing. The systematic discussion results in
practical formulas enabling to calculate expected running time using large
number of processors from experimental runs using low number of processors,
delivers a quantitative measure of computational efficiency of supercomputing
applications. Through separating non-parallelizable contribution to fractions
according to their origin, Amdahl's law enables to derive a timeline for
supercomputers (quite similar to Moore's law) and describes why Amdahl's law
limits the size of supercomputers. The paper validates that Amdahl's 50-years
old model (with slight extension) correctly describes the performance
limitations of the present supercomputers. Using some simple and reasonable
assumptions, the absolute performance bound of supercomputers is concluded,
furthermore that serious enhancements are still necessary to achieve the
exaFLOPS dream value.
</dc:description>
 <dc:description>Comment: 30 pages, 10 figures</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01464</identifier>
 <datestamp>2017-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Massively Multilingual Neural Grapheme-to-Phoneme Conversion</dc:title>
 <dc:creator>Peters, Ben</dc:creator>
 <dc:creator>Dehdari, Jon</dc:creator>
 <dc:creator>van Genabith, Josef</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Grapheme-to-phoneme conversion (g2p) is necessary for text-to-speech and
automatic speech recognition systems. Most g2p systems are monolingual: they
require language-specific data or handcrafting of rules. Such systems are
difficult to extend to low resource languages, for which data and handcrafted
rules are not available. As an alternative, we present a neural
sequence-to-sequence approach to g2p which is trained on
spelling--pronunciation pairs in hundreds of languages. The system shares a
single encoder and decoder across all languages, allowing it to utilize the
intrinsic similarities between different writing systems. We show an 11%
improvement in phoneme error rate over an approach based on adapting
high-resource monolingual g2p models to low-resource languages. Our model is
also much more compact relative to previous approaches.
</dc:description>
 <dc:description>Comment: EMNLP 2017 Workshop on Building Linguisically Generalizable NLP
  Systems</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01465</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Brain Responses During Robot-Error Observation</dc:title>
 <dc:creator>Welke, Dominik</dc:creator>
 <dc:creator>Behncke, Joos</dc:creator>
 <dc:creator>Hader, Marina</dc:creator>
 <dc:creator>Schirrmeister, Robin Tibor</dc:creator>
 <dc:creator>Sch&#xf6;nau, Andreas</dc:creator>
 <dc:creator>E&#xdf;mann, Boris</dc:creator>
 <dc:creator>M&#xfc;ller, Oliver</dc:creator>
 <dc:creator>Burgard, Wolfram</dc:creator>
 <dc:creator>Ball, Tonio</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Brain-controlled robots are a promising new type of assistive device for
severely impaired persons. Little is however known about how to optimize the
interaction of humans and brain-controlled robots. Information about the
human's perceived correctness of robot performance might provide a useful
teaching signal for adaptive control algorithms and thus help enhancing robot
control. Here, we studied whether watching robots perform erroneous vs. correct
action elicits differential brain responses that can be decoded from single
trials of electroencephalographic (EEG) recordings, and whether brain activity
during human-robot interaction is modulated by the robot's visual similarity to
a human. To address these topics, we designed two experiments. In experiment I,
participants watched a robot arm pour liquid into a cup. The robot performed
the action either erroneously or correctly, i.e. it either spilled some liquid
or not. In experiment II, participants observed two different types of robots,
humanoid and non-humanoid, grabbing a ball. The robots either managed to grab
the ball or not. We recorded high-resolution EEG during the observation tasks
in both experiments to train a Filter Bank Common Spatial Pattern (FBCSP)
pipeline on the multivariate EEG signal and decode for the correctness of the
observed action, and for the type of the observed robot. Our findings show that
it was possible to decode both correctness and robot type for the majority of
participants significantly, although often just slightly, above chance level.
Our findings suggest that non-invasive recordings of brain responses elicited
when observing robots indeed contain decodable information about the
correctness of the robot's action and the type of observed robot.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01465</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01466</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SNR Estimation in Linear Systems with Gaussian Matrices</dc:title>
 <dc:creator>Suliman, Mohamed A.</dc:creator>
 <dc:creator>Alrashdi, Ayed M.</dc:creator>
 <dc:creator>Ballal, Tarig</dc:creator>
 <dc:creator>Al-Naffouri, Tareq Y.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper proposes a highly accurate algorithm to estimate the
signal-to-noise ratio (SNR) for a linear system from a single realization of
the received signal. We assume that the linear system has a Gaussian matrix
with one sided left correlation. The unknown entries of the signal and the
noise are assumed to be independent and identically distributed with zero mean
and can be drawn from any distribution. We use the ridge regression function of
this linear model in company with tools and techniques adapted from random
matrix theory to achieve, in closed form, accurate estimation of the SNR
without prior statistical knowledge on the signal or the noise. Simulation
results are provided, and show that the proposed method is very accurate.
</dc:description>
 <dc:description>Comment: IEEE Signal Processing Letters</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:date>2017-10-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01466</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2017.2757398</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01471</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-modal Factorized Bilinear Pooling with Co-Attention Learning for
  Visual Question Answering</dc:title>
 <dc:creator>Yu, Zhou</dc:creator>
 <dc:creator>Yu, Jun</dc:creator>
 <dc:creator>Fan, Jianping</dc:creator>
 <dc:creator>Tao, Dacheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual question answering (VQA) is challenging because it requires a
simultaneous understanding of both the visual content of images and the textual
content of questions. The approaches used to represent the images and questions
in a fine-grained manner and questions and to fuse these multi-modal features
play key roles in performance. Bilinear pooling based models have been shown to
outperform traditional linear models for VQA, but their high-dimensional
representations and high computational complexity may seriously limit their
applicability in practice. For multi-modal feature fusion, here we develop a
Multi-modal Factorized Bilinear (MFB) pooling approach to efficiently and
effectively combine multi-modal features, which results in superior performance
for VQA compared with other bilinear pooling approaches. For fine-grained image
and question representation, we develop a co-attention mechanism using an
end-to-end deep network architecture to jointly learn both the image and
question attentions. Combining the proposed MFB approach with co-attention
learning in a new network architecture provides a unified model for VQA. Our
experimental results demonstrate that the single MFB with co-attention model
achieves new state-of-the-art performance on the real-world VQA dataset. Code
available at https://github.com/yuzcccc/mfb.
</dc:description>
 <dc:description>Comment: ICCV 2017</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01471</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01473</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicate Pairing for Program Verification</dc:title>
 <dc:creator>De Angelis, Emanuele</dc:creator>
 <dc:creator>Fioravanti, Fabio</dc:creator>
 <dc:creator>Pettorossi, Alberto</dc:creator>
 <dc:creator>Proietti, Maurizio</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  It is well-known that the verification of partial correctness properties of
imperative programs can be reduced to the satisfiability problem for
constrained Horn clauses (CHCs). However, state-of-the-art solvers for CHCs
(CHC solvers) based on predicate abstraction are sometimes unable to verify
satisfiability because they look for models that are definable in a given class
A of constraints, called A-definable models. We introduce a transformation
technique, called Predicate Pairing (PP), which is able, in many interesting
cases, to transform a set of clauses into an equisatisfiable set whose
satisfiability can be proved by finding an A-definable model, and hence can be
effectively verified by CHC solvers. We prove that, under very general
conditions on A, the unfold/fold transformation rules preserve the existence of
an A-definable model, i.e., if the original clauses have an A-definable model,
then the transformed clauses have an A-definable model. The converse does not
hold in general, and we provide suitable conditions under which the transformed
clauses have an A-definable model iff the original ones have an A-definable
model. Then, we present the PP strategy which guides the application of the
transformation rules with the objective of deriving a set of clauses whose
satisfiability can be proved by looking for A-definable models. PP introduces a
new predicate defined by the conjunction of two predicates together with some
constraints. We show through some examples that an A-definable model may exist
for the new predicate even if it does not exist for its defining atomic
conjuncts. We also present some case studies showing that PP plays a crucial
role in the verification of relational properties of programs (e.g., program
equivalence and non-interference). Finally, we perform an experimental
evaluation to assess the effectiveness of PP in increasing the power of CHC
solving.
</dc:description>
 <dc:description>Comment: Under consideration for publication in Theory and Practice of Logic
  Programming (TPLP)</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01476</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LIKWID Monitoring Stack: A flexible framework enabling job specific
  performance monitoring for the masses</dc:title>
 <dc:creator>R&#xf6;hl, Thomas</dc:creator>
 <dc:creator>Eitzinger, Jan</dc:creator>
 <dc:creator>Hager, Georg</dc:creator>
 <dc:creator>Wellein, Gerhard</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  System monitoring is an established tool to measure the utilization and
health of HPC systems. Usually system monitoring infrastructures make no
connection to job information and do not utilize hardware performance
monitoring (HPM) data. To increase the efficient use of HPC systems automatic
and continuous performance monitoring of jobs is an essential component. It can
help to identify pathological cases, provides instant performance feedback to
the users, offers initial data to judge on the optimization potential of
applications and helps to build a statistical foundation about application
specific system usage. The LIKWID monitoring stack is a modular framework build
on top of the LIKWID tools library. It aims on enabling job specific
performance monitoring using HPM data, system metrics and application-level
data for small to medium sized commodity clusters. Moreover, it is designed to
integrate in existing monitoring infrastructures to speed up the change from
pure system monitoring to job-aware monitoring.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures. Accepted for HPCMASPA 2017, the Workshop on
  Monitoring and Analysis for High Performance Computing Systems Plus
  Applications, held in conjunction with IEEE Cluster 2017, Honolulu, HI,
  September 5, 2017</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01477</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diffusion, Influence and Best-Response Dynamics in Networks: An Action
  Model Approach</dc:title>
 <dc:creator>Rendsvig, Rasmus K.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Threshold models and their dynamics may be used to model the spread of
`behaviors' in social networks. Regarding such from a modal logical
perspective, it is shown how standard update mechanisms may be emulated using
action models -- graphs encoding agents' decision rules. A small class of
action models capturing the possible sets of decision rules suitable for
threshold models is identified, and shown to include models characterizing
best-response dynamics of both coordination and anti-coordination games played
on graphs.
</dc:description>
 <dc:description>Comment: As appeared in R. de Haan (ed.), Proceedings of the ESSLLI 2014
  Student Session, p. 63-75, T\&quot;ubingen, Germany, 2014</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01494</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Metric Learning for Fine Grained Image Classification</dc:title>
 <dc:creator>Goel, Akashdeep</dc:creator>
 <dc:creator>Banerjee, Biplab</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper deals with the problem of fine-grained image classification and
introduces the notion of hierarchical metric learning for the same. It is
indeed challenging to categorize fine-grained image classes merely in terms of
a single level classifier given the subtle inter-class visual differences. In
order to tackle this problem, we propose a two stage framework where i) the
image categories are represented hierarchically in terms of a binary tree
structure where different subset of classes are present in the non-leaf nodes
of the tree. This is accomplished in an automatic fashion considering the
available training data in the visual domain, and ii) a (non-leaf) node
specific metric learning is further deployed for the categories constituting a
given node, thus enforcing better separation between both of its children.
Subsequently, we construct (non-leaf) node specific binary classifiers in the
learned metric spaces on which testing is henceforth carried out by following
the outcomes of the classifiers sequence from root to leaf nodes of the tree.
By separately focusing on the semantically similar classes at different levels
of the hierarchy, it is expected that the classifiers in the learned metric
spaces possess better discriminative capabilities than considering all the
classes at a single go. Experimental results obtained on two challenging
datasets (Oxford Flowers and Leeds Butterfly) establish the superiority of the
proposed framework in comparison to the standard single metric learning based
methods convincingly
</dc:description>
 <dc:description>Comment: Submitted for review in NCVPRIPG 2017</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01494</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01502</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting potential treatments for complex diseases based on miRNA and
  tissue specificity</dc:title>
 <dc:creator>Yu, Liang</dc:creator>
 <dc:creator>Zhao, Jin</dc:creator>
 <dc:creator>Gao, Lin</dc:creator>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Drug repositioning, that is finding new uses for existing drugs to treat more
patients. Cumulative studies demonstrate that the mature miRNAs as well as
their precursors can be targeted by small molecular drugs. At the same time,
human diseases result from the disordered interplay of tissue- and cell
lineage-specific processes. However, few computational researches predict
drug-disease potential relationships based on miRNA data and tissue
specificity. Therefore, based on miRNA data and the tissue specificity of
diseases, we propose a new method named as miTS to predict the potential
treatments for diseases. Firstly, based on miRNAs data, target genes and
information of FDA approved drugs, we evaluate the relationships between miRNAs
and drugs in the tissue-specific PPI network. Then, we construct a tripartite
network: drug-miRNA-disease Finally, we obtain the potential drug-disease
associations based on the tripartite network. In this paper, we take breast
cancer as case study and focus on the top-30 predicted drugs. 25 of them
(83.3%) are found having known connections with breast cancer in CTD benchmark
and the other 5 drugs are potential drugs for breast cancer. We further
evaluate the 5 newly predicted drugs from clinical records, literature mining,
KEGG pathways enrichment analysis and overlapping genes between enriched
pathways. For each of the 5 new drugs, strongly supported evidences can be
found in three or more aspects. In particular, Regorafenib has 15 overlapping
KEGG pathways with breast cancer and their p-values are all very small. In
addition, whether in the literature curation or clinical validation,
Regorafenib has a strong correlation with breast cancer. All the facts show
that Regorafenib is likely to be a truly effective drug, worthy of our further
study. It further follows that our method miTS is effective and practical for
predicting new drug indications.
</dc:description>
 <dc:date>2017-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01502</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01513</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial Mixing and Non-local Markov chains</dc:title>
 <dc:creator>Blanca, Antonio</dc:creator>
 <dc:creator>Caputo, Pietro</dc:creator>
 <dc:creator>Sinclair, Alistair</dc:creator>
 <dc:creator>Vigoda, Eric</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We consider spin systems with nearest-neighbor interactions on an $n$-vertex
$d$-dimensional cube of the integer lattice graph $\mathbb{Z}^d$. We study the
effects that exponential decay with distance of spin correlations, specifically
the strong spatial mixing condition (SSM), has on the rate of convergence to
equilibrium distribution of non-local Markov chains. We prove that SSM implies
$O(\log n)$ mixing of a block dynamics whose steps can be implemented
efficiently. We then develop a methodology, consisting of several new
comparison inequalities concerning various block dynamics, that allow us to
extend this result to other non-local dynamics. As a first application of our
method we prove that, if SSM holds, then the relaxation time (i.e., the inverse
spectral gap) of general block dynamics is $O(r)$, where $r$ is the number of
blocks. A second application of our technology concerns the Swendsen-Wang
dynamics for the ferromagnetic Ising and Potts models. We show that SSM implies
an $O(1)$ bound for the relaxation time. As a by-product of this implication we
observe that the relaxation time of the Swendsen-Wang dynamics in square boxes
of $\mathbb{Z}^2$ is $O(1)$ throughout the subcritical regime of the $q$-state
Potts model, for all $q \ge 2$. We also prove that for monotone spin systems
SSM implies that the mixing time of systematic scan dynamics is $O(\log n (\log
\log n)^2)$. Systematic scan dynamics are widely employed in practice but have
proved hard to analyze. Our proofs use a variety of techniques for the analysis
of Markov chains including coupling, functional analysis and linear algebra.
</dc:description>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01519</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Latent Variable Model for Two-Dimensional Canonical Correlation
  Analysis and its Variational Inference</dc:title>
 <dc:creator>Safayani, Mehran</dc:creator>
 <dc:creator>Momenzadeh, Saeid</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Describing the dimension reduction (DR) techniques by means of probabilistic
models has recently been given special attention. Probabilistic models, in
addition to a better interpretability of the DR methods, provide a framework
for further extensions of such algorithms. One of the new approaches to the
probabilistic DR methods is to preserving the internal structure of data. It is
meant that it is not necessary that the data first be converted from the matrix
or tensor format to the vector format in the process of dimensionality
reduction. In this paper, a latent variable model for matrix-variate data for
canonical correlation analysis (CCA) is proposed. Since in general there is not
any analytical maximum likelihood solution for this model, we present two
approaches for learning the parameters. The proposed methods are evaluated
using the synthetic data in terms of convergence and quality of mappings. Also,
real data set is employed for assessing the proposed methods with several
probabilistic and none-probabilistic CCA based approaches. The results confirm
the superiority of the proposed methods with respect to the competing
algorithms. Moreover, this model can be considered as a framework for further
extensions.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01519</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01524</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Challenges &amp; Solutions for above 6 GHz Radio Access Network Integration
  for Future Mobile Communication Systems</dc:title>
 <dc:creator>Rybakowski, Marcin</dc:creator>
 <dc:creator>Safjan, Krystian</dc:creator>
 <dc:creator>Venkatasubramanian, Venkatkumar</dc:creator>
 <dc:creator>Vijay, Arnesh</dc:creator>
 <dc:creator>Dussopt, Laurent</dc:creator>
 <dc:creator>Zaidi, Ali</dc:creator>
 <dc:creator>Peter, Michael</dc:creator>
 <dc:creator>Luo, Jian</dc:creator>
 <dc:creator>Fresia, Maria</dc:creator>
 <dc:creator>Shariat, Mehrdad</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Mobile communication technology has been rapidly evolving ever since its
first introduction in the late 1980s. The development witnessed is not just in
the refinement of the radio access techniques, but also in the progression
towards offering sophisticated features and services to the mobile phone users.
To fulfill this ever-growing user demand and market trends, frequency ranges in
millimeter wave bands are envisioned for wireless radio transmission. To
respond to this trends, the EU-funded mmMAGIC project has been launched and its
main objective is to design and develop radio access techniques operating in
6-100 GHz bands. When it comes to developing technologies for systems operating
these frequency ranges, a major challenge encountered will be in terms of its
radio access network integration. Unquestionably, issues at various aspects of
physical layer design, channel modelling, architecture, network functions and
deployment will be encountered; problems in multi-node and multi-antenna
transceiver designs will surface as well. The work carried in this project will
address those challenges and propose solutions; but additionally, measure its
efficiency against the project specific KPIs set to meet the requirements of
the operational future 5G systems. The main intention of this paper is to
outline some of the challenges, more specifically to highlight the network
integration challenges, and discuss some of its technical solutions. The
primary purpose here is to focus towards integrated 5G technology, thereby
opening further research avenues for the exploration of new and alternate
frequency bands in the electromagnetic spectrum.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01524</dc:identifier>
 <dc:identifier>doi:10.1109/ICCW.2016.7503855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01525</identifier>
 <datestamp>2017-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The physical structure of grammatical correlations: equivalences,
  formalizations and consequences</dc:title>
 <dc:creator>Gallego, Angel J.</dc:creator>
 <dc:creator>Orus, Roman</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Condensed Matter - Strongly Correlated Electrons</dc:subject>
 <dc:subject>Physics - History and Philosophy of Physics</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  In this paper we consider some well-known facts in syntax from a physics
perspective, which allows us to establish some remarkable equivalences.
Specifically, we observe that the operation MERGE put forward by N. Chomsky in
1995 can be interpreted as a physical information coarse-graining. Thus, MERGE
in linguistics entails information renormalization in physics, according to
different time scales. We make this point mathematically formal in terms of
language models, i.e., probability distributions over word sequences, widely
used in natural language processing as well as other ambits. In this setting,
MERGE corresponds to a 3-index probability tensor implementing a
coarse-graining, akin to a probabilistic context-free grammar. The probability
vectors of meaningful sentences are naturally given by tensor networks (TN)
that are mostly loop-free, such as Tree Tensor Networks and Matrix Product
States. These structures have short-ranged correlations in the syntactic
distance by construction and, because of the peculiarities of human language,
they are extremely efficient to manipulate computationally. We also propose how
to obtain such language models from probability distributions of certain TN
quantum states, which we show to be efficiently preparable by a quantum
computer. Moreover, using tools from quantum information and entanglement
theory, we use these quantum states to prove classical lower bounds on the
perplexity of the probability distribution for a set of words in a sentence.
Implications of these results are discussed in the ambits of theoretical and
computational linguistics, artificial intelligence, programming languages, RNA
and protein sequencing, quantum many-body systems, and beyond.
</dc:description>
 <dc:description>Comment: 20 pages, 21 figures. Revised version with minor corrections.
  Comments and feedback are welcomed</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:date>2017-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01525</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01541</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Associations among Image Assessments as Cost Functions in Linear
  Decomposition: MSE, SSIM, and Correlation Coefficient</dc:title>
 <dc:creator>Wang, Jianji</dc:creator>
 <dc:creator>Zheng, Nanning</dc:creator>
 <dc:creator>Chen, Badong</dc:creator>
 <dc:creator>Principe, Jose C.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The traditional methods of image assessment, such as mean squared error
(MSE), signal-to-noise ratio (SNR), and Peak signal-to-noise ratio (PSNR), are
all based on the absolute error of images. Pearson's inner-product correlation
coefficient (PCC) is also usually used to measure the similarity between
images. Structural similarity (SSIM) index is another important measurement
which has been shown to be more effective in the human vision system (HVS).
Although there are many essential differences among these image assessments,
some important associations among them as cost functions in linear
decomposition are discussed in this paper. Firstly, the selected bases from a
basis set for a target vector are the same in the linear decomposition schemes
with different cost functions MSE, SSIM, and PCC. Moreover, for a target
vector, the ratio of the corresponding affine parameters in the MSE-based
linear decomposition scheme and the SSIM-based scheme is a constant, which is
just the value of PCC between the target vector and its estimated vector.
</dc:description>
 <dc:description>Comment: 11 pages, 0 figures</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01541</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01547</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lifelong Learning with Dynamically Expandable Networks</dc:title>
 <dc:creator>Yoon, Jaehong</dc:creator>
 <dc:creator>Yang, Eunho</dc:creator>
 <dc:creator>Lee, Jeongtae</dc:creator>
 <dc:creator>Hwang, Sung ju</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:description>  We propose a novel deep network architecture for lifelong learning which we
refer to as Dynamically Expandable Network (DEN), that can dynamically decide
its network capacity as it trains on a sequence of tasks, to learn a compact
overlapping knowledge sharing structure among tasks. DEN is efficiently trained
in an online manner by performing selective retraining, dynamically expands
network capacity upon arrival of each task with only the necessary number of
units, and effectively prevents semantic drift by splitting/duplicating units
and timestamping them. We validate DEN on multiple public datasets under
lifelong learning scenarios, on which it not only significantly outperforms
existing lifelong learning methods for deep networks, but also achieves the
same level of performance as the batch counterparts with substantially fewer
number of parameters. Further, the obtained network fine-tuned on all tasks
obtained siginficantly better performance over the batch models, which shows
that it can be used to estimate the optimal network structure even when all
tasks are available in the first place.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01565</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Speaker-Independent Lipreading with Domain-Adversarial
  Training</dc:title>
 <dc:creator>Wand, Michael</dc:creator>
 <dc:creator>Schmidhuber, Juergen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a Lipreading system, i.e. a speech recognition system using only
visual features, which uses domain-adversarial training for speaker
independence. Domain-adversarial training is integrated into the optimization
of a lipreader based on a stack of feedforward and LSTM (Long Short-Term
Memory) recurrent neural networks, yielding an end-to-end trainable system
which only requires a very small number of frames of untranscribed target data
to substantially improve the recognition accuracy on the target speaker. On
pairs of different source and target speakers, we achieve a relative accuracy
improvement of around 40% with only 15 to 20 seconds of untranscribed target
speech data. On multi-speaker training setups, the accuracy improvements are
smaller but still substantial.
</dc:description>
 <dc:description>Comment: Accepted at Interspeech 2017</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01565</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01566</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Augmented Reality Meets Computer Vision : Efficient Data Generation for
  Urban Driving Scenes</dc:title>
 <dc:creator>Alhaija, Hassan Abu</dc:creator>
 <dc:creator>Mustikovela, Siva Karthik</dc:creator>
 <dc:creator>Mescheder, Lars</dc:creator>
 <dc:creator>Geiger, Andreas</dc:creator>
 <dc:creator>Rother, Carsten</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The success of deep learning in computer vision is based on availability of
large annotated datasets. To lower the need for hand labeled images, virtually
rendered 3D worlds have recently gained popularity. Creating realistic 3D
content is challenging on its own and requires significant human effort. In
this work, we propose an alternative paradigm which combines real and synthetic
data for learning semantic instance segmentation and object detection models.
Exploiting the fact that not all aspects of the scene are equally important for
this task, we propose to augment real-world imagery with virtual objects of the
target category. Capturing real-world images at large scale is easy and cheap,
and directly provides real background appearances without the need for creating
complex 3D models of the environment. We present an efficient procedure to
augment real images with virtual objects. This allows us to create realistic
composite images which exhibit both realistic background appearance and a large
number of complex object arrangements. In contrast to modeling complete 3D
environments, our augmentation approach requires only a few user interactions
in combination with 3D shapes of the target object. Through extensive
experimentation, we conclude the right set of parameters to produce augmented
data which can maximally enhance the performance of instance segmentation
models. Further, we demonstrate the utility of our approach on training
standard deep models for semantic instance segmentation and object detection of
cars in outdoor driving scenes. We test the models trained on our augmented
data on the KITTI 2015 dataset, which we have annotated with pixel-accurate
ground truth, and on Cityscapes dataset. Our experiments demonstrate that
models trained on augmented imagery generalize better than those trained on
synthetic data or models trained on limited amount of annotated real data.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01571</identifier>
 <datestamp>2017-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Standard Steady State Genetic Algorithms Can Hillclimb Faster than
  Mutation-only Evolutionary Algorithms</dc:title>
 <dc:creator>Corus, Dogan</dc:creator>
 <dc:creator>Oliveto, Pietro S.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>F.2</dc:subject>
 <dc:description>  Explaining to what extent the real power of genetic algorithms lies in the
ability of crossover to recombine individuals into higher quality solutions is
an important problem in evolutionary computation. In this paper we show how the
interplay between mutation and crossover can make genetic algorithms hillclimb
faster than their mutation-only counterparts. We devise a Markov Chain
framework that allows to rigorously prove an upper bound on the runtime of
standard steady state genetic algorithms to hillclimb the OneMax function. The
bound establishes that the steady-state genetic algorithms are 25% faster than
all standard bit mutation-only evolutionary algorithms with static mutation
rate up to lower order terms for moderate population sizes. The analysis also
suggests that larger populations may be faster than populations of size 2. We
present a lower bound for a greedy (2+1) GA that matches the upper bound for
populations larger than 2, rigorously proving that 2 individuals cannot
outperform larger population sizes under greedy selection and greedy crossover
up to lower order terms. In complementary experiments the best population size
is greater than 2 and the greedy genetic algorithms are faster than standard
ones, further suggesting that the derived lower bound also holds for the
standard steady state (2+1) GA.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:date>2017-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01572</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulation and Analysis of Quality of Service (QoS) Parameters of Voice
  over IP (VoIP) Traffic through Heterogeneous Networks</dc:title>
 <dc:creator>Miraz, Mahdi H.</dc:creator>
 <dc:creator>Molvi, Suhail A.</dc:creator>
 <dc:creator>Ganie, Muzafar A.</dc:creator>
 <dc:creator>Ali, Maaruf</dc:creator>
 <dc:creator>Hussein, AbdelRahman H.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Identifying those causes and parameters that affect the Quality of Service
(QoS) of Voice-over-Internet Protocol (VoIP) through heterogeneous networks
such as WiFi, WiMAX and between them are carried out using the OPNET simulation
tool. Optimization of the network for both intra- and intersystem traffic to
mitigate the deterioration of the QoS are discussed. The average value of the
jitter of the VoIP traffic traversing through the WiFi-WiMAX network was
observed to be higher than that of utilizing WiFi alone at some points in time.
It is routinely surmised to be less than that of transiting across the WiFi
network only and obviously higher than passing through the increased bandwidth
network of WiMAX. Moreover, both the values of the packet end-to-end delay and
the Mean Opinion Score (MOS) were considerably higher than expected. The
consequences of this optimization, leading to a solution, which can ameliorate
the QoS over these networks are analyzed and offered as the conclusion of this
ongoing research.
</dc:description>
 <dc:description>Comment: Voice over Internet Protocol (VoIP); Quality of Service (QoS); Mean
  Opinion Score (MOS); simulation</dc:description>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01572</dc:identifier>
 <dc:identifier>International Journal of Advanced Computer Science and
  Applications (IJACSA) Online ISSN: 2156-5570, Print ISSN: 2158-107X, Volume 8
  No 7 July 2017, pp. 242-248, published by Science and Information (SAI)
  Organization</dc:identifier>
 <dc:identifier>doi:10.14569/IJACSA.2017.080732</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01580</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sensing Urban Land-Use Patterns By Integrating Google Tensorflow And
  Scene-Classification Models</dc:title>
 <dc:creator>Yao, Yao</dc:creator>
 <dc:creator>Liang, Haolin</dc:creator>
 <dc:creator>Li, Xia</dc:creator>
 <dc:creator>Zhang, Jinbao</dc:creator>
 <dc:creator>He, Jialv</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With the rapid progress of China's urbanization, research on the automatic
detection of land-use patterns in Chinese cities is of substantial importance.
Deep learning is an effective method to extract image features. To take
advantage of the deep-learning method in detecting urban land-use patterns, we
applied a transfer-learning-based remote-sensing image approach to extract and
classify features. Using the Google Tensorflow framework, a powerful
convolution neural network (CNN) library was created. First, the transferred
model was previously trained on ImageNet, one of the largest object-image data
sets, to fully develop the model's ability to generate feature vectors of
standard remote-sensing land-cover data sets (UC Merced and WHU-SIRI). Then, a
random-forest-based classifier was constructed and trained on these generated
vectors to classify the actual urban land-use pattern on the scale of traffic
analysis zones (TAZs). To avoid the multi-scale effect of remote-sensing
imagery, a large random patch (LRP) method was used. The proposed method could
efficiently obtain acceptable accuracy (OA = 0.794, Kappa = 0.737) for the
study area. In addition, the results show that the proposed method can
effectively overcome the multi-scale effect that occurs in urban land-use
classification at the irregular land-parcel level. The proposed method can help
planners monitor dynamic urban land use and evaluate the impact of
urban-planning schemes.
</dc:description>
 <dc:description>Comment: 8 pages, 8 figures, 2 tables</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01580</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01583</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Recovery of Missing Data in Electricity Distribution Systems</dc:title>
 <dc:creator>Genes, Cristian</dc:creator>
 <dc:creator>Esnaola, I&#xf1;aki</dc:creator>
 <dc:creator>Perlaza, Samir. M.</dc:creator>
 <dc:creator>Ochoa, Luis F.</dc:creator>
 <dc:creator>Coca, Daniel</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The advanced operation of future electricity distribution systems is likely
to require significant observability of the different parameters of interest
(e.g., demand, voltages, currents, etc.). Ensuring completeness of data is,
therefore, paramount. In this context, an algorithm for recovering missing
state variable observations in electricity distribution systems is presented.
The proposed method exploits the low rank structure of the state variables via
a matrix completion approach while incorporating prior knowledge in the form of
second order statistics. Specifically, the recovery method combines nuclear
norm minimization with Bayesian estimation. The performance of the new
algorithm is compared to the information-theoretic limits and tested trough
simulations using real data of an urban low voltage distribution system. The
impact of the prior knowledge is analyzed when a mismatched covariance is used
and for a Markovian sampling that introduces structure in the observation
pattern. Numerical results demonstrate that the proposed algorithm is robust
and outperforms existing state of the art algorithms.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Trans. Smart Grid</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01589</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Region-Based Multiscale Spatiotemporal Saliency for Video</dc:title>
 <dc:creator>Le, Trung-Nghia</dc:creator>
 <dc:creator>Sugimoto, Akihiro</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Detecting salient objects from a video requires exploiting both spatial and
temporal knowledge included in the video. We propose a novel region-based
multiscale spatiotemporal saliency detection method for videos, where static
features and dynamic features computed from the low and middle levels are
combined together. Our method utilizes such combined features spatially over
each frame and, at the same time, temporally across frames using consistency
between consecutive frames. Saliency cues in our method are analyzed through a
multiscale segmentation model, and fused across scale levels, yielding to
exploring regions efficiently. An adaptive temporal window using motion
information is also developed to combine saliency values of consecutive frames
in order to keep temporal consistency across frames. Performance evaluation on
several popular benchmark datasets validates that our method outperforms
existing state-of-the-arts.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01589</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01590</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounding the size of an almost-equidistant set in Euclidean space</dc:title>
 <dc:creator>Kupavskii, Andrey</dc:creator>
 <dc:creator>Mustafa, Nabil H.</dc:creator>
 <dc:creator>Swanepoel, Konrad J.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:subject>52C10</dc:subject>
 <dc:description>  A set of points in d-dimensional Euclidean space is almost equidistant if
among any three points of the set, some two are at distance 1. We show that an
almost-equidistant set in $\mathbb{R}^d$ has cardinality $O(d^{4/3})$.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01590</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01599</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Agent based Tools for Modeling and Simulation of Self-Organization in
  Peer-to-Peer, Ad-Hoc and other Complex Networks</dc:title>
 <dc:creator>Niazi, Muaz A.</dc:creator>
 <dc:creator>Hussain, Amir</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>C.2</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:subject>D.4.8</dc:subject>
 <dc:subject>I.6</dc:subject>
 <dc:subject>I.6.5</dc:subject>
 <dc:description>  Agent-based modeling and simulation tools provide a mature platform for
development of complex simulations. They however, have not been applied much in
the domain of mainstream modeling and simulation of computer networks. In this
article, we evaluate how and if these tools can offer any value-addition in the
modeling &amp; simulation of complex networks such as pervasive computing,
large-scale peer-to-peer systems, and networks involving considerable
environment and human/animal/habitat interaction. Specifically, we demonstrate
the effectiveness of NetLogo - a tool that has been widely used in the area of
agent-based social simulation.
</dc:description>
 <dc:description>Comment: 20 pages, 6 figures</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01599</dc:identifier>
 <dc:identifier>IEEE Communications Magazine, 47(3), 163 - 173 (2009)</dc:identifier>
 <dc:identifier>doi:10.1109/MCOM.2009.4804403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01601</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Clinical and Finite Elements Study of Stress Urinary Incontinence in
  Women Using Fluid-Structure Interactions</dc:title>
 <dc:creator>Barzegari, Mojtaba</dc:creator>
 <dc:creator>Vahidi, Bahman</dc:creator>
 <dc:creator>Safarinejad, Mohammad Reza</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Stress Urinary Incontinence (SUI) or urine leakage from urethra occurs due to
an increase in abdominal pressure resulting from stress like a cough or jumping
height. SUI is more frequent among post-menopausal women. In the absence of
bladder contraction, vesical pressure exceeds from urethral pressure leading to
urine leakage. Despite a large number of patients diagnosed with this problem,
few studies have investigated its function and mechanics. The main goal of this
study is to model bladder and urethra computationally under an external
pressure like sneezing. Finite Element Method and Fluid-Structure Interactions
are utilized for simulation. Linear mechanical properties assigned to the
bladder and urethra and pressure boundary conditions are indispensable in this
model. The results show good accordance between the clinical data and predicted
values of the computational models, such as the pressure at the center of the
bladder. This indicates that numerical methods and simplified physics of
biological systems like inferior urinary tract are helpful to achieve the
results similar to clinical results, in order to investigate pathological
conditions.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01608</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A criterion for bubble merging in liquid metal: computational and
  experimental study</dc:title>
 <dc:creator>Barzegari, Mojtaba</dc:creator>
 <dc:creator>Bayani, Hossein</dc:creator>
 <dc:creator>Mirbagheri, S. M. H.</dc:creator>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  An innovative model is presented for merging of bubbles inside a liquid
metal. The proposed model is based on forming a thin film (narrow channel)
between merging bubbles during growth. Rupturing of the film occurs when an
oscillation in velocity and pressure arises inside the channel followed by
merging of the bubbles. The proposed model based on lattice Boltzmann Method is
capable of simulating merging bubbles in micro, meso, and macro-scales with no
limitation on the number of bubbles. Experimental studies reveal a good
consistency between modeling results and real conditions.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01608</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01610</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A novel X-FEM based fast computational method for crack propagation</dc:title>
 <dc:creator>Cheng, Zhenxing</dc:creator>
 <dc:creator>Wang, Hu</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  This study suggests a fast computational method for crack propagation, which
is based on the extended finite element method (X-FEM). It is well known that
the X-FEM might be the most popular numerical method for crack propagation.
However, with the increase of complexity of the given problem, the size of FE
model and the number of iterative steps are increased correspondingly. To
improve the efficiency of X-FEM, an efficient computational method termed
decomposed updating reanalysis (DUR) method is suggested. For most of X-FEM
simulation procedures, the change of each iterative step is small and it will
only lead a local change of stiffness matrix. Therefore, the DUR method is
proposed to predict the modified response by only calculating the changed part
of equilibrium equations. Compared with other fast computational methods, the
distinctive characteristic of the proposed method is to update the modified
stiffness matrix with a local updating strategy, which only the changed part of
stiffness matrix needs to be updated. To verify the performance of the DUR
method, several typical numerical examples have been analyzed and the results
demonstrate that this method is a highly efficient method with high accuracy.
</dc:description>
 <dc:description>Comment: 22 figures, 6 tables</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01610</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01611</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identification of Probabilities</dc:title>
 <dc:creator>Vitanyi, Paul M. B.</dc:creator>
 <dc:creator>Chater, Nick</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Within psychology, neuroscience and artificial intelligence, there has been
increasing interest in the proposal that the brain builds probabilistic models
of sensory and linguistic input: that is, to infer a probabilistic model from a
sample. The practical problems of such inference are substantial: the brain has
limited data and restricted computational resources. But there is a more
fundamental question: is the problem of inferring a probabilistic model from a
sample possible even in principle? We explore this question and find some
surprisingly positive and general results. First, for a broad class of
probability distributions characterised by computability restrictions, we
specify a learning algorithm that will almost surely identify a probability
distribution in the limit given a finite i.i.d. sample of sufficient but
unknown length. This is similarly shown to hold for sequences generated by a
broad class of Markov chains, subject to computability assumptions. The
technical tool is the strong law of large numbers. Second, for a large class of
dependent sequences, we specify an algorithm which identifies in the limit a
computable measure for which the sequence is typical, in the sense of
Martin-Lof (there may be more than one such measure). The technical tool is the
theory of Kolmogorov complexity. We analyse the associated predictions in both
cases. We also briefly consider special cases, including language learning, and
wider theoretical implications for psychology.
</dc:description>
 <dc:description>Comment: 31 pages LaTeX. arXiv admin note: substantial text overlap with
  arXiv:1311.7385</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01611</dc:identifier>
 <dc:identifier>Journal of Mathematical Psychology 51, 135-163 (2007)</dc:identifier>
 <dc:identifier>doi:10.1016/j.jmp.2006.10.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01613</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiphase Aluminum A356 Foam Formation Process Simulation Using Lattice
  Boltzmann Method</dc:title>
 <dc:creator>Barzegari, Mojtaba</dc:creator>
 <dc:creator>Bayani, Hossein</dc:creator>
 <dc:creator>Mirbagheri, S. M. H.</dc:creator>
 <dc:creator>Shetabivash, Hasan</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:description>  Shan-Chen model is a numerical scheme to simulate multiphase fluid flows
using Lattice Boltzmann approach. The original Shan-Chen model suffers from
inability to accurately predict behavior of air bubbles interacting in a
non-aqueous fluid. In the present study, we extended the Shan-Chen model to
take the effect of the attraction-repulsion barriers among bubbles in to
account. The proposed model corrects the interaction and coalescence criterion
of the original Shan-Chen scheme in order to have a more accurate simulation of
bubbles morphology in a metal foam. The model is based on forming a thin film
(narrow channel) between merging bubbles during growth. Rupturing of the film
occurs when an oscillation in velocity and pressure arises inside the channel
followed by merging of the bubbles. Comparing numerical results obtained from
proposed model with mettallorgraphy images for aluminum A356 demonstrated a
good consistency in mean bubble size and bubbles distribution
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01625</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Traffic flow optimization using a quantum annealer</dc:title>
 <dc:creator>Neukart, Florian</dc:creator>
 <dc:creator>Compostella, Gabriele</dc:creator>
 <dc:creator>Seidel, Christian</dc:creator>
 <dc:creator>von Dollen, David</dc:creator>
 <dc:creator>Yarkoni, Sheir</dc:creator>
 <dc:creator>Parney, Bob</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Quantum annealing algorithms belong to the class of meta-heuristic tools,
applicable for solving binary optimization problems. Hardware implementations
of quantum annealing, such as the quantum processing units (QPUs) produced by
D-Wave Systems, have been subject to multiple analyses in research, with the
aim of characterizing the technology's usefulness for optimization and sampling
tasks. In this paper, we present a real-world application that uses quantum
technologies. Specifically, we show how to map certain parts of the real-world
traffic flow optimization problem to be suitable for quantum annealing. We show
that time-critical optimization tasks, such as continuous redistribution of
position data for cars in dense road networks, are suitable candidates for
quantum applications. Due to the limited size and connectivity of
current-generation D-Wave QPUs, we use a hybrid quantum and classical approach
to solve the traffic flow problem.
</dc:description>
 <dc:description>Comment: 17 pages, 6 figures</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01625</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01628</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Validation of Enhanced Emotion Enabled Cognitive Agent Using Virtual
  Overlay Multi-Agent System Approach</dc:title>
 <dc:creator>Riaz, Faisal</dc:creator>
 <dc:creator>Niazi, Muaz A.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>I.2.11, I.2.9, J.7, I.2, I.2.0, I.6, I.6.4, D.2.4, D.4.5, G.4</dc:subject>
 <dc:description>  Making roads safer by avoiding road collisions is one of the main reasons for
inventing Autonomous vehicles (AVs). In this context, designing agent-based
collision avoidance components of AVs which truly represent human cognition and
emotions look is a more feasible approach as agents can replace human drivers.
However, to the best of our knowledge, very few human emotion and
cognition-inspired agent-based studies have previously been conducted in this
domain. Furthermore, these agent-based solutions have not been validated using
any key validation technique. Keeping in view this lack of validation
practices, we have selected state-of-the-art Emotion Enabled Cognitive Agent
(EEC_Agent), which was proposed to avoid lateral collisions between semi-AVs.
The architecture of EEC_Agent has been revised using Exploratory Agent Based
Modeling (EABM) level of the Cognitive Agent Based Computing (CABC) framework
and real-time fear emotion generation mechanism using the Ortony, Clore &amp;
Collins (OCC) model has also been introduced. Then the proposed fear generation
mechanism has been validated using the Validated Agent Based Modeling level of
CABC framework using a Virtual Overlay MultiAgent System (VOMAS). Extensive
simulation and practical experiments demonstrate that the Enhanced EEC_Agent
exhibits the capability to feel different levels of fear, according to
different traffic situations and also needs a smaller Stopping Sight Distance
(SSD) and Overtaking Sight Distance (OSD) as compared to human drivers.
</dc:description>
 <dc:description>Comment: 35 pages, 21 figures, 19 tables</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01628</dc:identifier>
 <dc:identifier>Broad Research in Artificial Intelligence and Neuroscience 8.3
  (2017): 13-37</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01632</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Localization of Electrical Flows</dc:title>
 <dc:creator>Schild, Aaron</dc:creator>
 <dc:creator>Rao, Satish</dc:creator>
 <dc:creator>Srivastava, Nikhil</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We show that in any graph, the average length of a flow path in an electrical
flow between the endpoints of a random edge is $O(\log^2 n)$. This is a
consequence of a more general result which shows that the spectral norm of the
entrywise absolute value of the transfer impedance matrix of a graph is
$O(\log^2 n)$. This result implies a simple oblivious routing scheme based on
electrical flows in the case of transitive graphs.
</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01632</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1708.01636</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Game theory models for communication between agents: a review</dc:title>
 <dc:creator>Farooqui, Aisha D.</dc:creator>
 <dc:creator>Niazi, Muaz A.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>I.2.11, C.2, F.4, H.1, I.5.1</dc:subject>
 <dc:description>  In the real world, agents or entities are in a continuous state of
interactions. These inter- actions lead to various types of complexity
dynamics. One key difficulty in the study of complex agent interactions is the
difficulty of modeling agent communication on the basis of rewards. Game theory
offers a perspective of analysis and modeling these interactions. Previously,
while a large amount of literature is available on game theory, most of it is
from specific domains and does not cater for the concepts from an agent- based
perspective. Here in this paper, we present a comprehensive multidisciplinary
state-of-the-art review and taxonomy of game theory models of complex
interactions between agents.
</dc:description>
 <dc:description>Comment: 31 pages, 7 figures</dc:description>
 <dc:date>2017-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1708.01636</dc:identifier>
 <dc:identifier>Complex Adaptive Systems Modeling, 4(1), 13. (2016)</dc:identifier>
 <dc:identifier>doi:10.1186/s40294-016-0026-7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="130000" completeListSize="155308">2369777|131001</resumptionToken>
</ListRecords>
</OAI-PMH>
