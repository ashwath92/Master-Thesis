<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2018-01-29T03:11:07Z</responseDate>
<request verb="ListRecords" resumptionToken="2369777|104001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05008</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A conjecture about Gauss sums and bentness of binomial Boolean functions</dc:title>
 <dc:creator>Flori, Jean-Pierre</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this note, the polar decomposition of binary fields of even extension
degree is used to reduce the evaluation of the Walsh transform of binomial
Boolean functions to that of Gauss sums. In the case of extensions of degree
four times an odd number, an explicit formula involving a Kloosterman sum is
conjectured, proved with further restrictions, and supported by extensive
experimental data in the general case. In particular, the validity of this
formula is shown to be equivalent to a simple and efficient characterization
for bentness previously conjectured by Mesnager.
</dc:description>
 <dc:date>2016-08-16</dc:date>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05011</identifier>
 <datestamp>2016-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Introduction to the Case Management Model and Notation (CMMN)</dc:title>
 <dc:creator>Marin, Mike A.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  This is a short tutorial of the Case Management Model and Notation (CMMN)
version 1.0. It is targeted to readers with knowledge of basic process or
workflow modeling, and it covers the complete CMMN notation. A simple
complaints process is used to demonstrate the notation. At the end of the
tutorial the reader will be able to understand and create CMMN models. An
appendix summarizing the notation is included for reference purposes.
</dc:description>
 <dc:description>Comment: This tutorial was used as part of a CMMN survey. An interactive but
  shorter version of this tutorial is available online at
  http://cmmn.byethost4.com</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05014</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Path-based vs. Distributional Information in Recognizing Lexical
  Semantic Relations</dc:title>
 <dc:creator>Shwartz, Vered</dc:creator>
 <dc:creator>Dagan, Ido</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recognizing various semantic relations between terms is beneficial for many
NLP tasks. While path-based and distributional information sources are
considered complementary for this task, the superior results the latter showed
recently suggested that the former's contribution might have become obsolete.
We follow the recent success of an integrated neural method for hypernymy
detection (Shwartz et al., 2016) and extend it to recognize multiple relations.
The empirical results show that this method is effective in the multiclass
setting as well. We further show that the path-based information source always
contributes to the classification, and analyze the cases in which it mostly
complements the distributional information.
</dc:description>
 <dc:description>Comment: 5 pages, accepted to the 5th Workshop on Cognitive Aspects of the
  Lexicon (CogALex-V), in COLING 2016</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05031</identifier>
 <datestamp>2016-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Topology of Distribution Grids using only Terminal Node
  Measurements</dc:title>
 <dc:creator>Deka, Deepjyoti</dc:creator>
 <dc:creator>Backhaus, Scott</dc:creator>
 <dc:creator>Chertkov, Michael</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Distribution grids include medium and low voltage lines that are involved in
the delivery of electricity from substation to end-users/loads. A distribution
grid is operated in a radial/tree-like structure, determined by switching on or
off lines from an underling loopy graph. Due to the presence of limited
real-time measurements, the critical problem of fast estimation of the radial
grid structure is not straightforward. This paper presents a new learning
algorithm that uses measurements only at the terminal or leaf nodes in the
distribution grid to estimate its radial structure. The algorithm is based on
results involving voltages of node triplets that arise due to the radial
structure. The polynomial computational complexity of the algorithm is
presented along with a detailed analysis of its working. The most significant
contribution of the approach is that it is able to learn the structure in
certain cases where available measurements are confined to only half of the
nodes. This represents learning under minimum permissible observability.
Performance of the proposed approach in learning structure is demonstrated by
experiments on test radial distribution grids.
</dc:description>
 <dc:description>Comment: A version of this paper will appear in IEEE Smartgridcomm 2016 (7
  pages, 7 figures)</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05043</identifier>
 <datestamp>2016-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On semiring complexity of Schur polynomials</dc:title>
 <dc:creator>Fomin, Sergey</dc:creator>
 <dc:creator>Grigoriev, Dima</dc:creator>
 <dc:creator>Nogneng, Dorian</dc:creator>
 <dc:creator>Schost, Eric</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>68Q25, 05E05</dc:subject>
 <dc:description>  Semiring complexity is the version of arithmetic circuit complexity that
allows only two operations: addition and multiplication. We show that when the
number of variables is fixed, the semiring complexity of a Schur polynomial
$s_\lambda$ is $O(log(\lambda_1))$; here $\lambda_1$ is the largest part of the
partition $\lambda$.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05044</identifier>
 <datestamp>2016-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulation of an Optional Strategy in the Prisoner's Dilemma in Spatial
  and Non-spatial Environments</dc:title>
 <dc:creator>Cardinot, Marcos</dc:creator>
 <dc:creator>Gibbons, Maud</dc:creator>
 <dc:creator>O'Riordan, Colm</dc:creator>
 <dc:creator>Griffith, Josephine</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  This paper presents research comparing the effects of different environments
on the outcome of an extended Prisoner's Dilemma, in which agents have the
option to abstain from playing the game. We consider three different pure
strategies: cooperation, defection and abstinence. We adopt an evolutionary
game theoretic approach and consider two different environments: the first
which imposes no spatial constraints and the second in which agents are placed
on a lattice grid. We analyse the performance of the three strategies as we
vary the loner's payoff in both structured and unstructured environments.
Furthermore we also present the results of simulations which identify scenarios
in which cooperative clusters of agents emerge and persist in both
environments.
</dc:description>
 <dc:description>Comment: 12 pages, 8 figures. International Conference on the Simulation of
  Adaptive Behavior</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05044</dc:identifier>
 <dc:identifier>From Animals to Animats 14 (pp. 145-156). Springer International
  Publishing, 2016</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-43488-9_14</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05045</identifier>
 <datestamp>2016-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large Angle based Skeleton Extraction for 3D Animation</dc:title>
 <dc:creator>Martin, Hugo</dc:creator>
 <dc:creator>Fernandez, Raphael</dc:creator>
 <dc:creator>Khoo, Yong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we present a solution for arbitrary 3D character deformation
by investigating rotation angle of decomposition and preserving the mesh
topology structure. In computer graphics, skeleton extraction and
skeleton-driven animation is an active areas and gains increasing interests
from researchers. The accuracy is critical for realistic animation and related
applications. There have been extensive studies on skeleton based 3D
deformation. However for the scenarios of large angle rotation of different
body parts, it has been relatively less addressed by the state-of-the-art,
which often yield unsatisfactory results. Besides 3D animation problems, we
also notice for many 3D skeleton detection or tracking applications from a
video or depth streams, large angle rotation is also a critical factor in the
regression accuracy and robustness. We introduced a distortion metric function
to quantify the surface curviness before and after deformation, which is a
major clue for large angle rotation detection. The intensive experimental
results show that our method is suitable for 3D modeling, animation, skeleton
based tracking applications.
</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05045</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05046</identifier>
 <datestamp>2016-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical optimal experiment design with probabilistic programs</dc:title>
 <dc:creator>Ouyang, Long</dc:creator>
 <dc:creator>Tessler, Michael Henry</dc:creator>
 <dc:creator>Ly, Daniel</dc:creator>
 <dc:creator>Goodman, Noah</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Scientists often run experiments to distinguish competing theories. This
requires patience, rigor, and ingenuity - there is often a large space of
possible experiments one could run. But we need not comb this space by hand -
if we represent our theories as formal models and explicitly declare the space
of experiments, we can automate the search for good experiments, looking for
those with high expected information gain. Here, we present a general and
principled approach to experiment design based on probabilistic programming
languages (PPLs). PPLs offer a clean separation between declaring problems and
solving them, which means that the scientist can automate experiment design by
simply declaring her model and experiment spaces in the PPL without having to
worry about the details of calculating information gain. We demonstrate our
system in two case studies drawn from cognitive psychology, where we use it to
design optimal experiments in the domains of sequence prediction and
categorization. We find strong empirical validation that our automatically
designed experiments were indeed optimal. We conclude by discussing a number of
interesting questions for future research.
</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05054</identifier>
 <datestamp>2016-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MT3S: Mobile Turkish Scene Text-to-Speech System for the Visually
  Impaired</dc:title>
 <dc:creator>Bastan, Muhammet</dc:creator>
 <dc:creator>Kandemir, Hilal</dc:creator>
 <dc:creator>Canturk, Busra</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Reading text is one of the essential needs of the visually impaired people.
We developed a mobile system that can read Turkish scene and book text, using a
fast gradient-based multi-scale text detection algorithm for real-time
operation and Tesseract OCR engine for character recognition. We evaluated the
OCR accuracy and running time of our system on a new, publicly available mobile
Turkish scene text dataset we constructed and also compared with
state-of-the-art systems. Our system proved to be much faster, able to run on a
mobile device, with OCR accuracy comparable to the state-of-the-art.
</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05054</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05064</identifier>
 <datestamp>2016-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tractable Structure Learning in Radial Physical Flow Networks</dc:title>
 <dc:creator>Deka, Deepjyoti</dc:creator>
 <dc:creator>Backhaus, Scott</dc:creator>
 <dc:creator>Chertkov, Michael</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Physical Flow Networks are different infrastructure networks that allow the
flow of physical commodities through edges between its constituent nodes. These
include power grid, natural gas transmission network, water pipelines etc. In
such networks, the flow on each edge is characterized by a function of the
nodal potentials on either side of the edge. Further the net flow in and out of
each node is conserved. Learning the structure and state of physical networks
is necessary for optimal control as well as to quantify its privacy needs. We
consider radial flow networks and study the problem of learning the operational
network from a loopy graph of candidate edges using statistics of nodal
potentials. Based on the monotonic properties of the flow functions, the key
result in this paper shows that if variance of the difference of nodal
potentials is used to weight candidate edges, the operational edges form the
minimum spanning tree in the loopy graph. Under realistic conditions on the
statistics of nodal injection (consumption or production), we provide a greedy
structure learning algorithm with quasilinear computational complexity in the
number of candidate edges in the network. Our learning framework is very
general due to two significant attributes. First it is independent of the
specific marginal distributions of nodal potentials and only uses order
properties in their second moments. Second, the learning algorithm is agnostic
to exact flow functions that relate edge flows to corresponding potential
differences and is applicable for a broad class of networks with monotonic flow
functions. We demonstrate the efficacy of our work through realistic
simulations on diverse physical flow networks and discuss possible extensions
of our work to other regimes.
</dc:description>
 <dc:description>Comment: A version of this paper will appear in IEEE CDC 2016 (8 pages, 5
  figures)</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05064</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05069</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Holistic Small Cell Traffic Balancing across Licensed and Unlicensed
  Bands</dc:title>
 <dc:creator>Challita, Ursula</dc:creator>
 <dc:creator>Marina, Mahesh K.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Due to the dramatic growth in mobile data traffic on one hand and the
scarcity of the licensed spectrum on the other hand, mobile operators are
considering the use of unlicensed bands (especially those in 5 GHz) as
complementary spectrum for providing higher system capacity and better user
experience. This approach is currently being standardized by 3GPP under the
name of LTE Licensed-Assisted Access (LTE-LAA). In this paper, we take a
holistic approach for LTE-LAA small cell traffic balancing by jointly
optimizing the use of the licensed and unlicensed bands. We pose this traffic
balancing as an optimization problem that seeks proportional fair coexistence
of WiFi, small cell and macro cell users by adapting the transmission
probability of the LTE-LAA small cell in the licensed and unlicensed bands. The
motivation for this formulation is for the LTE-LAA small cell to switch between
or aggregate licensed and unlicensed bands depending on the
interference/traffic level and the number of active users in each band. We
derive a closed form solution for this optimization problem and additionally
propose a transmission mechanism for the operation of the LTE-LAA small cell on
both bands. Through numerical and simulation results, we show that our proposed
traffic balancing scheme, besides enabling better LTE-WiFi coexistence and
efficient utilization of the radio resources relative to the existing traffic
balancing scheme, also provides a better tradeoff between maximizing the total
network throughput and achieving fairness among all network flows compared to
alternative approaches.
</dc:description>
 <dc:description>Comment: Accepted for publication at MSWiM 2016</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:date>2016-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05069</dc:identifier>
 <dc:identifier>doi:10.1145/2988287.2989143</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05081</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BBQ-Networks: Efficient Exploration in Deep Reinforcement Learning for
  Task-Oriented Dialogue Systems</dc:title>
 <dc:creator>Lipton, Zachary C.</dc:creator>
 <dc:creator>Li, Xiujun</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:creator>Li, Lihong</dc:creator>
 <dc:creator>Ahmed, Faisal</dc:creator>
 <dc:creator>Deng, Li</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a new algorithm that significantly improves the efficiency of
exploration for deep Q-learning agents in dialogue systems. Our agents explore
via Thompson sampling, drawing Monte Carlo samples from a Bayes-by-Backprop
neural network. Our algorithm learns much faster than common exploration
strategies such as $\epsilon$-greedy, Boltzmann, bootstrapping, and
intrinsic-reward-based ones. Additionally, we show that spiking the replay
buffer with experiences from just a few successful episodes can make Q-learning
feasible when it might otherwise fail.
</dc:description>
 <dc:description>Comment: 13 pages, 9 figures</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:date>2017-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05094</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tolerant Compressed Sensing With Partially Coherent Sensing Matrices</dc:title>
 <dc:creator>Birnbaum, Tobias</dc:creator>
 <dc:creator>Eldar, Yonina C.</dc:creator>
 <dc:creator>Needell, Deanna</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A12</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:subject>H.1.1</dc:subject>
 <dc:subject>G.1.0</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  Most of compressed sensing (CS) theory to date is focused on incoherent
sensing, that is, columns from the sensing matrix are highly uncorrelated.
However, sensing systems with naturally occurring correlations arise in many
applications, such as signal detection, motion detection and radar. Moreover,
in these applications it is often not necessary to know the support of the
signal exactly, but instead small errors in the support and signal are
tolerable.
  Despite the abundance of work utilizing incoherent sensing matrices, for this
type of tolerant recovery we suggest that coherence is actually beneficial. We
promote the use of coherent sampling when tolerant support recovery is
acceptable, and demonstrate its advantages empirically. In addition, we provide
a first step towards theoretical analysis by considering a specific
reconstruction method for selected signal classes.
</dc:description>
 <dc:description>Comment: 15 pages, 13 figures</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:date>2017-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05094</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05097</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secret Sharing With Trusted Third Parties Using Piggy Bank Protocol</dc:title>
 <dc:creator>Memon, Adnan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This paper presents a new scheme to distribute secret shares using two
trusted third parties to increase security and eliminate the dependency on
single trusted third party. This protocol for communication between a device
and two trusted third parties uses the piggy bank cryptographic paradigm. We
also present a protocol to give law enforcing agencies access to sensitive
information present on a cell phone or a device using secret sharing scheme.
The ideas for classical systems may also be applied to quantum schemes.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05097</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05098</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A unified approach to autocorrelation of Frank, Chu, and Milewski
  sequences</dc:title>
 <dc:creator>Mercer, Idris</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We construct a family of perfect polyphase sequences that has the Frank
sequences, Chu sequences, and Milewski sequences as special cases. This is not
the most general construction of this type, but it has a particularly simple
form. We also include some remarks about the acyclic autocorrelations of our
sequences.
</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05098</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05100</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>In-Place Sparse Suffix Sorting</dc:title>
 <dc:creator>Prezza, Nicola</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Suffix arrays encode the lexicographical order of all suffixes of a text and
are often combined with the Longest Common Prefix array (LCP) to simulate
navigational queries on the suffix tree in reduced space. In space-critical
applications such as sparse and compressed text indexing, only information
regarding the lexicographical order of a size-$b$ subset of all $n$ text
suffixes is often needed. Such information can be stored space-efficiently (in
$b$ words) in the sparse suffix array (SSA). The SSA and its relative sparse
LCP array (SLCP) can be used as a space-efficient substitute of the sparse
suffix tree. Very recently, Gawrychowski and Kociumaka [SODA 2017] showed that
the sparse suffix tree (and therefore SSA and SLCP) can be built in
asymptotically optimal $O(b)$ space with a Monte Carlo algorithm running in
$O(n)$ time. The main reason for using the SSA and SLCP arrays in place of the
sparse suffix tree is, however, their reduced space of $b$ words each. This
leads naturally to the quest for in-place algorithms building these arrays.
Franceschini and Muthukrishnan [ICALP 2007] showed that the full suffix array
can be built in-place and in optimal running time. On the other hand, finding
sub-quadratic in-place algorithms for building the SSA and SLCP for
\emph{general} subsets of suffixes has been an elusive task for decades. In
this paper, we give the first solution to this problem. We provide the first
in-place algorithm building the full LCP array in $O(n\log n)$ expected time
and the first Monte Carlo in-place algorithms building the SSA and SLCP in $O(n
+ b\log^2 n)$ expected time. We moreover describe the first in-place solution
for the suffix selection problem: to compute the $i$-th smallest text suffix.
</dc:description>
 <dc:description>Comment: ACM-SIAM Symposium on Discrete Algorithms 2018; arXiv admin note:
  text overlap with arXiv:1607.06660 Comment: new style (lipics); using
  Heath-Brown theorem for number of primes in Z; improved bounds for LCP array
  computation and sparse suffix sorting; added construction of the LCE
  structure using radix sort; added reference to lower bound for LCE query
  times; uploaded version accepted at SODA 2018</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05102</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complex Correntropy: Probabilistic Interpretation and Optimization</dc:title>
 <dc:creator>Guimar&#xe3;es, Jo&#xe3;o Paulo Ferreira</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Recent studies have demonstrated that correntropy is an efficient tool for
analyzing higher-order statistical moments in nonGaussian noise environments.
Although correntropy has been used with complex data, no theoretical study was
pursued to elucidate its properties, nor how to best use it for optimization.
This paper presents a probabilistic interpretation for correntropy using
complex-valued data called complex correntropy. A recursive solution for the
maximum complex correntropy criterion (MCCC) is introduced based on a fixed
point solution. This technique is applied to a simple system identification
case study, and the results demonstrate prominent advantages when compared to
the complex recursive least squares (RLS) algorithm. By using such
probabilistic interpretation, correntropy can be applied to solve several
problems involving complex data in a more straightforward way. Keywords:
complex-valued data correntropy, maximum complex correntropy criterion,
fixed-point algorithm.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1606.04761</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05104</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scene Labeling Through Knowledge-Based Rules Employing Constrained
  Integer Linear Programing</dc:title>
 <dc:creator>Souly, Nasim</dc:creator>
 <dc:creator>Shah, Mubarak</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Scene labeling task is to segment the image into meaningful regions and
categorize them into classes of objects which comprised the image. Commonly
used methods typically find the local features for each segment and label them
using classifiers. Afterward, labeling is smoothed in order to make sure that
neighboring regions receive similar labels. However, they ignore expressive and
non-local dependencies among regions due to expensive training and inference.
In this paper, we propose to use high-level knowledge regarding rules in the
inference to incorporate dependencies among regions in the image to improve
scores of classification. Towards this aim, we extract these rules from data
and transform them into constraints for Integer Programming to optimize the
structured problem of assigning labels to super-pixels (consequently pixels) of
an image. In addition, we propose to use soft-constraints in some scenarios,
allowing violating the constraint by imposing a penalty, to make the model more
flexible. We assessed our approach on three datasets and obtained promising
results.
</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05105</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolutionary Approaches to Optimization Problems in Chimera Topologies</dc:title>
 <dc:creator>Santana, Roberto</dc:creator>
 <dc:creator>Zhu, Zheng</dc:creator>
 <dc:creator>Katzgraber, Helmut G.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  Chimera graphs define the topology of one of the first commercially available
quantum computers. A variety of optimization problems have been mapped to this
topology to evaluate the behavior of quantum enhanced optimization heuristics
in relation to other optimizers, being able to efficiently solve problems
classically to use them as benchmarks for quantum machines. In this paper we
investigate for the first time the use of Evolutionary Algorithms (EAs) on
Ising spin glass instances defined on the Chimera topology. Three genetic
algorithms (GAs) and three estimation of distribution algorithms (EDAs) are
evaluated over $1000$ hard instances of the Ising spin glass constructed from
Sidon sets. We focus on determining whether the information about the topology
of the graph can be used to improve the results of EAs and on identifying the
characteristics of the Ising instances that influence the success rate of GAs
and EDAs.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, 3 tables</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05105</dc:identifier>
 <dc:identifier>Proceedings of the Genetic and Evolutionary Computation Conference
  (GECCO-2016), ACM Press, 397-404 (2016)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05109</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Management of Naturally Regenerating Uneven-aged Forests</dc:title>
 <dc:creator>Sinha, Ankur</dc:creator>
 <dc:creator>R&#xe4;m&#xf6;, Janne</dc:creator>
 <dc:creator>Malo, Pekka</dc:creator>
 <dc:creator>Kallio, Markku</dc:creator>
 <dc:creator>Tahvonen, Olli</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  A shift from even-aged forest management to uneven-aged management practices
leads to a problem rather different from the existing straightforward practice
that follows a rotation cycle of artificial regeneration, thinning of inferior
trees and a clearcut. A lack of realistic models and methods suggesting how to
manage uneven-aged stands in a way that is economically viable and ecologically
sustainable creates difficulties in adopting this new management practice. To
tackle this problem, we make a two-fold contribution in this paper. The first
contribution is the proposal of an algorithm that is able to handle a realistic
uneven-aged stand management model that is otherwise computationally tedious
and intractable. The model considered in this paper is an empirically estimated
size-structured ecological model for uneven-aged spruce forests. The second
contribution is on the sensitivity analysis of the forest model with respect to
a number of important parameters. The analysis provides us an insight into the
behavior of the uneven-aged forest model.
</dc:description>
 <dc:description>Comment: 29 pages, 11 tables and 13 figures</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05109</dc:identifier>
 <dc:identifier>doi:10.1016/j.ejor.2016.06.071</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05117</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Investigation of Randomized Controlled Trial (RCT) Method as a
  Customer Baseline Load (CBL) Calculation for Residential Customers</dc:title>
 <dc:creator>Mohajeryami, Saeed</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  FERC Order 745 allows demand response owners to sell their load reduction in
the wholesale market. However, in order to be able to sell the load reduction,
some implementation challenges must be addressed, one of which is to establish
Customer Baseline Load (CBL) calculation methods with acceptable error
performance, which has proven to be very challenging so far. In this paper, the
error and financial performance of Randomized Controlled Trial (RCT) method,
applied to both granular and aggregated forms of the consumption load, are
investigated for a hypothetical demand response program offered to a real
dataset of residential customers .
</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05121</identifier>
 <datestamp>2016-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Performance of Cell-Free Massive MIMO with Short-Term Power
  Constraints</dc:title>
 <dc:creator>Interdonato, Giovanni</dc:creator>
 <dc:creator>Ngo, Hien Quoc</dc:creator>
 <dc:creator>Larsson, Erik G.</dc:creator>
 <dc:creator>Frenger, P&#xe5;l</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we consider a time-division duplex cell-free massive
multiple-input multiple-output (MIMO) system where many distributed access
points (APs) simultaneously serve many users. A normalized conjugate
beamforming scheme, which satisfies short-term average power constraints at the
APs, is proposed and analyzed taking into account the effect of imperfect
channel information. We derive an approximate closed-form expression for the
per-user achievable downlink rate of this scheme. We also provide, analytically
and numerically, a performance comparison between the normalized conjugate
beamforming and the conventional conjugate beamforming scheme in [1] (which
satisfies long-term average power constraints). Normalized conjugate
beamforming scheme reduces the beamforming uncertainty gain, which comes from
the users' lack of the channel state information knowledge, and hence, it
improves the achievable downlink rate compared to the conventional conjugate
beamforming scheme.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, 21st IEEE International Workshop on Computer
  Aided Modelling and Design of Communication Links and Networks (CAMAD).
  Special Session - 5Gwireless: Innovative Architectures, Wireless Technologies
  and Tools for High Capacity and Sustainable 5G Ultra-Dense Cellular Networks</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:date>2016-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05127</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bayesian Network approach to County-Level Corn Yield Prediction using
  historical data and expert knowledge</dc:title>
 <dc:creator>Chawla, Vikas</dc:creator>
 <dc:creator>Naik, Hsiang Sing</dc:creator>
 <dc:creator>Akintayo, Adedotun</dc:creator>
 <dc:creator>Hayes, Dermot</dc:creator>
 <dc:creator>Schnable, Patrick</dc:creator>
 <dc:creator>Ganapathysubramanian, Baskar</dc:creator>
 <dc:creator>Sarkar, Soumik</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Crop yield forecasting is the methodology of predicting crop yields prior to
harvest. The availability of accurate yield prediction frameworks have enormous
implications from multiple standpoints, including impact on the crop commodity
futures markets, formulation of agricultural policy, as well as crop insurance
rating. The focus of this work is to construct a corn yield predictor at the
county scale. Corn yield (forecasting) depends on a complex, interconnected set
of variables that include economic, agricultural, management and meteorological
factors. Conventional forecasting is either knowledge-based computer programs
(that simulate plant-weather-soil-management interactions) coupled with
targeted surveys or statistical model based. The former is limited by the need
for painstaking calibration, while the latter is limited to univariate analysis
or similar simplifying assumptions that fail to capture the complex
interdependencies affecting yield. In this paper, we propose a data-driven
approach that is &quot;gray box&quot; i.e. that seamlessly utilizes expert knowledge in
constructing a statistical network model for corn yield forecasting. Our
multivariate gray box model is developed on Bayesian network analysis to build
a Directed Acyclic Graph (DAG) between predictors and yield. Starting from a
complete graph connecting various carefully chosen variables and yield, expert
knowledge is used to prune or strengthen edges connecting variables.
Subsequently the structure (connectivity and edge weights) of the DAG that
maximizes the likelihood of observing the training data is identified via
optimization. We curated an extensive set of historical data (1948-2012) for
each of the 99 counties in Iowa as data to train the model.
</dc:description>
 <dc:description>Comment: 8 pages, In Proceedings of the 22nd ACM SIGKDD Workshop on Data
  Science for Food, Energy and Water , 2016 (San Francisco, CA, USA)</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05127</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05129</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SlangSD: Building and Using a Sentiment Dictionary of Slang Words for
  Short-Text Sentiment Classification</dc:title>
 <dc:creator>Wu, Liang</dc:creator>
 <dc:creator>Morstatter, Fred</dc:creator>
 <dc:creator>Liu, Huan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Sentiment in social media is increasingly considered as an important resource
for customer segmentation, market understanding, and tackling other
socio-economic issues. However, sentiment in social media is difficult to
measure since user-generated content is usually short and informal. Although
many traditional sentiment analysis methods have been proposed, identifying
slang sentiment words remains untackled. One of the reasons is that slang
sentiment words are not available in existing dictionaries or sentiment
lexicons. To this end, we propose to build the first sentiment dictionary of
slang words to aid sentiment analysis of social media content. It is laborious
and time-consuming to collect and label the sentiment polarity of a
comprehensive list of slang words. We present an approach to leverage web
resources to construct an extensive Slang Sentiment word Dictionary (SlangSD)
that is easy to maintain and extend. SlangSD is publicly available for research
purposes. We empirically show the advantages of using SlangSD, the newly-built
slang sentiment word dictionary for sentiment classification, and provide
examples demonstrating its ease of use with an existing sentiment system.
</dc:description>
 <dc:description>Comment: 15 pages, 2 figures</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05129</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05131</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Females' Enrollment and Completion in Science, Technology, Engineering,
  and Mathematics Massive Open Online Courses</dc:title>
 <dc:creator>Jiang, Suhang</dc:creator>
 <dc:creator>Schenke, Katerina</dc:creator>
 <dc:creator>Eccles, Jacquelynne Sue</dc:creator>
 <dc:creator>Xu, Di</dc:creator>
 <dc:creator>Warschauer, Mark</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Massive Open Online Courses (MOOCs) have the potential to democratize
education by providing learners with access to rich sources of information.
However, evidence supporting this democratization across countries is limited.
We explored the question of democratization by investigating whether females
from different countries were more likely to enroll in and complete STEM MOOCs
compared with males. We found that whereas females were less likely to enroll
in STEM MOOCs, they were equally likely to complete them. We found smaller
gender gaps in STEM MOOC enrollment in less economically developed countries.
Further, females were more likely than males to complete STEM MOOCs in
countries identified as having a high potential to become the largest economies
in the 21st century.
</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05135</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum routing of single optical photons with a superconducting flux
  qubit</dc:title>
 <dc:creator>Xia, Keyu</dc:creator>
 <dc:creator>Jelezko, Fedor</dc:creator>
 <dc:creator>Twamley, Jason</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Controlling and swapping quantum information in a quantum coherent way
between the microwave and optical regimes is essential for building long-range
superconducting quantum networks but extremely challenging. We propose a hybrid
quantum interface between the microwave and optical domains where the
propagation of a single-photon pulse along a nanowaveguide is controlled in a
coherent way by tuning electromagnetically induced transparency window with the
quantum state of a flux qubit. The qubit can route a single-photon pulse with a
single spin in nanodiamond into a quantum superposition of paths without the
aid of an optical cavity - simplifying the setup. By preparing the flux qubit
in a superposition state our cavity-less scheme creates a hybrid state-path
entanglement between a flying single optical photon and a static
superconducting qubit, and can conduct heralded quantum state transfer via
measurement.
</dc:description>
 <dc:description>Comment: 9 pages, 5 figures</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05135</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05137</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IM2CAD</dc:title>
 <dc:creator>Izadinia, Hamid</dc:creator>
 <dc:creator>Shan, Qi</dc:creator>
 <dc:creator>Seitz, Steven M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Given a single photo of a room and a large database of furniture CAD models,
our goal is to reconstruct a scene that is as similar as possible to the scene
depicted in the photograph, and composed of objects drawn from the database. We
present a completely automatic system to address this IM2CAD problem that
produces high quality results on challenging imagery from interior home design
and remodeling websites. Our approach iteratively optimizes the placement and
scale of objects in the room to best match scene renderings to the input photo,
using image comparison metrics trained via deep convolutional neural nets. By
operating jointly on the full scene at once, we account for inter-object
occlusions. We also show the applicability of our method in standard scene
understanding benchmarks where we obtain significant improvement.
</dc:description>
 <dc:description>Comment: To appear at CVPR 2017</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:date>2017-04-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05138</identifier>
 <datestamp>2016-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid CPU-GPU Framework for Network Motifs</dc:title>
 <dc:creator>Rossi, Ryan A.</dc:creator>
 <dc:creator>Zhou, Rong</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>G.1.0</dc:subject>
 <dc:description>  Massively parallel architectures such as the GPU are becoming increasingly
important due to the recent proliferation of data. In this paper, we propose a
key class of hybrid parallel graphlet algorithms that leverages multiple CPUs
and GPUs simultaneously for computing k-vertex induced subgraph statistics
(called graphlets). In addition to the hybrid multi-core CPU-GPU framework, we
also investigate single GPU methods (using multiple cores) and multi-GPU
methods that leverage all available GPUs simultaneously for computing induced
subgraph statistics. Both methods leverage GPU devices only, whereas the hybrid
multi-core CPU-GPU framework leverages all available multi-core CPUs and
multiple GPUs for computing graphlets in large networks. Compared to recent
approaches, our methods are orders of magnitude faster, while also more cost
effective enjoying superior performance per capita and per watt. In particular,
the methods are up to 300 times faster than the recent state-of-the-art method.
To the best of our knowledge, this is the first work to leverage multiple CPUs
and GPUs simultaneously for computing induced subgraph statistics.
</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:date>2016-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05138</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05140</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Are Today's SDN Controllers Ready for Primetime?</dc:title>
 <dc:creator>Mallon, Stephen</dc:creator>
 <dc:creator>Gramoli, Vincent</dc:creator>
 <dc:creator>Jourjon, Guillaume</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  SDN efficiency is driven by the ability of controllers to process small
packets based on a global view of the network. The goal of such controllers is
thus to treat new flows coming from hundreds of switches in a timely fashion.
In this paper, we show this ideal remains impossible through the most extensive
evaluation of SDN controllers. We evaluated five state-of-the-art SDN
controllers and discovered that the most efficient one spends a fifth of his
time in packet serialization. More dramatically, we show that this limitation
is inherent to the object oriented design principle of these controllers. They
all treat each single packet as an individual object, a limitation that induces
an unaffordable per-packet overhead. To eliminate the responsibility of the
hardware from our results, we ported these controllers on a network-efficient
architecture, Tilera, and showed even worse performance. We thus argue for an
in-depth rethinking of the design of the SDN controller into a lower level
software that leverages both operating system optimizations and modern hardware
features.
</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05140</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05143</identifier>
 <datestamp>2017-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Systematic Approach for Cross-source Point Cloud Registration by
  Preserving Macro and Micro Structures</dc:title>
 <dc:creator>Huang, Xiaoshui</dc:creator>
 <dc:creator>Zhang, Jian</dc:creator>
 <dc:creator>Fan, Lixin</dc:creator>
 <dc:creator>Wu, Qiang</dc:creator>
 <dc:creator>Yuan, Chun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a systematic approach for registering cross-source point clouds.
The compelling need for cross-source point cloud registration is motivated by
the rapid development of a variety of 3D sensing techniques, but many existing
registration methods face critical challenges as a result of the large
variations in cross-source point clouds. This paper therefore illustrates a
novel registration method which successfully aligns two cross-source point
clouds in the presence of significant missing data, large variations in point
density, scale difference and so on. The robustness of the method is attributed
to the extraction of macro and micro structures. Our work has three main
contributions: (1) a systematic pipeline to deal with cross-source point cloud
registration; (2) a graph construction method to maintain macro and micro
structures; (3) a new graph matching method is proposed which considers the
global geometric constraint to robustly register these variable graphs.
Compared to most of the related methods, the experiments show that the proposed
method successfully registers in cross-source datasets, while other methods
have difficulty achieving satisfactory results. The proposed method also shows
great ability in same-source datasets.
</dc:description>
 <dc:description>Comment: Cross-source point cloud registration</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05143</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2017.2695888</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05148</identifier>
 <datestamp>2017-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Full Resolution Image Compression with Recurrent Neural Networks</dc:title>
 <dc:creator>Toderici, George</dc:creator>
 <dc:creator>Vincent, Damien</dc:creator>
 <dc:creator>Johnston, Nick</dc:creator>
 <dc:creator>Hwang, Sung Jin</dc:creator>
 <dc:creator>Minnen, David</dc:creator>
 <dc:creator>Shor, Joel</dc:creator>
 <dc:creator>Covell, Michele</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a set of full-resolution lossy image compression methods
based on neural networks. Each of the architectures we describe can provide
variable compression rates during deployment without requiring retraining of
the network: each network need only be trained once. All of our architectures
consist of a recurrent neural network (RNN)-based encoder and decoder, a
binarizer, and a neural network for entropy coding. We compare RNN types (LSTM,
associative LSTM) and introduce a new hybrid of GRU and ResNet. We also study
&quot;one-shot&quot; versus additive reconstruction architectures and introduce a new
scaled-additive framework. We compare to previous work, showing improvements of
4.3%-8.8% AUC (area under the rate-distortion curve), depending on the
perceptual metric used. As far as we know, this is the first neural network
architecture that is able to outperform JPEG at image compression across most
bitrates on the rate-distortion curve on the Kodak dataset images, with and
without the aid of entropy coding.
</dc:description>
 <dc:description>Comment: Updated with content for CVPR and removed supplemental material to an
  external link for size limitations</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:date>2017-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05150</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Experimental demonstration of Layered/Enhanced ACO-OFDM in short haul
  optical fiber transmission link</dc:title>
 <dc:creator>Song, Binhuang</dc:creator>
 <dc:creator>Zhu, Chen</dc:creator>
 <dc:creator>Corcoran, Bill</dc:creator>
 <dc:creator>Wang, Qibing</dc:creator>
 <dc:creator>Zhuang, Leimeng</dc:creator>
 <dc:creator>Lowery, Arthur J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Asymmetrically clipped optical orthogonal frequency division multiplexing
(ACO-OFDM) is theoretically more power efficient but less spectrally efficient
than DC-bias OFDM (DCO-OFDM), with less power allocating to the informationless
bias component by only using odd index sub-carriers. Layered/Enhanced
asymmetrically clipped optical orthogonal frequency division multiplexing
(L/E-ACO-OFDM) has been proposed to increase the spectral efficiency of
ACO-OFDM. In this letter, we experimentally demonstrate a 30-km single mode
fiber transmission using L/E-ACO-OFDM at 4.375 Gbits/s. Using a Volterra filter
based equalizer, 2-dB and 1.5-dB Q-factor improvements for L/E-ACO-OFDM
comparing with DCO-OFDM can be obtained in back-to-back and 30-km fiber
transmission respectively.
</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05150</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05151</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effective Multi-step Temporal-Difference Learning for Non-Linear
  Function Approximation</dc:title>
 <dc:creator>van Seijen, Harm</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Multi-step temporal-difference (TD) learning, where the update targets
contain information from multiple time steps ahead, is one of the most popular
forms of TD learning for linear function approximation. The reason is that
multi-step methods often yield substantially better performance than their
single-step counter-parts, due to a lower bias of the update targets. For
non-linear function approximation, however, single-step methods appear to be
the norm. Part of the reason could be that on many domains the popular
multi-step methods TD($\lambda$) and Sarsa($\lambda$) do not perform well when
combined with non-linear function approximation. In particular, they are very
susceptible to divergence of value estimates. In this paper, we identify the
reason behind this. Furthermore, based on our analysis, we propose a new
multi-step TD method for non-linear function approximation that addresses this
issue. We confirm the effectiveness of our method using two benchmark tasks
with neural networks as function approximation.
</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05152</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conditional Sparse Linear Regression</dc:title>
 <dc:creator>Juba, Brendan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Machine learning and statistics typically focus on building models that
capture the vast majority of the data, possibly ignoring a small subset of data
as &quot;noise&quot; or &quot;outliers.&quot; By contrast, here we consider the problem of jointly
identifying a significant (but perhaps small) segment of a population in which
there is a highly sparse linear regression fit, together with the coefficients
for the linear fit. We contend that such tasks are of interest both because the
models themselves may be able to achieve better predictions in such special
cases, but also because they may aid our understanding of the data. We give
algorithms for such problems under the sup norm, when this unknown segment of
the population is described by a k-DNF condition and the regression fit is
s-sparse for constant k and s. For the variants of this problem when the
regression fit is not so sparse or using expected error, we also give a
preliminary algorithm and highlight the question as a challenge for future
work.
</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05159</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-stage Object Detection with Group Recursive Learning</dc:title>
 <dc:creator>Li, Jianan</dc:creator>
 <dc:creator>Liang, Xiaodan</dc:creator>
 <dc:creator>Li, Jianshu</dc:creator>
 <dc:creator>Xu, Tingfa</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:creator>Yan, Shuicheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Most of existing detection pipelines treat object proposals independently and
predict bounding box locations and classification scores over them separately.
However, the important semantic and spatial layout correlations among proposals
are often ignored, which are actually useful for more accurate object
detection. In this work, we propose a new EM-like group recursive learning
approach to iteratively refine object proposals by incorporating such context
of surrounding proposals and provide an optimal spatial configuration of object
detections. In addition, we propose to incorporate the weakly-supervised object
segmentation cues and region-based object detection into a multi-stage
architecture in order to fully exploit the learned segmentation features for
better object detection in an end-to-end way. The proposed architecture
consists of three cascaded networks which respectively learn to perform
weakly-supervised object segmentation, object proposal generation and recursive
detection refinement. Combining the group recursive learning and the
multi-stage architecture provides competitive mAPs of 78.6% and 74.9% on the
PASCAL VOC2007 and VOC2012 datasets respectively, which outperforms many
well-established baselines [10] [20] significantly.
</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05167</identifier>
 <datestamp>2017-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AID: A Benchmark Dataset for Performance Evaluation of Aerial Scene
  Classification</dc:title>
 <dc:creator>Xia, Gui-Song</dc:creator>
 <dc:creator>Hu, Jingwen</dc:creator>
 <dc:creator>Hu, Fan</dc:creator>
 <dc:creator>Shi, Baoguang</dc:creator>
 <dc:creator>Bai, Xiang</dc:creator>
 <dc:creator>Zhong, Yanfei</dc:creator>
 <dc:creator>Zhang, Liangpei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Aerial scene classification, which aims to automatically label an aerial
image with a specific semantic category, is a fundamental problem for
understanding high-resolution remote sensing imagery. In recent years, it has
become an active task in remote sensing area and numerous algorithms have been
proposed for this task, including many machine learning and data-driven
approaches. However, the existing datasets for aerial scene classification like
UC-Merced dataset and WHU-RS19 are with relatively small sizes, and the results
on them are already saturated. This largely limits the development of scene
classification algorithms. This paper describes the Aerial Image Dataset (AID):
a large-scale dataset for aerial scene classification. The goal of AID is to
advance the state-of-the-arts in scene classification of remote sensing images.
For creating AID, we collect and annotate more than ten thousands aerial scene
images. In addition, a comprehensive review of the existing aerial scene
classification techniques as well as recent widely-used deep learning methods
is given. Finally, we provide a performance analysis of typical aerial scene
classification and deep learning approaches on AID, which can be served as the
baseline results on this benchmark.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05167</dc:identifier>
 <dc:identifier>IEEE Transactions on Geoscience and Remote Sensing, Vol. 55, No.7,
  pp.3965-3981 (July 2017)</dc:identifier>
 <dc:identifier>doi:10.1109/TGRS.2017.2685945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05168</identifier>
 <datestamp>2016-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optical quorum cycles for efficient communication</dc:title>
 <dc:creator>Kleinheksel, Cory J.</dc:creator>
 <dc:creator>Somani, Arun K.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Many optical networks face heterogeneous communication requests requiring
topologies to be efficient and fault tolerant. For efficiency and distributed
control, it is common in distributed systems and algorithms to group nodes into
intersecting sets referred to as quorum sets. We show efficiency and
distributed control can also be accomplished in optical network routing by
applying the same established quorum set theory. Cycle-based optical network
routing, whether using SONET rings or p-cycles, provides the sufficient
reliability in the network. Light-trails forming a cycle allow broadcasts
within a cycle to be used for efficient multicasts. Cyclic quorum sets also
have all pairs of nodes occurring in one or more quorums, so efficient,
arbitrary unicast communication can occur between any two nodes. Efficient
broadcasts to all network nodes are possible by a node broadcasting to all
quorum cycles to which it belongs (O(sqrt(N))). In this paper, we propose
applying the distributed efficiency of the quorum sets to routing optical
cycles based on light-trails. With this new method of topology construction,
unicast and multicast communication requests do not need to be known or even
modeled a priori. Additionally, in the presence of network link faults, greater
than 99 % average coverage enables the continued operation of nearly all
arbitrary unicast and multicast requests in the network. Finally, to further
improve the fault coverage, an augmentation to the ECBRA cycle finding
algorithm is proposed.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1608.05170,
  arXiv:1608.05172</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05168</dc:identifier>
 <dc:identifier>Photon Netw Commun (2016) 31: 196</dc:identifier>
 <dc:identifier>doi:10.1007/s11107-015-0561-8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05169</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>P_3-Games</dc:title>
 <dc:creator>Hon, Wing-Kai</dc:creator>
 <dc:creator>Kloks, Ton</dc:creator>
 <dc:creator>Liu, Fu-Hong</dc:creator>
 <dc:creator>Liu, Hsiang-Hsuan</dc:creator>
 <dc:creator>Wang, Tao-Ming</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Without further ado, we present the P_3-game. The P_3-game is decidable for
elementary classes of graphs such as paths and cycles. From an algorithmic
point of view, the connected P_3-game is fascinating. We show that the
connected P_3-game is polynomially decidable for classes such as trees, chordal
graphs, ladders, cacti, outerplanar graphs and circular arc graphs.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05170</identifier>
 <datestamp>2016-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resource efficient redundancy using quorum-based cycle routing in
  optical networks</dc:title>
 <dc:creator>Kleinheksel, Cory J.</dc:creator>
 <dc:creator>Somani, Arun K.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper we propose a cycle redundancy technique that provides optical
networks almost fault-tolerant point-to-point and multipoint-to-multipoint
communications. The technique more importantly is shown to approximately halve
the necessary light-trail resources in the network while maintaining the
fault-tolerance and dependability expected from cycle-based routing. For
efficiency and distributed control, it is common in distributed systems and
algorithms to group nodes into intersecting sets referred to as quorum sets.
Optimal communication quorum sets forming optical cycles based on light-trails
have been shown to flexibly and efficiently route both point-to-point and
multipoint-to-multipoint traffic requests. Commonly cycle routing techniques
will use pairs of cycles to achieve both routing and fault-tolerance, which
uses substantial resources and creates the potential for underutilization.
Instead, we intentionally utilize redundancy within the quorum cycles for
fault-tolerance such that almost every point-to-point communication occurs in
more than one cycle. The result is a set of cycles with 96.60% - 99.37% fault
coverage, while using 42.9% - 47.18% fewer resources.
</dc:description>
 <dc:description>Comment: 17th International Conference on Transparent Optical Networks
  (ICTON), 5-9 July 2015. arXiv admin note: substantial text overlap with
  arXiv:1608.05172, arXiv:1608.05168</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05170</dc:identifier>
 <dc:identifier>2015 17th International Conference on Transparent Optical Networks
  (ICTON), Budapest, 2015, pp. 1-4</dc:identifier>
 <dc:identifier>doi:10.1109/ICTON.2015.7193340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05172</identifier>
 <datestamp>2016-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing fault tolerance capabilities in quorum-based cycle routing</dc:title>
 <dc:creator>Kleinheksel, Cory J.</dc:creator>
 <dc:creator>Somani, Arun K.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper we propose a generalized R redundancy cycle technique that
provides optical networks almost fault-tolerant communications. More
importantly, when applied using only single cycles rather than the standard
paired cycles, the generalized R redundancy technique is shown to almost halve
the necessary light-trail resources in the network while maintaining the
fault-tolerance and dependability expected from cycle-based routing. For
efficiency and distributed control, it is common in distributed systems and
algorithms to group nodes into intersecting sets referred to as quorum sets.
Optimal communication quorum sets forming optical cycles based on light-trails
have been shown to flexibly and efficiently route both point-to-point and
multipoint-to-multipoint traffic requests. Commonly cycle routing techniques
will use pairs of cycles to achieve both routing and fault-tolerance, which
uses substantial resources and creates the potential for underutilization.
Instead, we intentionally utilize R redundancy within the quorum cycles for
fault-tolerance such that every point-to-point communication pairs occur in at
least R cycles. The result is a set of R = 3 redundant cycles with 93.23-99.34%
fault coverage even with two simultaneous faults all while using 38.85-42.39%
fewer resources.
</dc:description>
 <dc:description>Comment: 7th International Workshop on Reliable Networks Design and Modeling,
  5-7 Oct. 2015. arXiv admin note: substantial text overlap with
  arXiv:1608.05170, arXiv:1608.05168</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05172</dc:identifier>
 <dc:identifier>Reliable Networks Design and Modeling (RNDM), 2015 7th
  International Workshop on, Munich, 2015, pp. 27-33</dc:identifier>
 <dc:identifier>doi:10.1109/RNDM.2015.7324305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05174</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scaling Distributed All-Pairs Algorithms: Manage Computation and Limit
  Data Replication with Quorums</dc:title>
 <dc:creator>Kleinheksel, Cory J.</dc:creator>
 <dc:creator>Somani, Arun K.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this paper we propose and prove that cyclic quorum sets can efficiently
manage all-pairs computations and data replication. The quorums are
O(N/sqrt(P)) in size, up to 50% smaller than the dual N/sqrt(P) array
implementations, and significantly smaller than solutions requiring all data.
Implementation evaluation demonstrated scalability on real datasets with a 7x
speed up on 8 nodes with 1/3rd the memory usage per process. The all-pairs
problem requires all data elements to be paired with all other data elements.
These all-pair problems occur in many science fields, which has led to their
continued interest. Additionally, as datasets grow in size, new methods like
these that can reduce memory footprints and distribute work equally across
compute nodes will be demanded.
</dc:description>
 <dc:description>Comment: Chapter Information Science and Applications (ICISA) 2016 Volume 376
  of the series Lecture Notes in Electrical Engineering pp 247-257 Date: 16
  February 2016</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05174</dc:identifier>
 <dc:identifier>Kleinheksel, Cory J., and Arun K. Somani. &quot;Scaling Distributed
  All-Pairs Algorithms.&quot; Information Science and Applications (ICISA) 2016.
  Springer Singapore, 2016. 247-257</dc:identifier>
 <dc:identifier>doi:10.1007/978-981-10-0557-2_25</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05176</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Operator Spectrum Sharing for Small Cell Networks : A Matching
  Game Perspective</dc:title>
 <dc:creator>Sanguanpuak, Tachporn</dc:creator>
 <dc:creator>Guruacharya, Sudarshan</dc:creator>
 <dc:creator>Rajatheva, Nandana</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:creator>Latva-Aho, Matti</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  One of the many problems faced by current cellular network technology is the
under utilization of the dedicated, licensed spectrum of network operators. An
emerging paradigm to solve this issue is to allow multiple operators to share
some parts of each others' spectrum. Previous works on spectrum sharing have
failed to integrate the theoretical insights provided by recent developments in
stochastic geometrical approaches to cellular network analysis with the
objectives of network resource allocation problems. In this paper, we study the
non-orthogonal spectrum assignment with the goal of maximizing the social
welfare of the network, defined as the expected weighted sum rate of the
operators. We adopt the many-to-one stable matching game framework to tackle
this problem. Moreover, using the stochastic geometrical approach, we show that
its solution can be both stable as well as socially optimal. This allows for
computation of the game theoretical solution using generic Markov Chain Monte
Carlo method. We also investigate the role of power allocation schemes using
Q-learning, and we numerically show that the effect of resource allocation
scheme is much more significant than the effect of power allocation for the
social welfare of the system.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05177</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deeply-Supervised Recurrent Convolutional Neural Network for Saliency
  Detection</dc:title>
 <dc:creator>Tang, Youbao</dc:creator>
 <dc:creator>Wu, Xiangqian</dc:creator>
 <dc:creator>Bu, Wei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a novel saliency detection method by developing a
deeply-supervised recurrent convolutional neural network (DSRCNN), which
performs a full image-to-image saliency prediction. For saliency detection, the
local, global, and contextual information of salient objects is important to
obtain a high quality salient map. To achieve this goal, the DSRCNN is designed
based on VGGNet-16. Firstly, the recurrent connections are incorporated into
each convolutional layer, which can make the model more powerful for learning
the contextual information. Secondly, side-output layers are added to conduct
the deeply-supervised operation, which can make the model learn more
discriminative and robust features by effecting the intermediate layers.
Finally, all of the side-outputs are fused to integrate the local and global
information to get the final saliency detection results. Therefore, the DSRCNN
combines the advantages of recurrent convolutional neural networks and
deeply-supervised nets. The DSRCNN model is tested on five benchmark datasets,
and experimental results demonstrate that the proposed method significantly
outperforms the state-of-the-art saliency detection approaches on all test
datasets.
</dc:description>
 <dc:description>Comment: 5 pages, 5 figures, accepted by ACMMM 2016</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05177</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05179</identifier>
 <datestamp>2017-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving the Efficiency of DAMAS for Sound Source Localization via
  Wavelet Compression Computational Grid</dc:title>
 <dc:creator>Ma, Wei</dc:creator>
 <dc:creator>Liu, Xun</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Phased microphone arrays are used widely in the applications for acoustic
source localization. Deconvolution approaches such as DAMAS successfully
overcome the spatial resolution limit of the conventional delay-and-sum (DAS)
beamforming method. However deconvolution approaches require high computational
effort compared to conventional DAS beamforming method. This paper presents a
novel method that serves to improve the efficiency of DAMAS via wavelet
compression computational grid rather than via optimizing DAMAS algorithm. In
this method, the efficiency of DAMAS increases with compression ratio. This
method can thus save lots of run time in industrial applications for sound
source localization, particularly when sound sources are just located in a
small extent compared with scanning plane and a band of angular frequency needs
to be calculated. In addition, this method largely retains the spatial
resolution of DAMAS on original computational grid, although with a minor
deficiency that the occurrence probability of aliasing increasing slightly for
complicated sound source.
</dc:description>
 <dc:description>Comment: 15 pages, 6 figures, 2 tables, 23 conferences</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05179</dc:identifier>
 <dc:identifier>doi:10.1016/j.jsv.2017.02.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05180</identifier>
 <datestamp>2016-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Holistic Approach for Data-Driven Object Cutout</dc:title>
 <dc:creator>Xu, Huayong</dc:creator>
 <dc:creator>Li, Yangyan</dc:creator>
 <dc:creator>Chen, Wenzheng</dc:creator>
 <dc:creator>Lischinski, Dani</dc:creator>
 <dc:creator>Cohen-Or, Daniel</dc:creator>
 <dc:creator>Chen, Baoquan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Object cutout is a fundamental operation for image editing and manipulation,
yet it is extremely challenging to automate it in real-world images, which
typically contain considerable background clutter. In contrast to existing
cutout methods, which are based mainly on low-level image analysis, we propose
a more holistic approach, which considers the entire shape of the object of
interest by leveraging higher-level image analysis and learnt global shape
priors. Specifically, we leverage a deep neural network (DNN) trained for
objects of a particular class (chairs) for realizing this mechanism. Given a
rectangular image region, the DNN outputs a probability map (P-map) that
indicates for each pixel inside the rectangle how likely it is to be contained
inside an object from the class of interest. We show that the resulting P-maps
may be used to evaluate how likely a rectangle proposal is to contain an
instance of the class, and further process good proposals to produce an
accurate object cutout mask. This amounts to an automatic end-to-end pipeline
for catergory-specific object cutout. We evaluate our approach on segmentation
benchmark datasets, and show that it significantly outperforms the
state-of-the-art on them.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2016-09-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05180</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05182</identifier>
 <datestamp>2016-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bayesian Nonparametric Approach for Estimating Individualized
  Treatment-Response Curves</dc:title>
 <dc:creator>Xu, Yanbo</dc:creator>
 <dc:creator>Xu, Yanxun</dc:creator>
 <dc:creator>Saria, Suchi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the problem of estimating the continuous response over time to
interventions using observational time series---a retrospective dataset where
the policy by which the data are generated is unknown to the learner. We are
motivated by applications where response varies by individuals and therefore,
estimating responses at the individual-level is valuable for personalizing
decision-making. We refer to this as the problem of estimating individualized
treatment response (ITR) curves. In statistics, G-computation formula (Robins,
1986) has been commonly used for estimating treatment responses from
observational data containing sequential treatment assignments. However, past
studies have focused predominantly on obtaining point-in-time estimates at the
population level. We leverage the G-computation formula and develop a novel
Bayesian nonparametric (BNP) method that can flexibly model functional data and
provide posterior inference over the treatment response curves at both the
individual and population level. On a challenging dataset containing time
series from patients admitted to a hospital, we estimate responses to
treatments used in managing kidney function and show that the resulting fits
are more accurate than alternative approaches. Accurate methods for obtaining
ITRs from observational data can dramatically accelerate the pace at which
personalized treatment plans become possible.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2016-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05182</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05186</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Saliency Detection via Combining Region-Level and Pixel-Level
  Predictions with CNNs</dc:title>
 <dc:creator>Tang, Youbao</dc:creator>
 <dc:creator>Wu, Xiangqian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a novel saliency detection method by combining
region-level saliency estimation and pixel-level saliency prediction with CNNs
(denoted as CRPSD). For pixel-level saliency prediction, a fully convolutional
neural network (called pixel-level CNN) is constructed by modifying the VGGNet
architecture to perform multi-scale feature learning, based on which an
image-to-image prediction is conducted to accomplish the pixel-level saliency
detection. For region-level saliency estimation, an adaptive superpixel based
region generation technique is first designed to partition an image into
regions, based on which the region-level saliency is estimated by using a CNN
model (called region-level CNN). The pixel-level and region-level saliencies
are fused to form the final salient map by using another CNN (called fusion
CNN). And the pixel-level CNN and fusion CNN are jointly learned. Extensive
quantitative and qualitative experiments on four public benchmark datasets
demonstrate that the proposed method greatly outperforms the state-of-the-art
saliency detection approaches.
</dc:description>
 <dc:description>Comment: 18 pages, 9 figures, accepted by ECCV 2016</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05187</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blockchain in internet of things: Challenges and Solutions</dc:title>
 <dc:creator>Dorri, Ali</dc:creator>
 <dc:creator>Kanhere, Salil S.</dc:creator>
 <dc:creator>Jurdak, Raja</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The Internet of Things IoT is experiencing exponential growth in research and
industry, but it still suffers from privacy and security vulnerabilities.
Conventional security and privacy approaches tend to be inapplicable for IoT,
mainly due to its decentralized topology and the resource-constraints of the
majority of its devices. BlockChain BC that underpin the crypto-currency
Bitcoin have been recently used to provide security and privacy in peer-to-peer
networks with similar topologies to IoT. However, BCs are computationally
expensive and involve high bandwidth overhead and delays, which are not
suitable for IoT devices. This position paper proposes a new secure, private,
and lightweight architecture for IoT, based on BC technology that eliminates
the overhead of BC while maintaining most of its security and privacy benefits.
The described method is investigated on a smart home application as a
representative case study for broader IoT applications. The proposed
architecture is hierarchical, and consists of smart homes, an overlay network
and cloud storages coordinating data transactions with BC to provide privacy
and security. Our design uses different types of BCs depending on where in the
network hierarchy a transaction occurs, and uses distributed trust methods to
ensure a decentralized topology. Qualitative evaluation of the architecture
under common threat models highlights its effectiveness in providing security
and privacy for IoT applications.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05187</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05188</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Entanglement Distribution in Next-Generation Wireless
  Communication Systems</dc:title>
 <dc:creator>Hosseinidehaj, Nedasadat</dc:creator>
 <dc:creator>Malaney, Robert</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work we analyze the distribution of quantum entanglement over
communication channels in the millimeter-wave regime. The motivation for such a
study is the possibility for next-generation wireless networks (beyond 5G) to
accommodate such a distribution directly - without the need to integrate
additional optical communication hardware into the transceivers. Future
wireless communication systems are bound to require some level of quantum
communications capability. We find that direct quantum-entanglement
distribution in the millimeter-wave regime is indeed possible, but that its
implementation will be very demanding from both a system-design perspective and
a channel-requirement perspective.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05188</dc:identifier>
 <dc:identifier>doi:10.1109/VTCSpring.2017.8108494</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05203</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Seeing with Humans: Gaze-Assisted Neural Image Captioning</dc:title>
 <dc:creator>Sugano, Yusuke</dc:creator>
 <dc:creator>Bulling, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Gaze reflects how humans process visual scenes and is therefore increasingly
used in computer vision systems. Previous works demonstrated the potential of
gaze for object-centric tasks, such as object localization and recognition, but
it remains unclear if gaze can also be beneficial for scene-centric tasks, such
as image captioning. We present a new perspective on gaze-assisted image
captioning by studying the interplay between human gaze and the attention
mechanism of deep neural networks. Using a public large-scale gaze dataset, we
first assess the relationship between state-of-the-art object and scene
recognition models, bottom-up visual saliency, and human gaze. We then propose
a novel split attention model for image captioning. Our model integrates human
gaze information into an attention-based long short-term memory architecture,
and allows the algorithm to allocate attention selectively to both fixated and
non-fixated image regions. Through evaluation on the COCO/SALICON datasets we
show that our method improves image captioning performance and that gaze can
complement machine attention for semantic scene understanding tasks.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05204</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Refining Geometry from Depth Sensors using IR Shading Images</dc:title>
 <dc:creator>Choe, Gyeongmin</dc:creator>
 <dc:creator>Park, Jaesik</dc:creator>
 <dc:creator>Tai, Yu-Wing</dc:creator>
 <dc:creator>Kweon, In So</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a method to refine geometry of 3D meshes from a consumer level
depth camera, e.g. Kinect, by exploiting shading cues captured from an infrared
(IR) camera. A major benefit to using an IR camera instead of an RGB camera is
that the IR images captured are narrow band images that filter out most
undesired ambient light, which makes our system robust against natural indoor
illumination. Moreover, for many natural objects with colorful textures in the
visible spectrum, the subjects appear to have a uniform albedo in the IR
spectrum. Based on our analyses on the IR projector light of the Kinect, we
define a near light source IR shading model that describes the captured
intensity as a function of surface normals, albedo, lighting direction, and
distance between light source and surface points. To resolve the ambiguity in
our model between the normals and distances, we utilize an initial 3D mesh from
the Kinect fusion and multi-view information to reliably estimate surface
details that were not captured and reconstructed by the Kinect fusion. Our
approach directly operates on the mesh model for geometry refinement. We ran
experiments on our algorithm for geometries captured by both the Kinect I and
Kinect II, as the depth acquisition in Kinect I is based on a structured-light
technique and that of the Kinect II is based on a time-of-flight (ToF)
technology. The effectiveness of our approach is demonstrated through several
challenging real-world examples. We have also performed a user study to
evaluate the quality of the mesh models before and after our refinements.
</dc:description>
 <dc:description>Comment: Accepted to the International Journal of Computer Vision (IJCV)</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05205</identifier>
 <datestamp>2017-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tree-decomposable and Underconstrained Geometric Constraint Problems</dc:title>
 <dc:creator>Fudos, Ioannis</dc:creator>
 <dc:creator>Hoffmann, Christoph M.</dc:creator>
 <dc:creator>Joan-Arinyo, Robert</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we are concerned with geometric constraint solvers, i.e., with
programs that find one or more solutions of a geometric constraint problem. If
no solution exists, the solver is expected to announce that no solution has
been found. Owing to the complexity, type or difficulty of a constraint
problem, it is possible that the solver does not find a solution even though
one may exist. Thus, there may be false negatives, but there should never be
false positives. Intuitively, the ability to find solutions can be considered a
measure of solver's competence. We consider static constraint problems and
their solvers. We do not consider dynamic constraint solvers, also known as
dynamic geometry programs, in which specific geometric elements are moved,
interactively or along prescribed trajectories, while continually maintaining
all stipulated constraints. However, if we have a solver for static constraint
problems that is sufficiently fast and competent, we can build a dynamic
geometry program from it by solving the static problem for a sufficiently dense
sampling of the trajectory of the moving element(s). The work we survey has its
roots in applications, especially in mechanical computer-aided design (MCAD).
The constraint solvers used in MCAD took a quantum leap in the 1990s. These
approaches solve a geometric constraint problem by an initial, graph-based
structural analysis that extracts generic subproblems and determines how they
would combine to form a complete solution. These subproblems are then handed to
an algebraic solver that solves the specific instances of the generic
subproblems and combines them.
</dc:description>
 <dc:description>Comment: This work was accepted to appear as a chapter, pending minor
  revision, to the &quot;Handbook of Geometric Constraints Principles&quot;, edited by
  Meera Sitharam, Audrey St.John and Jessica Sidman, Mathematics series, CRC
  press (Taylor and Francis group). To appear in 2017. Universitat Politecnica
  de Catalunya, Research Report: http://hdl.handle.net/2117/91041</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2017-01-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05209</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Multi-Frequency Phase Unwrapping using Kernel Density
  Estimation</dc:title>
 <dc:creator>Lawin, Felix J&#xe4;remo</dc:creator>
 <dc:creator>Forss&#xe9;n, Per-Erik</dc:creator>
 <dc:creator>Ovr&#xe9;n, Hannes</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we introduce an efficient method to unwrap multi-frequency
phase estimates for time-of-flight ranging. The algorithm generates multiple
depth hypotheses and uses a spatial kernel density estimate (KDE) to rank them.
The confidence produced by the KDE is also an effective means to detect
outliers. We also introduce a new closed-form expression for phase noise
prediction, that better fits real data. The method is applied to depth decoding
for the Kinect v2 sensor, and compared to the Microsoft Kinect SDK and to the
open source driver libfreenect2. The intended Kinect v2 use case is scenes with
less than 8m range, and for such cases we observe consistent improvements,
while maintaining real-time performance. When extending the depth range to the
maximal value of 8.75m, we get about 52% more valid measurements than
libfreenect2. The effect is that the sensor can now be used in large depth
scenes, where it was previously not a good choice. Code and supplementary
material are available at
http://www.cvl.isy.liu.se/research/datasets/kinect2-dataset.
</dc:description>
 <dc:description>Comment: Accepted at ECCV 2016</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05209</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05211</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of Artificial Noise on Cellular Networks: A Stochastic Geometry
  Approach</dc:title>
 <dc:creator>Wang, Hui-Ming</dc:creator>
 <dc:creator>Wang, Chao</dc:creator>
 <dc:creator>Zheng, Tong-Xing</dc:creator>
 <dc:creator>Quek, Tony Q. S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies the impact of artificial noise (AN) on the secrecy
performance of a target cell in multi-cell cellular networks. Although AN turns
out to be an efficient approach for securing a pointto-point/single cell
confidential transmission, it would increase the inter-cell interference in a
multi-cell cellular network, which may degrade the network reliability and
secrecy performance. For analyzing the average secrecy performance of the
target cell which is of significant interest, we employ a hybrid cellular
deployment model, where the target cell is a circle of fixed size and the base
stations (BSs) outside the target cell are modeled as a homogeneous Poisson
point process (PPP). We investigate the impact of AN on the reliability and
security of users in the target cell in the presence of pilot contamination
using a stochastic geometry approach. The analytical results of the average
connection outage and the secrecy outage of its cellular user (CU) in the
target cell are given, which facilitates the evaluation of the average secrecy
throughput of a randomly chosen CU in the target cell. It shows that with an
optimized power allocation between the desired signals and AN, the AN scheme is
an efficient solution for securing the communications in a multi-cell cellular
network.
</dc:description>
 <dc:description>Comment: journal paper, single column, 30 pages, 10 figures, accepted to
  appear on IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05211</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2016.2601903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05221</identifier>
 <datestamp>2016-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application of Volterra Equations to Solve Unit Commitment Problem of
  Optimised Energy Storage and Generation</dc:title>
 <dc:creator>Muftahov, Ildar</dc:creator>
 <dc:creator>Sidorov, Denis</dc:creator>
 <dc:creator>Zhukov, Aleksei</dc:creator>
 <dc:creator>Panasetsky, Daniil</dc:creator>
 <dc:creator>Foley, Aoife</dc:creator>
 <dc:creator>Li, Yong</dc:creator>
 <dc:creator>Tynda, Aleksandr</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65R32, 45D05, 65R20</dc:subject>
 <dc:description>  Development of reliable methods for optimised energy storage and generation
is one of the most imminent challenges in moder power systems. In this paper an
adaptive approach to load leveling problem using novel dynamic models based on
the Volterra integral equations of the first kind with piecewise continuous
kernels. These integral equations efficiently solve such inverse problem taking
into account both the time dependent efficiencies and the availability of
generation/storage of each energy storage technology. In this analysis a direct
numerical method is employed to find the least-cost dispatch of available
storages. The proposed collocation type numerical method has second order
accuracy and enjoys self-regularization properties, which is associated with
confidence levels of system demand. This adaptive approach is suitable for
energy storage optimisation in real time. The efficiency of the proposed
methodology is demonstrated on the Single Electricity Market of Republic of
Ireland and Sakhalin island in the Russian Far East.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1507.06484</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2016-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05221</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05225</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Learning for Approximation of Expensive Functions with Normal
  Distributed Output Uncertainty</dc:title>
 <dc:creator>van der Herten, Joachim</dc:creator>
 <dc:creator>Couckuyt, Ivo</dc:creator>
 <dc:creator>Deschrijver, Dirk</dc:creator>
 <dc:creator>Dhaene, Tom</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  When approximating a black-box function, sampling with active learning
focussing on regions with non-linear responses tends to improve accuracy. We
present the FLOLA-Voronoi method introduced previously for deterministic
responses, and theoretically derive the impact of output uncertainty. The
algorithm automatically puts more emphasis on exploration to provide more
information to the models.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05231</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Implementation of a Procedural Content Generation Web
  Application for Vertex Shaders</dc:title>
 <dc:creator>Quiroz, Juan C.</dc:creator>
 <dc:creator>Dascalu, Sergiu M.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We present a web application for the procedural generation of transformations
of 3D models. We generate the transformations by algorithmically generating the
vertex shaders of the 3D models. The vertex shaders are created with an
interactive genetic algorithm, which displays to the user the visual effect
caused by each vertex shader, allows the user to select the visual effect the
user likes best, and produces a new generation of vertex shaders using the user
feedback as the fitness measure of the genetic algorithm. We use genetic
programming to represent each vertex shader as a computer program. This paper
presents details of requirements specification, software architecture, high and
low-level design, and prototype user interface. We discuss the project's
current status and development challenges.
</dc:description>
 <dc:description>Comment: 25th International Conference on Software Engineering and Data
  Engineering (SEDE 2016), September 26-28, Denver, CO</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05233</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coinductive Soundness of Corecursive Type Class Resolution</dc:title>
 <dc:creator>Farka, Franti&#x161;ek</dc:creator>
 <dc:creator>Komendantskaya, Ekaterina</dc:creator>
 <dc:creator>Hammond, Kevin</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Horn clauses and first-order resolution are commonly used to implement type
classes in Haskell. Several corecursive extensions to type class resolution
have recently been proposed, with the goal of allowing (co)recursive dictionary
construction where resolution does not termi- nate. This paper shows, for the
first time, that corecursive type class resolution and its extensions are
coinductively sound with respect to the greatest Herbrand models of logic
programs and that they are induc- tively unsound with respect to the least
Herbrand models. We establish incompleteness results for various fragments of
the proof system.
</dc:description>
 <dc:description>Comment: Pre-proceedings paper presented at the 26th International Symposium
  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,
  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05235</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Irregularity of Some Molecular Structures</dc:title>
 <dc:creator>Abdo, Hosam</dc:creator>
 <dc:creator>Dimitrov, Darko</dc:creator>
 <dc:creator>Gao, Wei</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Measures of the irregularity of chemical graphs could be helpful for
QSAR/QSPR studies and for the descriptive purposes of biological and chemical
properties, such as melting and boiling points, toxicity and resistance. Here
we consider the following four established irregularity measures: the
irregularity index by Albertson, the total irregularity, the variance of vertex
degrees and the Collatz-Sinogowitz index.
  Through the means of graph structural analysis and derivation, we study the
above-mentioned irregularity measures of several chemical molecular graphs
which frequently appear in chemical, medical and material engineering, as well
as the nanotubes: $TUC_4 C_8(S)$, $TUC_4 C_8(R)$, Zig-Zag $TUHC_{6}$, $TUC_4$,
Armchair $TUVC_{6}$, then dendrimers $T_{k,d}$ and the circumcoronene series of
benzenoid $H_k$. In addition, the irregularities of Mycielski's constructions
of cycle and path graphs are analyzed.
</dc:description>
 <dc:description>Comment: 23 pages, 15 figures</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05243</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilingual Modal Sense Classification using a Convolutional Neural
  Network</dc:title>
 <dc:creator>Marasovi&#x107;, Ana</dc:creator>
 <dc:creator>Frank, Anette</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Modal sense classification (MSC) is a special WSD task that depends on the
meaning of the proposition in the modal's scope. We explore a CNN architecture
for classifying modal sense in English and German. We show that CNNs are
superior to manually designed feature-based classifiers and a standard NN
classifier. We analyze the feature maps learned by the CNN and identify known
and previously unattested linguistic features. We benchmark the CNN on a
standard WSD task, where it compares favorably to models using
sense-disambiguated target vectors.
</dc:description>
 <dc:description>Comment: Final version, accepted at the 1st Workshop on Representation
  Learning for NLP, held in conjunction with ACL 2016</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05246</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Image Degradations Affect Deep CNN-based Face Recognition?</dc:title>
 <dc:creator>Karahan, Samil</dc:creator>
 <dc:creator>Yildirim, Merve Kilinc</dc:creator>
 <dc:creator>Kirtac, Kadir</dc:creator>
 <dc:creator>Rende, Ferhat Sukru</dc:creator>
 <dc:creator>Butun, Gultekin</dc:creator>
 <dc:creator>Ekenel, Hazim Kemal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Face recognition approaches that are based on deep convolutional neural
networks (CNN) have been dominating the field. The performance improvements
they have provided in the so called in-the-wild datasets are significant,
however, their performance under image quality degradations have not been
assessed, yet. This is particularly important, since in real-world face
recognition applications, images may contain various kinds of degradations due
to motion blur, noise, compression artifacts, color distortions, and occlusion.
In this work, we have addressed this problem and analyzed the influence of
these image degradations on the performance of deep CNN-based face recognition
approaches using the standard LFW closed-set identification protocol. We have
evaluated three popular deep CNN models, namely, the AlexNet, VGG-Face, and
GoogLeNet. Results have indicated that blur, noise, and occlusion cause a
significant decrease in performance, while deep CNN models are found to be
robust to distortions, such as color distortions and change in color balance.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05246</dc:identifier>
 <dc:identifier>doi:10.1109/BIOSIG.2016.7736924</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05248</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Source-level Energy Optimization Framework for Mobile Applications</dc:title>
 <dc:creator>Li, Xueliang</dc:creator>
 <dc:creator>Gallagher, John P.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Energy efficiency can have a significant influence on user experience of
mobile devices such as smartphones and tablets. Although energy is consumed by
hardware, software optimization plays an important role in saving energy, and
thus software developers have to participate in the optimization process. The
source code is the interface between the developer and hardware resources. In
this paper, we propose an energy-optimization framework guided by a source code
energy model that allows developers to be aware of energy usage induced by the
code and to apply very targeted source-level refactoring strategies. The
framework also lays a foundation for the code optimization by automatic tools.
To the best of our knowledge, our work is the first that achieves this for a
high-level language such as Java. In a case study, the experimental evaluation
shows that our approach is able to save from 6.4% to 50.2% of the CPU energy
consumption in various application scenarios.
</dc:description>
 <dc:description>Comment: 10 pages. arXiv admin note: substantial text overlap with
  arXiv:1605.05234</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05252</identifier>
 <datestamp>2017-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Slicing Concurrent Constraint Programs</dc:title>
 <dc:creator>Falaschi, Moreno</dc:creator>
 <dc:creator>Gabbrielli, Maurizio</dc:creator>
 <dc:creator>Olarte, Carlos</dc:creator>
 <dc:creator>Palamidessi, Catuscia</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Concurrent Constraint Programming (CCP) is a declarative model for
concurrency where agents interact by telling and asking constraints (pieces of
information) in a shared store. Some previous works have developed
(approximated) declarative debuggers for CCP languages. However, the task of
debugging concurrent programs remains difficult. In this paper we define a
dynamic slicer for CCP and we show it to be a useful companion tool for the
existing debugging techniques. Our technique starts by considering a partial
computation (a trace) that shows the presence of bugs. Often, the quantity of
information in such a trace is overwhelming, and the user gets easily lost,
since she cannot focus on the sources of the bugs. Our slicer allows for
marking part of the state of the computation and assists the user to eliminate
most of the redundant information in order to highlight the errors. We show
that this technique can be tailored to timed variants of CCP. We also develop a
prototypical implementation freely available for making experiments.
</dc:description>
 <dc:description>Comment: Pre-proceedings paper presented at the 26th International Symposium
  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,
  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2017-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05258</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parameter Learning for Log-supermodular Distributions</dc:title>
 <dc:creator>Shpakova, Tatiana</dc:creator>
 <dc:creator>Bach, Francis</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider log-supermodular models on binary variables, which are
probabilistic models with negative log-densities which are submodular. These
models provide probabilistic interpretations of common combinatorial
optimization tasks such as image segmentation. In this paper, we focus
primarily on parameter estimation in the models from known upper-bounds on the
intractable log-partition function. We show that the bound based on separable
optimization on the base polytope of the submodular function is always inferior
to a bound based on &quot;perturb-and-MAP&quot; ideas. Then, to learn parameters, given
that our approximation of the log-partition function is an expectation (over
our own randomization), we use a stochastic subgradient technique to maximize a
lower-bound on the log-likelihood. This can also be extended to conditional
maximum likelihood. We illustrate our new results in a set of experiments in
binary image denoising, where we highlight the flexibility of a probabilistic
model to learn with missing data.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05263</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Implementation of Probabilistic Programming Language Anglican</dc:title>
 <dc:creator>Tolpin, David</dc:creator>
 <dc:creator>van de Meent, Jan Willem</dc:creator>
 <dc:creator>Yang, Hongseok</dc:creator>
 <dc:creator>Wood, Frank</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Anglican is a probabilistic programming system designed to interoperate with
Clojure and other JVM languages. We introduce the programming language
Anglican, outline our design choices, and discuss in depth the implementation
of the Anglican language and runtime, including macro-based compilation,
extended CPS-based evaluation model, and functional representations for
probabilistic paradigms, such as a distribution, a random process, and an
inference algorithm.
  We show that a probabilistic functional language can be implemented
efficiently and integrated tightly with a conventional functional language with
only moderate computational overhead. We also demonstrate how advanced
probabilistic modeling concepts are mapped naturally to the functional
foundation.
</dc:description>
 <dc:description>Comment: IFL 2016 submission, 12 pages, 2 figures</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05265</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generation of the Single Precision BLAS library for the Parallella
  platform, with Epiphany co-processor acceleration, using the BLIS framework</dc:title>
 <dc:creator>Tasende, Miguel</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The Parallella is a hybrid computing platform that came into existence as the
result of a Kickstarter project by Adapteva. It is composed of the high
performance, energy-efficient, manycore architecture, Epiphany chip (used as
co-processor) and one Zynq-7000 series chip, which normally runs a regular
Linux OS version, serves as the main processor, and implements &quot;glue logic&quot; in
its internal FPGA to communicate with the many interfaces in the Parallella. In
this paper an Epiphany-accelerated BLAS library for the Parallella platform was
created (which could be suitable, also, for similar hybrid platforms that
include the Epiphany chip as a coprocessor). For the actual instantiation of
the BLAS, the BLIS framework was used. There have been previous implementations
of Matrix-Matrix multiplication, on this platform, that achieved very good
performances inside the Epiphany chip (up to 85% of peak), but not so good ones
for the complete Parallella platform (due to inter-chip data transfer bandwidth
limitations). The main purpose of this work was to get closer to practical
Linear Algebra aplications for the entire Parallella platform, with scientific
computing in view.
</dc:description>
 <dc:description>Comment: 8 pages, 9 figures, conference manuscript for IEEE DataCom 2016
  (Auckland, New Zealand)</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05265</dc:identifier>
 <dc:identifier>doi:10.1109/DASC-PICom-DataCom-CyberSciTec.2016.154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05267</identifier>
 <datestamp>2017-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Structural Context Models and Ranking Score Fusion for Human
  Interaction Prediction</dc:title>
 <dc:creator>Ke, Qiuhong</dc:creator>
 <dc:creator>Bennamoun, Mohammed</dc:creator>
 <dc:creator>An, Senjian</dc:creator>
 <dc:creator>Bossaid, Farid</dc:creator>
 <dc:creator>Sohel, Ferdous</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Predicting an interaction before it is fully executed is very important in
applications such as human-robot interaction and video surveillance. In a
two-human interaction scenario, there often contextual dependency structure
between the global interaction context of the two humans and the local context
of the different body parts of each human. In this paper, we propose to learn
the structure of the interaction contexts, and combine it with the spatial and
temporal information of a video sequence for a better prediction of the
interaction class. The structural models, including the spatial and the
temporal models, are learned with Long Short Term Memory (LSTM) networks to
capture the dependency of the global and local contexts of each RGB frame and
each optical flow image, respectively. LSTM networks are also capable of
detecting the key information from the global and local interaction contexts.
Moreover, to effectively combine the structural models with the spatial and
temporal models for interaction prediction, a ranking score fusion method is
also introduced to automatically compute the optimal weight of each model for
score fusion. Experimental results on the BIT Interaction and the
UT-Interaction datasets clearly demonstrate the benefits of the proposed
method.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2017-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05269</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-Timescale Stochastic Dispatch of Smart Distribution Grids</dc:title>
 <dc:creator>Lopez-Ramos, Luis M.</dc:creator>
 <dc:creator>Kekatos, Vassilis</dc:creator>
 <dc:creator>Marques, Antonio G.</dc:creator>
 <dc:creator>Giannakis, Georgios B.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Smart distribution grids should efficiently integrate stochastic renewable
resources while effecting voltage regulation. The design of energy management
schemes is challenging, one of the reasons being that energy management is a
multistage problem where decisions are not all made at the same timescale and
must account for the variability during real-time operation. The joint dispatch
of slow- and fast-timescale controls in a smart distribution grid is considered
here. The substation voltage, the energy exchanged with a main grid, and the
generation schedules for small diesel generators have to be decided on a slow
timescale; whereas optimal photovoltaic inverter setpoints are found on a more
frequent basis. While inverter and looser voltage regulation limits are imposed
at all times, tighter bus voltage constraints are enforced on the average or in
probability, thus enabling more efficient renewable integration. Upon
reformulating the two-stage grid dispatch as a stochastic convex-concave
problem, two distribution-free schemes are put forth. An average dispatch
algorithm converges provably to the optimal two-stage decisions via a sequence
of convex quadratic programs. Its non-convex probabilistic alternative entails
solving two slightly different convex problems and is numerically shown to
converge. Numerical tests on a real-world distribution feeder verify that both
novel data-driven schemes yield lower costs over competing alternatives.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, submitted to IEEE Transactions on Smart Grid</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05269</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05272</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Acceptable Strategy Profiles in Stochastic Games</dc:title>
 <dc:creator>Solan, Eilon</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>91A15, 91A50</dc:subject>
 <dc:description>  This paper presents a new solution concept for multiplayer stochastic games,
namely, acceptable strategy profiles. For each player $i$ and state $s$ in a
stochastic game, let $w_i(s)$ be a real number. A strategy profile is
\emph{$w$-acceptable}, where $w=(w_i(s))$, if the discounted payoff to each
player $i$ at every initial state $s$ is at least $w_i(s)$, provided the
discount factor of the players is sufficiently close to 1. Our goal is to
provide simple strategy profiles that are $w$-acceptable for payoff vectors $w$
in which all coordinates are high.
</dc:description>
 <dc:date>2016-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05272</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05273</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Period Do-Not-Exceed Limit for Variable Renewable Generation
  Dispatch Considering Discrete Recourse Controls</dc:title>
 <dc:creator>Li, Zhigang</dc:creator>
 <dc:creator>Qiu, Feng</dc:creator>
 <dc:creator>Wang, Jianhui</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The do-not-exceed (DNE) limit method was proposed to accommodate more
variable renewable generation (VRG) securely. However, the lack of involving
discrete recourse control precludes this method from gaining more flexibility
for better VRG integration. This letter formulates a multi-period DNE limit
model considering continuous and discrete recourse controls. This model belongs
to two-stage robust optimization with mixed integer recourse. A nested
column-and-constraint generation approach is employed to solve this model. Case
studies show the effectiveness of the proposed method.
</dc:description>
 <dc:description>Comment: Under review</dc:description>
 <dc:date>2016-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05275</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tight Convex Upper Bound on the Likelihood of a Finite Mixture</dc:title>
 <dc:creator>Mezuman, Elad</dc:creator>
 <dc:creator>Weiss, Yair</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The likelihood function of a finite mixture model is a non-convex function
with multiple local maxima and commonly used iterative algorithms such as EM
will converge to different solutions depending on initial conditions. In this
paper we ask: is it possible to assess how far we are from the global maximum
of the likelihood? Since the likelihood of a finite mixture model can grow
unboundedly by centering a Gaussian on a single datapoint and shrinking the
covariance, we constrain the problem by assuming that the parameters of the
individual models are members of a large discrete set (e.g. estimating a
mixture of two Gaussians where the means and variances of both Gaussians are
members of a set of a million possible means and variances). For this setting
we show that a simple upper bound on the likelihood can be computed using
convex optimization and we analyze conditions under which the bound is
guaranteed to be tight. This bound can then be used to assess the quality of
solutions found by EM (where the final result is projected on the discrete set)
or any other mixture estimation algorithm. For any dataset our method allows us
to find a finite mixture model together with a dataset-specific bound on how
far the likelihood of this mixture is from the global optimum of the likelihood
</dc:description>
 <dc:description>Comment: icpr 2016</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05277</identifier>
 <datestamp>2017-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Caveats on Bayesian and hidden-Markov models (v2.8)</dc:title>
 <dc:creator>Schomaker, Lambert</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  This paper describes a number of fundamental and practical problems in the
application of hidden-Markov models and Bayes when applied to cursive-script
recognition. Several problems, however, will have an effect in other
application areas. The most fundamental problem is the propagation of error in
the product of probabilities. This is a common and pervasive problem which
deserves more attention. On the basis of Monte Carlo modeling, tables for the
expected relative error are given. It seems that it is distributed according to
a continuous Poisson distribution over log probabilities. A second essential
problem is related to the appropriateness of the Markov assumption. Basic tests
will reveal whether a problem requires modeling of the stochastics of
seriality, at all. Examples are given of lexical encodings which cover 95-99%
classification accuracy of a lexicon, with removed sequence information, for
several European languages. Finally, a summary of results on a non- Bayes,
non-Markov method in handwriting recognition are presented, with very
acceptable results and minimal modeling or training requirements using
nearest-mean classification.
</dc:description>
 <dc:description>Comment: Difference of v2.8 with v2.7: a) Final empirical (simulation) table
  for word-trie experiment with epsilon-in-the-probabilities; b) Some small
  text changes; c) used ispell</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2017-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05277</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05288</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerating Exact and Approximate Inference for (Distributed) Discrete
  Optimization with GPUs</dc:title>
 <dc:creator>Fioretto, Ferdinando</dc:creator>
 <dc:creator>Pontelli, Enrico</dc:creator>
 <dc:creator>Yeoh, William</dc:creator>
 <dc:creator>Dechter, Rina</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Discrete optimization is a central problem in artificial intelligence. The
optimization of the aggregated cost of a network of cost functions arises in a
variety of problems including (W)CSP, DCOP, as well as optimization in
stochastic variants such as the tasks of finding the most probable explanation
(MPE) in belief networks. Inference-based algorithms are powerful techniques
for solving discrete optimization problems, which can be used independently or
in combination with other techniques. However, their applicability is often
limited by their compute intensive nature and their space requirements. This
paper proposes the design and implementation of a novel inference-based
technique, which exploits modern massively parallel architectures, such as
those found in Graphical Processing Units (GPUs), to speed up the resolution of
exact and approximated inference-based algorithms for discrete optimization.
The paper studies the proposed algorithm in both centralized and distributed
optimization contexts. The paper demonstrates that the use of GPUs provides
significant advantages in terms of runtime and scalability, achieving up to two
orders of magnitude in speedups and showing a considerable reduction in
execution time (up to 345 times faster) with respect to a sequential version.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2017-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05288</dc:identifier>
 <dc:identifier>Constraints (2018) 23: 1</dc:identifier>
 <dc:identifier>doi:10.1007/s10601-017-9274-1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05295</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sensitivity and Reliability in Incomplete Networks: Centrality Metrics
  to Community Scoring Functions</dc:title>
 <dc:creator>Sarkar, Soumya</dc:creator>
 <dc:creator>Bhowmick, Sanjukta</dc:creator>
 <dc:creator>Kumar, Suhansanu</dc:creator>
 <dc:creator>Mukherjee, Animesh</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Network analysis is an important tool in understanding the behavior of
complex systems of interacting entities. However, due to the limitations of
data gathering technologies, some interactions might be missing from the
network model. This is a ubiquitous problem in all domains that use network
analysis, from social networks to hyper-linked web networks to biological
networks. Consequently, an important question in analyzing networks is to
understand how increasing the noise level (i.e. percentage of missing edges)
affects different network parameters.
  In this paper we evaluate the effect of noise on community scoring and
centrality-based parameters with respect to two different aspects of network
analysis: (i) sensitivity, that is how the parameter value changes as edges are
removed and (ii) reliability in the context of message spreading, that is how
the time taken to broadcast a message changes as edges are removed.
  Our experiments on synthetic and real-world networks and three different
noise models demonstrate that for both the aspects over all networks and all
noise models, permanence qualifies as the most effective metric. For the
sensitivity experiments closeness centrality is a close second. For the message
spreading experiments, closeness and betweenness centrality based initiator
selection closely competes with permanence. This is because permanence has a
dual characteristic where the cumulative permanence over all vertices is
sensitive to noise but the ids of the top-rank vertices, which are used to find
seeds during message spreading remain relatively stable under noise.
</dc:description>
 <dc:description>Comment: Accepted in proceedings of ASONAM 2016</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05295</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05308</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distributed Satisfactory Content Delivery Scheme for QoS Provisioning
  in Delay Tolerant Networks</dc:title>
 <dc:creator>Ezzahidi, Sidi Ahmed</dc:creator>
 <dc:creator>Sabir, Essaid</dc:creator>
 <dc:creator>Ghogho, Mounir</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We deal in this paper with the content forwarding problem in Delay Tolerant
Networks (DTNs). We first formulate the content delivery interaction as a
non-cooperative satisfaction game. On one hand, the source node seeks to ensure
a delivery probability above some given threshold. On the other hand, the relay
nodes seek to maximize their own payoffs. The source node offers a reward
(virtual coins) to the relay which caches and forwards the file to the final
destination. Each relay faces the dilemma of accepting/rejecting to cache the
source's file. Cooperation incurs energy cost due to caching, carrying and
forwarding the source's file. Yet, when a relay accepts to cooperate, it may
receive some reward if it succeeds to be the first relay to forward the content
to the destination. Otherwise, the relay may receive some penalty in the form
of a constant regret; the latter parameter is introduced to make incentive for
cooperation. Next, we introduce the concept of Satisfaction Equilibrium (SE) as
a solution concept to the induced game. Now, the source node is solely
interested in reaching a file delivery probability greater than some given
threshold, while the relays behave rationally to maximize their respective
payoffs. Full characterizations of the SEs for both pure and mixed strategies
are derived. Furthermore, we propose two learning algorithms allowing the
players (source/relays) to reach the SE strategies. Finally, extensive
numerical investigations and some learning simulations are carried out to
illustrate the behaviour of the interacting nodes.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05315</identifier>
 <datestamp>2016-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multi-Dimensional Fairness Combinatorial Double-Sided Auction Model in
  Cloud Environment</dc:title>
 <dc:creator>Hassanzadeh, Reihaneh</dc:creator>
 <dc:creator>Movaghar, Ali</dc:creator>
 <dc:creator>Hassanzadeh, Hamid Reza</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In cloud investment markets, consumers are looking for the lowest cost and a
desirable fairness while providers are looking for strategies to achieve the
highest possible profit and return. Most existing models for auction-based
resource allocation in cloud environments only consider the overall profit
increase and ignore the profit of each participant individually or the
difference between the rich and the poor participants. This paper proposes a
multi-dimensional fairness combinatorial double auction (MDFCDA) model which
strikes a balance between the revenue and the fairness among participants. We
solve a winner determination problem (WDP) through integer programming which
incorporates the fairness attribute based on the history of participants which
is stored in a repository. Our evaluation results show that the proposed model
increases the willingness of participants to take part in the next auction
rounds. Moreover, the average percentage of resource utilization is increased.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2016-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05317</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>R\'enyi divergences as weighted non-commutative vector valued
  $L_p$-spaces</dc:title>
 <dc:creator>Berta, Mario</dc:creator>
 <dc:creator>Scholz, Volkher B.</dc:creator>
 <dc:creator>Tomamichel, Marco</dc:creator>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Operator Algebras</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  We show that Araki and Masuda's weighted non-commutative vector valued
$L_p$-spaces [Araki &amp; Masuda, Publ. Res. Inst. Math. Sci., 18:339 (1982)]
correspond to an algebraic generalization of the sandwiched R\'enyi divergences
with parameter $\alpha = \frac{p}{2}$. Using complex interpolation theory, we
prove various fundamental properties of these divergences in the setup of von
Neumann algebras, including a data processing inequality and monotonicity in
$\alpha$. We thereby also give new proofs for the corresponding
finite-dimensional properties. We discuss the limiting cases $\alpha\to
\{\frac{1}{2},1,\infty\}$ leading to minus the logarithm of Uhlmann's fidelity,
Umegaki's relative entropy, and the max-relative entropy, respectively. As a
contribution that might be of independent interest, we derive a Riesz-Thorin
theorem for Araki-Masuda $L_p$-spaces and an Araki-Lieb-Thirring inequality for
states on von Neumann algebras.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05327</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Short Counterexample Property for Safety and Liveness Verification of
  Fault-tolerant Distributed Algorithms</dc:title>
 <dc:creator>Konnov, Igor</dc:creator>
 <dc:creator>Lazic, Marijana</dc:creator>
 <dc:creator>Veith, Helmut</dc:creator>
 <dc:creator>Widder, Josef</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>D.4.5</dc:subject>
 <dc:description>  Distributed algorithms have many mission-critical applications ranging from
embedded systems and replicated databases to cloud computing. Due to
asynchronous communication, process faults, or network failures, these
algorithms are difficult to design and verify. Many algorithms achieve fault
tolerance by using threshold guards that, for instance, ensure that a process
waits until it has received an acknowledgment from a majority of its peers.
Consequently, domain-specific languages for fault-tolerant distributed systems
offer language support for threshold guards.
  We introduce an automated method for model checking of safety and liveness of
threshold-guarded distributed algorithms in systems where the number of
processes and the fraction of faulty processes are parameters. Our method is
based on a short counterexample property: if a distributed algorithm violates a
temporal specification (in a fragment of LTL), then there is a counterexample
whose length is bounded and independent of the parameters. We prove this
property by (i) characterizing executions depending on the structure of the
temporal formula, and (ii) using commutativity of transitions to accelerate and
shorten executions. We extended the ByMC toolset (Byzantine Model Checker) with
our technique, and verified liveness and safety of 10 prominent fault-tolerant
distributed algorithms, most of which were out of reach for existing
techniques.
</dc:description>
 <dc:description>Comment: 16 pages, 11 pages appendix</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05327</dc:identifier>
 <dc:identifier>doi:10.1145/3009837.3009860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05338</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The multi-level Monte Carlo method for simulations of turbulent flows</dc:title>
 <dc:creator>Chen, Qingsha</dc:creator>
 <dc:creator>Ming, Ju</dc:creator>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  In this paper the application of the multi-level Monte Carlo (MLMC) method on
numerical simulations of turbulent flows with uncertain parameters is
investigated. Several strategies for setting up the MLMC method are presented,
and the advantages and disadvantages of each strategy are also discussed. A
numerical experiment is carried out using the Antarctic Circumpolar Current
(ACC) with uncertain, small-scale bottom topographic features. It is
demonstrated that, unlike the pointwise solutions, the averaged volume
transports are correlated across grid resolutions, and the MLMC method could
increase simulation efficiency without losing accuracy in uncertainty
assessment.
</dc:description>
 <dc:description>Comment: 4 figures</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05339</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Photo Filter Recommendation by Category-Aware Aesthetic Learning</dc:title>
 <dc:creator>Sun, Wei-Tse</dc:creator>
 <dc:creator>Chao, Ting-Hsuan</dc:creator>
 <dc:creator>Kuo, Yin-Hsi</dc:creator>
 <dc:creator>Hsu, Winston H.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Nowadays, social media has become a popular platform for the public to share
photos. To make photos more visually appealing, users usually apply filters on
their photos without domain knowledge. However, due to the growing number of
filter types, it becomes a major issue for users to choose the best filter
type. For this purpose, filter recommendation for photo aesthetics takes an
important role in image quality ranking problems. In these years, several works
have declared that Convolutional Neural Networks (CNNs) outperform traditional
methods in image aesthetic categorization, which classifies images into high or
low quality. Most of them do not consider the effect on filtered images; hence,
we propose a novel image aesthetic learning for filter recommendation. Instead
of binarizing image quality, we adjust the state-of-the-art CNN architectures
and design a pairwise loss function to learn the embedded aesthetic responses
in hidden layers for filtered images. Based on our pilot study, we observe
image categories (e.g., portrait, landscape, food) will affect user preference
on filter selection. We further integrate category classification into our
proposed aesthetic-oriented models. To the best of our knowledge, there is no
public dataset for aesthetic judgment with filtered images. We create a new
dataset called Filter Aesthetic Comparison Dataset (FACD). It contains 28,160
filtered images based on the AVA dataset and 42,240 reliable image pairs with
aesthetic annotations using Amazon Mechanical Turk. It is the first dataset
containing filtered images and user preference labels. We conduct experiments
on the collected FACD for filter recommendation, and the results show that our
proposed category-aware aesthetic learning outperforms aesthetic classification
methods (e.g., 12% relative improvement).
</dc:description>
 <dc:description>Comment: 11 pages, 7 figures</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2017-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05343</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decoupled Neural Interfaces using Synthetic Gradients</dc:title>
 <dc:creator>Jaderberg, Max</dc:creator>
 <dc:creator>Czarnecki, Wojciech Marian</dc:creator>
 <dc:creator>Osindero, Simon</dc:creator>
 <dc:creator>Vinyals, Oriol</dc:creator>
 <dc:creator>Graves, Alex</dc:creator>
 <dc:creator>Silver, David</dc:creator>
 <dc:creator>Kavukcuoglu, Koray</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Training directed neural networks typically requires forward-propagating data
through a computation graph, followed by backpropagating error signal, to
produce weight updates. All layers, or more generally, modules, of the network
are therefore locked, in the sense that they must wait for the remainder of the
network to execute forwards and propagate error backwards before they can be
updated. In this work we break this constraint by decoupling modules by
introducing a model of the future computation of the network graph. These
models predict what the result of the modelled subgraph will produce using only
local information. In particular we focus on modelling error gradients: by
using the modelled synthetic gradient in place of true backpropagated error
gradients we decouple subgraphs, and can update them independently and
asynchronously i.e. we realise decoupled neural interfaces. We show results for
feed-forward models, where every layer is trained asynchronously, recurrent
neural networks (RNNs) where predicting one's future gradient extends the time
over which the RNN can effectively model, and also a hierarchical RNN system
with ticking at different timescales. Finally, we demonstrate that in addition
to predicting gradients, the same framework can be used to predict inputs,
resulting in models which are decoupled in both the forward and backwards pass
-- amounting to independent networks which co-learn such that they can be
composed into a single functioning corporation.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2017-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05346</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diversified Top-k Similarity Search in Large Attributed Networks</dc:title>
 <dc:creator>Meng, Zaiqiao</dc:creator>
 <dc:creator>Shen, Hong</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Given a large network and a query node, finding its top-k similar nodes is a
primitive operation in many graph-based applications. Recently enhancing search
results with diversification have received much attention. In this paper, we
explore an novel problem of searching for top-k diversified similar nodes in
attributed networks, with the motivation that modeling diversification in an
attributed network should consider both the emergence of network links and the
attribute features of nodes such as user profile information. We formulate this
practical problem as two optimization problems: the Attributed Coverage
Diversification (ACD) problem and the r-Dissimilar Attributed Coverage
Diversification (r-DACD) problem. Based on the submodularity and the
monotonicity of ACD, we propose an efficient greedy algorithm achieving a tight
approximation guarantee of 1-1/e. Unlike the expension based methods only
considering nodes' neighborhood, ACD generalize the definition of
diversification to nodes' own features. To capture diversification in
topological structure of networks, the r-DACD problem introduce a dissimilarity
constraint. We refer to this problem as the Dissimilarity Constrained
Non-monotone Submodular Maximization (DCNSM) problem. We prove that there is no
constant-factor approximation for DCNSM, and also present an efficient greedy
algorithms achieving $1/\rho$ approximation, where $\rho\le\Delta$, $\Delta$ is
the maximum degree of its dissimilarity based graph. To the best of our
knowledge, it is the first approximation algorithm for the Submodular
Maximization problem with a distance constraint. The experimental results on
real-world attributed network datasets demonstrate the effectiveness of our
methods, and confirm that adding dissimilarity constraint can significantly
enhance the performance of diversification.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures, conference</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05347</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Data Analysis with Probabilistic Programming</dc:title>
 <dc:creator>Saad, Feras</dc:creator>
 <dc:creator>Mansinghka, Vikash</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Probabilistic techniques are central to data analysis, but different
approaches can be difficult to apply, combine, and compare. This paper
introduces composable generative population models (CGPMs), a computational
abstraction that extends directed graphical models and can be used to describe
and compose a broad class of probabilistic data analysis techniques. Examples
include hierarchical Bayesian models, multivariate kernel methods,
discriminative machine learning, clustering algorithms, dimensionality
reduction, and arbitrary probabilistic programs. We also demonstrate the
integration of CGPMs into BayesDB, a probabilistic programming platform that
can express data analysis tasks using a modeling language and a structured
query language. The practical value is illustrated in two ways. First, CGPMs
are used in an analysis that identifies satellite data records which probably
violate Kepler's Third Law, by composing causal probabilistic programs with
non-parametric Bayes in under 50 lines of probabilistic code. Second, for
several representative data analysis tasks, we report on lines of code and
accuracy measurements of various CGPMs, plus comparisons with standard baseline
solutions from Python and MATLAB libraries.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05358</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary Constraint Satisfaction Problems Defined by Excluded Topological
  Minors</dc:title>
 <dc:creator>Cohen, David A.</dc:creator>
 <dc:creator>Cooper, Martin C.</dc:creator>
 <dc:creator>Jeavons, Peter G.</dc:creator>
 <dc:creator>Zivny, Stanislav</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The binary Constraint Satisfaction Problem (CSP) is to decide whether there
exists an assignment to a set of variables which satisfies specified
constraints between pairs of variables. A binary CSP instance can be presented
as a labelled graph encoding both the forms of the constraints and where they
are imposed. We consider subproblems defined by restricting the allowed form of
this graph. One type of restriction that has previously been considered is to
forbid certain specified substructures (patterns). This captures some tractable
classes of the CSP, but does not capture classes defined by language
restrictions, or the well-known structural property of acyclicity.
  In this paper we extend the notion of pattern and introduce the notion of a
topological minor of a binary CSP instance. By forbidding a finite set of
patterns from occurring as topological minors we obtain a compact mechanism for
expressing novel tractable subproblems of the binary CSP, including new
generalisations of the class of acyclic instances. Forbidding a finite set of
patterns as topological minors also captures all other tractable structural
restrictions of the binary CSP. Moreover, we show that several patterns give
rise to tractable subproblems if forbidden as topological minors but not if
forbidden as sub-patterns. Finally, we introduce the idea of augmented patterns
that allows for the identification of more tractable classes, including all
language restrictions of the binary CSP.
</dc:description>
 <dc:description>Comment: Full version of an IJCAI'15 paper</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05368</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scaling Bounded Model Checking By Transforming Programs With Arrays</dc:title>
 <dc:creator>Jana, Anushri</dc:creator>
 <dc:creator>Khedker, Uday P.</dc:creator>
 <dc:creator>Datar, Advaita</dc:creator>
 <dc:creator>Venkatesh, R</dc:creator>
 <dc:creator>Niyas, C</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Bounded Model Checking is one the most successful techniques for finding bugs
in program. However, for programs with loops iterating over large-sized arrays,
bounded model checkers often exceed the limit of resources available to them.
We present a transformation that enables bounded model checkers to verify a
certain class of array properties. Our technique transforms an
array-manipulating program in ANSI-C to an array-free and loop-free program.
The transformed program can efficiently be verified by an off-the-shelf bounded
model checker. Though the transformed program is, in general, an abstraction of
the original program, we formally characterize the properties for which the
transformation is precise. We demonstrate the applicability and usefulness of
our technique on both industry code as well as academic benchmarks.
</dc:description>
 <dc:description>Comment: Pre-proceedings paper presented at the 26th International Symposium
  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,
  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05374</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DNN-based Speech Synthesis for Indian Languages from ASCII text</dc:title>
 <dc:creator>Ronanki, Srikanth</dc:creator>
 <dc:creator>Reddy, Siva</dc:creator>
 <dc:creator>Bollepalli, Bajibabu</dc:creator>
 <dc:creator>King, Simon</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Text-to-Speech synthesis in Indian languages has a seen lot of progress over
the decade partly due to the annual Blizzard challenges. These systems assume
the text to be written in Devanagari or Dravidian scripts which are nearly
phonemic orthography scripts. However, the most common form of computer
interaction among Indians is ASCII written transliterated text. Such text is
generally noisy with many variations in spelling for the same word. In this
paper we evaluate three approaches to synthesize speech from such noisy ASCII
text: a naive Uni-Grapheme approach, a Multi-Grapheme approach, and a
supervised Grapheme-to-Phoneme (G2P) approach. These methods first convert the
ASCII text to a phonetic script, and then learn a Deep Neural Network to
synthesize speech from that. We train and test our models on Blizzard Challenge
datasets that were transliterated to ASCII using crowdsourcing. Our experiments
on Hindi, Tamil and Telugu demonstrate that our models generate speech of
competetive quality from ASCII text compared to the speech synthesized from the
native scripts. All the accompanying transliterated datasets are released for
public access.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures -- Accepted in 9th ISCA Speech Synthesis Workshop</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05376</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms to solve coupled systems of differential equations in terms
  of power series</dc:title>
 <dc:creator>Ablinger, Jakob</dc:creator>
 <dc:creator>Behring, Arnd</dc:creator>
 <dc:creator>Bluemlein, Johannes</dc:creator>
 <dc:creator>de Freitas, Abilio</dc:creator>
 <dc:creator>Schneider, Carsten</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>High Energy Physics - Phenomenology</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:description>  Using integration by parts relations, Feynman integrals can be represented in
terms of coupled systems of differential equations. In the following we suppose
that the unknown Feynman integrals can be given in power series
representations, and that sufficiently many initial values of the integrals are
given. Then there exist algorithms that decide constructively if the
coefficients of their power series representations can be given within the
class of nested sums over hypergeometric products. In this article we will work
out the calculation steps that solve this problem. First, we will present a
successful tactic that has been applied recently to challenging problems coming
from massive 3-loop Feynman integrals. Here our main tool is to solve scalar
linear recurrences within the class of nested sums over hypergeometric
products. Second, we will present a new variation of this tactic which relies
on more involved summation technologies but succeeds in reducing the problem to
solve scalar recurrences with lower recurrence orders. The article will work
out the different challenges of this new tactic and demonstrates how they can
be treated efficiently with our existing summation technologies.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05380</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Trust-Aware Neighbourhood in Trust-based Recommendation</dc:title>
 <dc:creator>Ghenai, Amira</dc:creator>
 <dc:creator>Ghanem, Moustafa M.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  Traditional Recommender Systems (RS) do not consider any personal user
information beyond rating history. Such information, on the other hand, is
widely available on social networking sites (Facebook, Twitter). As a result,
social networks have recently been used in recommendation systems. In this
paper, we propose an efficient method for incorporating social signals into the
recommendation process by building a trust network which supplements the users'
rating profiles. We first show the effect of different cold-start users types
on the Collaborative Filtering (CF) technique in several real-world datasets.
Later, we propose a &quot;Trust-Aware Neighbourhood&quot; algorithm which addresses a
performance issue of the former by limiting the trusted neighbourhood. We show
the doubling of the rating coverage compared to the traditional CF technique,
and a significant improvement in the accuracy for some datasets. Focusing
specifically on cold-start users, we propose a &quot;Hybrid Trust-Aware
Neighbourhood&quot; algorithm which expands the neighbourhood by considering both
trust and rating history of the users. We show a near complete coverage with a
rich trust network dataset-- Flixster. We conclude by discussing the potential
implementation of this algorithm in a budget-constrained cloud environment.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05380</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05384</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Millimeter Wave Wireless Communications: New Results for Rural
  Connectivity</dc:title>
 <dc:creator>MacCartney Jr., George R.</dc:creator>
 <dc:creator>Sun, Shu</dc:creator>
 <dc:creator>Rappaport, Theodore S.</dc:creator>
 <dc:creator>Xing, Yunchou</dc:creator>
 <dc:creator>Yan, Hangsong</dc:creator>
 <dc:creator>Koka, Jeton</dc:creator>
 <dc:creator>Wang, Ruichen</dc:creator>
 <dc:creator>Yu, Dian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper shows the remarkable distances that can be achieved using
millimeter wave communications, and presents a new rural macrocell (RMa) path
loss model for millimeter wave frequencies, based on measurements at 73 GHz in
rural Virginia. Path loss models are needed to estimate signal coverage and
interference for wireless network design, yet little is known about rural
propagation at millimeter waves. This work identifies problems with the RMa
model used by the 3rd Generation Partnership Project (3GPP) TR 38.900 Release
14, and offers a close-in (CI) reference distance model that has improved
accuracy, fewer parameters, and better stability as compared with the existing
3GPP RMa path loss model. The measurements and models presented here are the
first to validate rural millimeter wave path loss models.
</dc:description>
 <dc:description>Comment: to appear in All Things Cellular'16, in conjunction with ACM MobiCom,
  Oct. 7, 2016</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05384</dc:identifier>
 <dc:identifier>doi:10.1145/2980055.2987353</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05390</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constant Factor Approximate Solutions for Expanding Search on General
  Networks</dc:title>
 <dc:creator>Alpern, Steve</dc:creator>
 <dc:creator>Lidbetter, Thomas</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the classical problem introduced by R. Isaacs and S. Gal of
minimizing the time to find a hidden point $H$ on a network $Q$ moving from a
known starting point. Rather than adopting the traditional continuous unit
speed path paradigm, we use the ``expanding search'' paradigm recently
introduced by the authors. Here the regions $S\left( t\right) $ that have been
searched by time $t$ are increasing from the starting point and have total
length $t$. Roughly speaking the search follows a sequence of arcs $a_{i}$ such
that each one starts at some point of an earlier one. This type of search is
often carried out by real life search teams in the hunt for missing persons,
escaped convicts, terrorists or lost airplanes. The paper which introduced this
type of search solved the adversarial problem (where $H$ is hidden to take a
long time to find) for the cases where $Q$ is a tree or is 2-arc-connected.
This paper solves the game on some additional families of networks. However the
main contribution is to give strategy classes which can be used on any network
and have expected search times which are within a factor close to 1 of the
value of the game (minimax search time). We identify cases where our strategies
are in fact optimal.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05390</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05401</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Optimization of Convex Sum of Non-Convex Functions</dc:title>
 <dc:creator>Gade, Shripad</dc:creator>
 <dc:creator>Vaidya, Nitin H.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We present a distributed solution to optimizing a convex function composed of
several non-convex functions. Each non-convex function is privately stored with
an agent while the agents communicate with neighbors to form a network. We show
that coupled consensus and projected gradient descent algorithm proposed in [1]
can optimize convex sum of non-convex functions under an additional assumption
on gradient Lipschitzness. We further discuss the applications of this analysis
in improving privacy in distributed optimization.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05404</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Person Tracking by Multicut and Deep Matching</dc:title>
 <dc:creator>Tang, Siyu</dc:creator>
 <dc:creator>Andres, Bjoern</dc:creator>
 <dc:creator>Andriluka, Mykhaylo</dc:creator>
 <dc:creator>Schiele, Bernt</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In [1], we proposed a graph-based formulation that links and clusters person
hypotheses over time by solving a minimum cost subgraph multicut problem. In
this paper, we modify and extend [1] in three ways: 1) We introduce a novel
local pairwise feature based on local appearance matching that is robust to
partial occlusion and camera motion. 2) We perform extensive experiments to
compare different pairwise potentials and to analyze the robustness of the
tracking formulation. 3) We consider a plain multicut problem and remove
outlying clusters from its solution. This allows us to employ an efficient
primal feasible optimization algorithm that is not applicable to the subgraph
multicut problem of [1]. Unlike the branch-and-cut algorithm used there, this
efficient algorithm used here is applicable to long videos and many detections.
Together with the novel feature, it eliminates the need for the intermediate
tracklet representation of [1]. We demonstrate the effectiveness of our overall
approach on the MOT16 benchmark [2], achieving state-of-art performance.
</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05426</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Strong Baseline for Learning Cross-Lingual Word Embeddings from
  Sentence Alignments</dc:title>
 <dc:creator>Levy, Omer</dc:creator>
 <dc:creator>S&#xf8;gaard, Anders</dc:creator>
 <dc:creator>Goldberg, Yoav</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  While cross-lingual word embeddings have been studied extensively in recent
years, the qualitative differences between the different algorithms remain
vague. We observe that whether or not an algorithm uses a particular feature
set (sentence IDs) accounts for a significant performance gap among these
algorithms. This feature set is also used by traditional alignment algorithms,
such as IBM Model-1, which demonstrate similar performance to state-of-the-art
embedding algorithms on a variety of benchmarks. Overall, we observe that
different algorithmic approaches for utilizing the sentence ID feature space
result in similar performance. This paper draws both empirical and theoretical
parallels between the embedding and alignment literature, and suggests that
adding additional sources of information, which go beyond the traditional
signal of bilingual sentence-aligned corpora, may substantially improve
cross-lingual word embeddings, and that future baselines should at least take
such features into account.
</dc:description>
 <dc:description>Comment: EACL 2017</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2017-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05426</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05430</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entropy Jumps for Radially Symmetric Random Vectors</dc:title>
 <dc:creator>Courtade, Thomas A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We establish a quantitative bound on the entropy jump associated to the sum
of independent, identically distributed (IID) radially symmetric random vectors
having dimension greater than one. Following the usual approach, we first
consider the analogous problem of Fisher information dissipation, and then
integrate along the Ornstein-Uhlenbeck semigroup to obtain an entropic
inequality. In a departure from previous work, we appeal to a result by
Desvillettes and Villani on entropy production associated to the Landau
equation. This obviates strong regularity assumptions, such as presence of a
spectral gap and log-concavity of densities, but comes at the expense of radial
symmetry. As an application, we give a quantitative estimate of the deficit in
the Gaussian logarithmic Sobolev inequality for radially symmetric functions.
</dc:description>
 <dc:description>Comment: 19 pages. Updates relative to v1: Fixed a reference and added another</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05430</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05431</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Links between the Logarithmic Sobolev Inequality and the convolution
  inequalities for Entropy and Fisher Information</dc:title>
 <dc:creator>Courtade, Thomas A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Relative to the Gaussian measure on $\mathbb{R}^d$, entropy and Fisher
information are famously related via Gross' logarithmic Sobolev inequality
(LSI). These same functionals also separately satisfy convolution inequalities,
as proved by Stam. We establish a dimension-free inequality that interpolates
among these relations. Several interesting corollaries follow: (i) the deficit
in the LSI satisfies a convolution inequality itself; (ii) the deficit in the
LSI controls convergence in the entropic and Fisher information central limit
theorems; and (iii) the LSI is stable with respect to HWI jumps (i.e., a jump
in any of the convolution inequalities associated to the HWI functionals).
  Another consequence is that the convolution inequalities for Fisher
information and entropy powers are reversible in general, up to a factor
depending on the Stam defect. An improved form of Nelson's hypercontractivity
estimate also follows. Finally, we speculate on the possibility of an analogous
reverse Brunn-Minkowski inequality and a related upper bound on surface area
associated to Minkowski sums.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05440</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Papers presented at the 32nd International Conference on Logic
  Programming (ICLP 2016)</dc:title>
 <dc:creator>Carro, Manuel</dc:creator>
 <dc:creator>King, Andy</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  This is the list of the full papers accepted for presentation at the 32nd
International Conference on Logic Programming, New York City, USA, October
18-21, 2016.
  In addition to the main conference itself, ICLP hosted four pre-conference
workshops, the Autumn School on Logic Programing, and a Doctoral Consortium.
  The final versions of the full papers will be published in a special issue of
the journal Theory and Practice of Logic Programming (TPLP). We received eighty
eight abstract submissions, of which twenty seven papers were accepted for
publication as TPLP rapid communications.
  Papers deemed of sufficiently high quality to be presented as the conference,
but not enough to be appear in TPLP, will be published as Technical
Communications in the OASIcs series. Fifteen papers fell into this category.
</dc:description>
 <dc:description>Comment: To be published at Theory and Practive of Logic Programming</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05440</dc:identifier>
 <dc:identifier>Theory and Practice of Logic Programming, Vol. 16, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05442</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Understanding of Scenes through the ADE20K Dataset</dc:title>
 <dc:creator>Zhou, Bolei</dc:creator>
 <dc:creator>Zhao, Hang</dc:creator>
 <dc:creator>Puig, Xavier</dc:creator>
 <dc:creator>Fidler, Sanja</dc:creator>
 <dc:creator>Barriuso, Adela</dc:creator>
 <dc:creator>Torralba, Antonio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Scene parsing, or recognizing and segmenting objects and stuff in an image,
is one of the key problems in computer vision. Despite the community's efforts
in data collection, there are still few image datasets covering a wide range of
scenes and object categories with dense and detailed annotations for scene
parsing. In this paper, we introduce and analyze the ADE20K dataset, spanning
diverse annotations of scenes, objects, parts of objects, and in some cases
even parts of parts. A generic network design called Cascade Segmentation
Module is then proposed to enable the segmentation networks to parse a scene
into stuff, objects, and object parts in a cascade. We evaluate the proposed
module integrated within two existing semantic segmentation networks, yielding
significant improvements for scene parsing. We further show that the scene
parsing networks trained on ADE20K can be applied to a wide variety of scenes
and objects.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05442</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05444</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Model of Navigation History</dc:title>
 <dc:creator>Brewster, Connor G.</dc:creator>
 <dc:creator>Jeffrey, Alan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.1</dc:subject>
 <dc:description>  Navigation has been a core component of the web since its inception: users
and scripts can follow hyperlinks, and can go back or forwards through the
navigation history. In this paper, we present a formal model aligned with the
WHATWG specification of navigation history, and investigate its properties. The
fundamental property of navigation history is that traversing the history by
delta then by delta' should be the same as traversing by delta+delta'. In
particular, traversing by +1 (forward) then by -1 (back) is the same as
traversing by 0 (doing nothing). We show that the specification-aligned model
does not satisfy this property, by exhibiting a series of counter-examples,
which motivate four patches to the model. We present a series of experiments,
showing that browsers are inconsistent in their implementation of navigation
history, but that their behaviour is closer to the patched model than to the
specification-aligned model. We propose patches to the specification to align
it with the patched model.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05445</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Reconfigurable FIR Filter with Memristor-Based Weights</dc:title>
 <dc:creator>Bayat, F. Merrikh</dc:creator>
 <dc:creator>Alibart, F.</dc:creator>
 <dc:creator>Gao, L.</dc:creator>
 <dc:creator>Strukov, D. B.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  We report on experimental demonstration of a mixed-signal 6-tap
finite-impulse response (FIR) filter in which weights are implemented with
titanium dioxide memristive devices. In the proposed design weight of a tap is
stored with a relatively high precision in a memristive device that can be
configured in field. Such approach enables efficient implementation of the most
critical operation of an FIR filter, i.e. multiplication of the input signal
with the tap weights and summation of the products from taps, in analog domain.
As a result, the proposed design, when implemented with fully integrated hybrid
CMOS/memristor circuit, is expected to be much more compact and energy
efficient as compared to the state-of-the-art approaches.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05445</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05457</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Who did What: A Large-Scale Person-Centered Cloze Dataset</dc:title>
 <dc:creator>Onishi, Takeshi</dc:creator>
 <dc:creator>Wang, Hai</dc:creator>
 <dc:creator>Bansal, Mohit</dc:creator>
 <dc:creator>Gimpel, Kevin</dc:creator>
 <dc:creator>McAllester, David</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We have constructed a new &quot;Who-did-What&quot; dataset of over 200,000
fill-in-the-gap (cloze) multiple choice reading comprehension problems
constructed from the LDC English Gigaword newswire corpus. The WDW dataset has
a variety of novel features. First, in contrast with the CNN and Daily Mail
datasets (Hermann et al., 2015) we avoid using article summaries for question
formation. Instead, each problem is formed from two independent articles --- an
article given as the passage to be read and a separate article on the same
events used to form the question. Second, we avoid anonymization --- each
choice is a person named entity. Third, the problems have been filtered to
remove a fraction that are easily solved by simple baselines, while remaining
84% solvable by humans. We report performance benchmarks of standard systems
and propose the WDW dataset as a challenge task for the community.
</dc:description>
 <dc:description>Comment: To appear at EMNLP 2016. Our dataset is available at
  tticnlp.github.io/who_did_what</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05457</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05461</identifier>
 <datestamp>2017-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>We Can &quot;See&quot; You via Wi-Fi - WiFi Action Recognition via Vision-based
  Methods</dc:title>
 <dc:creator>Chang, Jen-Yin</dc:creator>
 <dc:creator>Lee, Kuan-Ying</dc:creator>
 <dc:creator>Wei, Yu-Lin</dc:creator>
 <dc:creator>Lin, Kate Ching-Ju</dc:creator>
 <dc:creator>Hsu, Winston</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, Wi-Fi has caught tremendous attention for its ubiquity, and,
motivated by Wi-Fi's low cost and privacy preservation, researchers have been
putting lots of investigation into its potential on action recognition and even
person identification. In this paper, we offer an comprehensive overview on
these two topics in Wi-Fi. Also, through looking at these two topics from an
unprecedented perspective, we could achieve generality instead of designing
specific ad-hoc features for each scenario. Observing the great resemblance of
Channel State Information (CSI, a fine-grained information captured from the
received Wi-Fi signal) to texture, we proposed a brand-new framework based on
computer vision methods. To minimize the effect of location dependency embedded
in CSI, we propose a novel de-noising method based on Singular Value
Decomposition (SVD) to eliminate the background energy and effectively extract
the channel information of signals reflected by human bodies. From the
experiments conducted, we demonstrate the feasibility and efficacy of the
proposed methods. Also, we conclude factors that would affect the performance
and highlight a few promising issues that require further deliberation.
</dc:description>
 <dc:description>Comment: 10 pages, 10 figures, submit to IEEE Transactions on Multimedia</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2017-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05461</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05467</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Channel Estimation and Uplink Achievable Rates in One-Bit Massive MIMO
  Systems</dc:title>
 <dc:creator>Li, Yongzhi</dc:creator>
 <dc:creator>Tao, Cheng</dc:creator>
 <dc:creator>Liu, Liu</dc:creator>
 <dc:creator>Seco-Granados, Gonzalo</dc:creator>
 <dc:creator>Swindlehurst, A. Lee</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers channel estimation and achievable rates for the uplink
of a massive multiple-input multiple-output (MIMO) system where the base
station is equipped with one-bit analog-to-digital converters (ADCs). By
rewriting the nonlinear one-bit quantization using a linear expression, we
first derive a simple and insightful expression for the linear minimum
mean-square-error (LMMSE) channel estimator. Then employing this channel
estimator, we derive a closed-form expression for the lower bound of the
achievable rate for the maximum ratio combiner (MRC) receiver. Numerical
results are presented to verify our analysis and show that our proposed LMMSE
channel estimator outperforms the near maximum likelihood (nML) estimator
proposed previously.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures, the Ninth IEEE Sensor Array and Multichannel
  Signal Processing Workshop</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05467</dc:identifier>
 <dc:identifier>doi:10.1109/SAM.2016.7569618</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05468</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Much Training is Needed in One-Bit Massive MIMO Systems at Low SNR?</dc:title>
 <dc:creator>Li, Yongzhi</dc:creator>
 <dc:creator>Tao, Cheng</dc:creator>
 <dc:creator>Liu, Liu</dc:creator>
 <dc:creator>Mezghani, Amine</dc:creator>
 <dc:creator>Swindlehurst, A. Lee</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers training-based transmissions in massive multi-input
multi-output (MIMO) systems with one-bit analog-to-digital converters (ADCs).
We assume that each coherent transmission block consists of a pilot training
stage and a data transmission stage. The base station (BS) first employs the
linear minimum mean-square-error (LMMSE) method to estimate the channel and
then uses the maximum-ratio combining (MRC) receiver to detect the data
symbols. We first obtain an approximate closed-form expression for the uplink
achievable rate in the low SNR region. Then based on the result, we investigate
the optimal training length that maximizes the sum spectral efficiency for two
cases: i) The training power and the data transmission power are both
optimized; ii) The training power and the data transmission power are equal.
Numerical results show that, in contrast to conventional massive MIMO systems,
the optimal training length in one-bit massive MIMO systems is greater than the
number of users and depends on various parameters such as the coherence
interval and the average transmit power. Also, unlike conventional systems, it
is observed that in terms of sum spectral efficiency, there is relatively
little benefit to separately optimizing the training and data power.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, IEEE GLOBECOM 2016</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05468</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05470</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual User Selection for Security Enhancement in Uplink Multiuser Systems</dc:title>
 <dc:creator>Deng, Hao</dc:creator>
 <dc:creator>Wang, Hui-Ming</dc:creator>
 <dc:creator>Wang, Wenjie</dc:creator>
 <dc:creator>Lee, Moon Ho</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This letter proposes a novel dual user selection scheme for uplink
transmission with multiple users, where a jamming user and a served user are
jointly selected to improve the secrecy performance. Specifically, the jamming
user transmits jamming signal with a certain rate, so that the base station
(BS) can decode the jamming signal before detecting the secret information
signal. By carefully selecting the jamming user and the served user, it makes
the eavesdropper decode the jamming signal with a low probability meanwhile the
BS can achieve a high receive signal-to-noise ratio (SNR). Therefore, the
uplink transmission achieves the dual secrecy improvement by jamming and
scheduling. It is shown that the proposed scheme can significantly improve the
security of the uplink transmission.
</dc:description>
 <dc:description>Comment: journal paper, double column, 4 pages, 1 figure, accepted for
  publication on IEEE Communications Letters</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05470</dc:identifier>
 <dc:identifier>doi:10.1109/LCOMM.2016.2585125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05473</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Communication in Uplink Transmissions: User Selection and
  Multiuser Secrecy Gain</dc:title>
 <dc:creator>Deng, Hao</dc:creator>
 <dc:creator>Wang, Hui-Ming</dc:creator>
 <dc:creator>Yuan, Jinhong</dc:creator>
 <dc:creator>Wang, Wenjie</dc:creator>
 <dc:creator>Yin, Qinye</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate secure communications in uplink transmissions,
where there are a base station (BS) with M receive antennas, K mobile users
each with a single antenna, and an eavesdropper with N receive antennas. The
closed-form expressions of the achievable ergodic secrecy sumrates (ESSR) for a
random k users selection scheme in the high and low SNR regimes are presented.
It is shown that the scaling behavior of ESSR with respect to the number of
served users k can be quite different under different system configurations,
determined by the numbers of the BS antennas and that of the eavesdropper
antennas. In order to achieve a multiuser gain, two low-complexity user
selection schemes are proposed under different assumptions on the
eavesdropper's channel state information (CSI). The closed-form expressions of
the achievable ESSRs and the multiuser secrecy gains of the two schemes are
also presented in both low and high SNR regimes. We observe that, as k
increases, the multiuser secrecy gain increases, while the ESSR may decrease.
Therefore, when N is much larger than M, serving one user with the strongest
channel (TDMA-like) is a favourable secrecy scheme, where the ESSR scales with
root square of 2 log K.
</dc:description>
 <dc:description>Comment: journal paper, double column, 15 pages, 9 figures, accepted for
  publication on IEEE Transactions on Communications</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05473</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2016.2585128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05477</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Recurrent Encoder-Decoder Network for Sequential Face Alignment</dc:title>
 <dc:creator>Peng, Xi</dc:creator>
 <dc:creator>Feris, Rogerio S.</dc:creator>
 <dc:creator>Wang, Xiaoyu</dc:creator>
 <dc:creator>Metaxas, Dimitris N.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel recurrent encoder-decoder network model for real-time
video-based face alignment. Our proposed model predicts 2D facial point maps
regularized by a regression loss, while uniquely exploiting recurrent learning
at both spatial and temporal dimensions. At the spatial level, we add a
feedback loop connection between the combined output response map and the
input, in order to enable iterative coarse-to-fine face alignment using a
single network model. At the temporal level, we first decouple the features in
the bottleneck of the network into temporal-variant factors, such as pose and
expression, and temporal-invariant factors, such as identity information.
Temporal recurrent learning is then applied to the decoupled temporal-variant
features, yielding better generalization and significantly more accurate
results at test time. We perform a comprehensive experimental analysis, showing
the importance of each component of our proposed model, as well as superior
results over the state-of-the-art in standard datasets.
</dc:description>
 <dc:description>Comment: European Conference on Computer Vision (ECCV), 2016</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05479</identifier>
 <datestamp>2017-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Computation of Slepian Functions for Arbitrary Regions on the
  Sphere</dc:title>
 <dc:creator>Bates, Alice P.</dc:creator>
 <dc:creator>Khalid, Zubair</dc:creator>
 <dc:creator>Kennedy, Rodney A.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  In this paper, we develop a new method for the fast and memory-efficient
computation of Slepian functions on the sphere. Slepian functions, which arise
as the solution of the Slepian concentration problem on the sphere, have
desirable properties for applications where measurements are only available
within a spatially limited region on the sphere and/or a function is required
to be analyzed over the spatially limited region. Slepian functions are
currently not easily computed for large band-limits for an arbitrary spatial
region due to high computational and large memory storage requirements. For the
special case of a polar cap, the symmetry of the region enables the
decomposition of the Slepian concentration problem into smaller subproblems and
consequently the efficient computation of Slepian functions for large
band-limits. By exploiting the efficient computation of Slepian functions for
the polar cap region on the sphere, we develop a formulation, supported by a
fast algorithm, for the approximate computation of Slepian functions for an
arbitrary spatial region to enable the analysis of modern datasets that support
large band-limits. For the proposed algorithm, we carry out accuracy analysis
of the approximation, computational complexity analysis, and review of memory
storage requirements. We illustrate, through numerical experiments, that the
proposed method enables faster computation, and has smaller storage
requirements, while allowing for sufficiently accurate computation of the
Slepian functions.
</dc:description>
 <dc:description>Comment: 16 pages, 10 figures accepted to IEEE Transactions on Signal
  Processing</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:date>2017-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05479</dc:identifier>
 <dc:identifier>A. P. Bates, Z. Khalid and R. A. Kennedy, &quot;Efficient Computation
  of Slepian Functions for Arbitrary Regions on the Sphere,&quot; in IEEE
  Transactions on Signal Processing, vol. 65, no. 16, pp. 4379-4393, Aug.15, 15
  2017</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2712122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05485</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A heuristic scheme for the Cooperative Team Orienteering Problem with
  Time Windows</dc:title>
 <dc:creator>Roozbeh, Iman</dc:creator>
 <dc:creator>Ozlen, Melih</dc:creator>
 <dc:creator>Hearne, John W.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The Cooperative Orienteering Problem with Time Windows (COPTW)is a class of
problems with some important applications and yet has received relatively
little attention. In the COPTW a certain number of team members are required to
collect the associated reward from each customer simultaneously and
cooperatively. This requirement to have one or more team members simultaneously
available at a vertex to collect the reward, poses a challenging OR task. Exact
methods are not able to handle large scale instances of the COPTW and no
heuristic schemes have been developed for this problem so far. In this paper, a
new modification to the classical Clarke and Wright saving heuristic is
proposed to handle this problem. A new benchmark set generated by adding the
resource requirement attribute to the existing benchmarks. The heuristic
algorithm followed by boosting operators achieves optimal solutions for 64.5%
of instances for which the optimal results are known. The proposed solution
approach attains an optimality gap of 2.61% for the same instances and solves
benchmarks with realistic size within short computational times.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05485</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05493</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Volume Anomaly Detection and Identification in Large-scale
  Networks based on Online Time-structured Traffic Tensor Tracking</dc:title>
 <dc:creator>Kasai, Hiroyuki</dc:creator>
 <dc:creator>Kellerer, Wolfgang</dc:creator>
 <dc:creator>Kleinsteuber, Martin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper addresses network anomography, that is, the problem of inferring
network-level anomalies from indirect link measurements. This problem is cast
as a low-rank subspace tracking problem for normal flows under incomplete
observations, and an outlier detection problem for abnormal flows. Since
traffic data is large-scale time-structured data accompanied with noise and
outliers under partial observations, an efficient modeling method is essential.
To this end, this paper proposes an online subspace tracking of a Hankelized
time-structured traffic tensor for normal flows based on the Candecomp/PARAFAC
decomposition exploiting the recursive least squares (RLS) algorithm. We
estimate abnormal flows as outlier sparse flows via sparsity maximization in
the underlying under-constrained linear-inverse problem. A major advantage is
that our algorithm estimates normal flows by low-dimensional matrices with
time-directional features as well as the spatial correlation of multiple links
without using the past observed measurements and the past model parameters.
Extensive numerical evaluations show that the proposed algorithm achieves
faster convergence per iteration of model approximation, and better volume
anomaly detection performance compared to state-of-the-art algorithms.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Network and Service Management</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05493</dc:identifier>
 <dc:identifier>doi:10.1109/TNSM.2016.2598788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05501</identifier>
 <datestamp>2017-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disambiguating the role of noise correlations when decoding neural
  populations together</dc:title>
 <dc:creator>Eyherabide, Hugo Gabriel</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>94A17, 92B20</dc:subject>
 <dc:description>  One of the most controversial problems in neural decoding is quantifying the
information loss caused by ignoring noise correlations during optimal brain
computations. For more than a decade, the measure here called $ \Delta I^{DL} $
has been believed exact. However, we have recently shown that it can exceed the
information loss $ \Delta I^{B} $ caused by optimal decoders constructed
ignoring noise correlations. Unfortunately, the different information notions
underlying $ \Delta I^{DL} $ and $ \Delta I^{B} $, and the putative rigorous
information-theoretical derivation of $ \Delta I^{DL} $, both render unclear
whether those findings indicate either flaws in $ \Delta I^{DL} $ or major
departures from traditional relations between information and decoding. Here we
resolve this paradox and prove that, under certain conditions, observing $
\Delta I^{DL} {&gt;}\Delta I^{B} $ implies that $ \Delta I^{DL} $ is flawed.
Motivated by this analysis, we test both measures using neural populations that
transmit independent information. Our results show that $ \Delta I^{DL} $ may
deem noise correlations more important when decoding the populations together
than when decoding them in parallel, whereas the opposite may occur for $
\Delta I^{B} $. We trace these phenomena back, for $ \Delta I^{B} $, to the
choice of tie-breaking rules, and for $ \Delta I^{DL} $, to unforeseen
limitations within its information-theoretical foundations. Our study
contributes with better estimates that potentially improve theoretical and
experimental inferences currently drawn from $ \Delta I^{DL} $ without noticing
that it may constitute an upper bound. On the practical side, our results
promote the design of optimal decoding algorithms and neuroprosthetics without
recording noise correlations, thereby saving experimental and computational
resources.
</dc:description>
 <dc:description>Comment: To improve readability, this version has more material, more
  explanations, more figures, less symbols, and more demonstrations than the
  previous version</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2017-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05505</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End of Publication? Open access and a new scholarly communication
  technology</dc:title>
 <dc:creator>Parinov, Sergey</dc:creator>
 <dc:creator>Antonova, Victoria</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>68U35</dc:subject>
 <dc:subject>D.2.2</dc:subject>
 <dc:subject>D.2.10</dc:subject>
 <dc:subject>D.2.12</dc:subject>
 <dc:subject>H.1.2</dc:subject>
 <dc:subject>H.3.4</dc:subject>
 <dc:subject>H.3.5</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:subject>K.4</dc:subject>
 <dc:description>  At this time, developers of research information systems are experimenting
with new tools for research outputs usage that can expand the open access to
research. These tools allow researchers to record research as annotations,
nanopublications or other micro research outputs and link them by scientific
relationships. If these micro outputs and relationships are shared by their
creators publicly, these actions can initiate direct scholarly communication
between the creators and the authors of the used research outputs. Such direct
communication takes place while researchers are manipulating and organising
their research results, e.g. as manuscripts. Thus, researchers come to
communication before the manuscripts become traditional publications. In this
paper, we discuss how this pre-publication communication can affect existing
research practice. It can have important consequences for the research
community like the end of publication as a communication instrument, the higher
level of transparency in research, changes for the Open Access movement,
academic publishers, peer-reviewing and research assessment systems. We analyse
a background that exists in the economics discipline for experiments with the
pre-publication communication. We propose a set of experiments with already
existed and new tools, which can help with exploring the end of publication
possible impacts on the research community.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05505</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05512</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Critical Points for Two-view Triangulation</dc:title>
 <dc:creator>Lee, Hon-Leung</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:description>  Two-view triangulation is a problem of minimizing a quadratic polynomial
under an equality constraint. We derive a polynomial that encodes the local
minimizers of this problem using the theory of Lagrange multipliers. This
offers a simpler derivation of the critical points that are given in
Hartley-Sturm [6].
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05513</identifier>
 <datestamp>2016-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Centroid Based Multi-Level Fuzzy Min-Max Neural Network</dc:title>
 <dc:creator>Deshmukh, Shraddha</dc:creator>
 <dc:creator>Gandhi, Sagar</dc:creator>
 <dc:creator>Sanap, Pratap</dc:creator>
 <dc:creator>Kulkarni, Vivek</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Recently, a multi-level fuzzy min max neural network (MLF) was proposed,
which improves the classification accuracy by handling an overlapped region
(area of confusion) with the help of a tree structure. In this brief, an
extension of MLF is proposed which defines a new boundary region, where the
previously proposed methods mark decisions with less confidence and hence
misclassification is more frequent. A methodology to classify patterns more
accurately is presented. Our work enhances the testing procedure by means of
data centroids. We exhibit an illustrative example, clearly highlighting the
advantage of our approach. Results on standard datasets are also presented to
evidentially prove a consistent improvement in the classification rate.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the author due to crucial evidence
  that the similar work has already been published</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2016-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05517</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting and Tracking The Real-time Hot Topics: A Study on
  Computational Neuroscience</dc:title>
 <dc:creator>Wang, Xianwen</dc:creator>
 <dc:creator>Fang, Zhichao</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In this study, following the idea of our previous paper (Wang, et al.,
2013a), we improve the method to detect and track hot topics in a specific
field by using the real-time article usage data. With the &quot;usage count&quot; data
provided by Web of Science, we take the field of computational neuroscience as
an example to make analysis. About 10 thousand articles in the field of
Computational Neuroscience are queried in Web of Science, when the records,
including the usage count data of each paper, have been harvested and updated
weekly from October 19, 2015 to March 21, 2016. The hot topics are defined by
the most frequently used keywords aggregated from the articles. The analysis
reveals that hot topics in Computational Neuroscience are related to the key
technologies, like &quot;fmri&quot;, &quot;eeg&quot;, &quot;erp&quot;, etc. Furthermore, using the weekly
updated data, we track the dynamical changes of the topics. The characteristic
of immediacy of usage data makes it possible to track the &quot;heat&quot; of hot topics
timely and dynamically.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05517</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05518</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Existence of a Projective Reconstruction</dc:title>
 <dc:creator>Lee, Hon-Leung</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this note we study the connection between the existence of a projective
reconstruction and the existence of a fundamental matrix satisfying the
epipolar constraints.
</dc:description>
 <dc:description>Comment: 7 pages, 1 figure</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05518</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05521</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Reversible Computation in Erlang</dc:title>
 <dc:creator>Nishida, Naoki</dc:creator>
 <dc:creator>Palacios, Adri&#xe1;n</dc:creator>
 <dc:creator>Vidal, Germ&#xe1;n</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In a reversible language, any forward computation can be undone by a finite
sequence of backward steps. Reversible computing has been studied in the
context of different programming languages and formalisms, where it has been
used for debugging and for enforcing fault-tolerance, among others. In this
paper, we consider a subset of Erlang, a concurrent language based on the actor
model. We formally introduce a reversible semantics for this language. To the
best of our knowledge, this is the first attempt to define a reversible
semantics for Erlang.
</dc:description>
 <dc:description>Comment: Pre-proceedings paper presented at the 26th International Symposium
  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,
  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05522</identifier>
 <datestamp>2016-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting enumerative two-part crude MDL for Bernoulli and multinomial
  distributions (Extended version)</dc:title>
 <dc:creator>Boull&#xe9;, Marc</dc:creator>
 <dc:creator>Cl&#xe9;rot, Fabrice</dc:creator>
 <dc:creator>Hue, Carine</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>68P30</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:description>  We leverage the Minimum Description Length (MDL) principle as a model
selection technique for Bernoulli distributions and compare several types of
MDL codes. We first present a simplistic crude two-part MDL code and a
Normalized Maximum Likelihood (NML) code. We then focus on the enumerative
two-part crude MDL code, suggest a Bayesian interpretation for finite size data
samples, and exhibit a strong connection with the NML approach. We obtain
surprising impacts on the estimation of the model complexity together with
superior compression performance. This is then generalized to the case of the
multinomial distributions. Both the theoretical analysis and the experimental
comparisons suggest that one might use the enumerative code rather than NML in
practice, for Bernoulli and multinomial distributions.
</dc:description>
 <dc:description>Comment: 25 pages</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2016-10-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05528</identifier>
 <datestamp>2017-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Selection of Context Configurations for Improved
  Class-Specific Word Representations</dc:title>
 <dc:creator>Vuli&#x107;, Ivan</dc:creator>
 <dc:creator>Schwartz, Roy</dc:creator>
 <dc:creator>Rappoport, Ari</dc:creator>
 <dc:creator>Reichart, Roi</dc:creator>
 <dc:creator>Korhonen, Anna</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper is concerned with identifying contexts useful for training word
representation models for different word classes such as adjectives (A), verbs
(V), and nouns (N). We introduce a simple yet effective framework for an
automatic selection of class-specific context configurations. We construct a
context configuration space based on universal dependency relations between
words, and efficiently search this space with an adapted beam search algorithm.
In word similarity tasks for each word class, we show that our framework is
both effective and efficient. Particularly, it improves the Spearman's rho
correlation with human scores on SimLex-999 over the best previously proposed
class-specific contexts by 6 (A), 6 (V) and 5 (N) rho points. With our selected
context configurations, we train on only 14% (A), 26.2% (V), and 33.6% (N) of
all dependency-based contexts, resulting in a reduced training time. Our
results generalise: we show that the configurations our algorithm learns for
one English training setup outperform previously proposed context types in
another training setup for English. Moreover, basing the configuration space on
universal dependencies, it is possible to transfer the learned configurations
to German and Italian. We also demonstrate improved per-class results over
other context types in these two languages.
</dc:description>
 <dc:description>Comment: CoNLL 2017</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2017-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05528</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05537</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Private and Truthful Aggregative Game for Large-Scale Spectrum Sharing</dc:title>
 <dc:creator>Zhou, Pan</dc:creator>
 <dc:creator>Wei, Wenqi</dc:creator>
 <dc:creator>Bian, Kaigui</dc:creator>
 <dc:creator>Wu, Dapeng Oliver</dc:creator>
 <dc:creator>Hu, Yuchong</dc:creator>
 <dc:creator>Wang, Qian</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Thanks to the rapid development of information technology, the size of the
wireless network becomes larger and larger, which makes spectrum resources more
precious than ever before. To improve the efficiency of spectrum utilization,
game theory has been applied to study the spectrum sharing in wireless networks
for a long time. However, the scale of wireless network in existing studies is
relatively small. In this paper, we introduce a novel game and model the
spectrum sharing problem as an aggregative game for large-scale, heterogeneous,
and dynamic networks. The massive usage of spectrum also leads to easier
privacy divulgence of spectrum users' actions, which calls for privacy and
truthfulness guarantees in wireless network. In a large decentralized scenario,
each user has no priori about other users' decisions, which forms an incomplete
information game. A &quot;weak mediator&quot;, e.g., the base station or licensed
spectrum regulator, is introduced and turns this game into a complete one,
which is essential to reach a Nash equilibrium (NE). By utilizing past
experience on the channel access, we propose an online learning algorithm to
improve the utility of each user, achieving NE over time. Our learning
algorithm also provides no regret guarantee to each user. Our mechanism admits
an approximate ex-post NE. We also prove that it satisfies the joint
differential privacy and is incentive-compatible. Efficiency of the approximate
NE is evaluated, and the innovative scaling law results are disclosed. Finally,
we provide simulation results to verify our analysis.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05538</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Routing in Anonymous Communication Protocols</dc:title>
 <dc:creator>Shirazi, Fatemeh</dc:creator>
 <dc:creator>Simeonovski, Milivoj</dc:creator>
 <dc:creator>Asghar, Muhammad Rizwan</dc:creator>
 <dc:creator>Backes, Michael</dc:creator>
 <dc:creator>Diaz, Claudia</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The Internet has undergone dramatic changes in the past 15 years, and now
forms a global communication platform that billions of users rely on for their
daily activities. While this transformation has brought tremendous benefits to
society, it has also created new threats to online privacy, ranging from
profiling of users for monetizing personal information to nearly omnipotent
governmental surveillance. As a result, public interest in systems for
anonymous communication has drastically increased. Several such systems have
been proposed in the literature, each of which offers anonymity guarantees in
different scenarios and under different assumptions, reflecting the plurality
of approaches for how messages can be anonymously routed to their destination.
Understanding this space of competing approaches with their different
guarantees and assumptions is vital for users to understand the consequences of
different design options.
  In this work, we survey previous research on designing, developing, and
deploying systems for anonymous communication. To this end, we provide a
taxonomy for clustering all prevalently considered approaches (including
Mixnets, DC-nets, onion routing, and DHT-based protocols) with respect to their
unique routing characteristics, deployability, and performance. This, in
particular, encompasses the topological structure of the underlying network;
the routing information that has to be made available to the initiator of the
conversation; the underlying communication model; and performance-related
indicators such as latency and communication layer. Our taxonomy and
comparative assessment provide important insights about the differences between
the existing classes of anonymous communication protocols, and it also helps to
clarify the relationship between the routing characteristics of these
protocols, and their performance and scalability.
</dc:description>
 <dc:description>Comment: 24 pages, 4 tables, 4 figures</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05543</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uncertainty Principle for Measurable Sets and Signal Recovery in
  Quaternion Domains</dc:title>
 <dc:creator>Kou, Kit Ian</dc:creator>
 <dc:creator>Yang, Yan</dc:creator>
 <dc:creator>Zou, Cuiming</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The classical uncertainty principle of harmonic analysis states that a
nontrivial function and its Fourier transform cannot both be sharply localized.
It plays an important role in signal processing and physics. This paper
generalizes the uncertainty principle for measurable sets from complex domain
to hypercomplex domain using quaternion algebras, associated with the
Quaternion Fourier transform. The performance is then evaluated in signal
recovery problems where there is an interplay of missing and time-limiting
data.
</dc:description>
 <dc:description>Comment: 10 pages, 3 figures</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2016-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05543</dc:identifier>
 <dc:identifier>doi:10.1002/mma.4271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05548</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Goal-Oriented Reduction of Automata Networks</dc:title>
 <dc:creator>Paulev&#xe9;, Lo&#xef;c</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:description>  We consider networks of finite-state machines having local transitions
conditioned by the current state of other automata. In this paper, we depict a
reduction procedure tailored for a given reachability property of the form
``from global state s there exists a sequence of transitions leading to a state
where an automaton g is in a local state T'. By exploiting a causality analysis
of the transitions within the individual automata, the proposed reduction
removes local transitions while preserving all the minimal traces that satisfy
the reachability property. The complexity of the procedure is polynomial in the
total number of local states and transitions, and exponential in the number of
local states within one automaton. Applied to automata networks modelling
dynamics of biological systems, we observe that the reduction shrinks down
significantly the reachable state space, enhancing the tractability of the
model-checking of large networks.
</dc:description>
 <dc:description>Comment: Accepted at CMSB 2016</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05548</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-45177-0_16</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05550</identifier>
 <datestamp>2017-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shortest unique palindromic substring queries in optimal time</dc:title>
 <dc:creator>Nakashima, Yuto</dc:creator>
 <dc:creator>Inoue, Hiroe</dc:creator>
 <dc:creator>Mieno, Takuya</dc:creator>
 <dc:creator>Inenaga, Shunsuke</dc:creator>
 <dc:creator>Bannai, Hideo</dc:creator>
 <dc:creator>Takeda, Masayuki</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A palindrome is a string that reads the same forward and backward. A
palindromic substring $P$ of a string $S$ is called a shortest unique
palindromic substring ($\mathit{SUPS}$) for an interval $[x, y]$ in $S$, if $P$
occurs exactly once in $S$, this occurrence of $P$ contains interval $[x, y]$,
and every palindromic substring of $S$ which contains interval $[x, y]$ and is
shorter than $P$ occurs at least twice in $S$. The $\mathit{SUPS}$ problem is,
given a string $S$, to preprocess $S$ so that for any subsequent query interval
$[x, y]$ all the $\mathit{SUPS}\mbox{s}$ for interval $[x, y]$ can be answered
quickly. We present an optimal solution to this problem. Namely, we show how to
preprocess a given string $S$ of length $n$ in $O(n)$ time and space so that
all $\mathit{SUPS}\mbox{s}$ for any subsequent query interval can be answered
in $O(k+1)$ time, where $k$ is the number of outputs.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2017-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05550</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05552</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relationship between the Reprogramming Determinants of Boolean Networks
  and their Interaction Graph</dc:title>
 <dc:creator>Mandon, Hugues</dc:creator>
 <dc:creator>Haar, Stefan</dc:creator>
 <dc:creator>Paulev&#xe9;, Lo&#xef;c</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Quantitative Biology - Molecular Networks</dc:subject>
 <dc:subject>05C82, 92C42</dc:subject>
 <dc:description>  In this paper, we address the formal characterization of targets triggering
cellular trans-differentiation in the scope of Boolean networks with
asynchronous dynamics. Given two fixed points of a Boolean network, we are
interested in all the combinations of mutations which allow to switch from one
fixed point to the other, either possibly, or inevitably. In the case of
existential reachability, we prove that the set of nodes to (permanently) flip
are only and necessarily in certain connected components of the interaction
graph. In the case of inevitable reachability, we provide an algorithm to
identify a subset of possible solutions.
</dc:description>
 <dc:description>Comment: Accepted at HSB 2016</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05552</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-47151-8_8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05554</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Start for Sequence to Sequence Architecture</dc:title>
 <dc:creator>Zhu, Qingfu</dc:creator>
 <dc:creator>Zhang, Weinan</dc:creator>
 <dc:creator>Zhou, Lianqiang</dc:creator>
 <dc:creator>Liu, Ting</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The sequence to sequence architecture is widely used in the response
generation and neural machine translation to model the potential relationship
between two sentences. It typically consists of two parts: an encoder that
reads from the source sentence and a decoder that generates the target sentence
word by word according to the encoder's output and the last generated word.
However, it faces to the cold start problem when generating the first word as
there is no previous word to refer. Existing work mainly use a special start
symbol &lt;/s&gt;to generate the first word. An obvious drawback of these work is
that there is not a learnable relationship between words and the start symbol.
Furthermore, it may lead to the error accumulation for decoding when the first
word is incorrectly generated. In this paper, we proposed a novel approach to
learning to generate the first word in the sequence to sequence architecture
rather than using the start symbol. Experimental results on the task of
response generation of short text conversation show that the proposed approach
outperforms the state-of-the-art approach in both of the automatic and manual
evaluations.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05554</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05560</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Iterative Views Agreement: An Iterative Low-Rank based Structured
  Optimization Method to Multi-View Spectral Clustering</dc:title>
 <dc:creator>Wang, Yang</dc:creator>
 <dc:creator>Zhang, Wenjie</dc:creator>
 <dc:creator>Wu, Lin</dc:creator>
 <dc:creator>Lin, Xuemin</dc:creator>
 <dc:creator>Fang, Meng</dc:creator>
 <dc:creator>Pan, Shirui</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Multi-view spectral clustering, which aims at yielding an agreement or
consensus data objects grouping across multi-views with their graph laplacian
matrices, is a fundamental clustering problem. Among the existing methods,
Low-Rank Representation (LRR) based method is quite superior in terms of its
effectiveness, intuitiveness and robustness to noise corruptions. However, it
aggressively tries to learn a common low-dimensional subspace for multi-view
data, while inattentively ignoring the local manifold structure in each view,
which is critically important to the spectral clustering; worse still, the
low-rank minimization is enforced to achieve the data correlation consensus
among all views, failing to flexibly preserve the local manifold structure for
each view. In this paper, 1) we propose a multi-graph laplacian regularized LRR
with each graph laplacian corresponding to one view to characterize its local
manifold structure. 2) Instead of directly enforcing the low-rank minimization
among all views for correlation consensus, we separately impose low-rank
constraint on each view, coupled with a mutual structural consensus constraint,
where it is able to not only well preserve the local manifold structure but
also serve as a constraint for that from other views, which iteratively makes
the views more agreeable. Extensive experiments on real-world multi-view data
sets demonstrate its superiority.
</dc:description>
 <dc:description>Comment: Accepted to appear in IJCAI 2016</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05562</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rigid Slice-To-Volume Medical Image Registration through Markov Random
  Fields</dc:title>
 <dc:creator>Porchetto, Roque</dc:creator>
 <dc:creator>Stramana, Franco</dc:creator>
 <dc:creator>Paragios, Nikos</dc:creator>
 <dc:creator>Ferrante, Enzo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Rigid slice-to-volume registration is a challenging task, which finds
application in medical imaging problems like image fusion for image guided
surgeries and motion correction for volume reconstruction. It is usually
formulated as an optimization problem and solved using standard continuous
methods. In this paper, we discuss how this task be formulated as a discrete
labeling problem on a graph. Inspired by previous works on discrete estimation
of linear transformations using Markov Random Fields (MRFs), we model it using
a pairwise MRF, where the nodes are associated to the rigid parameters, and the
edges encode the relation between the variables. We compare the performance of
the proposed method to a continuous formulation optimized using simplex, and we
discuss how it can be used to further improve the accuracy of our approach.
Promising results are obtained using a monomodal dataset composed of magnetic
resonance images (MRI) of a beating heart.
</dc:description>
 <dc:description>Comment: Bayesian and Graphical Models for Biomedical Imaging Workshop, BAMBI
  (MICCAI 2016, Athens, Greece)</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05562</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05564</identifier>
 <datestamp>2017-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Living in Parallel Realities -- Co-Existing Schema Versions with a
  Bidirectional Database Evolution Language</dc:title>
 <dc:creator>Herrmann, Kai</dc:creator>
 <dc:creator>Voigt, Hannes</dc:creator>
 <dc:creator>Behrend, Andreas</dc:creator>
 <dc:creator>Rausch, Jonas</dc:creator>
 <dc:creator>Lehner, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We introduce end-to-end support of co-existing schema versions within one
database. While it is state of the art to run multiple versions of a
continuously developed application concurrently, it is hard to do the same for
databases. In order to keep multiple co-existing schema versions alive; which
are all accessing the same data set; developers usually employ handwritten
delta code (e.g. views and triggers in SQL). This delta code is hard to write
and hard to maintain: if a database administrator decides to adapt the physical
table schema, all handwritten delta code needs to be adapted as well, which is
expensive and error-prone in practice. In this paper, we present InVerDa:
developers use the simple bidirectional database evolution language BiDEL,
which carries enough information to generate all delta code automatically.
Without additional effort, new schema versions become immediately accessible
and data changes in any version are visible in all schema versions at the same
time. InVerDa also allows for easily changing the physical table design without
affecting the availability of co-existing schema versions. This greatly
increases robustness (orders of magnitude less lines of code) and allows for
significant performance optimization. A main contribution is the formal
evaluation that each schema version acts like a common full-fledged database
schema independently of the chosen physical table design.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2017-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05564</dc:identifier>
 <dc:identifier>doi:10.1145/3035918.3064046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05571</identifier>
 <datestamp>2016-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Spatially Regularized Correlation Filters for Visual Tracking</dc:title>
 <dc:creator>Danelljan, Martin</dc:creator>
 <dc:creator>H&#xe4;ger, Gustav</dc:creator>
 <dc:creator>Khan, Fahad Shahbaz</dc:creator>
 <dc:creator>Felsberg, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Robust and accurate visual tracking is one of the most challenging computer
vision problems. Due to the inherent lack of training data, a robust approach
for constructing a target appearance model is crucial. Recently,
discriminatively learned correlation filters (DCF) have been successfully
applied to address this problem for tracking. These methods utilize a periodic
assumption of the training samples to efficiently learn a classifier on all
patches in the target neighborhood. However, the periodic assumption also
introduces unwanted boundary effects, which severely degrade the quality of the
tracking model.
  We propose Spatially Regularized Discriminative Correlation Filters (SRDCF)
for tracking. A spatial regularization component is introduced in the learning
to penalize correlation filter coefficients depending on their spatial
location. Our SRDCF formulation allows the correlation filters to be learned on
a significantly larger set of negative training samples, without corrupting the
positive samples. We further propose an optimization strategy, based on the
iterative Gauss-Seidel method, for efficient online learning of our SRDCF.
Experiments are performed on four benchmark datasets: OTB-2013, ALOV++,
OTB-2015, and VOT2014. Our approach achieves state-of-the-art results on all
four datasets. On OTB-2013 and OTB-2015, we obtain an absolute gain of 8.0% and
8.2% respectively, in mean overlap precision, compared to the best existing
trackers.
</dc:description>
 <dc:description>Comment: ICCV 2015</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05571</dc:identifier>
 <dc:identifier>International Conference on Computer Vision, (ICCV) 2015, pp.
  4310-4318. IEEE (2015)</dc:identifier>
 <dc:identifier>doi:10.1109/ICCV.2015.490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05578</identifier>
 <datestamp>2017-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Haploid-Diploid Evolutionary Algorithms</dc:title>
 <dc:creator>Bull, Larry</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  This paper uses the recent idea that the fundamental haploid-diploid
lifecycle of eukaryotic organisms implements a rudimentary form of learning
within evolution. A general approach for evolutionary computation is here
derived that differs from all previous known work using diploid
representations. The primary role of recombination is also changed from that
previously considered in both natural and artificial evolution under the new
view. Using well-known abstract tuneable models it is shown that varying
fitness landscape ruggedness varies the benefit of the new approach.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1607.00318</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2017-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05581</identifier>
 <datestamp>2017-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Feature Selection Based on the Morisita Estimator of
  Intrinsic Dimension</dc:title>
 <dc:creator>Golay, Jean</dc:creator>
 <dc:creator>Kanevski, Mikhail</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper deals with a new filter algorithm for selecting the smallest
subset of features carrying all the information content of a data set (i.e. for
removing redundant features). It is an advanced version of the fractal
dimension reduction technique, and it relies on the recently introduced
Morisita estimator of Intrinsic Dimension (ID). Here, the ID is used to
quantify dependencies between subsets of features, which allows the effective
processing of highly non-linear data. The proposed algorithm is successfully
tested on simulated and real world case studies. Different levels of sample
size and noise are examined along with the variability of the results. In
addition, a comprehensive procedure based on random forests shows that the data
dimensionality is significantly reduced by the algorithm without loss of
relevant information. And finally, comparisons with benchmark feature selection
techniques demonstrate the promising performance of this new filter.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2017-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05594</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Joining Graphs</dc:title>
 <dc:creator>Bergami, Giacomo</dc:creator>
 <dc:creator>Magnani, Matteo</dc:creator>
 <dc:creator>Montesi, Danilo</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  In the graph database literature the term &quot;join&quot; does not refer to an
operator used to merge two graphs. In particular, a counterpart of the
relational join is not present in existing graph query languages, and
consequently no efficient algorithms have been developed for this operator.
  This paper provides two main contributions. First, we define a binary graph
join operator that acts on the vertices as a standard relational join and
combines the edges according to a user-defined semantics. Then we propose the
&quot;CoGrouped Graph Conjunctive $\theta$-Join&quot; algorithm running over data indexed
in secondary memory. Our implementation outperforms the execution of the same
operation in Cypher and SPARQL on major existing graph database management
systems by at least one order of magnitude, also including indexing and loading
time.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05594</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05604</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling Human Reading with Neural Attention</dc:title>
 <dc:creator>Hahn, Michael</dc:creator>
 <dc:creator>Keller, Frank</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  When humans read text, they fixate some words and skip others. However, there
have been few attempts to explain skipping behavior with computational models,
as most existing work has focused on predicting reading times (e.g.,~using
surprisal). In this paper, we propose a novel approach that models both
skipping and reading, using an unsupervised architecture that combines a neural
attention with autoencoding, trained on raw text using reinforcement learning.
Our model explains human reading behavior as a tradeoff between precision of
language understanding (encoding the input accurately) and economy of attention
(fixating as few words as possible). We evaluate the model on the Dundee
eye-tracking corpus, showing that it accurately predicts skipping behavior and
reading times, is competitive with surprisal, and captures known qualitative
features of human reading.
</dc:description>
 <dc:description>Comment: EMNLP 2016, pp. 85-95, Austin, TX</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2017-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05605</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Distributed Representations to Disambiguate Biomedical and
  Clinical Concepts</dc:title>
 <dc:creator>Tulkens, St&#xe9;phan</dc:creator>
 <dc:creator>&#x160;uster, Simon</dc:creator>
 <dc:creator>Daelemans, Walter</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we report a knowledge-based method for Word Sense
Disambiguation in the domains of biomedical and clinical text. We combine word
representations created on large corpora with a small number of definitions
from the UMLS to create concept representations, which we then compare to
representations of the context of ambiguous terms. Using no relational
information, we obtain comparable performance to previous approaches on the
MSH-WSD dataset, which is a well-known dataset in the biomedical domain.
Additionally, our method is fast and easy to set up and extend to other
domains. Supplementary materials, including source code, can be found at https:
//github.com/clips/yarn
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, presented at the 15th Workshop on Biomedical
  Natural Language Processing, Berlin 2016</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05605</dc:identifier>
 <dc:identifier>Proceedings of the 15th Workshop on Biomedical Natural Language
  Processing, Berlin, Germany, 2016, pages 77-82. Association for Computational
  Linguistics</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05609</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implementing a Relevance Tracker Module</dc:title>
 <dc:creator>Jansen, Joachim</dc:creator>
 <dc:creator>Devriendt, Jo</dc:creator>
 <dc:creator>Bogaerts, Bart</dc:creator>
 <dc:creator>Janssens, Gerda</dc:creator>
 <dc:creator>Denecker, Marc</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  PC(ID) extends propositional logic with inductive definitions: rule sets
under the well-founded semantics. Recently, a notion of relevance was
introduced for this language. This notion determines the set of undecided
literals that can still influence the satisfiability of a PC(ID) formula in a
given partial assignment. The idea is that the PC(ID) solver can make decisions
only on relevant literals without losing soundness and thus safely ignore
irrelevant literals.
  One important insight that the relevance of a literal is completely
determined by the current solver state. During search, the solver state changes
have an effect on the relevance of literals. In this paper, we discuss an
incremental, lightweight implementation of a relevance tracker module that can
be added to and interact with an out-of-the-box SAT(ID) solver.
</dc:description>
 <dc:description>Comment: Paper presented at the 9th Workshop on Answer Set Programming and
  Other Computing Paradigms (ASPOCP 2016), New York City, USA, 16 October 2016</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05609</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05610</identifier>
 <datestamp>2017-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Strongly Quasiconvex PAC-Bayesian Bound</dc:title>
 <dc:creator>Thiemann, Niklas</dc:creator>
 <dc:creator>Igel, Christian</dc:creator>
 <dc:creator>Wintenberger, Olivier</dc:creator>
 <dc:creator>Seldin, Yevgeny</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a new PAC-Bayesian bound and a way of constructing a hypothesis
space, so that the bound is convex in the posterior distribution and also
convex in a trade-off parameter between empirical performance of the posterior
distribution and its complexity. The complexity is measured by the
Kullback-Leibler divergence to a prior. We derive an alternating procedure for
minimizing the bound. We show that the bound can be rewritten as a
one-dimensional function of the trade-off parameter and provide sufficient
conditions under which the function has a single global minimum. When the
conditions are satisfied the alternating minimization is guaranteed to converge
to the global minimum of the bound. We provide experimental results
demonstrating that rigorous minimization of the bound is competitive with
cross-validation in tuning the trade-off between complexity and empirical
performance. In all our experiments the trade-off turned to be quasiconvex even
when the sufficient conditions were violated.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2017-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05610</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05613</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A short-key one-time pad cipher</dc:title>
 <dc:creator>Starossek, Uwe</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A process for the secure transmission of data is presented that has to a
certain degree the advantages of the one-time pad (OTP) cipher, that is,
simplicity, speed, and information-theoretically security, but overcomes its
fundamental weakness, the necessity of securely exchanging a key that is as
long as the message. For each transmission, a dedicated one-time pad is
generated for encrypting and decrypting the plaintext message. This one-time
pad is built from a randomly chosen set of basic keys taken from a public
library. Because the basic keys can be chosen and used multiple times, the
method is called multiple-time pad (MTP) cipher. The information on the choice
of basic keys is encoded in a short keyword that is transmitted by secure
means. The process is made secure against known-plaintext attack by additional
design elements. The process is particularly useful for high-speed transmission
of mass data and video or audio streaming.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05617</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CurryCheck: Checking Properties of Curry Programs</dc:title>
 <dc:creator>Hanus, Michael</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We present CurryCheck, a tool to automate the testing of programs written in
the functional logic programming language Curry. CurryCheck executes unit tests
as well as property tests which are parameterized over one or more arguments.
In the latter case, CurryCheck tests these properties by systematically
enumerating test cases so that, for smaller finite domains, CurryCheck can
actually prove properties. Unit tests and properties can be defined in a Curry
module without being exported. Thus, they are also useful to document the
intended semantics of the source code. Furthermore, CurryCheck also supports
the automated checking of specifications and contracts occurring in source
programs. Hence, CurryCheck is a useful tool that contributes to the property-
and specification-based development of reliable and well tested declarative
programs.
</dc:description>
 <dc:description>Comment: Pre-proceedings paper presented at the 26th International Symposium
  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,
  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05617</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05619</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Symbolic Abstract Contract Synthesis in a Rewriting Framework</dc:title>
 <dc:creator>Alpuente, Mar&#xed;a</dc:creator>
 <dc:creator>Pardo, Daniel</dc:creator>
 <dc:creator>Villanueva, Alicia</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We propose an automated technique for inferring software contracts from
programs that are written in a non-trivial fragment of C, called KernelC, that
supports pointer-based structures and heap manipulation. Starting from the
semantic definition of KernelC in the K framework, we enrich the symbolic
execution facilities recently provided by K with novel capabilities for
assertion synthesis that are based on abstract subsumption. Roughly speaking,
we define an abstract symbolic technique that explains the execution of a
(modifier) C function by using other (observer) routines in the same program.
We implemented our technique in the automated tool KindSpec 2.0, which
generates logical axioms that express pre- and post-condition assertions by
defining the precise input/output behaviour of the C routines.
</dc:description>
 <dc:description>Comment: Pre-proceedings paper presented at the 26th International Symposium
  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,
  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05634</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Thrill: High-Performance Algorithmic Distributed Batch Data Processing
  with C++</dc:title>
 <dc:creator>Bingmann, Timo</dc:creator>
 <dc:creator>Axtmann, Michael</dc:creator>
 <dc:creator>J&#xf6;bstl, Emanuel</dc:creator>
 <dc:creator>Lamm, Sebastian</dc:creator>
 <dc:creator>Nguyen, Huyen Chau</dc:creator>
 <dc:creator>Noe, Alexander</dc:creator>
 <dc:creator>Schlag, Sebastian</dc:creator>
 <dc:creator>Stumpp, Matthias</dc:creator>
 <dc:creator>Sturm, Tobias</dc:creator>
 <dc:creator>Sanders, Peter</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:description>  We present the design and a first performance evaluation of Thrill -- a
prototype of a general purpose big data processing framework with a convenient
data-flow style programming interface. Thrill is somewhat similar to Apache
Spark and Apache Flink with at least two main differences. First, Thrill is
based on C++ which enables performance advantages due to direct native code
compilation, a more cache-friendly memory layout, and explicit memory
management. In particular, Thrill uses template meta-programming to compile
chains of subsequent local operations into a single binary routine without
intermediate buffering and with minimal indirections. Second, Thrill uses
arrays rather than multisets as its primary data structure which enables
additional operations like sorting, prefix sums, window scans, or combining
corresponding fields of several arrays (zipping). We compare Thrill with Apache
Spark and Apache Flink using five kernels from the HiBench suite. Thrill is
consistently faster and often several times faster than the other frameworks.
At the same time, the source codes have a similar level of simplicity and
abstraction
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05634</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05637</identifier>
 <datestamp>2017-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polynomial Kernels and Wideness Properties of Nowhere Dense Graph
  Classes</dc:title>
 <dc:creator>Kreutzer, Stephan</dc:creator>
 <dc:creator>Rabinovich, Roman</dc:creator>
 <dc:creator>Siebertz, Sebastian</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Nowhere dense classes of graphs are very general classes of uniformly sparse
graphs with several seemingly unrelated characterisations. From an algorithmic
perspective, a characterisation of these classes in terms of uniform
quasi-wideness, a concept originating in finite model theory, has proved to be
particularly useful. Uniform quasi-wideness is used in many fpt-algorithms on
nowhere dense classes. However, the existing constructions showing the
equivalence of nowhere denseness and uniform quasi-wideness imply a
non-elementary blow up in the parameter dependence of the fpt-algorithms,
making them infeasible in practice.
  As a first main result of this paper, we use tools from logic, in particular
from a subfield of model theory known as stability theory, to establish
polynomial bounds for the equivalence of nowhere denseness and uniform
quasi-wideness.
  A powerful method in parameterized complexity theory is to compute a problem
kernel in a pre-computation step, that is, to reduce the input instance in
polynomial time to a sub-instance of size bounded in the parameter only
(independently of the input graph size). Our new tools allow us to obtain for
every fixed value of $r$ a polynomial kernel for the distance-$r$ dominating
set problem on nowhere dense classes of graphs. This result is particularly
interesting, as it implies that for every class $\mathcal{C}$ of graphs which
is closed under subgraphs, the distance-$r$ dominating set problem admits a
kernel on $\mathcal{C}$ for every value of $r$ if, and only if, it admits a
polynomial kernel for every value of $r$ (under the standard assumption of
parameterized complexity theory that $\mathrm{FPT} \neq W[2]$).
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2017-02-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05637</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05639</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Operator-Valued Bochner Theorem, Fourier Feature Maps for
  Operator-Valued Kernels, and Vector-Valued Learning</dc:title>
 <dc:creator>Minh, Ha Quang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper presents a framework for computing random operator-valued feature
maps for operator-valued positive definite kernels. This is a generalization of
the random Fourier features for scalar-valued kernels to the operator-valued
case. Our general setting is that of operator-valued kernels corresponding to
RKHS of functions with values in a Hilbert space. We show that in general, for
a given kernel, there are potentially infinitely many random feature maps,
which can be bounded or unbounded. Most importantly, given a kernel, we present
a general, closed form formula for computing a corresponding probability
measure, which is required for the construction of the Fourier features, and
which, unlike the scalar case, is not uniquely and automatically determined by
the kernel. We also show that, under appropriate conditions, random bounded
feature maps can always be computed. Furthermore, we show the uniform
convergence, under the Hilbert-Schmidt norm, of the resulting approximate
kernel to the exact kernel on any compact subset of Euclidean space. Our
convergence requires differentiable kernels, an improvement over the
twice-differentiability requirement in previous work in the scalar setting. We
then show how operator-valued feature maps and their approximations can be
employed in a general vector-valued learning framework. The mathematical
formulation is illustrated by numerical examples on matrix-valued kernels.
</dc:description>
 <dc:description>Comment: 31 pages</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05648</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing with Dynamical Systems Based on Insulator-Metal-Transition
  Oscillators</dc:title>
 <dc:creator>Parihar, Abhinav</dc:creator>
 <dc:creator>Shukla, Nikhil</dc:creator>
 <dc:creator>Jerry, Matthew</dc:creator>
 <dc:creator>Datta, Suman</dc:creator>
 <dc:creator>Raychowdhury, Arijit</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Condensed Matter - Mesoscale and Nanoscale Physics</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  In this paper we review recent work on novel computing paradigms using
coupled oscillatory dynamical systems. We explore systems of relaxation
oscillators based on linear state transitioning devices, which switch between
two discrete states with hysteresis. By harnessing the dynamics of complex,
connected systems we embrace the philosophy of &quot;let physics do the computing&quot;
and demonstrate how complex phase and frequency dynamics of such systems can be
controlled, programmed and observed to solve computationally hard problems.
Although our discussion in this paper is limited to Insulator-to-Metallic (IMT)
state transition devices, the general philosophy of such computing paradigms
can be translated to other mediums including optical systems. We present the
necessary mathematical treatments necessary to understand the time evolution of
these systems and demonstrate through recent experimental results the potential
of such computational primitives.
</dc:description>
 <dc:description>Comment: Submitted to Journal of Nanophotonics for review</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05654</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>POLYPATH: Supporting Multiple Tradeoffs for Interaction Latency</dc:title>
 <dc:creator>Yun, Min Hong</dc:creator>
 <dc:creator>He, Songtao</dc:creator>
 <dc:creator>Zhong, Lin</dc:creator>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  Modern mobile systems use a single input-to-display path to serve all
applications. In meeting the visual goals of all applications, the path has a
latency inadequate for many important interactions. To accommodate the
different latency requirements and visual constraints by different
interactions, we present POLYPATH, a system design in which application
developers (and users) can choose from multiple path designs for their
application at any time. Because a POLYPATH system asks for two or more path
designs, we present a novel fast path design, called Presto. Presto reduces
latency by judiciously allowing frame drops and tearing.
  We report an Android 5-based prototype of POLYPATH with two path designs:
Android legacy and Presto. Using this prototype, we quantify the effectiveness,
overhead, and user experience of POLYPATH, especially Presto, through both
objective measurements and subjective user assessment. We show that Presto
reduces the latency of legacy touchscreen drawing applications by almost half;
and more importantly, this reduction is orthogonal to that of other popular
approaches and is achieved without any user-noticeable negative visual effect.
When combined with touch prediction, Presto is able to reduce the touch latency
below 10 ms, a remarkable achievement without any hardware support.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05660</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coded Caching and Content Delivery with Heterogeneous Distortion
  Requirements</dc:title>
 <dc:creator>Yang, Qianqian</dc:creator>
 <dc:creator>G&#xfc;nd&#xfc;z, Deniz</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Cache-aided coded content delivery is studied for devices with diverse
quality-of-service (QoS) requirements. The network consists of a server, which
holds a database of independent contents, and users equipped with local caches
of different capacities. User caches are filled by the server during a low
traffic period without the knowledge of particular user demands. It is assumed
that each user in the system has a distinct QoS requirement, which may be due
to the viewing preference of the user, or the display capability of the device.
Each user requests a single file from the database to be served at this fixed
QoS level, and all the requests are satisfied simultaneously by the server over
a shared error-free link. Each file is modeled as a sequence of independently
and identically distributed Gaussian samples, and the QoS is measured in terms
of the average squared error distortion between the original sequence and the
reconstruction. Our goal in this work is to characterize the minimum delivery
rate the server needs to transmit over the shared link to satisfy all possible
demand combinations, both in the centralized and decentralized settings.
</dc:description>
 <dc:description>Comment: Submitted for publication. This paper was presented in part at the
  IEEE International Symposium on Information Theory, Barcelona, Spain, Jul.
  2016</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05661</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Curious Case of the PDF Converter that Likes Mozart: Dissecting and
  Mitigating the Privacy Risk of Personal Cloud Apps</dc:title>
 <dc:creator>Harkous, Hamza</dc:creator>
 <dc:creator>Rahman, Rameez</dc:creator>
 <dc:creator>Karlas, Bojan</dc:creator>
 <dc:creator>Aberer, Karl</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Third party apps that work on top of personal cloud services such as Google
Drive and Dropbox, require access to the user's data in order to provide some
functionality. Through detailed analysis of a hundred popular Google Drive apps
from Google's Chrome store, we discover that the existing permission model is
quite often misused: around two thirds of analyzed apps are over-privileged,
i.e., they access more data than is needed for them to function. In this work,
we analyze three different permission models that aim to discourage users from
installing over-privileged apps. In experiments with 210 real users, we
discover that the most successful permission model is our novel ensemble method
that we call Far-reaching Insights. Far-reaching Insights inform the users
about the data-driven insights that apps can make about them (e.g., their
topics of interest, collaboration and activity patterns etc.) Thus, they seek
to bridge the gap between what third parties can actually know about users and
users perception of their privacy leakage. The efficacy of Far-reaching
Insights in bridging this gap is demonstrated by our results, as Far-reaching
Insights prove to be, on average, twice as effective as the current model in
discouraging users from installing over-privileged apps. In an effort for
promoting general privacy awareness, we deploy a publicly available privacy
oriented app store that uses Far-reaching Insights. Based on the knowledge
extracted from data of the store's users (over 115 gigabytes of Google Drive
data from 1440 users with 662 installed apps), we also delineate the ecosystem
for third-party cloud apps from the standpoint of developers and cloud
providers. Finally, we present several general recommendations that can guide
other future works in the area of privacy for the cloud.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05661</dc:identifier>
 <dc:identifier>Proceedings on Privacy Enhancing Technologies. Volume 2016, Issue
  4, Pages 123-143, ISSN (Online) 2299-0984</dc:identifier>
 <dc:identifier>doi:10.1515/popets-2016-0032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05664</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A family of linear codes with three weights</dc:title>
 <dc:creator>Yan, Yang</dc:creator>
 <dc:creator>Li, Fei</dc:creator>
 <dc:creator>Wang, Qiuyan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B05, 11T71</dc:subject>
 <dc:description>  Recently, linear codes constructed by defining sets have attracted a lot of
study, and many optimal linear codes with a few weights have been produced. The
objective of this paper is to present a class of binary linear codes with three
weights.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05668</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Assessing the Use of Social Media in Massive Open Online Courses</dc:title>
 <dc:creator>Jiang, Suhang</dc:creator>
 <dc:creator>Kotzias, Dimitrios</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The study explores whether the use of Twitter in Massive Open Online Courses
(MOOCs) promotes the interaction among learners. The social network analysis
shows that instructors still play a very central role in the social media
communication and the communication network between students shrinking over
time. The mere use of social media fails to promote learner-learner
interaction. More research is needed for understanding learner motivation and
how instructional design can help increase their engagement and participation.
</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05668</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05671</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dominating sets and ego-centered decompositions in social networks</dc:title>
 <dc:creator>Boudourides, Moses A.</dc:creator>
 <dc:creator>Lenis, Sergios T.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Our aim here is to address the problem of decomposing a whole network into a
minimal number of ego-centered subnetworks. For this purpose, the network egos
are picked out as the members of a minimum dominating set of the network.
However, to find such an efficient dominating ego-centered construction, we
need to be able to detect all the minimum dominating sets and to compare all
the corresponding dominating ego-centered decompositions of the network. To
find all the minimum dominating sets of the network, we are developing a
computational heuristic, which is based on the partition of the set of nodes of
a graph into three subsets, the always dominant vertices, the possible dominant
vertices and the never dominant vertices, when the domination number of the
network is known. To compare the ensuing dominating ego-centered decompositions
of the network, we are introducing a number of structural measures that count
the number of nodes and links inside and across the ego-centered subnetworks.
Furthermore, we are applying the techniques of graph domination and
ego=centered decomposition for six empirical social networks.
</dc:description>
 <dc:description>Comment: 17 pages, 7 figures</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05671</dc:identifier>
 <dc:identifier>Eur. Phys. J. Special Topics 225, 1293-1310 (2016)</dc:identifier>
 <dc:identifier>doi:10.1140/epjst/e2016-02673-0</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05675</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>lpopt: A Rule Optimization Tool for Answer Set Programming</dc:title>
 <dc:creator>Bichler, Manuel</dc:creator>
 <dc:creator>Morak, Michael</dc:creator>
 <dc:creator>Woltran, Stefan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  State-of-the-art answer set programming (ASP) solvers rely on a program
called a grounder to convert non-ground programs containing variables into
variable-free, propositional programs. The size of this grounding depends
heavily on the size of the non-ground rules, and thus, reducing the size of
such rules is a promising approach to improve solving performance. To this end,
in this paper we announce lpopt, a tool that decomposes large logic programming
rules into smaller rules that are easier to handle for current solvers. The
tool is specifically tailored to handle the standard syntax of the ASP language
(ASP-Core) and makes it easier for users to write efficient and intuitive ASP
programs, which would otherwise often require significant hand-tuning by expert
ASP engineers. It is based on an idea proposed by Morak and Woltran (2012) that
we extend significantly in order to handle the full ASP syntax, including
complex constructs like aggregates, weak constraints, and arithmetic
expressions. We present the algorithm, the theoretical foundations on how to
treat these constructs, as well as an experimental evaluation showing the
viability of our approach.
</dc:description>
 <dc:description>Comment: Pre-proceedings paper presented at the 26th International Symposium
  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,
  Scotland UK, 6-8 September 2016 (arXiv:1608.02534), 14 pages, LaTeX, 2
  figures</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05676</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Shape Abstraction for Analysis of Free-List Memory
  Allocators</dc:title>
 <dc:creator>Fang, Bin</dc:creator>
 <dc:creator>Sighireanu, Mihaela</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We propose a hierarchical abstract domain for the analysis of free-list
memory allocators that tracks shape and numerical properties about both the
heap and the free lists. Our domain is based on Separation Logic extended with
predicates that capture the pointer arithmetics constraints for the heap-list
and the shape of the free-list. These predicates are combined using a
hierarchical composition operator to specify the overlapping of the heap-list
by the free-list. In addition to expressiveness, this operator leads to a
compositional and compact representation of abstract values and simplifies the
implementation of the abstract domain. The shape constraints are combined with
numerical constraints over integer arrays to track properties about the
allocation policies (best-fit, first-fit, etc). Such properties are out of the
scope of the existing analyzers. We implemented this domain and we show its
effectiveness on several implementations of free-list allocators.
</dc:description>
 <dc:description>Comment: Pre-proceedings paper presented at the 26th International Symposium
  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,
  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05676</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05678</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting Reuse in Main Memory Database Systems</dc:title>
 <dc:creator>Dursun, Kayhan</dc:creator>
 <dc:creator>Binnig, Carsten</dc:creator>
 <dc:creator>Cetintemel, Ugur</dc:creator>
 <dc:creator>Kraska, Tim</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Reusing intermediates in databases to speed-up analytical query processing
has been studied in the past. Existing solutions typically require intermediate
results of individual operators to be materialized into temporary tables to be
considered for reuse in subsequent queries. However, these approaches are
fundamentally ill-suited for use in modern main memory databases. The reason is
that modern main memory DBMSs are typically limited by the bandwidth of the
memory bus, thus query execution is heavily optimized to keep tuples in the CPU
caches and registers. To that end, adding additional materialization operations
into a query plan not only add additional traffic to the memory bus but more
importantly prevent the important cache- and register-locality opportunities
resulting in high performance penalties.
  In this paper we study a novel reuse model for intermediates, which caches
internal physical data structures materialized during query processing (due to
pipeline breakers) and externalizes them so that they become reusable for
upcoming operations. We focus on hash tables, the most commonly used internal
data structure in main memory databases to perform join and aggregation
operations. As queries arrive, our reuse-aware optimizer reasons about the
reuse opportunities for hash tables, employing cost models that take into
account hash table statistics together with the CPU and data movement costs
within the cache hierarchy. Experimental results, based on our HashStash
prototype demonstrate performance gains of $2\times$ for typical analytical
workloads with no additional overhead for materializing intermediates.
</dc:description>
 <dc:description>Comment: 13 Pages, 11 Figures</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05684</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Vanishing Points using Global Image Context in a Non-Manhattan
  World</dc:title>
 <dc:creator>Zhai, Menghua</dc:creator>
 <dc:creator>Workman, Scott</dc:creator>
 <dc:creator>Jacobs, Nathan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel method for detecting horizontal vanishing points and the
zenith vanishing point in man-made environments. The dominant trend in existing
methods is to first find candidate vanishing points, then remove outliers by
enforcing mutual orthogonality. Our method reverses this process: we propose a
set of horizon line candidates and score each based on the vanishing points it
contains. A key element of our approach is the use of global image context,
extracted with a deep convolutional network, to constrain the set of candidates
under consideration. Our method does not make a Manhattan-world assumption and
can operate effectively on scenes with only a single horizontal vanishing
point. We evaluate our approach on three benchmark datasets and achieve
state-of-the-art performance on each. In addition, our approach is
significantly faster than the previous best method.
</dc:description>
 <dc:description>Comment: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
  2016</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05694</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The languages of actions, formal grammars and qualitive modeling of
  companies</dc:title>
 <dc:creator>Kovchegov, Vladislav B</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper we discuss methods of using the language of actions, formal
languages, and grammars for qualitative conceptual linguistic modeling of
companies as technological and human institutions. The main problem following
the discussion is the problem to find and describe a language structure for
external and internal flow of information of companies. We anticipate that the
language structure of external and internal base flows determine the structure
of companies. In the structure modeling of an abstract industrial company an
internal base flow of information is constructed as certain flow of words
composed on the theoretical parts-processes-actions language. The language of
procedures is found for an external base flow of information for an insurance
company. The formal stochastic grammar for the language of procedures is found
by statistical methods and is used in understanding the tendencies of the
health care industry. We present the model of human communications as a random
walk on the semantic tree
</dc:description>
 <dc:description>Comment: 40 pages</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05698</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automata Theory Approach to Predicate Intuitionistic Logic</dc:title>
 <dc:creator>Zielenkiewicz, Maciej</dc:creator>
 <dc:creator>Schubert, Aleksy</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.4.3</dc:subject>
 <dc:description>  Predicate intuitionistic logic is a well established fragment of dependent
types. According to the Curry-Howard isomorphism proof construction in the
logic corresponds well to synthesis of a program the type of which is a given
formula. We present a model of automata that can handle proof construction in
full intuitionistic first-order logic. The automata are constructed in such a
way that any successful run corresponds directly to a normal proof in the
logic. This makes it possible to discuss formal languages of proofs or
programs, the closure properties of the automata and their connections with the
traditional logical connectives.
</dc:description>
 <dc:description>Comment: Pre-proceedings paper presented at the 26th International Symposium
  on Logic-Based Program Synthesis and Transformation (LOPSTR 2016), Edinburgh,
  Scotland UK, 6-8 September 2016 (arXiv:1608.02534)</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05698</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05699</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Memory-efficient and Ultra-fast Network Lookup and Forwarding using
  Othello Hashing</dc:title>
 <dc:creator>Yu, Ye</dc:creator>
 <dc:creator>Belazzougui, Djamal</dc:creator>
 <dc:creator>Qian, Chen</dc:creator>
 <dc:creator>Zhang, Qin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Network algorithms always prefer low memory cost and fast packet processing
speed. Forwarding information base (FIB), as a typical network processing
component, requires a scalable and memory-efficient algorithm to support fast
lookups. In this paper, we present a new network algorithm, Othello Hashing,
and its application of a FIB design called Concise, which uses very little
memory to support ultra-fast lookups of network names. Othello Hashing and
Concise make use of minimal perfect hashing and relies on the programmable
network framework to support dynamic updates. Our conceptual contribution of
Concise is to optimize the memory efficiency and query speed in the data plane
and move the relatively complex construction and update components to the
resource-rich control plane. We implemented Concise on three platforms.
Experimental results show that Concise uses significantly smaller memory to
achieve much faster query speed compared to existing solutions of network name
lookups.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05699</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05701</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pilot Testing an Artificial Intelligence Algorithm That Selects Homeless
  Youth Peer Leaders Who Promote HIV Testing</dc:title>
 <dc:creator>Rice, Eric</dc:creator>
 <dc:creator>Petering, Robin</dc:creator>
 <dc:creator>Craddock, Jaih</dc:creator>
 <dc:creator>Yoshioka-Maxwell, Amanda</dc:creator>
 <dc:creator>Yadav, Amulya</dc:creator>
 <dc:creator>Tambe, Milind</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Objective. To pilot test an artificial intelligence (AI) algorithm that
selects peer change agents (PCA) to disseminate HIV testing messaging in a
population of homeless youth. Methods. We recruited and assessed 62 youth at
baseline, 1 month (n = 48), and 3 months (n = 38). A Facebook app collected
preliminary social network data. Eleven PCAs selected by AI attended a 1-day
training and 7 weekly booster sessions. Mixed-effects models with random
effects were used to assess change over time. Results. Significant change over
time was observed in past 6-month HIV testing (57.9%, 82.4%, 76.3%; p &lt; .05)
but not condom use (63.9%, 65.7%, 65.8%). Most youth reported speaking to a PCA
about HIV prevention (72.0% at 1 month, 61.5% at 3 months). Conclusions. AI is
a promising avenue for implementing PCA models for homeless youth. Increasing
rates of regular HIV testing is critical to HIV prevention and linking homeless
youth to treatment.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05722</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supermodularity in Unweighted Graph Optimization I: Branchings and
  Matchings</dc:title>
 <dc:creator>B&#xe9;rczi, Krist&#xf3;f</dc:creator>
 <dc:creator>Frank, Andr&#xe1;s</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C70, 05C85</dc:subject>
 <dc:description>  The main result of the paper is motivated by the following two, apparently
unrelated graph optimization problems: (A) as an extension of Edmonds' disjoint
branchings theorem, characterize digraphs comprising $k$ disjoint branchings
$B_i$ each having a specified number $\mu _i$ of arcs, (B) as an extension of
Ryser's maximum term rank formula, determine the largest possible matching
number of simple bipartite graphs complying with degree-constraints. The
solutions to these problems and to their generalizations will be obtained from
a new min-max theorem on covering a supermodular function by a simple
degree-constrained bipartite graph. A specific feature of the result is that
its minimum cost extension is already NP-complete. Therefore classic polyhedral
tools themselves definitely cannot be sufficient for solving the problem, even
though they make some good service in our approach.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2017-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05722</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05729</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supermodularity in Unweighted Graph Opitimization III: Highly-connected
  Digraphs</dc:title>
 <dc:creator>B&#xe9;rczi, Krist&#xf3;f</dc:creator>
 <dc:creator>Frank, Andr&#xe1;s</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C40, 05C70, 05C85</dc:subject>
 <dc:description>  By generalizing a recent result of Hong, Liu, and Lai on characterizing the
degree-sequences of simple strongly connected directed graphs, a
characterization is provided for degree-sequences of simple $k$-node-connected
digraphs. More generally, we solve the directed node-connectivity augmentation
problem when the augmented digraph is degree-specified and simple. As for
edge-connectivity augmentation, we solve the special case when the
edge-connectivity is to be increased by one and the augmenting digraph must be
simple.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2017-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05730</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supermodularity in Unweighted Graph Optimization II: Matroidal Term Rank
  Augmentation</dc:title>
 <dc:creator>B&#xe9;rczi, Krist&#xf3;f</dc:creator>
 <dc:creator>Frank, Andr&#xe1;s</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05B35, 05C70, 05C85</dc:subject>
 <dc:description>  Ryser's max term rank formula with graph theoretic terminology is equivalent
to a characterization of degree sequences of simple bipartite graphs with
matching number at least $\ell$. In a previous paper by the authors, a
generalization was developed for the case when the degrees are constrained by
upper and lower bounds. Here two other extensions of Ryser's theorem are
discussed. The first one is a matroidal model, while the second one settles the
augmentation version. In fact, the two directions shall be integrated into one
single framework.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2017-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05742</identifier>
 <datestamp>2017-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extending the OpenAI Gym for robotics: a toolkit for reinforcement
  learning using ROS and Gazebo</dc:title>
 <dc:creator>Zamora, Iker</dc:creator>
 <dc:creator>Lopez, Nestor Gonzalez</dc:creator>
 <dc:creator>Vilches, Victor Mayoral</dc:creator>
 <dc:creator>Cordero, Alejandro Hernandez</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents an extension of the OpenAI Gym for robotics using the
Robot Operating System (ROS) and the Gazebo simulator. The content discusses
the software architecture proposed and the results obtained by using two
Reinforcement Learning techniques: Q-Learning and Sarsa. Ultimately, the output
of this work presents a benchmarking system for robotics that allows different
techniques and algorithms to be compared using the same virtual conditions.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2017-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05743</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Scalable Framework for Wireless Distributed Computing</dc:title>
 <dc:creator>Li, Songze</dc:creator>
 <dc:creator>Yu, Qian</dc:creator>
 <dc:creator>Maddah-Ali, Mohammad Ali</dc:creator>
 <dc:creator>Avestimehr, A. Salman</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We consider a wireless distributed computing system, in which multiple mobile
users, connected wirelessly through an access point, collaborate to perform a
computation task. In particular, users communicate with each other via the
access point to exchange their locally computed intermediate computation
results, which is known as data shuffling. We propose a scalable framework for
this system, in which the required communication bandwidth for data shuffling
does not increase with the number of users in the network. The key idea is to
utilize a particular repetitive pattern of placing the dataset (thus a
particular repetitive pattern of intermediate computations), in order to
provide coding opportunities at both the users and the access point, which
reduce the required uplink communication bandwidth from users to access point
and the downlink communication bandwidth from access point to users by factors
that grow linearly with the number of users. We also demonstrate that the
proposed dataset placement and coded shuffling schemes are optimal (i.e.,
achieve the minimum required shuffling load) for both a centralized setting and
a decentralized setting, by developing tight information-theoretic lower
bounds.
</dc:description>
 <dc:description>Comment: To appear in IEEE/ACM Transactions on Networking</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2017-05-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05743</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05745</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RETAIN: An Interpretable Predictive Model for Healthcare using Reverse
  Time Attention Mechanism</dc:title>
 <dc:creator>Choi, Edward</dc:creator>
 <dc:creator>Bahadori, Mohammad Taha</dc:creator>
 <dc:creator>Kulas, Joshua A.</dc:creator>
 <dc:creator>Schuetz, Andy</dc:creator>
 <dc:creator>Stewart, Walter F.</dc:creator>
 <dc:creator>Sun, Jimeng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Accuracy and interpretability are two dominant features of successful
predictive models. Typically, a choice must be made in favor of complex black
box models such as recurrent neural networks (RNN) for accuracy versus less
accurate but more interpretable traditional models such as logistic regression.
This tradeoff poses challenges in medicine where both accuracy and
interpretability are important. We addressed this challenge by developing the
REverse Time AttentIoN model (RETAIN) for application to Electronic Health
Records (EHR) data. RETAIN achieves high accuracy while remaining clinically
interpretable and is based on a two-level neural attention model that detects
influential past visits and significant clinical variables within those visits
(e.g. key diagnoses). RETAIN mimics physician practice by attending the EHR
data in a reverse time order so that recent clinical visits are likely to
receive higher attention. RETAIN was tested on a large health system EHR
dataset with 14 million visits completed by 263K patients over an 8 year period
and demonstrated predictive accuracy and computational scalability comparable
to state-of-the-art methods such as RNN, and ease of interpretability
comparable to traditional models.
</dc:description>
 <dc:description>Comment: Accepted at Neural Information Processing Systems (NIPS) 2016</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05745</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05749</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving a Mixture of Many Random Linear Equations by Tensor
  Decomposition and Alternating Minimization</dc:title>
 <dc:creator>Yi, Xinyang</dc:creator>
 <dc:creator>Caramanis, Constantine</dc:creator>
 <dc:creator>Sanghavi, Sujay</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of solving mixed random linear equations with $k$
components. This is the noiseless setting of mixed linear regression. The goal
is to estimate multiple linear models from mixed samples in the case where the
labels (which sample corresponds to which model) are not observed. We give a
tractable algorithm for the mixed linear equation problem, and show that under
some technical conditions, our algorithm is guaranteed to solve the problem
exactly with sample complexity linear in the dimension, and polynomial in $k$,
the number of components. Previous approaches have required either exponential
dependence on $k$, or super-linear dependence on the dimension. The proposed
algorithm is a combination of tensor decomposition and alternating
minimization. Our analysis involves proving that the initialization provided by
the tensor method allows alternating minimization, which is equivalent to EM in
our setting, to converge to the global optimum at a linear rate.
</dc:description>
 <dc:description>Comment: 39 pages, 2 figures</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05749</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05754</identifier>
 <datestamp>2017-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast estimation of approximate matrix ranks using spectral densities</dc:title>
 <dc:creator>Ubaru, Shashanka</dc:creator>
 <dc:creator>Saad, Yousef</dc:creator>
 <dc:creator>Seghouane, Abd-Krim</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  In many machine learning and data related applications, it is required to
have the knowledge of approximate ranks of large data matrices at hand. In this
paper, we present two computationally inexpensive techniques to estimate the
approximate ranks of such large matrices. These techniques exploit approximate
spectral densities, popular in physics, which are probability density
distributions that measure the likelihood of finding eigenvalues of the matrix
at a given point on the real line. Integrating the spectral density over an
interval gives the eigenvalue count of the matrix in that interval. Therefore
the rank can be approximated by integrating the spectral density over a
carefully selected interval. Two different approaches are discussed to estimate
the approximate rank, one based on Chebyshev polynomials and the other based on
the Lanczos algorithm. In order to obtain the appropriate interval, it is
necessary to locate a gap between the eigenvalues that correspond to noise and
the relevant eigenvalues that contribute to the matrix rank. A method for
locating this gap and selecting the interval of integration is proposed based
on the plot of the spectral density. Numerical experiments illustrate the
performance of these techniques on matrices from typical applications.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05754</dc:identifier>
 <dc:identifier>Neural Computation, Vol. 29, No. 5, pp. 1317-1351 (May 2017)</dc:identifier>
 <dc:identifier>doi:10.1162/NECO_a_00951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05763</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inference in Probabilistic Logic Programs using Lifted Explanations</dc:title>
 <dc:creator>Nampally, Arun</dc:creator>
 <dc:creator>Ramakrishnan, C. R.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In this paper, we consider the problem of lifted inference in the context of
Prism-like probabilistic logic programming languages. Traditional inference in
such languages involves the construction of an explanation graph for the query
and computing probabilities over this graph. When evaluating queries over
probabilistic logic programs with a large number of instances of random
variables, traditional methods treat each instance separately. For many
programs and queries, we observe that explanations can be summarized into
substantially more compact structures, which we call lifted explanation graphs.
In this paper, we define lifted explanation graphs and operations over them. In
contrast to existing lifted inference techniques, our method for constructing
lifted explanations naturally generalizes existing methods for constructing
explanation graphs. To compute probability of query answers, we solve
recurrences generated from the lifted graphs. We show examples where the use of
our technique reduces the asymptotic complexity of inference.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05763</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05766</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Nonconvex Decentralized Gradient Descent</dc:title>
 <dc:creator>Zeng, Jinshan</dc:creator>
 <dc:creator>Yin, Wotao</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Consensus optimization has received considerable attention in recent years. A
number of decentralized algorithms have been proposed for {convex} consensus
optimization. However, to the behaviors or consensus \emph{nonconvex}
optimization, our understanding is more limited.
  When we lose convexity, we cannot hope our algorithms always return global
solutions though they sometimes still do sometimes. Somewhat surprisingly, the
decentralized consensus algorithms, DGD and Prox-DGD, retain most other
properties that are known in the convex setting. In particular, when
diminishing (or constant) step sizes are used, we can prove convergence to a
(or a neighborhood of) consensus stationary solution under some regular
assumptions. It is worth noting that Prox-DGD can handle nonconvex nonsmooth
functions if their proximal operators can be computed. Such functions include
SCAD and $\ell_q$ quasi-norms, $q\in[0,1)$. Similarly, Prox-DGD can take the
constraint to a nonconvex set with an easy projection.
  To establish these properties, we have to introduce a completely different
line of analysis, as well as modify existing proofs that were used the convex
setting.
</dc:description>
 <dc:description>Comment: This version is an extended one of the previous version. In the
  current version, we study the conververgence of DGD and Prox-DGD using both
  constant and diminishing step sizes</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05768</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Optimal Fronthaul Compression and Decoding Strategies for Uplink
  Cloud Radio Access Networks</dc:title>
 <dc:creator>Zhou, Yuhan</dc:creator>
 <dc:creator>Xu, Yinfei</dc:creator>
 <dc:creator>Yu, Wei</dc:creator>
 <dc:creator>Chen, Jun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates the compress-and-forward scheme for an uplink cloud
radio access network (C-RAN) model, where multi-antenna base-stations (BSs) are
connected to a cloud-computing based central processor (CP) via
capacity-limited fronthaul links. The BSs compress the received signals with
Wyner-Ziv coding and send the representation bits to the CP; the CP performs
the decoding of all the users' messages. Under this setup, this paper makes
progress toward the optimal structure of the fronthaul compression and CP
decoding strategies for the compress-and-forward scheme in C-RAN. On the CP
decoding strategy design, this paper shows that under a sum fronthaul capacity
constraint, a generalized successive decoding strategy of the quantization and
user message codewords that allows arbitrary interleaved order at the CP
achieves the same rate region as the optimal joint decoding. Further, it is
shown that a practical strategy of successively decoding the quantization
codewords first, then the user messages, achieves the same maximum sum rate as
joint decoding under individual fronthaul constraints. On the joint
optimization of user transmission and BS quantization strategies, this paper
shows that if the input distributions are assumed to be Gaussian, then under
joint decoding, the optimal quantization scheme for maximizing the achievable
rate region is Gaussian. Moreover, Gaussian input and Gaussian quantization
with joint decoding achieve to within a constant gap of the capacity region of
the Gaussian multiple-input multiple-output (MIMO) uplink C-RAN model. Finally,
this paper addresses the computational aspect of optimizing uplink MIMO C-RAN
by showing that under fixed Gaussian input, the sum rate maximization problem
over the Gaussian quantization noise covariance matrices can be formulated as
convex optimization problems, thereby facilitating its efficient solution.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Transactions on Information Theory,
  2016</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:date>2016-10-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05768</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2016.2617862</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05772</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Data-Driven Approach for Mapping Multivariate Data to Color</dc:title>
 <dc:creator>Cheng, Shenghui</dc:creator>
 <dc:creator>Xu, Wei</dc:creator>
 <dc:creator>Zhong, Wen</dc:creator>
 <dc:creator>Mueller, Klaus</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  A wide variety of color schemes have been devised for mapping scalar data to
color. Some use the data value to index a color scale. Others assign colors to
different, usually blended disjoint materials, to handle areas where materials
overlap. A number of methods can map low-dimensional data to color, however,
these methods do not scale to higher dimensional data. Likewise, schemes that
take a more artistic approach through color mixing and the like also face
limits when it comes to the number of variables they can encode. We address the
challenge of mapping multivariate data to color and avoid these limitations at
the same time. It is a data driven method, which first gauges the similarity of
the attributes and then arranges them according to the periphery of a convex 2D
color space, such as HSL. The color of a multivariate data sample is then
obtained via generalized barycentric coordinate (GBC) interpolation.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05772</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05773</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extending Scatterplots to Scalar Fields</dc:title>
 <dc:creator>Cheng, Shenghui</dc:creator>
 <dc:creator>Cui, Pengcheng</dc:creator>
 <dc:creator>Mueller, Klaus</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Embedding high-dimensional data into a 2D canvas is a popular strategy for
their visualization.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05773</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05777</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topic Sensitive Neural Headline Generation</dc:title>
 <dc:creator>Xu, Lei</dc:creator>
 <dc:creator>Wang, Ziyun</dc:creator>
 <dc:creator>Ayana</dc:creator>
 <dc:creator>Liu, Zhiyuan</dc:creator>
 <dc:creator>Sun, Maosong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Neural models have recently been used in text summarization including
headline generation. The model can be trained using a set of document-headline
pairs. However, the model does not explicitly consider topical similarities and
differences of documents. We suggest to categorizing documents into various
topics so that documents within the same topic are similar in content and share
similar summarization patterns. Taking advantage of topic information of
documents, we propose topic sensitive neural headline generation model. Our
model can generate more accurate summaries guided by document topics. We test
our model on LCSTS dataset, and experiments show that our method outperforms
other baselines on each topic and achieves the state-of-art performance.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05777</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05783</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Orthogonal Multiple Access (NOMA) in Cellular Uplink and Downlink:
  Challenges and Enabling Techniques</dc:title>
 <dc:creator>Tabassum, Hina</dc:creator>
 <dc:creator>Ali, Md Shipon</dc:creator>
 <dc:creator>Hossain, Ekram</dc:creator>
 <dc:creator>Hossain, Md. Jahangir</dc:creator>
 <dc:creator>Kim, Dong In</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  By combining the concepts of superposition coding at the transmitter(s) and
successive interference cancellation (SIC) at the receiver(s), non-orthogonal
multiple access (NOMA) has recently emerged as a promising multiple access
technique for 5G wireless technology. In this article, we first discuss the
fundamentals of uplink and downlink NOMA transmissions and outline their key
distinctions (in terms of implementation complexity, detection and decoding at
the SIC receiver(s), incurred intra-cell and inter-cell interferences). Later,
for both downlink and uplink NOMA, we theoretically derive the NOMA dominant
condition for each individual user in a two-user NOMA cluster. NOMA dominant
condition refers to the condition under which the spectral efficiency gains of
NOMA are guaranteed compared to conventional orthogonal multiple access (OMA).
The derived conditions provide direct insights on selecting appropriate users
in two-user NOMA clusters. The conditions are distinct for uplink and downlink
as well as for each individual user. Numerical results show the significance of
the derived conditions for the user selection in uplink/downlink NOMA clusters
and provide a comparison to the random user selection. A brief overview of the
recent research investigations is then provided to highlight the existing
research gaps. Finally, we discuss the potential applications and key
challenges of NOMA transmissions.
</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05786</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design of a Trajectory Tracking Controller for a Nanoquadcopter</dc:title>
 <dc:creator>Luis, Carlos</dc:creator>
 <dc:creator>Ny, J&#xe9;r&#xf4;me Le</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>93-06</dc:subject>
 <dc:description>  The primary purpose of this study is to investigate the system modeling of a
nanoquadcopter as well as designing position and trajectory control algorithms,
with the ultimate goal of testing the system both in simulation and on a real
platform.
  The open source nanoquadcopter platform named Crazyflie 2.0 was chosen for
the project. The first phase consisted in the development of a mathematical
model that describes the dynamics of the quadcopter. Secondly, a simulation
environment was created to design two different control architectures: cascaded
PID position tracker and LQT trajectory tracker. Finally, the implementation
phase consisted in testing the controllers on the chosen platform and comparing
their performance in trajectory tracking.
  Our simulations agreed with the experimental results, and further refinement
of the model is proposed as future work through closed-loop model
identification techniques. The results show that the LQT controller performed
better at tracking trajectories, with RMS errors in position up to four times
smaller than those obtained with the PID. LQT control effort was greater, but
eliminated the high control peaks that induced motor saturation in the PID
controller. The LQT controller was also tested using an ultra-wide band two-way
ranging system, and comparisons with the more precise VICON system indicate
that the controller could track a trajectory in both cases despise the
difference in noise levels between the two systems.
</dc:description>
 <dc:description>Comment: Complete Technical Report</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05786</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05787</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Formal Verification in Imperative Multivalued Programming over
  Continuous Data Types</dc:title>
 <dc:creator>Lee, Gyesik</dc:creator>
 <dc:creator>M&#xfc;ller, Norbert</dc:creator>
 <dc:creator>Neumann, Eike</dc:creator>
 <dc:creator>Park, Sewon</dc:creator>
 <dc:creator>Preining, Norbert</dc:creator>
 <dc:creator>Ziegler, Martin</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>68Q60, 65Y99</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>G.1.0</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:description>  Inspired and guided by the iRRAM C++ library (M\&quot;uller 2001), we formally
specify a programming language for the paradigm of EXACT REAL COMPUTATION
(ERC): reliably operating on encapsulated CONTINUOUS data types such as (not
necessarily algebraic) real numbers -- imperatively and exactly (no rounding
errors) with primitives COMPUTABLE in the sense of Recursive Analysis including
a necessarily modified multivalued (=non-functional) semantics of tests. Three
simple numerical problems demonstrate the elegance and convenience of writing
programs handling REAL real numbers: integer rounding, solving systems of
linear equations, and continuous root finding. We establish Turing-COMPLETENESS
over the reals: a partial function f:R^d x Z -&gt; R is computable (in the sense
of Recursive Analysis) iff it can be expressed in ERC. For rigorously
specifying and arguing about such computations in Mathematical Logic, we then
propose a DECIDABLE first-order theory over two sorts, integers and real
numbers. We extend the rules of Hoare Logic to support the formal derivation of
correctness proofs in ERC; and we have them, including their real
quantification, verified in the Coq Proof Assistant.
</dc:description>
 <dc:description>Comment: First presented at CCA2016</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05793</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity of the Energy Harvesting Gaussian MAC</dc:title>
 <dc:creator>Inan, Huseyin A.</dc:creator>
 <dc:creator>Shaviv, Dor</dc:creator>
 <dc:creator>Ozgur, Ayfer</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider an energy harvesting multiple access channel (MAC) where the
transmitters are powered by an exogenous stochastic energy harvesting process
and equipped with finite batteries. We characterize the capacity region of this
channel as n-letter mutual information rate and develop inner and outer bounds
that differ by a constant gap. An interesting conclusion that emerges from our
results is that the sum-capacity approaches that of a standard AWGN MAC (with
only an average constraint on the transmitted power), as the number of users in
the MAC becomes large.
</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05794</identifier>
 <datestamp>2017-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerating finite-rate chemical kinetics with coprocessors: comparing
  vectorization methods on GPUs, MICs, and CPUs</dc:title>
 <dc:creator>Stone, Christopher P.</dc:creator>
 <dc:creator>Alferman, Andrew T.</dc:creator>
 <dc:creator>Niemeyer, Kyle E.</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:subject>80A32 (Primary) 80A30, 65L04, 65L06 (Secondary)</dc:subject>
 <dc:description>  Efficient ordinary differential equation solvers for chemical kinetics must
take into account the available thread and instruction-level parallelism of the
underlying hardware, especially on many-core coprocessors, as well as the
numerical efficiency. A stiff Rosenbrock and nonstiff Runge-Kutta solver are
implemented using the single instruction, multiple thread (SIMT) and single
instruction, multiple data (SIMD) paradigms with OpenCL. The performances of
these parallel implementations were measured with three chemical kinetic models
across several multicore and many-core platforms. Two runtime benchmarks were
conducted to clearly determine any performance advantage offered by either
method: evaluating the right-hand-side source terms in parallel, and
integrating a series of constant-pressure homogeneous reactors using the
Rosenbrock and Runge-Kutta solvers. The right-hand-side evaluations with SIMD
parallelism on the host multicore Xeon CPU and many-core Xeon Phi co-processor
performed approximately three times faster than the baseline multithreaded
code. The SIMT model on the host and Phi was 13-35% slower than the baseline
while the SIMT model on the GPU provided approximately the same performance as
the SIMD model on the Phi. The runtimes for both ODE solvers decreased 2.5-2.7x
with the SIMD implementations on the host CPU and 4.7-4.9x with the Xeon Phi
coprocessor compared to the baseline parallel code. The SIMT implementations on
the GPU ran 1.4-1.6 times faster than the baseline multithreaded CPU code;
however, this was significantly slower than the SIMD versions on the host CPU
or the Xeon Phi. The performance difference between the three platforms was
attributed to thread divergence caused by the adaptive step-sizes within the
ODE integrators. Analysis showed that the wider vector width of the GPU incurs
a higher level of divergence than the narrower Sandy Bridge or Xeon Phi.
</dc:description>
 <dc:description>Comment: 32 pages, 11 figures</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:date>2017-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05812</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Bayesian Classification based Approaches for Android Malware
  Detection</dc:title>
 <dc:creator>Yerima, Suleiman Y.</dc:creator>
 <dc:creator>Sezer, Sakir</dc:creator>
 <dc:creator>McWilliams, Gavin</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Mobile malware has been growing in scale and complexity spurred by the
unabated uptake of smartphones worldwide. Android is fast becoming the most
popular mobile platform resulting in sharp increase in malware targeting the
platform. Additionally, Android malware is evolving rapidly to evade detection
by traditional signature-based scanning. Despite current detection measures in
place, timely discovery of new malware is still a critical issue. This calls
for novel approaches to mitigate the growing threat of zero-day Android
malware. Hence, in this paper we develop and analyze proactive Machine Learning
approaches based on Bayesian classification aimed at uncovering unknown Android
malware via static analysis. The study, which is based on a large malware
sample set of majority of the existing families, demonstrates detection
capabilities with high accuracy. Empirical results and comparative analysis are
presented offering useful insight towards development of effective
static-analytic Bayesian classification based solutions for detecting unknown
Android malware.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1608.00848</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05812</dc:identifier>
 <dc:identifier>IET Information Security, Volume 8, Issue 1, January 2014, pp.
  25-36, Print ISSN 1751-8709, Online ISSN 1751-8717</dc:identifier>
 <dc:identifier>doi:10.1049/iet-ifs.2013.0095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05813</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>phi-LSTM: A Phrase-based Hierarchical LSTM Model for Image Captioning</dc:title>
 <dc:creator>Tan, Ying Hua</dc:creator>
 <dc:creator>Chan, Chee Seng</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A picture is worth a thousand words. Not until recently, however, we noticed
some success stories in understanding of visual scenes: a model that is able to
detect/name objects, describe their attributes, and recognize their
relationships/interactions. In this paper, we propose a phrase-based
hierarchical Long Short-Term Memory (phi-LSTM) model to generate image
description. The proposed model encodes sentence as a sequence of combination
of phrases and words, instead of a sequence of words alone as in those
conventional solutions. The two levels of this model are dedicated to i) learn
to generate image relevant noun phrases, and ii) produce appropriate image
description from the phrases and other words in the corpus. Adopting a
convolutional neural network to learn image features and the LSTM to learn the
word sequence in a sentence, the proposed model has shown better or competitive
results in comparison to the state-of-the-art models on Flickr8k and Flickr30k
datasets.
</dc:description>
 <dc:description>Comment: This paper introduces phrase-based image captioning. Accepted in
  ACCV2016 (extended version, 21 pages, 12 figures)</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05816</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Kernels for Separating a Graph into Components of Bounded Size</dc:title>
 <dc:creator>Xiao, Mingyu</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Graph separation and partitioning are fundamental problems that have been
extensively studied both in theory and practice. The \textsc{$p$-Size
Separator} problem, closely related to the \textsc{Balanced Separator} problem,
is to check whether we can delete at most $k$ vertices in a given graph $G$
such that each connected component of the remaining graph has at most $p$
vertices. This problem is NP-hard for each fixed integer $p\geq 1$ and it
becomes the famous \textsc{Vertex Cover} problem when $p=1$. It is known that
the problem with parameter $k$ is W[1]-hard for unfixed $p$. In this paper, we
prove a kernel of $O(pk)$ vertices for this problem, i.e., a linear vertex
kernel for each fixed $p \geq 1$. In fact, we first obtain an $O(p^2k)$ vertex
kernel by using a nontrivial extension of the expansion lemma. Then we further
reduce the kernel size to $O(pk)$ by using some `local adjustment' techniques.
Our proofs are based on extremal combinatorial arguments and the main result
can be regarded as a generalization of the Nemhauser and Trotter's theorem for
the \textsc{Vertex Cover} problem. These techniques are possible to be used to
improve kernel sizes for more problems, especially problems with kernelization
algorithms based on techniques similar to the expansion lemma or crown
decompositions.
</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05816</dc:identifier>
 <dc:identifier>Journal of Computer and System Sciences 88 (2017): 260-270</dc:identifier>
 <dc:identifier>doi:10.1016/j.jcss.2017.04.004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05829</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chance constraint based multi agent navigation under uncertainty</dc:title>
 <dc:creator>Gopalakrishnan, Bharath</dc:creator>
 <dc:creator>Singh, Arun Kumar</dc:creator>
 <dc:creator>Kaushik, Meha</dc:creator>
 <dc:creator>Krishna, K. Madhava</dc:creator>
 <dc:creator>Manocha, Dinesh</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present Probabilistic Reciprocal Velocity Obstacle or PRVO as a general
algorithm for navigating multiple robots under perception and motion
uncertainty. PRVO is defined as the space of velocities that ensures dynamic
collision avoidance between a pair of robots with a specified probability. Our
approach is based on defining chance constraints over the inequalities defined
by the deterministic Reciprocal Velocity Obstacle (RVO). The computational
complexity of the proposed probabilistic RVO is comparable to the deterministic
counterpart. This is achieved by a series of reformulations where we first
substitute the computationally intractable chance constraints with a family of
surrogate constraints and then adopt a time scaling based solution methodology
to efficiently characterize their solution space. Further, we also show that
the solution space of each member of the family of surrogate constraints can be
mapped in closed form to the probability with which the original chance
constraints are satisfied and thus consequently to probability of collision
avoidance. We validate our formulations through numerical simulations where we
highlight the importance of incorporating the effect of motion uncertainty and
the advantages of PRVO over existing formulations which handles the effect of
uncertainty by using conservative bounding volumes.
</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05829</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05830</identifier>
 <datestamp>2017-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DEBH: Detection and Elimination Black Holes in Mobile Ad Hoc Network</dc:title>
 <dc:creator>Dorri, Ali</dc:creator>
 <dc:creator>Vaseghi, Soroush</dc:creator>
 <dc:creator>Gharib, Omid</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Security in Mobile Ad hoc Network (MANET) is one of the key challenges due to
its special features e.g. hop-by-hop communications, dynamic topology, and open
network boundary that received tremendous attention by scholars. Traditional
security methods are not applicable in MANET due to its special properties. In
this paper, a novel approach called Detecting and Eliminating Black Holes
(DEBH) is proposed that uses a data control packet and an additional Black hole
Check (BCh) table for detecting and eliminating malicious nodes. Benefiting
from trustable nodes, the processing overhead of the security method decreases
by passing time. Ad hoc On-demand Distance Vector (AODV) routing protocol is
used as the routing protocol in our design. After finding the freshest path
using AODV, our design checks the safety of selected path. In case of detecting
any malicious node, it is isolated from the entire network by broadcasting a
packet that contains the ID of malicious nodes. Simulation results show that
DEBH increases network throughput and decreases packet overhead and delay in
comparison with other studied approaches. Moreover, DEBH is able to detect all
active malicious nodes which generates fault routing information.
</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:date>2017-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05838</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proving chaotic behaviour of CBC mode of operation</dc:title>
 <dc:creator>Abidi, Abdessalem</dc:creator>
 <dc:creator>Wang, Qianxue</dc:creator>
 <dc:creator>Bouallegue, Belgacem</dc:creator>
 <dc:creator>Machhout, Mohsen</dc:creator>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  The cipher block chaining (CBC) block cipher mode of operation was invented
by IBM (International Business Machine) in 1976. It presents a very popular way
of encrypting which is used in various applications. In this paper, we have
mathematically proven that, under some conditions, the CBC mode of operation
can admit a chaotic behaviour according to Devaney. Some cases will be properly
studied in order to put in evidence this idea.
</dc:description>
 <dc:description>Comment: International Journal of Bifurcation and Chaos, accepted paper. arXiv
  admin note: substantial text overlap with arXiv:1601.08139, arXiv:1605.02950</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05838</dc:identifier>
 <dc:identifier>doi:10.1142/S0218127416501133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05839</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computation Offloading Decisions for Reducing Completion Time</dc:title>
 <dc:creator>Melendez, Salvador</dc:creator>
 <dc:creator>McGarry, Michael P.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We analyze the conditions in which offloading computation reduces completion
time. We extend the existing literature by deriving an inequality (Eq. 4) that
relates computation offloading system parameters to the bits per instruction
ratio of a computational job. This ratio is the inverse of the arithmetic
intensity. We then discuss how this inequality can be used to determine the
computations that can benefit from offloading as well as the computation
offloading systems required to make offloading beneficial for particular
computations.
</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05839</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05842</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Back to Basics: Unsupervised Learning of Optical Flow via Brightness
  Constancy and Motion Smoothness</dc:title>
 <dc:creator>Yu, Jason J.</dc:creator>
 <dc:creator>Harley, Adam W.</dc:creator>
 <dc:creator>Derpanis, Konstantinos G.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, convolutional networks (convnets) have proven useful for predicting
optical flow. Much of this success is predicated on the availability of large
datasets that require expensive and involved data acquisition and laborious la-
beling. To bypass these challenges, we propose an unsuper- vised approach
(i.e., without leveraging groundtruth flow) to train a convnet end-to-end for
predicting optical flow be- tween two images. We use a loss function that
combines a data term that measures photometric constancy over time with a
spatial term that models the expected variation of flow across the image.
Together these losses form a proxy measure for losses based on the groundtruth
flow. Empiri- cally, we show that a strong convnet baseline trained with the
proposed unsupervised approach outperforms the same network trained with
supervision on the KITTI dataset.
</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05844</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resiliency in Distributed Sensor Networks for PHM of the Monitoring
  Targets</dc:title>
 <dc:creator>Bahi, Jacques</dc:creator>
 <dc:creator>Elghazel, Wiem</dc:creator>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:creator>Haddad, Mohammed</dc:creator>
 <dc:creator>Hakem, Mourad</dc:creator>
 <dc:creator>Medjaher, Kamal</dc:creator>
 <dc:creator>Zerhouni, Nourredine</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In condition-based maintenance, real-time observations are crucial for
on-line health assessment. When the monitoring system is a wireless sensor
network, data loss becomes highly probable and this affects the quality of the
remaining useful life prediction. In this paper, we present a fully distributed
algorithm that ensures fault tolerance and recovers data loss in wireless
sensor networks. We first theoretically analyze the algorithm and give
correctness proofs, then provide simulation results and show that the algorithm
is (i) able to ensure data recovery with a low failure rate and (ii) preserves
the overall energy for dense networks.
</dc:description>
 <dc:description>Comment: The Computer Journal (accepted)</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05844</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05845</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Centrality Measures in Networks</dc:title>
 <dc:creator>Bloch, Francis</dc:creator>
 <dc:creator>Jackson, Matthew O.</dc:creator>
 <dc:creator>Tebaldi, Pietro</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We show that although the prominent centrality measures in network analysis
make use of different information about nodes' positions, they all process that
information in a very restrictive and identical way. They all spring from a
common family that are characterized by the same axioms. In particular, they
are all based on a additively separable and linear treatment of a statistic
that captures a node's position in the network. Using such statistics on nodes'
positions, we also characterize networks on which centrality measures all
agree.
</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:date>2017-06-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05850</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Steganalyzer performances in operational contexts</dc:title>
 <dc:creator>Fadil, Yousra A.</dc:creator>
 <dc:creator>Couchot, Jean-Fran&#xe7;ois</dc:creator>
 <dc:creator>Couturier, Rapha&#xeb;l</dc:creator>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Steganography and steganalysis are two important branches of the information
hiding field of research. Steganography methods consist in hiding information
in such a way that the secret message is undetectable for the uninitiated.
Steganalyzis encompasses all the techniques that attempt to detect the presence
of such hidden information. This latter is usually designed by making
classifiers able to separate innocent images from steganographied ones
according to their differences on well-selected features. We wonder, in this
article whether it is possible to construct a kind of universal steganalyzer
without any knowledge regarding the steganographier side. The effects on the
classification score of a modification of either parameters or methods between
the learning and testing stages are then evaluated, while the possibility to
improve the separation score by merging many methods during learning stage is
deeper investigated.
</dc:description>
 <dc:description>Comment: Proceedings of IIH-MSP 2015, The Eleventh International Conference on
  Intelligent Information Hiding and Multimedia Signal Processing</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05850</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05852</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Word Embeddings from Intrinsic and Extrinsic Views</dc:title>
 <dc:creator>Chen, Jifan</dc:creator>
 <dc:creator>Chen, Kan</dc:creator>
 <dc:creator>Qiu, Xipeng</dc:creator>
 <dc:creator>Zhang, Qi</dc:creator>
 <dc:creator>Huang, Xuanjing</dc:creator>
 <dc:creator>Zhang, Zheng</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  While word embeddings are currently predominant for natural language
processing, most of existing models learn them solely from their contexts.
However, these context-based word embeddings are limited since not all words'
meaning can be learned based on only context. Moreover, it is also difficult to
learn the representation of the rare words due to data sparsity problem. In
this work, we address these issues by learning the representations of words by
integrating their intrinsic (descriptive) and extrinsic (contextual)
information. To prove the effectiveness of our model, we evaluate it on four
tasks, including word similarity, reverse dictionaries,Wiki link prediction,
and document classification. Experiment results show that our model is powerful
in both word and document modeling.
</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05852</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05856</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Processing by a Unified Schatten-$p$ Norm and $\ell_q$ Norm
  Regularized Principal Component Pursuit</dc:title>
 <dc:creator>Wang, Jing</dc:creator>
 <dc:creator>Wang, Meng</dc:creator>
 <dc:creator>Hu, Xuegang</dc:creator>
 <dc:creator>Yan, Shuicheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a non-convex formulation to recover the authentic
structure from the corrupted real data. Typically, the specific structure is
assumed to be low rank, which holds for a wide range of data, such as images
and videos. Meanwhile, the corruption is assumed to be sparse. In the
literature, such a problem is known as Robust Principal Component Analysis
(RPCA), which usually recovers the low rank structure by approximating the rank
function with a nuclear norm and penalizing the error by an $\ell_1$-norm.
Although RPCA is a convex formulation and can be solved effectively, the
introduced norms are not tight approximations, which may cause the solution to
deviate from the authentic one. Therefore, we consider here a non-convex
relaxation, consisting of a Schatten-$p$ norm and an $\ell_q$-norm that promote
low rank and sparsity respectively. We derive a proximal iteratively reweighted
algorithm (PIRA) to solve the problem. Our algorithm is based on an alternating
direction method of multipliers, where in each iteration we linearize the
underlying objective function that allows us to have a closed form solution. We
demonstrate that solutions produced by the linearized approximation always
converge and have a tighter approximation than the convex counterpart.
Experimental results on benchmarks show encouraging results of our approach.
</dc:description>
 <dc:description>Comment: Pattern Recognition, 2015</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05856</dc:identifier>
 <dc:identifier>doi:10.1016/j.patcog.2015.01.024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05859</identifier>
 <datestamp>2017-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using the Output Embedding to Improve Language Models</dc:title>
 <dc:creator>Press, Ofir</dc:creator>
 <dc:creator>Wolf, Lior</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We study the topmost weight matrix of neural network language models. We show
that this matrix constitutes a valid word embedding. When training language
models, we recommend tying the input embedding and this output embedding. We
analyze the resulting update rules and show that the tied embedding evolves in
a more similar way to the output embedding than to the input embedding in the
untied model. We also offer a new method of regularizing the output embedding.
Our methods lead to a significant reduction in perplexity, as we are able to
show on a variety of neural network language models. Finally, we show that
weight tying can reduce the size of neural translation models to less than half
of their original size without harming their performance.
</dc:description>
 <dc:description>Comment: To appear in EACL 2017</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:date>2017-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05859</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05864</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Hybrid, PDE-ODE Control Strategy for Intercepting an Intelligent,
  well-informed Target in a Stationary, Cluttered Environment</dc:title>
 <dc:creator>Masoud, Ahmad A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In [1,2] a new class of intelligent controllers that can semantically embed
an agent in a spatial context constraining its behavior in a goal-oriented
manner was suggested. A controller of such a class can guide an agent in a
stationary unknown environment to a fixed target zone along an obstacle-free
trajectory. Here, an extension is suggested that would enable the interception
of an intelligent target that is maneuvering to evade capture amidst stationary
clutter (i.e. the target zone is moving). This is achieved by forcing the
differential properties of the potential field used to induce the control
action to satisfy the wave equation. Background of the problem, theoretical
developments, as well as, proofs of the ability of the modified control to
intercept the target along an obstacle-free trajectory are supplied. Simulation
results are also provided.
</dc:description>
 <dc:description>Comment: 22 pages, 20 figures, Journal paper</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05864</dc:identifier>
 <dc:identifier>Applied Mathematical Sciences, HIKARI Ltd, Vol. 1, 2007, No. 48,
  2345-2371</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05866</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AllConcur: Leaderless Concurrent Atomic Broadcast (Extended Version)</dc:title>
 <dc:creator>Poke, Marius</dc:creator>
 <dc:creator>Hoefler, Torsten</dc:creator>
 <dc:creator>Glass, Colin W.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Many distributed systems require coordination between the components
involved. With the steady growth of such systems, the probability of failures
increases, which necessitates scalable fault-tolerant agreement protocols. The
most common practical agreement protocol, for such scenarios, is leader-based
atomic broadcast. In this work, we propose AllConcur, a distributed system that
provides agreement through a leaderless concurrent atomic broadcast algorithm,
thus, not suffering from the bottleneck of a central coordinator. In AllConcur,
all components exchange messages concurrently through a logical overlay network
that employs early termination to minimize the agreement latency. Our
implementation of AllConcur supports standard sockets-based TCP as well as
high-performance InfiniBand Verbs communications. AllConcur can handle up to
135 million requests per second and achieves 17x higher throughput than today's
standard leader-based protocols, such as Libpaxos. Thus, AllConcur is highly
competitive with regard to existing solutions and, due to its decentralized
approach, enables hitherto unattainable system designs in a variety of fields.
</dc:description>
 <dc:description>Comment: Overview: 18 pages, 7 sections, 10 figures, 3 tables. Modifications
  from previous version: added Figure 4; added, in Section 4.4, a paragraph
  describing the construction of Gs digraphs; added Section 4.5, a theoretical
  comparison between AllConcur and leader-based agreement; added, in Section 5,
  a comparison to unreliable agreement; rephrased several paragraphs to improve
  clarity</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:date>2017-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05867</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple realizability of complete abstract topological graphs simplified</dc:title>
 <dc:creator>Kyn&#x10d;l, Jan</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C10, 68R10, 15A06</dc:subject>
 <dc:description>  An abstract topological graph (briefly an AT-graph) is a pair
$A=(G,\mathcal{X})$ where $G=(V,E)$ is a graph and $\mathcal{X}\subseteq {E
\choose 2}$ is a set of pairs of its edges. The AT-graph $A$ is simply
realizable if $G$ can be drawn in the plane so that each pair of edges from
$\mathcal{X}$ crosses exactly once and no other pair crosses. We show that
simply realizable complete AT-graphs are characterized by a finite set of
forbidden AT-subgraphs, each with at most six vertices. This implies a
straightforward polynomial algorithm for testing simple realizability of
complete AT-graphs, which simplifies a previous algorithm by the author. We
also show an analogous result for independent $\mathbb{Z}_2$-realizability,
where only the parity of the number of crossings for each pair of independent
edges is specified.
</dc:description>
 <dc:description>Comment: 26 pages, 16 figures</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05869</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Virtual Network PaaS for 3GPP 4G and Beyond Core Network Services</dc:title>
 <dc:creator>Abu-Lebdeh, Mohammad</dc:creator>
 <dc:creator>Yangui, Sami</dc:creator>
 <dc:creator>Naboulsi, Diala</dc:creator>
 <dc:creator>Glitho, Roch</dc:creator>
 <dc:creator>Tchouati, Constant Wette</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Cloud computing and Network Function Virtualization (NFV) are emerging as key
technologies to overcome the challenges facing 4G and beyond mobile systems.
Over the last few years, Platform-as-a-Service (PaaS) has gained momentum and
has become more widely adopted throughout IT enterprises. It simplifies the
applications provisioning and accelerates time-to-market while lowering costs.
Telco can leverage the same model to provision the 4G and beyond core network
services using NFV technology. However, many challenges have to be addressed,
mainly due to the specificities of network services. This paper proposes an
architecture for a Virtual Network Platform-as-a-Service (VNPaaS) to provision
3GPP 4G and beyond core network services in a distributed environment. As an
illustrative use case, the proposed architecture is employed to provision the
3GPP Home Subscriber Server (HSS) as-a-Service (HSSaaS). The HSSaaS is built
from Virtualized Network Functions (VNFs) resulting from a novel decomposition
of HSS. A prototype is implemented and early measurements are made.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures, 2 tables, 5th IEEE International Conference on
  Cloud Networking (IEEE CloudNet 2016)</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05869</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05874</identifier>
 <datestamp>2017-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient non-anonymous composition operator for modeling complex
  dependable systems</dc:title>
 <dc:creator>Chiaradonna, Silvano</dc:creator>
 <dc:creator>Di Giandomenico, Felicita</dc:creator>
 <dc:creator>Masetti, Giulio</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  A new model composer is proposed to automatically generate non-anonymous
model replicas in the context of performability and dependability evaluation.
It is a state-sharing composer that extends the standard anonymous replication
composer in order to share the state of a replica among a set of other specific
replicas or among the eplica and another external model. This new composition
operator aims to improve expressiveness and performance with respect to the
standard anonymous replicator, namely the one adopted by the M{\&quot;o}bius
modeling framework.
</dc:description>
 <dc:description>Comment: Editor: Gilles Tredan. 12th European Dependable Computing Conference
  (EDCC 2016), September 5-9, 2016, Gothenburg, Sweden. Fast Abstracts
  Proceedings- EDCC 2016</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:date>2017-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05874</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05878</identifier>
 <datestamp>2017-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The ground truth about metadata and community detection in networks</dc:title>
 <dc:creator>Peel, Leto</dc:creator>
 <dc:creator>Larremore, Daniel B.</dc:creator>
 <dc:creator>Clauset, Aaron</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Across many scientific domains, there is a common need to automatically
extract a simplified view or coarse-graining of how a complex system's
components interact. This general task is called community detection in
networks and is analogous to searching for clusters in independent vector data.
It is common to evaluate the performance of community detection algorithms by
their ability to find so-called &quot;ground truth&quot; communities. This works well in
synthetic networks with planted communities because such networks' links are
formed explicitly based on those known communities. However, there are no
planted communities in real world networks. Instead, it is standard practice to
treat some observed discrete-valued node attributes, or metadata, as ground
truth. Here, we show that metadata are not the same as ground truth, and that
treating them as such induces severe theoretical and practical problems. We
prove that no algorithm can uniquely solve community detection, and we prove a
general No Free Lunch theorem for community detection, which implies that there
can be no algorithm that is optimal for all possible community detection tasks.
However, community detection remains a powerful tool and node metadata still
have value so a careful exploration of their relationship with network
structure can yield insights of genuine worth. We illustrate this point by
introducing two statistical techniques that can quantify the relationship
between metadata and community structure for a broad class of models. We
demonstrate these techniques using both synthetic and real-world networks, and
for multiple types of metadata and community structure.
</dc:description>
 <dc:description>Comment: 27 pages, 10 figures, 11 tables</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:date>2017-05-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05878</dc:identifier>
 <dc:identifier>Science Advances 3(5) e1602548, 2017</dc:identifier>
 <dc:identifier>doi:10.1126/sciadv.1602548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05880</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deconstructing the Welch Equation Using $p$-adic Methods</dc:title>
 <dc:creator>Mann, Abigail</dc:creator>
 <dc:creator>Yeoh, Adelyn</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The Welch map $x \rightarrow g^{x-1+c}$ is similar to the discrete
exponential map $x \rightarrow g^x$, which is used in many cryptographic
applications including the ElGamal signature scheme. This paper analyzes the
number of solutions to the Welch equation: $g^{x-1+c} \equiv x \pmod{p^e}$
where $p$ is a prime and $g$ is a unit modulo $p$, and looks at other patterns
of the equation that could possibly be exploited in a similar cryptographic
system. Since the equation is modulo $p^e$, where $p$ is a prime number,
$p$-adic methods of analysis are used in counting the number of solutions
modulo $p^e$. These methods include: $p$-adic interpolation, Hensel's lemma and
Chinese Remainder Theorem.
</dc:description>
 <dc:description>Comment: 19 pages</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05880</dc:identifier>
 <dc:identifier>Rose-Hulman Undergraduate Mathematics Journal, Vol. 16, Issue 1,
  2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05882</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Counting Solutions to Discrete Non-Algebraic Equations Modulo Prime
  Powers</dc:title>
 <dc:creator>Mann, Abigail</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  As society becomes more reliant on computers, cryptographic security becomes
increasingly important. Current encryption schemes include the ElGamal
signature scheme, which depends on the complexity of the discrete logarithm
problem. It is thought that the functions that such schemes use have inverses
that are computationally intractable. In relation to this, we are interested in
counting the solutions to a generalization of the discrete logarithm problem
modulo a prime power. This is achieved by interpolating to p-adic functions,
and using Hensel's lemma, or other methods in the case of singular lifting, and
the Chinese Remainder Theorem.
</dc:description>
 <dc:description>Comment: 17 pages; Senior Thesis, Rose-Hulman Institute of Technology</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05889</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Feature Selection with Group Structure Analysis</dc:title>
 <dc:creator>Wang, Jing</dc:creator>
 <dc:creator>Wang, Meng</dc:creator>
 <dc:creator>Li, Peipei</dc:creator>
 <dc:creator>Liu, Luoqi</dc:creator>
 <dc:creator>Zhao, Zhongqiu</dc:creator>
 <dc:creator>Hu, Xuegang</dc:creator>
 <dc:creator>Wu, Xindong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Online selection of dynamic features has attracted intensive interest in
recent years. However, existing online feature selection methods evaluate
features individually and ignore the underlying structure of feature stream.
For instance, in image analysis, features are generated in groups which
represent color, texture and other visual information. Simply breaking the
group structure in feature selection may degrade performance. Motivated by this
fact, we formulate the problem as an online group feature selection. The
problem assumes that features are generated individually but there are group
structure in the feature stream. To the best of our knowledge, this is the
first time that the correlation among feature stream has been considered in the
online feature selection process. To solve this problem, we develop a novel
online group feature selection method named OGFS. Our proposed approach
consists of two stages: online intra-group selection and online inter-group
selection. In the intra-group selection, we design a criterion based on
spectral analysis to select discriminative features in each group. In the
inter-group selection, we utilize a linear regression model to select an
optimal subset. This two-stage procedure continues until there are no more
features arriving or some predefined stopping conditions are met. %Our method
has been applied Finally, we apply our method to multiple tasks including image
classification %, face verification and face verification. Extensive empirical
studies performed on real-world and benchmark data sets demonstrate that our
method outperforms other state-of-the-art online feature selection %method
methods.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Knowledge and Data Engineering,2015</dc:description>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05889</dc:identifier>
 <dc:identifier>doi:10.1109/TKDE.2015.2441716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05893</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reducing State Explosion for Software Model Checking with Relaxed Memory
  Consistency Models</dc:title>
 <dc:creator>Abe, Tatsuya</dc:creator>
 <dc:creator>Ugawa, Tomoharu</dc:creator>
 <dc:creator>Maeda, Toshiyuki</dc:creator>
 <dc:creator>Matsumoto, Kousuke</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Software model checking suffers from the so-called state explosion problem,
and relaxed memory consistency models even worsen this situation. What is
worse, parameterizing model checking by memory consistency models, that is, to
make the model checker as flexible as we can supply definitions of memory
consistency models as an input, intensifies state explosion. This paper
explores specific reasons for state explosion in model checking with multiple
memory consistency models, provides some optimizations intended to mitigate the
problem, and applies them to McSPIN, a model checker for memory consistency
models that we are developing. The effects of the optimizations and the
usefulness of McSPIN are demonstrated experimentally by verifying copying
protocols of concurrent copying garbage collection algorithms. To the best of
our knowledge, this is the first model checking of the concurrent copying
protocols under relaxed memory consistency models.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05893</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05895</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VoxResNet: Deep Voxelwise Residual Networks for Volumetric Brain
  Segmentation</dc:title>
 <dc:creator>Chen, Hao</dc:creator>
 <dc:creator>Dou, Qi</dc:creator>
 <dc:creator>Yu, Lequan</dc:creator>
 <dc:creator>Heng, Pheng-Ann</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently deep residual learning with residual units for training very deep
neural networks advanced the state-of-the-art performance on 2D image
recognition tasks, e.g., object detection and segmentation. However, how to
fully leverage contextual representations for recognition tasks from volumetric
data has not been well studied, especially in the field of medical image
computing, where a majority of image modalities are in volumetric format. In
this paper we explore the deep residual learning on the task of volumetric
brain segmentation. There are at least two main contributions in our work.
First, we propose a deep voxelwise residual network, referred as VoxResNet,
which borrows the spirit of deep residual learning in 2D image recognition
tasks, and is extended into a 3D variant for handling volumetric data. Second,
an auto-context version of VoxResNet is proposed by seamlessly integrating the
low-level image appearance features, implicit shape information and high-level
context together for further improving the volumetric segmentation performance.
Extensive experiments on the challenging benchmark of brain segmentation from
magnetic resonance (MR) images corroborated the efficacy of our proposed method
in dealing with volumetric data. We believe this work unravels the potential of
3D deep learning to advance the recognition performance on volumetric image
segmentation.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05910</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mining of health and disease events on Twitter: validating search
  protocols within the setting of Indonesia</dc:title>
 <dc:creator>Ramadona, Aditya L.</dc:creator>
 <dc:creator>Agusta, Rendra</dc:creator>
 <dc:creator>Sulistyawati</dc:creator>
 <dc:creator>Lazuardi, Lutfan</dc:creator>
 <dc:creator>Cahyono, Anwar D.</dc:creator>
 <dc:creator>Holmner, &#xc5;sa</dc:creator>
 <dc:creator>Dewi, Fatwa S. T.</dc:creator>
 <dc:creator>Kusnanto, Hari</dc:creator>
 <dc:creator>R&#xf6;cklov, Joacim</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  This study seeks to validate a search protocol of ill health-related terms
using Twitter data which can later be used to understand if, and how, Twitter
can reveal information on the current health situation. We extracted
conversations related to health and disease postings on Twitter using a set of
pre-defined keywords, assessed the prevalence, frequency, and timing of such
content in these conversations, and validated how this search protocol was able
to detect relevant disease tweets. Classification and Regression Trees (CART)
algorithm was used to train and test search protocols of disease and health
hits comparing to those identified by our team. The accuracy of predictions
showed a good validity with AUC beyond 0.8. Our study shows that monitoring of
public sentiment on Twitter can be used as a real-time proxy for health events.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:date>2017-05-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05910</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05916</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Networks and Chaos: Construction, Evaluation of Chaotic Networks,
  and Prediction of Chaos with Multilayer Feedforward Networks</dc:title>
 <dc:creator>Bahi, Jacques M.</dc:creator>
 <dc:creator>Couchot, Jean-Fran&#xe7;ois</dc:creator>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:creator>Salomon, Michel</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  Many research works deal with chaotic neural networks for various fields of
application. Unfortunately, up to now these networks are usually claimed to be
chaotic without any mathematical proof. The purpose of this paper is to
establish, based on a rigorous theoretical framework, an equivalence between
chaotic iterations according to Devaney and a particular class of neural
networks. On the one hand we show how to build such a network, on the other
hand we provide a method to check if a neural network is a chaotic one.
Finally, the ability of classical feedforward multilayer perceptrons to learn
sets of data obtained from a dynamical system is regarded. Various Boolean
functions are iterated on finite states. Iterations of some of them are proven
to be chaotic as it is defined by Devaney. In that context, important
differences occur in the training process, establishing with various neural
networks that chaotic behaviors are far more difficult to learn.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05916</dc:identifier>
 <dc:identifier>AIP Chaos, An Interdisciplinary Journal of Nonlinear Science.
  22(1), 013122 (2012)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05917</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Adaptive Trade-off Decision Making for Autoscaling Cloud-Based
  Services</dc:title>
 <dc:creator>Chen, Tao</dc:creator>
 <dc:creator>Bahsoon, Rami</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Elasticity in the cloud is often achieved by on-demand autoscaling. In such
context, the goal is to optimize the Quality of Service (QoS) and cost
objectives for the cloud-based services. However, the difficulty lies in the
facts that these objectives, e.g., throughput and cost, can be naturally
conflicted, and the QoS of cloud-based services often interfere due to the
shared infrastructure in cloud. Consequently, dynamic and effective trade-off
decision making of autoscaling in the cloud is necessary, yet challenging. In
particular, it is even harder to achieve well-compromised trade-offs, where the
decision largely improves the majority of the objectives, while causing
relatively small degradations to others. In this paper, we present a
self-adaptive decision making approach for autoscaling in the cloud. It is
capable to adaptively produce autoscaling decisions that lead to
well-compromised trade-offs without heavy human intervention. We leverage on
ant colony inspired multi-objective optimization for searching and optimizing
the trade-offs decisions, the result is then filtered by compromise-dominance,
a mechanism that extracts the decisions with balanced improvements in the
trade-offs. We experimentally compare our approach to four state-of-the-arts
autoscaling approaches: rule, heuristic, randomized and multi-objective genetic
algorithm based solutions. The results reveal the effectiveness of our approach
over the others, including better quality of trade-offs and significantly
smaller violation of the requirements.
</dc:description>
 <dc:description>Comment: published in IEEE Transactions on Services Computing 2015</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05917</dc:identifier>
 <dc:identifier>doi:10.1109/TSC.2015.2499770</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05920</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Topological Study of Chaotic Iterations. Application to Hash Functions</dc:title>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:creator>Bahi, Jacques M.</dc:creator>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  Chaotic iterations, a tool formerly used in distributed computing, has
recently revealed various interesting properties of disorder leading to its use
in the computer science security field. In this paper, a comprehensive study of
its topological behavior is proposed. It is stated that, in addition to being
chaotic as defined in the Devaney's formulation, this tool possesses the
property of topological mixing. Additionally, its level of sensibility,
expansivity, and topological entropy are evaluated. All of these properties
lead to a complete unpredictable behavior for the chaotic iterations. As it
only manipulates binary digits or integers, we show that it is possible to use
it to produce truly chaotic computer programs. As an application example, a
truly chaotic hash function is proposed in two versions. In the second version,
an artificial neural network is used, which can be stated as chaotic according
to Devaney.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1511.00117</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05920</dc:identifier>
 <dc:identifier>Studies in Computational Intelligence, pp. 51-73 (2012)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05921</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Knowledge Graph Construction: Compositional and
  Incremental Approaches</dc:title>
 <dc:creator>Kim, Dongwoo</dc:creator>
 <dc:creator>Xie, Lexing</dc:creator>
 <dc:creator>Ong, Cheng Soon</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Knowledge graph construction consists of two tasks: extracting information
from external resources (knowledge population) and inferring missing
information through a statistical analysis on the extracted information
(knowledge completion). In many cases, insufficient external resources in the
knowledge population hinder the subsequent statistical inference. The gap
between these two processes can be reduced by an incremental population
approach. We propose a new probabilistic knowledge graph factorisation method
that benefits from the path structure of existing knowledge (e.g. syllogism)
and enables a common modelling approach to be used for both incremental
population and knowledge completion tasks. More specifically, the probabilistic
formulation allows us to develop an incremental population algorithm that
trades off exploitation-exploration. Experiments on three benchmark datasets
show that the balanced exploitation-exploration helps the incremental
population, and the additional path structure helps to predict missing
information in knowledge completion.
</dc:description>
 <dc:description>Comment: The 25th ACM International Conference on Information and Knowledge
  Management (CIKM 2016)</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:date>2016-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05921</dc:identifier>
 <dc:identifier>doi:10.1145/2983323.2983677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05923</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Managing The Dynamics Of A Harmonic Potential Field-Guided Robot In A
  Cluttered Environment</dc:title>
 <dc:creator>Masoud, Ahmad A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper demonstrates the ability of the harmonic potential field, HPF,
planning method to generate a well-behaved constrained path for a robot with
second order dynamics in a cluttered environment. It is shown that HPF-based
controllers may be developed for holonomic as well as nonholonomic robots to
effectively suppress the effect of inertial forces on the robot trajectory
while maintaining all the attractive features of a purely kinematic HPF
planner. The capabilities of the suggested navigation controller are
demonstrated using simulation results. Comparisons are also supplied with other
approaches used for converting the guidance signal from a purely kinematic HPF
planner into a navigation control signal.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05923</dc:identifier>
 <dc:identifier>IEEE Transactions On Industrial Electronics, Vol. 56, NO. 2,
  February 2009, Pp. 488-496</dc:identifier>
 <dc:identifier>doi:10.1109/TIE.2008.2002720</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05924</identifier>
 <datestamp>2016-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Congruences and Concurrent Lines in Multi-View Geometry</dc:title>
 <dc:creator>Ponce, Jean</dc:creator>
 <dc:creator>Sturmfels, Bernd</dc:creator>
 <dc:creator>Trager, Matthew</dc:creator>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  We present a new framework for multi-view geometry in computer vision. A
camera is a mapping between $\mathbb{P}^3$ and a line congruence. This model,
which ignores image planes and measurements, is a natural abstraction of
traditional pinhole cameras. It includes two-slit cameras, pushbroom cameras,
catadioptric cameras, and many more. We study the concurrent lines variety,
which consists of $n$-tuples of lines in $\mathbb{P}^3$ that intersect at a
point. Combining its equations with those of various congruences, we derive
constraints for corresponding images in multiple views. We also study
photographic cameras which use image measurements and are modeled as rational
maps from $\mathbb{P}^3$ to $\mathbb{P}^2$ or $\mathbb{P}^1\times
\mathbb{P}^1$.
</dc:description>
 <dc:description>Comment: 26 pages</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:date>2016-12-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05924</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05926</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bridging Ecology and Cloud: Transposing Ecological Prespective to Enable
  Better Cloud Autoscaling</dc:title>
 <dc:creator>Chen, Tao</dc:creator>
 <dc:creator>Bahsoon, Rami</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Elastic autoscaling is the fundamental mechanism that enables the cloud-based
services to continually evolve themselves - through changing the related
software configurations and hardware resource provisions - under time-varying
workloads. However, given the increasingly complex dynamic, uncertainty and
trade-offs related to the runtime QoS and cost/energy of services, cloud
autoscaling system is becoming one of the most complex artifacts constructed by
human and thus its effectiveness is difficult to be preserved. In this article,
we present novel ideas for facilitating cloud autoscaling. Our hypothesis that
cloud ecosystem, represented by a collection of cloud-based services, bears
many similarities with the natural ecosystem. As such, we in- tend to
investigate how ecological view can be adopted to better explain how the
cloud-based services evolve, and to explore what are the key factors that drive
stable and sustainable cloud-based services in the cloud. To achieve this goal,
we aim to transpose ecological principles, theories and models into cloud
autoscaling analogues and spontaneously improve long-term stability and
sustainability of cloud ecosystem.
</dc:description>
 <dc:description>Comment: submitted for publication, 12 pages, 3 figures, 1 table</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05926</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05928</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quality Analysis of a Chaotic Proven Keyed Hash Function</dc:title>
 <dc:creator>Bahi, Jacques M.</dc:creator>
 <dc:creator>Couchot, Jean-Fran&#xe7;ois</dc:creator>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Hash functions are cryptographic tools, which are notably involved in
integrity checking and password storage. They are of primary importance to
improve the security of exchanges through the Internet. However, as security
flaws have been recently identified in the current standard in this domain, new
ways to hash digital data must be investigated. In this document an original
keyed hash function is evaluated. It is based on asynchronous iterations
leading to functions that have been proven to be chaotic. It thus possesses
various topological properties as uniformity and sensibility to its initial
condition. These properties make our hash function satisfies established
security requirements in this field. This claim is qualitatively proven and
experimentally verified in this research work, among other things by realizing
a large number of simulations.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1112.1271</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05928</dc:identifier>
 <dc:identifier>International Journal On Advances in Internet Technology. 5(1),
  pp.26-33, 2012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05930</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FPGA Design for Pseudorandom Number Generator Based on Chaotic Iteration
  used in Information Hiding Application</dc:title>
 <dc:creator>Bahi, Jacques M.</dc:creator>
 <dc:creator>Fang, Xiaole</dc:creator>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:creator>Larger, Laurent</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  Lots of researches indicate that the inefficient generation of random numbers
is a significant bottleneck for information communication applications.
Therefore, Field Programmable Gate Array (FPGA) is developed to process a
scalable fixed-point method for random streams generation. In our previous
researches, we have proposed a technique by applying some well-defined discrete
chaotic iterations that satisfy the reputed Devaney's definition of chaos,
namely chaotic iterations (CI). We have formerly proven that the generator with
CI can provide qualified chaotic random numbers. In this paper, this generator
based on chaotic iterations is optimally redesigned for FPGA device. By doing
so, the generation rate can be largely improved. Analyses show that these
hardware generators can also provide good statistical chaotic random bits and
can be cryptographically secure too. An application in the information hiding
security field is finally given as an illustrative example.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1012.4620, arXiv:1112.1201</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05930</dc:identifier>
 <dc:identifier>Applied Mathematics &amp; Information Sciences. Vol. 7(6), pp.
  2175-2188 (2013)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05931</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Planning With Discrete Harmonic Potential Fields</dc:title>
 <dc:creator>Masoud, Ahmad A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  In this work a discrete counterpart to the continuous harmonic potential
field approach is suggested. The extension to the discrete case makes use of
the strong relation HPF-based planning has to connectionist artificial
intelligence (AI). Connectionist AI systems are networks of simple,
interconnected processors running in parallel within the confines of the
environment in which the planning action is to be synthesized. It is not hard
to see that such a paradigm naturally lends itself to planning on weighted
graphs where the processors may be seen as the vertices of the graph and the
relations among them as its edges. Electrical networks are an effective
realization of connectionist AI. The utility of the discrete HPF (DHPF)
approach is demonstrated in three ways. First, the capability of the DHPF
approach to generate new, abstract, planning techniques is demonstrated by
constructing a novel, efficient, optimal, discrete planning method called the
M* algorithm. Also, its ability to augment the capabilities of existing
planners is demonstrated by suggesting a generic solution to the lower bound
problem faced by the A* algorithm. The DHPF approach is shown to be useful in
solving specific planning problems in communication. It is demonstrated that
the discrete HPF paradigm can support routing on-the-fly while the network is
still in a transient state. It is shown by simulation that if a path to the
target always exist and the switching delays in the routers are negligible, a
packet will reach its destination despite the changes in the network which may
simultaneously take place while the packet is being routed.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05931</dc:identifier>
 <dc:identifier>&quot;Mobile Robots Motion Planning: New Challanges&quot;, I-TECH, Vienna,
  Austeria, 2008, Pp. 335-360</dc:identifier>
 <dc:identifier>doi:10.5772/6006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05936</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two Security Layers for Hierarchical Data Aggregation in Sensor Networks</dc:title>
 <dc:creator>Bahi, Jacques M.</dc:creator>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:creator>Makhoul, Abdallah</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Due to resource restricted sensor nodes, it is important to minimize the
amount of data transmission among sensor networks. To reduce the amount of
sending data, an aggregation approach can be applied along the path from
sensors to the sink. However, as sensor networks are often deployed in
untrusted and even hostile environments, sensor nodes are prone to node
compromise attacks. Hence, an end-to-end secure aggregation approach is
required to ensure a healthy data reception. In this paper, we propose two
layers for secure data aggregation in sensor networks. Firstly, we provide an
end-to-end encryption scheme that supports operations over cypher-text. It is
based on elliptic curve cryptography that exploits a smaller key size, allows
the use of higher number of operations on cypher-texts, and prevents the
distinction between two identical texts from their cryptograms. Secondly, we
propose a new watermarking-based authentication that enables sensor nodes to
ensure the identity of other nodes they are communicating with. Our experiments
show that our hybrid approach of secure data aggregation enhances the security,
significantly reduces computation and communication overhead, and can be
practically implemented in on-the-shelf sensor platforms.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05936</dc:identifier>
 <dc:identifier>International Journal of Autonomous and Adaptive Communications
  Systems. 7(3), 239-270, 2014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05945</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Theoretical design and circuit implementation of integer domain chaotic
  systems</dc:title>
 <dc:creator>Wang, Qianxue</dc:creator>
 <dc:creator>Yu, Simin</dc:creator>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:creator>Bahi, Jacques</dc:creator>
 <dc:creator>Fang, Xiaole</dc:creator>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Nonlinear Sciences - Pattern Formation and Solitons</dc:subject>
 <dc:description>  In this paper, a new approach for constructing integer domain chaotic systems
(IDCS) is proposed, and its chaotic behavior is mathematically proven according
to the Devaney's definition of chaos. Furthermore, an analog-digital hybrid
circuit is also developed for realizing the designed basic IDCS. In the IDCS
circuit design, chaos generation strategy is realized through a sample-hold
circuit and a decoder circuit so as to convert the uniform noise signal into a
random sequence, which plays a key role in circuit implementation. The
experimental observations further validate the proposed systematic methodology
for the first time.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05945</dc:identifier>
 <dc:identifier>International Journal of Bifurcation and Chaos. 24(10), 1450128,
  2014</dc:identifier>
 <dc:identifier>doi:10.1142/S0218127414501284</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05949</identifier>
 <datestamp>2016-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Representations for Biological Sequence Analysis</dc:title>
 <dc:creator>Kimothi, Dhananjay</dc:creator>
 <dc:creator>Soni, Akshay</dc:creator>
 <dc:creator>Biyani, Pravesh</dc:creator>
 <dc:creator>Hogan, James M.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  Biological sequence comparison is a key step in inferring the relatedness of
various organisms and the functional similarity of their components. Thanks to
the Next Generation Sequencing efforts, an abundance of sequence data is now
available to be processed for a range of bioinformatics applications. Embedding
a biological sequence over a nucleotide or amino acid alphabet in a lower
dimensional vector space makes the data more amenable for use by current
machine learning tools, provided the quality of embedding is high and it
captures the most meaningful information of the original sequences. Motivated
by recent advances in the text document embedding literature, we present a new
method, called seq2vec, to represent a complete biological sequence in an
Euclidean space. The new representation has the potential to capture the
contextual information of the original sequence necessary for sequence
comparison tasks. We test our embeddings with protein sequence classification
and retrieval tasks and demonstrate encouraging outcomes.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:date>2016-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05949</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05951</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Epidemiological Approach for Data Survivability in Unattended Wireless
  Sensor Networks</dc:title>
 <dc:creator>Bahi, Jacques M.</dc:creator>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:creator>Hakem, Mourad</dc:creator>
 <dc:creator>Makhoul, Abdallah</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Unattended Wireless Sensor Networks (UWSNs) are Wireless Sensor Networks
characterized by sporadic sink presence and operation in hostile settings. The
absence of the sink for period of time, prevents sensor nodes to offload data
in real time and offer greatly increased opportunities for attacks resulting in
erasure, modification, or disclosure of sensor-collected data. In this paper,
we focus on UWSNs where sensor nodes collect and store data locally and try to
upload all the information once the sink becomes available. One of the most
relevant issues pertaining UWSNs is to guarantee a certain level of information
survivability in an unreliable network and even in presence of a powerful
attackers. In this paper, we first introduce an epidemic-domain inspired
approach to model the information survivability in UWSN. Next, we derive a
fully distributed algorithm that supports these models and give the correctness
proofs.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05966</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>KidsTube: Detection, Characterization and Analysis of Child Unsafe
  Content &amp; Promoters on YouTube</dc:title>
 <dc:creator>Kaushal, Rishabh</dc:creator>
 <dc:creator>Saha, Srishty</dc:creator>
 <dc:creator>Bajaj, Payal</dc:creator>
 <dc:creator>Kumaraguru, Ponnurangam</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  YouTube draws large number of users who contribute actively by uploading
videos or commenting on existing videos. However, being a crowd sourced and
large content pushed onto it, there is limited control over the content. This
makes malicious users push content (videos and comments) which is inappropriate
(unsafe), particularly when such content is placed around cartoon videos which
are typically watched by kids. In this paper, we focus on presence of unsafe
content for children and users who promote it. For detection of child unsafe
content and its promoters, we perform two approaches, one based on supervised
classification which uses an extensive set of video-level, user-level and
comment-level features and another based Convolutional Neural Network using
video frames. Detection accuracy of 85.7% is achieved which can be leveraged to
build a system to provide a safe YouTube experience for kids. Through detailed
characterization studies, we are able to successfully conclude that unsafe
content promoters are less popular and engage less as compared with other
users. Finally, using a network of unsafe content promoters and other users
based on their engagements (likes, subscription and playlist addition) and
other factors, we find that unsafe content is present very close to safe
content and unsafe content promoters form very close knit communities with
other users, thereby further increasing the likelihood of a child getting
getting exposed to unsafe content.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05966</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05971</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>STFCN: Spatio-Temporal FCN for Semantic Video Segmentation</dc:title>
 <dc:creator>Fayyaz, Mohsen</dc:creator>
 <dc:creator>Saffar, Mohammad Hajizadeh</dc:creator>
 <dc:creator>Sabokrou, Mohammad</dc:creator>
 <dc:creator>Fathy, Mahmood</dc:creator>
 <dc:creator>Klette, Reinhard</dc:creator>
 <dc:creator>Huang, Fay</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a novel method to involve both spatial and temporal
features for semantic video segmentation. Current work on convolutional neural
networks(CNNs) has shown that CNNs provide advanced spatial features supporting
a very good performance of solutions for both image and video analysis,
especially for the semantic segmentation task. We investigate how involving
temporal features also has a good effect on segmenting video data. We propose a
module based on a long short-term memory (LSTM) architecture of a recurrent
neural network for interpreting the temporal characteristics of video frames
over time. Our system takes as input frames of a video and produces a
correspondingly-sized output; for segmenting the video our method combines the
use of three components: First, the regional spatial features of frames are
extracted using a CNN; then, using LSTM the temporal features are added;
finally, by deconvolving the spatio-temporal features we produce pixel-wise
predictions. Our key insight is to build spatio-temporal convolutional networks
(spatio-temporal CNNs) that have an end-to-end architecture for semantic video
segmentation. We adapted fully some known convolutional network architectures
(such as FCN-AlexNet and FCN-VGG16), and dilated convolution into our
spatio-temporal CNNs. Our spatio-temporal CNNs achieve state-of-the-art
semantic segmentation, as demonstrated for the Camvid and NYUDv2 datasets.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05972</identifier>
 <datestamp>2017-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low Algorithmic Complexity Entropy-deceiving Graphs</dc:title>
 <dc:creator>Zenil, Hector</dc:creator>
 <dc:creator>Kiani, Narsis</dc:creator>
 <dc:creator>Tegn&#xe9;r, Jesper</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:description>  In estimating the complexity of objects, in particular of graphs, it is
common practice to rely on graph- and information-theoretic measures. Here,
using integer sequences with properties such as Borel normality, we explain how
these measures are not independent of the way in which an object, such as a
graph, can be described or observed. From observations that can reconstruct the
same graph and are therefore essentially translations of the same description,
we will see that when applying a computable measure such as Shannon Entropy,
not only is it necessary to pre-select a feature of interest where there is
one, and to make an arbitrary selection where there is not, but also that more
general properties, such as the causal likelihood of a graph as a measure
(opposed to randomness), can be largely misrepresented by computable measures
such as Entropy and Entropy rate. We introduce recursive and non-recursive
(uncomputable) graphs and graph constructions based on these integer sequences,
whose different lossless descriptions have disparate Entropy values, thereby
enabling the study and exploration of a measure's range of applications and
demonstrating the weaknesses of computable measures of complexity.
</dc:description>
 <dc:description>Comment: 28 pages</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:date>2017-05-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05972</dc:identifier>
 <dc:identifier>Phys. Rev. E 96, 012308 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.96.012308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05981</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Dependable Change Management and Traceability for Global
  Software Development</dc:title>
 <dc:creator>Adjepon-Yamoah, David Ebo</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  This paper reports on our definition of guidelines for managing global
software development (GSD) that implements the specific practice - manage
requirements changes - of the Capability Maturity Model Integration (CMMI)
Level 2. The guidelines present a model for change management and traceability
that supports the implementation of the specific CMMI Level 2 goal. Also, to
support the effective management of the system engineering processes, an
adaptation of the Project Management Body of Knowledge (PMBOK) process group
(PG) for project life-cycle practices is provided. We introduce a cloud-based
Reactive Middleware which provides services for managing GSD projects towards
dependable change management and traceability.
</dc:description>
 <dc:description>Comment: Editor: Gilles Tredan. 12th European Dependable Computing Conference
  (EDCC 2016), September 5-9, 2016, Gothenburg, Sweden. Fast Abstracts
  Proceedings- EDCC 2016</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05982</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social Networks Analysis in Discovering the Narrative Structure of
  Literary Fiction</dc:title>
 <dc:creator>Jarynowski, Andrzej</dc:creator>
 <dc:creator>Boland, Stephanie</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In our paper we would like to make a cross-disciplinary leap and use the
tools of network theory to understand and explore narrative structure in
literary fiction, an approach that is still underestimated. However, the
systems in fiction are sensitive to readers subjectivity and attention must to
be paid to different methods of extracting networks. The project aims at
investigating into different ways social interactions are read in texts by
comparing networks produced by automated algorithms-natural language processing
with those created by surveying more subjective human responses. Conversation
networks from fiction have been already extracted by scientists, but the more
general framework surrounding these interactions was missing. We propose
several NLP methods for detecting interactions and test them against a range of
human perceptions. In doing so, we have pointed to some limitations of using
network analysis to test literary theory, e.g. interaction, which corresponds
to the plot, does not form climax.
</dc:description>
 <dc:description>Comment: Shortened and translated version of paper (Transit YCCSA)</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05982</dc:identifier>
 <dc:identifier>Biuletyn Instytutu Systemow Informatycznych 12 P35, 2013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05983</identifier>
 <datestamp>2017-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inverting Variational Autoencoders for Improved Generative Accuracy</dc:title>
 <dc:creator>Gemp, Ian</dc:creator>
 <dc:creator>Durugkar, Ishan</dc:creator>
 <dc:creator>Parente, Mario</dc:creator>
 <dc:creator>Dyar, M. Darby</dc:creator>
 <dc:creator>Mahadevan, Sridhar</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recent advances in semi-supervised learning with deep generative models have
shown promise in generalizing from small labeled datasets
($\mathbf{x},\mathbf{y}$) to large unlabeled ones ($\mathbf{x}$). In the case
where the codomain has known structure, a large unfeatured dataset
($\mathbf{y}$) is potentially available. We develop a parameter-efficient, deep
semi-supervised generative model for the purpose of exploiting this untapped
data source. Empirical results show improved performance in disentangling
latent variable semantics as well as improved discriminative prediction on
Martian spectroscopic and handwritten digit domains.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:date>2017-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05983</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05995</identifier>
 <datestamp>2016-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Non-convex One-Pass Framework for Generalized Factorization Machine
  and Rank-One Matrix Sensing</dc:title>
 <dc:creator>Lin, Ming</dc:creator>
 <dc:creator>Ye, Jieping</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We develop an efficient alternating framework for learning a generalized
version of Factorization Machine (gFM) on steaming data with provable
guarantees. When the instances are sampled from $d$ dimensional random Gaussian
vectors and the target second order coefficient matrix in gFM is of rank $k$,
our algorithm converges linearly, achieves $O(\epsilon)$ recovery error after
retrieving $O(k^{3}d\log(1/\epsilon))$ training instances, consumes $O(kd)$
memory in one-pass of dataset and only requires matrix-vector product
operations in each iteration. The key ingredient of our framework is a
construction of an estimation sequence endowed with a so-called Conditionally
Independent RIP condition (CI-RIP). As special cases of gFM, our framework can
be applied to symmetric or asymmetric rank-one matrix sensing problems, such as
inductive matrix completion and phase retrieval.
</dc:description>
 <dc:description>Comment: accepted by NIPS 2016</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:date>2016-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05995</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.05997</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OFDM Without CP in Massive MIMO</dc:title>
 <dc:creator>Aminjavaheri, Amir</dc:creator>
 <dc:creator>Farhang, Arman</dc:creator>
 <dc:creator>RezazadehReyhani, Ahmad</dc:creator>
 <dc:creator>Doyle, Linda E.</dc:creator>
 <dc:creator>Farhang-Boroujeny, Behrouz</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the possibility of removing the cyclic prefix (CP) overhead from
orthogonal frequency division multiplexing (OFDM) in massive multiple-input
multiple-output (MIMO) systems. We consider the uplink transmission while our
results are applicable to the downlink as well. The absence of CP increases the
spectral efficiency in expense of intersymbol interference (ISI) and
intercarrier interference (ICI). It is known that in massive MIMO, the effects
of uncorrelated noise and multiuser interference vanish as the number of base
station (BS) antennas tends to infinity. To investigate if the channel
distortions in the absence of CP fade away, we study the performance of the
standard maximum ratio combining (MRC) receiver. Our analysis reveals that in
this receiver, there always remains some residual interference leading to
saturation of signal-to-interference-plus-noise ratio (SINR). To resolve this
problem, we propose to use the time reversal (TR) technique. Moreover, in order
to further reduce the multiuser interference, we propose a zero-forcing
equalization to be deployed after the TR combining. We compare the achievable
rate of the proposed system with that of the conventional CP-OFDM. We show that
in realistic channels, a higher spectral efficiency is achieved by removing the
CP from OFDM, while reducing the computational complexity.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.05997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06001</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on Beckett-Gray codes and the relationship of Gray codes to data
  structures</dc:title>
 <dc:creator>Cooke, Mark</dc:creator>
 <dc:creator>North, Chris</dc:creator>
 <dc:creator>Dewar, Megan</dc:creator>
 <dc:creator>Stevens, Brett</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>05C45 (Primary) 68R05 (Secondary)</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  In this paper we introduce a natural mathematical structure derived from
Samuel Beckett's play &quot;Quad&quot;. We call this structure a binary Beckett-Gray
code. We enumerate all codes for $n \leq 6$ and give examples for $n=7,8$.
Beckett-Gray codes can be realized as successive states of a queue data
structure. We show that the binary reflected Gray code can be realized as
successive states of two stack data structures.
</dc:description>
 <dc:description>Comment: 6 pages, 3 tables. Revisions requested from Journal of Combinatorial
  Mathematics and Combinatorial Computing</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06002</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence of Even Simpler Robots without Location Information</dc:title>
 <dc:creator>Pattanayak, Debasish</dc:creator>
 <dc:creator>Mondal, Kaushik</dc:creator>
 <dc:creator>Mandal, Partha Sarathi</dc:creator>
 <dc:creator>Schmid, Stefan</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The design of distributed gathering and convergence algorithms for tiny
robots has recently received much attention. In particular, it has been shown
that convergence problems can even be solved for very weak, \emph{oblivious}
robots: robots which cannot maintain state from one round to the next. The
oblivious robot model is hence attractive from a self-stabilization
perspective, where state is subject to adversarial manipulation. However, to
the best of our knowledge, all existing robot convergence protocols rely on the
assumption that robots, despite being &quot;weak&quot;, can measure distances.
  We in this paper initiate the study of convergence protocols for even simpler
robots, called \emph{monoculus robots}: robots which cannot measure distances.
In particular, we introduce two natural models which relax the assumptions on
the robots' cognitive capabilities: (1) a Locality Detection ($\mathcal{LD}$)
model in which a robot can only detect whether another robot is closer than a
given constant distance or not, (2) an Orthogonal Line Agreement
($\mathcal{OLA}$) model in which robots only agree on a pair of orthogonal
lines (say North-South and West-East, but without knowing which is which).
  The problem turns out to be non-trivial, and simple median and angle
bisection strategies can easily increase the distances among robots (e.g., the
area of the enclosing convex hull) over time. Our main contribution are
deterministic self-stabilizing convergence algorithms for these two models,
together with a complexity analysis. We also show that in some sense, the
assumptions made in our models are minimal: by relaxing the assumptions on the
\textit{monoculus robots} further, we run into impossibility results.
</dc:description>
 <dc:description>Comment: 15 pages, 13 figures</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06005</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space-Time Block Diagonalization for Frequency-Selective MIMO Broadcast
  Channels</dc:title>
 <dc:creator>Viteri-Mera, Carlos A.</dc:creator>
 <dc:creator>Teixeira, Fernando L.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The most relevant linear precoding method for frequency-flat MIMO broadcast
channels is block diagonalization (BD) which, under certain conditions, attains
the same nonlinear dirty paper coding channel capacity. However, BD is not
easily translated to frequency-selective channels, since space-time information
is required for transceiver design. In this paper, we demonstrate that BD is
feasible in frequency-selective MIMO broadcast channels to eliminate inter-user
interference (IUI) if the transmit block length is sufficiently large, and if
the number of transmit antennas is greater than the number of users. We also
propose three different approaches to mitigate/eliminate inter-symbol
interference (ISI) in block transmissions: i) time-reversal-based BD (TRBD)
which maximizes spatial focusing around the receivers using transmitter
processing only, ii) equalized BD (EBD) which minimizes the ISI using
transmitter processing only, and iii) joint processing BD (JPBD), which uses
linear processing at the transmitter and the receiver to suppress ISI. We
analyze the theoretical diversity and multiplexing gains of these techniques,
and we demonstrate that JPBD approximates full multiplexing gain for a
sufficiently large transmit block length. Extensive numerical simulations show
that the achievable rate and probability of error performance of all the
proposed methods improve those of conventional time-reversal beamforming.
Moreover, JPBD provides the highest achievable rate region for
frequency-selective MIMO broadcast channels.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06007</identifier>
 <datestamp>2016-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Probabilistic Bisection Search using Social Learning</dc:title>
 <dc:creator>Tsiligkaridis, Athanasios</dc:creator>
 <dc:creator>Tsiligkaridis, Theodoros</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  We present a novel distributed probabilistic bisection algorithm using social
learning with application to target localization. Each agent in the network
first constructs a query about the target based on its local information and
obtains a noisy response. Agents then perform a Bayesian update of their
beliefs followed by an averaging of the log beliefs over local neighborhoods.
This two stage algorithm consisting of repeated querying and averaging runs
until convergence. We derive bounds on the rate of convergence of the beliefs
at the correct target location. Numerical simulations show that our method
outperforms current state of the art methods.
</dc:description>
 <dc:description>Comment: 5 Pages, Accepted to ICASSP 2017</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:date>2016-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06009</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Random Access Zipper: Simple, Purely-Functional Sequences</dc:title>
 <dc:creator>Headley, Kyle</dc:creator>
 <dc:creator>Hammer, Matthew A.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We introduce the Random Access Zipper (RAZ), a simple, purely-functional data
structure for editable sequences. A RAZ combines the structure of a zipper with
that of a tree: like a zipper, edits at the cursor require constant time; by
leveraging tree structure, relocating the edit cursor in the sequence requires
logarithmic time. While existing data structures provide these time bounds,
none do so with the same simplicity and brevity of code as the RAZ. The
simplicity of the RAZ provides the opportunity for more programmers to extend
the structure to their own needs, and we provide some suggestions for how to do
so.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06010</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feedback-Controlled Sequential Lasso Screening</dc:title>
 <dc:creator>Wang, Yun</dc:creator>
 <dc:creator>Chen, Xu</dc:creator>
 <dc:creator>Ramadge, Peter J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  One way to solve lasso problems when the dictionary does not fit into
available memory is to first screen the dictionary to remove unneeded features.
Prior research has shown that sequential screening methods offer the greatest
promise in this endeavor. Most existing work on sequential screening targets
the context of tuning parameter selection, where one screens and solves a
sequence of $N$ lasso problems with a fixed grid of geometrically spaced
regularization parameters. In contrast, we focus on the scenario where a target
regularization parameter has already been chosen via cross-validated model
selection, and we then need to solve many lasso instances using this fixed
value. In this context, we propose and explore a feedback controlled sequential
screening scheme. Feedback is used at each iteration to select the next problem
to be solved. This allows the sequence of problems to be adapted to the
instance presented and the number of intermediate problems to be automatically
selected. We demonstrate our feedback scheme using several datasets including a
dictionary of approximate size 100,000 by 300,000.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06012</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Vision for Online Verification-Validation</dc:title>
 <dc:creator>Hammer, Matthew A.</dc:creator>
 <dc:creator>Chang, Bor-Yuh Evan</dc:creator>
 <dc:creator>Van Horn, David</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Today's programmers face a false choice between creating software that is
extensible and software that is correct. Specifically, dynamic languages permit
software that is richly extensible (via dynamic code loading, dynamic object
extension, and various forms of reflection), and today's programmers exploit
this flexibility to &quot;bring their own language features&quot; to enrich extensible
languages (e.g., by using common JavaScript libraries). Meanwhile, such
library-based language extensions generally lack enforcement of their
abstractions, leading to programming errors that are complex to avoid and
predict.
  To offer verification for this extensible world, we propose online
verification-validation (OVV), which consists of language and VM design that
enables a &quot;phaseless&quot; approach to program analysis, in contrast to the standard
static-dynamic phase distinction. Phaseless analysis freely interposes abstract
interpretation with concrete execution, allowing analyses to use dynamic
(concrete) information to prove universal (abstract) properties about future
execution.
  In this paper, we present a conceptual overview of OVV through a motivating
example program that uses a hypothetical database library. We present a generic
semantics for OVV, and an extension to this semantics that offers a simple
gradual type system for the database library primitives. The result of
instantiating this gradual type system in an OVV setting is a checker that can
progressively type successive continuations of the program until a continuation
is fully verified. To evaluate the proposed vision of OVV for this example, we
implement the VM semantics (in Rust), and show that this design permits
progressive typing in this manner.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06014</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Symmetry of a Simple Optimization Problem in Lasso Screening</dc:title>
 <dc:creator>Wang, Yun</dc:creator>
 <dc:creator>Ramadge, Peter J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recently dictionary screening has been proposed as an effective way to
improve the computational efficiency of solving the lasso problem, which is one
of the most commonly used method for learning sparse representations. To
address today's ever increasing large dataset, effective screening relies on a
tight region bound on the solution to the dual lasso. Typical region bounds are
in the form of an intersection of a sphere and multiple half spaces. One way to
tighten the region bound is using more half spaces, which however, adds to the
overhead of solving the high dimensional optimization problem in lasso
screening. This paper reveals the interesting property that the optimization
problem only depends on the projection of features onto the subspace spanned by
the normals of the half spaces. This property converts an optimization problem
in high dimension to much lower dimension, and thus sheds light on reducing the
computation overhead of lasso screening based on tighter region bounds.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06016</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing Maximum Flow with Augmenting Electrical Flows</dc:title>
 <dc:creator>Madry, Aleksander</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present an $\tilde{O}\left(m^{\frac{10}{7}}U^{\frac{1}{7}}\right)$-time
algorithm for the maximum $s$-$t$ flow problem and the minimum $s$-$t$ cut
problem in directed graphs with $m$ arcs and largest integer capacity $U$. This
matches the running time of the
$\tilde{O}\left((mU)^{\frac{10}{7}}\right)$-time algorithm of M\k{a}dry (FOCS
2013) in the unit-capacity case, and improves over it, as well as over the
$\tilde{O}\left(m \sqrt{n} \log U\right)$-time algorithm of Lee and Sidford
(FOCS 2014), whenever $U$ is moderately large and the graph is sufficiently
sparse. By well-known reductions, this also gives similar running time
improvements for the maximum-cardinality bipartite $b$-matching problem.
  One of the advantages of our algorithm is that it is significantly simpler
than the ones presented in Madry (FOCS 2013) and Lee and Sidford (FOCS 2014).
In particular, these algorithms employ a sophisticated interior-point method
framework, while our algorithm is cast directly in the classic augmenting path
setting that almost all the combinatorial maximum flow algorithms use. At a
high level, the presented algorithm takes a primal dual approach in which each
iteration uses electrical flows computations both to find an augmenting $s$-$t$
flow in the current residual graph and to update the dual solution. We show
that by maintain certain careful coupling of these primal and dual solutions we
are always guaranteed to make significant progress.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06019</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Domain Separation Networks</dc:title>
 <dc:creator>Bousmalis, Konstantinos</dc:creator>
 <dc:creator>Trigeorgis, George</dc:creator>
 <dc:creator>Silberman, Nathan</dc:creator>
 <dc:creator>Krishnan, Dilip</dc:creator>
 <dc:creator>Erhan, Dumitru</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The cost of large scale data collection and annotation often makes the
application of machine learning algorithms to new tasks or datasets
prohibitively expensive. One approach circumventing this cost is training
models on synthetic data where annotations are provided automatically. Despite
their appeal, such models often fail to generalize from synthetic to real
images, necessitating domain adaptation algorithms to manipulate these models
before they can be successfully applied. Existing approaches focus either on
mapping representations from one domain to the other, or on learning to extract
features that are invariant to the domain from which they were extracted.
However, by focusing only on creating a mapping or shared representation
between the two domains, they ignore the individual characteristics of each
domain. We suggest that explicitly modeling what is unique to each domain can
improve a model's ability to extract domain-invariant features. Inspired by
work on private-shared component analysis, we explicitly learn to extract image
representations that are partitioned into two subspaces: one component which is
private to each domain and one which is shared across domains. Our model is
trained not only to perform the task we care about in the source domain, but
also to use the partitioned representation to reconstruct the images from both
domains. Our novel architecture results in a model that outperforms the
state-of-the-art on a range of unsupervised domain adaptation scenarios and
additionally produces visualizations of the private and shared representations
enabling interpretation of the domain adaptation process.
</dc:description>
 <dc:description>Comment: This work will be presented at NIPS 2016</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06026</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy Efficient Cooperative Network Coding with Joint Relay Scheduling
  and Power Allocation</dc:title>
 <dc:creator>Qi, Nan</dc:creator>
 <dc:creator>Xiao, Ming</dc:creator>
 <dc:creator>Tsiftsis, Theodoros A.</dc:creator>
 <dc:creator>Skoglund, Mikael</dc:creator>
 <dc:creator>Cao, Phuong L.</dc:creator>
 <dc:creator>Li, Lixin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The energy efficiency (EE) of a multi-user multi-relay system with the
maximum diversity network coding (MDNC) is studied. We explicitly find the
connection among the outage probability, energy consumption and EE and
formulate the maximizing EE problem under the outage probability constraints.
Relay scheduling (RS) and power allocation (PA) are applied to schedule the
relay states (transmitting, sleeping, \emph{etc}) and optimize the transmitting
power under the practical channel and power consumption models. Since the
optimization problem is NP-hard, to reduce computational complexity, the outage
probability is first tightly approximated to a log-convex form. Further, the EE
is converted into a subtractive form based on the fractional programming. Then
a convex mixed-integer nonlinear problem (MINLP) is eventually obtained. With a
generalized outer approximation (GOA) algorithm, RS and PA are solved in an
iterative manner. The Pareto-optimal curves between the EE and the target
outage probability show the EE gains from PA and RS. Moreover, by comparing
with the no network coding (NoNC) scenario, we conclude that with the same
number of relays, MDNC can lead to EE gains. However, if RS is implemented,
NoNC can outperform MDNC in terms of the EE when more relays are needed in the
MDNC scheme.
</dc:description>
 <dc:description>Comment: 13 pages, 7 figures, Part of this work was presented at the
  International Conference on Telecommunications (ICT), 2016</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06027</identifier>
 <datestamp>2016-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Surprisal-Driven Feedback in Recurrent Networks</dc:title>
 <dc:creator>Rocki, Kamil M</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Recurrent neural nets are widely used for predicting temporal data. Their
inherent deep feedforward structure allows learning complex sequential
patterns. It is believed that top-down feedback might be an important missing
ingredient which in theory could help disambiguate similar patterns depending
on broader context. In this paper we introduce surprisal-driven recurrent
networks, which take into account past error information when making new
predictions. This is achieved by continuously monitoring the discrepancy
between most recent predictions and the actual observations. Furthermore, we
show that it outperforms other stochastic and fully deterministic approaches on
enwik8 character level prediction task achieving 1.37 BPC on the test portion
of the text.
</dc:description>
 <dc:description>Comment: ICLR 2017 submission, fixed some equations</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:date>2016-10-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06031</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Instance Optimal Bounds for Best Arm Identification</dc:title>
 <dc:creator>Chen, Lijie</dc:creator>
 <dc:creator>Li, Jian</dc:creator>
 <dc:creator>Qiao, Mingda</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In the classical best arm identification (Best-$1$-Arm) problem, we are given
$n$ stochastic bandit arms, each associated with a reward distribution with an
unknown mean. We would like to identify the arm with the largest mean with
probability at least $1-\delta$, using as few samples as possible.
Understanding the sample complexity of Best-$1$-Arm has attracted significant
attention since the last decade. However, the exact sample complexity of the
problem is still unknown.
  Recently, Chen and Li made the gap-entropy conjecture concerning the instance
sample complexity of Best-$1$-Arm. Given an instance $I$, let $\mu_{[i]}$ be
the $i$th largest mean and $\Delta_{[i]}=\mu_{[1]}-\mu_{[i]}$ be the
corresponding gap. $H(I)=\sum_{i=2}^n\Delta_{[i]}^{-2}$ is the complexity of
the instance. The gap-entropy conjecture states that
$\Omega\left(H(I)\cdot\left(\ln\delta^{-1}+\mathsf{Ent}(I)\right)\right)$ is an
instance lower bound, where $\mathsf{Ent}(I)$ is an entropy-like term
determined by the gaps, and there is a $\delta$-correct algorithm for
Best-$1$-Arm with sample complexity
$O\left(H(I)\cdot\left(\ln\delta^{-1}+\mathsf{Ent}(I)\right)+\Delta_{[2]}^{-2}\ln\ln\Delta_{[2]}^{-1}\right)$.
If the conjecture is true, we would have a complete understanding of the
instance-wise sample complexity of Best-$1$-Arm.
  We make significant progress towards the resolution of the gap-entropy
conjecture. For the upper bound, we provide a highly nontrivial algorithm which
requires \[O\left(H(I)\cdot\left(\ln\delta^{-1}
+\mathsf{Ent}(I)\right)+\Delta_{[2]}^{-2}\ln\ln\Delta_{[2]}^{-1}\mathrm{polylog}(n,\delta^{-1})\right)\]
samples in expectation. For the lower bound, we show that for any Gaussian
Best-$1$-Arm instance with gaps of the form $2^{-k}$, any $\delta$-correct
monotone algorithm requires $\Omega\left(H(I)\cdot\left(\ln\delta^{-1} +
\mathsf{Ent}(I)\right)\right)$ samples in expectation.
</dc:description>
 <dc:description>Comment: Accepted to COLT 2017</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06033</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deterministic and Fast Randomized Test-and-Set in Optimal Space</dc:title>
 <dc:creator>Giakkoupis, George</dc:creator>
 <dc:creator>Helmi, Maryam</dc:creator>
 <dc:creator>Higham, Lisa</dc:creator>
 <dc:creator>Woelfel, Philipp</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The test-and-set object is a fundamental synchronization primitive for shared
memory systems. A test-and-set object stores a bit, initialized to 0, and
supports one operation, test&amp;set(), which sets the bit's value to 1 and returns
its previous value. This paper studies the number of atomic registers required
to implement a test-and-set object in the standard asynchronous shared memory
model with n processes. The best lower bound is log(n)-1 for obstruction-free
(Giakkoupis and Woelfel, 2012) and deadlock-free (Styer and Peterson, 1989)
implementations. Recently a deterministic obstruction-free implementation using
O(sqrt(n)) registers was presented (Giakkoupis, Helmi, Higham, and Woelfel,
2013). This paper closes the gap between these known upper and lower bounds by
presenting a deterministic obstruction-free implementation of a test-and-set
object from Theta(log n) registers of size Theta(log n) bits. We also provide a
technique to transform any deterministic obstruction-free algorithm, in which,
from any configuration, any process can finish if it runs for b steps without
interference, into a randomized wait-free algorithm for the oblivious
adversary, in which the expected step complexity is polynomial in n and b. This
transformation allows us to combine our obstruction-free algorithm with the
randomized test-and-set algorithm by Giakkoupis and Woelfel (2012), to obtain a
randomized wait-free test-and-set algorithm from Theta(log n) registers, with
expected step-complexity Theta(log* n) against the oblivious adversary.
</dc:description>
 <dc:description>Comment: The results in this paper combine and elaborate on previous work by
  the same authors that appeared in the 2015 ACM Symposium on Theory of
  Computing and the 2013 International Symposium on Distributed Computing</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06037</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lets keep it simple, Using simple architectures to outperform deeper and
  more complex architectures</dc:title>
 <dc:creator>Hasanpour, Seyyed Hossein</dc:creator>
 <dc:creator>Rouhani, Mohammad</dc:creator>
 <dc:creator>Fayyaz, Mohsen</dc:creator>
 <dc:creator>Sabokrou, Mohammad</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Major winning Convolutional Neural Networks (CNNs), such as AlexNet, VGGNet,
ResNet, GoogleNet, include tens to hundreds of millions of parameters, which
impose considerable computation and memory overhead. This limits their
practical use for training, optimization and memory efficiency. On the
contrary, light-weight architectures, being proposed to address this issue,
mainly suffer from low accuracy. These inefficiencies mostly stem from
following an ad hoc procedure. We propose a simple architecture, called
SimpleNet, based on a set of designing principles and we empirically show that
SimpleNet provides a good tradeoff between the computation/memory efficiency
and the accuracy. Our simple 13-layer architecture outperforms most of the
deeper and complex architectures to date such as VGGNet, ResNet, and GoogleNet
on several well-known benchmarks while having 2 to 25 times fewer number of
parameters and operations. This makes it very handy for embedded system or
system with computational and memory limitations. We achieved state-of-the-art
result on CIFAR10 outperforming several heavier architectures, near state of
the art on MNIST and competitive results on CIFAR100 and SVHN. Models are made
available at: https://github.com/Coderx7/SimpleNet
</dc:description>
 <dc:description>Comment: Minor corrections to acknowledgement section</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:date>2018-01-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06039</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing Zigzag Persistent Cohomology</dc:title>
 <dc:creator>Maria, Cl&#xe9;ment</dc:creator>
 <dc:creator>Oudot, Steve</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Zigzag persistent homology is a powerful generalisation of persistent
homology that allows one not only to compute persistence diagrams with less
noise and using less memory, but also to use persistence in new fields of
application. However, due to the increase in complexity of the algebraic
treatment of the theory, most algorithmic results in the field have remained of
theoretical nature.
  This article describes an efficient algorithm to compute zigzag persistence,
emphasising on its practical interest. The algorithm is a zigzag persistent
cohomology algorithm, based on the dualisation of reflections and
transpositions transformations within the zigzag sequence.
  We provide an extensive experimental study of the algorithm. We study the
algorithm along two directions. First, we compare its performance with zigzag
persistent homology algorithm and show the interest of cohomology in zigzag
persistence. Second, we illustrate the interest of zigzag persistence in
topological data analysis by comparing it to state of the art methods in the
field, specifically optimised algorithm for standard persistent homology and
sparse filtrations. We compare the memory and time complexities of the
different algorithms, as well as the quality of the output persistence
diagrams.
</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06041</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Duplex Switching in Heterogeneous Networks</dc:title>
 <dc:creator>Tang, Weijun</dc:creator>
 <dc:creator>Feng, Suili</dc:creator>
 <dc:creator>Liu, Yuan</dc:creator>
 <dc:creator>Ding, Yuehua</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, a novel hybrid-duplex scheme based on received power is
proposed for heterogeneous networks (HetNets). In the proposed scheme, the
duplex mode (half- or full-duplex) of each user is switchable according to the
received power from its serving base station (BS). The
signal-to-interference-plus-noise-ratio (SINR) and spectral efficiency are
analyzed for both downlink and uplink channels by using the tools of
\emph{inhomogeneous} Poisson point process. Furthermore, determining power
threshold for duplex mode switching is investigated for sum rate maximization,
which is formulated as a nonlinear integer programming problem and a greedy
algorithm is proposed to solve this problem. The theoretical analysis and the
proposed algorithm are evaluated by numerical simulations. Simulation results
show that the proposed hybrid-duplex scheme outperforms the half-duplex or
full-duplex HetNet schemes.
</dc:description>
 <dc:description>Comment: journal paper, double column, 13 pages, 10 figures, accepted for
  publication on IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06041</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2016.2602329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06043</identifier>
 <datestamp>2017-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context Gates for Neural Machine Translation</dc:title>
 <dc:creator>Tu, Zhaopeng</dc:creator>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:creator>Lu, Zhengdong</dc:creator>
 <dc:creator>Liu, Xiaohua</dc:creator>
 <dc:creator>Li, Hang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In neural machine translation (NMT), generation of a target word depends on
both source and target contexts. We find that source contexts have a direct
impact on the adequacy of a translation while target contexts affect the
fluency. Intuitively, generation of a content word should rely more on the
source context and generation of a functional word should rely more on the
target context. Due to the lack of effective control over the influence from
source and target contexts, conventional NMT tends to yield fluent but
inadequate translations. To address this problem, we propose context gates
which dynamically control the ratios at which source and target contexts
contribute to the generation of target words. In this way, we can enhance both
the adequacy and fluency of NMT with more careful control of the information
flow from contexts. Experiments show that our approach significantly improves
upon a standard attention-based NMT system by +2.3 BLEU points.
</dc:description>
 <dc:description>Comment: Accepted by TACL 2017</dc:description>
 <dc:date>2016-08-21</dc:date>
 <dc:date>2017-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06048</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Survey of resampling techniques for improving classification performance
  in unbalanced datasets</dc:title>
 <dc:creator>More, Ajinkya</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A number of classification problems need to deal with data imbalance between
classes. Often it is desired to have a high recall on the minority class while
maintaining a high precision on the majority class. In this paper, we review a
number of resampling techniques proposed in literature to handle unbalanced
datasets and study their effect on classification performance.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06049</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Binary Convolutional Neural Networks</dc:title>
 <dc:creator>Juefei-Xu, Felix</dc:creator>
 <dc:creator>Boddeti, Vishnu Naresh</dc:creator>
 <dc:creator>Savvides, Marios</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose local binary convolution (LBC), an efficient alternative to
convolutional layers in standard convolutional neural networks (CNN). The
design principles of LBC are motivated by local binary patterns (LBP). The LBC
layer comprises of a set of fixed sparse pre-defined binary convolutional
filters that are not updated during the training process, a non-linear
activation function and a set of learnable linear weights. The linear weights
combine the activated filter responses to approximate the corresponding
activated filter responses of a standard convolutional layer. The LBC layer
affords significant parameter savings, 9x to 169x in the number of learnable
parameters compared to a standard convolutional layer. Furthermore, the sparse
and binary nature of the weights also results in up to 9x to 169x savings in
model size compared to a standard convolutional layer. We demonstrate both
theoretically and experimentally that our local binary convolution layer is a
good approximation of a standard convolutional layer. Empirically, CNNs with
LBC layers, called local binary convolutional neural networks (LBCNN), achieves
performance parity with regular CNNs on a range of visual datasets (MNIST,
SVHN, CIFAR-10, and ImageNet) while enjoying significant computational savings.
</dc:description>
 <dc:description>Comment: To appear in CVPR 2017 as Spotlight</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2017-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06054</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PowerWalk: Scalable Personalized PageRank via Random Walks with
  Vertex-Centric Decomposition</dc:title>
 <dc:creator>Liu, Qin</dc:creator>
 <dc:creator>Li, Zhenguo</dc:creator>
 <dc:creator>Lui, John C. S.</dc:creator>
 <dc:creator>Cheng, Jiefeng</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Most methods for Personalized PageRank (PPR) precompute and store all
accurate PPR vectors, and at query time, return the ones of interest directly.
However, the storage and computation of all accurate PPR vectors can be
prohibitive for large graphs, especially in caching them in memory for
real-time online querying. In this paper, we propose a distributed framework
that strikes a better balance between offline indexing and online querying. The
offline indexing attains a fingerprint of the PPR vector of each vertex by
performing billions of &quot;short&quot; random walks in parallel across a cluster of
machines. We prove that our indexing method has an exponential convergence,
achieving the same precision with previous methods using a much smaller number
of random walks. At query time, the new PPR vector is composed by a linear
combination of related fingerprints, in a highly efficient vertex-centric
decomposition manner. Interestingly, the resulting PPR vector is much more
accurate than its offline counterpart because it actually uses more random
walks in its estimation. More importantly, we show that such decomposition for
a batch of queries can be very efficiently processed using a shared
decomposition. Our implementation, PowerWalk, takes advantage of advanced
distributed graph engines and it outperforms the state-of-the-art algorithms by
orders of magnitude. Particularly, it responses to tens of thousands of queries
on graphs with billions of edges in just a few seconds.
</dc:description>
 <dc:description>Comment: technical report of our full paper in CIKM 2016</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06054</dc:identifier>
 <dc:identifier>doi:10.1145/2983323.2983713</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06057</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MIMO Gaussian Broadcast Channels with Common, Private and Confidential
  Messages</dc:title>
 <dc:creator>Goldfeld, Ziv</dc:creator>
 <dc:creator>Permuter, Haim H.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The two-user multiple-input multiple-output (MIMO) Gaussian broadcast channel
(BC) with common, private and confidential messages is considered. The
transmitter sends a common message to both users, a confidential message to
User 1 and a private (non-confidential) message to User 2. The secrecy-capacity
region is characterized by showing that certain inner and outer bounds coincide
and that the boundary points are achieved by Gaussian inputs. The proof relies
on factorization of upper concave envelopes and a variant of dirty-paper coding
(DPC). It is shown that the entire region is exhausted by using DPC to cancel
out the signal of the non-confidential message at Receiver 1, thus making DPC
against the signal of the confidential message unnecessary. A numerical example
visualizes the secrecy-capacity results.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06065</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scaling Laws for Ergodic Spectral Efficiency in MIMO Poisson Networks</dc:title>
 <dc:creator>Lee, Junse</dc:creator>
 <dc:creator>Lee, Namyoon</dc:creator>
 <dc:creator>Baccelli, Francois</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we examine the benefits of multiple antenna communication in
random wireless networks, the topology of which is modeled by stochastic
geometry. The setting is that of the Poisson bipolar model introduced in [1],
which is a natural model for ad-hoc and device-to-device (D2D) networks. The
primary finding is that, with knowledge of channel state information between a
receiver and its associated transmitter, by zero-forcing successive
interference cancellation, and for appropriate antenna configurations, the
ergodic spectral efficiency can be made to scale linearly with both 1) the
minimum of the number of transmit and receive antennas, 2) the density of nodes
and 3) the path-loss exponent. This linear gain is achieved by using the
transmit antennas to send multiple data streams (e.g. through an open-loop
transmission method) and by exploiting the receive antennas to cancel
interference. Furthermore, when a receiver is able to learn channel state
information from a certain number of near interferers, higher scaling gains can
be achieved when using a successive interference cancellation method. A major
implication of the derived scaling laws is that spatial multiplexing
transmission methods are essential for obtaining better and eventually optimal
scaling laws in multiple antenna random wireless networks. Simulation results
support this analysis.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Information Theory</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06067</identifier>
 <datestamp>2017-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effects of Base-Station Spatial Interdependence on Interference
  Correlation and Network Performance</dc:title>
 <dc:creator>Wen, Juan</dc:creator>
 <dc:creator>Sheng, Min</dc:creator>
 <dc:creator>Huang, Kaibin</dc:creator>
 <dc:creator>Li, Jiandong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The spatial-and-temporal correlation of interference has been well studied in
Poisson networks where the interfering base stations (BSs) are independent of
each other. However, there exists spatial interdependence including attraction
and repulsion among the BSs in practical wireless networks, affecting the
interference distribution and hence the network performance. In view of this,
by modeling the network as a Poisson clustered process, we quantify the effects
of spatial interdependence among BSs on the interference correlation and
analytically prove that BS clustering increases the level of interference
correlation. In particular, it is shown that the level increases as the
attraction between the BSs increases. Furthermore, we study the effects of
spatial interdependence among BSs on network performance with a retransmission
scheme via considering heterogeneous cellular networks in which small-cell BSs
exhibit a clustered topology in practice. It is shown that the interference
correlation degrades the network performance and the degradation increases as
the attraction between BSs increases. Finally, a correlation-aware
retransmission scheme is proposed to improve the network performance by taking
advantage of the interference correlation and avoiding the blind
retransmissions.
</dc:description>
 <dc:description>Comment: 32 pages, 4 figures</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2017-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06067</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06072</identifier>
 <datestamp>2016-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uniform Generalization, Concentration, and Adaptive Learning</dc:title>
 <dc:creator>Alabdulmohsin, Ibrahim</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>68T05, 94A15</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  One fundamental goal in any learning algorithm is to mitigate its risk for
overfitting. Mathematically, this requires that the learning algorithm enjoys a
small generalization risk, which is defined either in expectation or in
probability. Both types of generalization are commonly used in the literature.
For instance, generalization in expectation has been used to analyze
algorithms, such as ridge regression and SGD, whereas generalization in
probability is used in the VC theory, among others. Recently, a third notion of
generalization has been studied, called uniform generalization, which requires
that the generalization risk vanishes uniformly in expectation across all
bounded parametric losses. It has been shown that uniform generalization is, in
fact, equivalent to an information-theoretic stability constraint, and that it
recovers classical results in learning theory. It is achievable under various
settings, such as sample compression schemes, finite hypothesis spaces, finite
domains, and differential privacy. However, the relationship between uniform
generalization and concentration remained unknown. In this paper, we answer
this question by proving that, while a generalization in expectation does not
imply a generalization in probability, a uniform generalization in expectation
does imply concentration. We establish a chain rule for the uniform
generalization risk of the composition of hypotheses and use it to derive a
large deviation bound. Finally, we prove that the bound is tight.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2016-10-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06079</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A novel framework for assessing metadata quality in epidemiological and
  public health research settings</dc:title>
 <dc:creator>McMahon, Christiana</dc:creator>
 <dc:creator>Denaxas, Spiros</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Metadata are critical in epidemiological and public health research. However,
a lack of biomedical metadata quality frameworks and limited awareness of the
implications of poor quality metadata renders data analyses problematic. In
this study, we created and evaluated a novel framework to assess metadata
quality of epidemiological and public health research datasets. We performed a
literature review and surveyed stakeholders to enhance our understanding of
biomedical metadata quality assessment. The review identified 11 studies and
nine quality dimensions; none of which were specifically aimed at biomedical
metadata. 96 individuals completed the survey; of those who submitted data,
most only assessed metadata quality sometimes, and eight did not at all. Our
framework has four sections: a) general information; b) tools and technologies;
c) usability; and d) management and curation. We evaluated the framework using
three test cases and sought expert feedback. The framework can assess
biomedical metadata quality systematically and robustly.
</dc:description>
 <dc:description>Comment: American Medical Informatics Association (AMIA) Joint Summits on
  Translational Science 2015</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06079</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06080</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Worst case QC-MDPC decoder for McEliece cryptosystem</dc:title>
 <dc:creator>Chaulet, Julia</dc:creator>
 <dc:creator>Sendrier, Nicolas</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  McEliece encryption scheme which enjoys relatively small key sizes as well as
a security reduction to hard problems of coding theory. Furthermore, it remains
secure against a quantum adversary and is very well suited to low cost
implementations on embedded devices.
  Decoding MDPC codes is achieved with the (iterative) bit flipping algorithm,
as for LDPC codes. Variable time decoders might leak some information on the
code structure (that is on the sparse parity check equations) and must be
avoided. A constant time decoder is easy to emulate, but its running time
depends on the worst case rather than on the average case. So far
implementations were focused on minimizing the average cost. We show that the
tuning of the algorithm is not the same to reduce the maximal number of
iterations as for reducing the average cost. This provides some indications on
how to engineer the QC-MDPC-McEliece scheme to resist a timing side-channel
attack.
</dc:description>
 <dc:description>Comment: 5 pages, conference ISIT 2016</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06080</dc:identifier>
 <dc:identifier>doi:10.1109/ISIT.2016.7541522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06084</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Propositional dynamic logic with Belnapian truth values</dc:title>
 <dc:creator>Sedl&#xe1;r, Igor</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  We introduce BPDL, a combination of propositional dynamic logic PDL with the
basic four-valued modal logic BK studied by Odintsov and Wansing (`Modal logics
with Belnapian truth values', J. Appl. Non-Class. Log. 20, 279--301 (2010)). We
modify the standard arguments based on canonical models and filtration to suit
the four-valued context and prove weak completeness and decidability of BPDL.
</dc:description>
 <dc:description>Comment: To appear in the Proceedings of Advances in Modal Logic 2016</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06091</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the queue-number of graphs with bounded tree-width</dc:title>
 <dc:creator>Wiechert, Veit</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>68R10</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:description>  A queue layout of a graph consists of a linear order on the vertices and an
assignment of the edges to queues, such that no two edges in a single queue are
nested. The minimum number of queues needed in a queue layout of a graph is
called its queue-number.
  We show that for each $k\geq1$, graphs with tree-width at most $k$ have
queue-number at most $2^k-1$. This improves upon double exponential upper
bounds due to Dujmovi\'c et al. and Giacomo et al. As a consequence we obtain
that these graphs have track-number at most $2^{O(k^2)}$.
  We complement these results by a construction of $k$-trees that have
queue-number at least $k+1$. Already in the case $k=2$ this is an improvement
to existing results and solves a problem of Rengarajan and Veni Madhavan,
namely, that the maximal queue-number of $2$-trees is equal to $3$.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06098</identifier>
 <datestamp>2017-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Preambles With Low Out of Band Radiation for Channel Estimation</dc:title>
 <dc:creator>Ghatak, Gourab</dc:creator>
 <dc:creator>Matth&#xe9;, Maximilian</dc:creator>
 <dc:creator>Banerjee, Adrish</dc:creator>
 <dc:creator>Fettweis, Gerhard P.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate preamble designs for channel estimation, that
jointly address the estimation efficiency in terms of MSE of the channel
estimates, and the OOB radiation of the transmit preambles. We provide two
novel design techniques, based on a convex optimization problem, to obtain
optimal preambles for a single carrier and provide a juxtaposition based method
to extend their application to multi-carrier systems. The obtained preambles
are shown to have 10 dB to 35 dB lower OOB radiation than the existing preamble
based estimation techniques. We also show the fundamental trade-off between the
estimation efficiency and the OOB radiation and highlight that the improved OOB
performance comes at a cost of increased estimation error. Finally, as a case
study, the estimated channel values are used in equalization of a MIMO GFDM
system that is aimed for transmit diversity.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2017-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06098</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06103</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating Maximum Error Impact in Dynamic Data-driven Applications for
  Resource-aware Adaption of Software-based Fault-Tolerance</dc:title>
 <dc:creator>B&#xf6;nninghoff, Bj&#xf6;rn</dc:creator>
 <dc:creator>Schirmeier, Horst</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The rise of transient faults in modern hardware requires system designers to
consider errors occurring at runtime. Both hardware- and software-based error
handling must be deployed to meet application reliability requirements. The
level of required reliability can vary for system components and depend on
input and state, so that a selective use of resilience methods is advised,
especially for resource-constrained platforms as found in embedded systems. If
an error occurring at runtime can be classified as having negligible or
tolerable impact, less effort can be spent on correcting it. As the actual
impact of an error is often dependent on the state of a system at time of
occurrence, it can not be determined precisely for highly dynamic workloads in
data-driven applications. We present a concept to estimate error propagation in
sets of tasks with variable data dependencies. This allows for a coarse grained
analysis of the impact a failed task may have on the overall output. As an
application example, we demonstrate our method for a typical dynamic embedded
application, namely a decoder for the H.264 video format.
</dc:description>
 <dc:description>Comment: Editor: Gilles Tredan. 12th European Dependable Computing Conference
  (EDCC 2016), September 5-9, 2016, Gothenburg, Sweden. Fast Abstracts
  Proceedings- EDCC 2016</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06108</identifier>
 <datestamp>2017-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SensibleSleep: A Bayesian Model for Learning Sleep Patterns from
  Smartphone Events</dc:title>
 <dc:creator>Cuttone, Andrea</dc:creator>
 <dc:creator>B&#xe6;kgaard, Per</dc:creator>
 <dc:creator>Sekara, Vedran</dc:creator>
 <dc:creator>Jonsson, H&#xe5;kan</dc:creator>
 <dc:creator>Larsen, Jakob Eg</dc:creator>
 <dc:creator>Lehmann, Sune</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  We propose a Bayesian model for extracting sleep patterns from smartphone
events. Our method is able to identify individuals' daily sleep periods and
their evolution over time, and provides an estimation of the probability of
sleep and wake transitions. The model is fitted to more than 400 participants
from two different datasets, and we verify the results against ground truth
from dedicated armband sleep trackers. We show that the model is able to
produce reliable sleep estimates with an accuracy of 0.89, both at the
individual and at the collective level. Moreover the Bayesian model is able to
quantify uncertainty and encode prior knowledge about sleep patterns. Compared
with existing smartphone-based systems, our method requires only screen on/off
events, and is therefore much less intrusive in terms of privacy and more
battery-efficient.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06108</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0169901</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06111</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Incremental Parser for Abstract Meaning Representation</dc:title>
 <dc:creator>Damonte, Marco</dc:creator>
 <dc:creator>Cohen, Shay B.</dc:creator>
 <dc:creator>Satta, Giorgio</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Meaning Representation (AMR) is a semantic representation for natural
language that embeds annotations related to traditional tasks such as named
entity recognition, semantic role labeling, word sense disambiguation and
co-reference resolution. We describe a transition-based parser for AMR that
parses sentences left-to-right, in linear time. We further propose a test-suite
that assesses specific subtasks that are helpful in comparing AMR parsers, and
show that our parser is competitive with the state of the art on the LDC2015E86
dataset and that it outperforms state-of-the-art parsers for recovering named
entities and handling polarity.
</dc:description>
 <dc:description>Comment: EACL 2017</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06111</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06113</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the orthogonal rank of Cayley graphs and impossibility of quantum
  round elimination</dc:title>
 <dc:creator>Bri&#xeb;t, Jop</dc:creator>
 <dc:creator>Zuiddam, Jeroen</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>94A05, 05C15, 90C22</dc:subject>
 <dc:description>  After Bob sends Alice a bit, she responds with a lengthy reply. At the cost
of a factor of two in the total communication, Alice could just as well have
given the two possible replies without listening and have Bob select which
applies to him. Motivated by a conjecture stating that this form of &quot;round
elimination&quot; is impossible in exact quantum communication complexity, we study
the orthogonal rank and a symmetric variant thereof for a certain family of
Cayley graphs. The orthogonal rank of a graph is the smallest number $d$ for
which one can label each vertex with a nonzero $d$-dimensional complex vector
such that adjacent vertices receive orthogonal vectors.
  We show an exp$(n)$ lower bound on the orthogonal rank of the graph on
$\{0,1\}^n$ in which two strings are adjacent if they have Hamming distance at
least $n/2$. In combination with previous work, this implies an affirmative
answer to the above conjecture.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06113</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06117</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase Retrieval From the Magnitudes of Affine Linear Measurements</dc:title>
 <dc:creator>Gao, Bing</dc:creator>
 <dc:creator>Sun, Qiyu</dc:creator>
 <dc:creator>Wang, Yang</dc:creator>
 <dc:creator>Xu, Zhiqiang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider the phase retrieval problem in which one aims to
recover a signal from the magnitudes of affine measurements. Let $\{{\mathbf
a}_j\}_{j=1}^m \subset {\mathbb H}^d$ and ${\mathbf b}=(b_1, \ldots,
b_m)^\top\in{\mathbb H}^m$, where ${\mathbb H}={\mathbb R}$ or ${\mathbb C}$.
We say $\{{\mathbf a}_j\}_{j=1}^m$ and $\mathbf b$ are affine phase retrievable
for ${\mathbb H}^d$ if any ${\mathbf x}\in{\mathbb H}^d$ can be recovered from
the magnitudes of the affine measurements $\{|&lt;{\mathbf a}_j,{\mathbf
x}&gt;+b_j|,\, 1\leq j\leq m\}$. We develop general framework for affine phase
retrieval and prove necessary and sufficient conditions for $\{{\mathbf
a}_j\}_{j=1}^m$ and $\mathbf b$ to be affine phase retrievable. We establish
results on minimal measurements and generic measurements for affine phase
retrieval as well as on sparse affine phase retrieval. In particular, we also
highlight some notable differences between affine phase retrieval and the
standard phase retrieval in which one aims to recover a signal $\mathbf x$ from
the magnitudes of its linear measurements. In standard phase retrieval, one can
only recover $\mathbf x$ up to a unimodular constant, while affine phase
retrieval removes this ambiguity. We prove that unlike standard phase
retrieval, the affine phase retrievable measurements $\{{\mathbf
a}_j\}_{j=1}^m$ and $\mathbf b$ do not form an open set in ${\mathbb
H}^{m\times d}\times {\mathbb H}^m$. Also in the complex setting, the standard
phase retrieval requires $4d-O(\log_2d)$ measurements, while the affine phase
retrieval only needs $m=3d$ measurements.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06128</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Subcarrier and CPU Time Allocation for Mobile Edge Computing</dc:title>
 <dc:creator>Yu, Yinghao</dc:creator>
 <dc:creator>Zhang, Jun</dc:creator>
 <dc:creator>Letaief, Khaled Ben</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In mobile edge computing systems, mobile devices can offload
compute-intensive tasks to a nearby cloudlet,so as to save energy and extend
battery life. Unlike a fully-fledged cloud, a cloudlet is a small-scale
datacenter deployed at a wireless access point, and thus is highly constrained
by both radio and compute resources. We show in this paper that separately
optimizing the allocation of either compute or radio resource, as most existing
works did, is highly suboptimal: the congestion of compute resource leads to
the waste of radio resource, and vice versa. To address this problem, we
propose a joint scheduling algorithm that allocates both radio and compute
resources coordinately. Specifically, we consider a cloudlet in an Orthogonal
Frequency-Division Multiplexing Access (OFDMA) system with multiple mobile
devices, where we study subcarrier allocation for task offloading and CPU time
allocation for task execution in the cloudlet. Simulation results show that the
proposed algorithm significantly outperforms per-resource optimization,
accommodating more offloading requests while achieving salient energy saving.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, conference</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06130</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monadic Datalog Containment on Trees Using the Descendant-Axis</dc:title>
 <dc:creator>Frochaux, Andr&#xe9;</dc:creator>
 <dc:creator>Schweikardt, Nicole</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In their AMW14-paper, Frochaux, Grohe, and Schweikardt showed that the query
containment problem for monadic datalog on finite unranked labeled trees is
Exptime-complete when (a) considering unordered trees using the child-axis, and
when (b) considering ordered trees using the axes firstchild, nextsibling, and
child. Furthermore, when allowing to use also the descendant-axis, the query
containment problem was shown to be solvable in 2-fold exponential time, but it
remained open to determine the problems exact complexity in presence of the
descendant-axis. The present paper closes this gap by showing that, in the
presence of the descendant-axis, the problem is 2Exptime-hard.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06130</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06132</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reconstructing Neural Parameters and Synapses of arbitrary
  interconnected Neurons from their Simulated Spiking Activity</dc:title>
 <dc:creator>Fischer, J.</dc:creator>
 <dc:creator>Manoonpong, P.</dc:creator>
 <dc:creator>Lackner, S.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  To understand the behavior of a neural circuit it is a presupposition that we
have a model of the dynamical system describing this circuit. This model is
determined by several parameters, including not only the synaptic weights, but
also the parameters of each neuron. Existing works mainly concentrate on either
the synaptic weights or the neural parameters. In this paper we present an
algorithm to reconstruct all parameters including the synaptic weights of a
spiking neuron model. The model based on works of Eugene M. Izhikevich
(Izhikevich 2007) consists of two differential equations and covers different
types of cortical neurons. It combines the dynamical properties of
Hodgkin-Huxley-type dynamics with a high computational efficiency. The
presented algorithm uses the recordings of the corresponding membrane
potentials of the model for the reconstruction and consists of two main
components. The first component is a rank based Genetic Algorithm (GA) which is
used to find the neural parameters of the model. The second one is a Least Mean
Squares approach which computes the synaptic weights of all interconnected
neurons by minimizing the squared error between the calculated and the measured
membrane potentials for each time step. In preparation for the reconstruction
of the neural parameters and of the synaptic weights from real measured
membrane potentials, promising results based on simulated data generated with a
randomly parametrized Izhikevich model are presented. The reconstruction does
not only converge to a global minimum of neural parameters, but also
approximates the synaptic weights with high precision.
</dc:description>
 <dc:description>Comment: 6 pages, 7 figures</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06133</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Combined Dependability and Security Approach for Third Party Software
  in Space Systems</dc:title>
 <dc:creator>Rico, David Escorial</dc:creator>
 <dc:creator>Hann, Mark</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Software components for on-board architectures in the space domain are
increasingly reliant on Commercial Off-The-Shelf (COTS), Open Source (OSS) or
other third party software products. However, these software components often
have not been built with mission critical requirements in mind. Development
project teams incorporating these products have limited knowledge of or control
over the processes applied during the design, implementation, testing and
maintenance of selected COTS/OSS software products. These constraints generate
uncertainty of potential software induced failures. Moreover, the lack of
information regarding security vulnerabilities increases the risks of their
usage, since their exploitation might lead to undesired behaviour of the
software and therefore to a system failure. The purpose of this paper is to
present a combined approach that takes into account reliability and security
enhancements for third party software, based on Time-Space Partitioning and
Multiple Levels of Security.
</dc:description>
 <dc:description>Comment: Editor: Gilles Tredan. 12th European Dependable Computing Conference
  (EDCC 2016), September 5-9, 2016, Gothenburg, Sweden. Fast Abstracts
  Proceedings- EDCC 2016</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06134</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Median-Based Generation of Synthetic Speech Durations using a
  Non-Parametric Approach</dc:title>
 <dc:creator>Ronanki, Srikanth</dc:creator>
 <dc:creator>Watts, Oliver</dc:creator>
 <dc:creator>King, Simon</dc:creator>
 <dc:creator>Henter, Gustav Eje</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper proposes a new approach to duration modelling for statistical
parametric speech synthesis in which a recurrent statistical model is trained
to output a phone transition probability at each timestep (acoustic frame).
Unlike conventional approaches to duration modelling -- which assume that
duration distributions have a particular form (e.g., a Gaussian) and use the
mean of that distribution for synthesis -- our approach can in principle model
any distribution supported on the non-negative integers. Generation from this
model can be performed in many ways; here we consider output generation based
on the median predicted duration. The median is more typical (more probable)
than the conventional mean duration, is robust to training-data irregularities,
and enables incremental generation. Furthermore, a frame-level approach to
duration prediction is consistent with a longer-term goal of modelling
durations and acoustic features together. Results indicate that the proposed
method is competitive with baseline approaches in approximating the median
duration of held-out natural speech.
</dc:description>
 <dc:description>Comment: 7 pages, 1 figure -- Accepted for presentation at IEEE Workshop on
  Spoken Language Technology (SLT 2016)</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06135</identifier>
 <datestamp>2017-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resolution of ranking hierarchies in directed networks</dc:title>
 <dc:creator>Letizia, Elisa</dc:creator>
 <dc:creator>Barucca, Paolo</dc:creator>
 <dc:creator>Lillo, Fabrizio</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Identifying hierarchies and rankings of nodes in directed graphs is
fundamental in many applications such as social network analysis, biology,
economics, and finance. A recently proposed method identifies the hierarchy by
finding the ordered partition of nodes which minimises a score function, termed
agony. This function penalises the links violating the hierarchy in a way
depending on the strength of the violation. To investigate the resolution of
ranking hierarchies we introduce an ensemble of random graphs, the Ranked
Stochastic Block Model. We find that agony may fail to identify hierarchies
when the structure is not strong enough and the size of the classes is small
with respect to the whole network. We analytically characterise the resolution
threshold and we show that an iterated version of agony can partly overcome
this resolution limit.
</dc:description>
 <dc:description>Comment: 27 pages, 9 figures</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2017-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06135</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06136</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Linear Kernel for Finding Square Roots of Almost Planar Graphs</dc:title>
 <dc:creator>Golovach, Petr A.</dc:creator>
 <dc:creator>Kratsch, Dieter</dc:creator>
 <dc:creator>Paulusma, Dani&#xeb;l</dc:creator>
 <dc:creator>Stewart, Anthony</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A graph H is a square root of a graph G if G can be obtained from H by the
addition of edges between any two vertices in H that are of distance 2 from
each other. The Square Root problem is that of deciding whether a given graph
admits a square root. We consider this problem for planar graphs in the context
of the &quot;distance from triviality&quot; framework. For an integer k, a planar+kv
graph (or k-apex graph) is a graph that can be made planar by the removal of at
most k vertices. We prove that a generalization of Square Root, in which some
edges are prescribed to be either in or out of any solution, has a kernel of
size O(k) for planar+kv graphs, when parameterized by k. Our result is based on
a new edge reduction rule which, as we shall also show, has a wider
applicability for the Square Root problem.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06142</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Squares of Low Maximum Degree</dc:title>
 <dc:creator>Cochefert, Manfred</dc:creator>
 <dc:creator>Couturier, Jean-Fran&#xe7;ois</dc:creator>
 <dc:creator>Golovach, Petr A.</dc:creator>
 <dc:creator>Kratsch, Dieter</dc:creator>
 <dc:creator>Paulusma, Dani&#xeb;l</dc:creator>
 <dc:creator>Stewart, Anthony</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A graph H is a square root of a graph G if G can be obtained from H by adding
an edge between any two vertices in H that are of distance 2. The Square Root
problem is that of deciding whether a given graph admits a square root. This
problem is only known to be NP-complete for chordal graphs and polynomial-time
solvable for non-trivial minor-closed graph classes and a very limited number
of other graph classes. We prove that Square Root is O(n)-time solvable for
graphs of maximum degree 5 and O(n^4)-time solvable for graphs of maximum
degree at most 6.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06142</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06144</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DETOx: Towards Optimal Software-based Soft-Error Detector Configurations</dc:title>
 <dc:creator>Lenz, Michael</dc:creator>
 <dc:creator>Schirmeier, Horst</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Application developers often place executable assertions -- equipped with
program-specific predicates -- in their system, targeting programming errors.
However, these detectors can detect data errors resulting from transient
hardware faults in main memory as well. But while an assertion reduces silent
data corruptions (SDCs) in the program state they check, they add runtime to
the target program that increases the attack surface for the remaining state.
This article outlines an approach to find an optimal subset of assertions that
minimizes the SDC count, without the need to run fault-injection experiments
for every possible assertion subset.
</dc:description>
 <dc:description>Comment: Editor: Gilles Tredan. 12th European Dependable Computing Conference
  (EDCC 2016), September 5-9, 2016, Gothenburg, Sweden. Fast Abstracts
  Proceedings -- EDCC 2016</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06148</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple objects tracking in surveillance video using color and Hu
  moments</dc:title>
 <dc:creator>M, Chandrajit</dc:creator>
 <dc:creator>R, Girisha</dc:creator>
 <dc:creator>T, Vasudev</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Multiple objects tracking finds its applications in many high level vision
analysis like object behaviour interpretation and gait recognition. In this
paper, a feature based method to track the multiple moving objects in
surveillance video sequence is proposed. Object tracking is done by extracting
the color and Hu moments features from the motion segmented object blob and
establishing the association of objects in the successive frames of the video
sequence based on Chi-Square dissimilarity measure and nearest neighbor
classifier. The benchmark IEEE PETS and IEEE Change Detection datasets has been
used to show the robustness of the proposed method. The proposed method is
assessed quantitatively using the precision and recall accuracy metrics.
Further, comparative evaluation with related works has been carried out to
exhibit the efficacy of the proposed method.
</dc:description>
 <dc:description>Comment: 13 pages, Signal &amp; Image Processing : An International Journal
  (SIPIJ) Vol.7, No.3, June 2016</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06148</dc:identifier>
 <dc:identifier>doi:10.5121/sipij.2016.7302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06154</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Sensor Prognostics using an Unsupervised Health Index based on
  LSTM Encoder-Decoder</dc:title>
 <dc:creator>Malhotra, Pankaj</dc:creator>
 <dc:creator>TV, Vishnu</dc:creator>
 <dc:creator>Ramakrishnan, Anusha</dc:creator>
 <dc:creator>Anand, Gaurangi</dc:creator>
 <dc:creator>Vig, Lovekesh</dc:creator>
 <dc:creator>Agarwal, Puneet</dc:creator>
 <dc:creator>Shroff, Gautam</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Many approaches for estimation of Remaining Useful Life (RUL) of a machine,
using its operational sensor data, make assumptions about how a system degrades
or a fault evolves, e.g., exponential degradation. However, in many domains
degradation may not follow a pattern. We propose a Long Short Term Memory based
Encoder-Decoder (LSTM-ED) scheme to obtain an unsupervised health index (HI)
for a system using multi-sensor time-series data. LSTM-ED is trained to
reconstruct the time-series corresponding to healthy state of a system. The
reconstruction error is used to compute HI which is then used for RUL
estimation. We evaluate our approach on publicly available Turbofan Engine and
Milling Machine datasets. We also present results on a real-world industry
dataset from a pulverizer mill where we find significant correlation between
LSTM-ED based HI and maintenance costs.
</dc:description>
 <dc:description>Comment: Presented at 1st ACM SIGKDD Workshop on Machine Learning for
  Prognostics and Health Management, San Francisco, CA, USA, 2016. 10 pages</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06166</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Demand Side Management by Distributed and Secured Energy
  Commitment Framework</dc:title>
 <dc:creator>Chakraborty, Shantanu</dc:creator>
 <dc:creator>Okabe, Toshiya</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  This paper introduces a demand-side distributed and secured energy commitment
framework and operations for a Power Producer and Supplier (PPS) in deregulated
environment. Due to the diversity of geographical location as well as
customers' energy profile coupled with high number of customers, managing
energy transactions and resulting energy exchanges are challenging for a PPS.
The envisioned PPS maintains several aggregators (e.g. Microgrids), named as
Sub Service Provider (SSP) that manage customers/subscribers under their
domains. The SSPs act as agents that perform local energy matching (inside
their domains) and distributed energy matching within SSPs to determine the
energy commitment. The goal of the distributed energy matching is to reduce the
involvement of External Energy Supplier (e.g. Utility) while providing a
platform to demand side players to be a part of energy transaction. A
distributed assignment problem is designed that requires minimum and aggregated
information exchange (hence, secured) and solved by Linear Programming (LP)
that provides the distributed matching decision. The communicative burden among
SSPs due to the exchange of energy information is reduced by applying an
adaptive coalition formation method. The simulations are conducted by
implementing a synchronous distributed matching algorithm while showing the
effectiveness of the proposed framework.
</dc:description>
 <dc:description>Comment: 10 Pages; 13 Figures</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06166</dc:identifier>
 <dc:identifier>doi:10.1049/iet-gtd.2016.0413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06168</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Spectrum and Infrastructure Sharing in Multi-Operator Cellular
  Networks</dc:title>
 <dc:creator>Wang, Shanshan</dc:creator>
 <dc:creator>Samdanis, Konstantinos</dc:creator>
 <dc:creator>Perez, Xavier Costa</dc:creator>
 <dc:creator>Di Renzo, Marco</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we introduce a mathematical framework for analyzing and
optimizing multi-operator cellular networks that are allowed to share spectrum
licenses and infrastructure elements. The proposed approach exploits stochastic
geometry for modeling the locations of cellular base stations and for computing
the aggregate average rate. The trade-offs that emerge from sharing spectrum
frequencies and cellular base stations are quantified and discussed.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06169</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effective and Complete Discovery of Order Dependencies via Set-based
  Axiomatization</dc:title>
 <dc:creator>Szlichta, Jaroslaw</dc:creator>
 <dc:creator>Godfrey, Parke</dc:creator>
 <dc:creator>Golab, Lukasz</dc:creator>
 <dc:creator>Kargar, Mehdi</dc:creator>
 <dc:creator>Srivastava, Divesh</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Integrity constraints (ICs) provide a valuable tool for expressing and
enforcing application semantics. However, formulating constraints manually
requires domain expertise, is prone to human errors, and may be excessively
time consuming, especially on large datasets. Hence, proposals for automatic
discovery have been made for some classes of ICs, such as functional
dependencies (FDs), and recently, order dependencies (ODs). ODs properly
subsume FDs, as they can additionally express business rules involving order;
e.g., an employee never has a higher salary while paying lower taxes compared
with another employee.
  We address the limitations of prior work on OD discovery which has factorial
complexity in the number of attributes, is incomplete (i.e., it does not
discover valid ODs that cannot be inferred from the ones found) and is not
concise (i.e., it can result in &quot;redundant&quot; discovery and overly large
discovery sets). We improve significantly on complexity, offer completeness,
and define a compact canonical form. This is based on a novel polynomial
mapping to a canonical form for ODs, and a sound and complete set of axioms
(inference rules) for canonical ODs. This allows us to develop an efficient
set-containment, lattice-driven OD discovery algorithm that uses the inference
rules to prune the search space. Our algorithm has exponential worst-case time
complexity in the number of attributes and linear complexity in the number of
tuples. We prove that it produces a complete, minimal set of ODs (i.e., minimal
with regards to the canonical representation). Finally, using real and
synthetic datasets, we experimentally show orders-of-magnitude performance
improvements over the current state-of-the-art algorithm and demonstrate
effectiveness of our techniques.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06171</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MISO: An intermediate language to express parallel and dependable
  programs</dc:title>
 <dc:creator>Fonseca, Alcides</dc:creator>
 <dc:creator>Barbosa, Raul</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  One way to write fast programs is to explore the potential parallelism and
take advantage of the high number of cores available in microprocessors. This
can be achieved by manually specifying which code executes on which thread, by
using compiler parallelization hints (such as OpenMP or Cilk), or by using a
parallel programming language (such as X10, Chapel or Aeminium. Regardless of
the approach, all of these programs are compiled to an intermediate lower-level
language that is sequential, thus preventing the backend compiler from
optimizing the program and observing its parallel nature. This paper presents
MISO, an intermediate language that expresses the parallel nature of programs
and that can be targeted by front-end compilers. The language defines 'cells',
which are composed by a state and a transition function from one state to the
next. This language can express both sequential and parallel programs, and
provides information for a backend- compiler to generate efficient parallel
programs. Moreover, MISO can be used to automatically add redundancy to a
program, by replicating the state or by taking advantage of different processor
cores, in order to provide fault tolerance for programs running on unreliable
hardware.
</dc:description>
 <dc:description>Comment: Editor: Gilles Tredan. 12th European Dependable Computing Conference
  (EDCC 2016), September 5-9, 2016, Gothenburg, Sweden. Fast Abstracts
  Proceedings- EDCC 2016</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06171</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06172</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Origin of Samples: Attribution of Output to a Particular
  Algorithm</dc:title>
 <dc:creator>Yampolskiy, Roman V.</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  With unprecedented advances in genetic engineering we are starting to see
progressively more original examples of synthetic life. As such organisms
become more common it is desirable to be able to distinguish between natural
and artificial life forms. In this paper, we present this challenge as a
generalized version of Darwin's original problem, which he so brilliantly
addressed in On the Origin of Species. After formalizing the problem of
determining origin of samples we demonstrate that the problem is in fact
unsolvable, in the general case, if computational resources of considered
originator algorithms have not been limited and priors for such algorithms are
known to be equal. Our results should be of interest to astrobiologists and
scientists interested in producing a more complete theory of life, as well as
to AI-Safety researchers.
</dc:description>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06172</dc:identifier>
 <dc:identifier>Phys. Scr. 92 (2017)</dc:identifier>
 <dc:identifier>doi:10.1088/0031-8949/92/1/013002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06175</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effectiveness of greedily collecting items in open world games</dc:title>
 <dc:creator>Gajduk, Andrej</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Since Pokemon Go sent millions on the quest of collecting virtual monsters,
an important question has been on the minds of many people: Is going after the
closest item first a time-and-cost-effective way to play? Here, we show that
this is in fact a good strategy which performs on average only 7% worse than
the best possible solution in terms of the total distance traveled to gather
all the items. Even when accounting for errors due to the inability of people
to accurately measure distances by eye, the performance only goes down to 16%
of the optimal solution.
</dc:description>
 <dc:description>Comment: 3 pages, 4 figures</dc:description>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06183</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling Cellular Networks with Full Duplex D2D Communication: A
  Stochastic Geometry Approach</dc:title>
 <dc:creator>Ali, Konpal Shaukat</dc:creator>
 <dc:creator>ElSawy, Hesham</dc:creator>
 <dc:creator>Alouini, Mohamed-Slim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Full-duplex (FD) communication is optimistically promoted to double the
spectral efficiency if sufficient self-interference cancellation (SIC) is
achieved. However, this is not true when deploying FD-communication in a
large-scale setup due to the induced mutual interference. Therefore, a
large-scale study is necessary to draw legitimate conclusions about gains
associated with FD-communication. This paper studies the FD operation for
underlay device-to-device (D2D) communication sharing the uplink resources in
cellular networks. We propose a disjoint fine-tuned selection criterion for the
D2D and FD modes of operation. Then, we develop a tractable analytical
paradigm, based on stochastic geometry, to calculate the outage probability and
rate for cellular and D2D users. The results reveal that even in the case of
perfect SIC, due to the increased interference injected to the network by
FD-D2D communication, having all proximity UEs transmit in FD-D2D is not
beneficial for the network. However, if the system parameters are carefully
tuned, non-trivial network spectral-efficiency gains (64 shown) can be
harvested. We also investigate the effects of imperfect SIC and D2D-link
distance distribution on the harvested FD gains.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06183</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06192</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Continuous Relaxations for Dense CRF</dc:title>
 <dc:creator>Desmaison, Alban</dc:creator>
 <dc:creator>Bunel, Rudy</dc:creator>
 <dc:creator>Kohli, Pushmeet</dc:creator>
 <dc:creator>Torr, Philip H. S.</dc:creator>
 <dc:creator>Kumar, M. Pawan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Dense conditional random fields (CRF) with Gaussian pairwise potentials have
emerged as a popular framework for several computer vision applications such as
stereo correspondence and semantic segmentation. By modeling long-range
interactions, dense CRFs provide a more detailed labelling compared to their
sparse counterparts. Variational inference in these dense models is performed
using a filtering-based mean-field algorithm in order to obtain a
fully-factorized distribution minimising the Kullback-Leibler divergence to the
true distribution. In contrast to the continuous relaxation-based energy
minimisation algorithms used for sparse CRFs, the mean-field algorithm fails to
provide strong theoretical guarantees on the quality of its solutions. To
address this deficiency, we show that it is possible to use the same filtering
approach to speed-up the optimisation of several continuous relaxations.
Specifically, we solve a convex quadratic programming (QP) relaxation using the
efficient Frank-Wolfe algorithm. This also allows us to solve
difference-of-convex relaxations via the iterative concave-convex procedure
where each iteration requires solving a convex QP. Finally, we develop a novel
divide-and-conquer method to compute the subgradients of a linear programming
relaxation that provides the best theoretical bounds for energy minimisation.
We demonstrate the advantage of continuous relaxations over the widely used
mean-field algorithm on publicly available datasets.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06192</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06196</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Benchmark Models for Mesoscale Structure in Multilayer
  Networks</dc:title>
 <dc:creator>Bazzi, Marya</dc:creator>
 <dc:creator>Jeub, Lucas G. S.</dc:creator>
 <dc:creator>Arenas, Alex</dc:creator>
 <dc:creator>Howison, Sam D.</dc:creator>
 <dc:creator>Porter, Mason A.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  Multilayer networks allow one to represent diverse and interdependent
connectivity patterns --- e.g., time-dependence, multiple subsystems, or both
--- that arise in many applications and which are difficult or awkward to
incorporate into standard network representations. In the study of multilayer
networks, it is important to investigate &quot;mesoscale&quot; (i.e., intermediate-scale)
structures, such as dense sets of nodes known as &quot;communities&quot; that are
connected sparsely to each other, to discover network features that are not
apparent at the microscale or the macroscale. A variety of methods and
algorithms are available to identify communities in multilayer networks, but
they differ in their definitions and/or assumptions of what constitutes a
community, and many scalable algorithms provide approximate solutions with
little or no theoretical guarantee on the quality of their approximations.
Consequently, it is crucial to develop generative models of networks to use as
a common test of community-detection tools. In the present paper, we develop a
family of benchmarks for detecting mesoscale structures in multilayer networks
by introducing a generative model that can explicitly incorporate dependency
structure between layers. Our benchmark provides a standardized set of null
models, together with an associated set of principles from which they are
derived, for studies of mesoscale structures in multilayer networks. We discuss
the parameters and properties of our generative model, and we illustrate its
use by comparing a variety of community-detection methods.
</dc:description>
 <dc:description>Comment: 22 pages, 10 figures (some with multiple parts), 2 algorithm floats</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2016-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06197</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CrowdNet: A Deep Convolutional Network for Dense Crowd Counting</dc:title>
 <dc:creator>Boominathan, Lokesh</dc:creator>
 <dc:creator>Kruthiventi, Srinivas S S</dc:creator>
 <dc:creator>Babu, R. Venkatesh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Our work proposes a novel deep learning framework for estimating crowd
density from static images of highly dense crowds. We use a combination of deep
and shallow, fully convolutional networks to predict the density map for a
given crowd image. Such a combination is used for effectively capturing both
the high-level semantic information (face/body detectors) and the low-level
features (blob detectors), that are necessary for crowd counting under large
scale variations. As most crowd datasets have limited training samples (&lt;100
images) and deep learning based approaches require large amounts of training
data, we perform multi-scale data augmentation. Augmenting the training samples
in such a manner helps in guiding the CNN to learn scale invariant
representations. Our method is tested on the challenging UCF_CC_50 dataset, and
shown to outperform the state of the art methods.
</dc:description>
 <dc:description>Comment: Accepted at ACM Multimedia (MM) 2016</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06203</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational and Statistical Tradeoffs in Learning to Rank</dc:title>
 <dc:creator>Khetan, Ashish</dc:creator>
 <dc:creator>Oh, Sewoong</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  For massive and heterogeneous modern datasets, it is of fundamental interest
to provide guarantees on the accuracy of estimation when computational
resources are limited. In the application of learning to rank, we provide a
hierarchy of rank-breaking mechanisms ordered by the complexity in thus
generated sketch of the data. This allows the number of data points collected
to be gracefully traded off against computational resources available, while
guaranteeing the desired level of accuracy. Theoretical guarantees on the
proposed generalized rank-breaking implicitly provide such trade-offs, which
can be explicitly characterized under certain canonical scenarios on the
structure of the data.
</dc:description>
 <dc:description>Comment: 30 pages 5 figures</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06204</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards the Interactive Effects of Demand Response Participation on
  Electricity Spot Market Price</dc:title>
 <dc:creator>Mohajeryami, Saeed</dc:creator>
 <dc:creator>Doostan, Milad</dc:creator>
 <dc:creator>Moghadasi, Seyedmahdi</dc:creator>
 <dc:creator>Schwarz, Peter</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The electricity market is threatened by supply scarcity, which may lead to
very sharp price spikes in the spot market. On the other hand, demand-side's
activities could effectively mitigate the supply scarcity and absorb most of
these shocks and therefore smooth out the price volatility. In this paper, the
positive effects of employing demand response programs on the spot market price
are investigated. A demand-price elasticity based model is used to simulate the
customer reaction function in the presence of a real time pricing. The demand
achieve by DR program is used to adjust the spot market price by using a price
regression model. SAS software is used to run the multiple linear regression
model and MATLAB is used to simulate the demand response model. The approach is
applied on one week data in summer 2014 of Connecticut in New England ISO. It
could be concluded from the results of this study that applying DR program
smooths out most of the price spikes in the electricity spot market and
considerably reduces the customers' electricity cost.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06212</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Datatype defining rewrite systems for the ring of integers, and for
  natural and integer arithmetic in unary view</dc:title>
 <dc:creator>Bergstra, Jan A.</dc:creator>
 <dc:creator>Ponse, Alban</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:description>  A datatype defining rewrite system (DDRS) is a ground-complete term rewriting
system, intended to be used for the specification of datatypes. As a follow-up
of an earlier paper we define two concise DDRSes for the ring of integers, each
comprising only twelve rewrite rules, and prove their ground-completeness. Then
we introduce DDRSes for a concise specification of natural number arithmetic
and integer arithmetic in unary view, that is, arithmetic based on unary append
(a form of tallying) or on successor function. Finally, we relate one of the
DDRSes for the ring of integers to the above-mentioned DDRSes for natural and
integer arithmetic in unary view.
</dc:description>
 <dc:description>Comment: 14 pages, 8 tables</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06229</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Systematic Identification and Analysis of Scientists on Twitter</dc:title>
 <dc:creator>Ke, Qing</dc:creator>
 <dc:creator>Ahn, Yong-Yeol</dc:creator>
 <dc:creator>Sugimoto, Cassidy R.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Metrics derived from Twitter and other social media---often referred to as
altmetrics---are increasingly used to estimate the broader social impacts of
scholarship. Such efforts, however, may produce highly misleading results, as
the entities that participate in conversations about science on these platforms
are largely unknown. For instance, if altmetric activities are generated mainly
by scientists, does it really capture broader social impacts of science? Here
we present a systematic approach to identifying and analyzing scientists on
Twitter. Our method can identify scientists across many disciplines, without
relying on external bibliographic data, and be easily adapted to identify other
stakeholder groups in science. We investigate the demographics, sharing
behaviors, and interconnectivity of the identified scientists. We find that
Twitter has been employed by scholars across the disciplinary spectrum, with an
over-representation of social and computer and information scientists;
under-representation of mathematical, physical, and life scientists; and a
better representation of women compared to scholarly publishing. Analysis of
the sharing of URLs reveals a distinct imprint of scholarly sites, yet only a
small fraction of shared URLs are science-related. We find an assortative
mixing with respect to disciplines in the networks between scientists,
suggesting the maintenance of disciplinary walls in social media. Our work
contributes to the literature both methodologically and conceptually---we
provide new methods for disambiguating and identifying particular actors on
social media and describing the behaviors of scientists, thus providing
foundational information for the construction and use of indicators on the
basis of social media metrics.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06229</dc:identifier>
 <dc:identifier>PLOS ONE 12(4), e0175368 (2017)</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0175368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06235</identifier>
 <datestamp>2016-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Probabilistic Trajectory Optimization via Efficient Approximate
  Inference</dc:title>
 <dc:creator>Pan, Yunpeng</dc:creator>
 <dc:creator>Yan, Xinyan</dc:creator>
 <dc:creator>Theodorou, Evangelos</dc:creator>
 <dc:creator>Boots, Byron</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Robotic systems must be able to quickly and robustly make decisions when
operating in uncertain and dynamic environments. While Reinforcement Learning
(RL) can be used to compute optimal policies with little prior knowledge about
the environment, it suffers from slow convergence. An alternative approach is
Model Predictive Control (MPC), which optimizes policies quickly, but also
requires accurate models of the system dynamics and environment. In this paper
we propose a new approach, adaptive probabilistic trajectory optimization, that
combines the benefits of RL and MPC. Our method uses scalable approximate
inference to learn and updates probabilistic models in an online incremental
fashion while also computing optimal control policies via successive local
approximations. We present two variations of our algorithm based on the Sparse
Spectrum Gaussian Process (SSGP) model, and we test our algorithm on three
learning tasks, demonstrating the effectiveness and efficiency of our approach.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2016-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06244</identifier>
 <datestamp>2016-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analytical Investigations on Carrier Phase Recovery in
  Dispersion-Unmanaged n-PSK Coherent Optical Communication Systems</dc:title>
 <dc:creator>Xu, Tianhua</dc:creator>
 <dc:creator>Jacobsen, Gunnar</dc:creator>
 <dc:creator>Popov, Sergei</dc:creator>
 <dc:creator>Li, Jie</dc:creator>
 <dc:creator>Liu, Tiegen</dc:creator>
 <dc:creator>Zhang, Yimo</dc:creator>
 <dc:creator>Bayvel, Polina</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A12</dc:subject>
 <dc:subject>C.2.5</dc:subject>
 <dc:description>  Using coherent optical detection and digital signal processing, laser phase
noise and equalization enhanced phase noise can be effectively mitigated using
the feed-forward and feed-back carrier phase recovery approaches. In this
paper, theoretical analyses of feed-back and feed-forward carrier phase
recovery methods have been carried out in the long-haul high-speed n-level
phase shift keying (n-PSK) optical fiber communication systems, involving a
one-tap normalized least-mean-square (LMS) algorithm, a block-wise average
algorithm, and a Viterbi-Viterbi algorithm. The analytical expressions for
evaluating the estimated carrier phase and for predicting the bit-error-rate
(BER) performance (such as the BER floors) have been presented and discussed in
the n-PSK coherent optical transmission systems by considering both the laser
phase noise and the equalization enhanced phase noise. The results indicate
that the Viterbi-Viterbi carrier phase recovery algorithm outperforms the
one-tap normalized LMS and the block-wise average algorithms for small phase
noise variance (or effective phase noise variance), while the one-tap
normalized LMS algorithm shows a better performance than the other two
algorithms for large phase noise variance (or effective phase noise variance).
In addition, the one-tap normalized LMS algorithm is more sensitive to the
level of modulation formats.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2016-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06249</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Honeypot Software and Data Analysis</dc:title>
 <dc:creator>Nawrocki, Marcin</dc:creator>
 <dc:creator>W&#xe4;hlisch, Matthias</dc:creator>
 <dc:creator>Schmidt, Thomas C.</dc:creator>
 <dc:creator>Keil, Christian</dc:creator>
 <dc:creator>Sch&#xf6;nfelder, Jochen</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2.0</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:subject>C.2.3</dc:subject>
 <dc:subject>C.2.6</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:subject>K.6.5</dc:subject>
 <dc:description>  In this survey, we give an extensive overview on honeypots. This includes not
only honeypot software but also methodologies to analyse honeypot data.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06253</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Dueling Bandits and Their Application to Online Ranker Evaluation</dc:title>
 <dc:creator>Brost, Brian</dc:creator>
 <dc:creator>Seldin, Yevgeny</dc:creator>
 <dc:creator>Cox, Ingemar J.</dc:creator>
 <dc:creator>Lioma, Christina</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  New ranking algorithms are continually being developed and refined,
necessitating the development of efficient methods for evaluating these
rankers. Online ranker evaluation focuses on the challenge of efficiently
determining, from implicit user feedback, which ranker out of a finite set of
rankers is the best. Online ranker evaluation can be modeled by dueling ban-
dits, a mathematical model for online learning under limited feedback from
pairwise comparisons. Comparisons of pairs of rankers is performed by
interleaving their result sets and examining which documents users click on.
The dueling bandits model addresses the key issue of which pair of rankers to
compare at each iteration, thereby providing a solution to the
exploration-exploitation trade-off. Recently, methods for simultaneously
comparing more than two rankers have been developed. However, the question of
which rankers to compare at each iteration was left open. We address this
question by proposing a generalization of the dueling bandits model that uses
simultaneous comparisons of an unrestricted number of rankers. We evaluate our
algorithm on synthetic data and several standard large-scale online ranker
evaluation datasets. Our experimental results show that the algorithm yields
orders of magnitude improvement in performance compared to stateof- the-art
dueling bandit algorithms.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06253</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06254</identifier>
 <datestamp>2017-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Synthesis of Semantic Malware Signatures using Maximum
  Satisfiability</dc:title>
 <dc:creator>Feng, Yu</dc:creator>
 <dc:creator>Bastani, Osbert</dc:creator>
 <dc:creator>Martins, Ruben</dc:creator>
 <dc:creator>Dillig, Isil</dc:creator>
 <dc:creator>Anand, Saswat</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This paper proposes a technique for automatically learning semantic malware
signatures for Android from very few samples of a malware family. The key idea
underlying our technique is to look for a maximally suspicious common subgraph
(MSCS) that is shared between all known instances of a malware family. An MSCS
describes the shared functionality between multiple Android applications in
terms of inter-component call relations and their semantic metadata (e.g.,
data-flow properties). Our approach identifies such maximally suspicious common
subgraphs by reducing the problem to maximum satisfiability. Once a semantic
signature is learned, our approach uses a combination of static analysis and a
new approximate signature matching algorithm to determine whether an Android
application matches the semantic signature characterizing a given malware
family.
  We have implemented our approach in a tool called ASTROID and show that it
has a number of advantages over state-of-the-art malware detection techniques.
First, we compare the semantic malware signatures automatically synthesized by
ASTROID with manually-written signatures used in previous work and show that
the signatures learned by ASTROID perform better in terms of accuracy as well
as precision. Second, we compare ASTROID against two state-of-the-art malware
detection tools and demonstrate its advantages in terms of interpretability and
accuracy. Finally, we demonstrate that ASTROID's approximate signature matching
algorithm is resistant to behavioral obfuscation and that it can be used to
detect zero-day malware. In particular, we were able to find 22 instances of
zero-day malware in Google Play that are not reported as malware by existing
tools.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2017-06-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06272</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ASIC Design of a Noisy Gradient Descent Bit Flip Decoder for 10GBASE-T
  Ethernet Standard</dc:title>
 <dc:creator>Sundararajan, Gopalakrishnan</dc:creator>
 <dc:creator>Winstead, Chris</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, the NGDBF algorithm is implemented on a code that is deployed
in the IEEE 802.3an Ethernet standard. The design employs a fully parallel
architecture and operates in two-phases: start-up phase and decoding phase. The
two phase operation keeps the high latency operations off-line, thereby
reducing the decoding latency during the decoding phase. The design is
bench-marked with other state-of-the-art designs on the same code that employ
different algorithms and architectures. The results indicate that the NGDBF
decoder has a better area efficiency and a better energy efficiency compared to
other state-of-art decoders. When the design is operated in medium to high
signal to noise ratios, the design is able to provide greater than the required
minimum throughput of 10Gbps. The design consumes 0.81mm2 of area and has an
energy efficiency of 1.7pJ/bit, which are the lowest in the reported
literature. The design also provides better error performance compared to other
simplified decoder implementations and consumes lesser wire-length compared to
a recently proposed design.
</dc:description>
 <dc:description>Comment: 12 pages, 14 figures, 4 tables</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06272</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06277</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fundamental principles of cortical computation: unsupervised learning
  with prediction, compression and feedback</dc:title>
 <dc:creator>Richert, Micah</dc:creator>
 <dc:creator>Fisher, Dimitry</dc:creator>
 <dc:creator>Piekniewski, Filip</dc:creator>
 <dc:creator>Izhikevich, Eugene M.</dc:creator>
 <dc:creator>Hylton, Todd L.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  There has been great progress in understanding of anatomical and functional
microcircuitry of the primate cortex. However, the fundamental principles of
cortical computation - the principles that allow the visual cortex to bind
retinal spikes into representations of objects, scenes and scenarios - have so
far remained elusive. In an attempt to come closer to understanding the
fundamental principles of cortical computation, here we present a functional,
phenomenological model of the primate visual cortex. The core part of the model
describes four hierarchical cortical areas with feedforward, lateral, and
recurrent connections. The three main principles implemented in the model are
information compression, unsupervised learning by prediction, and use of
lateral and top-down context. We show that the model reproduces key aspects of
the primate ventral stream of visual processing including Simple and Complex
cells in V1, increasingly complicated feature encoding, and increased
separability of object representations in higher cortical areas. The model
learns representations of the visual environment that allow for accurate
classification and state-of-the-art visual tracking performance on novel
objects.
</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06277</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06298</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Infusing Collaborative Recommenders with Distributed Representations</dc:title>
 <dc:creator>Zanotti, Greg</dc:creator>
 <dc:creator>Horvath, Miller</dc:creator>
 <dc:creator>Barbosa, Lucas Nunes</dc:creator>
 <dc:creator>Immedisetty, Venkata Trinadh Kumar Gupta</dc:creator>
 <dc:creator>Gemmell, Jonathan</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Recommender systems assist users in navigating complex information spaces and
focus their attention on the content most relevant to their needs. Often these
systems rely on user activity or descriptions of the content. Social annotation
systems, in which users collaboratively assign tags to items, provide another
means to capture information about users and items. Each of these data sources
provides unique benefits, capturing different relationships.
  In this paper, we propose leveraging multiple sources of data: ratings data
as users report their affinity toward an item, tagging data as users assign
annotations to items, and item data collected from an online database. Taken
together, these datasets provide the opportunity to learn rich distributed
representations by exploiting recent advances in neural network architectures.
We first produce representations that subjectively capture interesting
relationships among the data. We then empirically evaluate the utility of the
representations to predict a user's rating on an item and show that it
outperforms more traditional representations. Finally, we demonstrate that
traditional representations can be combined with representations trained
through a neural network to achieve even better results.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06298</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06310</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Job Placement Advisor Based on Turnaround Predictions for HPC Hybrid
  Clouds</dc:title>
 <dc:creator>Cunha, Renato L. F.</dc:creator>
 <dc:creator>Rodrigues, Eduardo R.</dc:creator>
 <dc:creator>Tizzei, Leonardo P.</dc:creator>
 <dc:creator>Netto, Marco A. S.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Several companies and research institutes are moving their CPU-intensive
applications to hybrid High Performance Computing (HPC) cloud environments.
Such a shift depends on the creation of software systems that help users decide
where a job should be placed considering execution time and queue wait time to
access on-premise clusters. Relying blindly on turnaround prediction techniques
will affect negatively response times inside HPC cloud environments. This paper
introduces a tool to make job placement decisions in HPC hybrid cloud
environments taking into account the inaccuracy of execution and waiting time
predictions. We used job traces from real supercomputing centers to run our
experiments, and compared the performance between environments using real
speedup curves. We also extended a state-of-the-art machine learning based
predictor to work with data from the cluster scheduler. Our main findings are:
(i) depending on workload characteristics, there is a turning point where
predictions should be disregarded in favor of a more conservative decision to
minimize job turnaround times and (ii) scheduler data plays a key role in
improving predictions generated with machine learning using job trace
data---our experiments showed around 20% prediction accuracy improvements.
</dc:description>
 <dc:description>Comment: 14 pages, 7 figures, accepted for publication at Future Generation
  Computer Systems (FGCS)</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06315</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LFADS - Latent Factor Analysis via Dynamical Systems</dc:title>
 <dc:creator>Sussillo, David</dc:creator>
 <dc:creator>Jozefowicz, Rafal</dc:creator>
 <dc:creator>Abbott, L. F.</dc:creator>
 <dc:creator>Pandarinath, Chethan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Neuroscience is experiencing a data revolution in which many hundreds or
thousands of neurons are recorded simultaneously. Currently, there is little
consensus on how such data should be analyzed. Here we introduce LFADS (Latent
Factor Analysis via Dynamical Systems), a method to infer latent dynamics from
simultaneously recorded, single-trial, high-dimensional neural spiking data.
LFADS is a sequential model based on a variational auto-encoder. By making a
dynamical systems hypothesis regarding the generation of the observed data,
LFADS reduces observed spiking to a set of low-dimensional temporal factors,
per-trial initial conditions, and inferred inputs. We compare LFADS to existing
methods on synthetic data and show that it significantly out-performs them in
inferring neural firing rates and latent dynamics.
</dc:description>
 <dc:description>Comment: 16 pages, 11 figures</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06318</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy Amplification Against Active Quantum Adversaries</dc:title>
 <dc:creator>Cohen, Gil</dc:creator>
 <dc:creator>Vidick, Thomas</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Privacy amplification is the task by which two cooperating parties transform
a shared weak secret, about which an eavesdropper may have side information,
into a uniformly random string uncorrelated from the eavesdropper. Privacy
amplification against passive adversaries, where it is assumed that the
communication is over a public but authenticated channel, can be achieved in
the presence of classical as well as quantum side information by a
single-message protocol based on strong extractors.
  In 2009 Dodis and Wichs devised a two-message protocol to achieve privacy
amplification against active adversaries, where the public communication
channel is no longer assumed to be authenticated, through the use of a
strengthening of strong extractors called non-malleable extractors which they
introduced. Dodis and Wichs only analyzed the case of classical side
information.
  We consider the task of privacy amplification against active adversaries with
quantum side information. Our main result is showing that the Dodis-Wichs
protocol remains secure in this scenario provided its main building block, the
non-malleable extractor, satisfies a notion of quantum-proof non-malleability
which we introduce. We show that an adaptation of a recent construction of
non-malleable extractors due to Chattopadhyay et al. is quantum proof, thereby
providing the first protocol for privacy amplification that is secure against
active quantum adversaries. Our protocol is quantitatively comparable to the
near-optimal protocols known in the classical setting.
</dc:description>
 <dc:description>Comment: The result is invalidated due to a mistake, pointed out by an
  anonymous referee, in the use of the Markov condition at the beginning of the
  proof of Theorem 31</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2017-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06318</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06325</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A PTAS for the Steiner Forest Problem in Doubling Metrics</dc:title>
 <dc:creator>Chan, T-H. Hubert</dc:creator>
 <dc:creator>Hu, Shuguang</dc:creator>
 <dc:creator>Jiang, Shaofeng H. -C.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We achieve a (randomized) polynomial-time approximation scheme (PTAS) for the
Steiner Forest Problem in doubling metrics. Before our work, a PTAS is given
only for the Euclidean plane in [FOCS 2008: Borradaile, Klein and Mathieu]. Our
PTAS also shares similarities with the dynamic programming for sparse instances
used in [STOC 2012: Bartal, Gottlieb and Krauthgamer] and [SODA 2016: Chan and
Jiang]. However, extending previous approaches requires overcoming several
non-trivial hurdles, and we make the following technical contributions.
  (1) We prove a technical lemma showing that Steiner points have to be &quot;near&quot;
the terminals in an optimal Steiner tree. This enables us to define a heuristic
to estimate the local behavior of the optimal solution, even though the Steiner
points are unknown in advance. This lemma also generalizes previous results in
the Euclidean plane, and may be of independent interest for related problems
involving Steiner points.
  (2) We develop a novel algorithmic technique known as &quot;adaptive cells&quot; to
overcome the difficulty of keeping track of multiple components in a solution.
Our idea is based on but significantly different from the previously proposed
&quot;uniform cells&quot; in the FOCS 2008 paper, whose techniques cannot be readily
applied to doubling metrics.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06328</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Functional Multiplex PageRank</dc:title>
 <dc:creator>Iacovacci, Jacopo</dc:creator>
 <dc:creator>Rahmede, Christoph</dc:creator>
 <dc:creator>Arenas, Alex</dc:creator>
 <dc:creator>Bianconi, Ginestra</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Recently it has been recognized that many complex social, technological and
biological networks have a multilayer nature and can be described by multiplex
networks. Multiplex networks are formed by a set of nodes connected by links
having different connotations forming the different layers of the multiplex.
Characterizing the centrality of the nodes in a multiplex network is a
challenging task since the centrality of the node naturally depends on the
importance associated to links of a certain type. Here we propose to assign to
each node of a multiplex network a centrality called Functional Multiplex
PageRank that is a function of the weights given to every different pattern of
connections (multilinks) existent in the multiplex network between any two
nodes. Since multilinks distinguish all the possible ways in which the links in
different layers can overlap, the Functional Multiplex PageRank can describe
important non-linear effects when large relevance or small relevance is
assigned to multilinks with overlap. Here we apply the Functional Page Rank to
the multiplex airport networks, to the neuronal network of the nematode
c.elegans, and to social collaboration and citation networks between
scientists. This analysis reveals important differences existing between the
most central nodes of these networks, and the correlations between their so
called &quot;pattern to success&quot;.
</dc:description>
 <dc:description>Comment: (7 pages, 5 figures)</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06328</dc:identifier>
 <dc:identifier>EPL, 116 (2016) 28004</dc:identifier>
 <dc:identifier>doi:10.1209/0295-5075/116/28004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06336</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Event-driven Trajectory Optimization for Data Harvesting in Multi-Agent
  Systems</dc:title>
 <dc:creator>Khazaeni, Yasaman</dc:creator>
 <dc:creator>Cassandras, Christos G.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We propose a new event-driven method for on-line trajectory optimization to
solve the data harvesting problem: in a two-dimensional mission space, N mobile
agents are tasked with the collection of data generated at M stationary sources
and delivery to a base with the goal of minimizing expected collection and
delivery delays. We define a new performance measure that addresses the event
excitation problem in event-driven controllers and formulate an optimal control
problem. The solution of this problem provides some insights on its structure,
but it is computationally intractable, especially in the case where the data
generating processes are stochastic. We propose an agent trajectory
parameterization in terms of general function families which can be
subsequently optimized on line through the use of Infinitesimal Perturbation
Analysis (IPA). Properties of the solutions are identified, including
robustness with respect to the stochastic data generation process and
scalability in the size of the event set characterizing the underlying hybrid
dynamical system. Explicit results are provided for the case of elliptical and
Fourier series trajectories and comparisons with a state-of-the-art graph-based
algorithm are given.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1503.06133</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06338</identifier>
 <datestamp>2016-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-scale Continuous Gesture Recognition Using Convolutional Neural
  Networks</dc:title>
 <dc:creator>Wang, Pichao</dc:creator>
 <dc:creator>Li, Wanqing</dc:creator>
 <dc:creator>Liu, Song</dc:creator>
 <dc:creator>Zhang, Yuyao</dc:creator>
 <dc:creator>Gao, Zhimin</dc:creator>
 <dc:creator>Ogunbona, Philip</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper addresses the problem of continuous gesture recognition from
sequences of depth maps using convolutional neutral networks (ConvNets). The
proposed method first segments individual gestures from a depth sequence based
on quantity of movement (QOM). For each segmented gesture, an Improved Depth
Motion Map (IDMM), which converts the depth sequence into one image, is
constructed and fed to a ConvNet for recognition. The IDMM effectively encodes
both spatial and temporal information and allows the fine-tuning with existing
ConvNet models for classification without introducing millions of parameters to
learn. The proposed method is evaluated on the Large-scale Continuous Gesture
Recognition of the ChaLearn Looking at People (LAP) challenge 2016. It achieved
the performance of 0.2655 (Mean Jaccard Index) and ranked $3^{rd}$ place in
this challenge.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2016-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06339</identifier>
 <datestamp>2016-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantization and Feedback of Spatial Covariance Matrix for Massive MIMO
  Systems with Cascaded Precoding</dc:title>
 <dc:creator>Liu, Yinsheng</dc:creator>
 <dc:creator>Li, Geoffrey Ye</dc:creator>
 <dc:creator>Han, Wei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate the quantization and the feedback of downlink
spatial covariance matrix for massive multiple-input multiple-output (MIMO)
systems with cascaded precoding. Massive MIMO has gained a lot of attention
recently because of its ability to significantly improve the network
performance. To reduce the overhead of downlink channel estimation and uplink
feedback in frequency-division duplex massive MIMO systems, cascaded precoding
has been proposed, where the outer precoder is implemented using traditional
limited feedback while the inner precoder is determined by the spatial
covariance matrix of the channels. In massive MIMO systems, it is difficult to
quantize the spatial covariance matrix because of its large size caused by the
huge number of antennas. In this paper, we propose a spatial spectrum based
approach for the quantization and the feedback of the spatial covariance
matrix. The proposed inner precoder can be viewed as modulated discrete prolate
spheroidal sequences and thus achieve much smaller spatial leakage than the
traditional discrete Fourier transform submatrix based precoding. Practical
issues for the application of the proposed approach are also addressed in this
paper.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2016-10-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06341</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Analysis of Downlink Channel Estimation Based on Parametric
  Model for Massive MIMO in FDD Systems</dc:title>
 <dc:creator>Liu, Yinsheng</dc:creator>
 <dc:creator>Liu, Yinjun</dc:creator>
 <dc:creator>Cui, Qimei</dc:creator>
 <dc:creator>Jantti, Riku</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates downlink channel estimation in frequency-division
duplex (FDD)-based massive multiple-input multiple-output (MIMO) systems. To
reduce the overhead of downlink channel estimation and uplink feedback in FDD
systems, cascaded precoding has been used in massive MIMO such that only a
low-dimensional effective channel needs to be estimated and fed back. On the
other hand, traditional channel estimations can hardly achieve the minimum
mean-square-error (MMSE) performance due to lack of the a priori knowledge of
the channels. In this paper, we design and analyze a strategy for downlink
channel estimation based on the parametric model in massive MIMO with cascaded
precoding. For a parametric model, channel frequency responses are expressed
using the path delays and the associated complex amplitudes. The path delays of
uplink channels are first estimated and quantized at the base station, then fed
forward to the user equipment (UE) through a dedicated feedforward link. In
this manner, the UE can obtain the a priori knowledge of the downlink channel
in advance since it has been demonstrated that the downlink and the uplink
channels can have identical path delays. Our analysis and simulation results
show that the proposed approach can achieve near-MMSE performance.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06347</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Parallelization Method for K-means</dc:title>
 <dc:creator>Jin, Shikai</dc:creator>
 <dc:creator>Cui, Yuxuan</dc:creator>
 <dc:creator>Yu, Chunli</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  K-means is a popular clustering method used in data mining area. To work with
large datasets, researchers propose PKMeans, which is a parallel k-means on
MapReduce. However, the existing k-means parallelization methods including
PKMeans have many limitations. PKMeans can't finish all its iterations in one
MapReduce job, so it has to repeat cascading MapReduce jobs in a loop until
convergence. On the most popular MapReduce platform, Hadoop, every MapReduce
job introduces significant I/O overheads and extra execution time at stages of
job start-up and shuffling. Even worse, it has been proved that in the worst
case, k-means needs $2^{{\Omega}(n)}$ MapReduce jobs to converge, where n is
the number of data instances, which means huge overheads for large datasets.
Additionally, in PKMeans, at most one reducer can be assigned to and update
each centroid, so PKMeans can only make use of limited number of parallel
reducers. In this paper, we propose an improved parallel method for k-means,
IPKMeans, which has a parallel preprocessing stage using k-d tree and can
finish k-means in one single MapReduce job with much more reducers working in
parallel and lower I/O overheads than PKMeans and has a fast post-processing
stage generating the final result. In our method, both k-d tree and the new
improved parallel k-means are implemented using MapReduce and tested on Hadoop.
Our experiments show that with same dataset and initial centroids, our method
has up to 2/3 lower I/O overheads and consumes less amount of time than PKMeans
to get a very close clustering result.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06349</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Five dimensions of reasoning in the wild</dc:title>
 <dc:creator>Perlis, Don</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Reasoning does not work well when done in isolation from its significance,
both to the needs and interests of an agent and with respect to the wider
world. Moreover, those issues may best be handled with a new sort of data
structure that goes beyond the knowledge base and incorporates aspects of
perceptual knowledge and even more, in which a kind of anticipatory action may
be key.
</dc:description>
 <dc:description>Comment: minor typos corrected from AAAI version, Proceedings (Blue-Sky track)
  AAAI-2016, Phoenix AZ</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06368</identifier>
 <datestamp>2016-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Segmenting a Surface Mesh into Pants Using Morse Theory</dc:title>
 <dc:creator>Hajij, Mustafa</dc:creator>
 <dc:creator>Dey, Tamal</dc:creator>
 <dc:creator>Li, Xin</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Mathematics - Geometric Topology</dc:subject>
 <dc:description>  A pair of pants is a genus zero orientable surface with three boundary
components. A pants decomposition of a surface is a finite collection of
unordered pairwise disjoint simple closed curves embedded in the surface that
decompose the surface into pants. In this paper we present two Morse theory
based algorithms for pants decomposition of a surface mesh. Both algorithms
operates on a choice of an appropriate Morse function on the surface. The first
algorithm uses this Morse function to identify handles that are glued
systematically to obtain a pant decomposition. The second algorithm uses the
Reeb graph of the Morse function to obtain a pant decomposition. Both
algorithms work for surfaces with or without boundaries. Our preliminary
implementation of the two algorithms shows that both algorithms run in much
less time than an existing state-of-the-art method, and the Reeb graph based
algorithm achieves the best time efficiency. Finally, we demonstrate the
robustness of our algorithms against noise.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2016-09-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06374</identifier>
 <datestamp>2016-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Double Sparsity Encoder: Learning to Sparsify Not Only Features But
  Also Parameters</dc:title>
 <dc:creator>Wang, Zhangyang</dc:creator>
 <dc:creator>Huang, Thomas S.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper emphasizes the significance to jointly exploit the problem
structure and the parameter structure, in the context of deep modeling. As a
specific and interesting example, we describe the deep double sparsity encoder
(DDSE), which is inspired by the double sparsity model for dictionary learning.
DDSE simultaneously sparsities the output features and the learned model
parameters, under one unified framework. In addition to its intuitive model
interpretation, DDSE also possesses compact model size and low complexity.
Extensive simulations compare DDSE with several carefully-designed baselines,
and verify the consistently superior performance of DDSE. We further apply DDSE
to the novel application domain of brain encoding, with promising preliminary
results achieved.
</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:date>2016-10-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06378</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening
  Comprehension Test by Machine</dc:title>
 <dc:creator>Tseng, Bo-Hsiang</dc:creator>
 <dc:creator>Shen, Sheng-Syun</dc:creator>
 <dc:creator>Lee, Hung-Yi</dc:creator>
 <dc:creator>Lee, Lin-Shan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Multimedia or spoken content presents more attractive information than plain
text content, but it's more difficult to display on a screen and be selected by
a user. As a result, accessing large collections of the former is much more
difficult and time-consuming than the latter for humans. It's highly attractive
to develop a machine which can automatically understand spoken content and
summarize the key information for humans to browse over. In this endeavor, we
propose a new task of machine comprehension of spoken content. We define the
initial goal as the listening comprehension test of TOEFL, a challenging
academic English examination for English learners whose native language is not
English. We further propose an Attention-based Multi-hop Recurrent Neural
Network (AMRNN) architecture for this task, achieving encouraging results in
the initial tests. Initial results also have shown that word-level attention is
probably more robust than sentence-level attention for this task with ASR
errors.
</dc:description>
 <dc:description>Comment: Accepted conference paper: &quot;The Annual Conference of the
  International Speech Communication Association (Interspeech), 2016&quot;</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06378</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06379</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Profile Analyst: Advanced Job Candidate Matching via Automatic Skills
  Linking</dc:title>
 <dc:creator>Coleman, Martin A.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The recruitment process is a slow and inefficient one at best, and a
potentially ineffective one at worst. Matching candidates to jobs is one thing,
but matching candidates with jobs alongside appropriate expectations and taking
into account the right aptitude and suitability for any given role is another
thing and in this paper we look at a whole new way of matching jobs with
potential candidates as well as matching against their overall suitability for
a given role.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06386</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Which techniques does your application use?: An information extraction
  framework for scientific articles</dc:title>
 <dc:creator>Dan, Soham</dc:creator>
 <dc:creator>Agarwal, Sanyam</dc:creator>
 <dc:creator>Singh, Mayank</dc:creator>
 <dc:creator>Goyal, Pawan</dc:creator>
 <dc:creator>Mukherjee, Animesh</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Every field of research consists of multiple application areas with various
techniques routinely used to solve problems in these wide range of application
areas. With the exponential growth in research volumes, it has become difficult
to keep track of the ever-growing number of application areas as well as the
corresponding problem solving techniques. In this paper, we consider the
computational linguistics domain and present a novel information extraction
system that automatically constructs a pool of all application areas in this
domain and appropriately links them with corresponding problem solving
techniques. Further, we categorize individual research articles based on their
application area and the techniques proposed/used in the article. k-gram based
discounting method along with handwritten rules and bootstrapped pattern
learning is employed to extract application areas. Subsequently, a language
modeling approach is proposed to characterize each article based on its
application area. Similarly, regular expressions and high-scoring noun phrases
are used for the extraction of the problem solving techniques. We propose a
greedy approach to characterize each article based on the techniques. Towards
the end, we present a table representing the most frequent techniques adopted
for a particular application area. Finally, we propose three use cases
presenting an extensive temporal analysis of the usage of techniques and
application areas.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06392</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formalization of Fault Trees in Higher-order Logic: A Deep Embedding
  Approach</dc:title>
 <dc:creator>Ahmed, Waqar</dc:creator>
 <dc:creator>Hasan, Osman</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Fault Tree (FT) is a standard failure modeling technique that has been
extensively used to predict reliability, availability and safety of many
complex engineering systems. In order to facilitate the formal analysis of FT
based analyses, a higher-order-logic formalization of FTs has been recently
proposed. However, this formalization is quite limited in terms of handling
large systems and transformation of FT models into their corresponding
Reliability Block Diagram (RBD) structures, i.e., a frequently used
transformation in reliability and availability analyses. In order to overcome
these limitations, we present a deep embedding based formalization of FTs. In
particular, the paper presents a formalization of AND, OR and NOT FT gates,
which are in turn used to formalize other commonly used FT gates, i.e., NAND,
NOR, XOR, Inhibit, Comparator and majority Voting, and the formal verification
of their failure probability expressions. For illustration purposes, we present
a formal failure analysis of a communication gateway software for the next
generation air traffic management system.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1505.02648</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06392</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06403</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phased Exploration with Greedy Exploitation in Stochastic Combinatorial
  Partial Monitoring Games</dc:title>
 <dc:creator>Chaudhuri, Sougata</dc:creator>
 <dc:creator>Tewari, Ambuj</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Partial monitoring games are repeated games where the learner receives
feedback that might be different from adversary's move or even the reward
gained by the learner. Recently, a general model of combinatorial partial
monitoring (CPM) games was proposed \cite{lincombinatorial2014}, where the
learner's action space can be exponentially large and adversary samples its
moves from a bounded, continuous space, according to a fixed distribution. The
paper gave a confidence bound based algorithm (GCB) that achieves
$O(T^{2/3}\log T)$ distribution independent and $O(\log T)$ distribution
dependent regret bounds. The implementation of their algorithm depends on two
separate offline oracles and the distribution dependent regret additionally
requires existence of a unique optimal action for the learner. Adopting their
CPM model, our first contribution is a Phased Exploration with Greedy
Exploitation (PEGE) algorithmic framework for the problem. Different algorithms
within the framework achieve $O(T^{2/3}\sqrt{\log T})$ distribution independent
and $O(\log^2 T)$ distribution dependent regret respectively. Crucially, our
framework needs only the simpler &quot;argmax&quot; oracle from GCB and the distribution
dependent regret does not require existence of a unique optimal action. Our
second contribution is another algorithm, PEGE2, which combines gap estimation
with a PEGE algorithm, to achieve an $O(\log T)$ regret bound, matching the GCB
guarantee but removing the dependence on size of the learner's action space.
However, like GCB, PEGE2 requires access to both offline oracles and the
existence of a unique optimal action. Finally, we discuss how our algorithm can
be efficiently applied to a CPM problem of practical interest: namely, online
ranking with feedback at the top.
</dc:description>
 <dc:description>Comment: Appearing in NIPS 2016</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06405</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Pair Two-Way Relay Network with Harvest-Then-Transmit Users:
  Resolving Pairwise Uplink-Downlink Coupling</dc:title>
 <dc:creator>Wang, Shuai</dc:creator>
 <dc:creator>Xia, Minghua</dc:creator>
 <dc:creator>Wu, Yik-Chung</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  While two-way relaying is a promising way to enhance the spectral efficiency
of wireless networks, the imbalance of relay-user distances may lead to
excessive wireless power at the nearby-users. To exploit the excessive power,
the recently proposed harvest-then-transmit technique can be applied. However,
it is well-known that harvest-then-transmit introduces uplink-downlink coupling
for a user. Together with the co-dependent relationship between paired users
and interference among multiple user pairs, wirelessly powered two-way relay
network suffers from the unique pairwise uplink-downlink coupling, and the
joint uplink-downlink network design is nontrivial. To this end, for the one
pair users case, we show that a global optimal solution can be obtained. For
the general case of multi-pair users, based on the rank-constrained difference
of convex program, a convergence guaranteed iterative algorithm with an
efficient initialization is proposed. Furthermore, a lower bound to the
performance of the optimal solution is derived by introducing virtual receivers
at relay. Numerical results on total transmit power show that the proposed
algorithm achieves a transmit power value close to the lower bound.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2017-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06405</dc:identifier>
 <dc:identifier>IEEE Journal of Selected Topics in Signal Processing, vol. 10, no.
  8, pp. 1506-1521, Dec. 2016</dc:identifier>
 <dc:identifier>doi:10.1109/JSTSP.2016.2612162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06408</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Learning to Rank with Top-k Feedback</dc:title>
 <dc:creator>Chaudhuri, Sougata</dc:creator>
 <dc:creator>Tewari, Ambuj</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider two settings of online learning to rank where feedback is
restricted to top ranked items. The problem is cast as an online game between a
learner and sequence of users, over $T$ rounds. In both settings, the learners
objective is to present ranked list of items to the users. The learner's
performance is judged on the entire ranked list and true relevances of the
items. However, the learner receives highly restricted feedback at end of each
round, in form of relevances of only the top $k$ ranked items, where $k \ll m$.
The first setting is \emph{non-contextual}, where the list of items to be
ranked is fixed. The second setting is \emph{contextual}, where lists of items
vary, in form of traditional query-document lists. No stochastic assumption is
made on the generation process of relevances of items and contexts. We provide
efficient ranking strategies for both the settings. The strategies achieve
$O(T^{2/3})$ regret, where regret is based on popular ranking measures in first
setting and ranking surrogates in second setting. We also provide impossibility
results for certain ranking measures and a certain class of surrogates, when
feedback is restricted to the top ranked item, i.e. $k=1$. We empirically
demonstrate the performance of our algorithms on simulated and real world
datasets.
</dc:description>
 <dc:description>Comment: Under review in JMLR</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06408</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06409</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Communicate: Channel Auto-encoders, Domain Specific
  Regularizers, and Attention</dc:title>
 <dc:creator>O'Shea, Timothy J</dc:creator>
 <dc:creator>Karra, Kiran</dc:creator>
 <dc:creator>Clancy, T. Charles</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We address the problem of learning efficient and adaptive ways to communicate
binary information over an impaired channel. We treat the problem as
reconstruction optimization through impairment layers in a channel autoencoder
and introduce several new domain-specific regularizing layers to emulate common
channel impairments. We also apply a radio transformer network based attention
model on the input of the decoder to help recover canonical signal
representations. We demonstrate some promising initial capacity results from
this architecture and address several remaining challenges before such a system
could become practical.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06409</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06415</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online bin packing with cardinality constraints resolved</dc:title>
 <dc:creator>Balogh, J&#xe1;nos</dc:creator>
 <dc:creator>B&#xe9;k&#xe9;si, J&#xf3;zsef</dc:creator>
 <dc:creator>D&#xf3;sa, Gy&#xf6;rgy</dc:creator>
 <dc:creator>Epstein, Leah</dc:creator>
 <dc:creator>Levin, Asaf</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Cardinality constrained bin packing or bin packing with cardinality
constraints is a basic bin packing problem. In the online version with the
parameter k \geq 2, items having sizes in (0,1] associated with them are
presented one by one to be packed into unit capacity bins, such that the
capacities of bins are not exceeded, and no bin receives more than k items. We
resolve the online problem in the sense that we prove a lower bound of 2 on the
overall asymptotic competitive ratio. This closes this long standing open
problem, since an algorithm of an absolute competitive ratio 2 is known.
Additionally, we significantly improve the known lower bounds on the asymptotic
competitive ratio for every specific value of k. The novelty of our
constructions is based on full adaptivity that creates large gaps between item
sizes. Thus, our lower bound inputs do not follow the common practice for
online bin packing problems of having a known in advance input consisting of
batches for which the algorithm needs to be competitive on every prefix of the
input.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06415</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06417</identifier>
 <datestamp>2016-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometric Interpretation of Theoretical Bounds for RSS-based Source
  Localization with Uncertain Anchor Positions</dc:title>
 <dc:creator>Denkovski, Daniel</dc:creator>
 <dc:creator>Angjelichinoski, Marko</dc:creator>
 <dc:creator>Atanasovski, Vladimir</dc:creator>
 <dc:creator>Gavrilovska, Liljana</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The Received Signal Strength based source localization can encounter severe
problems originating from uncertain information about the anchor positions in
practice. The anchor positions, although commonly assumed to be precisely known
prior to the source localization, are usually obtained using previous
estimation algorithm such as GPS. This previous estimation procedure produces
anchor positions with limited accuracy that result in degradations of the
source localization algorithm and topology uncertainty. We have recently
addressed the problem with a joint estimation framework that jointly estimates
the unknown source and uncertain anchors positions and derived the theoretical
limits of the framework. This paper extends the authors previous work on the
theoretical performance bounds of the joint localization framework with
appropriate geometric interpretation of the overall problem exploiting the
properties of semi-definiteness and symmetry of the Fisher Information Matrix
and the Cram{\`e}r-Rao Lower Bound and using Information and Error Ellipses,
respectively. The numerical results aim to illustrate and discuss the
usefulness of the geometric interpretation. They provide in-depth insight into
the geometrical properties of the joint localization problem underlining the
various possibilities for practical design of efficient localization
algorithms.
</dc:description>
 <dc:description>Comment: 30 pages, 15 figures</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2016-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06420</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Harmonic Potential Field Approach for Joint Planning &amp; Control of a
  Rigid, Separable Nonholonomic, Mobile Robot</dc:title>
 <dc:creator>Masoud, Ahmad A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The main objective of this paper is to provide a tool for performing path
planning at the servo level of a mobile robot. The ability to perform, in a
provably correct manner, such a complex task at the servo level can lead to a
large increase in the speed of operation, low energy consumption and high
quality of response. Planning has been traditionally limited to the high level
controller of a robot. The guidance velocity signal from this stage is usually
converted to a control signal using what is known as an electronic speed
controller (ESC). This paper demonstrates the ability of the harmonic potential
field (HPF) approach to generate a provably correct, constrained, well behaved
trajectory and control signal for a rigid, nonholonomic robot in a stationary,
cluttered environment. It is shown that the HPF based, servo level planner can
address a large number of challenges facing planning in a realistic situation.
The suggested approach migrates the rich and provably correct properties of the
solution trajectories from an HPF planner to those of the robot. This is
achieved using a synchronizing control signal whose aim is to align the
velocity of the robot in its local coordinates, with that of the gradient of
the HPF. The link between the two is made possible by representing the robot
using what the paper terms separable form. The context-sensitive and
goal-oriented control signal used to steer the robot is demonstrated to be well
behaved and robust in the presence of actuator noise, saturation and
uncertainty in the parameters. The approach is developed, proofs of correctness
are provided and the capabilities of the scheme are demonstrated using
simulation results.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06420</dc:identifier>
 <dc:identifier>Robotics And Autonomous Systems, Vol. 61, No. 6, June 2013 Page
  593,615</dc:identifier>
 <dc:identifier>doi:10.1016/j.robot.2013.02.007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06427</identifier>
 <datestamp>2017-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Arbitrarily regularizable graphs</dc:title>
 <dc:creator>Franceschet, Massimo</dc:creator>
 <dc:creator>Bozzo, Enrico</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  A graph is regularizable if it is possible to assign weights to its edges so
that all nodes have the same degree. Weights can be positive, nonnegative or
arbitrary as soon as the regularization degree is not null. Positive and
nonnegative regularizable graphs have been thoroughly investigated in the
literature. In this work, we propose and study arbitrarily regularizable
graphs. In particular, we investigate necessary and sufficient regularization
conditions on the topology of the graph and of the corresponding adjacency
matrix. Moreover, we study the computational complexity of the regularization
problem and characterize it as a linear programming model.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2017-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06427</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06434</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Network for Attribute-driven and Identity-preserving Human
  Face Generation</dc:title>
 <dc:creator>Li, Mu</dc:creator>
 <dc:creator>Zuo, Wangmeng</dc:creator>
 <dc:creator>Zhang, David</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper focuses on the problem of generating human face pictures from
specific attributes. The existing CNN-based face generation models, however,
either ignore the identity of the generated face or fail to preserve the
identity of the reference face image. Here we address this problem from the
view of optimization, and suggest an optimization model to generate human face
with the given attributes while keeping the identity of the reference image.
The attributes can be obtained from the attribute-guided image or by tuning the
attribute features of the reference image. With the deep convolutional network
&quot;VGG-Face&quot;, the loss is defined on the convolutional feature maps. We then
apply the gradient decent algorithm to solve this optimization problem. The
results validate the effectiveness of our method for attribute driven and
identity-preserving face generation.
</dc:description>
 <dc:description>Comment: 9 pages, 7 figures</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06434</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06440</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Delay-Tolerant Potential-Field-Based Network Implementation of an
  Integrated Navigation System</dc:title>
 <dc:creator>Gupta, Rachana Ashok</dc:creator>
 <dc:creator>Masoud, Ahmad A.</dc:creator>
 <dc:creator>Chow, Mo-Yuen</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Network controllers (NCs) are devices that are capable of converting dynamic,
spatially extended, and functionally specialized modules into a taskable
goal-oriented group called networked control system. This paper examines the
practical aspects of designing and building an NC that uses the Internet as a
communication medium. It focuses on finding compatible controller components
that can be integrated via a host structure in a manner that makes it possible
to network, in real-time, a webcam, an unmanned ground vehicle (UGV), and a
remote computer server along with the necessary operator software interface.
The aim is to deskill the UGV navigation process and yet maintain a robust
performance. The structure of the suggested controller, its components, and the
manner in which they are interfaced are described. Thorough experimental
results along with performance assessment and comparisons to a previously
implemented NC are provided.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06440</dc:identifier>
 <dc:identifier>The IEEE Transactions On Industrial Electronics, Vol. 57, No.2,
  February 2010, PP. 769-783</dc:identifier>
 <dc:identifier>doi:10.1109/TIE.2009.2026764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06451</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Failure Detection for Facial Landmark Detectors</dc:title>
 <dc:creator>Steger, Andreas</dc:creator>
 <dc:creator>Timofte, Radu</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Most face applications depend heavily on the accuracy of the face and facial
landmarks detectors employed. Prediction of attributes such as gender, age, and
identity usually completely fail when the faces are badly aligned due to
inaccurate facial landmark detection. Despite the impressive recent advances in
face and facial landmark detection, little study is on the recovery from and
detection of failures or inaccurate predictions. In this work we study two top
recent facial landmark detectors and devise confidence models for their
outputs. We validate our failure detection approaches on standard benchmarks
(AFLW, HELEN) and correctly identify more than 40% of the failures in the
outputs of the landmark detectors. Moreover, with our failure detection we can
achieve a 12% error reduction on a gender estimation application at the cost of
a small increase in computation.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06451</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06458</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stack and Queue Layouts via Layered Separators</dc:title>
 <dc:creator>Dujmovi&#x107;, Vida</dc:creator>
 <dc:creator>Frati, Fabrizio</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  It is known that every proper minor-closed class of graphs has bounded
stack-number (a.k.a. book thickness and page number). While this includes
notable graph families such as planar graphs and graphs of bounded genus, many
other graph families are not closed under taking minors. For fixed $g$ and $k$,
we show that every $n$-vertex graph that can be embedded on a surface of genus
$g$ with at most $k$ crossings per edge has stack-number $\mathcal{O}(\log n)$;
this includes $k$-planar graphs. The previously best known bound for the
stack-number of these families was $\mathcal{O}(\sqrt{n})$, except in the case
of $1$-planar graphs. Analogous results are proved for map graphs that can be
embedded on a surface of fixed genus. None of these families is closed under
taking minors. The main ingredient in the proof of these results is a
construction proving that $n$-vertex graphs that admit constant layered
separators have $\mathcal{O}(\log n)$ stack-number.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06459</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracking Amendments to Legislation and Other Political Texts with a
  Novel Minimum-Edit-Distance Algorithm: DocuToads</dc:title>
 <dc:creator>Hermansson, Henrik</dc:creator>
 <dc:creator>Cross, James P.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Political scientists often find themselves tracking amendments to political
texts. As different actors weigh in, texts change as they are drafted and
redrafted, reflecting political preferences and power. This study provides a
novel solution to the prob- lem of detecting amendments to political text based
upon minimum edit distances. We demonstrate the usefulness of two
language-insensitive, transparent, and efficient minimum-edit-distance
algorithms suited for the task. These algorithms are capable of providing an
account of the types (insertions, deletions, substitutions, and trans-
positions) and substantive amount of amendments made between version of texts.
To illustrate the usefulness and efficiency of the approach we replicate two
existing stud- ies from the field of legislative studies. Our results
demonstrate that minimum edit distance methods can produce superior measures of
text amendments to hand-coded efforts in a fraction of the time and resource
costs.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06462</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Low-High Orders of Directed Graphs: Incremental Algorithms and
  Applications</dc:title>
 <dc:creator>Georgiadis, Loukas</dc:creator>
 <dc:creator>Karanasiou, Aikaterini</dc:creator>
 <dc:creator>Konstantinos, Giannis</dc:creator>
 <dc:creator>Laura, Luigi</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A flow graph $G=(V,E,s)$ is a directed graph with a distinguished start
vertex $s$. The dominator tree $D$ of $G$ is a tree rooted at $s$, such that a
vertex $v$ is an ancestor of a vertex $w$ if and only if all paths from $s$ to
$w$ include $v$. The dominator tree is a central tool in program optimization
and code generation and has many applications in other diverse areas including
constraint programming, circuit testing, biology, and in algorithms for graph
connectivity problems. A low-high order of $G$ is a preorder $\delta$ of $D$
that certifies the correctness of $D$ and has further applications in
connectivity and path-determination problems. In this paper, we first consider
how to maintain efficiently a low-high order of a flow graph incrementally
under edge insertions. We present algorithms that run in $O(mn)$ total time for
a sequence of $m$ edge insertions in an initially empty flow graph with $n$
vertices.These immediately provide the first incremental certifying algorithms
for maintaining the dominator tree in $O(mn)$ total time, and also imply
incremental algorithms for other problems. Hence, we provide a substantial
improvement over the $O(m^2)$ simple-minded algorithms, which recompute the
solution from scratch after each edge insertion. We also show how to apply
low-high orders to obtain a linear-time $2$-approximation algorithm for the
smallest $2$-vertex-connected spanning subgraph problem (2VCSS). Finally, we
present efficient implementations of our new algorithms for the incremental
low-high and 2VCSS problems and conduct an extensive experimental study on
real-world graphs taken from a variety of application areas. The experimental
results show that our algorithms perform very well in practice.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06469</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Warehousing Complex Archaeological Objects</dc:title>
 <dc:creator>Ozt&#xfc;rk, Ayb&#xfc;k&#xeb;</dc:creator>
 <dc:creator>Eyango, Louis</dc:creator>
 <dc:creator>Waksman, Sylvie Yona</dc:creator>
 <dc:creator>Lallich, St&#xe9;phane</dc:creator>
 <dc:creator>Darmont, J&#xe9;r&#xf4;me</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Data organization is a difficult and essential component in cultural heritage
applications. Over the years, a great amount of archaeological ceramic data
have been created and processed by various methods and devices. Such ceramic
data are stored in databases that concur to increase the amount of available
information rapidly. However , such databases typically focus on one type of
ceramic descriptors, e.g., qualitative textual descriptions, petrographic or
chemical analysis results, and do not interoperate. Thus, research involving
archaeological ceramics cannot easily take advantage of combining all these
types of information. In this application paper, we introduce an evolution of
the Ceramom database that includes text descriptors of archaeological features,
chemical analysis results, and various images, including petrographic and
fabric images. To illustrate what new analyses are permitted by such a
database, we source it to a data warehouse and present a sample on-line
analysis processing (OLAP) scenario to gain deep understanding of ceramic
context.
</dc:description>
 <dc:description>Comment: 9th International and Interdisciplinary Conference on Modeling and
  Using Context (CONTEXT 2015), Nov 2015, Larnaca, Cyprus. Springer,
  Proceedings of the 9th International and Interdisciplinary Conference on
  Modeling and Using Context (CONTEXT 2015), 9405, pp.226-239, 2015, Lecture
  Notes in Artificial Intelligence</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06469</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06472</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multivariate Cryptography with Mappings of Discrete Logarithms and
  Polynomials</dc:title>
 <dc:creator>Krishna, Duggirala Meher</dc:creator>
 <dc:creator>Ravi, Duggirala</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper, algorithms for multivariate public key cryptography and
digital signature are described. Plain messages and encrypted messages are
arrays, consisting of elements from a fixed finite ring or field. The
encryption and decryption algorithms are based on multivariate mappings. The
security of the private key depends on the difficulty of solving a system of
parametric simultaneous multivariate equations involving polynomial or
exponential mappings. The method is a general purpose utility for most data
encryption, digital certificate or digital signature applications.
</dc:description>
 <dc:description>Comment: 30 pages, this manuscript appears also as IACR Cryptology ePrint
  Archive Report Number 2016/821</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06473</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A two-scale approach for efficient on-the-fly operator assembly in
  massively parallel high performance multigrid codes</dc:title>
 <dc:creator>Bauer, Simon</dc:creator>
 <dc:creator>Mohr, Marcus</dc:creator>
 <dc:creator>R&#xfc;de, Ulrich</dc:creator>
 <dc:creator>Weism&#xfc;ller, Jens</dc:creator>
 <dc:creator>Wittmann, Markus</dc:creator>
 <dc:creator>Wohlmuth, Barbara</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Matrix-free finite element implementations of massively parallel geometric
multigrid save memory and are often significantly faster than implementations
using classical sparse matrix techniques. They are especially well suited for
hierarchical hybrid grids on polyhedral domains. In the case of constant
coefficients all fine grid node stencils in the interior of a coarse macro
element are equal. However, for non-polyhedral domains the situation changes.
Then even for the Laplace operator, the non-linear element mapping leads to
fine grid stencils that can vary from grid point to grid point. This
observation motivates a new two-scale approach that exploits a piecewise
polynomial approximation of the fine grid operator with respect to the coarse
mesh size. The low-cost evaluation of these surrogate polynomials results in an
efficient stencil assembly on-the-fly for non-polyhedral domains that can be
significantly more efficient than matrix-free techniques that are based on an
element-wise assembly. The performance analysis and additional hardware-aware
code optimizations are based on the Execution-Cache-Memory model. Several
aspects such as two-scale a priori error bounds and double discretization
techniques are presented. Weak and strong scaling results illustrate the
benefits of the new technique when used within large scale PDE solvers.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06491</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Delay Evaluation of OpenFlow Network Based on Queueing Model</dc:title>
 <dc:creator>Shang, Zhihao</dc:creator>
 <dc:creator>Wolter, Katinka</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  As one of the most popular south-bound protocol of software-defined
networking(SDN), OpenFlow decouples the network control from forwarding
devices. It offers flexible and scalable functionality for networks. These
advantages may cause performance issues since there are performance penalties
in terms of packet processing speed. It is important to understand the
performance of OpenFlow switches and controllers for its deployments. In this
paper we model the packet processing time of OpenFlow switches and controllers.
We mainly analyze how the probability of packet-in messages impacts the
performance of switches and controllers. Our results show that there is a
performance penalty in OpenFlow networks. However, the penalty is not much when
probability of packet-in messages is low. This model can be used for a network
designer to approximate the performance of her deployments.
</dc:description>
 <dc:description>Comment: Editor: Hans-Peter Schwefel. 12th European Dependable Computing
  Conference (EDCC 2016), September 5-9, 2016, Gothenburg, Sweden. Proceedings
  of Student Forum - EDCC 2016</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06492</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple Infection Sources Identification with Provable Guarantees</dc:title>
 <dc:creator>Nguyen, Hung T.</dc:creator>
 <dc:creator>Ghosh, Preetam</dc:creator>
 <dc:creator>Mayo, Michael L.</dc:creator>
 <dc:creator>Dinh, Thang N.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Given an aftermath of a cascade in the network, i.e. a set $V_I$ of
&quot;infected&quot; nodes after an epidemic outbreak or a propagation of
rumors/worms/viruses, how can we infer the sources of the cascade? Answering
this challenging question is critical for computer forensic, vulnerability
analysis, and risk management. Despite recent interest towards this problem,
most of existing works focus only on single source detection or simple network
topologies, e.g. trees or grids.
  In this paper, we propose a new approach to identify infection sources by
searching for a seed set $S$ that minimizes the \emph{symmetric difference}
between the cascade from $S$ and $V_I$, the given set of infected nodes. Our
major result is an approximation algorithm, called SISI, to identify infection
sources \emph{without the prior knowledge on the number of source nodes}. SISI,
to our best knowledge, is the first algorithm with \emph{provable guarantee}
for the problem in general graphs. It returns a
$\frac{2}{(1-\epsilon)^2}\Delta$-approximate solution with high probability,
where $\Delta$ denotes the maximum number of nodes in $V_I$ that may infect a
single node in the network. Our experiments on real-world networks show the
superiority of our approach and SISI in detecting true source(s), boosting the
F1-measure from few percents, for the state-of-the-art NETSLEUTH, to
approximately 50\%.
</dc:description>
 <dc:description>Comment: in The 25th ACM International Conference on Information and Knowledge
  Management (CIKM 2016)</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06495</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Searching Action Proposals via Spatial Actionness Estimation and
  Temporal Path Inference and Tracking</dc:title>
 <dc:creator>Li, Nannan</dc:creator>
 <dc:creator>Xu, Dan</dc:creator>
 <dc:creator>Ying, Zhenqiang</dc:creator>
 <dc:creator>Li, Zhihao</dc:creator>
 <dc:creator>Li, Ge</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we address the problem of searching action proposals in
unconstrained video clips. Our approach starts from actionness estimation on
frame-level bounding boxes, and then aggregates the bounding boxes belonging to
the same actor across frames via linking, associating, tracking to generate
spatial-temporal continuous action paths. To achieve the target, a novel
actionness estimation method is firstly proposed by utilizing both human
appearance and motion cues. Then, the association of the action paths is
formulated as a maximum set coverage problem with the results of actionness
estimation as a priori. To further promote the performance, we design an
improved optimization objective for the problem and provide a greedy search
algorithm to solve it. Finally, a tracking-by-detection scheme is designed to
further refine the searched action paths. Extensive experiments on two
challenging datasets, UCF-Sports and UCF-101, show that the proposed approach
advances state-of-the-art proposal generation performance in terms of both
accuracy and proposal quantity.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06498</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast binary embeddings with Gaussian circulant matrices: improved bounds</dc:title>
 <dc:creator>Dirksen, Sjoerd</dc:creator>
 <dc:creator>Stollenwerk, Alexander</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>60B20 (Primary) 68Q87 (Secondary)</dc:subject>
 <dc:description>  We consider the problem of encoding a finite set of vectors into a small
number of bits while approximately retaining information on the angular
distances between the vectors. By deriving improved variance bounds related to
binary Gaussian circulant embeddings, we largely fix a gap in the proof of the
best known fast binary embedding method. Our bounds also show that
well-spreadness assumptions on the data vectors, which were needed in earlier
work on variance bounds, are unnecessary. In addition, we propose a new binary
embedding with a faster running time on sparse data.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06499</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dijkstra Monads for Free</dc:title>
 <dc:creator>Ahman, Danel</dc:creator>
 <dc:creator>Hritcu, Catalin</dc:creator>
 <dc:creator>Maillard, Kenji</dc:creator>
 <dc:creator>Martinez, Guido</dc:creator>
 <dc:creator>Plotkin, Gordon</dc:creator>
 <dc:creator>Protzenko, Jonathan</dc:creator>
 <dc:creator>Rastogi, Aseem</dc:creator>
 <dc:creator>Swamy, Nikhil</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Dijkstra monads enable a dependent type theory to be enhanced with support
for specifying and verifying effectful code via weakest preconditions. Together
with their closely related counterparts, Hoare monads, they provide the basis
on which verification tools like F*, Hoare Type Theory (HTT), and Ynot are
built.
  We show that Dijkstra monads can be derived &quot;for free&quot; by applying a
continuation-passing style (CPS) translation to the standard monadic
definitions of the underlying computational effects. Automatically deriving
Dijkstra monads in this way provides a correct-by-construction and efficient
way of reasoning about user-defined effects in dependent type theories.
  We demonstrate these ideas in EMF*, a new dependently typed calculus,
validating it via both formal proof and a prototype implementation within F*.
Besides equipping F* with a more uniform and extensible effect system, EMF*
enables a novel mixture of intrinsic and extrinsic proofs within F*.
</dc:description>
 <dc:description>Comment: extended pre-print for POPL 2017 final version</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06499</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06510</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Data Collection Mechanisms for Smart Monitoring of Distribution
  Grids</dc:title>
 <dc:creator>Kemal, Mohammed S.</dc:creator>
 <dc:creator>Olsen, Rasmus L.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Smart Grid systems not only transport electric energy but also information
which will be active part of the electricity supply system. This has led to the
introduction of intelligent components on all layers of the electrical grid in
power generation, transmission, distribution and consumption units. For
electric distribution systems, Information from Smart Meters can be utilized to
monitor and control the state of the grid. Hence, it is indeed inherent that
data from Smart Meters should be collected in a resilient, reliable, secure and
timely manner fulfilling all the communication requirements and standards. This
paper presents a proposal for smart data collection mechanisms to monitor
electrical grids with adaptive smart metering infrastructures. A general
overview of a platform is given for testing, evaluating and implementing
mechanisms to adapt Smart Meter data aggregation. Three main aspects of
adaptiveness of the system are studied, adaptiveness to smart metering
application needs, adaptiveness to changing communication network dynamics and
adaptiveness to security attacks. Execution of tests will be conducted in real
field experimental set-up and in an advanced hardware in the loop test-bed with
power and communication co-simulation for validation purposes.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures , Hans-Peter Schwefel. 12th European Dependable
  Computing Conference (EDCC 2016), September 5-9, 2016, Gothenburg, Sweden.
  Proceedings of Student Forum - EDCC 2016</dc:description>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06510</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06511</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wireless Sensor Networks: Local Multicast Study</dc:title>
 <dc:creator>Ahmadpanah, Seyed Hossein</dc:creator>
 <dc:creator>Chashmi, Abdullah Jafari</dc:creator>
 <dc:creator>Siadatpour, Seyede Samaneh</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Wireless sensor networks and Ad-hoc network in the region Multicast
(Geocasting) means to deliver the message to all nodes in a given geographical
area from the source point. Regional Multicast practical application of the
specified area and other regions may be formed to broadcast transmission and
location-related business information, extensive advertising, or to send an
urgent message. Regional multicast protocol design goal is to ensure messaging
and low transport costs. Most have been proposed agreement does not guarantee
message delivery, although some other guaranteed messaging protocol has
triggered high transmission costs. The goal now is to ensure that research
messaging and low-cost local transmission protocol and its algorithm, to
promote the development of domain communication. This paper introduces the
research background and research results, and proposed to solve the problems
and ideas.
</dc:description>
 <dc:description>Comment: ICEEE 2016</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06514</identifier>
 <datestamp>2017-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Multi-Objectives Optimization with a Changing Number of
  Objectives</dc:title>
 <dc:creator>Chen, Renzhi</dc:creator>
 <dc:creator>Li, Ke</dc:creator>
 <dc:creator>Yao, Xin</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Existing studies on dynamic multi-objective optimization focus on problems
with time-dependent objective functions, while the ones with a changing number
of objectives have rarely been considered in the literature. Instead of
changing the shape or position of the Pareto-optimal front/set when having
time-dependent objective functions, increasing or decreasing the number of
objectives usually leads to the expansion or contraction of the dimension of
the Pareto-optimal front/set manifold. Unfortunately, most existing dynamic
handling techniques can hardly be adapted to this type of dynamics. In this
paper, we report our attempt toward tackling the dynamic multi-objective
optimization problems with a changing number of objectives. We implement a new
two-archive evolutionary algorithm which maintains two co-evolving populations
simultaneously. In particular, these two populations are complementary to each
other: one concerns more about the convergence while the other concerns more
about the diversity. The compositions of these two populations are adaptively
reconstructed once the environment changes. In addition, these two populations
interact with each other via a mating selection mechanism. Comprehensive
experiments are conducted on various benchmark problems with a time-dependent
number of objectives. Empirical results fully demonstrate the effectiveness of
our proposed algorithm.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2017-02-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06514</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06520</identifier>
 <datestamp>2017-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Flows over Time: Models and Complexity Results</dc:title>
 <dc:creator>Gottschalk, Corinna</dc:creator>
 <dc:creator>Koster, Arie M. C. A.</dc:creator>
 <dc:creator>Liers, Frauke</dc:creator>
 <dc:creator>Peis, Britta</dc:creator>
 <dc:creator>Schmand, Daniel</dc:creator>
 <dc:creator>Wierz, Andreas</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We study dynamic network flows with uncertain input data under a robust
optimization perspective. In the dynamic maximum flow problem, the goal is to
maximize the flow reaching the sink within a given time horizon $T$, while flow
requires a certain travel time to traverse an edge.
  In our setting, we account for uncertain travel times of flow. We investigate
maximum flows over time under the assumption that at most $\Gamma$ travel times
may be prolonged simultaneously due to delay. We develop and study a
mathematical model for this problem. As the dynamic robust flow problem
generalizes the static version, it is NP-hard to compute an optimal flow.
However, our dynamic version is considerably more complex than the static
version. We show that it is NP-hard to verify feasibility of a given candidate
solution. Furthermore, we investigate temporally repeated flows and show that
in contrast to the non-robust case (that is, without uncertainties) they no
longer provide optimal solutions for the robust problem, but rather yield a
worst case optimality gap of at least $T$. We finally show that the optimality
gap is at most $O(\eta k \log T)$, where $\eta$ and $k$ are newly introduced
instance characteristics and provide a matching lower bound instance with
optimality gap $\Omega(\log T)$ and $\eta = k = 1$. The results obtained in
this paper yield a first step towards understanding robust dynamic flow
problems with uncertain travel times.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2017-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06521</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Does V-NIR based Image Enhancement Come with Better Features?</dc:title>
 <dc:creator>Sharma, Vivek</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image enhancement using the visible (V) and near-infrared (NIR) usually
enhances useful image details. The enhanced images are evaluated by observers
perception, instead of quantitative feature evaluation. Thus, can we say that
these enhanced images using NIR information has better features in comparison
to the computed features in the Red, Green, and Blue color channels directly?
In this work, we present a new method to enhance the visible images using NIR
information via edge-preserving filters, and also investigate which method
performs best from a image features standpoint. We then show that our proposed
enhancement method produces more stable features than the existing
state-of-the-art methods.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06545</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network coding in undirected graphs is either very helpful or not
  helpful at all</dc:title>
 <dc:creator>Braverman, Mark</dc:creator>
 <dc:creator>Garg, Sumegha</dc:creator>
 <dc:creator>Schvartzman, Ariel</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  While it is known that using network coding can significantly improve the
throughput of directed networks, it is a notorious open problem whether coding
yields any advantage over the multicommodity flow (MCF) rate in undirected
networks. It was conjectured by Li and Li (2004) that the answer is &quot;no&quot;. In
this paper we show that even a small advantage over MCF can be amplified to
yield a near-maximum possible gap.
  We prove that any undirected network with $k$ source-sink pairs that exhibits
a $(1+\varepsilon)$ gap between its MCF rate and its network coding rate can be
used to construct a family of graphs $G'$ whose gap is $\log(|G'|)^c$ for some
constant $c &lt; 1$. The resulting gap is close to the best currently known upper
bound, $\log(|G'|)$, which follows from the connection between MCF and sparsest
cuts.
  Our construction relies on a gap-amplifying graph tensor product that, given
two graphs $G_1,G_2$ with small gaps, creates another graph $G$ with a gap that
is equal to the product of the previous two, at the cost of increasing the size
of the graph. We iterate this process to obtain a gap of $\log(|G'|)^c$ from
any initial gap.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06545</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06549</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Semantic Similarity for Input Topic Identification in
  Crawling-based Web Application Testing</dc:title>
 <dc:creator>Lin, Jun-Wei</dc:creator>
 <dc:creator>Wang, Farn</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  To automatically test web applications, crawling-based techniques are usually
adopted to mine the behavior models, explore the state spaces or detect the
violated invariants of the applications. However, in existing crawlers, rules
for identifying the topics of input text fields, such as login ids, passwords,
emails, dates and phone numbers, have to be manually configured. Moreover, the
rules for one application are very often not suitable for another. In addition,
when several rules conflict and match an input text field to more than one
topics, it can be difficult to determine which rule suggests a better match.
This paper presents a natural-language approach to automatically identify the
topics of encountered input fields during crawling by semantically comparing
their similarities with the input fields in labeled corpus. In our evaluation
with 100 real-world forms, the proposed approach demonstrated comparable
performance to the rule-based one. Our experiments also show that the accuracy
of the rule-based approach can be improved by up to 19% when integrated with
our approach.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06557</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Networks with Smooth Adaptive Activation Functions for Regression</dc:title>
 <dc:creator>Hou, Le</dc:creator>
 <dc:creator>Samaras, Dimitris</dc:creator>
 <dc:creator>Kurc, Tahsin M.</dc:creator>
 <dc:creator>Gao, Yi</dc:creator>
 <dc:creator>Saltz, Joel H.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In Neural Networks (NN), Adaptive Activation Functions (AAF) have parameters
that control the shapes of activation functions. These parameters are trained
along with other parameters in the NN. AAFs have improved performance of Neural
Networks (NN) in multiple classification tasks. In this paper, we propose and
apply AAFs on feedforward NNs for regression tasks. We argue that applying AAFs
in the regression (second-to-last) layer of a NN can significantly decrease the
bias of the regression NN. However, using existing AAFs may lead to
overfitting. To address this problem, we propose a Smooth Adaptive Activation
Function (SAAF) with piecewise polynomial form which can approximate any
continuous function to arbitrary degree of error. NNs with SAAFs can avoid
overfitting by simply regularizing the parameters. In particular, an NN with
SAAFs is Lipschitz continuous given a bounded magnitude of the NN parameters.
We prove an upper-bound for model complexity in terms of fat-shattering
dimension for any Lipschitz continuous regression model. Thus, regularizing the
parameters in NNs with SAAFs avoids overfitting. We empirically evaluated NNs
with SAAFs and achieved state-of-the-art results on multiple regression
datasets.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06558</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Non-Local Conventional Approach for Noise Removal in 3D MRI</dc:title>
 <dc:creator>Morajab, Sona</dc:creator>
 <dc:creator>Mahdavi, Mehregan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, a filtering approach for the 3D magnetic resonance imaging
(MRI) assuming a Rician model for noise is addressed. Our denoising method is
based on the Conventional Approach (CA) proposed to deal with the noise issue
in the squared domain of the acquired magnitude MRI, where the noise
distribution follows a Chi-square model rather than the Rician one. In the CA
filtering method, the local samples around each voxel is used to estimate the
unknown signal value. Intrinsically, such a method fails to achieve the best
results where the underlying signal values have different statistical
properties. On the contrary, our proposal takes advantage of the data
redundancy and self-similarity properties of real MR images to improve the
noise removal performance. In other words, in our approach, the statistical
momentums of the given 3D MR volume are first calculated to explore the similar
patches inside a defined search volume. Then, these patches are put together to
obtain the noise-free value for each voxel under processing. The experimental
results on the synthetic as well as the clinical MR data show our proposed
method outperforms the other compared denoising filters.
</dc:description>
 <dc:description>Comment: 1st International Conference on New Perspective in Electrical &amp;
  Computer Engineering</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06559</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving FPGA resilience through Partial Dynamic Reconfiguration</dc:title>
 <dc:creator>Nunes, Jose Luis</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.3</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:description>  This paper explores advances in reconfiguration properties of SRAM-based
FPGAs, namely Partial Dynamic Reconfiguration, to improve the resilience of
critical systems that take advantage of this technology. Commercial
of-the-shelf state-of-the-art FPGA devices use SRAM cells for the configuration
memory, which allow an increase in both performance and capacity. The fast
access times and unlimited number of writes of this technology, reduces
reconfiguration delays and extends the device lifetime but, at the same time,
makes them more sensitive to radiation effects, in the form of Single Event
Upsets. To overcome this limitation, manufacturers have proposed a few fault
tolerant approaches, which rely on space/time redundancy and configuration
memory content recovery - scrubbing. In this paper, we first present radiation
effects on these devices and investigate the applicability of the most commonly
used fault tolerant approaches, and then propose an approach to improve FPGA
resilience, through the use of a less intrusive failure prediction scrubbing.
It is expected that this approach relieves the system designer from
dependability concerns and reduces both time intrusiveness and overall power
consumption.
</dc:description>
 <dc:description>Comment: Editor: Hans-Peter Schwefel. 12th European Dependable Computing
  Conference (EDCC 2016), September 5-9, 2016, Gothenburg, Sweden. Proceedings
  of Student Forum - EDCC 2016</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06563</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms for the Iterative Estimation of Discrete-Valued Sparse
  Vectors</dc:title>
 <dc:creator>Sparrer, Susanne</dc:creator>
 <dc:creator>Fischer, Robert F. H.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In Compressed Sensing, a real-valued sparse vector has to be estimated from
an underdetermined system of linear equations. In many applications, however,
the elements of the sparse vector are drawn from a finite set. For the
estimation of these discrete-valued vectors, matched algorithms are required
which take the additional knowledge of the discrete nature into account. In
this paper, the estimation problem is treated from a communications engineering
point of view. A powerful new algorithm incorporating techniques known from
digital communications and information theory is derived. For comparison, Turbo
Compressed Sensing is adapted to the discrete setup and a simplified and
generalized notation is presented. The performance of the algorithms is covered
by numerical simulations.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06567</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Quality Synthesis Against Stochastic Environments</dc:title>
 <dc:creator>Almagor, Shaull</dc:creator>
 <dc:creator>Kupferman, Orna</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:description>  In the classical synthesis problem, we are given an LTL formula psi over sets
of input and output signals, and we synthesize a transducer that realizes psi.
One weakness of automated synthesis in practice is that it pays no attention to
the quality of the synthesized system. Indeed, the classical setting is
Boolean: a computation satisfies a specification or does not satisfy it.
Accordingly, while the synthesized system is correct, there is no guarantee
about its quality. In recent years, researchers have considered extensions of
the classical Boolean setting to a quantitative one. The logic LTL[F] is a
multi-valued logic that augments LTL with quality operators. The satisfaction
value of an LTL[F] formula is a real value in [0,1], where the higher the value
is, the higher is the quality in which the computation satisfies the
specification.
  Decision problems for LTL become search or optimization problems for LFL[F].
In particular, in the synthesis problem, the goal is to generate a transducer
that satisfies the specification in the highest possible quality.
  Previous work considered the worst-case setting, where the goal is to
maximize the quality of the computation with the minimal quality. We introduce
and solve the stochastic setting, where the goal is to generate a transducer
that maximizes the expected quality of a computation, subject to a given
distribution of the input signals. Thus, rather than being hostile, the
environment is assumed to be probabilistic, which corresponds to many realistic
settings. We show that the problem is 2EXPTIME-complete, like classical LTL
synthesis, and remains so in two extensions we consider: one that maximizes the
expected quality while guaranteeing that the minimal quality is, with
probability $1$, above a given threshold, and one that allows assumptions on
the environment.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06574</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Designing PLC Networks for Ubiquitous Connectivity in
  Enterprises</dc:title>
 <dc:creator>Ali, Kamran</dc:creator>
 <dc:creator>Pefkianakis, Ioannis</dc:creator>
 <dc:creator>Liu, Alex X.</dc:creator>
 <dc:creator>Kim, Kyu-Han</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Powerline communication (PLC) provides inexpensive, secure and high speed
network connectivity, by leveraging the existing power distribution networks
inside the buildings. While PLC technology has the potential to improve
connectivity and is considered a key enabler for sensing, control, and
automation applications in enterprises, it has been mainly deployed for
improving connectivity in homes. Deploying PLCs in enterprises is more
challenging since the power distribution network is more complex as compared to
homes. Moreover, existing PLC technologies such as HomePlug AV have not been
designed for and evaluated in enterprise deployments. In this paper, we first
present a comprehensive measurement study of PLC performance in enterprise
settings, by analyzing PLC channel characteristics across space, time, and
spectral dimensions, using commodity HomePlug AV PLC devices. Our results
uncover the impact of distribution lines, circuit breakers, AC phases and
electrical interference on PLC performance. Based on our findings, we show that
careful planning of PLC network topology, routing and spectrum sharing can
significantly boost performance of enterprise PLC networks. Our experimental
results show that multi-hop routing can increase throughput performance by 5x
in scenarios where direct PLC links perform poorly. Moreover, our trace driven
simulations for multiple deployments, show that our proposed fine-grained
spectrum sharing design can boost the aggregated and per-link PLC throughput by
more than 20% and 100% respectively, in enterprise PLC networks.
</dc:description>
 <dc:description>Comment: PLCs, Powerline Communications, Spectrum Sharing, Effect of Breakers,
  Enterprises, IoTs, Large Scale Indoor PLC Networks</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06580</identifier>
 <datestamp>2016-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communication complexity of approximate Nash equilibria</dc:title>
 <dc:creator>Babichenko, Yakov</dc:creator>
 <dc:creator>Rubinstein, Aviad</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  For a constant $\epsilon$, we prove a poly(N) lower bound on the (randomized)
communication complexity of $\epsilon$-Nash equilibrium in two-player NxN
games. For n-player binary-action games we prove an exp(n) lower bound for the
(randomized) communication complexity of $(\epsilon,\epsilon)$-weak approximate
Nash equilibrium, which is a profile of mixed actions such that at least
$(1-\epsilon)$-fraction of the players are $\epsilon$-best replying.
</dc:description>
 <dc:description>Comment: Second revision extends the lower bounds to randomized communication</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2016-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06580</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06581</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fathom: Reference Workloads for Modern Deep Learning Methods</dc:title>
 <dc:creator>Adolf, Robert</dc:creator>
 <dc:creator>Rama, Saketh</dc:creator>
 <dc:creator>Reagen, Brandon</dc:creator>
 <dc:creator>Wei, Gu-Yeon</dc:creator>
 <dc:creator>Brooks, David</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep learning has been popularized by its recent successes on challenging
artificial intelligence problems. One of the reasons for its dominance is also
an ongoing challenge: the need for immense amounts of computational power.
Hardware architects have responded by proposing a wide array of promising
ideas, but to date, the majority of the work has focused on specific algorithms
in somewhat narrow application domains. While their specificity does not
diminish these approaches, there is a clear need for more flexible solutions.
We believe the first step is to examine the characteristics of cutting edge
models from across the deep learning community.
  Consequently, we have assembled Fathom: a collection of eight archetypal deep
learning workloads for study. Each of these models comes from a seminal work in
the deep learning community, ranging from the familiar deep convolutional
neural network of Krizhevsky et al., to the more exotic memory networks from
Facebook's AI research group. Fathom has been released online, and this paper
focuses on understanding the fundamental performance characteristics of each
model. We use a set of application-level modeling tools built around the
TensorFlow deep learning framework in order to analyze the behavior of the
Fathom workloads. We present a breakdown of where time is spent, the
similarities between the performance profiles of our models, an analysis of
behavior in inference and training, and the effects of parallelism on scaling.
</dc:description>
 <dc:description>Comment: Proceedings of the IEEE International Symposium on Workload
  Characterization, 2016</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06581</dc:identifier>
 <dc:identifier>doi:10.1109/IISWC.2016.7581275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06583</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Syntax and analytic semantics of LISA</dc:title>
 <dc:creator>ALglave, Jade</dc:creator>
 <dc:creator>Cousot, Patrick</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We provide the syntax and semantics of the LISA (for &quot;Litmus Instruction Set
Architecture&quot;) language. The parallel assembly language LISA is implemented in
the herd7 tool (http://virginia.cs.ucl.ac.uk/herd/) for simulating weak
consistency models.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06592</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application of Public Ledgers to Revocation in Distributed Access
  Control</dc:title>
 <dc:creator>Bui, Thanh</dc:creator>
 <dc:creator>Aura, Tuomas</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  There has recently been a flood of interest in potential new applications of
blockchains, as well as proposals for more generic designs called public
ledgers. Most of the novel proposals have been in the financial sector.
However, the public ledger is an abstraction that solves several of the
fundamental problems in the design of secure distributed systems: global time
in the form of a strict linear order of past events, globally consistent and
immutable view of the history, and enforcement of some application-specific
safety properties. This paper investigates the applications of public ledgers
to access control and, more specifically, to group management in distributed
systems where entities are represented by their public keys and authorization
is encoded into signed certificates. It is particularly difficult to handle
negative information, such as revocation of certificates or group membership,
in the distributed setting. The linear order of events and global consistency
simplify these problems, but the enforcement of internal constraints in the
ledger implementation often presents problems. We show that different types of
revocation require slightly different properties from the ledger. We compare
the requirements with Bitcoin, the best known blockchain, and describe an
efficient ledger design for membership revocation that combines ideas from
blockchains and from web-PKI monitoring. While we use certificate-based
group-membership management as the case study, the same ideas can be applied
more widely to rights revocation in distributed systems.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06592</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06602</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Averaging Expectation Propagation</dc:title>
 <dc:creator>&#xc7;akmak, Burak</dc:creator>
 <dc:creator>Opper, Manfred</dc:creator>
 <dc:creator>Fleury, Bernard H.</dc:creator>
 <dc:creator>Winther, Ole</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We investigate the problem of approximate Bayesian inference for a general
class of observation models by means of the expectation propagation (EP)
framework for large systems under some statistical assumptions. Our approach
tries to overcome the numerical bottleneck of EP caused by the inversion of
large matrices. Assuming that the measurement matrices are realizations of
specific types of ensembles we use the concept of freeness from random matrix
theory to show that the EP cavity variances exhibit an asymptotic
self-averaging property. They can be pre-computed using specific generating
functions, i.e. the R- and/or S-transforms in free probability, which do not
require matrix inversions. Our approach extends the framework of (generalized)
approximate message passing -- assumes zero-mean iid entries of the measurement
matrix -- to a general class of random matrix ensembles. The generalization is
via a simple formulation of the R- and/or S-transforms of the limiting
eigenvalue distribution of the Gramian of the measurement matrix. We
demonstrate the performance of our approach on a signal recovery problem of
nonlinear compressed sensing and compare it with that of EP.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06602</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06606</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mobile and Residential INEA Wi-Fi Hotspot Network</dc:title>
 <dc:creator>Musznicki, Bartosz</dc:creator>
 <dc:creator>Kowalik, Karol</dc:creator>
 <dc:creator>Ko&#x142;odziejski, Piotr</dc:creator>
 <dc:creator>Grzybek, Eugeniusz</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Since 2012 INEA has been developing and expanding the network of IEEE 802.11
compliant Wi-Fi hotspots (access points) located across the Greater Poland
region. This network consists of 330 mobile (vehicular) access points carried
by public buses and trams and over 20,000 fixed residential hotspots
distributed throughout the homes of INEA customers to provide Internet access
via the &quot;community Wi-Fi&quot; service. Therefore, this paper is aimed at sharing
the insights gathered by INEA throughout 4 years of experience in providing
hotspot-based Internet access. The emphasis is put on daily and hourly trends
in order to evaluate user experience, to determine key patterns, and to
investigate the influences such as public transportation trends, user location
and mobility, as well as, radio frequency noise and interference.
</dc:description>
 <dc:description>Comment: 8 pages, invited to ISWCS 2016, Thirteenth International Symposium on
  Wireless Communication Systems 2016, 20-23 September 2016, Pozna\'n, Poland</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06608</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Infinite-Label Learning with Semantic Output Codes</dc:title>
 <dc:creator>Zhang, Yang</dc:creator>
 <dc:creator>Acharyya, Rupam</dc:creator>
 <dc:creator>Liu, Ji</dc:creator>
 <dc:creator>Gong, Boqing</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We develop a new statistical machine learning paradigm, named infinite-label
learning, to annotate a data point with more than one relevant labels from a
candidate set, which pools both the finite labels observed at training and a
potentially infinite number of previously unseen labels. The infinite-label
learning fundamentally expands the scope of conventional multi-label learning,
and better models the practical requirements in various real-world
applications, such as image tagging, ads-query association, and article
categorization. However, how can we learn a labeling function that is capable
of assigning to a data point the labels omitted from the training set? To
answer the question, we seek some clues from the recent work on zero-shot
learning, where the key is to represent a class/label by a vector of semantic
codes, as opposed to treating them as atomic labels. We validate the
infinite-label learning by a PAC bound in theory and some empirical studies on
both synthetic and real data.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2017-10-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06608</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06613</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diagonality Measures of Hermitian Positive-Definite Matrices with
  Application to the Approximate Joint Diagonalization Problem</dc:title>
 <dc:creator>Alyani, Khaled</dc:creator>
 <dc:creator>Congedo, Marco</dc:creator>
 <dc:creator>Moakher, Maher</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>15B48, 94A17</dc:subject>
 <dc:description>  In this paper, we introduce properly-invariant diagonality measures of
Hermitian positive-definite matrices. These diagonality measures are defined as
distances or divergences between a given positive-definite matrix and its
diagonal part. We then give closed-form expressions of these diagonality
measures and discuss their invariance properties. The diagonality measure based
on the log-determinant $\alpha$-divergence is general enough as it includes a
diagonality criterion used by the signal processing community as a special
case. These diagonality measures are then used to formulate minimization
problems for finding the approximate joint diagonalizer of a given set of
Hermitian positive-definite matrices. Numerical computations based on a
modified Newton method are presented and commented.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2016-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06617</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Communication Complexity of Distributed Set Joins</dc:title>
 <dc:creator>Jeffery, Stacey</dc:creator>
 <dc:creator>Gall, Fran&#xe7;ois Le</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Computing set joins of two inputs is a common task in database theory.
Recently, Van Gucht, Williams, Woodruff and Zhang [PODS 2015] considered the
complexity of such problems in the natural model of (classical) two-party
communication complexity and obtained tight bounds for the complexity of
several important distributed set joins.
  In this paper we initiate the study of the *quantum* communication complexity
of distributed set joins. We design a quantum protocol for distributed Boolean
matrix multiplication, which corresponds to computing the composition join of
two databases, showing that the product of two $n\times n$ Boolean matrices,
each owned by one of two respective parties, can be computed with
$\widetilde{O}(\sqrt{n}\ell^{3/4})$ qubits of communication, where $\ell$
denotes the number of non-zero entries of the product. Since Van Gucht et al.
showed that the classical communication complexity of this problem is
$\widetilde{\Theta}(n\sqrt{\ell})$, our quantum algorithm outperforms classical
protocols whenever the output matrix is sparse. We also show a quantum lower
bound and a matching classical upper bound on the communication complexity of
distributed matrix multiplication over $\mathbb{F}_2$.
  Besides their applications to database theory, the communication complexity
of set joins is interesting due to its connections to direct product theorems
in communication complexity. In this work we also introduce a notion of
*all-pairs* product theorem, and relate this notion to standard direct product
theorems in communication complexity.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06617</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06627</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Artificial Neural Networks for Detection of Malaria in RBCs</dc:title>
 <dc:creator>Pandit, Purnima</dc:creator>
 <dc:creator>Anand, A.</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>62M45</dc:subject>
 <dc:description>  Malaria is one of the most common diseases caused by mosquitoes and is a
great public health problem worldwide. Currently, for malaria diagnosis the
standard technique is microscopic examination of a stained blood film. We
propose use of Artificial Neural Networks (ANN) for the diagnosis of the
disease in the red blood cell. For this purpose features / parameters are
computed from the data obtained by the digital holographic images of the blood
cells and is given as input to ANN which classifies the cell as the infected
one or otherwise.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06651</identifier>
 <datestamp>2017-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised, Efficient and Semantic Expertise Retrieval</dc:title>
 <dc:creator>Van Gysel, Christophe</dc:creator>
 <dc:creator>de Rijke, Maarten</dc:creator>
 <dc:creator>Worring, Marcel</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce an unsupervised discriminative model for the task of retrieving
experts in online document collections. We exclusively employ textual evidence
and avoid explicit feature engineering by learning distributed word
representations in an unsupervised way. We compare our model to
state-of-the-art unsupervised statistical vector space and probabilistic
generative approaches. Our proposed log-linear model achieves the retrieval
performance levels of state-of-the-art document-centric methods with the low
inference cost of so-called profile-centric approaches. It yields a
statistically significant improved ranking over vector space and generative
models in most cases, matching the performance of supervised methods on various
benchmarks. That is, by using solely text we can do as well as methods that
work with external evidence and/or relevance feedback. A contrastive analysis
of rankings produced by discriminative and generative approaches shows that
they have complementary strengths due to the ability of the unsupervised
discriminative model to perform semantic matching.
</dc:description>
 <dc:description>Comment: WWW2016, Proceedings of the 25th International Conference on World
  Wide Web. 2016</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2017-09-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06651</dc:identifier>
 <dc:identifier>doi:10.1145/2872427.2882974</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06654</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stress-constrained continuum topology optimization: a new approach based
  on elasto-plasticity</dc:title>
 <dc:creator>Amir, Oded</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  A new approach for generating stress-constrained topological designs in
continua is presented. The main novelty is in the use of elasto-plastic
modeling and in optimizing the design such that it will exhibit a
linear-elastic response. This is achieved by imposing a single global
constraint on the total sum of equivalent plastic strains, providing accurate
control over all local stress violations. The single constraint essentially
replaces a large number of local stress constraints or an approximate
aggregation of them--two common approaches in the literature. A classical
rate-independent plasticity model is utilized, for which analytical adjoint
sensitivity analysis is derived and verified. Several examples demonstrate the
capability of the computational procedure to generate designs that challenge
results from the literature, in terms of the obtained stiffness-strength-weight
trade-offs. A full elasto-plastic analysis of the optimized designs shows that
prior to the initial yielding, these designs can sustain significantly higher
loads than minimum compliance topological layouts, with only a minor compromise
on stiffness.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06656</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lexical Query Modeling in Session Search</dc:title>
 <dc:creator>Van Gysel, Christophe</dc:creator>
 <dc:creator>Kanoulas, Evangelos</dc:creator>
 <dc:creator>de Rijke, Maarten</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Lexical query modeling has been the leading paradigm for session search. In
this paper, we analyze TREC session query logs and compare the performance of
different lexical matching approaches for session search. Naive methods based
on term frequency weighing perform on par with specialized session models. In
addition, we investigate the viability of lexical query models in the setting
of session search. We give important insights into the potential and
limitations of lexical query modeling for session search and propose future
directions for the field of session search.
</dc:description>
 <dc:description>Comment: ICTIR2016, Proceedings of the 2nd ACM International Conference on the
  Theory of Information Retrieval. 2016</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06656</dc:identifier>
 <dc:identifier>doi:10.1145/2970398.2970422</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06658</identifier>
 <datestamp>2017-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Metric and classical fidelity uncertainty relations for random unitary
  matrices</dc:title>
 <dc:creator>Adamczak, Rados&#x142;aw</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We analyze uncertainty relations on finite dimensional Hilbert spaces
expressed in terms of classical fidelity, which are stronger then metric
uncertainty relations introduced by Fawzi, Hayden and Sen. We establish
validity of fidelity uncertainty relations for random unitary matrices with
optimal parameters (up to universal constants) which improves upon known
results for the weaker notion of metric uncertainty. This result is then
applied to locking classical information in quantum states and allows to obtain
optimal locking in Hellinger distance, improving upon previous results on
locking in the total variation distance, both by strengthening the metric used
and by improving the dependence on parameters. We also show that general
probabilistic estimates behind the main theorem can be used to prove existence
of data hiding schemes with Bayesian type guarantees. As a byproduct of our
approach we obtain existence of almost Euclidean subspaces of the matrix spaces
$\ell_1^n(\ell_2^m)$ with a better dimension/distortion dependence than allowed
in previously known constructions.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06658</dc:identifier>
 <dc:identifier>doi:10.1088/1751-8121/aa5662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06664</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topic Grids for Homogeneous Data Visualization</dc:title>
 <dc:creator>Su, Shih-Chieh</dc:creator>
 <dc:creator>Vaughn, Joseph</dc:creator>
 <dc:creator>Huynh, Jean-Laurent</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  We propose the topic grids to detect anomaly and analyze the behavior based
on the access log content. Content-based behavioral risk is quantified in the
high dimensional space where the topics are generated from the log. The topics
are being projected homogeneously into a space that is perception- and
interaction-friendly to the human experts.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06665</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep learning is competing random forest in computational docking</dc:title>
 <dc:creator>Khamis, Mohamed</dc:creator>
 <dc:creator>Gomaa, Walid</dc:creator>
 <dc:creator>Galal, Basem</dc:creator>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:description>  Computational docking is the core process of computer-aided drug design; it
aims at predicting the best orientation and conformation of a small drug
molecule when bound to a target large protein receptor. The docking quality is
typically measured by a scoring function: a mathematical predictive model that
produces a score representing the binding free energy and hence the stability
of the resulting complex molecule. We analyze the performance of both learning
techniques on the scoring power, the ranking power, docking power, and
screening power using the PDBbind 2013 database. For the scoring and ranking
powers, the proposed learning scoring functions depend on a wide range of
features (energy terms, pharmacophore, intermolecular) that entirely
characterize the protein-ligand complexes. For the docking and screening
powers, the proposed learning scoring functions depend on the intermolecular
features of the RF-Score to utilize a larger number of training complexes. For
the scoring power, the DL\_RF scoring function achieves Pearson's correlation
coefficient between the predicted and experimentally measured binding
affinities of 0.799 versus 0.758 of the RF scoring function. For the ranking
power, the DL scoring function ranks the ligands bound to fixed target protein
with accuracy 54% for the high-level ranking and with accuracy 78% for the
low-level ranking while the RF scoring function achieves (46% and 62%)
respectively. For the docking power, the DL\_RF scoring function has a success
rate when the three best-scored ligand binding poses are considered within 2
\AA\ root-mean-square-deviation from the native pose of 36.0% versus 30.2% of
the RF scoring function. For the screening power, the DL scoring function has
an average enrichment factor and success rate at the top 1% level of (2.69 and
6.45%) respectively versus (1.61 and 4.84%) respectively of the RF scoring
function.
</dc:description>
 <dc:description>Comment: 29 pages, 7 figures</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06666</identifier>
 <datestamp>2016-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synergistic Sorting, MultiSelection and Deferred Data Structures on
  MultiSets</dc:title>
 <dc:creator>Barbay, J&#xe9;r&#xe9;my</dc:creator>
 <dc:creator>Ochoa, Carlos</dc:creator>
 <dc:creator>Satti, Srinivasa Rao</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Karp et al. (1988) described Deferred Data Structures for Multisets as &quot;lazy&quot;
data structures which partially sort data to support online rank and select
queries, with the minimum amount of work in the worst case over instances of
size $n$ and number of queries $q$ fixed (i.e., the query size). Barbay et al.
(2016) refined this approach to take advantage of the gaps between the
positions hit by the queries (i.e., the structure in the queries). We develop
new techniques in order to further refine this approach and to take advantage
all at once of the structure (i.e., the multiplicities of the elements), the
local order (i.e., the number and sizes of runs) and the global order (i.e.,
the number and positions of existing pivots) in the input; and of the structure
and order in the sequence of queries. Our main result is a synergistic deferred
data structure which performs much better on large classes of instances, while
performing always asymptotically as good as previous solutions. As intermediate
results, we describe two new synergistic sorting algorithms, which take
advantage of the structure and order (local and global) in the input, improving
upon previous results which take advantage only of the structure (Munro and
Spira 1979) or of the local order (Takaoka 1997) in the input; and one new
multiselection algorithm which takes advantage of not only the order and
structure in the input, but also of the structure in the queries. We described
two compressed data structures to represent a multiset taking advantage of both
the local order and structure, while supporting the operators rank and select
on the multiset.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2016-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06667</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coauthorship and citation networks for statisticians: Comment</dc:title>
 <dc:creator>Karwa, Vishesh</dc:creator>
 <dc:creator>Petrovi&#x107;, Sonja</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  This is a comment on the paper arXiv:1410.2840 by Ji and Jin, to appear in
the AOAS.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06667</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06668</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computerized Tomography with Total Variation and with Shearlets</dc:title>
 <dc:creator>Gardu&#xf1;o, Edgar</dc:creator>
 <dc:creator>Herman, Gabor T.</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  To reduce the x-ray dose in computerized tomography (CT), many constrained
optimization approaches have been proposed aiming at minimizing a regularizing
function that measures lack of consistency with some prior knowledge about the
object that is being imaged, subject to a (predetermined) level of consistency
with the detected attenuation of x-rays. Proponents of the shearlet transform
in the regularizing function claim that the reconstructions so obtained are
better than those produced using TV for texture preservation (but may be worse
for noise reduction). In this paper we report results related to this claim. In
our reported experiments using simulated CT data collection of the head,
reconstructions whose shearlet transform has a small $\ell_1$-norm are not more
efficacious than reconstructions that have a small TV value. Our experiments
for making such comparisons use the recently-developed superiorization
methodology for both regularizing functions. Superiorization is an automated
procedure for turning an iterative algorithm for producing images that satisfy
a primary criterion (such as consistency with the observed measurements) into
its superiorized version that will produce results that, according to the
primary criterion are as good as those produced by the original algorithm, but
in addition are superior to them according to a secondary (regularizing)
criterion. The method presented for superiorization involving the $\ell_1$-norm
of the shearlet transform is novel and is quite general: It can be used for any
regularizing function that is defined as the $\ell_1$-norm of a transform
specified by the application of a matrix. Because in the previous literature
the split Bregman algorithm is used for similar purposes, a section is included
comparing the results of the superiorization algorithm with the split Bregman
algorithm.
</dc:description>
 <dc:description>Comment: 25 pages, 7 figures, Special Issue on Superiorization, Inverse
  Problems 2016</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06668</dc:identifier>
 <dc:identifier>doi:10.1088/1361-6420/33/4/044011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06669</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Clustering and Embedding Mixture Manifolds using a Low Rank
  Neighborhood Approach</dc:title>
 <dc:creator>Saranathan, Arun M.</dc:creator>
 <dc:creator>Parente, Mario</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Samples from intimate (non-linear) mixtures are generally modeled as being
drawn from a smooth manifold. Scenarios where the data contains multiple
intimate mixtures with some constituent materials in common can be thought of
as manifolds which share a boundary. Two important steps in the processing of
such data are (i) to identify (cluster) the different mixture-manifolds present
in the data and (ii) to eliminate the non-linearities present the data by
mapping each mixture-manifold into some low-dimensional euclidean space
(embedding). Manifold clustering and embedding techniques appear to be an ideal
tool for this task, but the present state-of-the-art algorithms perform poorly
for hyperspectral data, particularly in the embedding task. We propose a novel
reconstruction-based algorithm for improved clustering and embedding of
mixture-manifolds. The algorithms attempts to reconstruct each target-point as
an affine combination of its nearest neighbors with an additional rank penalty
on the neighborhood to ensure that only neighbors on the same manifold as the
target-point are used in the reconstruction. The reconstruction matrix
generated by using this technique is block-diagonal and can be used for
clustering (using spectral clustering) and embedding. The improved performance
of the algorithms vis-a-vis its competitors is exhibited on a variety of
simulated and real mixture datasets.
</dc:description>
 <dc:description>Comment: 11 Pages</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06669</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06673</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Software-Defined Networking for Ransomware Mitigation: the Case of
  CryptoWall</dc:title>
 <dc:creator>Cabaj, Krzysztof</dc:creator>
 <dc:creator>Mazurczyk, Wojciech</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Currently, different forms of ransomware are increasingly threatening
Internet users. Modern ransomware encrypts important user data and it is only
possible to recover it once a ransom has been paid. In this paper we show how
Software-Defined Networking (SDN) can be utilized to improve ransomware
mitigation. In more detail, we analyze the behavior of popular ransomware -
CryptoWall - and, based on this knowledge, we propose two real-time mitigation
methods. Then we designed the SDN-based system, implemented using OpenFlow,
which facilitates a timely reaction to this threat, and is a crucial factor in
the case of crypto ransomware. What is important is that such a design does not
significantly affect overall network performance. Experimental results confirm
that the proposed approach is feasible and efficient.
</dc:description>
 <dc:description>Comment: 9 pages, 6 figures</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06673</dc:identifier>
 <dc:identifier>IEEE Network, 2016, pp. 12-19</dc:identifier>
 <dc:identifier>doi:10.1109/MNET.2016.1600110NM</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06674</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New quantum codes from dual-containing cyclic codes over finite rings</dc:title>
 <dc:creator>Tang, Yongsheng</dc:creator>
 <dc:creator>Zhu, Shixin</dc:creator>
 <dc:creator>Kai, Xiaoshan</dc:creator>
 <dc:creator>Ding, Jian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Let $R=\mathbb{F}_{2^{m}}+u\mathbb{F}_{2^{m}}+\cdots+u^{k}\mathbb{F}_{2^{m}}$
, where $\mathbb{F}_{2^{m}}$ is a finite field with $2^{m}$ elements, $m$ is a
positive integer, $u$ is an indeterminate with $u^{k+1}=0.$ In this paper, we
propose the constructions of two new families of quantum codes obtained from
dual-containing cyclic codes of odd length over $R$. A new Gray map over $R$ is
defined and a sufficient and necessary condition for the existence of
dual-containing cyclic codes over $R$ is given. A new family of $2^{m}$-ary
quantum codes is obtained via the Gray map and the Calderbank-Shor-Steane
construction from dual-containing cyclic codes over $R.$ Furthermore, a new
family of binary quantum codes is obtained via the Gray map, the trace map and
the Calderbank-Shor-Steane construction from dual-containing cyclic codes over
$R.$
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06676</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Future Network: End-to-End Slicing and Hop-On (a Slice)</dc:title>
 <dc:creator>Zhang, Hang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The concept of network slice, i.e.,a service customized virtual network (VN)
is attracting more and more attentions in the telecommunication industry. A
slice is a set of network resources which fits the service attributes and
requirements of customer services. The network resources consist of cloud
resources and communication link resources. A slice can serve one or more
customer services which share the similar service attributes and requirements.
To define, create and manage a slice (VN) is one aspect of future networks.
Another aspect is the slice operation, i.e., the provisioning of services to
customers using created slices. In this paper, the focus is put on the
configuration of slices and the operation of slices. In this paper, the
detailed description of slice (VN) configuration is provided. A new concept of
hop-on (a slice) is described. Given a well defined and configured end-to-end
slice (VN), the realtime data traffic delivery over a slice is governed by
network operation control entities, which are also pre-configured. Therefore,
the procedure of customer traffic delivery over a slice is just like a traveler
hopping on tourist bus and then the traffic control officers at key
intersections directing the traveler to go through pre-designed routes until
the destination is reached.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06676</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06690</identifier>
 <datestamp>2017-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Convolutional Neural Network Approach for Post-Processing in HEVC
  Intra Coding</dc:title>
 <dc:creator>Dai, Yuanying</dc:creator>
 <dc:creator>Liu, Dong</dc:creator>
 <dc:creator>Wu, Feng</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Lossy image and video compression algorithms yield visually annoying
artifacts including blocking, blurring, and ringing, especially at low
bit-rates. To reduce these artifacts, post-processing techniques have been
extensively studied. Recently, inspired by the great success of convolutional
neural network (CNN) in computer vision, some researches were performed on
adopting CNN in post-processing, mostly for JPEG compressed images. In this
paper, we present a CNN-based post-processing algorithm for High Efficiency
Video Coding (HEVC), the state-of-the-art video coding standard. We redesign a
Variable-filter-size Residue-learning CNN (VRCNN) to improve the performance
and to accelerate network training. Experimental results show that using our
VRCNN as post-processing leads to on average 4.6% bit-rate reduction compared
to HEVC baseline. The VRCNN outperforms previously studied networks in
achieving higher bit-rate reduction, lower memory cost, and multiplied
computational speedup.
</dc:description>
 <dc:description>Comment: MMM 2017</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2016-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06690</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-51811-4_3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06691</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conversion Methods for Improving Structural Analysis of
  Differential-Algebraic Equation Systems</dc:title>
 <dc:creator>Tan, Guangning</dc:creator>
 <dc:creator>Nedialkov, Nedialko S.</dc:creator>
 <dc:creator>Pryce, John D.</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>34A09, 65L80, 41A58, 68W30</dc:subject>
 <dc:description>  Differential-algebraic equation systems (DAEs) are generated routinely by
simulation and modeling environments. Before a simulation starts and a
numerical method is applied, some kind of structural analysis (SA) is used to
determine which equations to be differentiated, and how many times. Both
Pantelides's algorithm and Pryce's $\Sigma$-method are equivalent: if one of
them finds correct structural information, the other does also. Nonsingularity
of the Jacobian produced by SA indicates a success, which occurs on many
problems of interest. However, these methods can fail on simple, solvable DAEs
and give incorrect structural information including the index. This article
investigates $\Sigma$-method's failures and presents two conversion methods for
fixing them. Both methods convert a DAE on which the $\Sigma$-method fails to
an equivalent problem on which this SA is more likely to succeed.
</dc:description>
 <dc:description>Comment: 22 pages</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06691</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06693</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conversion Methods, Block Triangularization, and Structural Analysis of
  Differential-Algebraic Equation Systems</dc:title>
 <dc:creator>Tan, Guangning</dc:creator>
 <dc:creator>Nedialkov, Nedialko S.</dc:creator>
 <dc:creator>Pryce, John D.</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>34A09, 65L80, 41A58, 68W30</dc:subject>
 <dc:description>  In a previous article, the authors developed two conversion methods to
improve the $\Sigma$-method for structural analysis (SA) of
differential-algebraic equations (DAEs). These methods reformulate a DAE on
which the $\Sigma$-method fails into an equivalent problem on which this SA is
more likely to succeed with a generically nonsingular Jacobian. The basic
version of these methods processes the DAE as a whole. This article presents
the block version that exploits block triangularization of a DAE. Using a block
triangular form of a Jacobian sparsity pattern, we identify which diagonal
blocks of the Jacobian are identically singular and then perform a conversion
on each such block. This approach improves the efficiency of finding a suitable
conversion for fixing SA's failures. All of our conversion methods can be
implemented in a computer algebra system so that every conversion can be
automated.
</dc:description>
 <dc:description>Comment: 25 pages, 1 figure</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06693</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06694</identifier>
 <datestamp>2017-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Study on the Idle Mode Capability with LoS and NLoS Transmissions</dc:title>
 <dc:creator>Ding, Ming</dc:creator>
 <dc:creator>Perez, David Lopez</dc:creator>
 <dc:creator>Mao, Guoqiang</dc:creator>
 <dc:creator>Lin, Zihuai</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study the impact of the base station (BS) idle mode
capability (IMC) on the network performance in dense small cell networks
(SCNs). Different from existing works, we consider a sophisticated path loss
model incorporating both line-of-sight (LoS) and non-line-of-sight (NLoS)
transmissions. Analytical results are obtained for the coverage probability and
the area spectral efficiency (ASE) performance for SCNs with IMCs at the BSs.
The upper bound, the lower bound and the approximate expression of the
activated BS density are also derived. The performance impact of the IMC is
shown to be significant. As the BS density surpasses the UE density, thus
creating a surplus of BSs, the coverage probability will continuously increase
toward one. For the practical regime of the BS density, the results derived
from our analysis are distinctively different from existing results, and thus
shed new light on the deployment and the operation of future dense SCNs.
</dc:description>
 <dc:description>Comment: final IEEE version: http://ieeexplore.ieee.org/document/7842302/.
  arXiv admin note: substantial text overlap with arXiv:1609.07710,
  arXiv:1611.01869</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2017-09-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06694</dc:identifier>
 <dc:identifier>doi:10.1109/GLOCOM.2016.7842302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06696</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flexible Paxos: Quorum intersection revisited</dc:title>
 <dc:creator>Howard, Heidi</dc:creator>
 <dc:creator>Malkhi, Dahlia</dc:creator>
 <dc:creator>Spiegelman, Alexander</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:description>  Distributed consensus is integral to modern distributed systems. The widely
adopted Paxos algorithm uses two phases, each requiring majority agreement, to
reliably reach consensus. In this paper, we demonstrate that Paxos, which lies
at the foundation of many production systems, is conservative. Specifically, we
observe that each of the phases of Paxos may use non-intersecting quorums.
Majority quorums are not necessary as intersection is required only across
phases.
  Using this weakening of the requirements made in the original formulation, we
propose Flexible Paxos, which generalizes over the Paxos algorithm to provide
flexible quorums. We show that Flexible Paxos is safe, efficient and easy to
utilize in existing distributed systems. We conclude by discussing the wide
reaching implications of this result. Examples include improved availability
from reducing the size of second phase quorums by one when the number of
acceptors is even and utilizing small disjoint phase-2 quorums to speed up the
steady-state.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06697</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic descriptions of 24 evaluational adjectives, for application in
  sentiment analysis</dc:title>
 <dc:creator>Goddard, Cliff</dc:creator>
 <dc:creator>Taboada, Maite</dc:creator>
 <dc:creator>Trnavac, Radoslava</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We apply the Natural Semantic Metalanguage (NSM) approach (Goddard and
Wierzbicka 2014) to the lexical-semantic analysis of English evaluational
adjectives and compare the results with the picture developed in the Appraisal
Framework (Martin and White 2005). The analysis is corpus-assisted, with
examples mainly drawn from film and book reviews, and supported by
collocational and statistical information from WordBanks Online. We propose NSM
explications for 24 evaluational adjectives, arguing that they fall into five
groups, each of which corresponds to a distinct semantic template. The groups
can be sketched as follows: &quot;First-person thought-plus-affect&quot;, e.g. wonderful;
&quot;Experiential&quot;, e.g. entertaining; &quot;Experiential with bodily reaction&quot;, e.g.
gripping; &quot;Lasting impact&quot;, e.g. memorable; &quot;Cognitive evaluation&quot;, e.g.
complex, excellent. These groupings and semantic templates are compared with
the classifications in the Appraisal Framework's system of Appreciation. In
addition, we are particularly interested in sentiment analysis, the automatic
identification of evaluation and subjectivity in text. We discuss the relevance
of the two frameworks for sentiment analysis and other language technology
applications.
</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06697</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06709</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computer-Aided Colorectal Tumor Classification in NBI Endoscopy Using
  CNN Features</dc:title>
 <dc:creator>Tamaki, Toru</dc:creator>
 <dc:creator>Sonoyama, Shoji</dc:creator>
 <dc:creator>Hirakawa, Tsubasa</dc:creator>
 <dc:creator>Raytchev, Bisser</dc:creator>
 <dc:creator>Kaneda, Kazufumi</dc:creator>
 <dc:creator>Koide, Tetsushi</dc:creator>
 <dc:creator>Yoshida, Shigeto</dc:creator>
 <dc:creator>Mieno, Hiroshi</dc:creator>
 <dc:creator>Tanaka, Shinji</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we report results for recognizing colorectal NBI endoscopic
images by using features extracted from convolutional neural network (CNN). In
this comparative study, we extract features from different layers from
different CNN models, and then train linear SVM classifiers. Experimental
results with 10-fold cross validations show that features from first few
convolution layers are enough to achieve similar performance (i.e., recognition
rate of 95%) with non-CNN local features such as Bag-of-Visual words, Fisher
vector, and VLAD.
</dc:description>
 <dc:description>Comment: 5 pages, FCV2016</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06713</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transfer Learning for Endoscopic Image Classification</dc:title>
 <dc:creator>Sonoyama, Shoji</dc:creator>
 <dc:creator>Tamaki, Toru</dc:creator>
 <dc:creator>Hirakawa, Tsubasa</dc:creator>
 <dc:creator>Raytchev, Bisser</dc:creator>
 <dc:creator>Kaneda, Kazufumi</dc:creator>
 <dc:creator>Koide, Tetsushi</dc:creator>
 <dc:creator>Yoshida, Shigeto</dc:creator>
 <dc:creator>Mieno, Hiroshi</dc:creator>
 <dc:creator>Tanaka, Shinji</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we propose a method for transfer learning of endoscopic images.
For transferring between features obtained from images taken by different (old
and new) endoscopes, we extend the Max-Margin Domain Transfer (MMDT) proposed
by Hoffman et al. in order to use L2 distance constraints as regularization,
called Max-Margin Domain Transfer with L2 Distance Constraints (MMDTL2).
Furthermore, we develop the dual formulation of the optimization problem in
order to reduce the computation cost. Experimental results demonstrate that the
proposed MMDTL2 outperforms MMDT for real data sets taken by different
endoscopes.
</dc:description>
 <dc:description>Comment: 5 pages, FCV2016</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06713</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06716</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Approach for Shot Boundary Detection in Videos</dc:title>
 <dc:creator>Guru, D. S.</dc:creator>
 <dc:creator>Suhil, Mahamad</dc:creator>
 <dc:creator>Lolika, P.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a novel approach for video shot boundary detection. The
proposed approach is based on split and merge concept. A fisher linear
discriminant criterion is used to guide the process of both splitting and
merging. For the purpose of capturing the between class and within class
scatter we employ 2D2 FLD method which works on texture feature of regions in
each frame of a video. Further to reduce the complexity of the process we
propose to employ spectral clustering to group related regions together to a
single there by achieving reduction in dimension. The proposed method is
experimentally also validated on a cricket video. It is revealed that shots
obtained by the proposed approach are highly cohesive and loosely coupled
</dc:description>
 <dc:description>Comment: 12 pages, 2 figures, 2 tables; Conference: Multimedia Processing,
  Communication and Computing Applications, 2012</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06716</dc:identifier>
 <dc:identifier>ICMCCA, Springer LNEE 213, pp. 209-220, Springer India (2013)</dc:identifier>
 <dc:identifier>doi:10.1007/978-81-322-1143-3_17</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06718</identifier>
 <datestamp>2017-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Large-Scale Multilingual Disambiguation of Glosses</dc:title>
 <dc:creator>Collados, Jos&#xe9; Camacho</dc:creator>
 <dc:creator>Bovi, Claudio Delli</dc:creator>
 <dc:creator>Raganato, Alessandro</dc:creator>
 <dc:creator>Navigli, Roberto</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Linking concepts and named entities to knowledge bases has become a crucial
Natural Language Understanding task. In this respect, recent works have shown
the key advantage of exploiting textual definitions in various Natural Language
Processing applications. However, to date there are no reliable large-scale
corpora of sense-annotated textual definitions available to the research
community. In this paper we present a large-scale high-quality corpus of
disambiguated glosses in multiple languages, comprising sense annotations of
both concepts and named entities from a unified sense inventory. Our approach
for the construction and disambiguation of the corpus builds upon the structure
of a large multilingual semantic network and a state-of-the-art disambiguation
system; first, we gather complementary information of equivalent definitions
across different languages to provide context for disambiguation, and then we
combine it with a semantic similarity-based refinement. As a result we obtain a
multilingual corpus of textual definitions featuring over 38 million
definitions in 263 languages, and we make it freely available at
http://lcl.uniroma1.it/disambiguated-glosses. Experiments on Open Information
Extraction and Sense Clustering show how two state-of-the-art approaches
improve their performance by integrating our disambiguated corpus into their
pipeline.
</dc:description>
 <dc:description>Comment: Accepted in LREC 2016</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06718</dc:identifier>
 <dc:identifier>Proceedings of the Tenth International Conference on Language
  Resources and Evaluation (LREC), 2016, pages 1701-1708, Portoroz, Slovenia</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06724</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Sensitivity Complexity of $k$-Uniform Hypergraph Properties</dc:title>
 <dc:creator>Li, Qian</dc:creator>
 <dc:creator>Sun, Xiaoming</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In this paper we investigate the sensitivity complexity of hypergraph
properties. We present a $k$-uniform hypergraph property with sensitivity
complexity $O(n^{\lceil k/3\rceil})$ for any $k\geq3$, where $n$ is the number
of vertices. Moreover, we can do better when $k\equiv1$ (mod 3) by presenting a
$k$-uniform hypergraph property with sensitivity $O(n^{\lceil k/3\rceil-1/2})$.
This result disproves a conjecture of Babai~\cite{Babai}, which conjectures
that the sensitivity complexity of $k$-uniform hypergraph properties is at
least $\Omega(n^{k/2})$. We also investigate the sensitivity complexity of
other symmetric functions and show that for many classes of transitive Boolean
functions the minimum achievable sensitivity complexity can be $O(N^{1/3})$,
where $N$ is the number of variables. Finally, we give a lower bound for
sensitivity of $k$-uniform hypergraph properties, which implies the {\em
sensitivity conjecture} of $k$-uniform hypergraph properties for any constant
$k$.
</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06729</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Completeness for a First-order Abstract Separation Logic</dc:title>
 <dc:creator>Hou, Zhe</dc:creator>
 <dc:creator>Tiu, Alwen</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Existing work on theorem proving for the assertion language of separation
logic (SL) either focuses on abstract semantics which are not readily available
in most applications of program verification, or on concrete models for which
completeness is not possible. An important element in concrete SL is the
points-to predicate which denotes a singleton heap. SL with the points-to
predicate has been shown to be non-recursively enumerable. In this paper, we
develop a first-order SL, called FOASL, with an abstracted version of the
points-to predicate. We prove that FOASL is sound and complete with respect to
an abstract semantics, of which the standard SL semantics is an instance. We
also show that some reasoning principles involving the points-to predicate can
be approximated as FOASL theories, thus allowing our logic to be used for
reasoning about concrete program verification problems. We give some example
theories that are sound with respect to different variants of separation logics
from the literature, including those that are incompatible with Reynolds's
semantics. In the experiment we demonstrate our FOASL based theorem prover
which is able to handle a large fragment of separation logic with heap
semantics as well as non-standard semantics.
</dc:description>
 <dc:description>Comment: This is an extended version of the APLAS 2016 paper with the same
  title</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06748</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quasi-Perfect Lee Codes from Quadratic Curves over Finite Fields</dc:title>
 <dc:creator>Mesnager, Sihem</dc:creator>
 <dc:creator>Tang, Chunming</dc:creator>
 <dc:creator>Qi, Yanfeng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Golomb and Welch conjectured in 1970 that there only exist perfect Lee codes
for radius $t=1$ or dimension $n=1, 2$. It is admitted that the existence and
the construction of quasi-perfect Lee codes have to be studied since they are
the best alternative to the perfect codes. In this paper we firstly highlight
the relationships between subset sums, Cayley graphs, and Lee linear codes and
present some results. Next, we present a new constructive method for
constructing quasi-perfect Lee codes. Our approach uses subsets derived from
some quadratic curves over finite fields (in odd characteristic) to derive two
classes of $2$-quasi-perfect Lee codes are given over the space
$\mathbb{Z}_p^n$ for $n=\frac{p^k+1}{2}$ $(\text{with} ~p\equiv 1, -5 \mod 12
\text{and} k \text{is any integer}, \text{or} p\equiv -1, 5 \mod 12 \text{and}
k \text{is an even integer})$ and $n=\frac{p^k-1}{2}$ $(\text{with}p\equiv -1,
5 \mod 12, k \text{is an odd integer} \text{and} p^k&gt;12)$, where $p$ is an odd
prime. Our codes encompass the quasi-perfect Lee codes constructed recently by
Camarero and Mart\'inez. Furthermore, we solve a conjecture proposed by
Camarero and Mart\'inez (in &quot;quasi-perfect Lee codes of radius $2$ and
arbitrarily large dimension&quot;, IEEE Trans. Inf. Theory, vol. 62, no. 3, 2016) by
proving that the related Cayley graphs are Ramanujan or almost Ramanujan. The
Lee codes presented in this paper have applications to constrained and
partial-response channels, in flash memories and decision diagrams.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1412.5797 by other authors</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06748</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06749</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Load Coupling Power Optimization in Cloud Radio Access Networks</dc:title>
 <dc:creator>Fan, Qiang</dc:creator>
 <dc:creator>Lu, Hancheng</dc:creator>
 <dc:creator>Jiang, Wei</dc:creator>
 <dc:creator>Hong, Peilin</dc:creator>
 <dc:creator>Wu, Jun</dc:creator>
 <dc:creator>Chen, Chang Wen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Recently, Cloud-based Radio Access Network (C-RAN) has been proposed as a
potential solution to reduce energy cost in cellular networks. C-RAN
centralizes the baseband processing capabilities of Base Stations (BSs) in a
cloud computing platform in the form of BaseBand Unit (BBU) pool. In C-RAN,
power consumed by the traditional BS system is distributed as wireless
transmission power of the Remote Radio Heads (RRHs) and baseband processing
power of the BBU pool. Different from previous work where wireless transmission
power and baseband processing power are optimized individually and
independently, this paper focuses on joint optimization of allocation for these
two kinds of power and attempts to minimize the total power consumption subject
to Quality of Service (QoS) requirements from users in terms of data rates.
First, we exploit the load coupling model to express the coupling relations
among power, load and user data rates. Based on the load coupling mode, we
formulate the joint power optimization problem in C-RAN over both wireless
transmission power and baseband processing power. Second, we prove that
operating at full load may not be optimal in minimizing the total power
consumption in C-RAN. Finally, we propose an efficient iterative algorithm to
solve the target problem. Simulations have been performed to validate our
theoretical and algorithmic work. The results show that the proposed algorithm
outperforms existing schemes (without joint power optimization) in terms of
power consumption.
</dc:description>
 <dc:description>Comment: This paper is written in 10 pages with 7 figures. This paper has been
  submitted to IEEE Transactionso on Vehicular Technology for peer review</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06749</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06753</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Correctness of Inverted Index Based Public-Key Searchable
  Encryption Scheme for Multi-time Search</dc:title>
 <dc:creator>Ji, Shiyu</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this short note we argue that the state-of-art inverted index based public
key searchable encryption scheme proposed by Wang et al may not be completely
correct by giving a counterexample.
</dc:description>
 <dc:description>Comment: 3 pages, no figure</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06753</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06754</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resource Allocation in Dynamic TDD Heterogeneous Networks under Mixed
  Traffic</dc:title>
 <dc:creator>Fan, Qiang</dc:creator>
 <dc:creator>Lu, Hancheng</dc:creator>
 <dc:creator>Hong, Peilin</dc:creator>
 <dc:creator>Chen, Chang Wen</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Recently, Dynamic Time Division Duplex (TDD) has been proposed to handle the
asymmetry of traffic demand between DownLink (DL) and UpLink (UL) in
Heterogeneous Networks (HetNets). However, for mixed traffic consisting of best
effort traffic and soft Quality of Service (QoS) traffic, the resource
allocation problem has not been adequately studied in Dynamic TDD HetNets. In
this paper, we focus on such problem in a two-tier HetNet with co-channel
deployment of one Macro cell Base Station (MBS) and multiple Small cell Base
Stations (SBSs) in hotspots. Different from existing work, we introduce low
power almost blank subframes to alleviate MBS-to-SBS interference which is
inherent in TDD operation. To tackle the resource allocation problem, we
propose a two-step strategy. First, from the view point of base stations, we
propose a transmission protocol and perform time resource allocation by
formulating and solving a network capacity maximization problem under DL/UL
traffic demands. Second, from the view point of User Equipments (UEs), we
formulate their resource allocation as a Network Utility Maximization (NUM)
problem. An efficient iterative algorithm is proposed to solve the NUM problem.
Simulations show the advantage of the proposed algorithm in terms of network
throughput and UE QoS satisfaction level.
</dc:description>
 <dc:description>Comment: This paper is written in 12 pages with 8 figures. This paper has been
  submitted to IEEE Transactions on Wireless Communications for peer review</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06757</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Named Entity Recognition in Idiosyncratic Domains</dc:title>
 <dc:creator>Arnold, Sebastian</dc:creator>
 <dc:creator>Gers, Felix A.</dc:creator>
 <dc:creator>Kilias, Torsten</dc:creator>
 <dc:creator>L&#xf6;ser, Alexander</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Named entity recognition often fails in idiosyncratic domains. That causes a
problem for depending tasks, such as entity linking and relation extraction. We
propose a generic and robust approach for high-recall named entity recognition.
Our approach is easy to train and offers strong generalization over diverse
domain-specific language, such as news documents (e.g. Reuters) or biomedical
text (e.g. Medline). Our approach is based on deep contextual sequence learning
and utilizes stacked bidirectional LSTM networks. Our model is trained with
only few hundred labeled sentences and does not rely on further external
knowledge. We report from our results F1 scores in the range of 84-94% on
standard datasets.
</dc:description>
 <dc:description>Comment: 8 pages, 1 figure</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06759</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Systematic Evaluation of Sandboxed Software Deployment for Real-time
  Software on the Example of a Self-Driving Heavy Vehicle</dc:title>
 <dc:creator>Masek, Philip</dc:creator>
 <dc:creator>Thulin, Magnus</dc:creator>
 <dc:creator>Andrade, Hugo</dc:creator>
 <dc:creator>Berger, Christian</dc:creator>
 <dc:creator>Benderius, Ola</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Companies developing and maintaining software-only products like web shops
aim for establishing persistent links to their software running in the field.
Monitoring data from real usage scenarios allows for a number of improvements
in the software life-cycle, such as quick identification and solution of
issues, and elicitation of requirements from previously unexpected usage. While
the processes of continuous integration, continuous deployment, and continuous
experimentation using sandboxing technologies are becoming well established in
said software-only products, adopting similar practices for the automotive
domain is more complex mainly due to real-time and safety constraints. In this
paper, we systematically evaluate sandboxed software deployment in the context
of a self-driving heavy vehicle that participated in the 2016 Grand Cooperative
Driving Challenge (GCDC) in The Netherlands. We measured the system's
scheduling precision after deploying applications in four different execution
environments. Our results indicate that there is no significant difference in
performance and overhead when sandboxed environments are used compared to
natively deployed software. Thus, recent trends in software architecting,
packaging, and maintenance using microservices encapsulated in sandboxes will
help to realize similar software and system engineering for cyber-physical
systems.
</dc:description>
 <dc:description>Comment: Copyright 2016 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06759</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06761</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Study of Vision based Human Motion Recognition and Analysis</dc:title>
 <dc:creator>Kale, Geetanjali Vinayak</dc:creator>
 <dc:creator>Patil, Varsha Hemant</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.2.10, I.4.8, I.5.4</dc:subject>
 <dc:description>  Vision based human motion recognition has fascinated many researchers due to
its critical challenges and a variety of applications. The applications range
from simple gesture recognition to complicated behaviour understanding in
surveillance system. This leads to major development in the techniques related
to human motion representation and recognition. This paper discusses
applications, general framework of human motion recognition, and the details of
each of its components. The paper emphasizes on human motion representation and
the recognition methods along with their advantages and disadvantages. This
study also discusses the selected literature, popular datasets, and concludes
with the challenges in the domain along with a future direction. The human
motion recognition domain has been active for more than two decades, and has
provided a large amount of literature. A bird's eye view for new researchers in
the domain is presented in the paper.
</dc:description>
 <dc:description>Comment: 5 Figures, 18 Pages, International Journal of Ambient Computing and
  Intelligence, Volume 7 Issue 2,July-December 2016</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06761</dc:identifier>
 <dc:identifier>doi:10.4018/IJACI.2016070104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06767</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On-line Joint Limit Avoidance for Torque Controlled Robots by Joint
  Space Parametrization</dc:title>
 <dc:creator>Charbonneau, Marie</dc:creator>
 <dc:creator>Nori, Francesco</dc:creator>
 <dc:creator>Pucci, Daniele</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>93C85, 70E60, 70B15, 68T40</dc:subject>
 <dc:description>  This paper proposes control laws ensuring the stabilization of a time-varying
desired joint trajectory, as well as joint limit avoidance, in the case of
fully-actuated manipulators. The key idea is to perform a parametrization of
the feasible joint space in terms of exogenous states. It follows that the
control of these states allows for joint limit avoidance. One of the main
outcomes of this paper is that position terms in control laws are replaced by
parametrized terms, where joint limits must be avoided. Stability and
convergence of time-varying reference trajectories obtained with the proposed
method are demonstrated to be in the sense of Lyapunov. The introduced control
laws are verified by carrying out experiments on two degrees-of-freedom of the
humanoid robot iCub.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures. Submitted to the 2016 IEEE-RAS International
  Conference on Humanoid Robots</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2017-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06767</dc:identifier>
 <dc:identifier>2016 IEEE-RAS 16th International Conference on Humanoid Robots
  (Humanoids)</dc:identifier>
 <dc:identifier>doi:10.1109/HUMANOIDS.2016.7803379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06770</identifier>
 <datestamp>2017-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Synchronization of Multi-User Photo Galleries</dc:title>
 <dc:creator>Sansone, E.</dc:creator>
 <dc:creator>Apostolidis, K.</dc:creator>
 <dc:creator>Conci, N.</dc:creator>
 <dc:creator>Boato, G.</dc:creator>
 <dc:creator>Mezaris, V.</dc:creator>
 <dc:creator>De Natale, F. G. B.</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we address the issue of photo galleries synchronization, where
pictures related to the same event are collected by different users. Existing
solutions to address the problem are usually based on unrealistic assumptions,
like time consistency across photo galleries, and often heavily rely on
heuristics, limiting therefore the applicability to real-world scenarios. We
propose a solution that achieves better generalization performance for the
synchronization task compared to the available literature. The method is
characterized by three stages: at first, deep convolutional neural network
features are used to assess the visual similarity among the photos; then, pairs
of similar photos are detected across different galleries and used to construct
a graph; eventually, a probabilistic graphical model is used to estimate the
temporal offset of each pair of galleries, by traversing the minimum spanning
tree extracted from this graph. The experimental evaluation is conducted on
four publicly available datasets covering different types of events,
demonstrating the strength of our proposed method. A thorough discussion of the
obtained results is provided for a critical assessment of the quality in
synchronization.
</dc:description>
 <dc:description>Comment: ACCEPTED to IEEE Transactions on Multimedia</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2017-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06770</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06787</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Expressibility of norms in temporal logic</dc:title>
 <dc:creator>Alechina, Natasha</dc:creator>
 <dc:creator>Dastani, Mehdi</dc:creator>
 <dc:creator>Logan, Brian</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this short note we address the issue of expressing norms (such as
obligations and prohibitions) in temporal logic. In particular, we address the
argument from [Governatori 2015] that norms cannot be expressed in Linear Time
Temporal Logic (LTL).
</dc:description>
 <dc:description>Comment: 3 pages</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06794</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Sparse Word Representations with Distributional Inference for
  Semantic Composition</dc:title>
 <dc:creator>Kober, Thomas</dc:creator>
 <dc:creator>Weeds, Julie</dc:creator>
 <dc:creator>Reffin, Jeremy</dc:creator>
 <dc:creator>Weir, David</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Distributional models are derived from co-occurrences in a corpus, where only
a small proportion of all possible plausible co-occurrences will be observed.
This results in a very sparse vector space, requiring a mechanism for inferring
missing knowledge. Most methods face this challenge in ways that render the
resulting word representations uninterpretable, with the consequence that
semantic composition becomes hard to model. In this paper we explore an
alternative which involves explicitly inferring unobserved co-occurrences using
the distributional neighbourhood. We show that distributional inference
improves sparse word representations on several word similarity benchmarks and
demonstrate that our model is competitive with the state-of-the-art for
adjective-noun, noun-noun and verb-object compositions while being fully
interpretable.
</dc:description>
 <dc:description>Comment: To appear at EMNLP 2016</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06797</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Additive Stabilizers for Unstable Graphs</dc:title>
 <dc:creator>Chandrasekaran, Karthekeyan</dc:creator>
 <dc:creator>Gottschalk, Corinna</dc:creator>
 <dc:creator>K&#xf6;nemann, Jochen</dc:creator>
 <dc:creator>Peis, Britta</dc:creator>
 <dc:creator>Schmand, Daniel</dc:creator>
 <dc:creator>Wierz, Andreas</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Stabilization of graphs has received substantial attention in recent years
due to its connection to game theory. Stable graphs are exactly the graphs
inducing a matching game with non-empty core. They are also the graphs that
induce a network bargaining game with a balanced solution. A graph with
weighted edges is called stable if the maximum weight of an integral matching
equals the cost of a minimum fractional weighted vertex cover. If a graph is
not stable, it can be stabilized in different ways. Recent papers have
considered the deletion or addition of edges and vertices in order to stabilize
a graph. In this work, we focus on a fine-grained stabilization strategy,
namely stabilization of graphs by fractionally increasing edge weights. We show
the following results for stabilization by minimum weight increase in edge
weights (min additive stabilizer): (i) Any approximation algorithm for min
additive stabilizer that achieves a factor of $O(|V|^{1/24-\epsilon})$ for
$\epsilon&gt;0$ would lead to improvements in the approximability of
densest-$k$-subgraph. (ii) Min additive stabilizer has no $o(\log{|V|})$
approximation unless NP=P. Results (i) and (ii) together provide the first
super-constant hardness results for any graph stabilization problem. On the
algorithmic side, we present (iii) an algorithm to solve min additive
stabilizer in factor-critical graphs exactly in poly-time, (iv) an algorithm to
solve min additive stabilizer in arbitrary-graphs exactly in time exponential
in the size of the Tutte set, and (v) a poly-time algorithm with approximation
factor at most $\sqrt{|V|}$ for a super-class of the instances generated in our
hardness proofs.
</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06797</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06800</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>In the Saddle: Chasing Fast and Repeatable Features</dc:title>
 <dc:creator>Aldana-Iuit, Javier</dc:creator>
 <dc:creator>Mishkin, Dmytro</dc:creator>
 <dc:creator>Chum, Ondrej</dc:creator>
 <dc:creator>Matas, Jiri</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A novel similarity-covariant feature detector that extracts points whose
neighbourhoods, when treated as a 3D intensity surface, have a saddle-like
intensity profile. The saddle condition is verified efficiently by intensity
comparisons on two concentric rings that must have exactly two dark-to-bright
and two bright-to-dark transitions satisfying certain geometric constraints.
Experiments show that the Saddle features are general, evenly spread and
appearing in high density in a range of images. The Saddle detector is among
the fastest proposed. In comparison with detector with similar speed, the
Saddle features show superior matching performance on number of challenging
datasets.
</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06807</identifier>
 <datestamp>2016-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Training for Positive Unlabeled Learning</dc:title>
 <dc:creator>Sansone, Emanuele</dc:creator>
 <dc:creator>De Natale, Francesco G. B.</dc:creator>
 <dc:creator>Zhou, Zhi-Hua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Positive unlabeled (PU) learning is useful in various practical situations,
where there is a need to learn a classifier for a class of interest from an
unlabeled data set, which may contain anomalies as well as samples from unknown
classes. The learning task can be formulated as an optimization problem under
the framework of statistical learning theory. Recent studies have theoretically
analyzed its properties and generalization performance, nevertheless, little
effort has been made to consider the problem of scalability, especially when
large sets of unlabeled data are available. In this work we propose a novel
scalable PU learning algorithm that is theoretically proven to provide the
optimal solution, while showing superior computational and memory performance.
Experimental evaluation confirms the theoretical evidence and shows that the
proposed method can be successfully applied to a large variety of real-world
problems involving PU learning.
</dc:description>
 <dc:description>Comment: Submitted to IEEE TPAMI</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2016-10-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06819</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pricing and Optimization in Shared Vehicle Systems: An Approximation
  Framework</dc:title>
 <dc:creator>Banerjee, Siddhartha</dc:creator>
 <dc:creator>Freund, Daniel</dc:creator>
 <dc:creator>Lykouris, Thodoris</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Optimizing shared vehicle systems (bike-sharing/car-sharing/ride-sharing) is
more challenging compared to traditional resource allocation settings due to
the presence of \emph{complex network externalities} -- changes in the
demand/supply at any location affect future supply throughout the system within
short timescales. These externalities are well captured by steady-state
Markovian models, which are therefore widely used to analyze such systems.
However, using such models to design pricing/control policies is
computationally difficult since the resulting optimization problems are
high-dimensional and non-convex.
  To this end, we develop a general approximation framework for designing
pricing policies in shared vehicle systems, based on a novel convex relaxation
which we term \emph{elevated flow relaxation}. Our approach provides the first
efficient algorithms with \emph{rigorous approximation guarantees} for a wide
range of objective functions (throughput, revenue, welfare). For any shared
vehicle system with $n$ stations and $m$ vehicles, our framework provides a
pricing policy with an approximation ratio of $1+(n-1)/m$. This guarantee is
particularly meaningful when $m/n$, the average number of vehicles per station
is large, as is often the case in practice.
  Further, the simplicity of our approach allows us to extend it to more
complex settings: rebalancing empty vehicles, redirecting riders to nearby
vehicles, multi-objective settings (such as Ramsey pricing), incorporating
travel-times, etc. Our approach yields efficient algorithms with the same
approximation guarantees for all these problems, and in the process, obtains as
special cases several existing heuristics and asymptotic guarantees.
</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06828</identifier>
 <datestamp>2017-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient algorithms for computing the Euler-Poincar\'e characteristic
  of symmetric semi-algebraic sets</dc:title>
 <dc:creator>Basu, Saugata</dc:creator>
 <dc:creator>Riener, Cordian</dc:creator>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>14P25, 68W30</dc:subject>
 <dc:description>  Let $\mathrm{R}$ be a real closed field and $\mathrm{D} \subset \mathrm{R}$
an ordered domain. We consider the algorithmic problem of computing the
generalized Euler-Poincar\'e characteristic of real algebraic as well as
semi-algebraic subsets of $\mathrm{R}^k$, which are defined by symmetric
polynomials with coefficients in $\mathrm{D}$. We give algorithms for computing
the generalized Euler-Poincar\'e characteristic of such sets, whose
complexities measured by the number the number of arithmetic operations in
$\mathrm{D}$, are polynomially bounded in terms of $k$ and the number of
polynomials in the input, assuming that the degrees of the input polynomials
are bounded by a constant. This is in contrast to the best complexity of the
known algorithms for the same problems in the non-symmetric situation, which
are singly exponential. This singly exponential complexity for the latter
problem is unlikely to be improved because of hardness result
($\#\mathbf{P}$-hardness) coming from discrete complexity theory.
</dc:description>
 <dc:description>Comment: 29 pages, 1 Figure. arXiv admin note: substantial text overlap with
  arXiv:1312.6582</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2017-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06828</dc:identifier>
 <dc:identifier>Contemporary Mathematics, Vol 697, 2017</dc:identifier>
 <dc:identifier>doi:10.1090/conm/697/14046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06830</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$E^2$-MAC: Energy Efficient Medium Access for Massive M2M Communications</dc:title>
 <dc:creator>Miao, Guowang</dc:creator>
 <dc:creator>Azari, Amin</dc:creator>
 <dc:creator>Hwang, Taewon</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, we investigate energy-efficient clustering and medium access
control (MAC) for cellular-based M2M networks to minimize device energy
consumption and prolong network battery lifetime. First, we present an accurate
energy consumption model that considers both static and dynamic energy
consumptions, and utilize this model to derive the network lifetime. Second, we
find the cluster size to maximize the network lifetime and develop an
energy-efficient cluster-head selection scheme. Furthermore, we find feasible
regions where clustering is beneficial in enhancing network lifetime. We
further investigate communications protocols for both intra- and inter-cluster
communications. While inter-cluster communications use conventional cellular
access schemes, we develop an energy-efficient and load-adaptive multiple
access scheme, called n-phase CSMA/CA, which provides a tunable tradeoff
between energy efficiency, delay, and spectral efficiency of the network. The
simulation results show that the proposed clustering, cluster-head selection,
and communications protocol design outperform the others in energy saving and
significantly prolong the lifetimes of both individual nodes and the whole M2M
network.
</dc:description>
 <dc:description>Comment: Accepted in IEEE Transactions on communications</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06845</identifier>
 <datestamp>2016-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effect of Incomplete Meta-dataset on Average Ranking Method</dc:title>
 <dc:creator>Abdulrahman, Salisu Mamman</dc:creator>
 <dc:creator>Brazdil, Pavel</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  One of the simplest metalearning methods is the average ranking method. This
method uses metadata in the form of test results of a given set of algorithms
on given set of datasets and calculates an average rank for each algorithm. The
ranks are used to construct the average ranking. We investigate the problem of
how the process of generating the average ranking is affected by incomplete
metadata including fewer test results. This issue is relevant, because if we
could show that incomplete metadata does not affect the final results much, we
could explore it in future design. We could simply conduct fewer tests and save
thus computation time. In this paper we describe an upgraded average ranking
method that is capable of dealing with incomplete metadata. Our results show
that the proposed method is relatively robust to omission in test results in
the meta datasets.
</dc:description>
 <dc:description>Comment: 8 pages, two figures and 6 tables</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06850</identifier>
 <datestamp>2017-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximizing Influence in an Ising Network: A Mean-Field Optimal Solution</dc:title>
 <dc:creator>Lynn, Christopher</dc:creator>
 <dc:creator>Lee, Daniel D.</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Influence maximization in social networks has typically been studied in the
context of contagion models and irreversible processes. In this paper, we
consider an alternate model that treats individual opinions as spins in an
Ising system at dynamic equilibrium. We formalize the \textit{Ising influence
maximization} problem, which has a natural physical interpretation as
maximizing the magnetization given a budget of external magnetic field. Under
the mean-field (MF) approximation, we present a gradient ascent algorithm that
uses the susceptibility to efficiently calculate local maxima of the
magnetization, and we develop a number of sufficient conditions for when the MF
magnetization is concave and our algorithm converges to a global optimum. We
apply our algorithm on random and real-world networks, demonstrating,
remarkably, that the MF optimal external fields (i.e., the external fields
which maximize the MF magnetization) shift from focusing on high-degree
individuals at high temperatures to focusing on low-degree individuals at low
temperatures. We also establish a number of novel results about the structure
of steady-states in the ferromagnetic MF Ising model on general graph
topologies, which are of independent interest.
</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2017-02-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06850</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06861</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel K-Medoids++ Spatial Clustering Algorithm Based on MapReduce</dc:title>
 <dc:creator>Yue, Xia</dc:creator>
 <dc:creator>Man, Wang</dc:creator>
 <dc:creator>Yue, Jun</dc:creator>
 <dc:creator>Liu, Guangcao</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Clustering analysis has received considerable attention in spatial data
mining for several years. With the rapid development of the geospatial
information technologies, the size of spatial information data is growing
exponentially which makes clustering massive spatial data a challenging task.
In order to improve the efficiency of spatial clustering for large scale data,
many researchers proposed several efficient clustering algorithms in parallel.
In this paper, a new K-Medoids++ spatial clustering algorithm based on
MapReduce for clustering massive spatial data is proposed. The initialization
algorithm to decrease the number of iterations is combined with the MapReduce
framework. Comparative Experiments conducted over different dataset and
different number of nodes indicate that the proposed K-Medoids spatial
clustering algorithm provides better efficiency than traditional K-Medoids and
scales well while processing massive spatial data on commodity hardware.
</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06863</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kullback-Leibler Penalized Sparse Discriminant Analysis for
  Event-Related Potential Classification</dc:title>
 <dc:creator>Peterson, Victoria</dc:creator>
 <dc:creator>Rufiner, Hugo Leonardo</dc:creator>
 <dc:creator>Spies, Ruben Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A brain computer interface (BCI) is a system which provides direct
communication between the mind of a person and the outside world by using only
brain activity (EEG). The event-related potential (ERP)-based BCI problem
consists of a binary pattern recognition. Linear discriminant analysis (LDA) is
widely used to solve this type of classification problems, but it fails when
the number of features is large relative to the number of observations. In this
work we propose a penalized version of the sparse discriminant analysis (SDA),
called Kullback-Leibler penalized sparse discriminant analysis (KLSDA). This
method inherits both the discriminative feature selection and classification
properties of SDA and it also improves SDA performance through the addition of
Kullback-Leibler class discrepancy information. The KLSDA method is design to
automatically select the optimal regularization parameters. Numerical
experiments with two real ERP-EEG datasets show that this new method
outperforms standard SDA.
</dc:description>
 <dc:description>Comment: 27 pages, 4 figures</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06863</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06865</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Statistics in Software Engineering: Practical Guide and Case
  Studies</dc:title>
 <dc:creator>Furia, Carlo A.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Statistics comes in two main flavors: frequentist and Bayesian. For
historical and technical reasons, frequentist statistics has dominated data
analysis in the past; but Bayesian statistics is making a comeback at the
forefront of science. In this paper, we give a practical overview of Bayesian
statistics and illustrate its main advantages over frequentist statistics for
the kinds of analyses that are common in empirical software engineering, where
frequentist statistics still is standard. We also apply Bayesian statistics to
empirical data from previous research investigating agile vs. structured
development processes, the performance of programming languages, and random
testing of object-oriented programs. In addition to being case studies
demonstrating how Bayesian analysis can be applied in practice, they provide
insights beyond the results in the original publications (which used
frequentist statistics), thus showing the practical value brought by Bayesian
statistics.
</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06865</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06874</identifier>
 <datestamp>2016-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Perfect vector sets, properly overlapping partitions, and largest empty
  box</dc:title>
 <dc:creator>Dumitrescu, Adrian</dc:creator>
 <dc:creator>Jiang, Minghui</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We revisit the following problem (along with its higher dimensional variant):
Given a set $S$ of $n$ points inside an axis-parallel rectangle $U$ in the
plane, find a maximum-area axis-parallel sub-rectangle that is contained in $U$
but contains no points of $S$. (I) We present an algorithm that finds a large
empty box amidst $n$ points in $[0,1]^d$: a box whose volume is at least
$\frac{\log{d}}{4(n + \log{d})}$ can be computed in $O(n+d \log{d})$ time. (II)
To better analyze the above approach, we introduce the concepts of perfect
vector sets and properly overlapping partitions, in connection to the minimum
volume of a maximum empty box amidst $n$ points in the unit hypercube
$[0,1]^d$, and derive bounds on their sizes.
</dc:description>
 <dc:description>Comment: 14 pages, 1 figure; updated bibliography and note added at the end of
  Section 7</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2016-10-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06874</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06876</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sedano: A News Stream Processor for Business</dc:title>
 <dc:creator>Scaiella, Ugo</dc:creator>
 <dc:creator>Berardi, Giacomo</dc:creator>
 <dc:creator>Mega, Giuliano</dc:creator>
 <dc:creator>Santoro, Roberto</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  We present Sedano, a system for processing and indexing a continuous stream
of business-related news. Sedano defines pipelines whose stages analyze and
enrich news items (e.g., newspaper articles and press releases). News data
coming from several content sources are stored, processed and then indexed in
order to be consumed by Atoka, our business intelligence product. Atoka users
can retrieve news about specific companies, filtering according to various
facets. Sedano features both an entity-linking phase, which finds mentions of
companies in news, and a classification phase, which classifies news according
to a set of business events. Its flexible architecture allows Sedano to be
deployed on commodity machines while being scalable and fault-tolerant.
</dc:description>
 <dc:description>Comment: 2 pages, 1 figure. SIGIR '16 July 17-21, 2016, Pisa, Italy</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06876</dc:identifier>
 <dc:identifier>Proceedings of the 39th International ACM SIGIR Conference on
  Research and Development in Information Retrieval (SIGIR 2016). pp 525-526.
  Pisa, IT, 2016</dc:identifier>
 <dc:identifier>doi:10.1145/2911451.2926730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06879</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AIDE: Fast and Communication Efficient Distributed Optimization</dc:title>
 <dc:creator>Reddi, Sashank J.</dc:creator>
 <dc:creator>Kone&#x10d;n&#xfd;, Jakub</dc:creator>
 <dc:creator>Richt&#xe1;rik, Peter</dc:creator>
 <dc:creator>P&#xf3;cz&#xf3;s, Barnab&#xe1;s</dc:creator>
 <dc:creator>Smola, Alex</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we present two new communication-efficient methods for
distributed minimization of an average of functions. The first algorithm is an
inexact variant of the DANE algorithm that allows any local algorithm to return
an approximate solution to a local subproblem. We show that such a strategy
does not affect the theoretical guarantees of DANE significantly. In fact, our
approach can be viewed as a robustification strategy since the method is
substantially better behaved than DANE on data partition arising in practice.
It is well known that DANE algorithm does not match the communication
complexity lower bounds. To bridge this gap, we propose an accelerated variant
of the first method, called AIDE, that not only matches the communication lower
bounds but can also be implemented using a purely first-order oracle. Our
empirical results show that AIDE is superior to other communication efficient
algorithms in settings that naturally arise in machine learning applications.
</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06884</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Bayesian Deep Learning: A Framework and Some Existing Methods</dc:title>
 <dc:creator>Wang, Hao</dc:creator>
 <dc:creator>Yeung, Dit-Yan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  While perception tasks such as visual object recognition and text
understanding play an important role in human intelligence, the subsequent
tasks that involve inference, reasoning and planning require an even higher
level of intelligence. The past few years have seen major advances in many
perception tasks using deep learning models. For higher-level inference,
however, probabilistic graphical models with their Bayesian nature are still
more powerful and flexible. To achieve integrated intelligence that involves
both perception and inference, it is naturally desirable to tightly integrate
deep learning and Bayesian models within a principled probabilistic framework,
which we call Bayesian deep learning. In this unified framework, the perception
of text or images using deep learning can boost the performance of higher-level
inference and in return, the feedback from the inference process is able to
enhance the perception of text or images. This paper proposes a general
framework for Bayesian deep learning and reviews its recent applications on
recommender systems, topic models, and control. In this paper, we also discuss
the relationship and differences between Bayesian deep learning and other
related topics like Bayesian treatment of neural networks.
</dc:description>
 <dc:description>Comment: To appear in IEEE Transactions on Knowledge and Data Engineering
  (TKDE), 2016. This is a slightly shorter version of the survey
  arXiv:1604.01662</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06884</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06887</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-objective Compositions for Collision-Free Connectivity Maintenance
  in Teams of Mobile Robots</dc:title>
 <dc:creator>Wang, Li</dc:creator>
 <dc:creator>Ames, Aaron D.</dc:creator>
 <dc:creator>Egerstedt, Magnus</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Compositional barrier functions are proposed in this paper to systematically
compose multiple objectives for teams of mobile robots. The objectives are
first encoded as barrier functions, and then composed using AND and OR logical
operators. The advantage of this approach is that compositional barrier
functions can provably guarantee the simultaneous satisfaction of all composed
objectives. The compositional barrier functions are applied to the example of
ensuring collision avoidance and static/dynamical graph connectivity of teams
of mobile robots. The resulting composite safety and connectivity barrier
certificates are verified experimentally on a team of four mobile robots.
</dc:description>
 <dc:description>Comment: To appear in 55th IEEE Conference on Decision and Control, December
  12-14, 2016, Las Vegas, NV, USA</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06891</identifier>
 <datestamp>2017-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Absolute Pose Estimation from Line Correspondences using Direct Linear
  Transformation</dc:title>
 <dc:creator>P&#x159;ibyl, Bronislav</dc:creator>
 <dc:creator>Zem&#x10d;&#xed;k, Pavel</dc:creator>
 <dc:creator>&#x10c;ad&#xed;k, Martin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>68T45</dc:subject>
 <dc:subject>I.4.8</dc:subject>
 <dc:subject>I.4.1</dc:subject>
 <dc:description>  This work is concerned with camera pose estimation from correspondences of
3D/2D lines, i. e. with the Perspective-n-Line (PnL) problem. We focus on large
line sets, which can be efficiently solved by methods using linear formulation
of PnL. We propose a novel method &quot;DLT-Combined-Lines&quot; based on the Direct
Linear Transformation (DLT) algorithm, which benefits from a new combination of
two existing DLT methods for pose estimation. The method represents 2D
structure by lines, and 3D structure by both points and lines. The redundant 3D
information reduces the minimum required line correspondences to 5. A
cornerstone of the method is a combined projection matri xestimated by the DLT
algorithm. It contains multiple estimates of camera rotation and translation,
which can be recovered after enforcing constraints of the matrix. Multiplicity
of the estimates is exploited to improve the accuracy of the proposed method.
For large line sets (10 and more), the method is comparable to the
state-of-theart in accuracy of orientation estimation. It achieves
state-of-the-art accuracy in estimation of camera position and it yields the
smallest reprojection error under strong image noise. The method achieves top-3
results on real world data. The proposed method is also highly computationally
effective, estimating the pose of 1000 lines in 12 ms on a desktop computer.
</dc:description>
 <dc:description>Comment: 37 pages, 6 figures, 4 tables. Accepted for publication in Computer
  Vision and Image Understanding</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2017-05-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06891</dc:identifier>
 <dc:identifier>doi:10.1016/j.cviu.2017.05.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06902</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Neural Networks With Limited Numerical Precision</dc:title>
 <dc:creator>Ott, Joachim</dc:creator>
 <dc:creator>Lin, Zhouhan</dc:creator>
 <dc:creator>Zhang, Ying</dc:creator>
 <dc:creator>Liu, Shih-Chii</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>62M45</dc:subject>
 <dc:description>  Recurrent Neural Networks (RNNs) produce state-of-art performance on many
machine learning tasks but their demand on resources in terms of memory and
computational power are often high. Therefore, there is a great interest in
optimizing the computations performed with these models especially when
considering development of specialized low-power hardware for deep networks.
One way of reducing the computational needs is to limit the numerical precision
of the network weights and biases. This has led to different proposed rounding
methods which have been applied so far to only Convolutional Neural Networks
and Fully-Connected Networks. This paper addresses the question of how to best
reduce weight precision during training in the case of RNNs. We present results
from the use of different stochastic and deterministic reduced precision
training methods applied to three major RNN types which are then tested on
several datasets. The results show that the weight binarization methods do not
work with the RNNs. However, the stochastic and deterministic ternarization,
and pow2-ternarization methods gave rise to low-precision RNNs that produce
similar and even higher accuracy on certain datasets therefore providing a path
towards training more efficient implementations of RNNs in specialized
hardware.
</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06902</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06910</identifier>
 <datestamp>2016-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Parallel Memory-efficient Epistemic Logic Program Solver: Harder,
  Better, Faster</dc:title>
 <dc:creator>Kahl, Patrick Thor</dc:creator>
 <dc:creator>Leclerc, Anthony P.</dc:creator>
 <dc:creator>Son, Tran Cao</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  As the practical use of answer set programming (ASP) has grown with the
development of efficient solvers, we expect a growing interest in extensions of
ASP as their semantics stabilize and solvers supporting them mature. Epistemic
Specifications, which adds modal operators K and M to the language of ASP, is
one such extension. We call a program in this language an epistemic logic
program (ELP). Solvers have thus far been practical for only the simplest ELPs
due to exponential growth of the search space. We describe a solver that is
able to solve harder problems better (e.g., without exponentially-growing
memory needs w.r.t. K and M occurrences) and faster than any other known ELP
solver.
</dc:description>
 <dc:description>Comment: Paper presented at the 9th Workshop on Answer Set Programming and
  Other Computing Paradigms (ASPOCP 2016), New York City, USA, 16 October 2016</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2016-10-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06910</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06949</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Urban Pulse: Capturing the Rhythm of Cities</dc:title>
 <dc:creator>Miranda, Fabio</dc:creator>
 <dc:creator>Doraiswamy, Harish</dc:creator>
 <dc:creator>Lage, Marcos</dc:creator>
 <dc:creator>Zhao, Kai</dc:creator>
 <dc:creator>Gon&#xe7;alves, Bruno</dc:creator>
 <dc:creator>Wilson, Luc</dc:creator>
 <dc:creator>Hsieh, Mondrian</dc:creator>
 <dc:creator>Silva, Cl&#xe1;udio T.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Cities are inherently dynamic. Interesting patterns of behavior typically
manifest at several key areas of a city over multiple temporal resolutions.
Studying these patterns can greatly help a variety of experts ranging from city
planners and architects to human behavioral experts. Recent technological
innovations have enabled the collection of enormous amounts of data that can
help in these studies. However, techniques using these data sets typically
focus on understanding the data in the context of the city, thus failing to
capture the dynamic aspects of the city. The goal of this work is to instead
understand the city in the context of multiple urban data sets. To do so, we
define the concept of an &quot;urban pulse&quot; which captures the spatio-temporal
activity in a city across multiple temporal resolutions. The prominent pulses
in a city are obtained using the topology of the data sets, and are
characterized as a set of beats. The beats are then used to analyze and compare
different pulses. We also design a visual exploration framework that allows
users to explore the pulses within and across multiple cities under different
conditions. Finally, we present three case studies carried out by experts from
two different domains that demonstrate the utility of our framework.
</dc:description>
 <dc:description>Comment: 10 pages, 10 figures, 1 table. Demo video:
  https://www.youtube.com/watch?v=J70-Ns0cFnQ . Github project:
  https://github.com/ViDA-NYU/urban-pulse ; Added github link</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06949</dc:identifier>
 <dc:identifier>IEEE Transactions on Visualization and Computer Graphics (Volume:
  23, Issue: 1, Jan. 2017)</dc:identifier>
 <dc:identifier>doi:10.1109/TVCG.2016.2598585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06954</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>State Duration and Interval Modeling in Hidden Semi-Markov Model for
  Sequential Data Analysis</dc:title>
 <dc:creator>Narimatsu, Hiromi</dc:creator>
 <dc:creator>Kasai, Hiroyuki</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Sequential data modeling and analysis have become indispensable tools for
analyzing sequential data such as time-series data because a larger amount of
sensed event data have become available. These methods capture the sequential
structure of data of interest, such as input- output relationship and
correlation among datasets. However, since most studies in this area are
specialized or limited for their respective applications, rigorous requirement
analysis on such a model has not been examined in a general point of view.
Hence, we particularly examine the structure of sequential data, and extract
the necessity of &quot;state duration&quot; and &quot;state duration&quot; of events for efficient
and rich representation of sequential data. Specifically addressing the hidden
semi-Markov model (HSMM) that represents such state duration inside a model, we
attempt to newly add representational capability of state interval of events
onto HSMM. To this end, we propose two extended models; one is interval state
hidden semi-Markov model (IS-HSMM) to express the length of state interval with
a special state node designated as &quot;interval state node&quot;. The other is interval
length probability hidden semi-Markov model (ILP-HSMM) which repre- sents the
length of state interval with a new probabilistic parameter &quot;interval length
probability.&quot; From exhaustive simulations, we show superior performances of the
proposed models in comparison with HSMM. To the best of our knowledge, our
proposed models are the first extensions of HMM to support state interval
representation as well as state duration representation.
</dc:description>
 <dc:description>Comment: 30 pages, 20 figures</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06954</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06972</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design-Space Exploration and Optimization of an Energy-Efficient and
  Reliable 3D Small-world Network-on-Chip</dc:title>
 <dc:creator>Das, Sourav</dc:creator>
 <dc:creator>Doppa, Janardhan Rao</dc:creator>
 <dc:creator>Pande, Partha Pratim</dc:creator>
 <dc:creator>Chakrabarty, Krishnendu</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  A three-dimensional (3D) Network-on-Chip (NoC) enables the design of high
performance and low power many-core chips. Existing 3D NoCs are inadequate for
meeting the ever-increasing performance requirements of many-core processors
since they are simple extensions of regular 2D architectures and they do not
fully exploit the advantages provided by 3D integration. Moreover, the
anticipated performance gain of a 3D NoC-enabled many-core chip may be
compromised due to the potential failures of through-silicon-vias (TSVs) that
are predominantly used as vertical interconnects in a 3D IC. To address these
problems, we propose a machine-learning-inspired predictive design methodology
for energy-efficient and reliable many-core architectures enabled by 3D
integration. We demonstrate that a small-world network-based 3D NoC (3D SWNoC)
performs significantly better than its 3D MESH-based counterparts. On average,
the 3D SWNoC shows 35% energy-delay-product (EDP) improvement over 3D MESH for
the PARSEC and SPLASH2 benchmarks considered in this work. To improve the
reliability of 3D NoC, we propose a computationally efficient spare-vertical
link (sVL) allocation algorithm based on a state-space search formulation. Our
results show that the proposed sVL allocation algorithm can significantly
improve the reliability as well as the lifetime of 3D SWNoC.
</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06980</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A $\widetilde{O}(n)$ Non-Adaptive Tester for Unateness</dc:title>
 <dc:creator>Chakrabarty, Deeparnab</dc:creator>
 <dc:creator>Seshadhri, C.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Khot and Shinkar (RANDOM, 2016) recently describe an adaptive, $O(n
\log(n)/\varepsilon)$-query tester for unateness of Boolean functions
$f:\{0,1\}^n \to \{0,1\}$. In this note we describe a simple non-adaptive, $O(n
\log(n/\varepsilon)/\varepsilon)$ -query tester for unateness for functions
over the hypercube with any ordered range.
</dc:description>
 <dc:description>Comment: We mention the relation of our algorithm to Levin's investment
  strategy, as pointed out by Oded Goldreich</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06980</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06984</identifier>
 <datestamp>2017-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning an Optimization Algorithm through Human Design Iterations</dc:title>
 <dc:creator>Sexton, Thurston</dc:creator>
 <dc:creator>Ren, Max Yi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Solving optimal design problems through crowdsourcing faces a dilemma: On one
hand, human beings have been shown to be more effective than algorithms at
searching for good solutions of certain real-world problems with
high-dimensional or discrete solution spaces; on the other hand, the cost of
setting up crowdsourcing environments, the uncertainty in the crowd's
domain-specific competence, and the lack of commitment of the crowd, all
contribute to the lack of real-world application of design crowdsourcing. We
are thus motivated to investigate a solution-searching mechanism where an
optimization algorithm is tuned based on human demonstrations on solution
searching, so that the search can be continued after human participants abandon
the problem. To do so, we model the iterative search process as a Bayesian
Optimization (BO) algorithm, and propose an inverse BO (IBO) algorithm to find
the maximum likelihood estimators of the BO parameters based on human
solutions. We show through a vehicle design and control problem that the search
performance of BO can be improved by recovering its parameters based on an
effective human search. Thus, IBO has the potential to improve the success rate
of design crowdsourcing activities, by requiring only good search strategies
instead of good solutions from the crowd.
</dc:description>
 <dc:description>Comment: accepted to Journal of Mechanical Design</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2017-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06984</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06985</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A 4D Light-Field Dataset and CNN Architectures for Material Recognition</dc:title>
 <dc:creator>Wang, Ting-Chun</dc:creator>
 <dc:creator>Zhu, Jun-Yan</dc:creator>
 <dc:creator>Hiroaki, Ebi</dc:creator>
 <dc:creator>Chandraker, Manmohan</dc:creator>
 <dc:creator>Efros, Alexei A.</dc:creator>
 <dc:creator>Ramamoorthi, Ravi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce a new light-field dataset of materials, and take advantage of
the recent success of deep learning to perform material recognition on the 4D
light-field. Our dataset contains 12 material categories, each with 100 images
taken with a Lytro Illum, from which we extract about 30,000 patches in total.
To the best of our knowledge, this is the first mid-size dataset for
light-field images. Our main goal is to investigate whether the additional
information in a light-field (such as multiple sub-aperture views and
view-dependent reflectance effects) can aid material recognition. Since
recognition networks have not been trained on 4D images before, we propose and
compare several novel CNN architectures to train on light-field images. In our
experiments, the best performing CNN architecture achieves a 7% boost compared
with 2D image classification (70% to 77%). These results constitute important
baselines that can spur further research in the use of CNNs for light-field
applications. Upon publication, our dataset also enables other novel
applications of light-fields, including object detection, image segmentation
and view interpolation.
</dc:description>
 <dc:description>Comment: European Conference on Computer Vision (ECCV) 2016</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06985</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06986</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A short review and primer on electrodermal activity in human computer
  interaction applications</dc:title>
 <dc:creator>Cowley, Benjamin Ultan</dc:creator>
 <dc:creator>Torniainen, Jari</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The application of psychophysiology in human-computer interaction is a
growing field with significant potential for future smart personalised systems.
Working in this emerging field requires comprehension of an array of
physiological signals and analysis techniques.
  One of the most widely used signals is electrodermal activity, or EDA, also
known as galvanic skin response or GSR. This signal is commonly used as a proxy
for physiological arousal, but recent advances of interpretation and analysis
suggest that traditional approaches should be revised. We present a short
review on the application of EDA in human-computer interaction.
  This paper aims to serve as a primer for the novice, enabling rapid
familiarisation with the latest core concepts. We put special emphasis on
everyday human-computer interface applications to distinguish from the more
common clinical or sports uses of psychophysiology.
  This paper is an extract from a comprehensive review of the entire field of
ambulatory psychophysiology, including 12 similar chapters, plus application
guidelines and systematic review. Thus any citation should be made using the
following reference:
  B. Cowley, M. Filetti, K. Lukander, J. Torniainen, A. Henelius, L. Ahonen, O.
Barral, I. Kosunen, T. Valtonen, M. Huotilainen, N. Ravaja, G. Jacucci. The
Psychophysiology Primer: a guide to methods and a broad review with a focus on
human-computer interaction. Foundations and Trends in Human-Computer
Interaction, vol. 9, no. 3-4, pp. 150--307, 2016.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures. Part of journal paper</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06990</identifier>
 <datestamp>2016-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Sharing Economy for the Smart Grid</dc:title>
 <dc:creator>Kalathil, Dileep</dc:creator>
 <dc:creator>Wu, Chenye</dc:creator>
 <dc:creator>Poolla, Kameshwar</dc:creator>
 <dc:creator>Varaiya, Pravin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The sharing economy has disrupted housing and transportation sectors.
Homeowners can rent out their property when they are away on vacation, car
owners can offer ride sharing services. These sharing economy business models
are based on monetizing under-utilized infrastructure. They are enabled by
peer-to-peer platforms that match eager sellers with willing buyers.
  Are there compelling sharing economy opportunities in the electricity sector?
What products or services can be shared in tomorrow's Smart Grid? We begin by
exploring sharing economy opportunities in the electricity sector, and discuss
regulatory and technical obstacles to these opportunities. We then study the
specific problem of a collection of firms sharing their electricity storage. We
characterize equilibrium prices for shared storage in a spot market. We
formulate storage investment decisions of the firms as a non-convex
non-cooperative game. We show that under a mild alignment condition, a Nash
equilibrium exists, it is unique, and it supports the social welfare. We
discuss technology platforms necessary for the physical exchange of power, and
market platforms necessary to trade electricity storage. We close with
synthetic examples to illustrate our ideas.
</dc:description>
 <dc:description>Comment: 11 pages, 11 figures</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2016-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06990</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06991</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaussian hypothesis testing and quantum illumination</dc:title>
 <dc:creator>Wilde, Mark M.</dc:creator>
 <dc:creator>Tomamichel, Marco</dc:creator>
 <dc:creator>Lloyd, Seth</dc:creator>
 <dc:creator>Berta, Mario</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Quantum hypothesis testing is one of the most basic tasks in quantum
information theory and has fundamental links with quantum communication and
estimation theory. In this paper, we establish a formula that characterizes the
decay rate of the minimal Type-II error probability in a quantum hypothesis
test of two Gaussian states given a fixed constraint on the Type-I error
probability. This formula is a direct function of the mean vectors and
covariance matrices of the quantum Gaussian states in question. We give an
application to quantum illumination, which is the task of determining whether
there is a low-reflectivity object embedded in a target region with a bright
thermal-noise bath. For the asymmetric-error setting, we find that a quantum
illumination transmitter can achieve an error probability exponent stronger
than a coherent-state transmitter of the same mean photon number, and
furthermore, that it requires far fewer trials to do so. This occurs when the
background thermal noise is either low or bright, which means that a quantum
advantage is even easier to witness than in the symmetric-error setting because
it occurs for a larger range of parameters. Going forward from here, we expect
our formula to have applications in settings well beyond those considered in
this paper, especially to quantum communication tasks involving quantum
Gaussian channels.
</dc:description>
 <dc:description>Comment: v2: 13 pages, 1 figure, final version published in Physical Review
  Letters</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2017-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06991</dc:identifier>
 <dc:identifier>Physical Review Letters, vol. 119, no. 12, page 120501, September
  2017</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.119.120501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.06993</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Densely Connected Convolutional Networks</dc:title>
 <dc:creator>Huang, Gao</dc:creator>
 <dc:creator>Liu, Zhuang</dc:creator>
 <dc:creator>Weinberger, Kilian Q.</dc:creator>
 <dc:creator>van der Maaten, Laurens</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recent work has shown that convolutional networks can be substantially
deeper, more accurate, and efficient to train if they contain shorter
connections between layers close to the input and those close to the output. In
this paper, we embrace this observation and introduce the Dense Convolutional
Network (DenseNet), which connects each layer to every other layer in a
feed-forward fashion. Whereas traditional convolutional networks with L layers
have L connections - one between each layer and its subsequent layer - our
network has L(L+1)/2 direct connections. For each layer, the feature-maps of
all preceding layers are used as inputs, and its own feature-maps are used as
inputs into all subsequent layers. DenseNets have several compelling
advantages: they alleviate the vanishing-gradient problem, strengthen feature
propagation, encourage feature reuse, and substantially reduce the number of
parameters. We evaluate our proposed architecture on four highly competitive
object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet).
DenseNets obtain significant improvements over the state-of-the-art on most of
them, whilst requiring less memory and computation to achieve high performance.
Code and models are available at https://github.com/liuzhuang13/DenseNet .
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2017-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.06993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07001</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental Minimax Optimization based Fuzzy Clustering for Large
  Multi-view Data</dc:title>
 <dc:creator>Wang, Yangtao</dc:creator>
 <dc:creator>Chen, Lihui</dc:creator>
 <dc:creator>Li, Xiaoli</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Incremental clustering approaches have been proposed for handling large data
when given data set is too large to be stored. The key idea of these approaches
is to find representatives to represent each cluster in each data chunk and
final data analysis is carried out based on those identified representatives
from all the chunks. However, most of the incremental approaches are used for
single view data. As large multi-view data generated from multiple sources
becomes prevalent nowadays, there is a need for incremental clustering
approaches to handle both large and multi-view data. In this paper we propose a
new incremental clustering approach called incremental minimax optimization
based fuzzy clustering (IminimaxFCM) to handle large multi-view data. In
IminimaxFCM, representatives with multiple views are identified to represent
each cluster by integrating multiple complementary views using minimax
optimization. The detailed problem formulation, updating rules derivation, and
the in-depth analysis of the proposed IminimaxFCM are provided. Experimental
studies on several real world multi-view data sets have been conducted. We
observed that IminimaxFCM outperforms related incremental fuzzy clustering in
terms of clustering accuracy, demonstrating the great potential of IminimaxFCM
for large multi-view data analysis.
</dc:description>
 <dc:description>Comment: 32 pages, 1 figures, submitted to Fuzzy Sets and Systems</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07002</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A simple linear space algorithm for computing a longest common
  increasing subsequence</dc:title>
 <dc:creator>Zhu, Daxin</dc:creator>
 <dc:creator>Wang, Lei</dc:creator>
 <dc:creator>Wang, Tinran</dc:creator>
 <dc:creator>Wang, Xiaodong</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  This paper reformulates the problem of finding a longest common increasing
subsequence of the two given input sequences in a very succinct way. An
extremely simple linear space algorithm based on the new formula can find a
longest common increasing subsequence of sizes $n$ and $m$ respectively, in
time $O(nm)$ using additional $\min\{n,m\}+1$ space.
</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07005</identifier>
 <datestamp>2016-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-View Fuzzy Clustering with Minimax Optimization for Effective
  Clustering of Data from Multiple Sources</dc:title>
 <dc:creator>Wang, Yangtao</dc:creator>
 <dc:creator>Chen, Lihui</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Multi-view data clustering refers to categorizing a data set by making good
use of related information from multiple representations of the data. It
becomes important nowadays because more and more data can be collected in a
variety of ways, in different settings and from different sources, so each data
set can be represented by different sets of features to form different views of
it. Many approaches have been proposed to improve clustering performance by
exploring and integrating heterogeneous information underlying different views.
In this paper, we propose a new multi-view fuzzy clustering approach called
MinimaxFCM by using minimax optimization based on well-known Fuzzy c means. In
MinimaxFCM the consensus clustering results are generated based on minimax
optimization in which the maximum disagreements of different weighted views are
minimized. Moreover, the weight of each view can be learned automatically in
the clustering process. In addition, there is only one parameter to be set
besides the fuzzifier. The detailed problem formulation, updating rules
derivation, and the in-depth analysis of the proposed MinimaxFCM are provided
here. Experimental studies on nine multi-view data sets including real world
image and document data sets have been conducted. We observed that MinimaxFCM
outperforms related multi-view clustering approaches in terms of clustering
accuracy, demonstrating the great potential of MinimaxFCM for multi-view data
analysis.
</dc:description>
 <dc:description>Comment: 34 pages, submitted to Expert Systems with Applications. arXiv admin
  note: text overlap with arXiv:1608.07001</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07015</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Goodness of Covariance Selection Problem from AUC Bounds</dc:title>
 <dc:creator>Khajavi, Navid Tafaghodi</dc:creator>
 <dc:creator>Kuh, Anthony</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We conduct a study of graphical models and discuss the quality of model
selection approximation by formulating the problem as a detection problem and
examining the area under the curve (AUC). We are specifically looking at the
model selection problem for jointly Gaussian random vectors. For Gaussian
random vectors, this problem simplifies to the covariance selection problem
which is widely discussed in literature by Dempster [1]. In this paper, we give
the definition for the correlation approximation matrix (CAM) which contains
all information about the model selection problem and discuss the pth order
Markov chain model and the $p$th order star network model for the a Gaussian
distribution with Toeplitz covariance matrix. For each model, we compute the
model covariance matrix as well as the KL divergence between the Gaussian
distribution and its model. We also show that if the model order, p, is
proportional to the number of nodes, n, then the model selection is
asymptotically good as the number of nodes, n, goes to infinity since the AUC
in this case is bounded away from one. We conduct some simulations which
confirm the theoretical analysis and also show that the selected model quality
increases as the model order, p, increases.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1605.05776</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07017</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ambient Sound Provides Supervision for Visual Learning</dc:title>
 <dc:creator>Owens, Andrew</dc:creator>
 <dc:creator>Wu, Jiajun</dc:creator>
 <dc:creator>McDermott, Josh H.</dc:creator>
 <dc:creator>Freeman, William T.</dc:creator>
 <dc:creator>Torralba, Antonio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The sound of crashing waves, the roar of fast-moving cars -- sound conveys
important information about the objects in our surroundings. In this work, we
show that ambient sounds can be used as a supervisory signal for learning
visual models. To demonstrate this, we train a convolutional neural network to
predict a statistical summary of the sound associated with a video frame. We
show that, through this process, the network learns a representation that
conveys information about objects and scenes. We evaluate this representation
on several recognition tasks, finding that its performance is comparable to
that of other state-of-the-art unsupervised learning methods. Finally, we show
through visualizations that the network learns units that are selective to
objects that are often associated with characteristic sounds.
</dc:description>
 <dc:description>Comment: ECCV 2016</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07019</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparison among dimensionality reduction techniques based on Random
  Projection for cancer classification</dc:title>
 <dc:creator>Xie, Haozhe</dc:creator>
 <dc:creator>Li, Jie</dc:creator>
 <dc:creator>Zhang, Qiaosheng</dc:creator>
 <dc:creator>Wang, Yadong</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Random Projection (RP) technique has been widely applied in many scenarios
because it can reduce high-dimensional features into low-dimensional space
within short time and meet the need of real-time analysis of massive data.
There is an urgent need of dimensionality reduction with fast increase of big
genomics data. However, the performance of RP is usually lower. We attempt to
improve classification accuracy of RP through combining other reduction
dimension methods such as Principle Component Analysis (PCA), Linear
Discriminant Analysis (LDA), and Feature Selection (FS). We compared
classification accuracy and running time of different combination methods on
three microarray datasets and a simulation dataset. Experimental results show a
remarkable improvement of 14.77% in classification accuracy of FS followed by
RP compared to RP on BC-TCGA dataset. LDA followed by RP also helps RP to yield
a more discriminative subspace with an increase of 13.65% on classification
accuracy on the same dataset. FS followed by RP outperforms other combination
methods in classification accuracy on most of the datasets.
</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2017-06-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07019</dc:identifier>
 <dc:identifier>Computational biology and chemistry, 65: 165-172, 2016</dc:identifier>
 <dc:identifier>doi:10.1016/j.compbiolchem.2016.09.010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07020</identifier>
 <datestamp>2017-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Power of Uninitialized Qubits in Shallow Quantum Circuits</dc:title>
 <dc:creator>Takahashi, Yasuhiro</dc:creator>
 <dc:creator>Tani, Seiichiro</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We study the computational power of shallow quantum circuits with $O(\log n)$
initialized and $n^{O(1)}$ uninitialized ancillary qubits, where $n$ is the
input length and the initial state of the uninitialized ancillary qubits is
arbitrary. First, we show that such a circuit can compute any symmetric
function on $n$ bits that is classically computable in polynomial time. Then,
we regard such a circuit as an oracle and show that a polynomial-time classical
algorithm with the oracle can estimate the elements of any unitary matrix
corresponding to a constant-depth quantum circuit on $n$ qubits. Since it seems
unlikely that these tasks can be done with only $O(\log n)$ initialized
ancillary qubits, our results give evidences that adding uninitialized
ancillary qubits increases the computational power of shallow quantum circuits
with only $O(\log n)$ initialized ancillary qubits. Lastly, to understand the
limitations of uninitialized ancillary qubits, we focus on
near-logarithmic-depth quantum circuits with them and show the impossibility of
computing the parity function on $n$ bits.
</dc:description>
 <dc:description>Comment: 23 pages, 10 figures; v3: Theorem 1 improved, title changed, text
  substantially rewritten</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2017-09-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07022</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kernelization and Parameterized Algorithms for 3-Path Vertex Cover</dc:title>
 <dc:creator>Xiao, Mingyu</dc:creator>
 <dc:creator>Kou, Shaowei</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A 3-path vertex cover in a graph is a vertex subset $C$ such that every path
of three vertices contains at least one vertex from $C$. The parameterized
3-path vertex cover problem asks whether a graph has a 3-path vertex cover of
size at most $k$. In this paper, we give a kernel of $5k$ vertices and an
$O^*(1.7485^k)$-time and polynomial-space algorithm for this problem, both new
results improve previous known bounds.
</dc:description>
 <dc:description>Comment: in TAMC 2016, LNCS 9796, 2016</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07022</dc:identifier>
 <dc:identifier>TAMC 2017, LNCS 10185, 654-668</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-55911-7_47</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07032</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Discrete Logarithm Problem over Prime Fields can be transformed to a
  Linear Multivariable Chinese Remainder Theorem</dc:title>
 <dc:creator>Gadiyar, H. Gopalakrishna</dc:creator>
 <dc:creator>Padma, R.</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>11A07, 11T71, 11Y16, 14G50, 68Q25, 94A60</dc:subject>
 <dc:description>  We show that the classical discrete logarithm problem over prime fields can
be reduced to that of solving a system of linear modular equations.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07036</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>System Reliability, Fault Tolerance and Design Metrics Tradeoffs in the
  Distributed Minority and Majority Voting Based Redundancy Scheme</dc:title>
 <dc:creator>Balasubramanian, P</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The distributed minority and majority voting based redundancy (DMMR) scheme
was recently proposed as an efficient alternative to the conventional N-modular
redundancy (NMR) scheme for the physical design of mission/safety-critical
circuits and systems. The DMMR scheme enables significant improvements in fault
tolerance and design metrics compared to the NMR scheme albeit at the expense
of a slight decrease in the system reliability. In this context, this paper
studies the system reliability, fault tolerance and design metrics tradeoffs in
the DMMR scheme compared to the NMR scheme when the majority logic group of the
DMMR scheme is increased in size relative to the minority logic group. Some
example DMMR and NMR systems were realized using a 32/28nm CMOS process and
compared. The results show that 5-of-M DMMR systems have a similar or better
fault tolerance whilst requiring similar or fewer function modules than their
counterpart NMR systems and simultaneously achieve optimizations in design
metrics. Nevertheless, 3-of-M DMMR systems have the upper hand with respect to
fault tolerance and design metrics optimizations than the comparable NMR and
5-of-M DMMR systems. With regard to system reliability, NMR systems are closely
followed by 5-of-M DMMR systems which are closely followed by 3-of-M DMMR
systems. The verdict is 3-of-M DMMR systems are preferable to implement higher
levels of redundancy from a combined system reliability, fault tolerance and
design metrics perspective to realize mission/safety-critical circuits and
systems.
</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07036</dc:identifier>
 <dc:identifier>WSEAS Transactions on Systems, vol. 15, Article #7, pp. 59-62,
  2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07038</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The (minimum) rank of typical fooling set matrices</dc:title>
 <dc:creator>Pourmoradnasseri, Mozhgan</dc:creator>
 <dc:creator>Theis, Dirk Oliver</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A fooling-set matrix has nonzero diagonal, but at least one in every pair of
diagonally opposite entries is 0. Dietzfelbinger et al. '96 proved that the
rank of such a matrix is at least $\sqrt n$. It is known that the bound is
tight (up to a multiplicative constant).
  We ask for the &quot;typical&quot; minimum rank of a fooling-set matrix: For a
fooling-set zero-nonzero pattern chosen at random, is the minimum rank of a
matrix with that zero-nonzero pattern over a field $\mathbb F$ closer to its
lower bound $\sqrt{n}$ or to its upper bound $n$? We study random patterns with
a given density $p$, and prove an $\Omega(n)$ bound for the cases when: (a) $p$
tends to $0$ quickly enough, (b) $p$ tends to $0$ slowly, and $|\mathbb
F|=O(1)$, (c) $p\in(0,1]$ is a constant.
  We have to leave open the case when $p\to 0$ slowly and $\mathbb F$ is a
large or infinite field (e.g., $\mathbb F=GF(2^n)$, $F=\mathbb{R}$).
</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07046</identifier>
 <datestamp>2016-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transient performance analysis of zero-attracting LMS</dc:title>
 <dc:creator>Chen, Jie</dc:creator>
 <dc:creator>Richard, Cedric</dc:creator>
 <dc:creator>Song, Yingying</dc:creator>
 <dc:creator>Brie, David</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Zero-attracting least-mean-square (ZA-LMS) algorithm has been widely used for
online sparse system identification. It combines the LMS framework and
$\ell_1$-norm regularization to promote sparsity, and relies on subgradient
iterations. Despite the significant interest in ZA-LMS, few works analyzed its
transient behavior. The main difficulty lies in the nonlinearity of the update
rule. In this work, a detailed analysis in the mean and mean-square sense is
carried out in order to examine the behavior of the algorithm. Simulation
results illustrate the accuracy of the model and highlight its performance
through comparisons with an existing model.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07046</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2016.2616890</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07051</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Points and Routes to Recommend Trajectories</dc:title>
 <dc:creator>Chen, Dawei</dc:creator>
 <dc:creator>Ong, Cheng Soon</dc:creator>
 <dc:creator>Xie, Lexing</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The problem of recommending tours to travellers is an important and broadly
studied area. Suggested solutions include various approaches of
points-of-interest (POI) recommendation and route planning. We consider the
task of recommending a sequence of POIs, that simultaneously uses information
about POIs and routes. Our approach unifies the treatment of various sources of
information by representing them as features in machine learning algorithms,
enabling us to learn from past behaviour. Information about POIs are used to
learn a POI ranking model that accounts for the start and end points of tours.
Data about previous trajectories are used for learning transition patterns
between POIs that enable us to recommend probable routes. In addition, a
probabilistic model is proposed to combine the results of POI ranking and the
POI to POI transitions. We propose a new F$_1$ score on pairs of POIs that
capture the order of visits. Empirical results show that our approach improves
on recent methods, and demonstrate that combining points and routes enables
better trajectory recommendations.
</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07051</dc:identifier>
 <dc:identifier>doi:10.1145/2983323.2983672</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07056</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Colored Spanning Graphs</dc:title>
 <dc:creator>Akitaya, Hugo A.</dc:creator>
 <dc:creator>L&#xf6;ffler, Maarten</dc:creator>
 <dc:creator>T&#xf3;th, Csaba D.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We study a problem proposed by Hurtado et al. (2016) motivated by sparse set
visualization. Given $n$ points in the plane, each labeled with one or more
primary colors, a \emph{colored spanning graph} (CSG) is a graph such that for
each primary color, the vertices of that color induce a connected subgraph. The
\textsc{Min-CSG} problem asks for the minimum sum of edge lengths in a colored
spanning graph. We show that the problem is NP-hard for $k$ primary colors when
$k\ge 3$ and provide a $(2-\frac{1}{3+2\varrho})$-approximation algorithm for
$k=3$ that runs in polynomial time, where $\varrho$ is the Steiner ratio.
Further, we give a $O(n)$ time algorithm in the special case that the input
points are collinear and $k$ is constant.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07056</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07060</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structural properties of LPV to LFR transformation: minimality,
  input-output behavior and identifiability</dc:title>
 <dc:creator>Alkhoury, Ziad</dc:creator>
 <dc:creator>Petreczky, Mih&#xe1;ly</dc:creator>
 <dc:creator>Merc&#xe8;re, Guillaume</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we introduce and study important properties of the
transformation of Affine Linear Parameter-Varying (ALPV) state-space
representations into Linear Fractional Representations (LFR). More precisely,
we show that $(i)$ state minimal ALPV representations yield minimal LFRs, and
vice versa, $(ii)$ the input-output behavior of the ALPV represention
determines uniquely the input-output behavior of the resulting LFR, $(iii)$
structurally identifiable ALPVs yield structurally identifiable LFRs, and vice
versa. We then characterize LFR models which correspond to equivalent ALPV
models based on their input-output maps. As illustrated all along the paper,
these results have important consequences for identification and control of
systems described by LFRs.
</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07068</identifier>
 <datestamp>2016-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Title Generation for User Generated Videos</dc:title>
 <dc:creator>Zeng, Kuo-Hao</dc:creator>
 <dc:creator>Chen, Tseng-Hung</dc:creator>
 <dc:creator>Niebles, Juan Carlos</dc:creator>
 <dc:creator>Sun, Min</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  A great video title describes the most salient event compactly and captures
the viewer's attention. In contrast, video captioning tends to generate
sentences that describe the video as a whole. Although generating a video title
automatically is a very useful task, it is much less addressed than video
captioning. We address video title generation for the first time by proposing
two methods that extend state-of-the-art video captioners to this new task.
First, we make video captioners highlight sensitive by priming them with a
highlight detector. Our framework allows for jointly training a model for title
generation and video highlight localization. Second, we induce high sentence
diversity in video captioners, so that the generated titles are also diverse
and catchy. This means that a large number of sentences might be required to
learn the sentence structure of titles. Hence, we propose a novel sentence
augmentation method to train a captioner with additional sentence-only examples
that come without corresponding videos. We collected a large-scale Video Titles
in the Wild (VTW) dataset of 18100 automatically crawled user-generated videos
and titles. On VTW, our methods consistently improve title prediction accuracy,
and achieve the best performance in both automatic and human evaluation.
Finally, our sentence augmentation method also outperforms the baselines on the
M-VAD dataset.
</dc:description>
 <dc:description>Comment: 14 pages, 4 figures, ECCV2016</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2016-09-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07068</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07076</identifier>
 <datestamp>2017-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Context-aware Natural Language Generator for Dialogue Systems</dc:title>
 <dc:creator>Du&#x161;ek, Ond&#x159;ej</dc:creator>
 <dc:creator>Jur&#x10d;&#xed;&#x10d;ek, Filip</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We present a novel natural language generation system for spoken dialogue
systems capable of entraining (adapting) to users' way of speaking, providing
contextually appropriate responses. The generator is based on recurrent neural
networks and the sequence-to-sequence approach. It is fully trainable from data
which include preceding context along with responses to be generated. We show
that the context-aware generator yields significant improvements over the
baseline in both automatic metrics and a human pairwise preference test.
</dc:description>
 <dc:description>Comment: Accepted as a short paper for SIGDIAL 2016</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07076</dc:identifier>
 <dc:identifier>Proceedings of the SIGDIAL 2016 Conference, pages 185-190, Los
  Angeles, USA, 13-15 September 2016</dc:identifier>
 <dc:identifier>doi:10.18653/v1/W16-3622</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07085</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multimedia Storage in the Cloud using Amazon Web Services: Implications
  for Online Education</dc:title>
 <dc:creator>Erturk, Emre</dc:creator>
 <dc:creator>Obrutsky, Santiago</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This report is divided into three parts. Firstly, an explanation of the cloud
storage products is given, in particular, the Amazon Simple Storage Service
(S3). Secondly, the report discusses a case study about SmugMug's migration to
the cloud hosted by Amazon. SmugMug is a premium online photo and video sharing
service business, and currently has billions of photos and videos from amateur
and professional photographers around the world. This report also includes a
step by step explanation of how to modify a website and use Amazon S3 to host
videos in the cloud. These findings are evaluated in terms of how useful Amazon
S3 can be for an e-learning institute, especially one that is geared towards
mobile delivery of content. Finally, the paper covers the copyright, and
privacy implications, in order to understand the larger context.
</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07094</identifier>
 <datestamp>2016-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Term_Class Relevance Measure for Text Categorization</dc:title>
 <dc:creator>Guru, D S</dc:creator>
 <dc:creator>Suhil, Mahamad</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we introduce a new measure called Term_Class relevance to
compute the relevancy of a term in classifying a document into a particular
class. The proposed measure estimates the degree of relevance of a given term,
in placing an unlabeled document to be a member of a known class, as a product
of Class_Term weight and Class_Term density; where the Class_Term weight is the
ratio of the number of documents of the class containing the term to the total
number of documents containing the term and the Class_Term density is the
relative density of occurrence of the term in the class to the total occurrence
of the term in the entire population. Unlike the other existing term weighting
schemes such as TF-IDF and its variants, the proposed relevance measure takes
into account the degree of relative participation of the term across all
documents of the class to the entire population. To demonstrate the
significance of the proposed measure experimentation has been conducted on the
20 Newsgroups dataset. Further, the superiority of the novel measure is brought
out through a comparative analysis.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures, 2 tables</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2016-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07094</dc:identifier>
 <dc:identifier>Procedia Computer Science, vol.45, pp.13-22, 2015</dc:identifier>
 <dc:identifier>doi:10.1016/j.procs.2015.03.074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07102</identifier>
 <datestamp>2017-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-behavioral Sequential Prediction with Recurrent Log-bilinear Model</dc:title>
 <dc:creator>Liu, Qiang</dc:creator>
 <dc:creator>Wu, Shu</dc:creator>
 <dc:creator>Wang, Liang</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  With the rapid growth of Internet applications, sequential prediction in
collaborative filtering has become an emerging and crucial task. Given the
behavioral history of a specific user, predicting his or her next choice plays
a key role in improving various online services. Meanwhile, there are more and
more scenarios with multiple types of behaviors, while existing works mainly
study sequences with a single type of behavior. As a widely used approach,
Markov chain based models are based on a strong independence assumption. As two
classical neural network methods for modeling sequences, recurrent neural
networks cannot well model short-term contexts, and the log-bilinear model is
not suitable for long-term contexts. In this paper, we propose a Recurrent
Log-BiLinear (RLBL) model. It can model multiple types of behaviors in
historical sequences with behavior-specific transition matrices. RLBL applies a
recurrent structure for modeling long-term contexts. It models several items in
each hidden layer and employs position-specific transition matrices for
modeling short-term contexts. Moreover, considering continuous time difference
in behavioral history is a key factor for dynamic prediction, we further extend
RLBL and replace position-specific transition matrices with time-specific
transition matrices, and accordingly propose a Time-Aware Recurrent
Log-BiLinear (TA-RLBL) model. Experimental results show that the proposed RLBL
model and TA-RLBL model yield significant improvements over the competitive
compared methods on three datasets, i.e., Movielens-1M dataset, Global
Terrorism Database and Tmall dataset with different numbers of behavior types.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Knowledge and Data Engineering (TKDE), to appear</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2017-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07103</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling and evaluation of a multi-tag LED-ID platform</dc:title>
 <dc:creator>Blinowski, Grzegorz</dc:creator>
 <dc:creator>Kmieciak, Adrianna</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  An LED-ID system works like an electronic &quot;tag&quot; transmitting a short digital
broadcasted message. Low complexity LED-ID installations, being a subset of an
emerging class of visible light communication (VLC) systems, may be considered
as a replacement of popular RFID tags, Bluetooth tags and Wi-Fi beacons. In
this work, we focus on multi LED-ID environments with &quot;dense&quot; tag placement.
The problems that we focus on are estimating the level of cross-tag
interference and the issue of tag proximity: how closely can we place the tags
without making the system unusable? We present a theoretical model with a
numerical simulation of sample arrangements. We also describe the results of
experiments we conducted in a real- world test environment under different
external lighting conditions.
</dc:description>
 <dc:description>Comment: Submitted to FEDCSIS 2016</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07115</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aligning Packed Dependency Trees: a theory of composition for
  distributional semantics</dc:title>
 <dc:creator>Weir, David</dc:creator>
 <dc:creator>Weeds, Julie</dc:creator>
 <dc:creator>Reffin, Jeremy</dc:creator>
 <dc:creator>Kober, Thomas</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a new framework for compositional distributional semantics in
which the distributional contexts of lexemes are expressed in terms of anchored
packed dependency trees. We show that these structures have the potential to
capture the full sentential contexts of a lexeme and provide a uniform basis
for the composition of distributional knowledge in a way that captures both
mutual disambiguation and generalization.
</dc:description>
 <dc:description>Comment: To appear in Special issue of Computational Linguistics - Formal
  Distributional Semantics</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07117</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling Chemical Reasoning to Predict Reactions</dc:title>
 <dc:creator>Segler, Marwin H. S.</dc:creator>
 <dc:creator>Waller, Mark P.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:subject>Quantitative Biology - Molecular Networks</dc:subject>
 <dc:description>  The ability to reason beyond established knowledge allows Organic Chemists to
solve synthetic problems and to invent novel transformations. Here, we propose
a model which mimics chemical reasoning and formalises reaction prediction as
finding missing links in a knowledge graph. We have constructed a knowledge
graph containing 14.4 million molecules and 8.2 million binary reactions, which
represents the bulk of all chemical reactions ever published in the scientific
literature. Our model outperforms a rule-based expert system in the reaction
prediction task for 180,000 randomly selected binary reactions. We show that
our data-driven model generalises even beyond known reaction types, and is thus
capable of effectively (re-) discovering novel transformations (even including
transition-metal catalysed reactions). Our model enables computers to infer
hypotheses about reactivity and reactions by only considering the intrinsic
local structure of the graph, and because each single reaction prediction is
typically achieved in a sub-second time frame, our model can be used as a
high-throughput generator of reaction hypotheses for reaction discovery.
</dc:description>
 <dc:description>Comment: 17 pages, 8 figures</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07117</dc:identifier>
 <dc:identifier>Chem. Eur. J. 2017, 23, 6118-6128</dc:identifier>
 <dc:identifier>doi:10.1002/chem.201604556</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07138</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sympathy for the Details: Dense Trajectories and Hybrid Classification
  Architectures for Action Recognition</dc:title>
 <dc:creator>de Souza, C&#xe9;sar Roberto</dc:creator>
 <dc:creator>Gaidon, Adrien</dc:creator>
 <dc:creator>Vig, Eleonora</dc:creator>
 <dc:creator>L&#xf3;pez, Antonio Manuel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Action recognition in videos is a challenging task due to the complexity of
the spatio-temporal patterns to model and the difficulty to acquire and learn
on large quantities of video data. Deep learning, although a breakthrough for
image classification and showing promise for videos, has still not clearly
superseded action recognition methods using hand-crafted features, even when
training on massive datasets. In this paper, we introduce hybrid video
classification architectures based on carefully designed unsupervised
representations of hand-crafted spatio-temporal features classified by
supervised deep networks. As we show in our experiments on five popular
benchmarks for action recognition, our hybrid model combines the best of both
worlds: it is data efficient (trained on 150 to 10000 short clips) and yet
improves significantly on the state of the art, including recent deep models
trained on millions of manually labelled images and videos.
</dc:description>
 <dc:description>Comment: Accepted for publication in the 14th European Conference on Computer
  Vision (ECCV), Amsterdam, 2016, plus supplementary material</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07138</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07146</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The feasibility of launching physical layer attacks in visible light
  communication networks</dc:title>
 <dc:creator>Blinowski, Grzegorz</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  One of the areas in which wireless networks based on visible light
communication (VLC) are considered superior to traditional radio-based
communication is security. The common slogan summarizing VLC security features
is: WYSIWYS - &quot;What You See Is What You Send&quot;. However, especially in the case
of infrastructure downlink communication, security with respect to data
snooping, jamming and modification must be carefully provided for. This paper
examines the physical layer aspects of VLC networks with respect to possible
disruptions caused by rogue transmitters. We present the theoretical system
model that we use in simulations to evaluate various rogue transmission
scenarios in a typical office environment. We use estimated Bit Error Rate
(BER) as a measure of the effectiveness of jamming and rogue data transmission.
We find that it is quite easy to disrupt, and in some cases to even hijack
legitimate transmission.
</dc:description>
 <dc:description>Comment: preprint, 15 pages</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07155</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A new kind of parallelism and its programming in the Explicitly
  Many-Processor Approach</dc:title>
 <dc:creator>V&#xe9;gh, J&#xe1;nos</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>68N15, 68N19</dc:subject>
 <dc:subject>C.1.3</dc:subject>
 <dc:subject>D.2.11</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:description>  The processor accelerators are effective because they are working not
(completely) on principles of stored program computers. They use some kind of
parallelism, and it is rather hard to program them effectively: a parallel
architecture by means of (and thinking in) sequential programming. The recently
introduced EMPA architecture uses a new kind of parallelism, which offers the
potential of reaching higher degree of parallelism, and also provides extra
possibilities and challenges. It not only provides synchronization and inherent
parallelization, but also takes over some duties typically offered by the OS,
and even opens the till now closed machine instructions for the end-user. A
toolchain for EMPA architecture with Y86 cores has been prepared, including an
assembler and a cycle-accurate simulator. The assembler is equipped with some
meta-instructions, which allow to use all advanced possibilities of the EMPA
architecture, and at the same time provide a (nearly) conventional-style
programming. The cycle accurate simulator is able to execute the EMPA-aware
object code, and is a good tool for developing algorithms for EMPA
</dc:description>
 <dc:description>Comment: 13 pages. 7 figures, 2 tables, 5 program listings</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07155</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07159</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Robust Learning</dc:title>
 <dc:creator>Ghafarian, Hossein</dc:creator>
 <dc:creator>Yazdi, Hadi Sadoghi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In many practical applications of learning algorithms, unlabeled data is
cheap and abundant whereas labeled data is expensive. Active learning
algorithms developed to achieve better performance with lower cost. Usually
Representativeness and Informativeness are used in active learning algoirthms.
Advanced recent active learning methods consider both of these criteria.
Despite its vast literature, very few active learning methods consider noisy
instances, i.e. label noisy and outlier instances. Also, these methods didn't
consider accuracy in computing representativeness and informativeness. Based on
the idea that inaccuracy in these measures and not taking noisy instances into
consideration are two sides of a coin and are inherently related, a new loss
function is proposed. This new loss function helps to decrease the effect of
noisy instances while at the same time, reduces bias. We defined &quot;instance
complexity&quot; as a new notion of complexity for instances of a learning problem.
It is proved that noisy instances in the data if any, are the ones with maximum
instance complexity. Based on this loss function which has two functions for
classifying ordinary and noisy instances, a new classifier, named
&quot;Simple-Complex Classifier&quot; is proposed. In this classifier there are a simple
and a complex function, with the complex function responsible for selecting
noisy instances. The resulting optimization problem for both learning and
active learning is highly non-convex and very challenging. In order to solve
it, a convex relaxation is proposed.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07161</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple Guide to S3 Methods</dc:title>
 <dc:creator>Tierney, Nicholas</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Writing functions in R is an important skill for anyone using R. S3 methods
allow for functions to be generalised across different classes and are easy to
implement. Whilst many R users are be adept at creating their own functions, it
seems that there is room for many more to take advantage of R's S3 methods.
This paper provides a simple and targeted guide to explain what S3 methods are,
why people should them, and how they can do it.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07163</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Total Recursion over Lexicographical Orderings: Elementary Recursive
  Operators Beyond PR</dc:title>
 <dc:creator>Cerna, David</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  In this work we generalize primitive recursion in order to construct a
hierarchy of terminating total recursive operators which we refer to as {\em
leveled primitive recursion of order $i$}($\mathbf{PR}_{i}$). Primitive
recursion is equivalent to leveled primitive recursion of order $1$
($\mathbf{PR}_{1}$). The functions constructable from the basic functions make
up $\mathbf{PR}_{0}$. Interestingly, we show that $\mathbf{PR}_{2}$ is a
conservative extension of $\mathbf{PR}_{1}$. However, members of the hierarchy
beyond $\mathbf{PR}_{2}$, that is $\mathbf{PR}_{i}$ where $i\geq 3$, can
formalize the Ackermann function, and thus are more expressive than primitive
recursion. It remains an open question which members of the hierarchy are more
expressive than the previous members and which are conservative extensions. We
conjecture that for all $i\geq 1$ $\mathbf{PR}_{2i} \subset
\mathbf{PR}_{2i+1}$. Investigation of further extensions is left for future
work.
</dc:description>
 <dc:description>Comment: Remains too incomplete and I would like to avoid future reference to
  this work</dc:description>
 <dc:date>2016-08-24</dc:date>
 <dc:date>2018-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07163</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07164</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Hypohamiltonian Snarks and a Theorem of Fiorini</dc:title>
 <dc:creator>Goedgebeur, Jan</dc:creator>
 <dc:creator>Zamfirescu, Carol T.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We discuss an omission in the statement and proof of Fiorini's 1983 theorem
on hypohamiltonian snarks and present a version of this theorem which is more
general in several ways. Using Fiorini's erroneous result, Steffen showed that
hypohamiltonian snarks exist for some $n \ge 10$ and each even $n \ge 92$. We
rectify Steffen's proof by providing a correct demonstration of a technical
lemma on flower snarks, which might be of separate interest. We then strengthen
Steffen's theorem to the strongest possible form by determining all orders for
which hypohamiltonian snarks exists. This also strengthens a result of
M\'{a}\v{c}ajov\'{a} and \v{S}koviera. Finally, we verify a conjecture of
Steffen on hypohamiltonian snarks up to 36 vertices.
</dc:description>
 <dc:description>Comment: 21 pages; submitted for publication</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07179</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimizing Quadratic Functions in Constant Time</dc:title>
 <dc:creator>Hayashi, Kohei</dc:creator>
 <dc:creator>Yoshida, Yuichi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A sampling-based optimization method for quadratic functions is proposed. Our
method approximately solves the following $n$-dimensional quadratic
minimization problem in constant time, which is independent of $n$:
$z^*=\min_{\mathbf{v} \in \mathbb{R}^n}\langle\mathbf{v}, A \mathbf{v}\rangle +
n\langle\mathbf{v}, \mathrm{diag}(\mathbf{d})\mathbf{v}\rangle +
n\langle\mathbf{b}, \mathbf{v}\rangle$, where $A \in \mathbb{R}^{n \times n}$
is a matrix and $\mathbf{d},\mathbf{b} \in \mathbb{R}^n$ are vectors. Our
theoretical analysis specifies the number of samples $k(\delta, \epsilon)$ such
that the approximated solution $z$ satisfies $|z - z^*| = O(\epsilon n^2)$ with
probability $1-\delta$. The empirical performance (accuracy and runtime) is
positively confirmed by numerical experiments.
</dc:description>
 <dc:description>Comment: An extended abstract will appear in the proceedings of NIPS'16</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07182</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Technology Assessment in Entrepreneurial Financing - Can
  Crowdfunding Predict Venture Capital Investments?</dc:title>
 <dc:creator>Kaminski, Jermain</dc:creator>
 <dc:creator>Hopp, Christian</dc:creator>
 <dc:creator>Tykvova, Tereza</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Recent years have seen an upsurge of novel sources of new venture financing
through crowdfunding (CF). We draw on 54,943 successfully crowdfunded projects
and 3,313 venture capital (VC) investments throughout the period
04/2012-06/2015 to investigate, on the aggregate level, how crowdfunding is
related to a more traditional source of entrepreneurial finance, venture
capital. Granger causality tests support the view that VC investments follow
crowdfunding investments. Cointegration tests also suggest a long-run
relationship between crowdfunding and VC investments, while impulse response
functions (IRF) indicate a positive effect running from CF to VC within two to
six months. Crowdfunding seems to help VC investors in assessing future trends
rather than crowding them out of the market.
</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07182</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07187</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantics derived automatically from language corpora contain human-like
  biases</dc:title>
 <dc:creator>Caliskan, Aylin</dc:creator>
 <dc:creator>Bryson, Joanna J.</dc:creator>
 <dc:creator>Narayanan, Arvind</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Artificial intelligence and machine learning are in a period of astounding
growth. However, there are concerns that these technologies may be used, either
with or without intention, to perpetuate the prejudice and unfairness that
unfortunately characterizes many human institutions. Here we show for the first
time that human-like semantic biases result from the application of standard
machine learning to ordinary language---the same sort of language humans are
exposed to every day. We replicate a spectrum of standard human biases as
exposed by the Implicit Association Test and other well-known psychological
studies. We replicate these using a widely used, purely statistical
machine-learning model---namely, the GloVe word embedding---trained on a corpus
of text from the Web. Our results indicate that language itself contains
recoverable and accurate imprints of our historic biases, whether these are
morally neutral as towards insects or flowers, problematic as towards race or
gender, or even simply veridical, reflecting the {\em status quo} for the
distribution of gender with respect to careers or first names. These
regularities are captured by machine learning along with the rest of semantics.
In addition to our empirical findings concerning language, we also contribute
new methods for evaluating bias in text, the Word Embedding Association Test
(WEAT) and the Word Embedding Factual Association Test (WEFAT). Our results
have implications not only for AI and machine learning, but also for the fields
of psychology, sociology, and human ethics, since they raise the possibility
that mere exposure to everyday language can account for the biases we replicate
here.
</dc:description>
 <dc:description>Comment: 14 pages, 3 figures</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07187</dc:identifier>
 <dc:identifier>doi:10.1126/science.aal4230</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07188</identifier>
 <datestamp>2017-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Root Sparse Bayesian Learning for Off-Grid DOA Estimation</dc:title>
 <dc:creator>Dai, Jisheng</dc:creator>
 <dc:creator>Bao, Xu</dc:creator>
 <dc:creator>Xu, Weichao</dc:creator>
 <dc:creator>Chang, Chunqi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The performance of the existing sparse Bayesian learning (SBL) methods for
off-gird DOA estimation is dependent on the trade off between the accuracy and
the computational workload. To speed up the off-grid SBL method while remain a
reasonable accuracy, this letter describes a computationally efficient root SBL
method for off-grid DOA estimation, where a coarse refinable grid, whose
sampled locations are viewed as the adjustable parameters, is adopted. We
utilize an expectation-maximization (EM) algorithm to iteratively refine this
coarse grid, and illustrate that each updated grid point can be simply achieved
by the root of a certain polynomial. Simulation results demonstrate that the
computational complexity is significantly reduced and the modeling error can be
almost eliminated.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07188</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2016.2636319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07192</identifier>
 <datestamp>2016-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design of two combined health recommender systems for tailoring messages
  in a smoking cessation app</dc:title>
 <dc:creator>Hors-Fraile, Santiago</dc:creator>
 <dc:creator>Benjumea, Francisco J N&#xfa;&#xf1;ez</dc:creator>
 <dc:creator>Hern&#xe1;ndez, Laura Carrasco</dc:creator>
 <dc:creator>Ruiz, Francisco Ortega</dc:creator>
 <dc:creator>Fernandez-Luque, Luis</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  In this article, we describe the design of two recommender systems (RS)
designed to support the smoking cessation process through a mobile application.
We plan to use a hybrid RS (content-based, utility-based, and demographic
filtering) to tailor health recommendation messages, and a content-based RS to
schedule a timely delivery of the message. We also define metrics that we will
use to assess their performance, helping people quit smoking when we run the
pilot.
</dc:description>
 <dc:description>Comment: Please, cite as: Hors-Fraile, S., N\'u\~nez Benjumea, F.J., Carrasco
  Hern\'andez, L., Ruiz, F.O., Fernandez-Luque, L. (2016) Design of two
  combined health recommender systems for tailoring messages in a smoking
  cessation app. International Workshop on Engendering Health with RecSys
  co-located with ACM RecSys 2016. Boston, MA, USA</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2016-10-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07192</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07200</identifier>
 <datestamp>2017-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bulk-synchronous pseudo-streaming algorithms for many-core accelerators</dc:title>
 <dc:creator>Buurlage, Jan-Willem</dc:creator>
 <dc:creator>Bannink, Tom</dc:creator>
 <dc:creator>Wits, Abe</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The bulk-synchronous parallel (BSP) model provides a framework for writing
parallel programs with predictable performance. In this paper we extend the BSP
model to support what we will call pseudo-streaming algorithms for
accelerators. We also generalize the BSP cost function to these algorithms, so
that it is possible to predict the running time for programs targeting
many-core accelerators and to identify possible bottlenecks. Several examples
of algorithms within this new framework will be explored. We extend the BSPlib
standard by proposing a small number of new BSP primitives to create and use
streams in a portable way. We will introduce a software library called Epiphany
BSP that implements these ideas for the Parallella development board. Finally
we will give experimental results for pseudo-streaming algorithms on the
Parallella platform.
</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2017-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07200</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07202</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity-achieving and Flicker-free FEC coding scheme for Dimmable
  Visible Light Communication Based on Polar Codes</dc:title>
 <dc:creator>Fang, Junbin</dc:creator>
 <dc:creator>Che, Zhen</dc:creator>
 <dc:creator>Yu, Xiaolong</dc:creator>
 <dc:creator>Chen, Zhe</dc:creator>
 <dc:creator>Jiang, Zoe L.</dc:creator>
 <dc:creator>Yiu, Siu-Ming</dc:creator>
 <dc:creator>Ren, Kui</dc:creator>
 <dc:creator>Tan, Xiaoqing</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Visible light communication (VLC) could provide short-range optical wireless
communication together with illumination using LED lighting. However,
conventional forward error correction (FEC) codes for reliable communication do
not have the features for dimming support and flicker mitigation which are
required in VLC for the main functionality of lighting. Therefore, auxiliary
coding techniques are usually needed, which eventually reduce the coding
efficiency and increase the complexity. In this paper, a polar codes-based FEC
coding scheme for dimmable VLC is proposed to increase the coding efficiency
and simplify the coding structure. Experimental results show that the proposed
scheme has the following advantages: 1) equal probability of 1's and 0's in
codewords, which is inherently supporting 50% dimming balance; 2) short run
length property (about 90% bits have runs shorter than 5) which can avoid
flickers and additional run-length limited line coding; 3) higher coding
efficiency about twofold than that of other coding schemes; 4) capacity
achieving error correction performance with low-complexity encoding and
decoding, which is about 3 dB higher coding gain than that of RS(64,32) in IEEE
standard for dimming ratio 50% and about 1 dB higher coding gain than that of
LDPC codes for dimming ratio 25% (or 75%).
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07206</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Embedded SML using the MLton compiler</dc:title>
 <dc:creator>Murphy, Jeffrey</dc:creator>
 <dc:creator>Shivkumar, Bhargav</dc:creator>
 <dc:creator>Ziarek, Lukasz</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  In this extended abstract we present our current work on leveraging Standard
ML for developing embedded and real-time systems. Specifically we detail our
experiences in modifying MLton, a whole program, optimizing compiler for
Standard ML, for use in such contexts. We focus primarily on the language
runtime, re-working the threading subsystem and garbage collector, as well as
necessary changes for integrating MLton generated programs into a light weight
operating system kernel. We compare and contrast these changes to our previous
work on extending MLton for multicore systems, which focused around acheiving
scalability.
</dc:description>
 <dc:description>Comment: IFL 2016</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07223</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Is a good offensive always the best defense?</dc:title>
 <dc:creator>Toledo-Mar&#xed;n, J. Quetzalc&#xf3;atl</dc:creator>
 <dc:creator>D&#xed;az-M&#xe9;ndez, Rogelio</dc:creator>
 <dc:creator>Mussot, Marcelo del Castillo</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  A checkers-like model game with a simplified set of rules is studied through
extensive simulations of agents with different expertise and strategies. The
introduction of complementary strategies, in a quite general way, provides a
tool to mimic the basic ingredients of a wide scope of real games. We find that
only for the player having the higher offensive expertise (the dominant player
), maximizing the offensive always increases the probability to win. For the
non-dominant player, interestingly, a complete minimization of the offensive
becomes the best way to win in many situations, depending on the relative
values of the defense expertise. Further simulations on the interplay of
defense expertise were done separately, in the context of a fully-offensive
scenario, offering a starting point for analytical treatments. In particular,
we established that in this scenario the total number of moves is defined only
by the player with the lower defensive expertise. We believe that these results
stand for a first step towards a new way to improve decisions-making in a large
number of zero-sum real games.
</dc:description>
 <dc:description>Comment: 12 pages, 12 figures</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07224</identifier>
 <datestamp>2017-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The specific shapes of gender imbalance in scientific authorships: a
  network approach</dc:title>
 <dc:creator>Ara&#xfa;jo, Tanya</dc:creator>
 <dc:creator>Fontainha, Elsa</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Gender differences in collaborative research have received little attention
when compared with the growing importance that women hold in academia and
research. Unsurprisingly, most of bibliometric databases have a strong lack of
directly available information by gender. Although empirical-based network
approaches are often used in the study of research collaboration, the studies
about the influence of gender dissimilarities on the resulting topological
outcomes are still scarce. Here, networks of scientific subjects are used to
characterize patterns that might be associated to five categories of
authorships which were built based on gender. We find enough evidence that
gender imbalance in scientific authorships brings a peculiar trait to the
networks induced from papers published in Web of Science (WoS) indexed journals
of Economics over the period 2010-2015 and having at least one author
affiliated to a Portuguese institution. Our results show the emergence of a
specific pattern when the network of co-occurring subjects is induced from a
set of papers exclusively authored by men. Such a male-exclusive authorship
condition is found to be the solely responsible for the emergence that
particular shape in the network structure. This peculiar trait might facilitate
future network analyses of research collaboration and interdisciplinarity.
</dc:description>
 <dc:description>Comment: 27 Pages, 10 Figures</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2017-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07225</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Simulated Annealing Dedicated to Maximin Latin Hypercube Designs</dc:title>
 <dc:creator>Berg&#xe9;, Pierre</dc:creator>
 <dc:creator>Guiban, Kaourintin Le</dc:creator>
 <dc:creator>Rimmel, Arpad</dc:creator>
 <dc:creator>Tomasik, Joanna</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The goal of our research was to enhance local search heuristics used to
construct Latin Hypercube Designs. First, we introduce the \textit{1D-move}
perturbation to improve the space exploration performed by these algorithms.
Second, we propose a new evaluation function $\psi_{p,\sigma}$ specifically
targeting the Maximin criterion.
  Exhaustive series of experiments with Simulated Annealing, which we used as a
typically well-behaving local search heuristics, confirm that our goal was
reached as the result we obtained surpasses the best scores reported in the
literature. Furthermore, the $\psi_{p,\sigma}$ function seems very promising
for a wide spectrum of optimization problems through the Maximin criterion.
</dc:description>
 <dc:description>Comment: extended version of ACM GECCO 2016 paper entitled &quot;Search Space
  Exploration and an Optimization Criterion for Hard Design Problems&quot;</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07233</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reduction of Self-heating effect in LDMOS devices</dc:title>
 <dc:creator>Maiti, T. K.</dc:creator>
 <dc:creator>Maiti, C. K.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Isotopic purification of group IV elements leads to substantial increase in
thermal conductivity due to reduced scattering of the phonons. Based on this
concept, a simulation study is used to demonstrate the reduction of at least 25
oC in LDMOS average temperature.
</dc:description>
 <dc:description>Comment: 17 pages, 5 figures</dc:description>
 <dc:date>2016-07-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07242</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling and Propagating CNNs in a Tree Structure for Visual Tracking</dc:title>
 <dc:creator>Nam, Hyeonseob</dc:creator>
 <dc:creator>Baek, Mooyeol</dc:creator>
 <dc:creator>Han, Bohyung</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present an online visual tracking algorithm by managing multiple target
appearance models in a tree structure. The proposed algorithm employs
Convolutional Neural Networks (CNNs) to represent target appearances, where
multiple CNNs collaborate to estimate target states and determine the desirable
paths for online model updates in the tree. By maintaining multiple CNNs in
diverse branches of tree structure, it is convenient to deal with
multi-modality in target appearances and preserve model reliability through
smooth updates along tree paths. Since multiple CNNs share all parameters in
convolutional layers, it takes advantage of multiple models with little extra
cost by saving memory space and avoiding redundant network evaluations. The
final target state is estimated by sampling target candidates around the state
in the previous frame and identifying the best sample in terms of a weighted
average score from a set of active CNNs. Our algorithm illustrates outstanding
performance compared to the state-of-the-art techniques in challenging datasets
such as online tracking benchmark and visual object tracking challenge.
</dc:description>
 <dc:description>Comment: 10 pages, Hyeonseob Nam and Mooyeol Baek have equal contribution</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07249</identifier>
 <datestamp>2017-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Benchmarking State-of-the-Art Deep Learning Software Tools</dc:title>
 <dc:creator>Shi, Shaohuai</dc:creator>
 <dc:creator>Wang, Qiang</dc:creator>
 <dc:creator>Xu, Pengfei</dc:creator>
 <dc:creator>Chu, Xiaowen</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep learning has been shown as a successful machine learning method for a
variety of tasks, and its popularity results in numerous open-source deep
learning software tools. Training a deep network is usually a very
time-consuming process. To address the computational challenge in deep
learning, many tools exploit hardware features such as multi-core CPUs and
many-core GPUs to shorten the training time. However, different tools exhibit
different features and running performance when training different types of
deep networks on different hardware platforms, which makes it difficult for end
users to select an appropriate pair of software and hardware. In this paper, we
aim to make a comparative study of the state-of-the-art GPU-accelerated deep
learning software tools, including Caffe, CNTK, MXNet, TensorFlow, and Torch.
We first benchmark the running performance of these tools with three popular
types of neural networks on two CPU platforms and three GPU platforms. We then
benchmark some distributed versions on multiple GPUs. Our contribution is
two-fold. First, for end users of deep learning tools, our benchmarking results
can serve as a guide to selecting appropriate hardware platforms and software
tools. Second, for software developers of deep learning tools, our in-depth
analysis points out possible future directions to further optimize the running
performance.
</dc:description>
 <dc:description>Comment: Revision history: 1. Revise ResNet-50 configuration in MXNet. 2. Add
  faster implementation of ResNet-56 in TensorFlow with multiple GPUs</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2017-02-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07251</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-scale Collaborative Imaging Genetics Studies of Risk Genetic
  Factors for Alzheimer's Disease Across Multiple Institutions</dc:title>
 <dc:creator>Li, Qingyang</dc:creator>
 <dc:creator>Yang, Tao</dc:creator>
 <dc:creator>Zhan, Liang</dc:creator>
 <dc:creator>Hibar, Derrek Paul</dc:creator>
 <dc:creator>Jahanshad, Neda</dc:creator>
 <dc:creator>Wang, Yalin</dc:creator>
 <dc:creator>Ye, Jieping</dc:creator>
 <dc:creator>Thompson, Paul M.</dc:creator>
 <dc:creator>Wang, Jie</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Genome-wide association studies (GWAS) offer new opportunities to identify
genetic risk factors for Alzheimer's disease (AD). Recently, collaborative
efforts across different institutions emerged that enhance the power of many
existing techniques on individual institution data. However, a major barrier to
collaborative studies of GWAS is that many institutions need to preserve
individual data privacy. To address this challenge, we propose a novel
distributed framework, termed Local Query Model (LQM) to detect risk SNPs for
AD across multiple research institutions. To accelerate the learning process,
we propose a Distributed Enhanced Dual Polytope Projection (D-EDPP) screening
rule to identify irrelevant features and remove them from the optimization. To
the best of our knowledge, this is the first successful run of the
computationally intensive model selection procedure to learn a consistent model
across different institutions without compromising their privacy while ranking
the SNPs that may collectively affect AD. Empirical studies are conducted on
809 subjects with 5.9 million SNP features which are distributed across three
individual institutions. D-EDPP achieved a 66-fold speed-up by effectively
identifying irrelevant features.
</dc:description>
 <dc:description>Comment: Published on the 19th International Conference on Medical Image
  Computing and Computer Assisted Intervention (MICCAI). 2016</dc:description>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07251</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07253</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Latent Vector Spaces for Product Search</dc:title>
 <dc:creator>Van Gysel, Christophe</dc:creator>
 <dc:creator>de Rijke, Maarten</dc:creator>
 <dc:creator>Kanoulas, Evangelos</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We introduce a novel latent vector space model that jointly learns the latent
representations of words, e-commerce products and a mapping between the two
without the need for explicit annotations. The power of the model lies in its
ability to directly model the discriminative relation between products and a
particular word. We compare our method to existing latent vector space models
(LSI, LDA and word2vec) and evaluate it as a feature in a learning to rank
setting. Our latent vector space model achieves its enhanced performance as it
learns better product representations. Furthermore, the mapping from words to
products and the representations of words benefit directly from the errors
propagated back from the product representations during parameter estimation.
We provide an in-depth analysis of the performance of our model and analyze the
structure of the learned representations.
</dc:description>
 <dc:description>Comment: CIKM2016, Proceedings of the 25th ACM International Conference on
  Information and Knowledge Management. 2016</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07253</dc:identifier>
 <dc:identifier>doi:10.1145/2983323.2983702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07255</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combinatorial characterization of upward planarity</dc:title>
 <dc:creator>Lu, Xuexing</dc:creator>
 <dc:creator>Ye, Yu</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We give a combinatorial characterization of upward planar graphs in terms of
upward planar orders, which are special linear extensions of edge posets.
</dc:description>
 <dc:description>Comment: 12 pages,8 figures. Comments are welcome!</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07260</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complexity of inheritance of $\mathcal{F}$-convexity for restricted
  games induced by minimum partitions</dc:title>
 <dc:creator>Skoda, Alexandre</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Let $G = (N,E,w)$ be a weighted communication graph (with weight function $w$
on $E$). For every subset $A \subseteq N$, we delete in the subset $E(A)$ of
edges with ends in $A$, all edges of minimum weight in $E(A)$. Then the
connected components of the corresponding induced subgraph constitute a
partition of $A$ that we call $P_{\min}(A)$. For every game $(N, v)$, we define
the $P_{\min}$-restricted game $(N, \bar{v})$ by $\bar{v}(A) = \sum_{F \in
P_{\min}(A)} v(F)$ for all $A \subseteq N$. We prove that we can decide in
polynomial time if there is inheritance of $\mathcal{F}$-convexity from $(N,
v)$ to the $P_{\min}$-restricted game $(N, \bar{v})$ where
$\mathcal{F}$-convexity is obtained by restricting convexity to connected
subsets.
</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07261</identifier>
 <datestamp>2016-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Type Inference for Static Compilation of JavaScript (Extended Version)</dc:title>
 <dc:creator>Chandra, Satish</dc:creator>
 <dc:creator>Gordon, Colin S.</dc:creator>
 <dc:creator>Jeannin, Jean-Baptiste</dc:creator>
 <dc:creator>Schlesinger, Cole</dc:creator>
 <dc:creator>Sridharan, Manu</dc:creator>
 <dc:creator>Tip, Frank</dc:creator>
 <dc:creator>Choi, Youngil</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We present a type system and inference algorithm for a rich subset of
JavaScript equipped with objects, structural subtyping, prototype inheritance,
and first-class methods. The type system supports abstract and recursive
objects, and is expressive enough to accommodate several standard benchmarks
with only minor workarounds. The invariants enforced by the types enable an
ahead-of-time compiler to carry out optimizations typically beyond the reach of
static compilers for dynamic languages. Unlike previous inference techniques
for prototype inheritance, our algorithm uses a combination of lower and upper
bound propagation to infer types and discover type errors in all code,
including uninvoked functions. The inference is expressed in a simple
constraint language, designed to leverage off-the-shelf fixed point solvers. We
prove soundness for both the type system and inference algorithm. An
experimental evaluation showed that the inference is powerful, handling the
aforementioned benchmarks with no manual type annotation, and that the inferred
types enable effective static compilation.
</dc:description>
 <dc:description>Comment: Extended version of OOPSLA 2016 paper of the same name</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2016-10-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07264</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Game Application to Spectrum Scarcity Problems</dc:title>
 <dc:creator>Zabaleta, O. G.</dc:creator>
 <dc:creator>Barrang&#xfa;, J. P.</dc:creator>
 <dc:creator>Arizmendi, C. M.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Recent spectrum-sharing research has produced a strategy to address spectrum
scarcity problems. This novel idea, named cognitive radio, considers that
secondary users can opportunistically exploit spectrum holes left temporarily
unused by primary users. This presents a competitive scenario among cognitive
users, making it suitable for game theory treatment. In this work, we show that
the spectrum-sharing benefits of cognitive radio can be increased by designing
a medium access control based on quantum game theory. In this context, we
propose a model to manage spectrum fairly and effectively, based on a
multiple-users multiple-choice quantum minority game. By taking advantage of
quantum entanglement and quantum interference, it is possible to reduce the
probability of collision problems commonly associated with classic algorithms.
Collision avoidance is an essential property for classic and quantum
communications systems. In our model, two different scenarios are considered,
to meet the requirements of different user strategies. The first considers
sensor networks where the rational use of energy is a cornerstone; the second
focuses on installations where the quality of service of the entire network is
a priority.
</dc:description>
 <dc:description>Comment: 16 pages, 1 figure</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07264</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2016.09.054</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07307</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low Complexity Power Allocation Schemes in Regenerative Multi-user Relay
  Networks</dc:title>
 <dc:creator>Chakrapani, Arvind</dc:creator>
 <dc:creator>Malaney, Robert</dc:creator>
 <dc:creator>Yuan, Jinhong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In relay assisted wireless communications, the multi-source, single relay and
single destination system (an $M$-1-1 system) is of growing importance, due to
the increased demand for higher network throughput and connectivity.
Previously, power allocation in $M$-1-1 systems have assumed availability of
instantaneous channel state information (CSI), which is rather idealistic. In
this paper we consider an $M$-1-1 Decode-and-Forward (DF), Full-Duplex,
orthogonal frequencey division multiple access (OFDMA) based relay system with
statistical-CSI and analyze the achievable rate $R$ of such a system. We show
how $R$ can only be maximized by numerical power allocation schemes which has a
high-complexity of order $\mathcal O(M^3)$. By introducing a rational
approximation in the achievable rate analysis, we develop two low-complexity
power allocation schemes that can obtain a system achievable rate very close to
the maximum $R$. Most importantly, we show that the complexity of our power
allocation schemes is of order $\mathcal O(M\log M)$. We then show how our
power allocation schemes are suitable for a multi-user relay system, where
either the priority is to maximize system throughput, or where lower
computations in power allocation scheme are essential. The work we present in
this paper will be of value to the design and implementation of real-time
multi-user relay systems operating under realistic channel conditions.
</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07310</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning in games with continuous action sets and unknown payoff
  functions</dc:title>
 <dc:creator>Mertikopoulos, Panayotis</dc:creator>
 <dc:creator>Zhou, Zhengyuan</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Primary 91A26, 90C15, secondary 90C33, 68Q32</dc:subject>
 <dc:description>  This paper examines the convergence of no-regret learning in games with
continuous action sets. For concreteness, we focus on learning via &quot;dual
averaging&quot;, a widely used class of no-regret learning schemes where players
take small steps along their individual payoff gradients and then &quot;mirror&quot; the
output back to their action sets. In terms of feedback, we assume that players
can only estimate their payoff gradients up to a zero-mean error with bounded
variance. To study the convergence of the induced sequence of play, we
introduce the notion of variational stability, and we show that stable
equilibria are locally attracting with high probability whereas globally stable
equilibria are globally attracting with probability 1. We also discuss some
applications to mixed-strategy learning in finite games, and we provide
explicit estimates of the method's convergence speed.
</dc:description>
 <dc:description>Comment: 36 pages, 2 figures; completely reworked structure of first version
  and dropped individual concavity assumptions</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07310</dc:identifier>
 <dc:identifier>doi:10.1007/s10107-017-1228-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07323</identifier>
 <datestamp>2018-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparing Speech and Keyboard Text Entry for Short Messages in Two
  Languages on Touchscreen Phones</dc:title>
 <dc:creator>Ruan, Sherry</dc:creator>
 <dc:creator>Wobbrock, Jacob O.</dc:creator>
 <dc:creator>Liou, Kenny</dc:creator>
 <dc:creator>Ng, Andrew</dc:creator>
 <dc:creator>Landay, James</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:description>  With the ubiquity of mobile touchscreen devices like smartphones, two widely
used text entry methods have emerged: small touch-based keyboards and speech
recognition. Although speech recognition has been available on desktop
computers for years, it has continued to improve at a rapid pace, and it is
currently unknown how today's modern speech recognizers compare to
state-of-the-art mobile touch keyboards, which also have improved considerably
since their inception. To discover both methods' &quot;upper-bound performance,&quot; we
evaluated them in English and Mandarin Chinese on an Apple iPhone 6 Plus in a
laboratory setting. Our experiment was carried out using Baidu's Deep Speech 2,
a deep learning-based speech recognition system, and the built-in Qwerty
(English) or Pinyin (Mandarin) Apple iOS keyboards. We found that with speech
recognition, the English input rate was 2.93 times faster (153 vs. 52 WPM), and
the Mandarin Chinese input rate was 2.87 times faster (123 vs. 43 WPM) than the
keyboard for short message transcription under laboratory conditions for both
methods. Furthermore, although speech made fewer errors during entry (5.30% vs.
11.22% corrected error rate), it left slightly more errors in the final
transcribed text (1.30% vs. 0.79% uncorrected error rate). Our results show
that comparatively, under ideal conditions for both methods, upper-bound speech
recognition performance has greatly improved compared to prior systems, and
might see greater uptake in the future, although further study is required to
quantify performance in non-laboratory settings for both methods.
</dc:description>
 <dc:description>Comment: 23 pages</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07323</dc:identifier>
 <dc:identifier>Journal Proceedings of the ACM on Interactive, Mobile, Wearable
  and Ubiquitous Technologies archive Volume 1 Issue 4, December 2017</dc:identifier>
 <dc:identifier>doi:10.1145/3161187</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07328</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fundamental Limits of Budget-Fidelity Trade-off in Label Crowdsourcing</dc:title>
 <dc:creator>Lahouti, Farshad</dc:creator>
 <dc:creator>Hassibi, Babak</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Digital crowdsourcing (CS) is a modern approach to perform certain large
projects using small contributions of a large crowd. In CS, a taskmaster
typically breaks down the project into small batches of tasks and assigns them
to so-called workers with imperfect skill levels. The crowdsourcer then
collects and analyzes the results for inference and serving the purpose of the
project. In this work, the CS problem, as a human-in-the-loop computation
problem, is modeled and analyzed in an information theoretic rate-distortion
framework. The purpose is to identify the ultimate fidelity that one can
achieve by any form of query from the crowd and any decoding (inference)
algorithm with a given budget. The results are established by a joint source
channel (de)coding scheme, which represent the query scheme and inference, over
parallel noisy channels, which model workers with imperfect skill levels. We
also present and analyze a query scheme dubbed $k$-ary incidence coding and
study optimized query pricing in this setting.
</dc:description>
 <dc:description>Comment: Accepted for NIPS 2016, Barcelona, Spain</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07329</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scheduling Resource-Bounded Monitoring Devices for Event Detection and
  Isolation in Networks</dc:title>
 <dc:creator>Abbas, Waseem</dc:creator>
 <dc:creator>Laszka, Aron</dc:creator>
 <dc:creator>Vorobeychik, Yevgeniy</dc:creator>
 <dc:creator>Koutsoukos, Xenofon</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In networked systems, monitoring devices such as sensors are typically
deployed to monitor various target locations. Targets are the points in the
physical space at which events of some interest, such as random faults or
attacks, can occur. Most often, these devices have limited energy supplies, and
they can operate for a limited duration. As a result, energy-efficient
monitoring of various target locations through a set of monitoring devices with
limited energy supplies is a crucial problem in networked systems. In this
paper, we study optimal scheduling of monitoring devices to maximize network
coverage for detecting and isolating events on targets for a given network
lifetime. The monitoring devices considered could remain active only for a
fraction of the overall network lifetime. We formulate the problem of
scheduling of monitoring devices as a graph labeling problem, which unlike
other existing solutions, allows us to directly utilize the underlying network
structure to explore the trade-off between coverage and network lifetime. In
this direction, first we propose a greedy heuristic to solve the graph labeling
problem, and then provide a game-theoretic solution to achieve near optimal
graph labeling. Moreover, the proposed setup can be used to simultaneously
solve the scheduling and placement of monitoring devices, which yields improved
performance as compared to separately solving the placement and scheduling
problems. Finally, we illustrate our results on various networks, including
real-world water distribution networks.
</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07336</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Playing Anonymous Games using Simple Strategies</dc:title>
 <dc:creator>Cheng, Yu</dc:creator>
 <dc:creator>Diakonikolas, Ilias</dc:creator>
 <dc:creator>Stewart, Alistair</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We investigate the complexity of computing approximate Nash equilibria in
anonymous games. Our main algorithmic result is the following: For any
$n$-player anonymous game with a bounded number of strategies and any constant
$\delta&gt;0$, an $O(1/n^{1-\delta})$-approximate Nash equilibrium can be computed
in polynomial time. Complementing this positive result, we show that if there
exists any constant $\delta&gt;0$ such that an $O(1/n^{1+\delta})$-approximate
equilibrium can be computed in polynomial time, then there is a fully
polynomial-time approximation scheme for this problem.
  We also present a faster algorithm that, for any $n$-player $k$-strategy
anonymous game, runs in time $\tilde O((n+k) k n^k)$ and computes an $\tilde
O(n^{-1/3} k^{11/3})$-approximate equilibrium. This algorithm follows from the
existence of simple approximate equilibria of anonymous games, where each
player plays one strategy with probability $1-\delta$, for some small $\delta$,
and plays uniformly at random with probability $\delta$.
  Our approach exploits the connection between Nash equilibria in anonymous
games and Poisson multinomial distributions (PMDs). Specifically, we prove a
new probabilistic lemma establishing the following: Two PMDs, with large
variance in each direction, whose first few moments are approximately matching
are close in total variation distance. Our structural result strengthens
previous work by providing a smooth tradeoff between the variance bound and the
number of matching moments.
</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07337</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>YouSkyde: Information Hiding for Skype Video Traffic</dc:title>
 <dc:creator>Mazurczyk, Wojciech</dc:creator>
 <dc:creator>Karas, Maciej</dc:creator>
 <dc:creator>Szczypiorski, Krzysztof</dc:creator>
 <dc:creator>Janicki, Artur</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  In this paper a new information hiding method for Skype videoconference calls
- YouSkyde - is introduced. A Skype traffic analysis revealed that introducing
intentional losses into the Skype video traffic stream to provide the means for
clandestine communication is the most favourable solution. A YouSkyde
proof-of-concept implementation was carried out and its experimental evaluation
is presented. The results obtained prove that the proposed method is feasible
and offer a steganographic bandwidth as high as 0.93 kbps, while introducing
negligible distortions into transmission quality and providing high
undetectability.
</dc:description>
 <dc:description>Comment: 16 pages, 10 figures</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07337</dc:identifier>
 <dc:identifier>Multimedia Tools and Applications, 2015</dc:identifier>
 <dc:identifier>doi:10.1007/s11042-015-2740-0</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07338</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Trajectory Simplification Algorithm for Natural User Interfaces in
  Robot Programming by Demonstration</dc:title>
 <dc:creator>Marino, Daniel L.</dc:creator>
 <dc:creator>Manic, Milos</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Trajectory simplification is a problem encountered in areas like Robot
programming by demonstration, CAD/CAM, computer vision, and in GPS-based
applications like traffic analysis. This problem entails reduction of the
points in a given trajectory while keeping the relevant points which preserve
important information. The benefits include storage reduction, computational
expense, while making data more manageable. Common techniques formulate a
minimization problem to be solved, where the solution is found iteratively
under some error metric, which causes the algorithms to work in super-linear
time. We present an algorithm called FastSTray, which selects the relevant
points in the trajectory in linear time by following an open loop heuristic
approach. While most current trajectory simplification algorithms are tailored
for GPS trajectories, our approach focuses on smooth trajectories for robot
programming by demonstration recorded using motion capture systems.Two
variations of the algorithm are presented: 1. aims to preserve shape and
temporal information; 2. preserves only shape information. Using the points in
the simplified trajectory we use cubic splines to interpolate between these
points and recreate the original trajectory. The presented algorithm was tested
on trajectories recorded from a hand-tracking system. It was able to eliminate
about 90% of the points in the original trajectories while maintaining errors
between 0.78-2cm which corresponds to 1%-2.4% relative error with respect to
the bounding box of the trajectories.
</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07343</identifier>
 <datestamp>2017-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modified Relay Selection and Circuit Selection for Faster Tor</dc:title>
 <dc:creator>Imani, Mohsen</dc:creator>
 <dc:creator>Amirabadi, Mehrdad</dc:creator>
 <dc:creator>Wright, Matthew</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Users of the Tor anonymity system suffer from lessthan- ideal performance, in
part because circuit building and selection processes are not tuned for speed.
In this paper, we examine both the process of selecting among pre-built
circuits and the process of selecting the path of relays for use in building
new circuits to improve performance while maintaining anonymity. First, we show
that having three pre-built circuits available allows the Tor client to
identify fast circuits and improves median time to first byte (TTFB) by 15%
over congestion-aware routing, the current state-of-the-art method. Second, we
propose a new path selection algorithm that includes broad geographic location
information together with bandwidth to reduce delays. In Shadow simulations, we
find 20% faster median TTFB and 11% faster median total download times over
congestion-aware routing for accessing webpage-sized objects. Our security
evaluations show that this approach leads to better or equal security against a
generic relay-level adversary compared to Tor, but increased vulnerability to
targeted attacks. We explore this trade-off and find settings of our system
that offer good performance, modestly better security against a generic
adversary, and only slightly more vulnerability to a targeted adversary.
</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2017-06-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07348</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms for Colourful Simplicial Depth and Medians in the Plane</dc:title>
 <dc:creator>Zasenko, Olga</dc:creator>
 <dc:creator>Stephen, Tamon</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>68U05, 52B55, 05C85</dc:subject>
 <dc:description>  The colourful simplicial depth of a point x in the plane relative to a
configuration of n points in k colour classes is exactly the number of closed
simplices (triangles) with vertices from 3 different colour classes that
contain x in their convex hull. We consider the problems of efficiently
computing the colourful simplicial depth of a point x, and of finding a point,
called a median, that maximizes colourful simplicial depth.
  For computing the colourful simplicial depth of x, our algorithm runs in time
O(n log(n) + k n) in general, and O(kn) if the points are sorted around x. For
finding the colourful median, we get a time of O(n^4). For comparison, the
running times of the best known algorithm for the monochrome version of these
problems are O(n log(n)) in general, improving to O(n) if the points are sorted
around x for monochrome depth, and O(n^4) for finding a monochrome median.
</dc:description>
 <dc:description>Comment: 17 pages, 8 figures</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07348</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07352</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Connectivity-Aware Traffic Phase Scheduling for Heterogeneously
  Connected Vehicles</dc:title>
 <dc:creator>Zhou, Shanyu</dc:creator>
 <dc:creator>Seferoglu, Hulya</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We consider a transportation system of heterogeneously connected vehicles,
where not all vehicles are able to communicate. Heterogeneous connectivity in
transportation systems is coupled to practical constraints such that (i) not
all vehicles may be equipped with devices having communication interfaces, (ii)
some vehicles may not prefer to communicate due to privacy and security
reasons, and (iii) communication links are not perfect and packet losses and
delay occur in practice. In this context, it is crucial to develop control
algorithms by taking into account the heterogeneity. In this paper, we
particularly focus on making traffic phase scheduling decisions. We develop a
connectivity-aware traffic phase scheduling algorithm for heterogeneously
connected vehicles that increases the intersection efficiency (in terms of the
average number of vehicles that are allowed to pass the intersection) by taking
into account the heterogeneity. The simulation results show that our algorithm
significantly improves the efficiency of intersections as compared to the
baselines.
</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07352</dc:identifier>
 <dc:identifier>doi:10.1145/2980100.2980105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07357</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Bidding in Repeated Wireless Spectrum Auctions with Budget
  Constraints</dc:title>
 <dc:creator>Khaledi, Mehrdad</dc:creator>
 <dc:creator>Abouzeid, Alhussein</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Small operators who take part in secondary wireless spectrum markets
typically have strict budget limits. In this paper, we study the bidding
problem of a budget constrained operator in repeated secondary spectrum
auctions. In existing truthful auctions, truthful bidding is the optimal
strategy of a bidder. However, budget limits impact bidding behaviors and make
bidding decisions complicated, since bidders may behave differently to avoid
running out of money. We formulate the problem as a dynamic auction game
between operators, where knowledge of other operators is limited due to the
distributed nature of wireless networks/markets. We first present a Markov
Decision Process (MDP) formulation of the problem and characterize the optimal
bidding strategy of an operator, provided that opponents' bids are i.i.d. Next,
we generalize the formulation to a Markov game that, in conjunction with
model-free reinforcement learning approaches, enables an operator to make
inferences about its opponents based on local observations. Finally, we present
a fully distributed learning-based bidding algorithm which relies only on local
information. Our numerical results show that our proposed learning-based
bidding results in a better utility than truthful bidding.
</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07358</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cloud Radio Access Networks: Uplink Channel Estimation and Downlink
  Precoding</dc:title>
 <dc:creator>Simeone, Osvaldo</dc:creator>
 <dc:creator>Kang, Jinkyu</dc:creator>
 <dc:creator>Kang, Joonhyuk</dc:creator>
 <dc:creator>Shamai, Shlomo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The gains afforded by cloud radio access network (C-RAN) in terms of savings
in capital and operating expenses, flexibility, interference management and
network densification rely on the presence of high-capacity low-latency
fronthaul connectivity between remote radio heads (RRHs) and baseband unit
(BBU). In light of the non-uniform and limited availability of fiber optics
cables, the bandwidth constraints on the fronthaul network call, on the one
hand, for the development of advanced baseband compression strategies and, on
the other hand, for a closer investigation of the optimal functional split
between RRHs and BBU. In this chapter, after a brief introduction to signal
processing challenges in C-RAN, this optimal function split is studied at the
physical (PHY) layer as it pertains to two key baseband signal processing
steps, namely channel estimation in the uplink and channel encoding/ linear
precoding in the downlink. Joint optimization of baseband fronthaul compression
and of baseband signal processing is tackled under different PHY functional
splits, whereby uplink channel estimation and downlink channel encoding/ linear
precoding are carried out either at the RRHs or at the BBU. The analysis, based
on information-theoretical arguments, and numerical results yields insight into
the configurations of network architecture and fronthaul capacities in which
different functional splits are advantageous. The treatment also emphasizes the
versatility of deterministic and stochastic successive convex approximation
strategies for the optimization of C-RANs.
</dc:description>
 <dc:description>Comment: to appear in &quot;Signal Processing for 5G: Algorithm and
  Implementations,&quot; Wiley, USA, Editors: Fa-Long Luo and J. Zhong. arXiv admin
  note: substantial text overlap with arXiv:1412.7713</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07362</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Implementation of a TDD-Based 128-Antenna Massive MIMO
  Prototyping System</dc:title>
 <dc:creator>Yang, Xi</dc:creator>
 <dc:creator>Lu, Wen-Jun</dc:creator>
 <dc:creator>Wang, Ning</dc:creator>
 <dc:creator>Nieman, Karl</dc:creator>
 <dc:creator>Jin, Shi</dc:creator>
 <dc:creator>Zhu, Hongbo</dc:creator>
 <dc:creator>Mu, Xiaomin</dc:creator>
 <dc:creator>Wong, Ian</dc:creator>
 <dc:creator>Huang, Yongming</dc:creator>
 <dc:creator>You, Xiaohu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Spurred by the dramatic mobile IP growth and the emerging Internet of Things
(IoT) and cloud-based applications, wireless networking is witnessing a
paradigm shift. By fully exploiting the spatial degrees of freedom, the massive
multipleinput- multiple-output (MIMO) technology promises significant gains in
both data rates and link reliability. This paper presents a time-division
duplex (TDD)-based 128-antenna massive MIMO prototyping system designed to
operate on a 20 MHz bandwidth. Up to twelve single-antenna users can be served
by the designed system at the same time. System model is provided and
link-level simulation corresponding to our practical TDDbased massive MIMO
prototyping system is conducted to validate our design and performance of the
algorithms. Based on the system hardware design demonstrated in this paper,
both uplink real-time video and downlink data transmissions are realized, and
the experiment results show that 268.8 Mbps rate was achieved for eight
single-antenna users using QPSK modulation. The maximum spectral efficiency of
the designed system will be 80.64 bit/s/Hz by twelve single-antenna users with
256-QAM modulation.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07362</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07365</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Compression of Deep Neural Networks</dc:title>
 <dc:creator>Wang, Xing</dc:creator>
 <dc:creator>Liang, Jie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep neural networks generally involve some layers with mil- lions of
parameters, making them difficult to be deployed and updated on devices with
limited resources such as mobile phones and other smart embedded systems. In
this paper, we propose a scalable representation of the network parameters, so
that different applications can select the most suitable bit rate of the
network based on their own storage constraints. Moreover, when a device needs
to upgrade to a high-rate network, the existing low-rate network can be reused,
and only some incremental data are needed to be downloaded. We first
hierarchically quantize the weights of a pre-trained deep neural network to
enforce weight sharing. Next, we adaptively select the bits assigned to each
layer given the total bit budget. After that, we retrain the network to
fine-tune the quantized centroids. Experimental results show that our method
can achieve scalable compression with graceful degradation in the performance.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures, ACM Multimedia 2016</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07371</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracing technological development trajectories: A genetic knowledge
  persistence-based main path approach</dc:title>
 <dc:creator>Park, Hyunseok</dc:creator>
 <dc:creator>Magee, Christopher L.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The aim of this paper is to propose a new method to identify main paths in a
technological domain using patent citations. Previous approaches for using main
path analysis have greatly improved our understanding of actual technological
trajectories but nonetheless have some limitations. They have high potential to
miss some dominant patents from the identified main paths; nonetheless, the
high network complexity of their main paths makes qualitative tracing of
trajectories problematic. The proposed method searches backward and forward
paths from the high-persistence patents which are identified based on a
standard genetic knowledge persistence algorithm. We tested the new method by
applying it to the desalination and the solar photovoltaic domains and compared
the results to output from the same domains using a prior method. The empirical
results show that the proposed method overcomes the aforementioned drawbacks
defining main paths that are almost 10x less complex while containing more of
the relevant important knowledge than the main path networks defined by the
existing method.
</dc:description>
 <dc:description>Comment: 20 pages, 7 figures</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07371</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0170895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07373</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applying Topological Persistence in Convolutional Neural Network for
  Music Audio Signals</dc:title>
 <dc:creator>Liu, Jen-Yu</dc:creator>
 <dc:creator>Jeng, Shyh-Kang</dc:creator>
 <dc:creator>Yang, Yi-Hsuan</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Recent years have witnessed an increased interest in the application of
persistent homology, a topological tool for data analysis, to machine learning
problems. Persistent homology is known for its ability to numerically
characterize the shapes of spaces induced by features or functions. On the
other hand, deep neural networks have been shown effective in various tasks. To
our best knowledge, however, existing neural network models seldom exploit
shape information. In this paper, we investigate a way to use persistent
homology in the framework of deep neural networks. Specifically, we propose to
embed the so-called &quot;persistence landscape,&quot; a rather new topological summary
for data, into a convolutional neural network (CNN) for dealing with audio
signals. Our evaluation on automatic music tagging, a multi-label
classification task, shows that the resulting persistent convolutional neural
network (PCNN) model can perform significantly better than state-of-the-art
models in prediction accuracy. We also discuss the intuition behind the design
of the proposed model, and offer insights into the features that it learns.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07373</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07383</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Restricted completion of sparse partial Latin squares</dc:title>
 <dc:creator>Andr&#xe9;n, Lina J.</dc:creator>
 <dc:creator>Casselgren, Carl Johan</dc:creator>
 <dc:creator>Markstr&#xf6;m, Klas</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  An $n \times n$ partial Latin square $P$ is called $\alpha$-dense if each row
and column has at most $\alpha n$ non-empty cells and each symbol occurs at
most $\alpha n$ times in $P$. An $n \times n$ array $A$ where each cell
contains a subset of $\{1,\dots, n\}$ is a $(\beta n, \beta n, \beta n)$-array
if each symbol occurs at most $\beta n$ times in each row and column and each
cell contains a set of size at most $\beta n$. Combining the notions of
completing partial Latin squares and avoiding arrays, we prove that there are
constants $\alpha, \beta &gt; 0$ such that, for every positive integer $n$, if $P$
is an $\alpha$-dense $n \times n$ partial Latin square, $A$ is an $n \times n$
$(\beta n, \beta n, \beta n)$-array, and no cell of $P$ contains a symbol that
appears in the corresponding cell of $A$, then there is a completion of $P$
that avoids $A$; that is, there is a Latin square $L$ that agrees with $P$ on
every non-empty cell of $P$, and, for each $i,j$ satisfying $1 \leq i,j \leq
n$, the symbol in position $(i,j)$ in $L$ does not appear in the corresponding
cell of $A$.
</dc:description>
 <dc:description>Comment: 19 pages</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07398</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings First Workshop on Causal Reasoning for Embedded and
  safety-critical Systems Technologies</dc:title>
 <dc:creator>G&#xf6;ssler, Gregor</dc:creator>
 <dc:creator>Sokolsky, Oleg</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Formal approaches for automated causality analysis, fault localization,
explanation of events, accountability and blaming have been proposed
independently by several communities --- in particular, AI, concurrency,
model-based diagnosis, formal methods. Work on these topics has significantly
gained speed during the last years. The goals of CREST are to bring together
and foster exchange between researchers from the different communities, and to
present and discuss recent advances and new ideas in the field.
  The workshop program consisted of a set of invited and contributed
presentations that illustrate different techniques for, and applications of,
causality analysis and fault localization.
  The program was anchored by two keynote talks. The keynote by Hana Chockler
(King's College) provided a broad perspective on the application of causal
reasoning based on Halpern and Pearl's definitions of actual causality to a
variety of application domains ranging from formal verification to legal
reasoning. The keynote by Chao Wang (Virginia Tech) concentrated on
constraint-based analysis techniques for debugging and verifying concurrent
programs.
  Workshop papers deal with compositional causality analysis and a wide
spectrum of application for causal reasoning, such as debugging of
probabilistic models, accountability and responsibility, hazard analysis in
practice based on Lewis' counterfactuals, and fault localization and repair.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07398</dc:identifier>
 <dc:identifier>EPTCS 224, 2016</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07400</identifier>
 <datestamp>2017-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collaborative Filtering with Recurrent Neural Networks</dc:title>
 <dc:creator>Devooght, Robin</dc:creator>
 <dc:creator>Bersini, Hugues</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We show that collaborative filtering can be viewed as a sequence prediction
problem, and that given this interpretation, recurrent neural networks offer
very competitive approach. In particular we study how the long short-term
memory (LSTM) can be applied to collaborative filtering, and how it compares to
standard nearest neighbors and matrix factorization methods on movie
recommendation. We show that the LSTM is competitive in all aspects, and
largely outperforms other methods in terms of item coverage and short term
predictions.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:date>2017-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07403</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Assurance-based Approach to Verification and Validation of
  Human--Robot Teams</dc:title>
 <dc:creator>Webster, Matt</dc:creator>
 <dc:creator>Western, David</dc:creator>
 <dc:creator>Araiza-Illan, Dejanira</dc:creator>
 <dc:creator>Dixon, Clare</dc:creator>
 <dc:creator>Eder, Kerstin</dc:creator>
 <dc:creator>Fisher, Michael</dc:creator>
 <dc:creator>Pipe, Anthony G.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  We present an approach for the verification and validation (V\&amp;V) of robot
assistants in the context of human-robot interactions (HRI), to demonstrate
their trustworthiness through integral assurances on their safety and
functional correctness. Trust in robot assistants will allow them to transition
from the laboratory into our everyday lives. The complex and unpredictable
nature of the real world in which assistant and service robots operate, the
limitations on available V\&amp;V techniques when used individually, and the
consequent lack of confidence on the verification results (or assurances),
present challenges to overcome. Our approach, called \textit{assurance-based
verification}, addresses these challenges by combining formal verification
(model checking), simulation-based testing, and user validation in experiments
with a real robot. We demonstrate our assurance-based V\&amp;V approach through a
handover task, the most critical part of a complex cooperative manufacturing
scenario, for which we proposed some safety and liveness requirements to verify
and validate. We construct formal models, simulations and an experimental test
rig for the HRI. To capture requirements we use temporal logic properties,
assertion checkers and informal textual descriptions. This combination of
approaches allows V\&amp;V of the HRI task at different levels of modelling detail
and thoroughness of exploration, thus overcoming the individual limitations of
each method. Should the resulting assurances present discrepancies, an
iterative process between the three V\&amp;V techniques takes place until
confidence in these assurances is gained from refining and improving the assets
(i.e., system and requirement models) to represent the HRI task in a more
truthful manner.
</dc:description>
 <dc:description>Comment: 49 pages</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07410</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topological aggregation, the twin paradox and the no show paradox</dc:title>
 <dc:creator>Ch&#xe8;ze, Guillaume</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Consider the framework of topological aggregation introduced by Chichilnisky
(1980). We prove that in this framework the Twin Paradox and the No Show
Paradox cannot be avoided. Anonymity and unanimity are not needed to obtain
these results.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07410</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07411</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Octree-Based Approach towards Efficient Variational Range Data Fusion</dc:title>
 <dc:creator>Kehl, Wadim</dc:creator>
 <dc:creator>Holl, Tobias</dc:creator>
 <dc:creator>Tombari, Federico</dc:creator>
 <dc:creator>Ilic, Slobodan</dc:creator>
 <dc:creator>Navab, Nassir</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Volume-based reconstruction is usually expensive both in terms of memory
consumption and runtime. Especially for sparse geometric structures, volumetric
representations produce a huge computational overhead. We present an efficient
way to fuse range data via a variational Octree-based minimization approach by
taking the actual range data geometry into account. We transform the data into
Octree-based truncated signed distance fields and show how the optimization can
be conducted on the newly created structures. The main challenge is to uphold
speed and a low memory footprint without sacrificing the solutions' accuracy
during optimization. We explain how to dynamically adjust the optimizer's
geometric structure via joining/splitting of Octree nodes and how to define the
operators. We evaluate on various datasets and outline the suitability in terms
of performance and geometric accuracy.
</dc:description>
 <dc:description>Comment: BMVC 2016</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07413</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$\chi$-bounds, operations and chords</dc:title>
 <dc:creator>Pham, Lan Anh</dc:creator>
 <dc:creator>Trotignon, Nicolas</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C75, 05C15, 05C85</dc:subject>
 <dc:description>  A \emph{long unichord} in a graph is an edge that is the unique chord of some
cycle of length at least 5. A graph is \emph{long-unichord-free} if it does not
contain any long-unichord. We prove a structure theorem for long-unichord-free
graph. We give an $O(n^4m)$-time algorithm to recognize them. We show that any
long-unichord-free graph $G$ can be colored with at most $O(\omega^3)$ colors,
where $\omega$ is the maximum number of pairwise adjacent vertices in $G$.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07433</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mean Deviation Similarity Index: Efficient and Reliable Full-Reference
  Image Quality Evaluator</dc:title>
 <dc:creator>Nafchi, Hossein Ziaei</dc:creator>
 <dc:creator>Shahkolaei, Atena</dc:creator>
 <dc:creator>Hedjam, Rachid</dc:creator>
 <dc:creator>Cheriet, Mohamed</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Applications of perceptual image quality assessment (IQA) in image and video
processing, such as image acquisition, image compression, image restoration and
multimedia communication, have led to the development of many IQA metrics. In
this paper, a reliable full reference IQA model is proposed that utilize
gradient similarity (GS), chromaticity similarity (CS), and deviation pooling
(DP). By considering the shortcomings of the commonly used GS to model human
visual system (HVS), a new GS is proposed through a fusion technique that is
more likely to follow HVS. We propose an efficient and effective formulation to
calculate the joint similarity map of two chromatic channels for the purpose of
measuring color changes. In comparison with a commonly used formulation in the
literature, the proposed CS map is shown to be more efficient and provide
comparable or better quality predictions. Motivated by a recent work that
utilizes the standard deviation pooling, a general formulation of the DP is
presented in this paper and used to compute a final score from the proposed GS
and CS maps. This proposed formulation of DP benefits from the Minkowski
pooling and a proposed power pooling as well. The experimental results on six
datasets of natural images, a synthetic dataset, and a digitally retouched
dataset show that the proposed index provides comparable or better quality
predictions than the most recent and competing state-of-the-art IQA metrics in
the literature, it is reliable and has low complexity. The MATLAB source code
of the proposed metric is available at
https://www.mathworks.com/matlabcentral/fileexchange/59809.
</dc:description>
 <dc:description>Comment: 11 pages, 8 figures, 6 tables</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07433</dc:identifier>
 <dc:identifier>doi:10.1109/ACCESS.2016.2604042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07435</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Skew-t Filter and Smoother with Improved Covariance Matrix Approximation</dc:title>
 <dc:creator>Nurminen, Henri</dc:creator>
 <dc:creator>Ardeshiri, Tohid</dc:creator>
 <dc:creator>Pich&#xe9;, Robert</dc:creator>
 <dc:creator>Gustafsson, Fredrik</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  Filtering and smoothing algorithms for linear discrete-time state-space
models with skew-t-distributed measurement noise are presented. The presented
algorithms use a variational Bayes based posterior approximation with coupled
location and skewness variables to reduce the error caused by the variational
approximation. Although the variational update is done suboptimally, our
simulations show that the proposed method gives a more accurate approximation
of the posterior covariance matrix than an earlier proposed variational
algorithm. Consequently, the novel filter and smoother outperform the earlier
proposed robust filter and smoother and other existing low-complexity
alternatives in accuracy and speed. We present both simulations and tests based
on real-world navigation data, in particular GPS data in an urban area, to
demonstrate the performance of the novel methods. Moreover, the extension of
the proposed algorithms to cover the case where the distribution of the
measurement noise is multivariate skew-t is outlined. Finally, the paper
presents a study of theoretical performance bounds for the proposed algorithms.
</dc:description>
 <dc:description>Comment: 13 pages, 17 figures. Submitted for publication in IEEE Transactions
  on Signal Processing. arXiv admin note: substantial text overlap with
  arXiv:1603.06216</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07435</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07440</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Activity Networks with Delays An application to toxicity analysis</dc:title>
 <dc:creator>Delaplace, Franck</dc:creator>
 <dc:creator>Di Giusto, Cinzia</dc:creator>
 <dc:creator>Giavitto, Jean-Louis</dc:creator>
 <dc:creator>Klaudel, Hanna</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  ANDy , Activity Networks with Delays, is a discrete time framework aimed at
the qualitative modelling of time-dependent activities. The modular and concise
syntax makes ANDy suitable for an easy and natural modelling of time-dependent
biological systems (i.e., regulatory pathways). Activities involve entities
playing the role of activators, inhibitors or products of biochemical network
operation. Activities may have given duration, i.e., the time required to
obtain results. An entity may represent an object (e.g., an agent, a
biochemical species or a family of thereof) with a local attribute, a state
denoting its level (e.g., concentration, strength). Entities levels may change
as a result of an activity or may decay gradually as time passes by. The
semantics of ANDy is formally given via high-level Petri nets ensuring this way
some modularity. As main results we show that ANDy systems have finite state
representations even for potentially infinite processes and it well adapts to
the modelling of toxic behaviours. As an illustration, we present a
classification of toxicity properties and give some hints on how they can be
verified with existing tools on ANDy systems. A small case study on blood
glucose regulation is provided to exemplify the ANDy framework and the toxicity
properties.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07440</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07441</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hard Negative Mining for Metric Learning Based Zero-Shot Classification</dc:title>
 <dc:creator>Bucher, Maxime</dc:creator>
 <dc:creator>Herbin, St&#xe9;phane</dc:creator>
 <dc:creator>Jurie, Fr&#xe9;d&#xe9;ric</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Zero-Shot learning has been shown to be an efficient strategy for domain
adaptation. In this context, this paper builds on the recent work of Bucher et
al. [1], which proposed an approach to solve Zero-Shot classification problems
(ZSC) by introducing a novel metric learning based objective function. This
objective function allows to learn an optimal embedding of the attributes
jointly with a measure of similarity between images and attributes. This paper
extends their approach by proposing several schemes to control the generation
of the negative pairs, resulting in a significant improvement of the
performance and giving above state-of-the-art results on three challenging ZSC
datasets.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07441</dc:identifier>
 <dc:identifier>ECCV 16 WS TASK-CV: Transferring and Adapting Source Knowledge in
  Computer Vision, Oct 2016, Amsterdam, Netherlands. ECCV 16 WS TASK-CV:
  Transferring and Adapting Source Knowledge in Computer Vision</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07443</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using an epidemiological approach to maximize data survival in the
  internet of things</dc:title>
 <dc:creator>Makhoul, Abdallah</dc:creator>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:creator>Hakem, Mourad</dc:creator>
 <dc:creator>Bahi, Jacques M.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The internet of things (IoT) has gained worldwide attention in recent years.
It transforms the everyday objects that surround us into proactive actors of
the Internet, generating and consuming information. An important issue related
to the appearance of such large-scale self-coordinating IoT is the reliability
and the collaboration between the objects in the presence of environmental
hazards. High failure rates lead to significant loss of data. Therefore, data
survivability is a main challenge of the IoT. In this paper, we have developed
a compartmental e-Epidemic SIR (Susceptible-Infectious-Recovered) model to save
the data in the network and let it survive after attacks. Furthermore, our
model takes into account the dynamic topology of the network where natural
death (crashing nodes) and birth are defined and analyzed. Theoretical methods
and simulations are employed to solve and simulate the system of equations
developed and to analyze the model.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1608.05951</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07443</dc:identifier>
 <dc:identifier>ACM Transactions on Internet Technology. 16 (1), 2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07444</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Who Leads the Clothing Fashion: Style, Color, or Texture? A
  Computational Study</dc:title>
 <dc:creator>Zou, Qin</dc:creator>
 <dc:creator>Zhang, Zheng</dc:creator>
 <dc:creator>Wang, Qian</dc:creator>
 <dc:creator>Li, Qingquan</dc:creator>
 <dc:creator>Chen, Long</dc:creator>
 <dc:creator>Wang, Song</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  It is well known that clothing fashion is a distinctive and often habitual
trend in the style in which a person dresses. Clothing fashions are usually
expressed with visual stimuli such as style, color, and texture. However, it is
not clear which visual stimulus places higher/lower influence on the updating
of clothing fashion. In this study, computer vision and machine learning
techniques are employed to analyze the influence of different visual stimuli on
clothing-fashion updates. Specifically, a classification-based model is
proposed to quantify the influence of different visual stimuli, in which each
visual stimulus's influence is quantified by its corresponding accuracy in
fashion classification. Experimental results demonstrate that, on
clothing-fashion updates, the style holds a higher influence than the color,
and the color holds a higher influence than the texture.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07454</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fine Hand Segmentation using Convolutional Neural Networks</dc:title>
 <dc:creator>Vodopivec, Tadej</dc:creator>
 <dc:creator>Lepetit, Vincent</dc:creator>
 <dc:creator>Peer, Peter</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a method for extracting very accurate masks of hands in egocentric
views. Our method is based on a novel Deep Learning architecture: In contrast
with current Deep Learning methods, we do not use upscaling layers applied to a
low-dimensional representation of the input image. Instead, we extract features
with convolutional layers and map them directly to a segmentation mask with a
fully connected layer. We show that this approach, when applied in a
multi-scale fashion, is both accurate and efficient enough for real-time. We
demonstrate it on a new dataset made of images captured in various
environments, from the outdoors to offices.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07454</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07468</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On pairwise comparisons with values in a group: algebraic structures</dc:title>
 <dc:creator>Magnot, Jean-Pierre</dc:creator>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>03F25</dc:subject>
 <dc:description>  We describe the algebraic properties of pairwise comparisons matrices with
coefficients in an arbitrary group. We provide a vocabulary adapted for the
description of main algebaric properties of inconsistency maps, describe an
example where the use of a non abelian group is necessary, and decribe a
generalization of pairwise comparisons matrices and inconsistency maps on a
graph.
</dc:description>
 <dc:date>2016-08-25</dc:date>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07468</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07470</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fast Ellipse Detector Using Projective Invariant Pruning</dc:title>
 <dc:creator>Jia, Qi</dc:creator>
 <dc:creator>Fan, Xin</dc:creator>
 <dc:creator>Luo, Zhongxuan</dc:creator>
 <dc:creator>Song, Lianbo</dc:creator>
 <dc:creator>Qiu, Tie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>I.4.6</dc:subject>
 <dc:subject>I.4.8</dc:subject>
 <dc:description>  Detecting elliptical objects from an image is a central task in robot
navigation and industrial diagnosis where the detection time is always a
critical issue. Existing methods are hardly applicable to these real-time
scenarios of limited hardware resource due to the huge number of fragment
candidates (edges or arcs) for fitting ellipse equations. In this paper, we
present a fast algorithm detecting ellipses with high accuracy. The algorithm
leverage a newly developed projective invariant to significantly prune the
undesired candidates and to pick out elliptical ones. The invariant is able to
reflect the intrinsic geometry of a planar curve, giving the value of -1 on any
three collinear points and +1 for any six points on an ellipse. Thus, we apply
the pruning and picking by simply comparing these binary values. Moreover, the
calculation of the invariant only involves the determinant of a 3*3 matrix.
Extensive experiments on three challenging data sets with 650 images
demonstrate that our detector runs 20%-50% faster than the state-of-the-art
algorithms with the comparable or higher precision.
</dc:description>
 <dc:description>Comment: 14 pages, 34 figures, journal</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07470</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2017.2704660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07481</identifier>
 <datestamp>2016-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uncovering Influence Cookbooks : Reverse Engineering the Topological
  Impact in Peer Ranking Services</dc:title>
 <dc:creator>Merrer, Erwan Le</dc:creator>
 <dc:creator>Tr&#xe9;dan, Gilles</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Ensuring the early detection of important social network users is a
challenging task. Some peer ranking services are now well established, such as
PeerIndex, Klout, or Kred. Their function is to rank users according to their
influence. This notion of influence is however abstract, and the algorithms
achieving this ranking are opaque. Following the rising demand for a more
transparent web, we explore the problem of gaining knowledge by reverse
engineering such peer ranking services, with regards to the social network
topology they get as an input. Since these services exploit the online activity
of users (and therefore their connectivity in social networks), we provide a
precise evaluation of how topological metrics of the social network impact the
final user ranking. Our approach is the following : we first model the ranking
service as a black-box with which we interact by creating user profiles and by
performing operations on them. Through those profiles, we trigger some slight
topological modifications. By monitoring the impact of these modifications on
the rankings of those profiles, we infer the weight of each topological metric
in the black-box, thus reversing the service influence cookbook.
</dc:description>
 <dc:description>Comment: To appear in CSCW 2017 (The 20th ACM Conference on Computer-Supported
  Cooperative Work and Social Computing)</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:date>2016-10-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07485</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When to use 3D Die-Stacked Memory for Bandwidth-Constrained Big Data
  Workloads</dc:title>
 <dc:creator>Lowe-Power, Jason</dc:creator>
 <dc:creator>Hill, Mark D.</dc:creator>
 <dc:creator>Wood, David A.</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Response time requirements for big data processing systems are shrinking. To
meet this strict response time requirement, many big data systems store all or
most of their data in main memory to reduce the access latency. Main memory
capacities have grown, and systems with 2 TB of main memory capacity available
today. However, the rate at which processors can access this data--the memory
bandwidth--has not grown at the same rate. In fact, some of these big-memory
systems can access less than 10% of their main memory capacity in one second
(billions of processor cycles).
  3D die-stacking is one promising solution to this bandwidth problem, and
industry is investing significantly in 3D die-stacking. We use a simple
back-of-the-envelope-style model to characterize if and when the 3D die-stacked
architecture is more cost-effective than current architectures for in-memory
big data workloads. We find that die-stacking has much higher performance than
current systems (up to 256x lower response times), and it does not require
expensive memory over provisioning to meet real-time (10 ms) response time
service-level agreements. However, the power requirements of the die-stacked
systems are significantly higher (up to 50x) than current systems, and its
memory capacity is lower in many cases. Even in this limited case study, we
find 3D die-stacking is not a panacea. Today, die-stacking is the most
cost-effective solution for strict SLAs and by reducing the power of the
compute chip and increasing memory densities die-stacking can be cost-effective
under other constraints in the future.
</dc:description>
 <dc:description>Comment: Originally presented The Seventh workshop on Big Data Benchmarks,
  Performance Optimization, and Emerging Hardware (BPOE-7).
  http://www.bafst.com/events/asplos16/bpoe7/</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07485</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07486</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A $2n^2-log(n)-1$ lower bound for the border rank of matrix
  multiplication</dc:title>
 <dc:creator>Landsberg, J. M.</dc:creator>
 <dc:creator>Micha&#x142;ek, Mateusz</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>68Q17, 14L30, 15A69</dc:subject>
 <dc:description>  Let M_n denote the matrix multiplication tensor for nxn matrices. We use the
border substitution method combined with Koszul flattenings to prove the border
rank lower bound of 2n^2-log(n)-1 for M_n.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07486</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07492</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mechanism Design Approach for Energy Efficiency</dc:title>
 <dc:creator>Bistarelli, Stefano</dc:creator>
 <dc:creator>Culmone, Rosario</dc:creator>
 <dc:creator>Giuliodori, Paolo</dc:creator>
 <dc:creator>Mugnoz, Stefano</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In this work we deploy a mechanism design approach for allocating a divisible
commodity (electricity in our example) among consumers. We consider each
consumer with an associated personal valuation function of the energy resource
during a certain time interval. We aim to select the optimal consumption
profile for every user avoiding consumption peaks when the total required
energy could exceed the energy production. The mechanism will be able to drive
users in shifting energy consumptions in different hours of the day. We start
by presenting a very basic Vickrey-Clarke-Groves mechanism, we discuss its
weakness and propose several more complex variants.
</dc:description>
 <dc:description>Comment: Techical report</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07502</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entity Embedding-based Anomaly Detection for Heterogeneous Categorical
  Events</dc:title>
 <dc:creator>Chen, Ting</dc:creator>
 <dc:creator>Tang, Lu-An</dc:creator>
 <dc:creator>Sun, Yizhou</dc:creator>
 <dc:creator>Chen, Zhengzhang</dc:creator>
 <dc:creator>Zhang, Kai</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Anomaly detection plays an important role in modern data-driven security
applications, such as detecting suspicious access to a socket from a process.
In many cases, such events can be described as a collection of categorical
values that are considered as entities of different types, which we call
heterogeneous categorical events. Due to the lack of intrinsic distance
measures among entities, and the exponentially large event space, most existing
work relies heavily on heuristics to calculate abnormal scores for events.
Different from previous work, we propose a principled and unified probabilistic
model APE (Anomaly detection via Probabilistic pairwise interaction and Entity
embedding) that directly models the likelihood of events. In this model, we
embed entities into a common latent space using their observed co-occurrence in
different events. More specifically, we first model the compatibility of each
pair of entities according to their embeddings. Then we utilize the weighted
pairwise interactions of different entity types to define the event
probability. Using Noise-Contrastive Estimation with &quot;context-dependent&quot; noise
distribution, our model can be learned efficiently regardless of the large
event space. Experimental results on real enterprise surveillance data show
that our methods can accurately detect abnormal events compared to other
state-of-the-art abnormal detection techniques.
</dc:description>
 <dc:description>Comment: Published as a conference paper in IJCAI'16</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07502</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07505</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on the Practicality of Maximal Planar Subgraph Algorithms</dc:title>
 <dc:creator>Chimani, Markus</dc:creator>
 <dc:creator>Klein, Karsten</dc:creator>
 <dc:creator>Wiedera, Tilo</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Given a graph $G$, the NP-hard Maximum Planar Subgraph problem (MPS) asks for
a planar subgraph of $G$ with the maximum number of edges. There are several
heuristic, approximative, and exact algorithms to tackle the problem, but---to
the best of our knowledge---they have never been compared competitively in
practice. We report on an exploratory study on the relative merits of the
diverse approaches, focusing on practical runtime, solution quality, and
implementation complexity. Surprisingly, a seemingly only theoretically strong
approximation forms the building block of the strongest choice.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07505</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07514</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The logical strength of B\&quot;uchi's decidability theorem</dc:title>
 <dc:creator>Ko&#x142;odziejczyk, Leszek</dc:creator>
 <dc:creator>Michalewski, Henryk</dc:creator>
 <dc:creator>Pradic, Pierre</dc:creator>
 <dc:creator>Skrzypczak, Micha&#x142;</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  We study the strength of axioms needed to prove various results related to
automata on infinite words and B\&quot;uchi's theorem on the decidability of the MSO
theory of $(N, {\le})$. We prove that the following are equivalent over the
weak second-order arithmetic theory $RCA_0$:
  - B\&quot;uchi's complementation theorem for nondeterministic automata on infinite
words,
  - the decidability of the depth-$n$ fragment of the MSO theory of $(N,
{\le})$, for each $n \ge 5$,
  - the induction scheme for $\Sigma^0_2$ formulae of arithmetic.
  Moreover, each of (1)-(3) is equivalent to the additive version of Ramsey's
Theorem for pairs, often used in proofs of (1); each of (1)-(3) implies
McNaughton's determinisation theorem for automata on infinite words; and each
of (1)-(3) implies the &quot;bounded-width&quot; version of K\&quot;onig's Lemma, often used
in proofs of McNaughton's theorem.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07514</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07518</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimizing Outage Probability by Exploiting CSI in Wireless Powered
  Cooperative Networks</dc:title>
 <dc:creator>Butt, M. Majid</dc:creator>
 <dc:creator>Krikidis, Ioannis</dc:creator>
 <dc:creator>Marchetti, Nicola</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this work, we address the relay selection problem for the wireless powered
communication networks, where the relays harvest energy from the source radio
frequency signals. A single source-destination pair is considered without a
direct link. The connecting relay nodes are equipped with storage batteries of
infinite size. We assume that the channel state information (CSI) on the
source-relay link is available at the relay nodes. Depending on the
availability of the CSI on the relay-destination link at the relay node, we
propose different relay selection schemes and evaluate the outage probability.
The availability of the CSI at the relay node on the relay-destination link
considerably improves the performance due to additional flexibility in the
relay selection mechanism. We numerically quantify the performance for the
proposed schemes and compare the outage probability for fixed and equal number
of wireless powered forwarding relays.
</dc:description>
 <dc:description>Comment: accepted in IEEE Globecom 2016</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07518</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07531</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Syntax and semantics of the weak consistency model specification
  language cat</dc:title>
 <dc:creator>Alglave, Jade</dc:creator>
 <dc:creator>Cousot, Patrick</dc:creator>
 <dc:creator>Maranget, Luc</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We provide the syntax and semantics of the cat language, a domain specific
language to describe consistency properties of parallel/distributed programs.
The language is implemented in the herd7 too
(http://diy.inria.fr/doc/herd.html)l.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07531</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07533</identifier>
 <datestamp>2016-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-Optimal Sensor Scheduling for Batch State Estimation: Complexity,
  Algorithms, and Limits</dc:title>
 <dc:creator>Tzoumas, Vasileios</dc:creator>
 <dc:creator>Jadbabaie, Ali</dc:creator>
 <dc:creator>Pappas, George J.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  In this paper, we focus on batch state estimation for linear systems. This
problem is important in applications such as environmental field estimation,
robotic navigation, and target tracking. Its difficulty lies on that limited
operational resources among the sensors, e.g., shared communication bandwidth
or battery power, constrain the number of sensors that can be active at each
measurement step. As a result, sensor scheduling algorithms must be employed.
Notwithstanding, current sensor scheduling algorithms for batch state
estimation scale poorly with the system size and the time horizon. In addition,
current sensor scheduling algorithms for Kalman filtering, although they scale
better, provide no performance guarantees or approximation bounds for the
minimization of the batch state estimation error. In this paper, one of our
main contributions is to provide an algorithm that enjoys both the estimation
accuracy of the batch state scheduling algorithms and the low time complexity
of the Kalman filtering scheduling algorithms. In particular: 1) our algorithm
is near-optimal: it achieves a solution up to a multiplicative factor 1/2 from
the optimal solution, and this factor is close to the best approximation factor
1/e one can achieve in polynomial time for this problem; 2) our algorithm has
(polynomial) time complexity that is not only lower than that of the current
algorithms for batch state estimation; it is also lower than, or similar to,
that of the current algorithms for Kalman filtering. We achieve these results
by proving two properties for our batch state estimation error metric, which
quantifies the square error of the minimum variance linear estimator of the
batch state vector: a) it is supermodular in the choice of the sensors; b) it
has a sparsity pattern (it involves matrices that are block tri-diagonal) that
facilitates its evaluation at each sensor set.
</dc:description>
 <dc:description>Comment: Correction of typos in proofs</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:date>2016-09-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07533</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07536</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging over intact priors for boosting control and dexterity of
  prosthetic hands by amputees</dc:title>
 <dc:creator>Gregori, Valentina</dc:creator>
 <dc:creator>Caputo, Barbara</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Non-invasive myoelectric prostheses require a long training time to obtain
satisfactory control dexterity. These training times could possibly be reduced
by leveraging over training efforts by previous subjects. So-called domain
adaptation algorithms formalize this strategy and have indeed been shown to
significantly reduce the amount of required training data for intact subjects
for myoelectric movements classification. It is not clear, however, whether
these results extend also to amputees and, if so, whether prior information
from amputees and intact subjects is equally useful. To overcome this problem,
we evaluated several domain adaptation algorithms on data coming from both
amputees and intact subjects. Our findings indicate that: (1) the use of
previous experience from other subjects allows us to reduce the training time
by about an order of magnitude; (2) this improvement holds regardless of
whether an amputee exploits previous information from other amputees or from
intact subjects.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07547</identifier>
 <datestamp>2017-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TriCheck: Memory Model Verification at the Trisection of Software,
  Hardware, and ISA</dc:title>
 <dc:creator>Trippel, Caroline</dc:creator>
 <dc:creator>Manerkar, Yatin A.</dc:creator>
 <dc:creator>Lustig, Daniel</dc:creator>
 <dc:creator>Pellauer, Michael</dc:creator>
 <dc:creator>Martonosi, Margaret</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Memory consistency models (MCMs) which govern inter-module interactions in a
shared memory system, are a significant, yet often under-appreciated, aspect of
system design. MCMs are defined at the various layers of the hardware-software
stack, requiring thoroughly verified specifications, compilers, and
implementations at the interfaces between layers. Current verification
techniques evaluate segments of the system stack in isolation, such as proving
compiler mappings from a high-level language (HLL) to an ISA or proving
validity of a microarchitectural implementation of an ISA.
  This paper makes a case for full-stack MCM verification and provides a
toolflow, TriCheck, capable of verifying that the HLL, compiler, ISA, and
implementation collectively uphold MCM requirements. The work showcases
TriCheck's ability to evaluate a proposed ISA MCM in order to ensure that each
layer and each mapping is correct and complete. Specifically, we apply TriCheck
to the open source RISC-V ISA, seeking to verify accurate, efficient, and legal
compilations from C11. We uncover under-specifications and potential
inefficiencies in the current RISC-V ISA documentation and identify possible
solutions for each. As an example, we find that a RISC-V-compliant
microarchitecture allows 144 outcomes forbidden by C11 to be observed out of
1,701 litmus tests examined. Overall, this paper demonstrates the necessity of
full-stack verification for detecting MCM-related bugs in the hardware-software
stack.
</dc:description>
 <dc:description>Comment: Proceedings of the Twenty-Second International Conference on
  Architectural Support for Programming Languages and Operating Systems</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:date>2017-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07547</dc:identifier>
 <dc:identifier>doi:10.1145/3037697.3037719</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07564</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>#P- and $\oplus$P- completeness of counting roots of a sparse polynomial</dc:title>
 <dc:creator>Milovanov, Alexey</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We improve and simplify the result of the part 4 of &quot;Counting curves and
their projections&quot; (Joachim von zur Gathen, Marek Karpinski, Igor Shparlinski)
by showing that counting roots of a sparse polynomial over $\mathbb{F}_{2^n}$
is #P- and $\oplus$P-complete under deterministic reductions.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2016-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07568</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graphic TSP in cubic graphs</dc:title>
 <dc:creator>Dvorak, Zdenek</dc:creator>
 <dc:creator>Kral, Daniel</dc:creator>
 <dc:creator>Mohar, Bojan</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We present a polynomial-time 9/7-approximation algorithm for the graphic TSP
for cubic graphs, which improves the previously best approximation factor of
1.3 for 2-connected cubic graphs and drops the requirement of 2-connectivity at
the same time. To design our algorithm, we prove that every simple 2-connected
cubic n-vertex graph contains a spanning closed walk of length at most 9n/7-1,
and that such a walk can be found in polynomial time.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:date>2016-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07568</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07573</identifier>
 <datestamp>2017-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Containers for portable, productive and performant scientific computing</dc:title>
 <dc:creator>Hale, Jack S.</dc:creator>
 <dc:creator>Li, Lizao</dc:creator>
 <dc:creator>Richardson, Chris N.</dc:creator>
 <dc:creator>Wells, Garth N.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>68N99, 68U0</dc:subject>
 <dc:subject>D.2.7</dc:subject>
 <dc:subject>D.2.8</dc:subject>
 <dc:subject>D.2.9</dc:subject>
 <dc:description>  Containers are an emerging technology that hold promise for improving
productivity and code portability in scientific computing. We examine Linux
container technology for the distribution of a non-trivial scientific computing
software stack and its execution on a spectrum of platforms from laptop
computers through to high performance computing (HPC) systems. We show on a
workstation and a leadership-class HPC system that when deployed appropriately
there are no performance penalties running scientific programs inside
containers. For Python code run on large parallel computers, the run time is
reduced inside a container due to faster library imports. The software
distribution approach and data that we present will help developers and users
decide on whether container technology is appropriate for them. We also provide
guidance for the vendors of HPC systems that rely on proprietary libraries for
performance on what they can do to make containers work seamlessly and without
performance penalty.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07573</dc:identifier>
 <dc:identifier>doi:10.1109/MCSE.2017.2421459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07575</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strategic play in stable marriage problem</dc:title>
 <dc:creator>Digulescu, Mircea Adrian</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The stable marriage problem, as addressed by Gale and Shapely [1] consists of
providing a bipartite matching between n &quot; boys &quot; and n &quot; girls &quot;-each of whom
have a totally ordered preference list over the other set-such that there
exists no &quot; boy &quot; and no &quot; girl &quot; that would prefer each other over their
partner in the matching. In this paper, we analyze the cases of strategic play
by the &quot; boys &quot; in the game directly inspired by this problem. We provide an
O(n^3) algorithm for determining a matching which is not necessarily stable in
the Gale-Shapely sense, but it is coalition-stable, in that no player has a
selfish interest to leave the resulting grand coalition to join any potential
alternative one which might feasibly form, and is also man-optimal. Thus, under
a realistic assumption set, no player has an interest to &quot; destabilize &quot; the
matching, even though he theoretically could. The resulting matching is often
better than the na\&quot;ive Gale-Shapely one for some (not all) of the &quot; boys &quot; ,
being no worse for the rest. This matching is more realistic (stable) than the
one produced by top-trading-cycles method, thus offering a qualitative
improvement over the latter. Furthermore, we analyze the situation when players
are allowed to make strategic threats (i.e. be willing to sacrifice their own
outcome to hurt others), offer a relevant example to illustrate the benefits of
this form of play, and ultimately provide an exponential time algorithm which
tries to determine a good threat-making strategy. We then briefly examine a few
other non-conventional possibilities a player has to affect his outcome. Most
common variations to the game model are also described and analyzed with regard
to applicability of the methods in this paper. Finally, a few examples of
real-life problems which can be modeled and solved with the methods in this
paper are presented.
</dc:description>
 <dc:description>Comment: 89 pages, 8 sections. Main result in Section 3. Other results in
  other sections</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07575</dc:identifier>
 <dc:identifier>doi:10.13140/RG.2.2.20331.75041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07596</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An algorithm for dividing two complex numbers</dc:title>
 <dc:creator>Cariow, Aleksandr</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>15A23, 65Y20, 65F30</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>G.1.0</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:description>  In this work a rationalized algorithm for calculating the quotient of two
complex numbers is presented which reduces the number of underlying real
multiplications. The performing of a complex number division using the naive
method takes 4 multiplications, 3 additions, 2 squarings and 2 divisions of
real numbers while the proposed algorithm can compute the same result in only 3
multiplications ( or multipliers in hardware implementation case), 6 additions,
2 squarings and 2 divisions of real numbers.
</dc:description>
 <dc:description>Comment: 4 pages, 1 figure</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07605</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Clustering and Community Detection with Imbalanced Clusters</dc:title>
 <dc:creator>Aksoylar, Cem</dc:creator>
 <dc:creator>Qian, Jing</dc:creator>
 <dc:creator>Saligrama, Venkatesh</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Spectral clustering methods which are frequently used in clustering and
community detection applications are sensitive to the specific graph
constructions particularly when imbalanced clusters are present. We show that
ratio cut (RCut) or normalized cut (NCut) objectives are not tailored to
imbalanced cluster sizes since they tend to emphasize cut sizes over cut
values. We propose a graph partitioning problem that seeks minimum cut
partitions under minimum size constraints on partitions to deal with imbalanced
cluster sizes. Our approach parameterizes a family of graphs by adaptively
modulating node degrees on a fixed node set, yielding a set of parameter
dependent cuts reflecting varying levels of imbalance. The solution to our
problem is then obtained by optimizing over these parameters. We present
rigorous limit cut analysis results to justify our approach and demonstrate the
superiority of our method through experiments on synthetic and real datasets
for data clustering, semi-supervised learning and community detection.
</dc:description>
 <dc:description>Comment: Extended version of arXiv:1309.2303 with new applications. Accepted
  to IEEE TSIPN</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07605</dc:identifier>
 <dc:identifier>doi:10.1109/TSIPN.2016.2601022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07616</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mitosis Detection in Intestinal Crypt Images with Hough Forest and
  Conditional Random Fields</dc:title>
 <dc:creator>Bortsova, Gerda</dc:creator>
 <dc:creator>Sterr, Michael</dc:creator>
 <dc:creator>Wang, Lichao</dc:creator>
 <dc:creator>Milletari, Fausto</dc:creator>
 <dc:creator>Navab, Nassir</dc:creator>
 <dc:creator>B&#xf6;ttcher, Anika</dc:creator>
 <dc:creator>Lickert, Heiko</dc:creator>
 <dc:creator>Theis, Fabian</dc:creator>
 <dc:creator>Peng, Tingying</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Intestinal enteroendocrine cells secrete hormones that are vital for the
regulation of glucose metabolism but their differentiation from intestinal stem
cells is not fully understood. Asymmetric stem cell divisions have been linked
to intestinal stem cell homeostasis and secretory fate commitment. We monitored
cell divisions using 4D live cell imaging of cultured intestinal crypts to
characterize division modes by means of measurable features such as orientation
or shape. A statistical analysis of these measurements requires annotation of
mitosis events, which is currently a tedious and time-consuming task that has
to be performed manually. To assist data processing, we developed a learning
based method to automatically detect mitosis events. The method contains a
dual-phase framework for joint detection of dividing cells (mothers) and their
progeny (daughters). In the first phase we detect mother and daughters
independently using Hough Forest whilst in the second phase we associate mother
and daughters by modelling their joint probability as Conditional Random Field
(CRF). The method has been evaluated on 32 movies and has achieved an AUC of
72%, which can be used in conjunction with manual correction and dramatically
speed up the processing pipeline.
</dc:description>
 <dc:description>Comment: Accepted at the 7th International Conference on Machine Learning in
  Medical Imaging</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07616</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07617</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;Sampling&quot;' as a Baseline Optimizer for Search-based Software
  Engineering</dc:title>
 <dc:creator>Chen, Jianfeng</dc:creator>
 <dc:creator>Nair, Vivek</dc:creator>
 <dc:creator>Krishna, Rahul</dc:creator>
 <dc:creator>Menzies, Tim</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Increasingly, Software Engineering (SE) researchers use search-based
optimization techniques to solve SE problems with multiple conflicting
objectives. These techniques often apply CPU-intensive evolutionary algorithms
to explore generations of mutations to a population of candidate solutions. An
alternative approach, proposed in this paper, is to start with a very large
population and sample down to just the better solutions. We call this method
&quot;SWAY&quot;, short for &quot;the sampling way&quot;. Sway is very simple to implement and, in
studies with various software engineering models, this sampling approach was
found to be competitive with corresponding state-of-the-art evolutionary
algorithms while requiring far less computation cost. Considering the
simplicity and effectiveness of Sway, we, therefore, propose this approach as a
baseline method for search-based software engineering models, especially for
models that are very slow to execute.
</dc:description>
 <dc:description>Comment: 15 pages, 11 figures, 4 tables. To appear, IEEE Trans Software
  Engineering 2018</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:date>2018-01-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07617</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07619</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interacting with Massive Behavioral Data</dc:title>
 <dc:creator>Su, Shih-Chieh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this short paper, we propose the split-diffuse (SD) algorithm that takes
the output of an existing word embedding algorithm, and distributes the data
points uniformly across the visualization space. The result improves the
perceivability and the interactability by the human.
  We apply the SD algorithm to analyze the user behavior through access logs
within the cyber security domain. The result, named the topic grids, is a set
of grids on various topics generated from the logs. On the same set of grids,
different behavioral metrics can be shown on different targets over different
periods of time, to provide visualization and interaction to the human experts.
  Analysis, investigation, and other types of interaction can be performed on
the topic grids more efficiently than on the output of existing dimension
reduction methods. In addition to the cyber security domain, the topic grids
can be further applied to other domains like e-commerce, credit card
transaction, customer service to analyze the behavior in a large scale.
</dc:description>
 <dc:description>Comment: KDD 2016 Workshop on Interactive Data Exploration and Analytics</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07623</identifier>
 <datestamp>2016-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A dynamic system characterization of road network node models</dc:title>
 <dc:creator>Wright, Matthew A.</dc:creator>
 <dc:creator>Horowitz, Roberto</dc:creator>
 <dc:creator>Kurzhanskiy, Alex A.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The propagation of traffic congestion along roads is a commonplace nonlinear
phenomenon. When many roads are connected in a network, congestion can spill
from one road to others as drivers queue to enter a congested road, creating
further nonlinearities in the network dynamics. This paper considers the node
model problem, which refers to methods for solving for cross-flows when roads
meet at a junction. We present a simple hybrid dynamic system that, given a
macroscopic snapshot of the roads entering and exiting a node, intuitively
models the node's throughflows over time. This dynamic system produces
solutions to the node model problem that are equal to those produced by many
popular node models without intuitive physical meanings. We also show how the
earlier node models can be rederived as executions of our dynamic system. The
intuitive physical description supplied by our system provides a base for
control of the road junction system dynamics, as well as the emergent network
dynamics.
</dc:description>
 <dc:description>Comment: Appeared at NOLCOS 2016, 10th IFAC Symposium on Nonlinear Control
  Systems</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07623</dc:identifier>
 <dc:identifier>doi:10.1016/j.ifacol.2016.10.307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07625</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large Scale Behavioral Analytics via Topical Interaction</dc:title>
 <dc:creator>Su, Shih-Chieh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose the split-diffuse (SD) algorithm that takes the output of an
existing dimension reduction algorithm, and distributes the data points
uniformly across the visualization space. The result, called the topic grids,
is a set of grids on various topics which are generated from the free-form text
content of any domain of interest. The topic grids efficiently utilizes the
visualization space to provide visual summaries for massive data. Topical
analysis, comparison and interaction can be performed on the topic grids in a
more perceivable way.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07625</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07630</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global analysis of Expectation Maximization for mixtures of two
  Gaussians</dc:title>
 <dc:creator>Xu, Ji</dc:creator>
 <dc:creator>Hsu, Daniel</dc:creator>
 <dc:creator>Maleki, Arian</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Expectation Maximization (EM) is among the most popular algorithms for
estimating parameters of statistical models. However, EM, which is an iterative
algorithm based on the maximum likelihood principle, is generally only
guaranteed to find stationary points of the likelihood objective, and these
points may be far from any maximizer. This article addresses this disconnect
between the statistical principles behind EM and its algorithmic properties.
Specifically, it provides a global analysis of EM for specific models in which
the observations comprise an i.i.d. sample from a mixture of two Gaussians.
This is achieved by (i) studying the sequence of parameters from idealized
execution of EM in the infinite sample limit, and fully characterizing the
limit points of the sequence in terms of the initial parameters; and then (ii)
based on this convergence analysis, establishing statistical consistency (or
lack thereof) for the actual sequence of parameters produced by EM.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07630</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07632</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resource Allocation for Machine-to-Machine Communications with Unmanned
  Aerial Vehicles</dc:title>
 <dc:creator>Soorki, Mehdi Naderi</dc:creator>
 <dc:creator>Mozaffari, Mohammad</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Manshaei, Mohammad Hossein</dc:creator>
 <dc:creator>Saidi, Hossein</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, a novel framework for power-efficient, cluster-based
machine-to-machine (M2M) communications is proposed. In the studied model, a
number of unmanned aerial vehicles (UAVs) are used as aerial base stations to
collect data from the cluster heads (CHs) of a set of M2M clusters. To minimize
the CHs' transmit power while satisfying the rate requirements of M2M devices,
an optimal scheduling and resource allocation mechanism for CH-UAV
communications is proposed. First, using the queue rate stability concept, the
minimum number of UAVs as well as the dwelling time that each UAV must spend
for servicing the CHs are computed. Next, the optimal resource allocation for
the CH-UAV communication links is determined such that M2M devices rate
requirements are satisfied with a minimum transmit power. Simulation results
show that, as the packet transmission probability of machines increases, the
minimum number of UAVs required to guarantee the queue rate stability of CHs
will also significantly increase. Our results also show that, compared to a
case with pre-deployed terrestrial base stations, the average transmit power of
CHs will decrease by 68% when UAVs are used.
</dc:description>
 <dc:description>Comment: Accepted in IEEE GLOBECOM Workshop</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07632</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07634</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Guaranteed Approximation Algorithm for Minimum $k$-Connected
  $m$-Fold Dominating Set</dc:title>
 <dc:creator>Zhang, Zhao</dc:creator>
 <dc:creator>Zhou, Jiao</dc:creator>
 <dc:creator>Huang, Xiaohui</dc:creator>
 <dc:creator>Du, Ding-Zhu</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C85, 68W25</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  To achieve an efficient routing in a wireless sensor network, connected
dominating set (CDS) is used as virtual backbone. A fault-tolerant virtual
backbone can be modeled as a $(k,m)$-CDS. For a connected graph $G=(V,E)$ and
two fixed integers $k$ and $m$, a node set $C\subseteq V$ is a $(k,m)$-CDS of
$G$ if every node in $V\setminus C$ has at least $m$ neighbors in $C$, and the
subgraph of $G$ induced by $C$ is $k$-connected. Previous to this work,
approximation algorithms with guaranteed performance ratio in a general graph
were know only for $k\leq 3$. This paper makes a significant progress by
presenting a $(2k-1)\alpha_0$ approximation algorithm for general $k$ and $m$
with $m\geq k$, where $\alpha_0$ is the performance ratio for the minimum CDS
problem. Using currently best known ratio for $\alpha_0$, our algorithm has
performance ratio $O(\ln\Delta)$, where $\Delta$ is the maximum degree of the
graph.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07634</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07636</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Temporal Dependence from Time-Series Data with Latent Variables</dc:title>
 <dc:creator>Hosseini, Hossein</dc:creator>
 <dc:creator>Kannan, Sreeram</dc:creator>
 <dc:creator>Zhang, Baosen</dc:creator>
 <dc:creator>Poovendran, Radha</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the setting where a collection of time series, modeled as random
processes, evolve in a causal manner, and one is interested in learning the
graph governing the relationships of these processes. A special case of wide
interest and applicability is the setting where the noise is Gaussian and
relationships are Markov and linear. We study this setting with two additional
features: firstly, each random process has a hidden (latent) state, which we
use to model the internal memory possessed by the variables (similar to hidden
Markov models). Secondly, each variable can depend on its latent memory state
through a random lag (rather than a fixed lag), thus modeling memory recall
with differing lags at distinct times. Under this setting, we develop an
estimator and prove that under a genericity assumption, the parameters of the
model can be learned consistently. We also propose a practical adaption of this
estimator, which demonstrates significant performance gains in both synthetic
and real-world datasets.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07637</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Class Invariants: Concepts, Problems, Solutions</dc:title>
 <dc:creator>Meyer, Bertrand</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Class invariants are both a core concept of object-oriented programming and
the source of the two key open OO verification problems: furtive access (from
callbacks) and reference leak. Existing approaches force on programmers an
unacceptable annotation burden. This article explains invariants and solves
both problems modularly through the O-rule, defining fundamental OO semantics,
and the inhibition rule, using information hiding to remove harmful reference
leaks. It also introduces the concept of &quot;object tribe&quot; as a basis for other
possible approaches.
  For all readers: this article is long because it includes a tutorial, covers
many examples and dispels misconceptions. To understand the key ideas and
results, however, the first two pages suffice.
  For non-experts in verification: all concepts are explained; anyone with a
basic understanding of object-oriented programming can understand the
discussion.
  For experts: the main limitation of this work is that it is a paper proposal
(no soundness proof, no implementation). It addresses, however, the known
problems with class invariants, solving such examples as linked lists and
Observer, through a simple theory and without any of the following: ownership;
separation logic; universe types; object wrapping and unwrapping; semantic
collaboration, observer specifications; history invariants; &quot;inc&quot; and &quot;coop&quot;
constructs; friendship construct; non-modular reasoning. More generally, it
involves no new language construct and no new programmer annotations.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07637</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07639</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to generalize to new compositions in image understanding</dc:title>
 <dc:creator>Atzmon, Yuval</dc:creator>
 <dc:creator>Berant, Jonathan</dc:creator>
 <dc:creator>Kezami, Vahid</dc:creator>
 <dc:creator>Globerson, Amir</dc:creator>
 <dc:creator>Chechik, Gal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recurrent neural networks have recently been used for learning to describe
images using natural language. However, it has been observed that these models
generalize poorly to scenes that were not observed during training, possibly
depending too strongly on the statistics of the text in the training data. Here
we propose to describe images using short structured representations, aiming to
capture the crux of a description. These structured representations allow us to
tease-out and evaluate separately two types of generalization: standard
generalization to new images with similar scenes, and generalization to new
combinations of known entities. We compare two learning approaches on the
MS-COCO dataset: a state-of-the-art recurrent network based on an LSTM (Show,
Attend and Tell), and a simple structured prediction model on top of a deep
network. We find that the structured model generalizes to new compositions
substantially better than the LSTM, ~7 times the accuracy of predicting
structured representations. By providing a concrete method to quantify
generalization for unseen combinations, we argue that structured
representations and compositional splits are a useful benchmark for image
captioning, and advocate compositional models that capture linguistic and
visual structure.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07641</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Batched Stochastic Gradient Descent with Weighted Sampling</dc:title>
 <dc:creator>Needell, Deanna</dc:creator>
 <dc:creator>Ward, Rachel</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>65B99, 52A99, 60G99, 62L20</dc:subject>
 <dc:description>  We analyze a batched variant of Stochastic Gradient Descent (SGD) with
weighted sampling distribution for smooth and non-smooth objective functions.
We show that by distributing the batches computationally, a significant speedup
in the convergence rate is provably possible compared to either batched
sampling or weighted sampling alone. We propose several computationally
efficient schemes to approximate the optimal weights, and compute proposed
sampling distributions explicitly for the least squares and hinge loss
problems. We show both analytically and experimentally that substantial gains
can be obtained.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07647</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Elementary polytopes with high lift-and-project ranks for strong
  positive semidefinite operators</dc:title>
 <dc:creator>Au, Yu Hin</dc:creator>
 <dc:creator>Tun&#xe7;el, Levent</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We consider operators acting on convex subsets of the unit hypercube. These
operators are used in constructing convex relaxations of combinatorial
optimization problems presented as a 0,1 integer programming problem or a 0,1
polynomial optimization problem. Our focus is mostly on operators that, when
expressed as a lift-and-project operator, involve the use of semidefiniteness
constraints in the lifted space, including operators due to Lasserre and
variants of the Sherali--Adams and Bienstock--Zuckerberg operators. We study
the performance of these semidefinite-optimization-based lift-and-project
operators on some elementary polytopes --- hypercubes that are chipped (at
least one vertex of the hypercube removed by intersection with a closed
halfspace) or cropped (all $2^n$ vertices of the hypercube removed by
intersection with $2^n$ closed halfspaces) to varying degrees of severity
$\rho$. We prove bounds on $\rho$ where these operators would perform badly on
the aforementioned examples. We also show that the integrality gap of the
chipped hypercube is invariant under the application of several
lift-and-project operators of varying strengths.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07647</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07652</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Testing Unateness of Real-Valued Functions</dc:title>
 <dc:creator>Baleshzar, Roksana</dc:creator>
 <dc:creator>Murzabulatov, Meiram</dc:creator>
 <dc:creator>Pallavoor, Ramesh Krishnan S.</dc:creator>
 <dc:creator>Raskhodnikova, Sofya</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We give a unateness tester for functions of the form $f:[n]^d\rightarrow R$,
where $n,d\in \mathbb{N}$ and $R\subseteq \mathbb{R}$ with query complexity
$O(\frac{d\log (\max(d,n))}{\epsilon})$. Previously known unateness testers
work only for Boolean functions over the domain $\{0,1\}^d$. We show that every
unateness tester for real-valued functions over hypergrid has query complexity
$\Omega(\min\{d, |R|^2\})$. Consequently, our tester is nearly optimal for
real-valued functions over $\{0,1\}^d$. We also prove that every nonadaptive,
1-sided error unateness tester for Boolean functions needs
$\Omega(\sqrt{d}/\epsilon)$ queries. Previously, no lower bounds for testing
unateness were known.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07658</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TopoMan: Global Network Visibility in the Presence of Middleboxes (A
  Graybox Approach)</dc:title>
 <dc:creator>Nagendra, Vasudevan</dc:creator>
 <dc:creator>Patil, Shubhada</dc:creator>
 <dc:creator>Polychronakis, Michalis</dc:creator>
 <dc:creator>Das, Samir R.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Software Defined Networks (SDN) provide vital benefits to network
administrators by offering global visibility and network-wide control over the
switching infrastructure of the network. It is rather much difficult to obtain
the same benefits in the presence of middleboxes (MBs), due to (i) lack of a
proper topology discovery mechanism in environments with a mix of forwarding
devices and middleboxes. (ii) lack of generic APIs to abstract and gain control
on these rigid and heterogeneous third-party middleboxes (iii) lack of a
generic network infrastructure framework to monitor and verify any specific
device or path connectivity status in the network. These limitations make
automation of network operations such as, network-wide monitoring, policy
enforcement and rule-placement much difficult to handle. Hence, there is a
greater urge even from middlebox vendors, to better handle the control and
visibility aspects of the network in presence of middleboxes.
  In this paper, we propose a Unified network infrastructure framework for
gaining global network visibility, by discovering the network topology in the
presence of middleboxes, along with a framework to support the end-to-end path
connectivity verification, independent of SDN. We have also addressed security
aspects and provided necessary APIs to support our framework.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07662</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Re-embedding a 1-Plane Graph into a Straight-line Drawing in Linear Time</dc:title>
 <dc:creator>Hong, Seok-Hee</dc:creator>
 <dc:creator>Nagamochi, Hiroshi</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Thomassen characterized some 1-plane embedding as the forbidden configuration
such that a given 1-plane embedding of a graph is drawable in straight-lines if
and only if it does not contain the configuration [C. Thomassen, Rectilinear
drawings of graphs, J. Graph Theory, 10(3), 335-341, 1988].
  In this paper, we characterize some 1-plane embedding as the forbidden
configuration such that a given 1-plane embedding of a graph can be re-embedded
into a straight-line drawable 1-plane embedding of the same graph if and only
if it does not contain the configuration. Re-embedding of a 1-plane embedding
preserves the same set of pairs of crossing edges.
  We give a linear-time algorithm for finding a straight-line drawable 1-plane
re-embedding or the forbidden configuration.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016). This is an extended
  abstract. For a full version of this paper, see Hong S-H, Nagamochi H.:
  Re-embedding a 1-Plane Graph into a Straight-line Drawing in Linear Time,
  Technical Report TR 2016-002, Department of Applied Mathematics and Physics,
  Kyoto University (2016)</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07664</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatio-temporal Aware Non-negative Component Representation for Action
  Recognition</dc:title>
 <dc:creator>Wang, Jianhong</dc:creator>
 <dc:creator>Lan, Tian</dc:creator>
 <dc:creator>Zhang, Xu</dc:creator>
 <dc:creator>Luo, Limin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a novel mid-level representation for action recognition,
named spatio-temporal aware non-negative component representation (STANNCR).
The proposed STANNCR is based on action component and incorporates the
spatial-temporal information. We first introduce a spatial-temporal
distribution vector (STDV) to model the distributions of local feature
locations in a compact and discriminative manner. Then we employ non-negative
matrix factorization (NMF) to learn the action components and encode the video
samples. The action component considers the correlations of visual words, which
effectively bridge the sematic gap in action recognition. To incorporate the
spatial-temporal cues for final representation, the STDV is used as the part of
graph regularization for NMF. The fusion of spatial-temporal information makes
the STANNCR more discriminative, and our fusion manner is more compact than
traditional method of concatenating vectors. The proposed approach is
extensively evaluated on three public datasets. The experimental results
demonstrate the effectiveness of STANNCR for action recognition.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures, 6 tables</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07666</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Destination-aided Wireless Power Transfer in Energy-limited Cognitive
  Relay Systems</dc:title>
 <dc:creator>Sun, Ruijin</dc:creator>
 <dc:creator>Wang, Ying</dc:creator>
 <dc:creator>Miao, Zhongyu</dc:creator>
 <dc:creator>Wang, Xinshui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers an energy-limited cognitive relay network where a
secondary transmitter (ST) assists to forward the traffic from a primary
transmitter (PT) to a primary receiver (PR), in exchange for serving its own
secondary receiver (SR) in the same frequency. The multiple-antenna ST is
assumed to be energy-constrained and powered by both information flow from
source (PT) and dedicated energy streams from destinations (PR and SR), which
is called destination-aided wireless power transfer (DWPT) scheme. Then, the
relay processing matrix, cognitive beamforming vector and power splitter are
jointly de- signed to maximize the rate of secondary users under the energy
causality constraint and the constraint that the demanded rate of primary users
is satisfied. For the perfect channel information state (CSI) case, by adopting
semi-definite relax (SDR) technique and Charnes-Cooper transformation, the
global optimal solution is given. To reduce the complexity, matrix
decomposition, zero forcing (ZF) scheme, and dual method are jointly employed
to derive a suboptimal solution. For the imperfect CSI case, S- procedure is
used to transform the worst-case robust problem into a tractable semi-definite
program (SDP). Simulation results reveal that our proposed DWPT scheme is
greatly preferred for both perfect and imperfect CSI cases when ST is close to
PR/SR.
</dc:description>
 <dc:description>Comment: 12 pages, 9 figures</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07670</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CISER: An Amoebiasis inspired Model for Epidemic Message Propagation in
  DTN</dc:title>
 <dc:creator>CC, Sobin</dc:creator>
 <dc:creator>Saha, Snehanshu</dc:creator>
 <dc:creator>Raychoudhury, Vaskar</dc:creator>
 <dc:creator>Fidele, Hategekimana</dc:creator>
 <dc:creator>Sinha, Sumana</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Delay Tolerant Networks (DTNs) are sparse mobile networks, which experiences
frequent disruptions in connectivity among nodes. Usually, DTN follows
store-carry-and forward mechanism for message forwarding, in which a node store
and carry the message until it finds an appropriate relay node to forward
further in the network. So, The efficiency of DTN routing protocol relies on
the intelligent selection of a relay node from a set of encountered nodes.
Although there are plenty of DTN routing schemes proposed in the literature
based on different strategies of relay selection, there are not many
mathematical models proposed to study the behavior of message forwarding in
DTN. In this paper, we have proposed a novel epidemic model, called as CISER
model, for message propagation in DTN, based on Amoebiasis disease propagation
in human population. The proposed CISER model is an extension of SIR epidemic
model with additional states to represent the resource constrained behavior of
nodes in DTN. Experimental results using both synthetic and real-world traces
show that the proposed model improves the routing performance metrics, such as
delivery ratio, overhead ratio and delivery delay compared to SIR model.
</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07670</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07672</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transceiver Design for Cooperative Non-Orthogonal Multiple Access
  Systems with Wireless Energy Transfer</dc:title>
 <dc:creator>Sun, Ruijin</dc:creator>
 <dc:creator>Wang, Ying</dc:creator>
 <dc:creator>Wang, Xinshui</dc:creator>
 <dc:creator>Zhang, Yuan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, an energy harvesting (EH) based cooperative non-orthogonal
multiple access (NOMA) system is considered, where node S simultaneously sends
independent signals to a stronger node R and a weaker node D. We focus on the
scenario that the direct link between S and D is too weak to meet the quality
of service (QoS) of D. Based on the NOMA principle, node R, the stronger user,
has prior knowledge about the information of the weaker user, node D. To
satisfy the targeted rate of D, R also serves as an EH decode-and-forward (DF)
relay to forward the traffic from S to D. In the sense of equivalent cognitive
radio concept, node R viewed as a secondary user assists to boost the
performance of D, in exchange for receiving its own information from S.
Specifically, transmitter beamforming design, power splitting ratio
optimization and receiver filter design to maximize node R rate are studied
with the predefined QoS constraint of D and the power constraint of S. Since
the problem is non-convex, we propose an iterative approach to solve it.
Moreover, to reduce the computational complexity, a zero- forcing (ZF) based
solution is also presented. Simulation results demonstrate that, both two
proposed schemes have better performance than the direction transmission.
</dc:description>
 <dc:description>Comment: 23 pages, 6 figures</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07672</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07679</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Passive Fingerprinting of SCADA in Critical Infrastructure Network
  without Deep Packet Inspection</dc:title>
 <dc:creator>Jeon, Sungho</dc:creator>
 <dc:creator>Yun, Jeong-Han</dc:creator>
 <dc:creator>Choi, Seungoh</dc:creator>
 <dc:creator>Kim, Woo-Nyon</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We present the first technique of passive fingerprinting for Supervisory
Control And Data Acquisition (SCADA) networks without Deep Packet Inspection
(DPI) and experience on real environment. Unlike existing work, our method does
not rely on the functions of a specific product or DPI of the SCADA protocol.
Our inference method, which is based on the intrinsic characteristics of SCADA,
first identifies the network port used for the SCADA protocol, then
consecutively infers the field devices and master server. We evaluated the
effectiveness of our method using two network traces collected from a real
environment for a month and a half, three days from different CI respectively.
This confirmed the ability of our method to capture most of the SCADA with high
F-score nearly 1, except for HMIs connected to master server, and demonstrated
the practical applicability of the method.
</dc:description>
 <dc:description>Comment: IEEE 8 pages, submitted</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07679</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07685</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>KSR: A Semantic Representation of Knowledge Graph within a Novel
  Unsupervised Paradigm</dc:title>
 <dc:creator>Xiao, Han</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Knowledge representation is a long-history topic in AI, which is very
important. A variety of models have been proposed for knowledge graph
embedding, which projects symbolic entities and relations into continuous
vector space. However, most related methods merely focus on the data-fitting of
knowledge graph, and ignore the interpretable semantic expression. Thus,
traditional embedding methods are not friendly for applications that require
semantic analysis, such as question answering and entity retrieval. To this
end, this paper proposes a semantic representation method for knowledge graph
\textbf{(KSR)}, which imposes a two-level hierarchical generative process that
globally extracts many aspects and then locally assigns a specific category in
each aspect for every triple. Since both aspects and categories are
semantics-relevant, the collection of categories in each aspect is treated as
the semantic representation of this triple. Extensive experiments show that our
model outperforms other state-of-the-art baselines substantially.
</dc:description>
 <dc:description>Comment: submitting to IJCAI 2018</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:date>2017-12-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07685</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07690</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Boundary Tilting Persepective on the Phenomenon of Adversarial
  Examples</dc:title>
 <dc:creator>Tanay, Thomas</dc:creator>
 <dc:creator>Griffin, Lewis</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep neural networks have been shown to suffer from a surprising weakness:
their classification outputs can be changed by small, non-random perturbations
of their inputs. This adversarial example phenomenon has been explained as
originating from deep networks being &quot;too linear&quot; (Goodfellow et al., 2014). We
show here that the linear explanation of adversarial examples presents a number
of limitations: the formal argument is not convincing, linear classifiers do
not always suffer from the phenomenon, and when they do their adversarial
examples are different from the ones affecting deep networks.
  We propose a new perspective on the phenomenon. We argue that adversarial
examples exist when the classification boundary lies close to the submanifold
of sampled data, and present a mathematical analysis of this new perspective in
the linear case. We define the notion of adversarial strength and show that it
can be reduced to the deviation angle between the classifier considered and the
nearest centroid classifier. Then, we show that the adversarial strength can be
made arbitrarily high independently of the classification performance due to a
mechanism that we call boundary tilting. This result leads us to defining a new
taxonomy of adversarial examples. Finally, we show that the adversarial
strength observed in practice is directly dependent on the level of
regularisation used and the strongest adversarial examples, symptomatic of
overfitting, can be avoided by using a proper level of regularisation.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1412.6572 by other authors</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07703</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsound Inferences Make Proofs Shorter</dc:title>
 <dc:creator>Aguilera, Juan P.</dc:creator>
 <dc:creator>Baaz, Matthias</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We give examples of calculi that extend Gentzen's sequent calculus LK by
unsound quantifier inferences in such a way that (i) derivations lead only to
true sequents, and (ii) proofs therein are non-elementarily shorter than
LK-proofs.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07706</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Path Feedback Recurrent Neural Network for Scene Parsing</dc:title>
 <dc:creator>Jin, Xiaojie</dc:creator>
 <dc:creator>Chen, Yunpeng</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:creator>Jie, Zequn</dc:creator>
 <dc:creator>Yan, Shuicheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we consider the scene parsing problem and propose a novel
Multi-Path Feedback recurrent neural network (MPF-RNN) for parsing scene
images. MPF-RNN can enhance the capability of RNNs in modeling long-range
context information at multiple levels and better distinguish pixels that are
easy to confuse. Different from feedforward CNNs and RNNs with only single
feedback, MPF-RNN propagates the contextual features learned at top layer
through \textit{multiple} weighted recurrent connections to learn bottom
features. For better training MPF-RNN, we propose a new strategy that considers
accumulative loss at multiple recurrent steps to improve performance of the
MPF-RNN on parsing small objects. With these two novel components, MPF-RNN has
achieved significant improvement over strong baselines (VGG16 and Res101) on
five challenging scene parsing benchmarks, including traditional SiftFlow,
Barcelona, CamVid, Stanford Background as well as the recently released
large-scale ADE20K.
</dc:description>
 <dc:description>Comment: Accepted by AAAI-17. Camera-ready version</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:date>2016-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07706</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07708</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Logic programming: laxness and saturation</dc:title>
 <dc:creator>Komendantskaya, Ekaterina</dc:creator>
 <dc:creator>Power, John</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  A propositional logic program $P$ may be identified with a $P_fP_f$-coalgebra
on the set of atomic propositions in the program. The corresponding
$C(P_fP_f)$-coalgebra, where $C(P_fP_f)$ is the cofree comonad on $P_fP_f$,
describes derivations by resolution. That correspondence has been developed to
model first-order programs in two ways, with lax semantics and saturated
semantics, based on locally ordered categories and right Kan extensions
respectively. We unify the two approaches, exhibiting them as complementary
rather than competing, reflecting the theorem-proving and proof-search aspects
of logic programming. While maintaining that unity, we further refine lax
semantics to give finitary models of logic programs with existential variables,
and to develop a precise semantic relationship between variables in logic
programming and worlds in local state.
</dc:description>
 <dc:description>Comment: 30 pages, submitted to Journal of Logic and Algebraic Methods in
  Programming. arXiv admin note: substantial text overlap with arXiv:1602.05400</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07708</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07710</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random Forest for Label Ranking</dc:title>
 <dc:creator>Zhou, Yangming</dc:creator>
 <dc:creator>Qiu, Guoping</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Label ranking aims to learn a mapping from instances to rankings over a
finite number of predefined labels. Random forest is a powerful and one of the
most successfully general-purpose machine learning algorithms of modern times.
In the literature, there seems no research has yet been done in applying random
forest to label ranking. In this paper, We present a powerful random forest
label ranking method which uses random decision trees to retrieve nearest
neighbors that are not only similar in the feature space but also in the
ranking space. We have developed a novel two-step rank aggregation strategy to
effectively aggregate neighboring rankings discovered by the random forest into
a final predicted ranking. Compared with existing methods, the new random
forest method has many advantages including its intrinsically scalable tree
data structure, highly parallel-able computational architecture and much
superior performances. We present extensive experimental results to demonstrate
that our new method achieves the best predictive accuracy performances compared
with state-of-the-art methods for datasets with complete ranking and datasets
with only partial ranking information.
</dc:description>
 <dc:description>Comment: 22 pages, 4 figures, improved version of the paper originally
  submitted to ICML 2016</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07711</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Object Proposals using Stereo Imagery for Accurate Object Class
  Detection</dc:title>
 <dc:creator>Chen, Xiaozhi</dc:creator>
 <dc:creator>Kundu, Kaustav</dc:creator>
 <dc:creator>Zhu, Yukun</dc:creator>
 <dc:creator>Ma, Huimin</dc:creator>
 <dc:creator>Fidler, Sanja</dc:creator>
 <dc:creator>Urtasun, Raquel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The goal of this paper is to perform 3D object detection in the context of
autonomous driving. Our method first aims at generating a set of high-quality
3D object proposals by exploiting stereo imagery. We formulate the problem as
minimizing an energy function that encodes object size priors, placement of
objects on the ground plane as well as several depth informed features that
reason about free space, point cloud densities and distance to the ground. We
then exploit a CNN on top of these proposals to perform object detection. In
particular, we employ a convolutional neural net (CNN) that exploits context
and depth information to jointly regress to 3D bounding box coordinates and
object pose. Our experiments show significant performance gains over existing
RGB and RGB-D object proposal methods on the challenging KITTI benchmark. When
combined with the CNN, our approach outperforms all existing results in object
detection and orientation estimation tasks for all three KITTI object classes.
Furthermore, we experiment also with the setting where LIDAR information is
available, and show that using both LIDAR and stereo leads to the best result.
</dc:description>
 <dc:description>Comment: 14 pages, 12 figures</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:date>2017-04-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07713</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diffuse-field coherence of sensors with arbitrary directional responses</dc:title>
 <dc:creator>Politis, Archontis</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Knowledge of the diffuse-field coherence between array sensors is a basic
assumption for a wide range of array processing applications. Explicit
relations previously existed only for omnidirectional and first-order
directional sensors, or a restricted arrangement of differential patterns. We
present a closed-form formulation of the theoretical coherence function between
arbitrary directionally band-limited sensors for the general cases that a) the
responses of the individual sensors are known or estimated, and the coherence
needs to be known for an arbitrary arrangement, and b) that no information on
the sensor directionality or on array geometry exists, but calibration
measurements around the array are available.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07713</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07719</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temperature-Based Deep Boltzmann Machines</dc:title>
 <dc:creator>Junior, Leandro Aparecido Passos</dc:creator>
 <dc:creator>Papa, Joao Paulo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep learning techniques have been paramount in the last years, mainly due to
their outstanding results in a number of applications, that range from speech
recognition to face-based user identification. Despite other techniques
employed for such purposes, Deep Boltzmann Machines are among the most used
ones, which are composed of layers of Restricted Boltzmann Machines (RBMs)
stacked on top of each other. In this work, we evaluate the concept of
temperature in DBMs, which play a key role in Boltzmann-related distributions,
but it has never been considered in this context up to date. Therefore, the
main contribution of this paper is to take into account this information and to
evaluate its influence in DBMs considering the task of binary image
reconstruction. We expect this work can foster future research considering the
usage of different temperatures during learning in DBMs.
</dc:description>
 <dc:description>Comment: Submitted to Neural Processing Letters</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07719</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07720</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bi-LSTM-RNN Model for Relation Classification Using Low-Cost Sequence
  Features</dc:title>
 <dc:creator>Li, Fei</dc:creator>
 <dc:creator>Zhang, Meishan</dc:creator>
 <dc:creator>Fu, Guohong</dc:creator>
 <dc:creator>Qian, Tao</dc:creator>
 <dc:creator>Ji, Donghong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Relation classification is associated with many potential applications in the
artificial intelligence area. Recent approaches usually leverage neural
networks based on structure features such as syntactic or dependency features
to solve this problem. However, high-cost structure features make such
approaches inconvenient to be directly used. In addition, structure features
are probably domain-dependent. Therefore, this paper proposes a bi-directional
long-short-term-memory recurrent-neural-network (Bi-LSTM-RNN) model based on
low-cost sequence features to address relation classification. This model
divides a sentence or text segment into five parts, namely two target entities
and their three contexts. It learns the representations of entities and their
contexts, and uses them to classify relations. We evaluate our model on two
standard benchmark datasets in different domains, namely SemEval-2010 Task 8
and BioNLP-ST 2016 Task BB3. In the former dataset, our model achieves
comparable performance compared with other models using sequence features. In
the latter dataset, our model obtains the third best results compared with
other models in the official evaluation. Moreover, we find that the context
between two target entities plays the most important role in relation
classification. Furthermore, statistic experiments show that the context
between two target entities can be used as an approximate replacement of the
shortest dependency path when dependency parsing is not used.
</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07720</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07724</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Temporal Transformations From Time-Lapse Videos</dc:title>
 <dc:creator>Zhou, Yipin</dc:creator>
 <dc:creator>Berg, Tamara L.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Based on life-long observations of physical, chemical, and biologic phenomena
in the natural world, humans can often easily picture in their minds what an
object will look like in the future. But, what about computers? In this paper,
we learn computational models of object transformations from time-lapse videos.
In particular, we explore the use of generative models to create depictions of
objects at future times. These models explore several different prediction
tasks: generating a future state given a single depiction of an object,
generating a future state given two depictions of an object at different times,
and generating future states recursively in a recurrent framework. We provide
both qualitative and quantitative evaluations of the generated results, and
also conduct a human evaluation to compare variations of our models.
</dc:description>
 <dc:description>Comment: ECCV2016</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07727</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Parameters and Ramsey Theory</dc:title>
 <dc:creator>Lozin, Vadim</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05 Combinatorics</dc:subject>
 <dc:description>  Ramsey's Theorem tells us that there are exactly two minimal hereditary
classes containing graphs with arbitrarily many vertices: the class of complete
graphs and the class of edgeless graphs. In other words, Ramsey's Theorem
characterizes the graph vertex number in terms of minimal hereditary classes
where this parameter is unbounded. In the present paper, we show that a similar
Ramsey-type characterization is possible for a number of other graph
parameters, such as vertex cover number, matching number, neighbourhood
diversity, VC-dimension.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07727</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07730</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithmic complexity of quantum capacity</dc:title>
 <dc:creator>Oskouei, Samad Khabbazi</dc:creator>
 <dc:creator>Mancini, Stefano</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  Recently the theory of communication developed by Shannon has been extended
to the quantum realm by exploiting the rules of quantum theory. This latter
stems on complex vector spaces. However complex (as well as real) numbers are
just idealizations and they are not available in practice where we can only
deal with rational numbers. This fact naturally leads to the question of
whether the developed notions of capacities for quantum channels truly catch
their ability to transmit information. Here we answer this question for the
quantum capacity. To this end we resort to the notion of semi-computability in
order to approximately (by rational numbers) describe quantum states and
quantum channel maps. Then we introduce algorithmic entropies (like algorithmic
quantum coherent information) and derive relevant properties for them. Finally
we define algorithmic quantum capacity and prove that it equals the standard
one.
</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07734</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Bayesian Networks with Incomplete Data by Augmentation</dc:title>
 <dc:creator>Adel, Tameem</dc:creator>
 <dc:creator>de Campos, Cassio P.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present new algorithms for learning Bayesian networks from data with
missing values using a data augmentation approach. An exact Bayesian network
learning algorithm is obtained by recasting the problem into a standard
Bayesian network learning problem without missing data. To the best of our
knowledge, this is the first exact algorithm for this problem. As expected, the
exact algorithm does not scale to large domains. We build on the exact method
to create an approximate algorithm using a hill-climbing technique. This
algorithm scales to large domains so long as a suitable standard structure
learning method for complete data is available. We perform a wide range of
experiments to demonstrate the benefits of learning Bayesian networks with such
new approach.
</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:date>2016-10-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07738</identifier>
 <datestamp>2016-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Testing APSyn against Vector Cosine on Similarity Estimation</dc:title>
 <dc:creator>Santus, Enrico</dc:creator>
 <dc:creator>Chersoni, Emmanuele</dc:creator>
 <dc:creator>Lenci, Alessandro</dc:creator>
 <dc:creator>Huang, Chu-Ren</dc:creator>
 <dc:creator>Blache, Philippe</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In Distributional Semantic Models (DSMs), Vector Cosine is widely used to
estimate similarity between word vectors, although this measure was noticed to
suffer from several shortcomings. The recent literature has proposed other
methods which attempt to mitigate such biases. In this paper, we intend to
investigate APSyn, a measure that computes the extent of the intersection
between the most associated contexts of two target words, weighting it by
context relevance. We evaluated this metric in a similarity estimation task on
several popular test sets, and our results show that APSyn is in fact highly
competitive, even with respect to the results reported in the literature for
word embeddings. On top of it, APSyn addresses some of the weaknesses of Vector
Cosine, performing well also on genuine similarity estimation.
</dc:description>
 <dc:description>Comment: 8 pages, 1 figure, 4 tables, PACLIC, cosine, vectors, DSMs</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:date>2016-10-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07738</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07739</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian selection for the l2-Potts model regularization parameter: 1D
  piecewise constant signal denoising</dc:title>
 <dc:creator>Frecon, Jordan</dc:creator>
 <dc:creator>Pustelnik, Nelly</dc:creator>
 <dc:creator>Dobigeon, Nicolas</dc:creator>
 <dc:creator>Wendt, Herwig</dc:creator>
 <dc:creator>Abry, Patrice</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Piecewise constant denoising can be solved either by deterministic
optimization approaches, based on the Potts model, or by stochastic Bayesian
procedures. The former lead to low computational time but require the selection
of a regularization parameter, whose value significantly impacts the achieved
solution, and whose automated selection remains an involved and challenging
problem. Conversely, fully Bayesian formalisms encapsulate the regularization
parameter selection into hierarchical models, at the price of high
computational costs. This contribution proposes an operational strategy that
combines hierarchical Bayesian and Potts model formulations, with the double
aim of automatically tuning the regularization parameter and of maintaining
computational effciency. The proposed procedure relies on formally connecting a
Bayesian framework to a l2-Potts functional. Behaviors and performance for the
proposed piecewise constant denoising and regularization parameter tuning
techniques are studied qualitatively and assessed quantitatively, and shown to
compare favorably against those of a fully Bayesian hierarchical procedure,
both in accuracy and in computational load.
</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07739</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2715000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07740</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Forecasting the onset and course of mental illness with Twitter data</dc:title>
 <dc:creator>Reece, Andrew G.</dc:creator>
 <dc:creator>Reagan, Andrew J.</dc:creator>
 <dc:creator>Lix, Katharina L. M.</dc:creator>
 <dc:creator>Dodds, Peter Sheridan</dc:creator>
 <dc:creator>Danforth, Christopher M.</dc:creator>
 <dc:creator>Langer, Ellen J.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We developed computational models to predict the emergence of depression and
Post-Traumatic Stress Disorder in Twitter users. Twitter data and details of
depression history were collected from 204 individuals (105 depressed, 99
healthy). We extracted predictive features measuring affect, linguistic style,
and context from participant tweets (N=279,951) and built models using these
features with supervised learning algorithms. Resulting models successfully
discriminated between depressed and healthy content, and compared favorably to
general practitioners' average success rates in diagnosing depression. Results
held even when the analysis was restricted to content posted before first
depression diagnosis. State-space temporal analysis suggests that onset of
depression may be detectable from Twitter data several months prior to
diagnosis. Predictive results were replicated with a separate sample of
individuals diagnosed with PTSD (174 users, 243,775 tweets). A state-space time
series model revealed indicators of PTSD almost immediately post-trauma, often
many months prior to clinical diagnosis. These methods suggest a data-driven,
predictive approach for early screening and detection of mental illness.
</dc:description>
 <dc:description>Comment: 23 pages, 6 figures</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07743</identifier>
 <datestamp>2016-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effect of Human Learning on the Transient Performance of Cloud-based
  Tiered Applications</dc:title>
 <dc:creator>Das, Arindam</dc:creator>
 <dc:creator>Das, Olivia</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Cloud based tiered applications are increasingly becoming popular, be it on
phones or on desktops. End users of these applications range from novice to
expert depending on how experienced they are in using them. With repeated usage
(practice) of an application, a user's think time gradually decreases, known as
learning phenomenon. In contrast to the popular notion of constant mean think
time of users across all practice sessions, decrease in mean think time over
practice sessions does occur due to learning. This decrease gives rise to a
different system workload thereby affecting the application's short-term
performance. However, such impact of learning on performance has never been
accounted for. In this work we propose a model that accounts for human learning
behavior in analyzing the transient (short-term) performance of a 3-tier cloud
based application. Our approach is based on a closed queueing network model. We
solve the model using discrete event simulation. In addition to the overall
mean System Response Time (SRT), our model solution also generates the mean
SRTs for various types (novice, intermediate, expert) of requests submitted by
users at various levels of their expertise. We demonstrate that our model can
be used to evaluate various what-if scenarios to decide the number of VMs we
need for each tier-a VM configuration-that would meet the response time SLA.
The results show that the lack of accountability of learning may lead to a
selection of an inappropriate VM configuration. The results further show that
the mean SRTs for various types of requests are better measures to consider in
VM allocation process in comparison to the overall mean SRT.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07743</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07745</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Type-Directed Code Reuse using Integer Linear Programming</dc:title>
 <dc:creator>Wang, Yuepeng</dc:creator>
 <dc:creator>Feng, Yu</dc:creator>
 <dc:creator>Martins, Ruben</dc:creator>
 <dc:creator>Kaushik, Arati</dc:creator>
 <dc:creator>Dillig, Isil</dc:creator>
 <dc:creator>Reiss, Steven P.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  In many common scenarios, programmers need to implement functionality that is
already provided by some third party library. This paper presents a tool called
Hunter that facilitates code reuse by finding relevant methods in large code
bases and automatically synthesizing any necessary wrapper code. The key
technical idea underlying our approach is to use types to both improve search
results and guide synthesis. Specifically, our method computes similarity
metrics between types and uses this information to solve an integer linear
programming (ILP) problem in which the objective is to minimize the cost of
synthesis. We have implemented Hunter as an Eclipse plug-in and evaluate it by
(a) comparing it against S6, a state-of-the-art code reuse tool, and (b)
performing a user study. Our evaluation shows that Hunter compares favorably
with S6 and significantly increases programmer productivity.
</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07745</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07754</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Precise Condition Synthesis for Program Repair</dc:title>
 <dc:creator>Xiong, Yingfei</dc:creator>
 <dc:creator>Wang, Jie</dc:creator>
 <dc:creator>Yan, Runfa</dc:creator>
 <dc:creator>Zhang, Jiachen</dc:creator>
 <dc:creator>Han, Shi</dc:creator>
 <dc:creator>Huang, Gang</dc:creator>
 <dc:creator>Zhang, Lu</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Due to the difficulty of repairing defect, many research efforts have been
devoted into automatic defect repair. Given a buggy program that fails some
test cases, a typical automatic repair technique tries to modify the program to
make all tests pass. However, since the test suites in real world projects are
usually insufficient, aiming at passing the test suites often leads to
incorrect patches.
  In this paper we aim to produce precise patches, that is, any patch we
produce has a relatively high probability to be correct. More concretely, we
focus on condition synthesis, which was shown to be able to repair more than
half of the defects in existing approaches. Our key insight is threefold.
First, it is important to know what variables in a local context should be used
in an &quot;if&quot; condition, and we propose a sorting method based on the dependency
relations between variables. Second, we observe that the API document can be
used to guide the repair process, and propose document analysis technique to
further filter the variables. Third, it is important to know what predicates
should be performed on the set of variables, and we propose to mine a set of
frequently used predicates in similar contexts from existing projects.
  We develop a novel program repair system, ACS, that could generate precise
conditions at faulty locations. Furthermore, given the generated conditions are
very precise, we can perform a repair operation that is previously deemed to be
too overfitting: directly returning the test oracle to repair the defect. Using
our approach, we successfully repaired 18 defects on four projects of
Defects4J, which is the largest number of fully automatically repaired defects
reported on the dataset so far. More importantly, the precision of our approach
in the evaluation is 78.3%, which is significantly higher than previous
approaches, which are usually less than 40%.
</dc:description>
 <dc:description>Comment: Accepted at ICSE 2017. This is a longer version of the conference
  paper and also corrects errors in Table III</dc:description>
 <dc:date>2016-08-27</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07764</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Movie Graph Argument Revisited</dc:title>
 <dc:creator>Standish, Russell K.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>68T99</dc:subject>
 <dc:subject>I.2.0</dc:subject>
 <dc:description>  In this paper, we reexamine the Movie Graph Argument, which demonstrates a
basic incompatibility between computationalism and materialism. We discover
that the incompatibility is only manifest in singular classical-like universes.
If we accept that we live in a Multiverse, then the incompatibility goes away,
but in that case another line of argument shows that with computationalism, the
fundamental, or primitive materiality has no causal influence on what is
observed, which must must be derivable from basic arithmetic properties.
</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07767</identifier>
 <datestamp>2016-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sum Secrecy Rate Maximization for Full-Duplex Two-Way Relay Networks
  Using Alamouti-based Rank-Two Beamforming</dc:title>
 <dc:creator>Li, Qiang</dc:creator>
 <dc:creator>Ma, Wing-Kin</dc:creator>
 <dc:creator>Han, Dong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Consider a two-way communication scenario where two single-antenna nodes,
operating under full-duplex mode, exchange information to one another through
the aid of a (full-duplex) multi-antenna relay, and there is another
single-antenna node who intends to eavesdrop. The relay employs artificial
noise (AN) to interfere the eavesdropper's channel, and amplify-forward (AF)
Alamouti-based rank-two beamforming to establish the two-way communication
links of the legitimate nodes. Our problem is to optimize the rank-two
beamformer and AN covariance for sum secrecy rate maximization (SSRM). This
SSRM problem is nonconvex, and we develop an efficient solution approach using
semidefinite relaxation (SDR) and minorization-maximization (MM). We prove that
SDR is tight for the SSRM problem and thus introduces no loss. Also, we
consider an inexact MM method where an approximately but computationally cheap
MM solution update is used in place of the exact update in conventional MM. We
show that this inexact MM method guarantees convergence to a stationary
solution to the SSRM problem. The effectiveness of our proposed approach is
further demonstrated by an energy-harvesting scenario extension, and by
extensive simulation results.
</dc:description>
 <dc:description>Comment: 15 pages, 7 figures, accepted by IEEE Journal of Selected Topics in
  Signal Processing</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07767</dc:identifier>
 <dc:identifier>doi:10.1109/JSTSP.2016.2603970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07775</identifier>
 <datestamp>2017-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Attention Model for Improved Machine Comprehension of
  Spoken Content</dc:title>
 <dc:creator>Fang, Wei</dc:creator>
 <dc:creator>Hsu, Jui-Yang</dc:creator>
 <dc:creator>Lee, Hung-yi</dc:creator>
 <dc:creator>Lee, Lin-Shan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Multimedia or spoken content presents more attractive information than plain
text content, but the former is more difficult to display on a screen and be
selected by a user. As a result, accessing large collections of the former is
much more difficult and time-consuming than the latter for humans. It's
therefore highly attractive to develop machines which can automatically
understand spoken content and summarize the key information for humans to
browse over. In this endeavor, a new task of machine comprehension of spoken
content was proposed recently. The initial goal was defined as the listening
comprehension test of TOEFL, a challenging academic English examination for
English learners whose native languages are not English. An Attention-based
Multi-hop Recurrent Neural Network (AMRNN) architecture was also proposed for
this task, which considered only the sequential relationship within the speech
utterances. In this paper, we propose a new Hierarchical Attention Model (HAM),
which constructs multi-hopped attention mechanism over tree-structured rather
than sequential representations for the utterances. Improved comprehension
performance robust with respect to ASR errors were obtained.
</dc:description>
 <dc:description>Comment: Copyright 2016 IEEE. Published in the 2016 IEEE Workshop on Spoken
  Language Technology (SLT 2016)</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:date>2017-01-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07775</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07781</identifier>
 <datestamp>2016-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiversion Altruistic Locking</dc:title>
 <dc:creator>Chandak, Chinmay</dc:creator>
 <dc:creator>Vaidya, Hrishikesh</dc:creator>
 <dc:creator>Peri, Sathya</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This paper builds on altruistic locking which is an extension of 2PL. It
allows more relaxed rules as compared to 2PL. But altruistic locking too
enforces some rules which disallow some valid schedules (present in VSR and
CSR) to be passed by AL. This paper proposes a multiversion variant of AL which
solves this problem. The report also discusses the relationship or comparison
between different protocols such as MAL and MV2PL, MAL and AL, MAL and 2PL and
so on. This paper also discusses the caveats involved in MAL and where it lies
in the Venn diagram of multiversion serializable schedule protocols. Finally,
the possible use of MAL in hybrid protocols and the parameters involved in
making MAL successful are discussed.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:date>2016-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07781</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07792</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Generalized Resolution Proof Schema and the Pigeonhole Principle</dc:title>
 <dc:creator>Cerna, David M.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The schematic CERES method is a method of cut elimination for proof schemata,
that is a sequence of proofs with a recursive construction. Proof schemata can
be thought of as a way to circumvent the addition of an induction rule to the
LK-calculus. In this work, we formalize a schematic version of the Infinitary
Pigeonhole Principle (IPP), in the LKS-calculus, and analyse the extracted
clause set schema. However, the refutation we find cannot be expressed as a
resolution proof schema because there is no clear ordering of the terms
indexing the recursion, every ordering is used in the refutation. Interesting
enough, the clause set and its refutation is very close to a canonical form
found in cut elimination of LK-proofs. Not being able to handle refutations of
this form is problematic in that proof schema, when instantiated, are
LK-proofs. Based on the structure of our refutation and structural results, we
develop a generalized resolution proof schema based on recursion over a special
type of list, and provide a refutation, using our generalization, of the clause
set extracted from our formal proof of IPP. We also extract a Herbrand System
from the refutation.
</dc:description>
 <dc:description>Comment: Work is progress. This is the current extension of the the schematic
  resolution refutation formalism. A better formalism is being investigated.
  arXiv admin note: substantial text overlap with arXiv:1503.08551,
  arXiv:1601.06548</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07793</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Partially Observable Markov Decision Process for Recommender Systems</dc:title>
 <dc:creator>Lu, Zhongqi</dc:creator>
 <dc:creator>Yang, Qiang</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  We report the &quot;Recurrent Deterioration&quot; (RD) phenomenon observed in online
recommender systems. The RD phenomenon is reflected by the trend of performance
degradation when the recommendation model is always trained based on users'
feedbacks of the previous recommendations. There are several reasons for the
recommender systems to encounter the RD phenomenon, including the lack of
negative training data and the evolution of users' interests, etc. Motivated to
tackle the problems causing the RD phenomenon, we propose the POMDP-Rec
framework, which is a neural-optimized Partially Observable Markov Decision
Process algorithm for recommender systems. We show that the POMDP-Rec framework
effectively uses the accumulated historical data from real-world recommender
systems and automatically achieves comparable results with those models
fine-tuned exhaustively by domain exports on public datasets.
</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07799</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SUMMeR: Sub-Nyquist MIMO Radar</dc:title>
 <dc:creator>Cohen, David</dc:creator>
 <dc:creator>Cohen, Deborah</dc:creator>
 <dc:creator>Eldar, Yonina C.</dc:creator>
 <dc:creator>Haimovich, Alexander M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Multiple input multiple output (MIMO) radar exhibits several advantages with
respect to traditional radar array systems in terms of flexibility and
performance. However, MIMO radar poses new challenges for both hardware design
and digital processing. In particular, achieving high azimuth resolution
requires a large number of transmit and receive antennas. In addition, the
digital processing is performed on samples of the received signal, from each
transmitter to each receiver, at its Nyquist rate, which can be prohibitively
large when high resolution is needed. Overcoming the rate bottleneck,
sub-Nyquist sampling methods have been proposed that break the link between
radar signal bandwidth and sampling rate. In this work, we extend these methods
to MIMO configurations and propose a sub-Nyquist MIMO radar (SUMMeR) system
that performs both time and spatial compression. We present a
range-azimuth-Doppler recovery algorithm from sub-Nyquist samples obtained from
a reduced number of transmitters and receivers, that exploits the sparsity of
the recovered targets' parameters. This allows us to achieve reduction in the
number of deployed antennas and the number of samples per receiver, without
degrading the time and spatial resolutions. Simulations illustrate the
detection performance of SUMMeR for different compression levels and shows that
both time and spatial resolution are preserved, with respect to classic Nyquist
MIMO configurations. We also examine the impact of design parameters, such as
antennas' locations and carrier frequencies, on the detection performance, and
provide guidelines for their choice.
</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07800</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Rank Matrix Completion for Mobile Edge Caching in Fog-RAN via
  Riemannian Optimization</dc:title>
 <dc:creator>Yang, Kai</dc:creator>
 <dc:creator>Shi, Yuanming</dc:creator>
 <dc:creator>Ding, Zhi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The upcoming big data era is likely to demand tremendous computation and
storage resources for communications. By pushing computation and storage to
network edges, fog radio access networks (Fog-RAN) can effectively increase
network throughput and reduce transmission latency. Furthermore, we can exploit
the benefits of cache enabled architecture in Fog-RAN to deliver contents with
low latency. Radio access units (RAUs) need content delivery from fog servers
through wireline links whereas multiple mobile devices acquire contents from
RAUs wirelessly. This work proposes a unified low-rank matrix completion (LRMC)
approach to solving the content delivery problem in both wireline and wireless
parts of Fog-RAN. To attain a low caching latency, we present a high precision
approach with Riemannian trust-region method to solve the challenging LRMC
problem by exploiting the quotient manifold geometry of fixed-rank matrices.
Numerical results show that the new approach has a faster convergence rate, is
able to achieve optimal results, and outperforms other state-of-art algorithms.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:date>2016-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07802</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MindX: Denoising Mixed Impulse Poisson-Gaussian Noise Using Proximal
  Algorithms</dc:title>
 <dc:creator>Aly, Mohamed</dc:creator>
 <dc:creator>Heidrich, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We present a novel algorithm for blind denoising of images corrupted by mixed
impulse, Poisson, and Gaussian noises. The algorithm starts by applying the
Anscombe variance-stabilizing transformation to convert the Poisson into white
Gaussian noise. Then it applies a combinatorial optimization technique to
denoise the mixed impulse Gaussian noise using proximal algorithms. The result
is then processed by the inverse Anscombe transform. We compare our algorithm
to state of the art methods on standard images, and show its superior
performance in various noise conditions.
</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07802</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07807</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cast and Self Shadow Segmentation in Video Sequences using Interval
  based Eigen Value Representation</dc:title>
 <dc:creator>M, Chandrajit</dc:creator>
 <dc:creator>R, Girisha</dc:creator>
 <dc:creator>T, Vasudev</dc:creator>
 <dc:creator>B, Ashok C</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Tracking of motion objects in the surveillance videos is useful for the
monitoring and analysis. The performance of the surveillance system will
deteriorate when shadows are detected as moving objects. Therefore, shadow
detection and elimination usually benefits the next stages. To overcome this
issue, a method for detection and elimination of shadows is proposed. This
paper presents a method for segmenting moving objects in video sequences based
on determining the Euclidian distance between two pixels considering
neighborhood values in temporal domain. Further, a method that segments cast
and self shadows in video sequences by computing the Eigen values for the
neighborhood of each pixel is proposed. The dual-map for cast and self shadow
pixels is represented based on the interval of Eigen values. The proposed
methods are tested on the benchmark IEEE CHANGE DETECTION 2014 dataset.
</dc:description>
 <dc:description>Comment: 6 pages journal article</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07807</dc:identifier>
 <dc:identifier>International Journal of Computer Applications 142(4):27-32, May
  2016</dc:identifier>
 <dc:identifier>doi:10.5120/ijca2016909752</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07809</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Generalization of the Directed Graph Layering Problem</dc:title>
 <dc:creator>R&#xfc;egg, Ulf</dc:creator>
 <dc:creator>Ehlers, Thorsten</dc:creator>
 <dc:creator>Sp&#xf6;nemann, Miro</dc:creator>
 <dc:creator>von Hanxleden, Reinhard</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  The Directed Layering Problem (DLP) solves a step of the widely used
layer-based approach to automatically draw directed acyclic graphs. To cater
for cyclic graphs, usually a preprocessing step is used that solves the
Feedback Arc Set Problem (FASP) to make the graph acyclic before a layering is
determined. Here we present the Generalized Layering Problem (GLP), which
solves the combination of DLP and FASP simultaneously, allowing general graphs
as input. We present an integer programming model and a heuristic to solve the
NP-complete GLP and perform thorough evaluations on different sets of graphs
and with different implementations for the steps of the layer-based approach.
We observe that GLP reduces the number of dummy nodes significantly, can
produce more compact drawings, and improves on graphs where DLP yields poor
aspect ratios.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07813</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Total variation reconstruction for compressive sensing using nonlocal
  Lagrangian multiplier</dc:title>
 <dc:creator>Van Chien, Trinh</dc:creator>
 <dc:creator>Dinh, Khanh Quoc</dc:creator>
 <dc:creator>Nguyen, Viet Anh</dc:creator>
 <dc:creator>Jeon, Byeungwoo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Total variation has proved its effectiveness in solving inverse problems for
compressive sensing. Besides, the nonlocal means filter used as regularization
preserves texture better for recovered images, but it is quite complex to
implement. In this paper, based on existence of both noise and image
information in the Lagrangian multiplier, we propose a simple method in term of
implementation called nonlocal Lagrangian multiplier (NLLM) in order to reduce
noise and boost useful image information. Experimental results show that the
proposed NLLM is superior both in subjective and objective qualities of
recovered image over other recovery algorithms.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, 3 tables. EUSIPCO2014. Matlab software:
  https://www.researchgate.net/profile/Trinh_Chien/publications</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07836</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What to do about non-standard (or non-canonical) language in NLP</dc:title>
 <dc:creator>Plank, Barbara</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Real world data differs radically from the benchmark corpora we use in
natural language processing (NLP). As soon as we apply our technologies to the
real world, performance drops. The reason for this problem is obvious: NLP
models are trained on samples from a limited set of canonical varieties that
are considered standard, most prominently English newswire. However, there are
many dimensions, e.g., socio-demographics, language, genre, sentence type, etc.
on which texts can differ from the standard. The solution is not obvious: we
cannot control for all factors, and it is not clear how to best go beyond the
current practice of training on homogeneous data from a single domain and
language.
  In this paper, I review the notion of canonicity, and how it shapes our
community's approach to language. I argue for leveraging what I call fortuitous
data, i.e., non-obvious data that is hitherto neglected, hidden in plain sight,
or raw data that needs to be refined. If we embrace the variety of this
heterogeneous data by combining it with proper algorithms, we will not only
produce more robust models, but will also enable adaptive language technology
capable of addressing natural language variation.
</dc:description>
 <dc:description>Comment: KONVENS 2016</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07836</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07838</identifier>
 <datestamp>2016-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can one see the shape of a network?</dc:title>
 <dc:creator>Weber, Melanie</dc:creator>
 <dc:creator>Saucan, Emil</dc:creator>
 <dc:creator>Jost, J&#xfc;rgen</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C10, 05C82</dc:subject>
 <dc:description>  Traditionally, network analysis is based on local properties of vertices,
like their degree or clustering, and their statistical behavior across the
network in question. This paper develops an approach which is different in two
respects. We investigate edge-based properties, and we define global
characteristics of networks directly. The latter will provide our affirmative
answer to the question raised in the title. More concretely, we start with
Forman's notion of the Ricci curvature of a graph, or more generally, a
polyhedral complex. This will allow us to pass from a graph as representing a
network to a polyhedral complex for instance by filling in triangles into
connected triples of edges and to investigate the resulting effect on the
curvature. This is insightful for two reasons: First, we can define a curvature
flow in order to asymptotically simplify a network and reduce it to its
essentials. Second, using a construction of Bloch, which yields a discrete
Gauss-Bonnet theorem, we have the Euler characteristic of a network as a global
characteristic. These two aspects beautifully merge in the sense that the
asymptotic properties of the curvature flow are indicated by that Euler
characteristic.
</dc:description>
 <dc:description>Comment: Submitted. (25 pages, 6 figures, 3 tables)</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:date>2016-10-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07846</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Analytics using Ontologies of Management Theories: Towards
  Implementing 'From Theory to Practice'</dc:title>
 <dc:creator>Kim, Henry M.</dc:creator>
 <dc:creator>Cheung, Jackie Ho Nam</dc:creator>
 <dc:creator>Laskowski, Marek</dc:creator>
 <dc:creator>Gel, Iryna</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We explore how computational ontologies can be impactful vis-a-vis the
developing discipline of &quot;data science.&quot; We posit an approach wherein
management theories are represented as formal axioms, and then applied to draw
inferences about data that reside in corporate databases. That is, management
theories would be implemented as rules within a data analytics engine. We
demonstrate a case study development of such an ontology by formally
representing an accounting theory in First-Order Logic. Though quite
preliminary, the idea that an information technology, namely ontologies, can
potentially actualize the academic cliche, &quot;From Theory to Practice,&quot; and be
applicable to the burgeoning domain of data analytics is novel and exciting.
</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07846</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07847</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Indexing and querying color sets of images</dc:title>
 <dc:creator>Belazzougui, Djamal</dc:creator>
 <dc:creator>Kolpakov, Roman</dc:creator>
 <dc:creator>Raffinot, Mathieu</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We aim to study the set of color sets of continuous regions of an image given
as a matrix of $m$ rows over $n\geq m$ columns where each element in the matrix
is an integer from $[1,\sigma]$ named a {\em color}.
  The set of distinct colors in a region is called fingerprint. We aim to
compute, index and query the fingerprints of all rectangular regions named
rectangles. The set of all such fingerprints is denoted by ${\cal F}$. A
rectangle is {\em maximal} if it is not contained in a greater rectangle with
the same fingerprint. The set of all locations of maximal rectangles is denoted
by $\mathcal{L}.$ We first explain how to determine all the $|\mathcal{L}|$
maximal locations with their fingerprints in expected time $O(nm^2\sigma)$
using a Monte Carlo algorithm (with polynomially small probability of error) or
within deterministic $O(nm^2\sigma\log(\frac{|\mathcal{L}|}{nm^2}+2))$ time. We
then show how to build a data structure which occupies $O(nm\log
n+\mathcal{|L|})$ space such that a query which asks for all the maximal
locations with a given fingerprint $f$ can be answered in time $O(|f|+\log\log
n+k)$, where $k$ is the number of maximal locations with fingerprint $f$. If
the query asks only for the presence of the fingerprint, then the space usage
becomes $O(nm\log n+|{\cal F}|)$ while the query time becomes $O(|f|+\log\log
n)$. We eventually consider the special case of squared regions (squares).
</dc:description>
 <dc:description>Comment: 20 pages, 5 figures</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07847</dc:identifier>
 <dc:identifier>doi:10.1016/j.tcs.2016.07.041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07852</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantitative Analyses of Chinese Poetry of Tang and Song Dynasties:
  Using Changing Colors and Innovative Terms as Examples</dc:title>
 <dc:creator>Liu, Chao-Lin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Tang (618-907 AD) and Song (960-1279) dynasties are two very important
periods in the development of Chinese literary. The most influential forms of
the poetry in Tang and Song were Shi and Ci, respectively. Tang Shi and Song Ci
established crucial foundations of the Chinese literature, and their influences
in both literary works and daily lives of the Chinese communities last until
today.
  We can analyze and compare the Complete Tang Shi and the Complete Song Ci
from various viewpoints. In this presentation, we report our findings about the
differences in their vocabularies. Interesting new words that started to appear
in Song Ci and continue to be used in modern Chinese were identified. Colors
are an important ingredient of the imagery in poetry, and we discuss the most
frequent color words that appeared in Tang Shi and Song Ci.
</dc:description>
 <dc:description>Comment: 2016 International Conference on Digital Humanities</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07852</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07854</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantified Spectrum Sharing: Motivation, Approach, and Benefits</dc:title>
 <dc:creator>Khambekar, Nilesh</dc:creator>
 <dc:creator>Spooner, Chad</dc:creator>
 <dc:creator>Chaudhary, Vipin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  A significant portion of the radio frequency spectrum remains underutilized
with exclusive and static allocation of spectrum. The growing demand for
spectrum has spurred a need for dynamic spectrum sharing paradigm. While the
new dynamic spectrum sharing paradigm helps to improve utilization of the
precious spectrum resource, there exist several obstacles on the technical,
regulatory, and business fronts for the adoption of the new paradigm.
  In this paper, we investigate the limitations of the existing techniques and
argue for quantified approach to dynamic spectrum sharing and management. We
introduce a quantified approach to spectrum sharing based on defining and
enforcing quantified spectrum-access rights. By discretizing the spectrum-space
in the time, space, frequency dimensions, this approach enables quantifying the
spectrum consumed by individual transceivers. It enables defining and enforcing
a quantified spectrum-access policy in real-time. The proposed quantified
approach brings in simplicity, precision and efficiency in terms of spectrum
commerce and operations while addressing the key technical and regulatory
challenges.
</dc:description>
 <dc:description>Comment: In preparation to a conference</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07854</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07855</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Direct Proof of the Strong Hanani-Tutte Theorem on the Projective
  Plane</dc:title>
 <dc:creator>de Verdi&#xe8;re, &#xc9;ric Colin</dc:creator>
 <dc:creator>Kalu&#x17e;a, Vojt&#x11b;ch</dc:creator>
 <dc:creator>Pat&#xe1;k, Pavel</dc:creator>
 <dc:creator>Pat&#xe1;kov&#xe1;, Zuzana</dc:creator>
 <dc:creator>Tancer, Martin</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C10</dc:subject>
 <dc:description>  We reprove the strong Hanani-Tutte theorem on the projective plane. In
contrast to the previous proof by Pelsmajer, Schaefer and Stasi, our method is
constructive and does not rely on the characterization of forbidden minors,
which gives hope to extend it to other surfaces. Moreover, our approach can be
used to provide an efficient algorithm turning a Hanani-Tutte drawing on the
projective plane into an embedding.
</dc:description>
 <dc:description>Comment: This is the full version of the paper. Its extended abstract appeared
  in the Proceedings of the 24th International Symposium on Graph Drawing and
  Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07856</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing The Spatial Content Caching Distribution for Device-to-Device
  Communications</dc:title>
 <dc:creator>Malak, Derya</dc:creator>
 <dc:creator>Al-Shalash, Mazin</dc:creator>
 <dc:creator>Andrews, Jeffrey G.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We study the optimal geographic content placement problem for
device-to-device (D2D) networks in which the content popularity follows the
Zipf law. We consider a D2D caching model where the locations of the D2D users
(caches) are modeled by a Poisson point process (PPP) and have limited
communication range and finite storage. Unlike most related work which assumes
independent placement of content, and does not capture the locations of the
users, we model the spatial properties of the network including spatial
correlation in terms of the cached content. We propose two novel spatial
correlation models, the exchangeable content model and a Mat\'{e}rn (MHC)
content placement model, and analyze and optimize the \emph{hit probability},
which is the probability of a given D2D node finding a desired file at another
node within its communication range. We contrast these results to the
independent placement model, and show that exchangeable placement performs
worse. On the other hand, MHC placement yields a higher cache hit probability
than independent placement for small cache sizes.
</dc:description>
 <dc:description>Comment: appeared in Proc. IEEE Intl. Symposium on Info. Theory, Barcelona,
  Spain, July 2016</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07856</dc:identifier>
 <dc:identifier>doi:10.1109/ISIT.2016.7541305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07857</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Content Caching to Maximize the Density of Successful
  Receptions in Device-to-Device Networking</dc:title>
 <dc:creator>Malak, Derya</dc:creator>
 <dc:creator>Al-Shalash, Mazin</dc:creator>
 <dc:creator>Andrews, Jeffrey G.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Device-to-device (D2D) communication is a promising approach to optimize the
utilization of air interface resources in 5G networks, since it allows
decentralized opportunistic short-range communication. For D2D to be useful,
mobile nodes must possess content that other mobiles want. Thus, intelligent
caching techniques are essential for D2D. In this paper we use results from
stochastic geometry to derive the probability of successful content delivery in
the presence of interference and noise. We employ a general transmission
strategy where multiple files are cached at the users and different files can
be transmitted simultaneously throughout the network. We then formulate an
optimization problem, and find the caching distribution that maximizes the
density of successful receptions (DSR) under a simple transmission strategy
where a single file is transmitted at a time throughout the network. We model
file requests by a Zipf distribution with exponent $\gamma_r$, which results in
an optimal caching distribution that is also a Zipf distribution with exponent
$\gamma_c$, which is related to $\gamma_r$ through a simple expression
involving the path loss exponent. We solve the optimal content placement
problem for more general demand profiles under Rayleigh, Ricean and Nakagami
small-scale fading distributions. Our results suggest that it is required to
flatten the request distribution to optimize the caching performance. We also
develop strategies to optimize content caching for the more general case with
multiple files, and bound the DSR for that scenario.
</dc:description>
 <dc:description>Comment: published in IEEE Transactions on Communications, 2016</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07857</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2016.2600571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07872</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Opportunistic Execution for Integrating Security into Legacy
  Hard Real-Time Systems</dc:title>
 <dc:creator>Hasan, Monowar</dc:creator>
 <dc:creator>Mohan, Sibin</dc:creator>
 <dc:creator>Bobba, Rakesh B.</dc:creator>
 <dc:creator>Pellizzoni, Rodolfo</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Due to physical isolation as well as use of proprietary hardware and
protocols, traditional real-time systems (RTS) were considered to be
invulnerable to security breaches and external attacks. However, this
assumption is being challenged by recent attacks that highlight the
vulnerabilities in such systems. In this paper, we focus on integrating
security mechanisms into RTS (especially legacy RTS) and provide a metric to
measure the effectiveness of such mechanisms. We combine opportunistic
execution with hierarchical scheduling to maintain compatibility with legacy
systems while still providing flexibility. The proposed approach is shown to
increase the security posture of RTS systems without impacting their temporal
constraints.
</dc:description>
 <dc:description>Comment: Accepted for publication, IEEE RTSS 2016</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07876</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human Action Recognition without Human</dc:title>
 <dc:creator>He, Yun</dc:creator>
 <dc:creator>Shirakabe, Soma</dc:creator>
 <dc:creator>Satoh, Yutaka</dc:creator>
 <dc:creator>Kataoka, Hirokatsu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  The objective of this paper is to evaluate &quot;human action recognition without
human&quot;. Motion representation is frequently discussed in human action
recognition. We have examined several sophisticated options, such as dense
trajectories (DT) and the two-stream convolutional neural network (CNN).
However, some features from the background could be too strong, as shown in
some recent studies on human action recognition. Therefore, we considered
whether a background sequence alone can classify human actions in current
large-scale action datasets (e.g., UCF101).
  In this paper, we propose a novel concept for human action analysis that is
named &quot;human action recognition without human&quot;. An experiment clearly shows the
effect of a background sequence for understanding an action label.
</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07876</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07878</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TrueReview: A Platform for Post-Publication Peer Review</dc:title>
 <dc:creator>de Alfaro, Luca</dc:creator>
 <dc:creator>Faella, Marco</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In post-publication peer review, scientific contributions are first published
in open-access forums, such as arXiv or other digital libraries, and are
subsequently reviewed and possibly ranked and/or evaluated. Compared to the
classical process of scientific publishing, in which review precedes
publication, post-publication peer review leads to faster dissemination of
ideas, and publicly-available reviews. The chief concern in post-publication
reviewing consists in eliciting high-quality, insightful reviews from
participants.
  We describe the mathematical foundations and structure of TrueReview, an
open-source tool we propose to build in support of post-publication review. In
TrueReview, the motivation to review is provided via an incentive system that
promotes reviews and evaluations that are both truthful (they turn out to be
correct in the long run) and informative (they provide significant new
information). TrueReview organizes papers in venues, allowing different
scientific communities to set their own submission and review policies. These
venues can be manually set-up, or they can correspond to categories in
well-known repositories such as arXiv. The review incentives can be used to
form a reviewer ranking that can be prominently displayed alongside papers in
the various disciplines, thus offering a concrete benefit to reviewers. The
paper evaluations, in turn, reward the authors of the most significant papers,
both via an explicit paper ranking, and via increased visibility in search.
</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:date>2017-05-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07878</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07879</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Causality and Responsibility for Formal Verification and Beyond</dc:title>
 <dc:creator>Chockler, Hana</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The theory of actual causality, defined by Halpern and Pearl, and its
quantitative measure - the degree of responsibility - was shown to be extremely
useful in various areas of computer science due to a good match between the
results it produces and our intuition. In this paper, I describe the
applications of causality to formal verification, namely, explanation of
counterexamples, refinement of coverage metrics, and symbolic trajectory
evaluation. I also briefly discuss recent applications of causality to legal
reasoning.
</dc:description>
 <dc:description>Comment: In Proceedings CREST 2016, arXiv:1608.07398. Invited paper</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07879</dc:identifier>
 <dc:identifier>EPTCS 224, 2016, pp. 1-8</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.224.1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07880</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>(De-)Composing Causality in Labeled Transition Systems</dc:title>
 <dc:creator>Caltais, Georgiana</dc:creator>
 <dc:creator>Leue, Stefan</dc:creator>
 <dc:creator>Mousavi, Mohammad Reza</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In this paper we introduce a notion of counterfactual causality in the
Halpern and Pearl sense that is compositional with respect to the interleaving
of transition systems. The formal framework for reasoning on what caused the
violation of a safety property is established in the context of labeled
transition systems and Hennessy Milner logic. The compositionality results are
devised for non-communicating systems.
</dc:description>
 <dc:description>Comment: In Proceedings CREST 2016, arXiv:1608.07398</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07880</dc:identifier>
 <dc:identifier>EPTCS 224, 2016, pp. 10-24</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.224.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07881</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Debugging of Markov Decision Processes (MDPs) Models</dc:title>
 <dc:creator>Debbi, Hichem</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In model checking, a counterexample is considered as a valuable tool for
debugging. In Probabilistic Model Checking (PMC), counterexample generation has
a quantitative aspect. The counterexample in PMC is a set of paths in which a
path formula holds, and their accumulative probability mass violates the
probability threshold. However, understanding the counterexample is not an easy
task. In this paper we address the task of counterexample analysis for Markov
Decision Processes (MDPs). We propose an aided-diagnostic method for
probabilistic counterexamples based on the notions of causality, responsibility
and blame. Given a counterexample for a Probabilistic CTL (PCTL) formula that
does not hold over an MDP model, this method guides the user to the most
relevant parts of the model that led to the violation.
</dc:description>
 <dc:description>Comment: In Proceedings CREST 2016, arXiv:1608.07398</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07881</dc:identifier>
 <dc:identifier>EPTCS 224, 2016, pp. 25-39</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.224.4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07882</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Unified Model of Accountability Infrastructures</dc:title>
 <dc:creator>Kacianka, Severin</dc:creator>
 <dc:creator>Kelbert, Florian</dc:creator>
 <dc:creator>Pretschner, Alexander</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Accountability aims to provide explanations for why unwanted situations
occurred, thus providing means to assign responsibility and liability. As such,
accountability has slightly different meanings across the sciences. In computer
science, our focus is on providing explanations for technical systems, in
particular if they interact with their physical environment using sensors and
actuators and may do serious harm. Accountability is relevant when considering
safety, security and privacy properties and we realize that all these
incarnations are facets of the same core idea. Hence, in this paper we motivate
and propose a model for accountability infrastructures that is expressive
enough to capture all of these domains. At its core, this model leverages
formal causality models from the literature in order to provide a solid
reasoning framework. We show how this model can be instantiated for several
real-world use cases.
</dc:description>
 <dc:description>Comment: In Proceedings CREST 2016, arXiv:1608.07398</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07882</dc:identifier>
 <dc:identifier>EPTCS 224, 2016, pp. 40-54</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.224.5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07883</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fault Localization in Web Applications via Model Finding</dc:title>
 <dc:creator>Hall&#xe9;, Sylvain</dc:creator>
 <dc:creator>Beroual, Oussama</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We describe a generic technique for fault localization independent from the
nature of the object or the specification language used to declare its expected
properties. This technique is based on the concept of &quot;repair&quot;, a minimal set
of transformations which, when applied to the original object, restores its
satisfiability with respect to the specification. We show how this technique
can be applied with various specification languages, including propositional
and finite first-order logic. In particular, we focus on its use in the
detection of layout faults in web applications.
</dc:description>
 <dc:description>Comment: In Proceedings CREST 2016, arXiv:1608.07398</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07883</dc:identifier>
 <dc:identifier>EPTCS 224, 2016, pp. 55-67</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.224.6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07886</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incentives for Truthful Evaluations</dc:title>
 <dc:creator>de Alfaro, Luca</dc:creator>
 <dc:creator>Faella, Marco</dc:creator>
 <dc:creator>Polychronopoulos, Vassilis</dc:creator>
 <dc:creator>Shavlovsky, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider crowdsourcing problems where the users are asked to provide
evaluations for items; the user evaluations are then used directly, or
aggregated into a consensus value. Lacking an incentive scheme, users have no
motive in making effort in completing the evaluations, providing inaccurate
answers instead. We propose incentive schemes that are truthful and cheap:
truthful as the optimal user behavior consists in providing accurate
evaluations, and cheap because the truthfulness is achieved with little
overhead cost. We consider both discrete evaluation tasks, where an evaluation
can be done either correctly, or incorrectly, with no degrees of approximation
in between, and quantitative evaluation tasks, where evaluations are real
numbers, and the error is measured as distance from the correct value. For both
types of tasks, we propose hierarchical incentive schemes that can be effected
with a small amount of additional evaluations, and that scale to arbitrarily
large crowd sizes: they have the property that the strength of the incentive
does not weaken with increasing hierarchy depth. Interestingly, we show that
for these schemes to work, the only requisite is that workers know their place
in the hierarchy in advance.
</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:date>2017-05-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07888</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Monotone Optimization</dc:title>
 <dc:creator>Gemp, Ian</dc:creator>
 <dc:creator>Mahadevan, Sridhar</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper presents a new framework for analyzing and designing no-regret
algorithms for dynamic (possibly adversarial) systems. The proposed framework
generalizes the popular online convex optimization framework and extends it to
its natural limit allowing it to capture a notion of regret that is intuitive
for more general problems such as those encountered in game theory and
variational inequalities. The framework hinges on a special choice of a
system-wide loss function we have developed. Using this framework, we prove
that a simple update scheme provides a no-regret algorithm for monotone
systems. While previous results in game theory prove individual agents can
enjoy unilateral no-regret guarantees, our result proves monotonicity
sufficient for guaranteeing no-regret when considering the adjustments of
multiple agent strategies in parallel. Furthermore, to our knowledge, this is
the first framework to provide a suitable notion of regret for variational
inequalities. Most importantly, our proposed framework ensures monotonicity a
sufficient condition for employing multiple online learners safely in parallel.
</dc:description>
 <dc:description>Comment: 23 pages, 6 figures</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07888</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07891</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Non-stochastic Learning Approach to Energy Efficient Mobility
  Management</dc:title>
 <dc:creator>Shen, Cong</dc:creator>
 <dc:creator>Tekin, Cem</dc:creator>
 <dc:creator>van der Schaar, Mihaela</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Energy efficient mobility management is an important problem in modern
wireless networks with heterogeneous cell sizes and increased nodes densities.
We show that optimization-based mobility protocols cannot achieve long-term
optimal energy consumption, particularly for ultra-dense networks (UDN). To
address the complex dynamics of UDN, we propose a non-stochastic
online-learning approach which does not make any assumption on the statistical
behavior of the small base station (SBS) activities. In addition, we introduce
handover cost to the overall energy consumption, which forces the resulting
solution to explicitly minimize frequent handovers. The proposed Batched
Randomization with Exponential Weighting (BREW) algorithm relies on batching to
explore in bulk, and hence reduces unnecessary handovers. We prove that the
regret of BREW is sublinear in time, thus guaranteeing its convergence to the
optimal SBS selection. We further study the robustness of the BREW algorithm to
delayed or missing feedback. Moreover, we study the setting where SBSs can be
dynamically turned on and off. We prove that sublinear regret is impossible
with respect to arbitrary SBS on/off, and then develop a novel learning
strategy, called ranking expert (RE), that simultaneously takes into account
the handover cost and the availability of SBS. To address the high complexity
of RE, we propose a contextual ranking expert (CRE) algorithm that only assigns
experts in a given context. Rigorous regret bounds are proved for both RE and
CRE with respect to the best expert. Simulations show that not only do the
proposed mobility algorithms greatly reduce the system energy consumption, but
they are also robust to various dynamics which are common in practical
ultra-dense wireless networks.
</dc:description>
 <dc:description>Comment: 32 pages, 7 figures, to appear in JSAC special issue on Green
  Communications and Networking</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07891</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07892</identifier>
 <datestamp>2017-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Recurrent Neural Networks Architectures under Time
  Constraints</dc:title>
 <dc:creator>Jin, Junqi</dc:creator>
 <dc:creator>Yan, Ziang</dc:creator>
 <dc:creator>Fu, Kun</dc:creator>
 <dc:creator>Jiang, Nan</dc:creator>
 <dc:creator>Zhang, Changshui</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recurrent neural network (RNN)'s architecture is a key factor influencing its
performance. We propose algorithms to optimize hidden sizes under running time
constraint. We convert the discrete optimization into a subset selection
problem. By novel transformations, the objective function becomes submodular
and constraint becomes supermodular. A greedy algorithm with bounds is
suggested to solve the transformed problem. And we show how transformations
influence the bounds. To speed up optimization, surrogate functions are
proposed which balance exploration and exploitation. Experiments show that our
algorithms can find more accurate models or faster models than manually tuned
state-of-the-art and random search. We also compare popular RNN architectures
using our algorithms.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:date>2017-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07892</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07895</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human-Algorithm Interaction Biases in the Big Data Cycle: A Markov Chain
  Iterated Learning Framework</dc:title>
 <dc:creator>Nasraoui, Olfa</dc:creator>
 <dc:creator>Shafto, Patrick</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>K.4.m</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>H.1.2</dc:subject>
 <dc:description>  Early supervised machine learning algorithms have relied on reliable expert
labels to build predictive models. However, the gates of data generation have
recently been opened to a wider base of users who started participating
increasingly with casual labeling, rating, annotating, etc. The increased
online presence and participation of humans has led not only to a
democratization of unchecked inputs to algorithms, but also to a wide
democratization of the &quot;consumption&quot; of machine learning algorithms' outputs by
general users. Hence, these algorithms, many of which are becoming essential
building blocks of recommender systems and other information filters, started
interacting with users at unprecedented rates. The result is machine learning
algorithms that consume more and more data that is unchecked, or at the very
least, not fitting conventional assumptions made by various machine learning
algorithms. These include biased samples, biased labels, diverging training and
testing sets, and cyclical interaction between algorithms, humans, information
consumed by humans, and data consumed by algorithms. Yet, the continuous
interaction between humans and algorithms is rarely taken into account in
machine learning algorithm design and analysis. In this paper, we present a
preliminary theoretical model and analysis of the mutual interaction between
humans and algorithms, based on an iterated learning framework that is inspired
from the study of human language evolution. We also define the concepts of
human and algorithm blind spots and outline machine learning approaches to mend
iterated bias through two novel notions: antidotes and reactive learning.
</dc:description>
 <dc:description>Comment: This research was supported by National Science Foundation grant
  NSF-1549981</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07897</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using k-nearest neighbors to construct cancelable minutiae templates</dc:title>
 <dc:creator>Gao, Qinghai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Fingerprint is widely used in a variety of applications. Security measures
have to be taken to protect the privacy of fingerprint data. Cancelable
biometrics is proposed as an effective mechanism of using and protecting
biometrics. In this paper we propose a new method of constructing cancelable
fingerprint template by combining real template with synthetic template.
Specifically, each user is given one synthetic minutia template generated with
random number generator. Every minutia point from the real template is
individually thrown into the synthetic template, from which its k-nearest
neighbors are found. The verification template is constructed by combining an
arbitrary set of the k-nearest neighbors. To prove the validity of the scheme,
testing is carried out on three databases. The results show that the
constructed templates satisfy the requirements of cancelable biometrics.
</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07897</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07899</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diffusion in Networks and the Unexpected Virtue of Burstiness</dc:title>
 <dc:creator>Akbarpour, Mohammad</dc:creator>
 <dc:creator>Jackson, Matthew O.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Whether an idea, information, infection, or innovation diffuses throughout a
society depends not only on the structure of the network of interactions, but
also on the timing of those interactions. Recent studies have shown that
diffusion can fail on a network in which people are only active in &quot;bursts&quot;,
active for a while and then silent for a while, but diffusion could succeed on
the same network if people were active in a more random Poisson manner. Those
studies generally consider models in which nodes are active according to the
same random timing process and then ask which timing is optimal. In reality,
people differ widely in their activity patterns -- some are bursty and others
are not. Here we show that, if people differ in their activity patterns, bursty
behavior does not always hurt the diffusion, and in fact having some (but not
all) of the population be bursty significantly helps diffusion. We prove that
maximizing diffusion requires heterogeneous activity patterns across agents,
and the overall maximizing pattern of agents' activity times does not involve
any Poisson behavior.
</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07899</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07901</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Networks: An Economic Perspective</dc:title>
 <dc:creator>Jackson, Matthew O.</dc:creator>
 <dc:creator>Rogers, Brian W.</dc:creator>
 <dc:creator>Zenou, Yves</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Quantitative Finance - General Finance</dc:subject>
 <dc:description>  We discuss social network analysis from the perspective of economics. We
organize the presentaion around the theme of externalities: the effects that
one's behavior has on others' well-being. Externalities underlie the
interdependencies that make networks interesting. We discuss network formation,
as well as interactions between peoples' behaviors within a given network, and
the implications in a variety of settings. Finally, we highlight some empirical
challenges inherent in the statistical analysis of network-based data.
</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07901</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07905</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Comprehension Using Match-LSTM and Answer Pointer</dc:title>
 <dc:creator>Wang, Shuohang</dc:creator>
 <dc:creator>Jiang, Jing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Machine comprehension of text is an important problem in natural language
processing. A recently released dataset, the Stanford Question Answering
Dataset (SQuAD), offers a large number of real questions and their answers
created by humans through crowdsourcing. SQuAD provides a challenging testbed
for evaluating machine comprehension algorithms, partly because compared with
previous datasets, in SQuAD the answers do not come from a small set of
candidate answers and they have variable lengths. We propose an end-to-end
neural architecture for the task. The architecture is based on match-LSTM, a
model we proposed previously for textual entailment, and Pointer Net, a
sequence-to-sequence model proposed by Vinyals et al.(2015) to constrain the
output tokens to be from the input sequences. We propose two ways of using
Pointer Net for our task. Our experiments show that both of our two models
substantially outperform the best results obtained by Rajpurkar et al.(2016)
using logistic regression and manually crafted features.
</dc:description>
 <dc:description>Comment: 11 pages; 3 figures</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:date>2016-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07916</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vehicle Detection from 3D Lidar Using Fully Convolutional Network</dc:title>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Zhang, Tianlei</dc:creator>
 <dc:creator>Xia, Tian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Convolutional network techniques have recently achieved great success in
vision based detection tasks. This paper introduces the recent development of
our research on transplanting the fully convolutional network technique to the
detection tasks on 3D range scan data. Specifically, the scenario is set as the
vehicle detection task from the range data of Velodyne 64E lidar. We proposes
to present the data in a 2D point map and use a single 2D end-to-end fully
convolutional network to predict the objectness confidence and the bounding
boxes simultaneously. By carefully design the bounding box encoding, it is able
to predict full 3D bounding boxes even using a 2D convolutional network.
Experiments on the KITTI dataset shows the state-of-the-art performance of the
proposed method.
</dc:description>
 <dc:description>Comment: Robotics: Science and Systems, 2016</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07923</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recent Results on Fault-Tolerant Consensus in Message-Passing Networks</dc:title>
 <dc:creator>Tseng, Lewis</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Fault-tolerant consensus has been studied extensively in the literature,
because it is one of the most important distributed primitives and has wide
applications in practice. This paper surveys important results on
fault-tolerant consensus in message-passing networks, and the focus is on
results from the past decade. Particularly, we categorize the results into two
groups: new problem formulations and practical applications. In the first part,
we discuss new ways to define the consensus problem, which includes larger
input domains, link fault models, different network models . . . etc, and
briefly discuss the important techniques. In the second part, we focus on Crash
Fault-Tolerant (CFT) systems that use Paxos or Raft, and Byzantine
Fault-Tolerant (BFT) systems. We also discuss Bitcoin, which can be related to
solving Byzantine consensus in anonymous systems, and compare Bitcoin with BFT
systems and Byzantine consensus.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07923</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07929</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering Patterns in Time-Varying Graphs: A Triclustering Approach</dc:title>
 <dc:creator>Guigour&#xe8;s, Romain</dc:creator>
 <dc:creator>Boull&#xe9;, Marc</dc:creator>
 <dc:creator>Rossi, Fabrice</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  This paper introduces a novel technique to track structures in time varying
graphs. The method uses a maximum a posteriori approach for adjusting a
three-dimensional co-clustering of the source vertices, the destination
vertices and the time, to the data under study, in a way that does not require
any hyper-parameter tuning. The three dimensions are simultaneously segmented
in order to build clusters of source vertices, destination vertices and time
segments where the edge distributions across clusters of vertices follow the
same evolution over the time segments. The main novelty of this approach lies
in that the time segments are directly inferred from the evolution of the edge
distribution between the vertices, thus not requiring the user to make any a
priori quantization. Experiments conducted on artificial data illustrate the
good behavior of the technique, and a study of a real-life data set shows the
potential of the proposed approach for exploratory data analysis.
</dc:description>
 <dc:description>Comment: Advances in Data Analysis and Classification, Springer Verlag, 2015,
  Online First</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07929</dc:identifier>
 <dc:identifier>doi:10.1007/s11634-015-0218-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07934</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relevant based structure learning for feature selection</dc:title>
 <dc:creator>Zare, Hadi</dc:creator>
 <dc:creator>Niazi, Mojtaba</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Feature selection is an important task in many problems occurring in pattern
recognition, bioinformatics, machine learning and data mining applications. The
feature selection approach enables us to reduce the computation burden and the
falling accuracy effect of dealing with huge number of features in typical
learning problems. There is a variety of techniques for feature selection in
supervised learning problems based on different selection metrics. In this
paper, we propose a novel unified framework for feature selection built on the
graphical models and information theoretic tools. The proposed approach
exploits the structure learning among features to select more relevant and less
redundant features to the predictive modeling problem according to a primary
novel likelihood based criterion. In line with the selection of the optimal
subset of features through the proposed method, it provides us the Bayesian
network classifier without the additional cost of model training on the
selected subset of features. The optimal properties of our method are
established through empirical studies and computational complexity analysis.
Furthermore the proposed approach is evaluated on a bunch of benchmark datasets
based on the well-known classification algorithms. Extensive experiments
confirm the significant improvement of the proposed approach compared to the
earlier works.
</dc:description>
 <dc:description>Comment: 29 pages, 11 figures</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07934</dc:identifier>
 <dc:identifier>Eng. Appl. Artif. Intel. 55 (2016) 93-102</dc:identifier>
 <dc:identifier>doi:10.1016/j.engappai.2016.06.001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07949</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning-Based Resource Allocation Scheme for TDD-Based CRAN System</dc:title>
 <dc:creator>Imtiaz, Sahar</dc:creator>
 <dc:creator>Ghauch, Hadi</dc:creator>
 <dc:creator>Rahman, M. Mahboob Ur</dc:creator>
 <dc:creator>Koudouridis, George</dc:creator>
 <dc:creator>Gross, James</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Explosive growth in the use of smart wireless devices has necessitated the
provision of higher data rates and always-on connectivity, which are the main
motivators for designing the fifth generation (5G) systems. To achieve higher
system efficiency, massive antenna deployment with tight coordination is one
potential strategy for designing 5G systems, but has two types of associated
system overhead. First is the synchronization overhead, which can be reduced by
implementing a cloud radio access network (CRAN)-based architecture design,
that separates the baseband processing and radio access functionality to
achieve better system synchronization. Second is the overhead for acquiring
channel state information (CSI) of the users present in the system, which,
however, increases tremendously when instantaneous CSI is used to serve
high-mobility users. To serve a large number of users, a CRAN system with a
dense deployment of remote radio heads (RRHs) is considered, such that each
user has a line-of-sight (LOS) link with the corresponding RRH. Since, the
trajectory of movement for high-mobility users is predictable; therefore,
fairly accurate position estimates for those users can be obtained, and can be
used for resource allocation to serve the considered users. The resource
allocation is dependent upon various correlated system parameters, and these
correlations can be learned using well-known \emph{machine learning}
algorithms. This paper proposes a novel \emph{learning-based resource
allocation scheme} for time division duplex (TDD) based 5G CRAN systems with
dense RRH deployment, by using only the users' position estimates for resource
allocation, thus avoiding the need for CSI acquisition. This reduces the
overall system overhead significantly, while still achieving near-optimal
system performance; thus, better (effective) system efficiency is achieved.
(See the paper for full abstract)
</dc:description>
 <dc:description>Comment: 10 pages, 9 figures, accepted for publication in MSWiM 2016</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07949</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07951</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approaching the Computational Color Constancy as a Classification
  Problem through Deep Learning</dc:title>
 <dc:creator>Oh, Seoung Wug</dc:creator>
 <dc:creator>Kim, Seon Joo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Computational color constancy refers to the problem of computing the
illuminant color so that the images of a scene under varying illumination can
be normalized to an image under the canonical illumination. In this paper, we
adopt a deep learning framework for the illumination estimation problem. The
proposed method works under the assumption of uniform illumination over the
scene and aims for the accurate illuminant color computation. Specifically, we
trained the convolutional neural network to solve the problem by casting the
color constancy problem as an illumination classification problem. We designed
the deep learning architecture so that the output of the network can be
directly used for computing the color of the illumination. Experimental results
show that our deep network is able to extract useful features for the
illumination estimation and our method outperforms all previous color constancy
methods on multiple test datasets.
</dc:description>
 <dc:description>Comment: This is a preprint of an article accepted for publication in Pattern
  Recognition, ELSEVIER</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07951</dc:identifier>
 <dc:identifier>Pattern Recognition, Volume 61, January 2017, Pages 405 to 416</dc:identifier>
 <dc:identifier>doi:10.1016/j.patcog.2016.08.013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07952</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topical Generalization for Presentation of User Profiles</dc:title>
 <dc:creator>Olieman, Alex</dc:creator>
 <dc:creator>Kamps, Jaap</dc:creator>
 <dc:creator>Satyukov, Gleb</dc:creator>
 <dc:creator>de Valk, Emil</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Fine-grained user profile generation approaches have made it increasingly
feasible to display on a profile page in which topics a user has expertise or
interest. Earlier work on topical user profiling has been directed at enhancing
search and personalization functionality, but making such profiles useful for
human consumption presents new challenges. With this work, we have taken a
first step toward a semantic layout mode for topical user profiles. We have
developed a topical generalization approach which finds coherent groups of
topics and adds labels to them, based on their association with broader topics
in the Wikipedia category graph. A nested layout mode, employing topical
generalization, is compared with a simpler flat layout mode in our user study.
The results indicate that users favor the nested structure over flat profiles,
but tend to overlook the specific topics on the lower level. We propose a third
layout mode to address this issue.
</dc:description>
 <dc:description>Comment: (to be) presented at DIR'16, November 25, 2016, Delft, The
  Netherlands</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07952</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07953</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coexistence of OFDM and FBMC for Underlay D2D Communication in 5G
  Networks</dc:title>
 <dc:creator>Sexton, Conor</dc:creator>
 <dc:creator>Bodinier, Quentin</dc:creator>
 <dc:creator>Farhang, Arman</dc:creator>
 <dc:creator>Marchetti, Nicola</dc:creator>
 <dc:creator>Bader, Faouzi</dc:creator>
 <dc:creator>DaSilva, Luiz A.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Device-to-device (D2D) communication is being heralded as an important part
of the solution to the capacity problem in future networks, and is expected to
be natively supported in 5G. Given the high network complexity and required
signalling overhead associated with achieving synchronization in D2D networks,
it is necessary to study asynchronous D2D communications. In this paper, we
consider a scenario whereby asynchronous D2D communication underlays an OFDMA
macro-cell in the uplink. Motivated by the superior performance of new
waveforms with increased spectral localization in the presence of frequency and
time misalignments, we compare the system-level performance of a set-up for
when D2D pairs use either OFDM or FBMC/OQAM. We first demonstrate that
inter-D2D interference, resulting from misaligned communications, plays a
significant role in clustered D2D topologies. We then demonstrate that the
resource allocation procedure can be simplified when D2D pairs use FBMC/OQAM,
since the high spectral localization of FBMC/OQAM results in negligible
inter-D2D interference. Specifically, we identify that FBMC/OQAM is best suited
to scenarios consisting of small, densely populated D2D clusters located near
the encompassing cell's edge.
</dc:description>
 <dc:description>Comment: 7 pages, 9 figures, Accepted at IEEE Globecom 2016 Workshops</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07953</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07955</identifier>
 <datestamp>2017-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Magnetic skyrmion-based synaptic devices</dc:title>
 <dc:creator>Huang, Yangqi</dc:creator>
 <dc:creator>Kang, Wang</dc:creator>
 <dc:creator>Zhang, Xichao</dc:creator>
 <dc:creator>Zhou, Yan</dc:creator>
 <dc:creator>Zhao, Weisheng</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Condensed Matter - Strongly Correlated Electrons</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Magnetic skyrmions are promising candidates for next-generation information
carriers, owing to their small size, topological stability, and ultralow
depinning current density. A wide variety of skyrmionic device concepts and
prototypes have been proposed, highlighting their potential applications. Here,
we report on a bioinspired skyrmionic device with synaptic plasticity. The
synaptic weight of the proposed device can be strengthened/weakened by
positive/negative stimuli, mimicking the potentiation/depression process of a
biological synapse. Both short-term plasticity(STP) and long-term
potentiation(LTP) functionalities have been demonstrated for a spiking
time-dependent plasticity(STDP) scheme. This proposal suggests new
possibilities for synaptic devices for use in spiking neuromorphic computing
applications.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07955</dc:identifier>
 <dc:identifier>Nanotechnology 28, 08LT02 (2017)</dc:identifier>
 <dc:identifier>doi:10.1088/1361-6528/aa5838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07960</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Which early works are cited most frequently in climate change research
  literature? A bibliometric approach based on Reference Publication Year
  Spectroscopy</dc:title>
 <dc:creator>Marx, Werner</dc:creator>
 <dc:creator>Haunschild, Robin</dc:creator>
 <dc:creator>Thor, Andreas</dc:creator>
 <dc:creator>Bornmann, Lutz</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  This bibliometric analysis focuses on the general history of climate change
research and, more specifically, on the discovery of the greenhouse effect.
First, the Reference Publication Year Spectroscopy (RPYS) is applied to a large
publication set on climate change of 222,060 papers published between 1980 and
2014. The references cited therein were extracted and analyzed with regard to
publications, which are cited most frequently. Second, a new method for
establishing a more subject-specific publication set for applying RPYS (based
on the co-citations of a marker reference) is proposed (RPYS-CO). The RPYS of
the climate change literature focuses on the history of climate change research
in total. We identified 35 highly-cited publications across all disciplines,
which include fundamental early scientific works of the 19th century (with a
weak connection to climate change) and some cornerstones of science with a
stronger connection to climate change. By using the Arrhenius (1896) paper as a
RPYS-CO marker paper, we selected only publications specifically discussing the
discovery of the greenhouse effect and the role of carbon dioxide. Also, we
focused on the time period 1800-1850 to reveal the contributions of J.B.J
Fourier in terms of cited references. Using different RPYS approaches in this
study, we were able to identify the complete range of works of the celebrated
icons as well as many less known works relevant for the history of climate
change research. The analyses confirmed the potential of the RPYS method for
historical studies: Seminal papers are detected on the basis of the references
cited by the overall community without any further assumptions.
</dc:description>
 <dc:description>Comment: in press at Scientometrics</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2016-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07960</dc:identifier>
 <dc:identifier>doi:10.1007/s11192-016-2115-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07965</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Physical Layer Security in MIMO Backscatter Wireless Systems</dc:title>
 <dc:creator>Yang, Qian</dc:creator>
 <dc:creator>Wang, Hui-Ming</dc:creator>
 <dc:creator>Zhang, Yi</dc:creator>
 <dc:creator>Han, Zhu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Backscatter wireless communication is an emerging technique widely used in
low-cost and low-power wireless systems, especially in passive radio frequency
identification (RFID) systems. Recently, the requirement of high data rates,
data reliability, and security drives the development of RFID systems, which
motivates our investigation on the physical layer security of a multiple-input
multiple-output (MIMO) RFID system. In this paper, we propose a noise-injection
precoding strategy to safeguard the system security with the
resource-constrained nature of the backscatter system taken into consideration.
We first consider a multi-antenna RFID tag case and investigate the secrecy
rate maximization (SRM) problem by jointly optimizing the energy supply power
and the precoding matrix of the injected artificial noise at the RFID reader.
We exploit the alternating optimization method and the sequential parametric
convex approximation method, respectively, to tackle the non-convex SRM problem
and show an interesting fact that the two methods are actually equivalent for
our SRM problem with the convergence of a Karush-Kuhn-Tucker (KKT) point. To
facilitate the practical implementation for resource-constrained RFID devices,
we propose a fast algorithm based on projected gradient. We also consider a
single-antenna RFID tag case and develop a low-complexity algorithm which
yields the global optimal solution. Simulation results show the superiority of
our proposed algorithms in terms of the secrecy rate and computational
complexity.
</dc:description>
 <dc:description>Comment: 14 pages, 5 figures, accepted for publication on IEEE Transactions on
  Wireless Communications</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07965</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2016.2604800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07973</identifier>
 <datestamp>2017-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linking Image and Text with 2-Way Nets</dc:title>
 <dc:creator>Eisenschtat, Aviv</dc:creator>
 <dc:creator>Wolf, Lior</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Linking two data sources is a basic building block in numerous computer
vision problems. Canonical Correlation Analysis (CCA) achieves this by
utilizing a linear optimizer in order to maximize the correlation between the
two views. Recent work makes use of non-linear models, including deep learning
techniques, that optimize the CCA loss in some feature space. In this paper, we
introduce a novel, bi-directional neural network architecture for the task of
matching vectors from two data sources. Our approach employs two tied neural
network channels that project the two views into a common, maximally correlated
space using the Euclidean loss. We show a direct link between the
correlation-based loss and Euclidean loss, enabling the use of Euclidean loss
for correlation maximization. To overcome common Euclidean regression
optimization problems, we modify well-known techniques to our problem,
including batch normalization and dropout. We show state of the art results on
a number of computer vision matching tasks including MNIST image matching and
sentence-image matching on the Flickr8k, Flickr30k and COCO datasets.
</dc:description>
 <dc:description>Comment: 14 pages, 2 figures, 6 tables</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2017-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07973</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07981</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Parallel Processing of Big Data Using Order-Preserving Encryption
  on Google BigQuery</dc:title>
 <dc:creator>Schindler, Timo</dc:creator>
 <dc:creator>Skornia, Christoph</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  With the increase of centralization of resources in IT-infrastructure and the
growing amount of cloud services, database management systems (DBMS) will be
more and more outsourced to Infrastructure-as-a-Service (IaaS) providers. The
outsourcing of entire databases, or the computation power for processing Big
Data to an external provider also means that the provider has full access to
the information contained in the database. In this article we propose a
feasible solution with Order-Preserving Encryption (OPE) and further, state of
the art, encryption methods to sort and process Big Data on external resources
without exposing the unencrypted data to the IaaS provider. We also introduce a
proof-of-concept client for Google BigQuery as example IaaS Provider.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures, 1 table, Paper for conference: GI Informatik
  2016, Klagenfurt, Heinrich C. Mayr, Martin Pinzger (Hrsg.): INFORMATIK 2016.
  Lecture Notes in Informatics (LNI), Volume P-259, GI Bonn 2016. date of
  publication: 26.09.2016, ISBN 978-3-88579-653-4, ISSN 1617-5468</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07989</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MIMO Cellular Networks with Simultaneous Wireless Information and Power
  Transfer</dc:title>
 <dc:creator>Tu, Lam Thanh</dc:creator>
 <dc:creator>Di Renzo, Marco</dc:creator>
 <dc:creator>Coon, Justin P.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we introduce a mathematical approach for system-level analysis
and optimization of densely deployed multiple-antenna cellular networks, where
low-energy devices are capable of decoding information data and harvesting
power simultaneously. The base stations are assumed to be deployed according to
a Poisson point process and tools from stochastic geometry are exploited to
quantify the trade-off in terms of information rate and harvested power. It is
shown that multiple-antenna transmission is capable of increasing information
rate and harvested power at the same time.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.07997</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correspondence Insertion for As-Projective-As-Possible Image Stitching</dc:title>
 <dc:creator>Liu, William X.</dc:creator>
 <dc:creator>Chin, Tat-Jun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Spatially varying warps are increasingly popular for image alignment. In
particular, as-projective-as-possible (APAP) warps have been proven effective
for accurate panoramic stitching, especially in cases with significant depth
parallax that defeat standard homographic warps. However, estimating spatially
varying warps requires a sufficient number of feature matches. In image regions
where feature detection or matching fail, the warp loses guidance and is unable
to accurately model the true underlying warp, thus resulting in poor
registration. In this paper, we propose a correspondence insertion method for
APAP warps, with a focus on panoramic stitching. Our method automatically
identifies misaligned regions, and inserts appropriate point correspondences to
increase the flexibility of the warp and improve alignment. Unlike other warp
varieties, the underlying projective regularization of APAP warps reduces
overfitting and geometric distortion, despite increases to the warp complexity.
Comparisons with recent techniques for parallax-tolerant image stitching
demonstrate the effectiveness and simplicity of our approach.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.07997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08014</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal QoS-Aware Channel Assignment in D2D Communications with Partial
  CSI</dc:title>
 <dc:creator>Wang, Rui</dc:creator>
 <dc:creator>Zhang, Jun</dc:creator>
 <dc:creator>Song, S. H.</dc:creator>
 <dc:creator>Letaief, Khaled B.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose effective channel assignment algorithms for network
utility maximization in a cellular network with underlaying device-to-device
(D2D) communications. A major innovation is the consideration of partial
channel state information (CSI), i.e., the base station (BS) is assumed to be
able to acquire `partial' instantaneous CSI of the cellular and D2D links, as
well as, the interference links. In contrast to existing works, multiple D2D
links are allowed to share the same channel, and the quality of service (QoS)
requirements for both the cellular and D2D links are enforced. We first develop
an optimal channel assignment algorithm based on dynamic programming (DP),
which enjoys a much lower complexity compared to exhaustive search and will
serve as a performance benchmark. To further reduce complexity, we propose a
cluster-based sub-optimal channel assignment algorithm. New closed-form
expressions for the expected weighted sum-rate and the successful transmission
probabilities are also derived. Simulation results verify the effectiveness of
the proposed algorithms. Moreover, by comparing different partial CSI
scenarios, we observe that the CSI of the D2D communication links and the
interference links from the D2D transmitters to the BS significantly affects
the network performance, while the CSI of the interference links from the BS to
the D2D receivers only has a negligible impact.
</dc:description>
 <dc:description>Comment: 16 pages, 13 figures, to appear in IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08015</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Event Selection Rules to Compute Explanations</dc:title>
 <dc:creator>Prud'homme, Charles</dc:creator>
 <dc:creator>Lorca, Xavier</dc:creator>
 <dc:creator>Jussien, Narendra</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Explanations have been introduced in the previous century. Their interest in
reducing the search space is no longer questioned. Yet, their efficient
implementation into CSP solver is still a challenge. In this paper, we
introduce ESeR, an Event Selection Rules algorithm that filters events
generated during propagation. This dynamic selection enables an efficient
computation of explanations for intelligent backtracking al- gorithms. We show
the effectiveness of our approach on the instances of the last three MiniZinc
challenges
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08020</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Breaching the Privacy of Israel's Paper Ballot Voting System</dc:title>
 <dc:creator>Ashur, Tomer</dc:creator>
 <dc:creator>Dunkelman, Orr</dc:creator>
 <dc:creator>Talmon, Nimrod</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>94A60</dc:subject>
 <dc:description>  An election is a process through which citizens in liberal democracies select
their governing bodies, usually through voting. For elections to be truly
honest, people must be able to vote freely without being subject to coercion;
that is why voting is usually done in a private manner. In this paper we
analyze the security offered by a paper-ballot voting system that is used in
Israel, as well as in several other countries around the world. we provide an
algorithm which, based on publicly available information, breaks the privacy of
the voters participating in such elections. Simulations based on real data
collected in Israel show that our algorithm performs well, and can correctly
recover the vote of up to 96% of the voters.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08021</identifier>
 <datestamp>2016-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PVANET: Deep but Lightweight Neural Networks for Real-time Object
  Detection</dc:title>
 <dc:creator>Kim, Kye-Hyeon</dc:creator>
 <dc:creator>Hong, Sanghoon</dc:creator>
 <dc:creator>Roh, Byungseok</dc:creator>
 <dc:creator>Cheon, Yeongjae</dc:creator>
 <dc:creator>Park, Minje</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents how we can achieve the state-of-the-art accuracy in
multi-category object detection task while minimizing the computational cost by
adapting and combining recent technical innovations. Following the common
pipeline of &quot;CNN feature extraction + region proposal + RoI classification&quot;, we
mainly redesign the feature extraction part, since region proposal part is not
computationally expensive and classification part can be efficiently compressed
with common techniques like truncated SVD. Our design principle is &quot;less
channels with more layers&quot; and adoption of some building blocks including
concatenated ReLU, Inception, and HyperNet. The designed network is deep and
thin and trained with the help of batch normalization, residual connections,
and learning rate scheduling based on plateau detection. We obtained solid
results on well-known object detection benchmarks: 83.8% mAP (mean average
precision) on VOC2007 and 82.5% mAP on VOC2012 (2nd place), while taking only
750ms/image on Intel i7-6700K CPU with a single core and 46ms/image on NVIDIA
Titan X GPU. Theoretically, our network requires only 12.3% of the
computational cost compared to ResNet-101, the winner on VOC2012.
</dc:description>
 <dc:description>Comment: Full details about &quot;PVANet 9.0&quot; in the VOC2012 leaderboard
  (https://goo.gl/DuQBku). The test codes are available at
  https://github.com/sanghoon/pva-faster-rcnn</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2016-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08027</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crossing Minimization in Storyline Visualization</dc:title>
 <dc:creator>Gronemann, Martin</dc:creator>
 <dc:creator>J&#xfc;nger, Michael</dc:creator>
 <dc:creator>Liers, Frauke</dc:creator>
 <dc:creator>Mambelli, Francesco</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A storyline visualization is a layout that represents the temporal dynamics
of social interactions along time by the convergence of chronological lines.
Among the criteria oriented at improving aesthetics and legibility of a
representation of this type, a small number of line crossings is the hardest to
achieve. We model the crossing minimization in the storyline visualization
problem as a multi-layer crossing minimization problem with tree constraints.
Our algorithm can compute a layout with the minimum number of crossings of the
chronological lines. Computational results demonstrate that it can solve
instances with more than 100 interactions and with more than 100 chronological
lines to optimality.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08028</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Deterministic ODEs to Dynamic Structural Causal Models</dc:title>
 <dc:creator>Rubenstein, Paul K.</dc:creator>
 <dc:creator>Bongers, Stephan</dc:creator>
 <dc:creator>Mooij, Joris M.</dc:creator>
 <dc:creator>Schoelkopf, Bernhard</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We show how, under certain conditions, the asymptotic behaviour of an
Ordinary Differential Equation under non-constant interventions can be modelled
using Dynamic Structural Causal Models. In contrast to earlier work, we study
not only the effect of interventions on equilibrium states; rather, we model
asymptotic behaviour that is dynamic under interventions that vary in time, and
include as a special case the study of static equilibria.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08029</identifier>
 <datestamp>2017-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Edge Preserving and Multi-Scale Contextual Neural Network for Salient
  Object Detection</dc:title>
 <dc:creator>Wang, Xiang</dc:creator>
 <dc:creator>Ma, Huimin</dc:creator>
 <dc:creator>Chen, Xiaozhi</dc:creator>
 <dc:creator>You, Shaodi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a novel edge preserving and multi-scale contextual
neural network for salient object detection. The proposed framework is aiming
to address two limits of the existing CNN based methods. First, region-based
CNN methods lack sufficient context to accurately locate salient object since
they deal with each region independently. Second, pixel-based CNN methods
suffer from blurry boundaries due to the presence of convolutional and pooling
layers. Motivated by these, we first propose an end-to-end edge-preserved
neural network based on Fast R-CNN framework (named RegionNet) to efficiently
generate saliency map with sharp object boundaries. Later, to further improve
it, multi-scale spatial context is attached to RegionNet to consider the
relationship between regions and the global scenes. Furthermore, our method can
be generally applied to RGB-D saliency detection by depth refinement. The
proposed framework achieves both clear detection boundary and multi-scale
contextual robustness simultaneously for the first time, and thus achieves an
optimized performance. Experiments on six RGB and two RGB-D benchmark datasets
demonstrate that the proposed method achieves state-of-the-art performance.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2017-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08029</dc:identifier>
 <dc:identifier>IEEE TIP 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2017.2756825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08033</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fuzzy Logic in Narrow Sense with Hedges</dc:title>
 <dc:creator>Le, Van Hung</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Classical logic has a serious limitation in that it cannot cope with the
issues of vagueness and uncertainty into which fall most modes of human
reasoning. In order to provide a foundation for human knowledge representation
and reasoning in the presence of vagueness, imprecision, and uncertainty, fuzzy
logic should have the ability to deal with linguistic hedges, which play a very
important role in the modification of fuzzy predicates. In this paper, we
extend fuzzy logic in narrow sense with graded syntax, introduced by Novak et
al., with many hedge connectives. In one case, each hedge does not have any
dual one. In the other case, each hedge can have its own dual one. The
resulting logics are shown to also have the Pavelka-style completeness
</dc:description>
 <dc:description>Comment: 10 pages, International Journal of Computer Science &amp; Information
  Technology (IJCSIT) Vol 8, No 3, June 2016</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08033</dc:identifier>
 <dc:identifier>doi:10.5121/ijcsit.2016.8310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08041</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A short review and primer on electromyography in human computer
  interaction applications</dc:title>
 <dc:creator>Ravaja, Niklas</dc:creator>
 <dc:creator>Cowley, Benjamin</dc:creator>
 <dc:creator>Torniainen, Jari</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The application of psychophysiology in human-computer interaction is a
growing field with significant potential for future smart personalised systems.
Working in this emerging field requires comprehension of an array of
physiological signals and analysis techniques.
  Electromyography (EMG) is a useful signal to estimate the emotional context
of individuals, because it is relatively robust, and simple to record and
analyze. Common uses are to infer emotional valence in response to a stimulus,
and to index some symptoms of stress. However, in order to interpret EMG
signals, they must be considered alongside data on physical, social and
intentional context. Here we present a short review on the application of EMG
in human-computer interaction.
  This paper aims to serve as a primer for the novice, enabling rapid
familiarisation with the latest core concepts. We put special emphasis on
everyday human-computer interface applications to distinguish from the more
common clinical or sports uses of psychophysiology.
  This paper is an extract from a comprehensive review of the entire field of
ambulatory psychophysiology, including 12 similar chapters, plus application
guidelines and systematic review. Thus any citation should be made using the
following reference:
  B. Cowley, M. Filetti, K. Lukander, J. Torniainen, A. Henelius, L. Ahonen, O.
Barral, I. Kosunen, T. Valtonen, M. Huotilainen, N. Ravaja, G. Jacucci. The
Psychophysiology Primer: a guide to methods and a broad review with a focus on
human-computer interaction. Foundations and Trends in Human-Computer
Interaction, vol. 9, no. 3-4, pp. 150--307, 2016.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures. Part of a journal</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08042</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectrum Investment under Uncertainty: A Behavioral Economics
  Perspective</dc:title>
 <dc:creator>Yu, Junlin</dc:creator>
 <dc:creator>Cheung, Man Hon</dc:creator>
 <dc:creator>Huang, Jianwei</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In this paper, we study a virtual wireless operator's spectrum investment
problem under spectrum supply uncertainty. To obtain enough spectrum resources
to meet its customer demands, the virtual operator can either sense for the
temporarily unused spectrum in a licensed band, or lease spectrum from a
spectrum owner. Sensing is usually cheaper than leasing, but the amount of
available spectrum obtained by sensing is uncertain due to the primary users'
activities in the licensed band. Previous studies on spectrum investment
problems mainly considered the expected profit maximization problem of a
risk-neutral operator based on the expected utility theory (EUT). In reality,
however, an operator's decision is influenced by not only the consideration of
expected profit maximization, but also the level of its risk preference. To
capture this tradeoff between these two considerations, we analyze the
operator's optimal decision problem using the prospect theory from behavioral
economics, which includes EUT as a special case. The sensing and leasing
optimal problem under prospect theory is non-convex and challenging to solve.
Nevertheless, by exploiting the unimodal structure of the problem, we are able
to compute the unique global optimal solution. We show that comparing to an EUT
operator, both the risk-averse and risk-seeking operator achieve a smaller
expected profit. On the other hand, a risk-averse operator can guarantee a
larger minimum possible profit, while a risk-seeking operator can achieve a
larger maximum possible profit. Furthermore, the tradeoff between the expected
profit and the minimum possible profit for a risk-averse operator is better
when the sensing cost increases, while the tradeoff between the expected profit
and the maximum possible profit for a risk-seeking operator is better when the
sensing cost decreases.
</dc:description>
 <dc:description>Comment: 15 pages, 5 figures, accepted by JSAC SI-Spectrum Sharing</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08047</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonlinear Model Reduction in Power Systems by Balancing of Empirical
  Controllability and Observability Covariances</dc:title>
 <dc:creator>Qi, Junjian</dc:creator>
 <dc:creator>Wang, Jianhui</dc:creator>
 <dc:creator>Liu, Hui</dc:creator>
 <dc:creator>Dimitrovski, Aleksandar D.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, nonlinear model reduction for power systems is performed by
the balancing of empirical controllability and observability covariances that
are calculated around the operating region. Unlike existing model reduction
methods, the external system does not need to be linearized but is directly
dealt with as a nonlinear system. A transformation is found to balance the
controllability and observability covariances in order to determine which
states have the greatest contribution to the input-output behavior. The
original system model is then reduced by Galerkin projection based on this
transformation. The proposed method is tested and validated on a system
comprised of a 16-machine 68-bus system and an IEEE 50-machine 145-bus system.
The results show that by using the proposed model reduction the calculation
efficiency can be greatly improved; at the same time, the obtained state
trajectories are close to those for directly simulating the whole system or
partitioning the system while not performing reduction. Compared with the
balanced truncation method based on a linearized model, the proposed nonlinear
model reduction method can guarantee higher accuracy and similar calculation
efficiency. It is shown that the proposed method is not sensitive to the choice
of the matrices for calculating the empirical covariances.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Transactions on Power Systems</dc:description>
 <dc:date>2016-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08047</dc:identifier>
 <dc:identifier>doi:10.1109/TPWRS.2016.2557760</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08049</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Curvature Integration in a 5D Kernel for Extracting Vessel Connections
  in Retinal Images</dc:title>
 <dc:creator>Abbasi-Sureshjani, Samaneh</dc:creator>
 <dc:creator>Favali, Marta</dc:creator>
 <dc:creator>Citti, Giovanna</dc:creator>
 <dc:creator>Sarti, Alessandro</dc:creator>
 <dc:creator>Romeny, Bart M. ter Haar</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Tree-like structures such as retinal images are widely studied in
computer-aided diagnosis systems for large-scale screening programs. Despite
several segmentation and tracking methods proposed in the literature, there
still exist several limitations specifically when two or more curvilinear
structures cross or bifurcate, or in the presence of interrupted lines or
highly curved blood vessels. In this paper, we propose a novel approach based
on multi-orientation scores augmented with a contextual affinity matrix, which
both are inspired by the geometry of the primary visual cortex (V1) and their
contextual connections. The connectivity is described with a five-dimensional
kernel obtained as the fundamental solution of the Fokker-Planck equation
modelling the cortical connectivity in the lifted space of positions,
orientations, curvatures and intensity. It is further used in a self-tuning
spectral clustering step to identify the main perceptual units in the stimuli.
The proposed method has been validated on several easy and challenging
structures in a set of artificial images and actual retinal patches. Supported
by quantitative and qualitative results, the method is capable of overcoming
the limitations of current state-of-the-art techniques.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2017-06-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08051</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Duplication of Windows Services</dc:title>
 <dc:creator>Shan, Zhiyong</dc:creator>
 <dc:creator>Chiueh, Tzi-cker</dc:creator>
 <dc:creator>Wang, Xin</dc:creator>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  OS-level virtualization techniques virtualize system resources at the system
call interface, has the distinct advantage of smaller run-time resource
requirements as compared to HAL-level virtualization techniques, and thus forms
an important building block for virtualizing parallel and distributed
applications such as a HPC clusters. Because the Windows operating system puts
certain critical functionalities in privileged user-level system service
processes, a complete OS-level virtualization solution for the Windows platform
requires duplication of such Windows service as Remote Procedure Call Server
Service (RPCSS). As many implementation details of the Windows system services
are proprietary, duplicating Windows system services becomes the key technical
challenge for virtualizing the Windows platform at the OS level. Moreover, as a
core component of cloud computing, IIS web server-related services need to be
duplicated in containers (i.e., OS-level virtual machines), but so far there is
no such scheme. In this paper, we thoroughly identify all issues that affect
service duplication, and then propose the first known methodology to
systematically duplicate both system and ordinary Windows services. Our
experiments show that the methodology can duplicate a set of system and
ordinary services on different versions of Windows OS.
</dc:description>
 <dc:date>2016-08-13</dc:date>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08052</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Discriminative Clustering with Sparse Regularizers</dc:title>
 <dc:creator>Flammarion, Nicolas</dc:creator>
 <dc:creator>Palaniappan, Balamurugan</dc:creator>
 <dc:creator>Bach, Francis</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Clustering high-dimensional data often requires some form of dimensionality
reduction, where clustered variables are separated from &quot;noise-looking&quot;
variables. We cast this problem as finding a low-dimensional projection of the
data which is well-clustered. This yields a one-dimensional projection in the
simplest situation with two clusters, and extends naturally to a multi-label
scenario for more than two clusters. In this paper, (a) we first show that this
joint clustering and dimension reduction formulation is equivalent to
previously proposed discriminative clustering frameworks, thus leading to
convex relaxations of the problem, (b) we propose a novel sparse extension,
which is still cast as a convex relaxation and allows estimation in higher
dimensions, (c) we propose a natural extension for the multi-label scenario,
(d) we provide a new theoretical analysis of the performance of these
formulations with a simple probabilistic model, leading to scalings over the
form $d=O(\sqrt{n})$ for the affine invariant case and $d=O(n)$ for the sparse
case, where $n$ is the number of examples and $d$ the ambient dimension, and
finally, (e) we propose an efficient iterative algorithm with running-time
complexity proportional to $O(nd^2)$, improving on earlier algorithms which had
quadratic complexity in the number of examples.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08053</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kisa Donem Uzam-Zamansal Trafik Tahmini</dc:title>
 <dc:creator>Tascikaraoglu, Akin</dc:creator>
 <dc:creator>Tascikaraoglu, Fatma Yildiz</dc:creator>
 <dc:creator>Kucukdemiral, Ibrahim Beklan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  The studies carried out with the objective of minimizing the effects of
congestion, delay and environment problems on the transportation network have
gained increasing importance in the last years. Among these studies, short-term
traffic flow and average vehicle speed forecasting methods have come into
prominence due to their easy implementations, efficient usage on different
areas and cost-effectiveness. A large number of studies have reported that
these methods, in which the expected future values of link flows and average
speeds are forecasted in desired points, can reduce the traffic congestion by
anticipating the problems in traffic management. In this paper, a
spatio-temporal approach accounted for historical traffic characteristics data
collected from a large number of points is presented for average speed
forecasts in a given link. The proposed approach includes an algorithm that
enables to take into account the most informative data in an input set by
determining them for each stage. It is aimed to increase the forecasting
accuracy by using sparse matrices in the algorithm while decreasing the
calculation times significantly compared to the similar methods presented in
the literature.
</dc:description>
 <dc:description>Comment: in Turkish, 2016 Otomatik Kontrol Ulusal Toplantisi</dc:description>
 <dc:date>2016-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08063</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wasserstein Discriminant Analysis</dc:title>
 <dc:creator>Flamary, R&#xe9;mi</dc:creator>
 <dc:creator>Cuturi, Marco</dc:creator>
 <dc:creator>Courty, Nicolas</dc:creator>
 <dc:creator>Rakotomamonjy, Alain</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Wasserstein Discriminant Analysis (WDA) is a new supervised method that can
improve classification of high-dimensional data by computing a suitable linear
map onto a lower dimensional subspace. Following the blueprint of classical
Linear Discriminant Analysis (LDA), WDA selects the projection matrix that
maximizes the ratio of two quantities: the dispersion of projected points
coming from different classes, divided by the dispersion of projected points
coming from the same class. To quantify dispersion, WDA uses regularized
Wasserstein distances, rather than cross-variance measures which have been
usually considered, notably in LDA. Thanks to the the underlying principles of
optimal transport, WDA is able to capture both global (at distribution scale)
and local (at samples scale) interactions between classes. Regularized
Wasserstein distances can be computed using the Sinkhorn matrix scaling
algorithm; We show that the optimization of WDA can be tackled using automatic
differentiation of Sinkhorn iterations. Numerical experiments show promising
results both in terms of prediction and visualization on toy examples and real
life datasets such as MNIST and on deep features obtained from a subset of the
Caltech dataset.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08072</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Approach to Multimedia Ontology Engineering for Automated
  Reasoning over Audiovisual LOD Datasets</dc:title>
 <dc:creator>Sikos, Leslie F.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Multimedia reasoning, which is suitable for, among others, multimedia content
analysis and high-level video scene interpretation, relies on the formal and
comprehensive conceptualization of the represented knowledge domain. However,
most multimedia ontologies are not exhaustive in terms of role definitions, and
do not incorporate complex role inclusions and role interdependencies. In fact,
most multimedia ontologies do not have a role box at all, and implement only a
basic subset of the available logical constructors. Consequently, their
application in multimedia reasoning is limited. To address the above issues,
VidOnt, the very first multimedia ontology with SROIQ(D) expressivity and a
DL-safe ruleset has been introduced for next-generation multimedia reasoning.
In contrast to the common practice, the formal grounding has been set in one of
the most expressive description logics, and the ontology validated with
industry-leading reasoners, namely HermiT and FaCT++. This paper also presents
best practices for developing multimedia ontologies, based on my ontology
engineering approach.
</dc:description>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08072</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-662-49381-6_1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08100</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trends in Topics in Software Engineering</dc:title>
 <dc:creator>Mathew, George</dc:creator>
 <dc:creator>Menzies, Tim</dc:creator>
 <dc:creator>Agrawal, Amritanshu</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Researchers should be able to explore software engineering, however their
whims guide them. But do our current structure of conferences and journals
inhibits that free exploration? To check this, this paper explores the trends
in software engineering research within 35,391 Software Engineering(SE) papers
from 34 leading SE venues over the last 25 years. These trends are discovered
via a combination of (a) text mining; (b) Latent Dirichlet Allocation, to find
the topics; (c) search-based software engineering, to automatically tune LDA;
(d) clustering conferences and journals according to how often they publish on
each topic. Trends in these topics reveal what topics are becoming more/less
popular over time. Overlaps and gaps between conferences and journals are
identified, from which we can identify what journals/ conferences might be
merged and what new venues might be created to cover gaps. These results can be
used for strategic and tactical purposes. Organizers of SE venues could use
them as a long-term planning aid for improving and rationalizing how they
service our research community. Also, individual researchers could also use
these results to make short-term publication plans. Note that our analysis is
100% automatic, thus making it readily repeatable and easily updatable.
</dc:description>
 <dc:description>Comment: 13 pages, TSE 2018 submission</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2017-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08104</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constraint matrix factorization for space variant PSFs field restoration</dc:title>
 <dc:creator>Mboula, F. M. Ngol&#xe8;</dc:creator>
 <dc:creator>Starck, J. -L.</dc:creator>
 <dc:creator>Okumura, K.</dc:creator>
 <dc:creator>Amiaux, J.</dc:creator>
 <dc:creator>Hudelot, P.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>00</dc:subject>
 <dc:description>  Context: in large-scale spatial surveys, the Point Spread Function (PSF)
varies across the instrument field of view (FOV). Local measurements of the
PSFs are given by the isolated stars images. Yet, these estimates may not be
directly usable for post-processings because of the observational noise and
potentially the aliasing. Aims: given a set of aliased and noisy stars images
from a telescope, we want to estimate well-resolved and noise-free PSFs at the
observed stars positions, in particular, exploiting the spatial correlation of
the PSFs across the FOV. Contributions: we introduce RCA (Resolved Components
Analysis) which is a noise-robust dimension reduction and super-resolution
method based on matrix factorization. We propose an original way of using the
PSFs spatial correlation in the restoration process through sparsity. The
introduced formalism can be applied to correlated data sets with respect to any
euclidean parametric space. Results: we tested our method on simulated
monochromatic PSFs of Euclid telescope (launch planned for 2020). The proposed
method outperforms existing PSFs restoration and dimension reduction methods.
We show that a coupled sparsity constraint on individual PSFs and their spatial
distribution yields a significant improvement on both the restored PSFs shapes
and the PSFs subspace identification, in presence of aliasing. Perspectives:
RCA can be naturally extended to account for the wavelength dependency of the
PSFs.
</dc:description>
 <dc:description>Comment: 33 pages</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08104</dc:identifier>
 <dc:identifier>doi:10.1088/0266-5611/32/12/124001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08112</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scholarly use of social media and altmetrics: a review of the literature</dc:title>
 <dc:creator>Sugimoto, Cassidy R.</dc:creator>
 <dc:creator>Work, Sam</dc:creator>
 <dc:creator>Larivi&#xe8;re, Vincent</dc:creator>
 <dc:creator>Haustein, Stefanie</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Social media has become integrated into the fabric of the scholarly
communication system in fundamental ways: principally through scholarly use of
social media platforms and the promotion of new indicators on the basis of
interactions with these platforms. Research and scholarship in this area has
accelerated since the coining and subsequent advocacy for altmetrics -- that
is, research indicators based on social media activity. This review provides an
extensive account of the state-of-the art in both scholarly use of social media
and altmetrics. The review consists of two main parts: the first examines the
use of social media in academia, examining the various functions these
platforms have in the scholarly communication process and the factors that
affect this use. The second part reviews empirical studies of altmetrics,
discussing the various interpretations of altmetrics, data collection and
methodological limitations, and differences according to platform. The review
ends with a critical discussion of the implications of this transformation in
the scholarly communication system.
</dc:description>
 <dc:description>Comment: preprint, submitted to JASIST</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08128</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Activity Detection in Untrimmed Videos with Recurrent Neural
  Networks</dc:title>
 <dc:creator>Montes, Alberto</dc:creator>
 <dc:creator>Salvador, Amaia</dc:creator>
 <dc:creator>Pascual, Santiago</dc:creator>
 <dc:creator>Giro-i-Nieto, Xavier</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4.8</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  This thesis explore different approaches using Convolutional and Recurrent
Neural Networks to classify and temporally localize activities on videos,
furthermore an implementation to achieve it has been proposed. As the first
step, features have been extracted from video frames using an state of the art
3D Convolutional Neural Network. This features are fed in a recurrent neural
network that solves the activity classification and temporally location tasks
in a simple and flexible way. Different architectures and configurations have
been tested in order to achieve the best performance and learning of the video
dataset provided. In addition it has been studied different kind of post
processing over the trained network's output to achieve a better results on the
temporally localization of activities on the videos. The results provided by
the neural network developed in this thesis have been submitted to the
ActivityNet Challenge 2016 of the CVPR, achieving competitive results using a
simple and flexible architecture.
</dc:description>
 <dc:description>Comment: Best Poster Award at the 1st NIPS Workshop on Large Scale Computer
  Vision Systems (Barcelona, December 2016). Source code available at
  https://imatge-upc.github.io/activitynet-2016-cvprw/</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08130</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scheduling Refresh Queries for Keeping Results from a SPARQL Endpoint
  Up-to-Date (Extended Version)</dc:title>
 <dc:creator>Knuth, Magnus</dc:creator>
 <dc:creator>Hartig, Olaf</dc:creator>
 <dc:creator>Sack, Harald</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Many datasets change over time. As a consequence, long-running applications
that cache and repeatedly use query results obtained from a SPARQL endpoint may
resubmit the queries regularly to ensure up-to-dateness of the results. While
this approach may be feasible if the number of such regular refresh queries is
manageable, with an increasing number of applications adopting this approach,
the SPARQL endpoint may become overloaded with such refresh queries. A more
scalable approach would be to use a middle-ware component at which the
applications register their queries and get notified with updated query results
once the results have changed. Then, this middle-ware can schedule the repeated
execution of the refresh queries without overloading the endpoint. In this
paper, we study the problem of scheduling refresh queries for a large number of
registered queries by assuming an overload-avoiding upper bound on the length
of a regular time slot available for testing refresh queries. We investigate a
variety of scheduling strategies and compare them experimentally in terms of
time slots needed before they recognize changes and number of changes that they
miss.
</dc:description>
 <dc:description>Comment: This document is an extended version of a paper published in ODBASE
  2016</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08130</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08139</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Where is my Phone ? Personal Object Retrieval from Egocentric Images</dc:title>
 <dc:creator>Reyes, Cristian</dc:creator>
 <dc:creator>Mohedano, Eva</dc:creator>
 <dc:creator>McGuinness, Kevin</dc:creator>
 <dc:creator>O'Connor, Noel E.</dc:creator>
 <dc:creator>Giro-i-Nieto, Xavier</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.4.9</dc:subject>
 <dc:description>  This work presents a retrieval pipeline and evaluation scheme for the problem
of finding the last appearance of personal objects in a large dataset of images
captured from a wearable camera. Each personal object is modelled by a small
set of images that define a query for a visual search engine.The retrieved
results are reranked considering the temporal timestamps of the images to
increase the relevance of the later detections. Finally, a temporal
interleaving of the results is introduced for robustness against false
detections. The Mean Reciprocal Rank is proposed as a metric to evaluate this
problem. This application could help into developing personal assistants
capable of helping users when they do not remember where they left their
personal belongings.
</dc:description>
 <dc:description>Comment: Lifelogging Tools and Applications Workshop (LTA'16) at ACM
  Multimedia 2016</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08142</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximizing Data Rate for Multiway Relay Channels with Pairwise
  Transmission Strategy</dc:title>
 <dc:creator>Borujeny, Reza Rafie</dc:creator>
 <dc:creator>Noori, Moslem</dc:creator>
 <dc:creator>Ardakani, Masoud</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In a multiway relay channel (MWRC), pairwise transmission strategy can be
used to reduce the computational complexity at the relay and the users without
sacrificing the data rate, significantly. The performance of such pairwise
strategies, however, is affected by the way that the users are paired to
transmit. In this paper, we study the effect of pairing on the common rate and
sum rate of an MWRC with functional-decode-forward (FDF) relaying strategy
where users experience asymmetric channel conditions. To this end, we first
develop a graphical model for an MWRC with pairwise transmission strategy.
Using this model, we then find the maximum achievable common rate and sum rate
as well as the user pairings that achieve these rates. This marks the ultimate
performance of FDF relaying in an MWRC setup. Further, we show that the rate
enhancement achieved through the optimal user pairing becomes less pronounced
at higher SNRs. Using computer simulations, the performance of the optimal
pairing is compared with those of other proposed pairings in the literature.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Wireless Communications, under
  second round of revisions. 10 pages, 8 figures. arXiv admin note: text
  overlap with arXiv:1406.4610</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08142</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08144</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Achievements in Answer Set Programming (Preliminary Report)</dc:title>
 <dc:creator>Lifschitz, Vladimir</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper describes an approach to the methodology of answer set programming
(ASP) that can facilitate the design of encodings that are easy to understand
and provably correct. Under this approach, after appending a rule or a small
group of rules to the emerging program we include a comment that states what
has been &quot;achieved&quot; so far. This strategy allows us to set out our
understanding of the design of the program by describing the roles of small
parts of the program in a mathematically precise way.
</dc:description>
 <dc:description>Comment: Paper presented at the 9th Workshop on Answer Set Programming and
  Other Computing Paradigms (ASPOCP 2016), New York City, USA, 16 October 2016</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08148</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>brTPF: Bindings-Restricted Triple Pattern Fragments (Extended Preprint)</dc:title>
 <dc:creator>Hartig, Olaf</dc:creator>
 <dc:creator>Buil-Aranda, Carlos</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The Triple Pattern Fragment (TPF) interface is a recent proposal for reducing
server load in Web-based approaches to execute SPARQL queries over public RDF
datasets. The price for less overloaded servers is a higher client-side load
and a substantial increase in network load (in terms of both the number of HTTP
requests and data transfer). In this paper, we propose a slightly extended
interface that allows clients to attach intermediate results to triple pattern
requests. The response to such a request is expected to contain triples from
the underlying dataset that do not only match the given triple pattern (as in
the case of TPF), but that are guaranteed to contribute in a join with the
given intermediate result. Our hypothesis is that a distributed query execution
using this extended interface can reduce the network load (in comparison to a
pure TPF-based query execution) without reducing the overall throughput of the
client-server system significantly. Our main contribution in this paper is
twofold: we empirically verify the hypothesis and provide an extensive
experimental comparison of our proposal and TPF.
</dc:description>
 <dc:description>Comment: This document is an extended preprint of a paper published in the
  proceedings of the ODBASE 2016 conference. In contrast to the proceedings
  version, this document contains Appendixes A and B which present additional
  experimental results</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08149</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ORBSLAM-based Endoscope Tracking and 3D Reconstruction</dc:title>
 <dc:creator>Mahmoud, Nader</dc:creator>
 <dc:creator>Cirauqui, I&#xf1;igo</dc:creator>
 <dc:creator>Hostettler, Alexandre</dc:creator>
 <dc:creator>Doignon, Christophe</dc:creator>
 <dc:creator>Soler, Luc</dc:creator>
 <dc:creator>Marescaux, Jacques</dc:creator>
 <dc:creator>Montiel, J. M. M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We aim to track the endoscope location inside the surgical scene and provide
3D reconstruction, in real-time, from the sole input of the image sequence
captured by the monocular endoscope. This information offers new possibilities
for developing surgical navigation and augmented reality applications. The main
benefit of this approach is the lack of extra tracking elements which can
disturb the surgeon performance in the clinical routine. It is our first
contribution to exploit ORBSLAM, one of the best performing monocular SLAM
algorithms, to estimate both of the endoscope location, and 3D structure of the
surgical scene. However, the reconstructed 3D map poorly describe textureless
soft organ surfaces such as liver. It is our second contribution to extend
ORBSLAM to be able to reconstruct a semi-dense map of soft organs. Experimental
results on in-vivo pigs, shows a robust endoscope tracking even with organs
deformations and partial instrument occlusions. It also shows the
reconstruction density, and accuracy against ground truth surface obtained from
CT.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08159</identifier>
 <datestamp>2017-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coloring Jordan regions and curves</dc:title>
 <dc:creator>van Batenburg, Wouter Cames</dc:creator>
 <dc:creator>Esperet, Louis</dc:creator>
 <dc:creator>M&#xfc;ller, Tobias</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  A Jordan region is a subset of the plane that is homeomorphic to a closed
disk. Consider a family $\mathcal{F}$ of Jordan regions whose interiors are
pairwise disjoint, and such that any two Jordan regions intersect in at most
one point. If any point of the plane is contained in at most $k$ elements of
$\mathcal{F}$ (with $k$ sufficiently large), then we show that the elements of
$\mathcal{F}$ can be colored with at most $k+1$ colors so that intersecting
Jordan regions are assigned distinct colors. This is best possible and answers
a question raised by Reed and Shepherd in 1996. As a simple corollary, we also
obtain a positive answer to a problem of Hlin\v{e}n\'y (1998) on the chromatic
number of contact systems of strings.
  We also investigate the chromatic number of families of touching Jordan
curves. This can be used to bound the ratio between the maximum number of
vertex-disjoint directed cycles in a planar digraph, and its fractional
counterpart.
</dc:description>
 <dc:description>Comment: 17 pages, 7 figures - final version</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2017-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08159</dc:identifier>
 <dc:identifier>SIAM Journal on Discrete Mathematics 31(3) (2017), 1670-1684</dc:identifier>
 <dc:identifier>doi:10.1137/16M1092726</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08161</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Bundled Crossing Number</dc:title>
 <dc:creator>Alam, Md. Jawaherul</dc:creator>
 <dc:creator>Fink, Martin</dc:creator>
 <dc:creator>Pupyrev, Sergey</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the algorithmic aspect of edge bundling. A bundled crossing in a
drawing of a graph is a group of crossings between two sets of parallel edges.
The bundled crossing number is the minimum number of bundled crossings that
group all crossings in a drawing of the graph.
  We show that the bundled crossing number is closely related to the orientable
genus of the graph. If multiple crossings and self-intersections of edges are
allowed, the two values are identical; otherwise, the bundled crossing number
can be higher than the genus.
  We then investigate the problem of minimizing the number of bundled
crossings. For circular graph layouts with a fixed order of vertices, we
present a constant-factor approximation algorithm. When the circular order is
not prescribed, we get a $\frac{6c}{c-2}$ approximation for a graph with $n$
vertices having at least $cn$ edges for $c&gt;2$. For general graph layouts, we
develop an algorithm with an approximation factor of $\frac{6c}{c-3}$ for
graphs with at least $cn$ edges for $c &gt; 3$.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08171</identifier>
 <datestamp>2016-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracking Completion</dc:title>
 <dc:creator>Sui, Yao</dc:creator>
 <dc:creator>Wang, Guanghui</dc:creator>
 <dc:creator>Tang, Yafei</dc:creator>
 <dc:creator>Zhang, Li</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A fundamental component of modern trackers is an online learned tracking
model, which is typically modeled either globally or locally. The two kinds of
models perform differently in terms of effectiveness and robustness under
different challenging situations. This work exploits the advantages of both
models. A subspace model, from a global perspective, is learned from previously
obtained targets via rank-minimization to address the tracking, and a
pixel-level local observation is leveraged si- multaneously, from a local point
of view, to augment the subspace model. A matrix completion method is employed
to integrate the two models. Unlike previous tracking methods, which locate the
target among all fully observed target candidates, the proposed approach first
estimates an expected target via the matrix completion through partially
observed target candidates, and then, identifies the target according to the
estimation accuracy with respect to the target candidates. Specifically, the
tracking is formulated as a problem of target appearance estimation. Extensive
experiments on various challenging video sequences verify the effectiveness of
the proposed approach and demonstrate that the proposed tracker outperforms
other popular state-of-the-art trackers.
</dc:description>
 <dc:description>Comment: Published at ECCV 2016</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2016-09-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08171</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08173</identifier>
 <datestamp>2016-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-Time Visual Tracking: Promoting the Robustness of Correlation
  Filter Learning</dc:title>
 <dc:creator>Sui, Yao</dc:creator>
 <dc:creator>Zhang, Ziming</dc:creator>
 <dc:creator>Wang, Guanghui</dc:creator>
 <dc:creator>Tang, Yafei</dc:creator>
 <dc:creator>Zhang, Li</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Correlation filtering based tracking model has received lots of attention and
achieved great success in real-time tracking, however, the lost function in
current correlation filtering paradigm could not reliably response to the
appearance changes caused by occlusion and illumination variations. This study
intends to promote the robustness of the correlation filter learning. By
exploiting the anisotropy of the filter response, three sparsity related loss
functions are proposed to alleviate the overfitting issue of previous methods
and improve the overall tracking performance. As a result, three real-time
trackers are implemented. Extensive experiments in various challenging
situations demonstrate that the robustness of the learned correlation filter
has been greatly improved via the designed loss functions. In addition, the
study reveals, from an experimental perspective, how different loss functions
essentially influence the tracking performance. An important conclusion is that
the sensitivity of the peak values of the filter in successive frames is
consistent with the tracking performance. This is a useful reference criterion
in designing a robust correlation filter for visual tracking.
</dc:description>
 <dc:description>Comment: Published at ECCV 2016</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2016-09-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08173</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08176</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What is Wrong with Topic Modeling? (and How to Fix it Using Search-based
  Software Engineering)</dc:title>
 <dc:creator>Agrawal, Amritanshu</dc:creator>
 <dc:creator>Fu, Wei</dc:creator>
 <dc:creator>Menzies, Tim</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Context: Topic modeling finds human-readable structures in unstructured
textual data. A widely used topic modeler is Latent Dirichlet allocation. When
run on different datasets, LDA suffers from &quot;order effects&quot; i.e. different
topics are generated if the order of training data is shuffled. Such order
effects introduce a systematic error for any study. This error can relate to
misleading results;specifically, inaccurate topic descriptions and a reduction
in the efficacy of text mining classification results. Objective: To provide a
method in which distributions generated by LDA are more stable and can be used
for further analysis. Method: We use LDADE, a search-based software engineering
tool that tunes LDA's parameters using DE (Differential Evolution). LDADE is
evaluated on data from a programmer information exchange site (Stackoverflow),
title and abstract text of thousands ofSoftware Engineering (SE) papers, and
software defect reports from NASA. Results were collected across different
implementations of LDA (Python+Scikit-Learn, Scala+Spark); across different
platforms (Linux, Macintosh) and for different kinds of LDAs (VEM,or using
Gibbs sampling). Results were scored via topic stability and text mining
classification accuracy. Results: In all treatments: (i) standard LDA exhibits
very large topic instability; (ii) LDADE's tunings dramatically reduce cluster
instability; (iii) LDADE also leads to improved performances for supervised as
well as unsupervised learning. Conclusion: Due to topic instability, using
standard LDA with its &quot;off-the-shelf&quot; settings should now be depreciated. Also,
in future, we should require SE papers that use LDA to test and (if needed)
mitigate LDA topic instability. Finally, LDADE is a candidate technology for
effectively and efficiently reducing that instability.
</dc:description>
 <dc:description>Comment: 15 pages + 2 page references. Submitted to IST Journal</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08180</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bibliometrics and Information Retrieval: Creating Knowledge through
  Research Synergies</dc:title>
 <dc:creator>Bar-Ilan, Judit</dc:creator>
 <dc:creator>Koopman, Rob</dc:creator>
 <dc:creator>Wang, Shenghui</dc:creator>
 <dc:creator>Scharnhorst, Andrea</dc:creator>
 <dc:creator>John, Marcus</dc:creator>
 <dc:creator>Mayr, Philipp</dc:creator>
 <dc:creator>Wolfram, Dietmar</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  This panel brings together experts in bibliometrics and information retrieval
to discuss how each of these two important areas of information science can
help to inform the research of the other. There is a growing body of literature
that capitalizes on the synergies created by combining methodological
approaches of each to solve research problems and practical issues related to
how information is created, stored, organized, retrieved and used. The session
will begin with an overview of the common threads that exist between IR and
metrics, followed by a summary of findings from the BIR workshops and examples
of research projects that combine aspects of each area to benefit IR or metrics
research areas, including search results ranking, semantic indexing and
visualization. The panel will conclude with an engaging discussion with the
audience to identify future areas of research and collaboration.
</dc:description>
 <dc:description>Comment: 4 pages, accepted at the 2016 Annual Meeting of the Association for
  Information Science and Technology (ASIST 2016) in Copenhagen</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08180</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08182</identifier>
 <datestamp>2016-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Poisoning Attacks on Factorization-Based Collaborative Filtering</dc:title>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Wang, Yining</dc:creator>
 <dc:creator>Singh, Aarti</dc:creator>
 <dc:creator>Vorobeychik, Yevgeniy</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Recommendation and collaborative filtering systems are important in modern
information and e-commerce applications. As these systems are becoming
increasingly popular in the industry, their outputs could affect business
decision making, introducing incentives for an adversarial party to compromise
the availability or integrity of such systems. We introduce a data poisoning
attack on collaborative filtering systems. We demonstrate how a powerful
attacker with full knowledge of the learner can generate malicious data so as
to maximize his/her malicious objectives, while at the same time mimicking
normal user behavior to avoid being detected. While the complete knowledge
assumption seems extreme, it enables a robust assessment of the vulnerability
of collaborative filtering schemes to highly motivated attacks. We present
efficient solutions for two popular factorization-based collaborative filtering
algorithms: the \emph{alternative minimization} formulation and the
\emph{nuclear norm minimization} method. Finally, we test the effectiveness of
our proposed algorithms on real-world data and discuss potential defensive
strategies.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2016-10-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08182</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08188</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Question: Predicting If a Crowd Will Agree on the Answer</dc:title>
 <dc:creator>Gurari, Danna</dc:creator>
 <dc:creator>Grauman, Kristen</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Visual question answering (VQA) systems are emerging from a desire to empower
users to ask any natural language question about visual content and receive a
valid answer in response. However, close examination of the VQA problem reveals
an unavoidable, entangled problem that multiple humans may or may not always
agree on a single answer to a visual question. We train a model to
automatically predict from a visual question whether a crowd would agree on a
single answer. We then propose how to exploit this system in a novel
application to efficiently allocate human effort to collect answers to visual
questions. Specifically, we propose a crowdsourcing system that automatically
solicits fewer human responses when answer agreement is expected and more human
responses when answer disagreement is expected. Our system improves upon
existing crowdsourcing systems, typically eliminating at least 20% of human
effort with no loss to the information collected from the crowd.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08196</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smart Policies for Artificial Intelligence</dc:title>
 <dc:creator>Brundage, Miles</dc:creator>
 <dc:creator>Bryson, Joanna</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  We argue that there already exists de facto artificial intelligence policy -
a patchwork of policies impacting the field of AI's development in myriad ways.
The key question related to AI policy, then, is not whether AI should be
governed at all, but how it is currently being governed, and how that
governance might become more informed, integrated, effective, and anticipatory.
We describe the main components of de facto AI policy and make some
recommendations for how AI policy can be improved, drawing on lessons from
other scientific and technological domains.
</dc:description>
 <dc:description>Comment: This is a draft of an article being revised - feedback is welcome</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08219</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NoFAQ: Synthesizing Command Repairs from Examples</dc:title>
 <dc:creator>D'Antoni, Loris</dc:creator>
 <dc:creator>Singh, Rishabh</dc:creator>
 <dc:creator>Vaughn, Michael</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Command-line tools are confusing and hard to use for novice programmers due
to their cryptic error messages and lack of documentation. Novice users often
resort to online help-forums for finding corrections to their buggy commands,
but have a hard time in searching precisely for posts that are relevant to
their problem and then applying the suggested solutions to their buggy command.
  We present a tool, NoFAQ, that uses a set of rules to suggest possible fixes
when users write buggy commands that trigger commonly occurring errors. The
rules are expressed in a language called FixIt and each rule pattern-matches
against the user's buggy command and the corresponding error message, and uses
these inputs to produce a possible fixed command. Our main contribution is an
algorithm based on lazy VSA for synthesizing FixIt rules from examples of buggy
and repaired commands. The algorithm allows users to add new rules in NoFAQ
without having to manually encode them. We present the evaluation of NoFAQ on
92 benchmark problems and show that NoFAQ is able to instantly synthesize rules
for 81 benchmark problems in real time using just 2 to 5 input-output examples
for each rule.
</dc:description>
 <dc:description>Comment: 15 Pages, 9 Figures</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08219</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08225</identifier>
 <datestamp>2017-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why does deep and cheap learning work so well?</dc:title>
 <dc:creator>Lin, Henry W.</dc:creator>
 <dc:creator>Tegmark, Max</dc:creator>
 <dc:creator>Rolnick, David</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We show how the success of deep learning could depend not only on mathematics
but also on physics: although well-known mathematical theorems guarantee that
neural networks can approximate arbitrary functions well, the class of
functions of practical interest can frequently be approximated through &quot;cheap
learning&quot; with exponentially fewer parameters than generic ones. We explore how
properties frequently encountered in physics such as symmetry, locality,
compositionality, and polynomial log-probability translate into exceptionally
simple neural networks. We further argue that when the statistical process
generating the data is of a certain hierarchical form prevalent in physics and
machine-learning, a deep neural network can be more efficient than a shallow
one. We formalize these claims using information theory and discuss the
relation to the renormalization group. We prove various &quot;no-flattening
theorems&quot; showing when efficient linear deep networks cannot be accurately
approximated by shallow ones without efficiency loss, for example, we show that
$n$ variables cannot be multiplied using fewer than 2^n neurons in a single
hidden layer.
</dc:description>
 <dc:description>Comment: Replaced to match version published in Journal of Statistical
  Physics: https://link.springer.com/article/10.1007/s10955-017-1836-5 Improved
  refs &amp; discussion, typos fixed. 16 pages, 3 figs</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08225</dc:identifier>
 <dc:identifier>doi:10.1007/s10955-017-1836-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08237</identifier>
 <datestamp>2017-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Clustering determines the dynamics of complex contagions in multiplex
  networks</dc:title>
 <dc:creator>Zhuang, Yong</dc:creator>
 <dc:creator>Arenas, Alex</dc:creator>
 <dc:creator>Ya&#x11f;an, Osman</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We present the mathematical analysis of generalized complex contagions in
clustered multiplex networks for susceptible-infected-recovered (SIR)-like
dynamics. The model is intended to understand diffusion of influence, or any
other spreading process implying a threshold dynamics, in setups of
interconnected networks with significant clustering. The contagion is assumed
to be general enough to account for a content-dependent linear threshold model,
where each link type has a different weight (for spreading influence) that may
depend on the content (e.g., product, rumor, political view) that is being
spread. Using the generating functions formalism, we determine the conditions,
probability, and expected size of the emergent global cascades. This analysis
provides a generalization of previous approaches and is specially useful in
problems related to spreading and percolation. The results present non trivial
dependencies between the clustering coefficient of the networks and its average
degree. In particular, several phase transitions are shown to occur depending
on these descriptors. Generally speaking, our findings reveal that increasing
clustering decreases the probability of having global cascades and their size,
however this tendency changes with the average degree. There exists a certain
average degree from which on clustering favours the probability and size of the
contagion. By comparing the dynamics of complex contagions over multiplex
networks and their monoplex projections, we demonstrate that ignoring link
types and aggregating network layers may lead to inaccurate conclusions about
contagion dynamics, particularly when the correlation of degrees between layers
is high.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08237</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.95.012312</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08242</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Convolutional Networks: A Unified Approach to Action
  Segmentation</dc:title>
 <dc:creator>Lea, Colin</dc:creator>
 <dc:creator>Vidal, Rene</dc:creator>
 <dc:creator>Reiter, Austin</dc:creator>
 <dc:creator>Hager, Gregory D.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The dominant paradigm for video-based action segmentation is composed of two
steps: first, for each frame, compute low-level features using Dense
Trajectories or a Convolutional Neural Network that encode spatiotemporal
information locally, and second, input these features into a classifier that
captures high-level temporal relationships, such as a Recurrent Neural Network
(RNN). While often effective, this decoupling requires specifying two separate
models, each with their own complexities, and prevents capturing more nuanced
long-range spatiotemporal relationships. We propose a unified approach, as
demonstrated by our Temporal Convolutional Network (TCN), that hierarchically
captures relationships at low-, intermediate-, and high-level time-scales. Our
model achieves superior or competitive performance using video or sensor data
on three public action segmentation datasets and can be trained in a fraction
of the time it takes to train an RNN.
</dc:description>
 <dc:description>Comment: Submitted to the ECCV workshop on &quot;Brave new ideas for motion
  representations in videos&quot; (http://bravenewmotion.github.io/)</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08251</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Construction of Convex Sets on Quadrilateral Ordered Tiles or Graphs
  with Propagation Neighborhood Operations. Dales, Concavity Structures.
  Application to Gray Image Analysis of Human-Readable Shapes</dc:title>
 <dc:creator>Polkovnikov, Igor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  An effort has been made to show mathematicians some new ideas applied to
image analysis. Gray images are presented as tilings. Based on topological
properties of the tiling, a number of gray convex hulls: maximal, minimal, and
oriented ones are constructed and some are proved. They are constructed with
only one operation. Two tilings are used in the Constraint and Allowance types
of operations. New type of concavity described: a dale. All operations are
parallel, possible to realize clock-less. Convexities define what is the
background. They are treated as separate gray objects. There are multiple
relations among them and their descendants. Via that, topological size of
concavities is proposed. Constructed with the same type of operations, Rays and
Angles in a tiling define possible spatial relations. Notions like &quot;strokes&quot;
are defined through concavities. Unusual effects on levelized gray objects are
shown. It is illustrated how alphabet and complex hieroglyphs can be described
through concavities and their relations. A hypothesis of living organisms image
analysis is proposed. A number of examples with symbols and a human face are
calculated with new Asynchwave C++ software library.
</dc:description>
 <dc:description>Comment: 58 pages, more than 50 figures</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08251</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08252</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Business Process Deviance Mining: Review and Evaluation</dc:title>
 <dc:creator>Nguyen, Hoang</dc:creator>
 <dc:creator>Dumas, Marlon</dc:creator>
 <dc:creator>La Rosa, Marcello</dc:creator>
 <dc:creator>Maggi, Fabrizio Maria</dc:creator>
 <dc:creator>Suriadi, Suriadi</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Business process deviance refers to the phenomenon whereby a subset of the
executions of a business process deviate, in a negative or positive way, with
respect to its expected or desirable outcomes. Deviant executions of a business
process include those that violate compliance rules, or executions that
undershoot or exceed performance targets. Deviance mining is concerned with
uncovering the reasons for deviant executions by analyzing business process
event logs. This article provides a systematic review and comparative
evaluation of deviance mining approaches based on a family of data mining
techniques known as sequence classification. Using real-life logs from multiple
domains, we evaluate a range of feature types and classification methods in
terms of their ability to accurately discriminate between normal and deviant
executions of a process. We also analyze the interestingness of the rule sets
extracted using different methods. We observe that feature sets extracted using
pattern mining techniques only slightly outperform simpler feature sets based
on counts of individual activity occurrences in a trace.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08253</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Stackelberg Game Approach for Two-Level Distributed Energy Management
  in Smart Grids</dc:title>
 <dc:creator>Chen, Juntao</dc:creator>
 <dc:creator>Zhu, Quanyan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The pursuit of sustainability motivates microgrids that depend on distributed
resources to produce more renewable energies. An efficient operation and
planning relies on a holistic framework that takes into account the
interdependent decision-making of the generators of the existing power grids
and the distributed resources of the microgrid in the integrated system. To
this end, we use a Stackelberg game-theoretic framework to study the
interactions between generators (leaders) and microgrids (followers). Entities
on both sides make strategic decisions on the amount of power generation to
maximize their payoffs. Our framework not only takes into account the economic
factors but also incorporates the stability and efficiency of the smart grid,
such as the power flow constraints and voltage angle regulations. We develop
three update schemes for both generators and microgrids, respectively, and
among which a fully distributed algorithm enabled by phasor measurement units
is presented. The distributed algorithm merely requires the information of
voltage angles at local buses for updates, and its convergence to the unique
equilibrium is shown. We further develop the implementation architectures of
the update schemes in the smart grid. Finally, case studies are used to
corroborate the effectiveness of the proposed algorithms.
</dc:description>
 <dc:description>Comment: Published in IEEE Transactions on Smart Grids</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2017-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08253</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08258</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reenactment for Read-Committed Snapshot Isolation</dc:title>
 <dc:creator>Arab, Bahareh Sadat</dc:creator>
 <dc:creator>Gawlick, Dieter</dc:creator>
 <dc:creator>Krishnaswamy, Vasudha</dc:creator>
 <dc:creator>Radhakrishnan, Venkatesh</dc:creator>
 <dc:creator>Glavic, Boris</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:description>  Provenance for transactional updates is critical for many applications such
as auditing and debugging of transactions. Recently, we have introduced
MV-semirings, an extension of the semiring provenance model that supports
updates and transactions. Furthermore, we have proposed reenactment, a
declarative form of replay with provenance capture, as an efficient and
non-invasive method for computing this type of provenance. However, this
approach is limited to the snapshot isolation (SI) concurrency control protocol
while many real world applications apply the read committed version of snapshot
isolation (RC-SI) to improve performance at the cost of consistency. We present
non-trivial extensions of the model and reenactment approach to be able to
compute provenance of RC-SI transactions efficiently. In addition, we develop
techniques for applying reenactment across multiple RC-SI transactions. Our
experiments demonstrate that our implementation in the GProM system supports
efficient re-construction and querying of provenance.
</dc:description>
 <dc:description>Comment: long versions of CIKM paper</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08258</dc:identifier>
 <dc:identifier>doi:10.1145/2983323.2983825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08261</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interference Power Bound Analysis of a Network of Wireless Robots</dc:title>
 <dc:creator>Ghosh, Pradipta</dc:creator>
 <dc:creator>Krishnamachari, Bhaskar</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We consider a fundamental problem concerning the deployment of a wireless
robotic network: to fulfill various end-to-end performance requirements, a
&quot;sufficient&quot; number of robotic relays must be deployed to ensure that links are
of acceptable quality. Prior work has not addressed how to find this number. We
use the properties of Carrier Sense Multiple Access (CSMA) based wireless
communication to derive an upper bound on the spacing between any
transmitter-receiver pair, which directly translates to a lower bound on the
number of robots to deploy. We focus on SINR-based performance requirements due
to their wide applicability. Next, we show that the bound can be improved by
exploiting the geometrical structure of a network, such as linearity in the
case of flow-based robotic router networks. Furthermore, we also use the bound
on robot count to formulate a lower bound on the number of orthogonal codes
required for a high probability of interference free communication. We
demonstrate and validate our proposed bounds through simulations.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08262</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vicious Circle Principle and Formation of Sets in ASP Based Languages</dc:title>
 <dc:creator>Gelfond, Michael</dc:creator>
 <dc:creator>Zhang, Yuanlin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The paper continues the investigation of Poincare and Russel's Vicious Circle
Principle (VCP) in the context of the design of logic programming languages
with sets. We expand previously introduced language Alog with aggregates by
allowing infinite sets and several additional set related constructs useful for
knowledge representation and teaching. In addition, we propose an alternative
formalization of the original VCP and incorporate it into the semantics of new
language, Slog+, which allows more liberal construction of sets and their use
in programming rules. We show that, for programs without disjunction and
infinite sets, the formal semantics of aggregates in Slog+ coincides with that
of several other known languages. Their intuitive and formal semantics,
however, are based on quite different ideas and seem to be more involved than
that of Slog+.
</dc:description>
 <dc:description>Comment: Paper presented at the 9th Workshop on Answer Set Programming and
  Other Computing Paradigms (ASPOCP 2016), New York City, USA, 16 October 2016</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08262</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08265</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>About Learning in Recurrent Bistable Gradient Networks</dc:title>
 <dc:creator>Fischer, J.</dc:creator>
 <dc:creator>Lackner, S.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Recurrent Bistable Gradient Networks are attractor based neural networks
characterized by bistable dynamics of each single neuron. Coupled together
using linear interaction determined by the interconnection weights, these
networks do not suffer from spurious states or very limited capacity anymore.
Vladimir Chinarov and Michael Menzinger, who invented these networks, trained
them using Hebb's learning rule. We show, that this way of computing the
weights leads to unwanted behaviour and limitations of the networks
capabilities. Furthermore we evince, that using the first order of Hintons
Contrastive Divergence algorithm leads to a quite promising recurrent neural
network. These findings are tested by learning images of the MNIST database for
handwritten numbers.
</dc:description>
 <dc:description>Comment: 3 pages, 4 figures</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08265</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08266</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visualizing and Understanding Sum-Product Networks</dc:title>
 <dc:creator>Vergari, Antonio</dc:creator>
 <dc:creator>Di Mauro, Nicola</dc:creator>
 <dc:creator>Esposito, Floriana</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Sum-Product Networks (SPNs) are recently introduced deep tractable
probabilistic models by which several kinds of inference queries can be
answered exactly and in a tractable time. Up to now, they have been largely
used as black box density estimators, assessed only by comparing their
likelihood scores only. In this paper we explore and exploit the inner
representations learned by SPNs. We do this with a threefold aim: first we want
to get a better understanding of the inner workings of SPNs; secondly, we seek
additional ways to evaluate one SPN model and compare it against other
probabilistic models, providing diagnostic tools to practitioners; lastly, we
want to empirically evaluate how good and meaningful the extracted
representations are, as in a classic Representation Learning framework. In
order to do so we revise their interpretation as deep neural networks and we
propose to exploit several visualization techniques on their node activations
and network outputs under different types of inference queries. To investigate
these models as feature extractors, we plug some SPNs, learned in a greedy
unsupervised fashion on image datasets, in supervised classification learning
tasks. We extract several embedding types from node activations by filtering
nodes by their type, by their associated feature abstraction level and by their
scope. In a thorough empirical comparison we prove them to be competitive
against those generated from popular feature extractors as Restricted Boltzmann
Machines. Finally, we investigate embeddings generated from random
probabilistic marginal queries as means to compare other tractable
probabilistic models on a common ground, extending our experiments to Mixtures
of Trees.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08266</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08267</identifier>
 <datestamp>2016-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning and Inferring Relations in Cortical Networks</dc:title>
 <dc:creator>Diehl, Peter U.</dc:creator>
 <dc:creator>Cook, Matthew</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  A pressing scientific challenge is to understand how brains work. Of
particular interest is the neocortex,the part of the brain that is especially
large in humans, capable of handling a wide variety of tasks including visual,
auditory, language, motor, and abstract processing. These functionalities are
processed in different self-organized regions of the neocortical sheet, and yet
the anatomical structure carrying out the processing is relatively uniform
across the sheet. We are at a loss to explain, simulate, or understand such a
multi-functional homogeneous sheet-like computational structure - we do not
have computational models which work in this way. Here we present an important
step towards developing such models: we show how uniform modules of excitatory
and inhibitory neurons can be connected bidirectionally in a network that, when
exposed to input in the form of population codes, learns the input encodings as
well as the relationships between the inputs. STDP learning rules lead the
modules to self-organize into a relational network, which is able to infer
missing inputs,restore noisy signals, decide between conflicting inputs, and
combine cues to improve estimates. These networks show that it is possible for
a homogeneous network of spiking units to self-organize so as to provide
meaningful processing of its inputs. If such networks can be scaled up, they
could provide an initial computational model relevant to the large scale
anatomy of the neocortex.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08278</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Deployment of Resources for Maximizing Impact in Spreading
  Processes</dc:title>
 <dc:creator>Lokhov, Andrey Y.</dc:creator>
 <dc:creator>Saad, David</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The effective use of limited resources for controlling spreading processes on
networks is of prime significance in diverse contexts, ranging from the
identification of &quot;influential spreaders&quot; for maximizing information
dissemination and targeted interventions in regulatory networks, to the
development of mitigation policies for infectious diseases and financial
contagion in economic systems. Solutions for these optimization tasks that are
based purely on topological arguments are not fully satisfactory; in realistic
settings the problem is often characterized by heterogeneous interactions and
requires interventions over a finite time window via a restricted set of
controllable nodes. The optimal distribution of available resources hence
results from an interplay between network topology and spreading dynamics. We
show how these problems can be addressed as particular instances of a universal
analytical framework based on a scalable dynamic message-passing approach and
demonstrate the efficacy of the method on a variety of real-world examples.
</dc:description>
 <dc:description>Comment: 10 pages and appendices, 6 figures</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08292</identifier>
 <datestamp>2016-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Energy Storage Scheduling for Imbalance Reduction of
  Strategically Formed Energy Balancing Groups</dc:title>
 <dc:creator>Chakraborty, Shantanu</dc:creator>
 <dc:creator>Okabe, Toshiya</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Imbalance (on-line energy gap between contracted supply and actual demand,
and associated cost) reduction is going to be a crucial service for a Power
Producer and Supplier (PPS) in the deregulated energy market. PPS requires
forward market interactions to procure energy as precisely as possible in order
to reduce imbalance energy. This paper presents, 1) (off-line) an effective
demand aggregation based strategy for creating a number of balancing groups
that leads to higher predictability of group-wise aggregated demand, 2)
(on-line) a robust energy storage scheduling that minimizes the imbalance for a
particular balancing group considering the demand prediction uncertainty. The
group formation is performed by a Probabilistic Programming approach using
Bayesian Markov Chain Monte Carlo (MCMC) method after applied on the historical
demand statistics. Apart from the group formation, the aggregation strategy
(with the help of Bayesian Inference) also clears out the upper-limit of the
required storage capacity for a formed group, fraction of which is to be
utilized in on-line operation. For on-line operation, a robust energy storage
scheduling method is proposed that minimizes expected imbalance energy and cost
(a non-linear function of imbalance energy) while incorporating the demand
uncertainty of a particular group. The proposed methods are applied on the real
apartment buildings' demand data in Tokyo, Japan. Simulation results are
presented to verify the effectiveness of the proposed methods.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08292</dc:identifier>
 <dc:identifier>Energy, Volume 114, 1 November 2016, Pages 405-417, ISSN 0360-5442</dc:identifier>
 <dc:identifier>doi:10.1016/j.energy.2016.07.170.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08305</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Utilizing Large Scale Vision and Text Datasets for Image Segmentation
  from Referring Expressions</dc:title>
 <dc:creator>Hu, Ronghang</dc:creator>
 <dc:creator>Rohrbach, Marcus</dc:creator>
 <dc:creator>Venugopalan, Subhashini</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image segmentation from referring expressions is a joint vision and language
modeling task, where the input is an image and a textual expression describing
a particular region in the image; and the goal is to localize and segment the
specific image region based on the given expression. One major difficulty to
train such language-based image segmentation systems is the lack of datasets
with joint vision and text annotations. Although existing vision datasets such
as MS COCO provide image captions, there are few datasets with region-level
textual annotations for images, and these are often smaller in scale. In this
paper, we explore how existing large scale vision-only and text-only datasets
can be utilized to train models for image segmentation from referring
expressions. We propose a method to address this problem, and show in
experiments that our method can help this joint vision and language modeling
task with vision-only and text-only data and outperforms previous results.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08306</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Downlink Coordinated Multipoint Performance in Heterogeneous
  Networks</dc:title>
 <dc:creator>Mismar, Faris B.</dc:creator>
 <dc:creator>Evans, Brian L.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We propose a novel method for practical Joint Processing downlink coordinated
multipoint (DL CoMP) implementation in LTE/LTE-A systems using supervised
machine learning. DL CoMP has not been thoroughly studied in previous work
although cluster formation and interference mitigation have been studied
extensively. In this paper, we attempt to improve the cell edge data rate
served by a heterogeneous network cluster by means of dynamically changing the
DL SINR threshold at which the DL CoMP feature is triggered. We do so by using
a support vector machine (SVM) classifier. The simulation results show a cell
edge user throughput improvement of 33.3% for pico cells and more than
four-fold improvement in user throughput in the cluster. This has resulted from
a reduction in the downlink block error rate (DL BLER) and an improvement in
the spectral efficiency due to the informed triggering of the multiple radio
streams as part of DL CoMP.
</dc:description>
 <dc:description>Comment: 9 pages, 6 figures, submitted to IEEE Journal of Selected Topics in
  Signal Processing on June 30, 2017</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:date>2018-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08313</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sub-channel Assignment, Power Allocation and User Scheduling for
  Non-Orthogonal Multiple Access Networks</dc:title>
 <dc:creator>Di, Boya</dc:creator>
 <dc:creator>Song, Lingyang</dc:creator>
 <dc:creator>Li, Yonghui</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study the resource allocation and user scheduling problem
for a downlink nonorthogonal multiple access network where the base station
allocates spectrum and power resources to a set of users. We aim to jointly
optimize the sub-channel assignment and power allocation to maximize the
weighted total sum-rate while taking into account user fairness. We formulate
the sub-channel allocation problem as equivalent to a many-to-many two-sided
user-subchannel matching game in which the set of users and sub-channels are
considered as two sets of players pursuing their own interests. We then propose
a matching algorithm which converges to a two-side exchange stable matching
after a limited number of iterations. A joint solution is thus provided to
solve the sub-channel assignment and power allocation problems iteratively.
Simulation results show that the proposed algorithm greatly outperforms the
orthogonal multiple access scheme and a previous non-orthogonal multiple access
scheme.
</dc:description>
 <dc:description>Comment: Accepted as a regular paper by IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08313</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2016.2606100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08324</identifier>
 <datestamp>2017-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topological Drawings of Complete Bipartite Graphs</dc:title>
 <dc:creator>Cardinal, Jean</dc:creator>
 <dc:creator>Felsner, Stefan</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Topological drawings are natural representations of graphs in the plane,
where vertices are represented by points, and edges by curves connecting the
points. Topological drawings of complete graphs and of complete bipartite
graphs have been studied extensively in the context of crossing number
problems. We consider a natural class of simple topological drawings of
complete bipartite graphs, in which we require that one side of the vertex set
bipartition lies on the outer boundary of the drawing.
  We investigate the combinatorics of such drawings. For this purpose, we
define combinatorial encodings of the drawings by enumerating the distinct
drawings of subgraphs isomorphic to $K_{2,2}$ and $K_{3,2}$, and investigate
the constraints they must satisfy. We prove that a drawing of $K_{k,n}$ exists
if and only if some simple local conditions are satisfied by the encodings.
This directly yields a polynomial-time algorithm for deciding the existence of
such a drawing given the encoding. We show the encoding is equivalent to
specifying which pairs of edges cross, yielding a similar polynomial-time
algorithm for the realizability of abstract topological graphs.
  We also completely characterize and enumerate such drawings of $K_{k,n}$ in
which the order of the edges around each vertex is the same for vertices on the
same side of the bipartition. Finally, we investigate drawings of $K_{k,n}$
using straight lines and pseudolines, and consider the complexity of the
corresponding realizability problems.
</dc:description>
 <dc:description>Comment: A preliminary version appeared in the Proceedings of the 24th
  International Symposium on Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2017-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08330</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Static Trace-Based Deadlock Analysis for Synchronous Mini-Go</dc:title>
 <dc:creator>Stadtm&#xfc;ller, Kai</dc:creator>
 <dc:creator>Sulzmann, Martin</dc:creator>
 <dc:creator>Thiemann, Peter</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We consider the problem of static deadlock detection for programs in the Go
programming language which make use of synchronous channel communications. In
our analysis, regular expressions extended with a fork operator capture the
communication behavior of a program. Starting from a simple criterion that
characterizes traces of deadlock-free programs, we develop automata-based
methods to check for deadlock-freedom. The approach is implemented and
evaluated with a series of examples.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08330</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08331</identifier>
 <datestamp>2017-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Home Location Estimation with Iteration on Twitter Following
  Relationship</dc:title>
 <dc:creator>Hironaka, Shiori</dc:creator>
 <dc:creator>Yoshida, Mitsuo</dc:creator>
 <dc:creator>Umemura, Kyoji</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  User's home locations are used by numerous social media applications, such as
social media analysis. However, since the user's home location is not generally
open to the public, many researchers have been attempting to develop a more
accurate home location estimation. A social network that expresses
relationships between users is used to estimate the users' home locations. The
network-based home location estimation method with iteration, which propagates
the estimated locations, is used to estimate more users' home locations. In
this study, we analyze the function of network-based home location estimation
with iteration while using the social network based on following relationships
on Twitter. The results indicate that the function that selects the most
frequent location among the friends' location has the best accuracy. Our
analysis also shows that the 88% of users, who are in the social network based
on following relationships, has at least one correct home location within
one-hop (friends and friends of friends). According to this characteristic of
the social network, we indicate that twice is sufficient for iteration.
</dc:description>
 <dc:description>Comment: The 2016 International Conference on Advanced Informatics: Concepts,
  Theory and Application (ICAICTA2016)</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08331</dc:identifier>
 <dc:identifier>doi:10.1109/ICAICTA.2016.7803100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08334</identifier>
 <datestamp>2016-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Egocentric Meets Top-view</dc:title>
 <dc:creator>Ardeshir, Shervin</dc:creator>
 <dc:creator>Borji, Ali</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Thanks to the availability and increasing popularity of Egocentric cameras
such as GoPro cameras, glasses, and etc. we have been provided with a plethora
of videos captured from the first person perspective. Surveillance cameras and
Unmanned Aerial Vehicles(also known as drones) also offer tremendous amount of
videos, mostly with top-down or oblique view-point. Egocentric vision and
top-view surveillance videos have been studied extensively in the past in the
computer vision community. However, the relationship between the two has yet to
be explored thoroughly. In this effort, we attempt to explore this relationship
by approaching two questions. First, having a set of egocentric videos and a
top-view video, can we verify if the top-view video contains all, or some of
the egocentric viewers present in the egocentric set? And second, can we
identify the egocentric viewers in the content of the top-view video? In other
words, can we find the cameramen in the surveillance videos? These problems can
become more challenging when the videos are not time-synchronous. Thus we
formalize the problem in a way which handles and also estimates the unknown
relative time-delays between the egocentric videos and the top-view video. We
formulate the problem as a spectral graph matching instance, and jointly seek
the optimal assignments and relative time-delays of the videos. As a result, we
spatiotemporally localize the egocentric observers in the top-view video. We
model each view (egocentric or top) using a graph, and compute the assignment
and time-delays in an iterative-alternative fashion.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2016-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08334</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08336</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-rank Multi-view Clustering in Third-Order Tensor Space</dc:title>
 <dc:creator>Yin, Ming</dc:creator>
 <dc:creator>Gao, Junbin</dc:creator>
 <dc:creator>Xie, Shengli</dc:creator>
 <dc:creator>Guo, Yi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The plenty information from multiple views data as well as the complementary
information among different views are usually beneficial to various tasks,
e.g., clustering, classification, de-noising. Multi-view subspace clustering is
based on the fact that the multi-view data are generated from a latent
subspace. To recover the underlying subspace structure, the success of the
sparse and/or low-rank subspace clustering has been witnessed recently. Despite
some state-of-the-art subspace clustering approaches can numerically handle
multi-view data, by simultaneously exploring all possible pairwise correlation
within views, the high order statistics is often disregarded which can only be
captured by simultaneously utilizing all views. As a consequence, the
clustering performance for multi-view data is compromised. To address this
issue, in this paper, a novel multi-view clustering method is proposed by using
\textit{t-product} in third-order tensor space. Based on the circular
convolution operation, multi-view data can be effectively represented by a
\textit{t-linear} combination with sparse and low-rank penalty using
&quot;self-expressiveness&quot;. Our extensive experimental results on facial, object,
digits image and text data demonstrate that the proposed method outperforms the
state-of-the-art methods in terms of many criteria.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08337</identifier>
 <datestamp>2016-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Dependent Convergence for Distributed Stochastic Optimization</dc:title>
 <dc:creator>Bijral, Avleen S.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this dissertation we propose alternative analysis of distributed
stochastic gradient descent (SGD) algorithms that rely on spectral properties
of the data covariance. As a consequence we can relate questions pertaining to
speedups and convergence rates for distributed SGD to the data distribution
instead of the regularity properties of the objective functions. More precisely
we show that this rate depends on the spectral norm of the sample covariance
matrix. An estimate of this norm can provide practitioners with guidance
towards a potential gain in algorithm performance. For example many sparse
datasets with low spectral norm prove to be amenable to gains in distributed
settings. Towards establishing this data dependence we first study a
distributed consensus-based SGD algorithm and show that the rate of convergence
involves the spectral norm of the sample covariance matrix when the underlying
data is assumed to be independent and identically distributed (homogenous).
This dependence allows us to identify network regimes that prove to be
beneficial for datasets with low sample covariance spectral norm. Existing
consensus based analyses prove to be sub-optimal in the homogenous setting. Our
analysis method also allows us to find data-dependent convergence rates as we
limit the amount of communication. Spreading a fixed amount of data across more
nodes slows convergence; in the asymptotic regime we show that adding more
machines can help when minimizing twice-differentiable losses. Since the
mini-batch results don't follow from the consensus results we propose a
different data dependent analysis thereby providing theoretical validation for
why certain datasets are more amenable to mini-batching. We also provide
empirical evidence for results in this thesis.
</dc:description>
 <dc:description>Comment: PhD thesis</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08337</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08339</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>American Sign Language fingerspelling recognition from video: Methods
  for unrestricted recognition and signer-independence</dc:title>
 <dc:creator>Kim, Taehwan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this thesis, we study the problem of recognizing video sequences of
fingerspelled letters in American Sign Language (ASL). Fingerspelling comprises
a significant but relatively understudied part of ASL, and recognizing it is
challenging for a number of reasons: It involves quick, small motions that are
often highly coarticulated; it exhibits significant variation between signers;
and there has been a dearth of continuous fingerspelling data collected. In
this work, we propose several types of recognition approaches, and explore the
signer variation problem. Our best-performing models are segmental
(semi-Markov) conditional random fields using deep neural network-based
features. In the signer-dependent setting, our recognizers achieve up to about
8% letter error rates. The signer-independent setting is much more challenging,
but with neural network adaptation we achieve up to 17% letter error rates.
</dc:description>
 <dc:description>Comment: PhD Thesis</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08342</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Paradigm of Software Service Engineering in the Era of Big Data
  and Big Service</dc:title>
 <dc:creator>Xu, Xiaofei</dc:creator>
 <dc:creator>Motta, Gianmario</dc:creator>
 <dc:creator>Wang, Xianzhi</dc:creator>
 <dc:creator>Tu, Zhiying</dc:creator>
 <dc:creator>Xu, Hanchuan</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Servitization is one of the most significant trends that reshapes the
information world and society in recent years. The requirement of
collecting,storing, processing, and sharing of the Big Data has led to massive
software resources being developed and made accessible as web-based services to
facilitate such process. These services that handle the Big Data come from
various domains and heterogeneous networks, and converge into a huge
complicated service network (or ecosystem), called the Big Service.The key
issue facing the big data and big service ecosystem is how to optimally
configure and operate the related service resources to serve the specific
requirements of possible applications, i.e., how to reuse the existing service
resources effectively and efficiently to develop the new applications or
software services, to meet the massive individualized requirements of
end-users.Based on analyzing the big service ecosystem, we present in this
paper a new paradigm for software service engineering, RE2SEP
(Requirement-Engineering Two-Phase of Service Engineering Paradigm), which
includes three components: service-oriented requirement engineering,
domain-oriented service engineering, and software service development approach.
RE2SEP enables the rapid design and implementation of service solutions to
match the requirement propositions of massive individualized customers in the
Big Service ecosystem. A case study on people's mobility service in a smart
city environment is given to demonstrate the application of RE2SEP.RE2SEP can
potentially revolutionize the traditional life-cycle oriented software
engineering, leading to a new approach to software service engineering.
</dc:description>
 <dc:description>Comment: 23 pages+ 1 page references. Submitted to Springer Computing</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08346</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A family of fast exact pattern matching algorithms</dc:title>
 <dc:creator>Zavadskyi, Igor O.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A family of comparison-based exact pattern matching algorithms is described.
They utilize multi-dimensional arrays in order to process more than one
adjacent text window in each iteration of the search cycle. This approach leads
to a lower average time complexity by the cost of space. The algorithms of this
family perform well for short patterns and middle size alphabets. In such case
the shift of the window by several pattern lengths at once is quite probable,
which is the main factor of algorithm success. Our algorithms outperform the
Boyer-Moore-Horspool algorithm, either in the original version or with Sunday's
Quick search modification, in a wide area of pattern length - alphabet size
plane. In some subareas the proposed algorithms are the fastest among all known
exact pattern matching algorithms. Namely, they perform best when alphabet size
is about 30-40 and pattern length is about 4-10. Such parameters are typical
for search in natural language text databases.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, submitted to 'Bulletin of Taras Shevchenko
  NationalUniversity of Kyiv'</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08353</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A short review and primer on event-related potentials in human computer
  interaction applications</dc:title>
 <dc:creator>Huotilainen, Minna</dc:creator>
 <dc:creator>Cowley, Benjamin</dc:creator>
 <dc:creator>Ahonen, Lauri</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The application of psychophysiology in human-computer interaction is a
growing field with significant potential for future smart personalised systems.
Working in this emerging field requires comprehension of an array of
physiological signals and analysis techniques.
  Event-related potentials, termed ERPs, are a stimulus- or action-locked
waveform indicating a characteristic neural response. ERPs derived from
electroencephalography have been extensively studied in basic research, and
have been applied especially in the field of brain-computer interfaces. For
ecologically-valid settings there are considerable challenges to application,
however recent work shows some promise for ERPs outside the lab. Here we
present a short review on the application of ERPs in human-computer
interaction.
  This paper aims to serve as a primer for the novice, enabling rapid
familiarisation with the latest core concepts. We put special emphasis on
everyday human-computer interface applications to distinguish from the more
common clinical or sports uses of psychophysiology.
  This paper is an extract from a comprehensive review of the entire field of
ambulatory psychophysiology, including 12 similar chapters, plus application
guidelines and systematic review. Thus any citation should be made using the
following reference:
  B. Cowley, M. Filetti, K. Lukander, J. Torniainen, A. Henelius, L. Ahonen, O.
Barral, I. Kosunen, T. Valtonen, M. Huotilainen, N. Ravaja, G. Jacucci. The
Psychophysiology Primer: a guide to methods and a broad review with a focus on
human-computer interaction. Foundations and Trends in Human-Computer
Interaction, vol. 9, no. 3-4, pp. 150--307, 2016.
</dc:description>
 <dc:description>Comment: 8 pages, 1 figure. Part of a journal</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08353</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08365</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable and Cost Efficient Algorithms for Virtual CDN Migration</dc:title>
 <dc:creator>Ibn-Khedher, Hatem</dc:creator>
 <dc:creator>Hadji, Makhlouf</dc:creator>
 <dc:creator>Abd-Elrahman, Emad</dc:creator>
 <dc:creator>Afifi, Hossam</dc:creator>
 <dc:creator>Kamal, Ahmed E.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Virtual Content Delivery Network (vCDN) migration is necessary to optimize
the use of resources and improve the performance of the overall SDN/NFV-based
CDN function in terms of network operator cost reduction and high streaming
quality. It requires intelligent and enticed joint SDN/NFV migration algorithms
due to the evident huge amount of traffic to be delivered to end customers of
the network. In this paper, two approaches for finding the optimal and near
optimal path placement(s) and vCDN migration(s) are proposed (OPAC and HPAC).
Moreover, several scenarios are considered to quantify the OPAC and HPAC
behaviors and to compare their efficiency in terms of migration cost, migration
time, vCDN replication number, and other cost factors. Then, they are
implemented and evaluated under different network scales. Finally, the proposed
algorithms are integrated in an SDN/NFV framework. Index Terms: vCDN; SDN/NFV
Optimization; Migration Algorithms; Scalability Algorithms.
</dc:description>
 <dc:description>Comment: 9 pages, 11 figures, 4 tableaux, conference Local Computer Networks
  (LCN), class A</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08367</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pattern Coding Meets Censoring: (almost) Adaptive Coding on Countable
  Alphabets</dc:title>
 <dc:creator>Ben-Hamou, Anna</dc:creator>
 <dc:creator>Boucheron, Stephane</dc:creator>
 <dc:creator>Gassiat, Elisabeth</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  Adaptive coding faces the following problem: given a collection of source
classes such that each class in the collection has non-trivial minimax
redundancy rate, can we design a single code which is asymptotically minimax
over each class in the collection? In particular, adaptive coding makes sense
when there is no universal code on the union of classes in the collection. In
this paper, we deal with classes of sources over an infinite alphabet, that are
characterized by a dominating envelope. We provide asymptotic equivalents for
the redundancy of envelope classes enjoying a regular variation property. We
finally construct a computationally efficient online prefix code, which
interleaves the encoding of the so-called pattern of the message and the
encoding of the dictionary of discovered symbols. This code is shown to be
adaptive, within a $\log\log n$ factor, over the collection of regularly
varying envelope classes. The code is both simpler and less redundant than
previously described contenders. In contrast with previous attempts, it also
covers the full range of slowly varying envelope classes.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08368</identifier>
 <datestamp>2017-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Constructing Persistent Identifiers with Persistent Resolution
  Targets</dc:title>
 <dc:creator>Wannenwetsch, Oliver</dc:creator>
 <dc:creator>Majchrzak, Tim A.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Persistent Identifiers (PID) are the foundation referencing digital assets in
scientific publications, books, and digital repositories. In its realization,
PIDs contain metadata and resolving targets in form of URLs that point to data
sets located on the network. In contrast to PIDs, the target URLs are typically
changing over time; thus, PIDs need continuous maintenance -- an effort that is
increasing tremendously with the advancement of e-Science and the advent of the
Internet-of-Things (IoT). Nowadays, billions of sensors and data sets are
subject of PID assignment. This paper presents a new approach of embedding
location independent targets into PIDs that allows the creation of
maintenance-free PIDs using content-centric network technology and overlay
networks. For proving the validity of the presented approach, the Handle PID
System is used in conjunction with Magnet Link access information encoding,
state-of-the-art decentralized data distribution with BitTorrent, and Named
Data Networking (NDN) as location-independent data access technology for
networks. Contrasting existing approaches, no green-field implementation of PID
or major modifications of the Handle System is required to enable
location-independent data dissemination with maintenance-free PIDs.
</dc:description>
 <dc:description>Comment: Published IEEE paper of the FedCSIS 2016 (SoFAST-WS'16) conference,
  11.-14. September 2016, Gdansk, Poland. Also available online:
  http://ieeexplore.ieee.org/document/7733372/</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2017-05-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08368</dc:identifier>
 <dc:identifier>doi:10.15439/2016F87</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08370</identifier>
 <datestamp>2016-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Empirical Chaos Processes and Blind Deconvolution</dc:title>
 <dc:creator>Ahmed, Ali</dc:creator>
 <dc:creator>Krahmer, Felix</dc:creator>
 <dc:creator>Romberg, Justin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates conditions under which certain kinds of systems of
bilinear equations have a unique structured solution. In particular, we look at
when we can recover vectors $\boldsymbol{w},\boldsymbol{q}$ from observations
of the form \[ y_{\ell} =
&lt;\boldsymbol{w},\boldsymbol{b}_{\ell}&gt;&lt;\boldsymbol{c}_{\ell},\boldsymbol{q}&gt;,
\quad \ell = 1,\ldots,L, \] where $\boldsymbol{b}_\ell,\boldsymbol{c}_\ell$ are
known. We show that if $\boldsymbol{w}\in\mathbb{C}^{M_1}$ and
$\boldsymbol{q}\in\mathbb{C}^{M_2}$ are sparse, with no more than $K$ and $N$
nonzero entries, respectively, and the
$\boldsymbol{b}_\ell,\boldsymbol{c}_\ell$ are generic, selected as independent
Gaussian random vectors, then $\boldsymbol{w},\boldsymbol{q}$ are uniquely
determined from \[
  L \geq \mathrm{Const}\cdot (K+N)\log^5(M_1M_2) \] such equations with high
probability.
  The key ingredient in our analysis is a uniform probabilistic bound on how
far a random process of the form \[Z(\boldsymbol{X}) =
\sum_{\ell=1}^L|\boldsymbol{b}_\ell^*\boldsymbol{X}\boldsymbol{c}_\ell|^2 \]
deviates from its mean over a set of structured matrices
$\boldsymbol{X}\in\mathcal{X}$. As both $\boldsymbol{b}_\ell$ and
$\boldsymbol{c}_\ell$ are random, this is a specialized type of $4$th order
chaos; we refer to $Z(\boldsymbol{X})$ as an {\em empirical chaos process}.
Bounding this process yields a set of general conditions for when the map
$\boldsymbol{X}\rightarrow
\{\boldsymbol{b}_\ell^*\boldsymbol{X}\boldsymbol{c}_\ell\}_{\ell=1}^L$ is a
restricted isometry over the set of matrices $\mathcal{X}$. The conditions are
stated in terms of general geometric properties of the set $\mathcal{X}$, and
are explicitly computed for the case where $\mathcal{X}$ is the set of matrices
that are simultaneously sparse and low rank.
</dc:description>
 <dc:description>Comment: A counter example suggests that the result in Theorem 2 may not be
  completely true. This requires a re-evaluation of the entire manuscript and
  the underlying analytical proofs. The authors have therefore decided to
  withdraw the paper at this point</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2016-09-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08376</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A near-threshold RISC-V core with DSP extensions for scalable IoT
  Endpoint Devices</dc:title>
 <dc:creator>Gautschi, Michael</dc:creator>
 <dc:creator>Schiavone, Pasquale Davide</dc:creator>
 <dc:creator>Traber, Andreas</dc:creator>
 <dc:creator>Loi, Igor</dc:creator>
 <dc:creator>Pullini, Antonio</dc:creator>
 <dc:creator>Rossi, Davide</dc:creator>
 <dc:creator>Flamand, Eric</dc:creator>
 <dc:creator>Gurkaynak, Frank K.</dc:creator>
 <dc:creator>Benini, Luca</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Endpoint devices for Internet-of-Things not only need to work under extremely
tight power envelope of a few milliwatts, but also need to be flexible in their
computing capabilities, from a few kOPS to GOPS. Near-threshold(NT) operation
can achieve higher energy efficiency, and the performance scalability can be
gained through parallelism. In this paper we describe the design of an
open-source RISC-V processor core specifically designed for NT operation in
tightly coupled multi-core clusters. We introduce instruction-extensions and
microarchitectural optimizations to increase the computational density and to
minimize the pressure towards the shared memory hierarchy. For typical
data-intensive sensor processing workloads the proposed core is on average 3.5x
faster and 3.2x more energy-efficient, thanks to a smart L0 buffer to reduce
cache access contentions and support for compressed instructions. SIMD
extensions, such as dot-products, and a built-in L0 storage further reduce the
shared memory accesses by 8x reducing contentions by 3.2x. With four
NT-optimized cores, the cluster is operational from 0.6V to 1.2V achieving a
peak efficiency of 67MOPS/mW in a low-cost 65nm bulk CMOS technology. In a low
power 28nm FDSOI process a peak efficiency of 193MOPS/mW(40MHz, 1mW) can be
achieved.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08381</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the set of uniquely decodable codes with a given sequence of code
  word lengths</dc:title>
 <dc:creator>Woryna, Adam</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  For every natural number $n\geq 2$ and every finite sequence $L$ of natural
numbers, we consider the set $UD_n(L)$ of all uniquely decodable codes over an
$n$-letter alphabet with the sequence $L$ as the sequence of code word lengths,
as well as its subsets $PR_n(L)$ and $FD_n(L)$ consisting of, respectively, the
prefix codes and the codes with finite delay. We derive the estimation for the
quotient $|UD_n(L)|/|PR_n(L)|$, which allows to characterize those sequences
$L$ for which the equality $PR_n(L)=UD_n(L)$ holds. We also characterize those
sequences $L$ for which the equality $FD_n(L)=UD_n(L)$ holds.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08381</dc:identifier>
 <dc:identifier>Discrete Mathematics 340 (2017), pp. 51-57</dc:identifier>
 <dc:identifier>doi:10.1016/j.disc.2016.08.013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08384</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time scale modeling for consensus in sparse directed networks with
  time-varying topologies</dc:title>
 <dc:creator>Martin, Samuel</dc:creator>
 <dc:creator>Morarescu, Irinel-Constantin</dc:creator>
 <dc:creator>Nesic, Dragan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The paper considers the consensus problem in large networks represented by
time-varying directed graphs. A practical way of dealing with large-scale
networks is to reduce their dimension by collapsing the states of nodes
belonging to densely and intensively connected clusters into aggregate
variables. It will be shown that under suitable conditions, the states of the
agents in each cluster converge fast toward a local agreement. Local agreements
correspond to aggregate variables which slowly converge to consensus. Existing
results concerning the time-scale separation in large networks focus on fixed
and undirected graphs. The aim of this work is to extend these results to the
more general case of time-varying directed topologies. It is noteworthy that in
the fixed and undirected graph case the average of the states in each cluster
is time-invariant when neglecting the interactions between clusters. Therefore,
they are good candidates for the aggregate variables. This is no longer
possible here. Instead, we find suitable time-varying weights to compute the
aggregate variables as time-invariant weighted averages of the states in each
cluster. This allows to deal with the more challenging time-varying directed
graph case. We end up with a singularly perturbed system which is analyzed by
using the tools of two time-scales averaging which seem appropriate to this
system.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08384</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08385</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Offline Drawing of Dynamic Trees: Algorithmics and Document Integration</dc:title>
 <dc:creator>Skambath, Malte</dc:creator>
 <dc:creator>Tantau, Till</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  While the algorithmic drawing of static trees is well-understood and
well-supported by software tools, creating animations depicting how a tree
changes over time is currently difficult: software support, if available at
all, is not integrated into a document production workflow and algorithmic
approaches only rarely take temporal information into consideration. During the
production of a presentation or a paper, most users will visualize how, say, a
search tree evolves over time by manually drawing a sequence of trees. We
present an extension of the popular $\TeX$ typesetting system that allows users
to specify dynamic trees inside their documents, together with a new algorithm
for drawing them. Running $\TeX$ on the documents then results in documents in
the SVG format with visually pleasing embedded animations. Our algorithm
produces animations that satisfy a set of natural aesthetic criteria when
possible. On the negative side, we show that one cannot always satisfy all
criteria simultaneously and that minimizing their violations is NP-complete.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08386</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cryptographic Enforcement of Information Flow Policies without Public
  Information via Tree Partitions</dc:title>
 <dc:creator>Crampton, Jason</dc:creator>
 <dc:creator>Farley, Naomi</dc:creator>
 <dc:creator>Gutin, Gregory</dc:creator>
 <dc:creator>Jones, Mark</dc:creator>
 <dc:creator>Poettering, Bertram</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We may enforce an information flow policy by encrypting a protected resource
and ensuring that only users authorized by the policy are able to decrypt the
resource. In most schemes in the literature that use symmetric cryptographic
primitives, each user is assigned a single secret and derives decryption keys
using this secret and publicly available information. Recent work has
challenged this approach by developing schemes, based on a chain partition of
the information flow policy, that do not require public information for key
derivation, the trade-off being that a user may need to be assigned more than
one secret. In general, many different chain partitions exist for the same
policy and, until now, it was not known how to compute an appropriate one.
  In this paper, we introduce the notion of a tree partition, of which chain
partitions are a special case. We show how a tree partition may be used to
define a cryptographic enforcement scheme and prove that such schemes can be
instantiated in such a way as to preserve the strongest security properties
known for cryptographic enforcement schemes. We establish a number of results
linking the amount of secret material that needs to be distributed to users
with a weighted acyclic graph derived from the tree partition. These results
enable us to develop efficient algorithms for deriving tree and chain
partitions that minimize the amount of secret material that needs to be
distributed.
</dc:description>
 <dc:description>Comment: Extended version of conference papers from ACNS 2015 and DBSec 2015</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08395</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Motion Representation with Acceleration Images</dc:title>
 <dc:creator>Kataoka, Hirokatsu</dc:creator>
 <dc:creator>He, Yun</dc:creator>
 <dc:creator>Shirakabe, Soma</dc:creator>
 <dc:creator>Satoh, Yutaka</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Information of time differentiation is extremely important cue for a motion
representation. We have applied first-order differential velocity from a
positional information, moreover we believe that second-order differential
acceleration is also a significant feature in a motion representation. However,
an acceleration image based on a typical optical flow includes motion noises.
We have not employed the acceleration image because the noises are too strong
to catch an effective motion feature in an image sequence. On one hand, the
recent convolutional neural networks (CNN) are robust against input noises. In
this paper, we employ acceleration-stream in addition to the spatial- and
temporal-stream based on the two-stream CNN. We clearly show the effectiveness
of adding the acceleration stream to the two-stream CNN.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08395</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08396</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An algorithm to estimate the vertices of a tetrahedron from uniform
  random points inside</dc:title>
 <dc:creator>V&#xee;lcu, Alina-Daniela</dc:creator>
 <dc:creator>V&#xee;lcu, Gabriel-Eduard</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>60D05, 62F10, 65C05, 65D18, 68U05</dc:subject>
 <dc:description>  In this paper, we give an algorithm to infer the positions of the vertices of
an unknown tetrahedron, given a sample of points which are uniformly
distributed within the tetrahedron. The accuracy of the algorithm is
demonstrated using some numerical experiments.
</dc:description>
 <dc:description>Comment: 15 pages; version accepted for publication in Annali di Matematica
  Pura ed Applicata</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2017-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08396</dc:identifier>
 <dc:identifier>doi:10.1007/s10231-017-0688-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08397</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>USBee: Air-Gap Covert-Channel via Electromagnetic Emission from USB</dc:title>
 <dc:creator>Guri, Mordechai</dc:creator>
 <dc:creator>Monitz, Matan</dc:creator>
 <dc:creator>Elovici, Yuval</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In recent years researchers have demonstrated how attackers could use USB
connectors implanted with RF transmitters to exfiltrate data from secure, and
even air-gapped, computers (e.g., COTTONMOUTH in the leaked NSA ANT catalog).
Such methods require a hardware modification of the USB plug or device, in
which a dedicated RF transmitter is embedded. In this paper we present USBee, a
software that can utilize an unmodified USB device connected to a computer as a
RF transmitter. We demonstrate how a software can intentionally generate
controlled electromagnetic emissions from the data bus of a USB connector. We
also show that the emitted RF signals can be controlled and modulated with
arbitrary binary data. We implement a prototype of USBee, and discuss its
design and implementation details including signal generation and modulation.
We evaluate the transmitter by building a receiver and demodulator using GNU
Radio. Our evaluation shows that USBee can be used for transmitting binary data
to a nearby receiver at a bandwidth of 20 to 80 BPS (bytes per second).
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08412</identifier>
 <datestamp>2016-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on how the problem of Partion of Integers show in Caching</dc:title>
 <dc:creator>Thakur, Mohit</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this article, we show how the finding the number of partitions of same
size of a positive integer show up in caching networks. We present a stochastic
model for caching where user requests (represented with positive integers) are
a random process with uniform distribution and the sum of user requests plays
an important role to tell us about the nature of the caching process. We
discuss Euler's generating function to compute the number of partitions of a
positive integer of same size. Also, we derive a simple approximation for
guessing the guessing the number of partitions of same size and discuss some
special sequences. Lastly, we present a simple algorithm to enumerate all the
partitions of a positive integer of same size.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08413</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotically optimal pilot allocation over Markovian fading channels</dc:title>
 <dc:creator>Larranaga, Maialen</dc:creator>
 <dc:creator>Assaad, Mohamad</dc:creator>
 <dc:creator>Destounis, Apostolos</dc:creator>
 <dc:creator>Paschos, Georgios S.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We investigate a pilot allocation problem in wireless networks over Markovian
fading channels. In wireless systems, the Channel State Information (CSI) is
collected at the Base Station (BS), in particular, this paper considers a
pilot-aided channel estimation method (TDD mode). Typically, there are less
available pilots than users, hence at each slot the scheduler needs to decide
an allocation of pilots to users with the goal of maximizing the long-term
average throughput. There is an inherent tradeoff in how the limited pilots are
used: assign a pilot to a user with up-to-date CSI and good channel condition
for exploitation, or assign a pilot to a user with outdated CSI for
exploration. As we show, the arising pilot allocation problem is a restless
bandit problem and thus its optimal solution is out of reach. In this paper, we
propose an approximation that, through the Lagrangian relaxation approach,
provides a low-complexity heuristic, the Whittle index policy. We prove this
policy to be asymptotically optimal in the many users regime (when the number
of users in the system and the available pilots for channel sensing grow
large). We evaluate the performance of Whittle's index policy in various
scenarios and illustrate its remarkably good performance.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08414</identifier>
 <datestamp>2016-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identification of milestone papers through time-balanced network
  centrality</dc:title>
 <dc:creator>Mariani, Manuel Sebastian</dc:creator>
 <dc:creator>Medo, Matus</dc:creator>
 <dc:creator>Zhang, Yi-Cheng</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Citations between scientific papers and related bibliometric indices, such as
the $h$-index for authors and the impact factor for journals, are being
increasingly used - often in controversial ways - as quantitative tools for
research evaluation. Yet, a fundamental research question remains still open:
to which extent do quantitative metrics capture the significance of scientific
works? We analyze the network of citations among the $449,935$ papers published
by the American Physical Society (APS) journals between 1893 and 2009, and
focus on the comparison of metrics built on the citation count with
network-based metrics. We contrast five article-level metrics with respect to
the rankings that they assign to a set of fundamental papers, called Milestone
Letters, carefully selected by the APS editors for &quot;making long-lived
contributions to physics, either by announcing significant discoveries, or by
initiating new areas of research&quot;. A new metric, which combines PageRank
centrality with the explicit requirement that paper score is not biased by
paper age, is the best-performing metric overall in identifying the Milestone
Letters. The lack of time bias in the new metric makes it also possible to use
it to compare papers of different age on the same scale. We find that
network-based metrics identify the Milestone Letters better than metrics based
on the citation count, which suggests that the structure of the citation
network contains information that can be used to improve the ranking of
scientific publications. The methods and results presented here are relevant
for all evolving systems where network centrality metrics are applied, for
example the World Wide Web and online social networks. An interactive Web
platform where it is possible to view the ranking of the APS papers by rescaled
PageRank is available at the address \url{http://www.sciencenow.info}.
</dc:description>
 <dc:description>Comment: Main text (pp. 1-12) + Appendices (pp. 13-18)</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08414</dc:identifier>
 <dc:identifier>Journal of Informetrics 10, 1207-1223 (2016)</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2016.10.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08418</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>1-Bend RAC Drawings of 1-Planar Graphs</dc:title>
 <dc:creator>Didimo, Walter</dc:creator>
 <dc:creator>Liotta, Giuseppe</dc:creator>
 <dc:creator>Mehrabi, Saeed</dc:creator>
 <dc:creator>Montecchiani, Fabrizio</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  A graph is 1-planar if it has a drawing where each edge is crossed at most
once. A drawing is RAC (Right Angle Crossing) if the edges cross only at right
angles. The relationships between 1-planar graphs and RAC drawings have been
partially studied in the literature. It is known that there are both 1-planar
graphs that are not straight-line RAC drawable and graphs that have a
straight-line RAC drawing but that are not 1-planar. Also, straight-line RAC
drawings always exist for IC-planar graphs, a subclass of 1-planar graphs. One
of the main questions still open is whether every 1-planar graph has a RAC
drawing with at most one bend per edge. We positively answer this question.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08418</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08425</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>1-bend Upward Planar Drawings of SP-digraphs</dc:title>
 <dc:creator>Di Giacomo, Emilio</dc:creator>
 <dc:creator>Liotta, Giuseppe</dc:creator>
 <dc:creator>Montecchiani, Fabrizio</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  It is proved that every series-parallel digraph whose maximum vertex-degree
is $\Delta$ admits an upward planar drawing with at most one bend per edge such
that each edge segment has one of $\Delta$ distinct slopes. This is shown to be
worst-case optimal in terms of the number of slopes. Furthermore, our
construction gives rise to drawings with optimal angular resolution
$\frac{\pi}{\Delta}$. A variant of the proof technique is used to show that
(non-directed) reduced series-parallel graphs and flat series-parallel graphs
have a (non-upward) one-bend planar drawing with $\lceil\frac{\Delta}{2}\rceil$
distinct slopes if biconnected, and with $\lceil\frac{\Delta}{2}\rceil+1$
distinct slopes if connected.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08427</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simultaneous Orthogonal Planarity</dc:title>
 <dc:creator>Angelini, Patrizio</dc:creator>
 <dc:creator>Chaplick, Steven</dc:creator>
 <dc:creator>Cornelsen, Sabine</dc:creator>
 <dc:creator>Da Lozzo, Giordano</dc:creator>
 <dc:creator>Di Battista, Giuseppe</dc:creator>
 <dc:creator>Eades, Peter</dc:creator>
 <dc:creator>Kindermann, Philipp</dc:creator>
 <dc:creator>Kratochvil, Jan</dc:creator>
 <dc:creator>Lipp, Fabian</dc:creator>
 <dc:creator>Rutter, and Ignaz</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We introduce and study the $\textit{OrthoSEFE}-k$ problem: Given $k$ planar
graphs each with maximum degree 4 and the same vertex set, do they admit an
OrthoSEFE, that is, is there an assignment of the vertices to grid points and
of the edges to paths on the grid such that the same edges in distinct graphs
are assigned the same path and such that the assignment induces a planar
orthogonal drawing of each of the $k$ graphs?
  We show that the problem is NP-complete for $k \geq 3$ even if the shared
graph is a Hamiltonian cycle and has sunflower intersection and for $k \geq 2$
even if the shared graph consists of a cycle and of isolated vertices. Whereas
the problem is polynomial-time solvable for $k=2$ when the union graph has
maximum degree five and the shared graph is biconnected. Further, when the
shared graph is biconnected and has sunflower intersection, we show that every
positive instance has an OrthoSEFE with at most three bends per edge.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08427</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08434</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Class Multi-Object Tracking using Changing Point Detection</dc:title>
 <dc:creator>Lee, Byungjae</dc:creator>
 <dc:creator>Erdenee, Enkhbayar</dc:creator>
 <dc:creator>Jin, Songguo</dc:creator>
 <dc:creator>Rhee, Phill Kyu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a robust multi-class multi-object tracking (MCMOT)
formulated by a Bayesian filtering framework. Multi-object tracking for
unlimited object classes is conducted by combining detection responses and
changing point detection (CPD) algorithm. The CPD model is used to observe
abrupt or abnormal changes due to a drift and an occlusion based spatiotemporal
characteristics of track states. The ensemble of convolutional neural network
(CNN) based object detector and Lucas-Kanede Tracker (KLT) based motion
detector is employed to compute the likelihoods of foreground regions as the
detection responses of different object classes. Extensive experiments are
performed using lately introduced challenging benchmark videos; ImageNet VID
and MOT benchmark dataset. The comparison to state-of-the-art video tracking
techniques shows very encouraging results.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08434</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08435</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Label Classification Method Based on Extreme Learning Machines</dc:title>
 <dc:creator>Venkatesan, Rajasekar</dc:creator>
 <dc:creator>Er, Meng Joo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper, an Extreme Learning Machine (ELM) based technique for
Multi-label classification problems is proposed and discussed. In multi-label
classification, each of the input data samples belongs to one or more than one
class labels. The traditional binary and multi-class classification problems
are the subset of the multi-label problem with the number of labels
corresponding to each sample limited to one. The proposed ELM based multi-label
classification technique is evaluated with six different benchmark multi-label
datasets from different domains such as multimedia, text and biology. A
detailed comparison of the results is made by comparing the proposed method
with the results from nine state of the arts techniques for five different
evaluation metrics. The nine methods are chosen from different categories of
multi-label methods. The comparative results shows that the proposed Extreme
Learning Machine based multi-label classification technique is a better
alternative than the existing state of the art methods for multi-label
problems.
</dc:description>
 <dc:description>Comment: 6 pages, 7 figures, 7 tables, ICARCV</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08435</dc:identifier>
 <dc:identifier>doi:10.1109/ICARCV.2014.7064375</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08445</identifier>
 <datestamp>2017-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Delay Performance of Wireless Communications with Imperfect CSI and
  Finite Length Coding</dc:title>
 <dc:creator>Schiessl, Sebastian</dc:creator>
 <dc:creator>Al-Zubaidy, Hussein</dc:creator>
 <dc:creator>Skoglund, Mikael</dc:creator>
 <dc:creator>Gross, James</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  With the rise of critical machine-to-machine applications, next generation
wireless communication systems must be designed with strict constraints on the
latency and reliability. A key question in this context relates to channel
state estimation, which allows the transmitter to adapt the code rate to the
channel. In this work, we characterize the trade-off between the estimation
sequence length and data codeword length: shorter channel estimation leaves
more time for the actual payload transmission but reduces the estimation
accuracy and causes more decoding errors. Using lower coding rates can mitigate
this effect, but may result in a higher backlog of data at the transmitter. We
analyze this trade-off using queueing analysis on top of accurate models of the
physical layer, which also account for the finite blocklength of the channel
code. Based on a novel closed-form approximation for the error probability
given the rate, we show that finding the optimal rate adaptation strategy
becomes a convex problem. The optimal rate adaptation strategy and the optimal
training sequence length, which both depend on the latency and reliability
constraints of the application, can improve the delay performance by an order
of magnitude, compared to suboptimal strategies that do not consider those
constraints.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2017-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08445</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08447</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BreakID: Static Symmetry Breaking for ASP (System Description)</dc:title>
 <dc:creator>Devriendt, Jo</dc:creator>
 <dc:creator>Bogaerts, Bart</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Symmetry breaking has been proven to be an efficient preprocessing technique
for satisfiability solving (SAT). In this paper, we port the state-of-the-art
SAT symmetry breaker BreakID to answer set programming (ASP). The result is a
lightweight tool that can be plugged in between the grounding and the solving
phases that are common when modelling in ASP. We compare our tool with sbass,
the current state-of-the-art symmetry breaker for ASP.
</dc:description>
 <dc:description>Comment: Paper presented at the 9th Workshop on Answer Set Programming and
  Other Computing Paradigms (ASPOCP 2016), New York City, USA, 16 October 2016</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08450</identifier>
 <datestamp>2016-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Compression-Complexity Measure of Integrated Information</dc:title>
 <dc:creator>Virmani, Mohit</dc:creator>
 <dc:creator>Nagaraj, Nithin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Quantifying integrated information is a leading approach towards building a
fundamental theory of consciousness. Integrated Information Theory (IIT) has
gained attention in this regard due to its theoretically strong framework.
However, it faces some limitations such as current state dependence,
computationally expensive and inability to be applied to real brain data. On
the other hand, Perturbational Complexity Index (PCI) is a clinical measure for
distinguishing different levels of consciousness. Though PCI claims to capture
the functional differentiation and integration in brain networks (similar to
IIT), its link to integrated information theories is rather weak. Inspired by
these two approaches, we propose a new measure - $\Phi^C$ using a novel
compression-complexity perspective that serves as a bridge between the two, for
the first time. $\Phi^C$ is founded on the principles of lossless data
compression based complexity measures which characterize the dynamical
complexity of brain networks. $\Phi^{C}$ exhibits following salient
innovations: (i) mathematically well bounded, (ii) negligible current state
dependence unlike $\Phi$, (iii) integrated information measured as
compression-complexity rather than as an infotheoretic quantity, and (iv)
faster to compute since number of atomic bipartitions scales linearly with the
number of nodes of the network, thus avoiding combinatorial explosion. Our
computer simulations show that $\Phi^C$ has similar hierarchy to $&lt;\Phi&gt;$ for
several multiple-node networks and it demonstrates a rich interplay between
differentiation, integration and entropy of the nodes of a network. $\Phi^C$ is
a promising heuristic measure to characterize the quantity of integrated
information (and hence a measure of quantity of consciousness) in larger
networks like human brain and provides an opportunity to test the predictions
of brain complexity on real neural data.
</dc:description>
 <dc:description>Comment: 28 pages, 10 figures</dc:description>
 <dc:date>2016-08-23</dc:date>
 <dc:date>2016-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08450</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08454</identifier>
 <datestamp>2016-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving the Correlation Lower Bound for Simultaneous Orthogonal
  Matching Pursuit</dc:title>
 <dc:creator>Determe, Jean-Fran&#xe7;ois</dc:creator>
 <dc:creator>Louveaux, J&#xe9;r&#xf4;me</dc:creator>
 <dc:creator>Jacques, Laurent</dc:creator>
 <dc:creator>Horlin, Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The simultaneous orthogonal matching pursuit (SOMP) algorithm aims to find
the joint support of a set of sparse signals acquired under a multiple
measurement vector model. Critically, the analysis of SOMP depends on the
maximal inner product of any atom of a suitable dictionary and the current
signal residual, which is formed by the subtraction of previously selected
atoms. This inner product, or correlation, is a key metric to determine the
best atom to pick at each iteration. This paper provides, for each iteration of
SOMP, a novel lower bound of the aforementioned metric for the atoms belonging
to the correct and common joint support of the multiple signals. Although the
bound is obtained for the noiseless case, its main purpose is to intervene in
noisy analyses of SOMP. Finally, it is shown for specific signal patterns that
the proposed bound outperforms state-of-the-art results for SOMP, and
orthogonal matching pursuit (OMP) as a special case.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2016-10-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08454</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2016.2612759</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08456</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matrix Energy as a Measure of Topological Complexity of a Graph</dc:title>
 <dc:creator>Sinha, Kaushik</dc:creator>
 <dc:creator>de Weck, Olivier L.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C50</dc:subject>
 <dc:description>  The complexity of highly interconnected systems is rooted in the interwoven
architecture defined by its connectivity structure. In this paper, we develop
matrix energy of the underlying connectivity structure as a measure of
topological complexity and highlight interpretations about certain global
features of underlying system connectivity patterns. The proposed complexity
metric is shown to satisfy the Weyuker criteria as a measure of its validity as
a formal complexity metric. We also introduce the notion of P point in the
graph density space. The P point acts as a boundary between multiple
connectivity regimes for finite-size graphs.
</dc:description>
 <dc:description>Comment: Finite Graphs, Draft Version</dc:description>
 <dc:date>2016-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08459</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Construction of Zero Cross Correlation Code using a type of Pascal's
  Triangle Matrix for Spectral Amplitude Coding Optical Code Division Multiple
  Access networks</dc:title>
 <dc:creator>Nisar, K S</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper a new method to construct zero cross correlation code with the
help of Pascal's triangle pattern called Pascal's Triangle Matrix Code (PTMC)
for Spectral Amplitude Coding Optical Code Division Multiple Access (SAC-OCDMA)
system is successfully developed. The advantages of this code are simplicity of
code construction, flexibility of choosing code weight and number of users. The
numerical comparison shows that the newly constructed code is better in code
length than the existing codes such as Optical Orthogonal Code (OOC), Hadamard,
Modified Frequency Hopping (MFH) and Modified Double Weight (MDW) codes and it
supports more users than other Optical Spectrum Code Division Multiple Access
(OSCDMA) codes.
</dc:description>
 <dc:date>2016-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08465</identifier>
 <datestamp>2017-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intelligent Pinning Based Cooperative Secondary Control of Distributed
  Generators for Microgrid in Islanding Operation Mode</dc:title>
 <dc:creator>Talebi, M.</dc:creator>
 <dc:creator>Manaffam, S.</dc:creator>
 <dc:creator>Jain, A. K.</dc:creator>
 <dc:creator>Behal, A.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Motivated by the fact that the location(s) and structural properties of the
pinning node(s) affect the algebraic connectivity of a network with respect to
the reference value and thereby, its dynamic performance, this paper studies
the application of intelligent single and multiple pinning of distributed
cooperative secondary control of distributed generators (DGs) in islanded
microgrid operation. It is shown that the intelligent selection of a pinning
set based on the degree of connectivity and distance of leader DG(s) from the
rest of the network improves the transient performance for microgrid voltage
and frequency regulation. The efficacy of the distributed control strategy
based on the proposed algorithms is illustrated via numerical results
simulating typical scenarios for a variety of microgrid configurations.
</dc:description>
 <dc:description>Comment: 8 pages, 11 figures, submitted to Trans. on Power Systems</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08465</dc:identifier>
 <dc:identifier>doi:10.1109/TPWRS.2017.2732958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08469</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Efficiency and Fairness of Multiplayer HTTP-based Adaptive Video
  Streaming</dc:title>
 <dc:creator>Yin, Xiaoqi</dc:creator>
 <dc:creator>Bartulovi&#x107;, Mihovil</dc:creator>
 <dc:creator>Sekar, Vyas</dc:creator>
 <dc:creator>Sinopoli, Bruno</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  User-perceived quality-of-experience (QoE) is critical in internet video
delivery systems. Extensive prior work has studied the design of client-side
bitrate adaptation algorithms to maximize single-player QoE. However,
multiplayer QoE fairness becomes critical as the growth of video traffic makes
it more likely that multiple players share a bottleneck in the network. Despite
several recent proposals, there is still a series of open questions. In this
paper, we bring the problem space to light from a control theory perspective by
formalizing the multiplayer QoE fairness problem and addressing two key
questions in the broader problem space. First, we derive the sufficient
conditions of convergence to steady state QoE fairness under TCP-based
bandwidth sharing scheme. Based on the insight from this analysis that
in-network active bandwidth allocation is needed, we propose a non-linear
MPC-based, router-assisted bandwidth allocation algorithm that regards each
player as closed-loop systems. We use trace-driven simulation to show the
improvement over existing approaches. We identify several research directions
enabled by the control theoretic modeling and envision that control theory can
play an important role on guiding real system design in adaptive video
streaming.
</dc:description>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08469</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08471</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Methods to Improve Large-Scale Microscopy Image Analysis with Prior
  Knowledge and Uncertainty</dc:title>
 <dc:creator>Stegmaier, Johannes</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Multidimensional imaging techniques provide powerful ways to examine various
kinds of scientific questions. The routinely produced datasets in the
terabyte-range, however, can hardly be analyzed manually and require an
extensive use of automated image analysis. The present thesis introduces a new
concept for the estimation and propagation of uncertainty involved in image
analysis operators and new segmentation algorithms that are suitable for
terabyte-scale analyses of 3D+t microscopy images.
</dc:description>
 <dc:description>Comment: 218 pages, 58 figures, PhD thesis, Department of Mechanical
  Engineering, Karlsruhe Institute of Technology, published online with KITopen
  (License: CC BY-SA 3.0, http://dx.doi.org/10.5445/IR/1000057821)</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08471</dc:identifier>
 <dc:identifier>doi:10.5445/IR/1000057821</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08472</identifier>
 <datestamp>2017-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ALLSAT compressed with wildcards. Part 1: Converting CNF's to orthogonal
  DNF's</dc:title>
 <dc:creator>Wild, Marcel</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  For most branching algorithms in Boolean logic &quot;branching&quot; means
&quot;variable-wise branching&quot;. We present the apparently novel technique of
clause-wise branching, which is used to solve the ALLSAT problem for arbitrary
Boolean functions in CNF format. Specifically, it converts a CNF into an
orthogonal DNF, i.e. into an exclusive sum of products. Our method is enhanced
by two ingredients: The use of a good SAT-solver and wildcards beyond the
common don't-care symbol.
</dc:description>
 <dc:description>Comment: 27 pages, 3 figures, 10 Tables</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2017-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08474</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Empirical and Strong Coordination via Soft Covering with Polar Codes</dc:title>
 <dc:creator>Chou, Remi A.</dc:creator>
 <dc:creator>Bloch, Matthieu</dc:creator>
 <dc:creator>Kliewer, Joerg</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We design polar codes for empirical coordination and strong coordination in
two-node networks. Our constructions hinge on the fact that polar codes enable
explicit low complexity schemes for soft covering. We leverage this property to
propose explicit and low-complexity coding schemes that achieve the capacity
regions of both empirical coordination and strong coordination for sequences of
actions taking value in an alphabet of prime cardinality. Our results improve
previously known polar coding schemes, which (i) were restricted to uniform
distributions and to actions obtained via binary symmetric channels for strong
coordination, (ii) required a non-negligible amount of common randomness for
empirical coordination, and (iii) assumed that the simulation of discrete
memoryless channels could be perfectly implemented. As a by-product of our
results, we obtain a polar coding scheme that achieves channel resolvability
for an arbitrary discrete memoryless channel whose input alphabet has prime
cardinality.
</dc:description>
 <dc:description>Comment: 33 pages, 5 figures, submitted to IEEE Transactions on Information
  Theory; parts of the results were presented at the 2015 IEEE International
  Symposium on Information Theory</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08474</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08483</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WNetKAT: A Weighted SDN Programming and Verification Language</dc:title>
 <dc:creator>Larsen, Kim G.</dc:creator>
 <dc:creator>Schmid, Stefan</dc:creator>
 <dc:creator>Xue, Bingtian</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:description>  Programmability and verifiability lie at the heart of the software-defined
networking paradigm. While OpenFlow and its match-action concept provide
primitive operations to manipulate hardware configurations, over the last
years, several more expressive network programming languages have been
developed. This paper presents WNetKAT, the first network programming language
accounting for the fact that networks are inherently weighted, and
communications subject to capacity constraints (e.g., in terms of bandwidth)
and costs (e.g., latency or monetary costs). WNetKAT is based on a syntactic
and semantic extension of the NetKAT algebra. We demonstrate several relevant
applications for WNetKAT, including cost- and capacity-aware reachability, as
well as quality-of-service and fairness aspects. These applications do not only
apply to classic, splittable and unsplittable (s; t)-flows, but also generalize
to more complex network functions and service chains. For example, WNetKAT
allows to model flows which need to traverse certain waypoint functions, which
may change the traffic rate. This paper also shows the relation between the
equivalence problem of WNetKAT and the equivalence problem of the weighted
finite automata, which implies undecidability of the former. However, this
paper also succeeds to prove the decidability of another useful problem, which
is sufficient in many practical scnearios: whether an expression equals to 0.
Moreover, we initiate the discussion of decidable subsets of the whole
language.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2016-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08484</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Opinion Manipulation in Social Networks</dc:title>
 <dc:creator>Silva, Alonso</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this work, we are interested in finding the most efficient use of a budget
to promote an opinion by paying agents within a group to supplant their true
opinions. We model opinions as continuous scalars ranging from 0 to 1 with 1
(0) representing extremely positive (negative) opinion. We focus on asymmetric
confidence between agents. The iterative update of an agent corresponds to the
best response to other agents' actions. The resulting confidence matrix can be
seen as an equivalent Markov chain. We provide simple and efficient algorithms
to solve this problem and we show through an example how to solve the stated
problem in practice.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08484</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08489</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New refiners for permutation group search</dc:title>
 <dc:creator>Jefferson, Christopher</dc:creator>
 <dc:creator>Pfeiffer, Markus</dc:creator>
 <dc:creator>Waldecker, Rebecca</dc:creator>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We describe how orbital graphs can be used to improve the practical
performance of many algorithms for permutation groups, including intersection
and stabilizer problems. First we explain how orbital graphs can be integrated
in partition backtracking, the current state of the art algorithm for many
permutation group problems. We then show how our algorithms perform in
practice, demonstrating improvements of several orders of magnitude for some
problems.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08492</identifier>
 <datestamp>2016-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Separating Components of Attention and Surprise</dc:title>
 <dc:creator>B&#xe6;kgaard, Per</dc:creator>
 <dc:creator>Petersen, Michael Kai</dc:creator>
 <dc:creator>Larsen, Jakob Eg</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Cognitive processes involved in both allocation of attention during decision
making as well as surprise when making mistakes trigger release of the
neurotransmitter norepinephrine, which has been shown to be correlated with an
increase in pupil dilation, in turn reflecting raised levels of arousal.
Extending earlier experiments based on the Attention Network Test (ANT),
separating the neural components of alertness and spatial re-orientation from
the attention involved in more demanding conflict resolution tasks, we
demonstrate that these signatures of attention are so robust that they may be
retrieved even when applying low cost eye tracking in an everyday mobile
computing context. Furthermore we find that the reaction of surprise elicited
when committing mistakes in a decision task, which in the neuroimaging EEG
literature have been referred to as a negativity feedback error correction
signal, may likewise be retrieved solely based on an increase in pupil
dilation.
</dc:description>
 <dc:description>Comment: 13 pages, 10 figures</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08497</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling Cyber-Security Experts' Decision Making Processes using
  Aggregation Operators</dc:title>
 <dc:creator>Miller, Simon</dc:creator>
 <dc:creator>Wagner, Christian</dc:creator>
 <dc:creator>Aickelin, Uwe</dc:creator>
 <dc:creator>Garibaldi, Jonathan M.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  An important role carried out by cyber-security experts is the assessment of
proposed computer systems, during their design stage. This task is fraught with
difficulties and uncertainty, making the knowledge provided by human experts
essential for successful assessment. Today, the increasing number of
progressively complex systems has led to an urgent need to produce tools that
support the expert-led process of system-security assessment. In this research,
we use weighted averages (WAs) and ordered weighted averages (OWAs) with
evolutionary algorithms (EAs) to create aggregation operators that model parts
of the assessment process. We show how individual overall ratings for security
components can be produced from ratings of their characteristics, and how these
individual overall ratings can be aggregated to produce overall rankings of
potential attacks on a system. As well as the identification of salient attacks
and weak points in a prospective system, the proposed method also highlights
which factors and security components contribute most to a component's
difficulty and attack ranking respectively. A real world scenario is used in
which experts were asked to rank a set of technical attacks, and to answer a
series of questions about the security components that are the subject of the
attacks. The work shows how finding good aggregation operators, and identifying
important components and factors of a cyber-security problem can be automated.
The resulting operators have the potential for use as decision aids for systems
designers and cyber-security experts, increasing the amount of assessment that
can be achieved with the limited resources available.
</dc:description>
 <dc:description>Comment: Computers and Security, Volume 62, September 2016, Pages 229-245</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08500</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collaborative Delivery with Energy-Constrained Mobile Robots</dc:title>
 <dc:creator>B&#xe4;rtschi, Andreas</dc:creator>
 <dc:creator>Chalopin, J&#xe9;r&#xe9;mie</dc:creator>
 <dc:creator>Das, Shantanu</dc:creator>
 <dc:creator>Disser, Yann</dc:creator>
 <dc:creator>Geissmann, Barbara</dc:creator>
 <dc:creator>Graf, Daniel</dc:creator>
 <dc:creator>Labourel, Arnaud</dc:creator>
 <dc:creator>Mihal&#xe1;k, Mat&#xfa;&#x161;</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the problem of collectively delivering some message from a
specified source to a designated target location in a graph, using multiple
mobile agents. Each agent has a limited energy which constrains the distance it
can move. Hence multiple agents need to collaborate to move the message, each
agent handing over the message to the next agent to carry it forward. Given the
positions of the agents in the graph and their respective budgets, the problem
of finding a feasible movement schedule for the agents can be challenging. We
consider two variants of the problem: in non-returning delivery, the agents can
stop anywhere; whereas in returning delivery, each agent needs to return to its
starting location, a variant which has not been studied before.
  We first provide a polynomial-time algorithm for returning delivery on trees,
which is in contrast to the known (weak) NP-hardness of the non-returning
version. In addition, we give resource-augmented algorithms for returning
delivery in general graphs. Finally, we give tight lower bounds on the required
resource augmentation for both variants of the problem. In this sense, our
results close the gap left by previous research.
</dc:description>
 <dc:description>Comment: 19 pages. An extended abstract of this paper was published at the
  23rd International Colloquium on Structural Information and Communication
  Complexity 2016, SIROCCO'16</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08500</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08505</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Placing Arrows in Directed Graph Drawings</dc:title>
 <dc:creator>Binucci, Carla</dc:creator>
 <dc:creator>Chimani, Markus</dc:creator>
 <dc:creator>Didimo, Walter</dc:creator>
 <dc:creator>Liotta, Giuseppe</dc:creator>
 <dc:creator>Montecchiani, Fabrizio</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the problem of placing arrow heads in directed graph drawings
without them overlapping other drawn objects. This gives drawings where edge
directions can be deduced unambiguously. We show hardness of the problem,
present exact and heuristic algorithms, and report on a practical study.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08505</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08515</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Language Detection For Short Text Messages In Social Media</dc:title>
 <dc:creator>Balazevic, Ivana</dc:creator>
 <dc:creator>Braun, Mikio</dc:creator>
 <dc:creator>M&#xfc;ller, Klaus-Robert</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  With the constant growth of the World Wide Web and the number of documents in
different languages accordingly, the need for reliable language detection tools
has increased as well. Platforms such as Twitter with predominantly short texts
are becoming important information resources, which additionally imposes the
need for short texts language detection algorithms. In this paper, we show how
incorporating personalized user-specific information into the language
detection algorithm leads to an important improvement of detection results. To
choose the best algorithm for language detection for short text messages, we
investigate several machine learning approaches. These approaches include the
use of the well-known classifiers such as SVM and logistic regression, a
dictionary based approach, and a probabilistic model based on modified
Kneser-Ney smoothing. Furthermore, the extension of the probabilistic model to
include additional user-specific information such as evidence accumulation per
user and user interface language is explored, with the goal of improving the
classification performance. The proposed approaches are evaluated on randomly
collected Twitter data containing Latin as well as non-Latin alphabet languages
and the quality of the obtained results is compared, followed by the selection
of the best performing algorithm. This algorithm is then evaluated against two
already existing general language detection tools: Chromium Compact Language
Detector 2 (CLD2) and langid, where our method significantly outperforms the
results achieved by both of the mentioned methods. Additionally, a preview of
benefits and possible applications of having a reliable language detection
algorithm is given.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08515</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08517</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Empirically Grounded Agent-Based Models of Innovation Diffusion: A
  Critical Review</dc:title>
 <dc:creator>Zhang, Haifeng</dc:creator>
 <dc:creator>Vorobeychik, Yevgeniy</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Innovation diffusion has been studied extensively in a variety of
disciplines, including sociology, economics, marketing, ecology, and computer
science. Traditional literature on innovation diffusion has been dominated by
models of aggregate behavior and trends. However, the agent-based modeling
(ABM) paradigm is gaining popularity as it captures agent heterogeneity and
enables fine-grained modeling of interactions mediated by social and geographic
networks. While most ABM work on innovation diffusion is theoretical,
empirically grounded models are increasingly important, particularly in guiding
policy decisions. We present a critical review of empirically grounded
agent-based models of innovation diffusion, developing a categorization of this
research based on types of agent models as well as applications. By connecting
the modeling methodologies in the fields of information and innovation
diffusion, we suggest that the maximum likelihood estimation framework widely
used in the former is a promising paradigm for calibration of agent-based
models for innovation diffusion. Although many advances have been made to
standardize ABM methodology, we identify four major issues in model calibration
and validation, and suggest potential solutions.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08517</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08521</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Profitable Task Allocation in Mobile Cloud Computing</dc:title>
 <dc:creator>Khaledi, Mojgan</dc:creator>
 <dc:creator>khaledi, Mehrdad</dc:creator>
 <dc:creator>Kasera, Sneha Kumar</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We propose a game theoretic framework for task allocation in mobile cloud
computing that corresponds to offloading of compute tasks to a group of nearby
mobile devices. Specifically, in our framework, a distributor node holds a
multidimensional auction for allocating the tasks of a job among nearby mobile
nodes based on their computational capabilities and also the cost of
computation at these nodes, with the goal of reducing the overall job
completion time. Our proposed auction also has the desired incentive
compatibility property that ensures that mobile devices truthfully reveal their
capabilities and costs and that those devices benefit from the task allocation.
To deal with node mobility, we perform multiple auctions over adaptive time
intervals. We develop a heuristic approach to dynamically find the best time
intervals between auctions to minimize unnecessary auctions and the
accompanying overheads. We evaluate our framework and methods using both real
world and synthetic mobility traces. Our evaluation results show that our game
theoretic framework improves the job completion time by a factor of 2-5 in
comparison to the time taken for executing the job locally, while minimizing
the number of auctions and the accompanying overheads. Our approach is also
profitable for the nearby nodes that execute the distributor's tasks with these
nodes receiving a compensation higher than their actual costs.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08522</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distributed Multilevel Force-directed Algorithm</dc:title>
 <dc:creator>Arleo, Alessio</dc:creator>
 <dc:creator>Didimo, Walter</dc:creator>
 <dc:creator>Liotta, Giuseppe</dc:creator>
 <dc:creator>Montecchiani, Fabrizio</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The wide availability of powerful and inexpensive cloud computing services
naturally motivates the study of distributed graph layout algorithms, able to
scale to very large graphs. Nowadays, to process Big Data, companies are
increasingly relying on PaaS infrastructures rather than buying and maintaining
complex and expensive hardware. So far, only a few examples of basic
force-directed algorithms that work in a distributed environment have been
described. Instead, the design of a distributed multilevel force-directed
algorithm is a much more challenging task, not yet addressed. We present the
first multilevel force-directed algorithm based on a distributed vertex-centric
paradigm, and its implementation on Giraph, a popular platform for distributed
graph algorithms. Experiments show the effectiveness and the scalability of the
approach. Using an inexpensive cloud computing service of Amazon, we draw
graphs with ten million edges in about 60 minutes.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08526</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Person Pose Estimation with Local Joint-to-Person Associations</dc:title>
 <dc:creator>Iqbal, Umar</dc:creator>
 <dc:creator>Gall, Juergen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Despite of the recent success of neural networks for human pose estimation,
current approaches are limited to pose estimation of a single person and cannot
handle humans in groups or crowds. In this work, we propose a method that
estimates the poses of multiple persons in an image in which a person can be
occluded by another person or might be truncated. To this end, we consider
multi-person pose estimation as a joint-to-person association problem. We
construct a fully connected graph from a set of detected joint candidates in an
image and resolve the joint-to-person association and outlier detection using
integer linear programming. Since solving joint-to-person association jointly
for all persons in an image is an NP-hard problem and even approximations are
expensive, we solve the problem locally for each person. On the challenging
MPII Human Pose Dataset for multiple persons, our approach achieves the
accuracy of a state-of-the-art method, but it is 6,000 to 19,000 times faster.
</dc:description>
 <dc:description>Comment: Accepted to European Conference on Computer Vision (ECCV) Workshops,
  Crowd Understanding, 2016</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08526</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08527</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The $(h,k)$-Server Problem on Bounded Depth Trees</dc:title>
 <dc:creator>Bansal, Nikhil</dc:creator>
 <dc:creator>Eli&#xe1;&#x161;, Marek</dc:creator>
 <dc:creator>Je&#x17c;, &#x141;ukasz</dc:creator>
 <dc:creator>Koumoutsos, Grigorios</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the $k$-server problem in the resource augmentation setting i.e.,
when the performance of the online algorithm with $k$ servers is compared to
the offline optimal solution with $h \leq k$ servers. The problem is very
poorly understood beyond uniform metrics. For this special case, the classic
$k$-server algorithms are roughly $(1+1/\epsilon)$-competitive when
$k=(1+\epsilon) h$, for any $\epsilon &gt;0$. Surprisingly however, no
$o(h)$-competitive algorithm is known even for HSTs of depth 2 and even when
$k/h$ is arbitrarily large.
  We obtain several new results for the problem. First we show that the known
$k$-server algorithms do not work even on very simple metrics. In particular,
the Double Coverage algorithm has competitive ratio $\Omega(h)$ irrespective of
the value of $k$, even for depth-2 HSTs. Similarly the Work Function Algorithm,
that is believed to be optimal for all metric spaces when $k=h$, has
competitive ratio $\Omega(h)$ on depth-3 HSTs even if $k=2h$. Our main result
is a new algorithm that is $O(1)$-competitive for constant depth trees,
whenever $k =(1+\epsilon )h$ for any $\epsilon &gt; 0$. Finally, we give a general
lower bound that any deterministic online algorithm has competitive ratio at
least 2.4 even for depth-2 HSTs and when $k/h$ is arbitrarily large. This gives
a surprising qualitative separation between uniform metrics and depth-2 HSTs
for the $(h,k)$-server problem, and gives the strongest known lower bound for
the problem on general metrics.
</dc:description>
 <dc:description>Comment: Appeared in SODA 2017</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2017-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08527</dc:identifier>
 <dc:identifier>doi:10.1137/1.9781611974782.65</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08538</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low Ply Drawings of Trees</dc:title>
 <dc:creator>Angelini, Patrizio</dc:creator>
 <dc:creator>Bekos, Michael A.</dc:creator>
 <dc:creator>Bruckdorfer, Till</dc:creator>
 <dc:creator>Han&#x10d;l Jr., Jaroslav</dc:creator>
 <dc:creator>Kaufmann, Michael</dc:creator>
 <dc:creator>Kobourov, Stephen</dc:creator>
 <dc:creator>Symvonis, Antonios</dc:creator>
 <dc:creator>Valtr, Pavel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the recently introduced model of \emph{low ply graph drawing}, in
which the ply-disks of the vertices do not have many common overlaps, which
results in a good distribution of the vertices in the plane. The
\emph{ply-disk} of a vertex in a straight-line drawing is the disk centered at
it whose radius is half the length of its longest incident edge. The largest
number of ply-disks having a common overlap is called the \emph{ply-number} of
the drawing.
  We focus on trees. We first consider drawings of trees with constant
ply-number, proving that they may require exponential area, even for stars, and
that they may not even exist for bounded-degree trees. Then, we turn our
attention to drawings with logarithmic ply-number and show that trees with
maximum degree $6$ always admit such drawings in polynomial area.
</dc:description>
 <dc:description>Comment: This is a complete access version of a paper that will appear in the
  proceedings of GD2016</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08545</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Controllability of Conditional Simple Temporal Networks is
  PSPACE-complete</dc:title>
 <dc:creator>Cairo, Massimo</dc:creator>
 <dc:creator>Rizzi, Romeo</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Even after the proposal of various solution algorithms, the precise
computational complexity of checking whether a Conditional Temporal Network is
Dynamically Controllable had still remained widely open. This issue gets
settled in this paper which provides constructions, algorithms, and bridging
lemmas and arguments to formally prove that: (1) the problem is PSPACE-hard,
and (2) the problem lies in PSPACE.
</dc:description>
 <dc:description>Comment: Accepted to TIME2016</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08545</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08570</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpolations of Smoke and Liquid Simulations</dc:title>
 <dc:creator>Thuerey, Nils</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>I.6.8</dc:subject>
 <dc:subject>I.3.7</dc:subject>
 <dc:description>  We present a novel method to interpolate smoke and liquid simulations in
order to perform data-driven fluid simulations. Our approach calculates a dense
space-time deformation using grid-based signed-distance functions of the
inputs. A key advantage of this implicit Eulerian representation is that it
allows us to use powerful techniques from the optical flow area. We employ a
five-dimensional optical flow solve. In combination with a projection
algorithm, and residual iterations, we achieve a robust matching of the inputs.
Once the match is computed, arbitrary in between variants can be created very
efficiently. To concatenate multiple long-range deformations, we propose a
novel alignment technique. Our approach has numerous advantages, including
automatic matches without user input, volumetric deformations that can be
applied to details around the surface, and the inherent handling of topology
changes. As a result, we can interpolate swirling smoke clouds, and splashing
liquid simulations. We can even match and interpolate phenomena with
fundamentally different physics: a drop of liquid, and a blob of heavy smoke.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08570</dc:identifier>
 <dc:identifier>ACM Transactions on Graphics, 36(1), 2017</dc:identifier>
 <dc:identifier>doi:10.1145/2956233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08574</identifier>
 <datestamp>2016-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applying Naive Bayes Classification to Google Play Apps Categorization</dc:title>
 <dc:creator>Olabenjo, Babatunde</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  There are over one million apps on Google Play Store and over half a million
publishers. Having such a huge number of apps and developers can pose a
challenge to app users and new publishers on the store. Discovering apps can be
challenging if apps are not correctly published in the right category, and, in
turn, reduce earnings for app developers. Additionally, with over 41 categories
on Google Play Store, deciding on the right category to publish an app can be
challenging for developers due to the number of categories they have to choose
from. Machine Learning has been very useful, especially in classification
problems such sentiment analysis, document classification and spam detection.
These strategies can also be applied to app categorization on Google Play Store
to suggest appropriate categories for app publishers using details from their
application.
  In this project, we built two variations of the Naive Bayes classifier using
open metadata from top developer apps on Google Play Store in other to classify
new apps on the store. These classifiers are then evaluated using various
evaluation methods and their results compared against each other. The results
show that the Naive Bayes algorithm performs well for our classification
problem and can potentially automate app categorization for Android app
publishers on Google Play Store
</dc:description>
 <dc:description>Comment: Experiment Results</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08576</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistically Robust SWIPT for Secrecy MISOME Systems</dc:title>
 <dc:creator>Khandaker, Muhammad R. A.</dc:creator>
 <dc:creator>Wong, Kai-Kit</dc:creator>
 <dc:creator>Zhang, Yangyang</dc:creator>
 <dc:creator>Zheng, Zhongbin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers simultaneous wireless information and power transfer
(SWIPT) in a multiple-input single-output (MISO) downlink system consisting of
one multi-antenna transmitter, one single-antenna information receiver (IR),
multiple multi-antenna eavesdroppers (Eves) and multiple single-antenna
energy-harvesting receivers (ERs). The main objective is to keep the
probability of the legitimate user's achievable secrecy rate outage as well as
the ERs' harvested energy outage caused by channel state information (CSI)
uncertainties below some prescribed thresholds. As is well known, the secrecy
rate outage constraints present a significant analytical and computational
challenge. Incorporating the energy harvesting (EH) outage constraints only
intensifies that challenge. In this paper, we address this challenging issue
using convex restriction approaches which are then proved to yield rank-one
optimal beamforming solutions. Numerical results reveal the effectiveness of
the proposed schemes.
</dc:description>
 <dc:description>Comment: This is an open access article accepted for publication as a regular
  paper in the IEEE Transactions on Information Forensics &amp; Security. Copyright
  (c) 2016 IEEE. Personal use of this material is permitted. However,
  permission to use this material for any other purposes must be obtained from
  the IEEE by sending a request to pubs-permissions@ieee.org</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08576</dc:identifier>
 <dc:identifier>IEEE Trans. Inf. Forensics &amp; Security, 2016</dc:identifier>
 <dc:identifier>doi:10.1109/TIFS.2016.2611478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08578</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bitonic st-orderings for Upward Planar Graphs</dc:title>
 <dc:creator>Gronemann, Martin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Canonical orderings serve as the basis for many incremental planar drawing
algorithms. All these techniques, however, have in common that they are limited
to undirected graphs. While $st$-orderings do extend to directed graphs,
especially planar $st$-graphs, they do not offer the same properties as
canonical orderings. In this work we extend the so called bitonic
$st$-orderings to directed graphs. We fully characterize planar $st$-graphs
that admit such an ordering and provide a linear-time algorithm for recognition
and ordering. If for a graph no bitonic $st$-ordering exists, we show how to
find in linear time a minimum set of edges to split such that the resulting
graph admits one. With this new technique we are able to draw every upward
planar graph on $n$ vertices by using at most one bend per edge, at most $n -
3$ bends in total and within quadratic area.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08584</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Error Invariants for Concurrent Traces</dc:title>
 <dc:creator>Holzer, Andreas</dc:creator>
 <dc:creator>Schwartz-Narbonne, Daniel</dc:creator>
 <dc:creator>Befrouei, Mitra Tabaei</dc:creator>
 <dc:creator>Weissenbacher, Georg</dc:creator>
 <dc:creator>Wies, Thomas</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Error invariants are assertions that over-approximate the reachable program
states at a given position in an error trace while only capturing states that
will still lead to failure if execution of the trace is continued from that
position. Such assertions reflect the effect of statements that are involved in
the root cause of an error and its propagation, enabling slicing of statements
that do not contribute to the error. Previous work on error invariants focused
on sequential programs. We generalize error invariants to concurrent traces by
augmenting them with additional information about hazards such as
write-after-write events, which are often involved in race conditions and
atomicity violations. By providing the option to include varying levels of
details in error invariants-such as hazards and branching information-our
approach allows the programmer to systematically analyze individual aspects of
an error trace.We have implemented a hazard-sensitive slicing tool for
concurrent traces based on error invariants and evaluated it on benchmarks
covering a broad range of real-world concurrency bugs. Hazard-sensitive slicing
significantly reduced the length of the considered traces and still maintained
the root causes of the concurrency bugs.
</dc:description>
 <dc:description>Comment: 21 pages, 7 figures, accepted in FM 2016</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08584</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08589</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Game-Theoretic Modeling of Driver and Vehicle Interactions for
  Verification and Validation of Autonomous Vehicle Control Systems</dc:title>
 <dc:creator>Li, Nan</dc:creator>
 <dc:creator>Oyler, Dave</dc:creator>
 <dc:creator>Zhang, Mengxuan</dc:creator>
 <dc:creator>Yildiz, Yildiray</dc:creator>
 <dc:creator>Kolmanovsky, Ilya</dc:creator>
 <dc:creator>Girard, Anouck</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Autonomous driving has been the subject of increased interest in recent years
both in industry and in academia. Serious efforts are being pursued to address
legal, technical and logistical problems and make autonomous cars a viable
option for everyday transportation. One significant challenge is the time and
effort required for the verification and validation of the decision and control
algorithms employed in these vehicles to ensure a safe and comfortable driving
experience. Hundreds of thousands of miles of driving tests are required to
achieve a well calibrated control system that is capable of operating an
autonomous vehicle in an uncertain traffic environment where multiple
interactions between vehicles and drivers simultaneously occur. Traffic
simulators where these interactions can be modeled and represented with
reasonable fidelity can help decrease the time and effort necessary for the
development of the autonomous driving control algorithms by providing a venue
where acceptable initial control calibrations can be achieved quickly and
safely before actual road tests. In this paper, we present a game theoretic
traffic model that can be used to 1) test and compare various autonomous
vehicle decision and control systems and 2) calibrate the parameters of an
existing control system. We demonstrate two example case studies, where, in the
first case, we test and quantitatively compare two autonomous vehicle control
systems in terms of their safety and performance, and, in the second case, we
optimize the parameters of an autonomous vehicle control system, utilizing the
proposed traffic model and simulation environment.
</dc:description>
 <dc:description>Comment: 13 pages, 16 figures</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08589</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08592</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Frobenius problem for the shuffle operation</dc:title>
 <dc:creator>Nicholson, Jeremy</dc:creator>
 <dc:creator>Rampersad, Narad</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We characterize the finite sets S of words such that that the iterated
shuffle of S is co-finite and we give some bounds on the length of a longest
word not in the iterated shuffle of S.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08592</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08596</identifier>
 <datestamp>2017-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A statistical model of tristimulus measurements within and between OLED
  displays</dc:title>
 <dc:creator>Raitoharju, Matti</dc:creator>
 <dc:creator>Kallio, Samu</dc:creator>
 <dc:creator>Pellikka, Matti</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present an empirical model for noises in color measurements from OLED
displays. According to measured data the noise is not isotropic in the XYZ
space, instead most of the noise is along an axis that is parallel to a vector
from origin to measured XYZ vector. The presented empirical model is simple and
depends only on the measured XYZ values. Our tests show that the variations
between multiple panels of the same type have similar distribution as the
temporal noise in measurements from a single panel, but a larger magnitude.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures</dc:description>
 <dc:date>2016-08-28</dc:date>
 <dc:date>2017-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08607</identifier>
 <datestamp>2017-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matching-Based Selection with Incomplete Lists for Decomposition
  Multi-Objective Optimization</dc:title>
 <dc:creator>Wu, Mengyuan</dc:creator>
 <dc:creator>Li, Ke</dc:creator>
 <dc:creator>Kwong, Sam</dc:creator>
 <dc:creator>Zhou, Yu</dc:creator>
 <dc:creator>Zhang, Qingfu</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The balance between convergence and diversity is a key issue of evolutionary
multi-objective optimization. The recently proposed stable matching-based
selection provides a new perspective to handle this balance under the framework
of decomposition multi-objective optimization. In particular, the stable
matching between subproblems and solutions, which achieves an equilibrium
between their mutual preferences, implicitly strikes a balance between the
convergence and diversity. Nevertheless, the original stable matching model has
a high risk of matching a solution with a unfavorable subproblem which finally
leads to an imbalanced selection result. In this paper, we propose an adaptive
two-level stable matching-based selection for decomposition multi-objective
optimization. Specifically, borrowing the idea of stable matching with
incomplete lists, we match each solution with one of its favorite subproblems
by restricting the length of its preference list during the first-level stable
matching. During the second-level stable matching, the remaining subproblems
are thereafter matched with their favorite solutions according to the classic
stable matching model. In particular, we develop an adaptive mechanism to
automatically set the length of preference list for each solution according to
its local competitiveness. The performance of our proposed method is validated
and compared with several state-of-the-art evolutionary multi-objective
optimization algorithms on 62 benchmark problem instances. Empirical results
fully demonstrate the competitive performance of our proposed method on
problems with complicated Pareto sets and those with more than three
objectives.
</dc:description>
 <dc:description>Comment: 27 pages, 3 figures, 15 tables</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2017-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08609</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A new fast algorithm for reproducing complex networks with community
  structure</dc:title>
 <dc:creator>Kowalczyk, Mateusz</dc:creator>
 <dc:creator>Fronczak, Piotr</dc:creator>
 <dc:creator>Fronczak, Agata</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this paper, we introduce a new algorithm allowing for generation of
networks with heterogeneity of both node degrees and community sizes. The
quality and efficiency of the algorithm is analyzed and compared to the other,
so far the most popular algorithm which was proposed by Lancichinetti et al. We
discuss the advantages and shortcomings of both algorithms indicating the areas
of their potential application.
</dc:description>
 <dc:description>Comment: 17 pages, 6 figures</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08609</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08614</identifier>
 <datestamp>2016-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What makes ImageNet good for transfer learning?</dc:title>
 <dc:creator>Huh, Minyoung</dc:creator>
 <dc:creator>Agrawal, Pulkit</dc:creator>
 <dc:creator>Efros, Alexei A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The tremendous success of ImageNet-trained deep features on a wide range of
transfer tasks begs the question: what are the properties of the ImageNet
dataset that are critical for learning good, general-purpose features? This
work provides an empirical investigation of various facets of this question: Is
more pre-training data always better? How does feature quality depend on the
number of training examples per class? Does adding more object classes improve
performance? For the same data budget, how should the data be split into
classes? Is fine-grained recognition necessary for learning good features?
Given the same number of training classes, is it better to have coarse classes
or fine-grained classes? Which is better: more classes or more examples per
class? To answer these and related questions, we pre-trained CNN features on
various subsets of the ImageNet dataset and evaluated transfer performance on
PASCAL detection, PASCAL action classification, and SUN scene classification
tasks. Our overall findings suggest that most changes in the choice of
pre-training data long thought to be critical do not significantly affect
transfer performance.? Given the same number of training classes, is it better
to have coarse classes or fine-grained classes? Which is better: more classes
or more examples per class?
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2016-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08614</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08622</identifier>
 <datestamp>2017-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Age of Information: Real-Time Status Updating by Multiple Sources</dc:title>
 <dc:creator>Yates, Roy D.</dc:creator>
 <dc:creator>Kaul, Sanjit K.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We examine multiple independent sources providing status updates to a monitor
through simple queues. We formulate an Age of Information (AoI) timeliness
metric and derive a general result for the AoI that is applicable to a wide
variety of multiple source service systems. For first-come first-served and two
types of last-come first-served systems with Poisson arrivals and exponential
service times, we find the region of feasible average status ages for multiple
updating sources. We then use these results to characterize how a service
facility can be shared among multiple updating sources. A new simplified
technique for evaluating the AoI in finite-state continuous-time queueing
systems is also derived. Based on stochastic hybrid systems, this method makes
AoI evaluation to be comparable in complexity to finding the stationary
distribution of a finite-state Markov chain.
</dc:description>
 <dc:description>Comment: Submitted to the IEEE Transactions on Information Theory</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2017-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08622</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08644</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial Multiplexing of QPSK Signals with a Single Radio: Antenna Design
  and Over-the-Air Experiments</dc:title>
 <dc:creator>Yousefbeiki, Mohsen</dc:creator>
 <dc:creator>Austin, Andrew C. M.</dc:creator>
 <dc:creator>Mosig, Juan R.</dc:creator>
 <dc:creator>Burg, Andreas</dc:creator>
 <dc:creator>Perruisseau-Carrier, Julien</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The paper describes the implementation and performance analysis of the first
fully-operational beam-space MIMO antenna for the spatial multiplexing of two
QPSK streams. The antenna is composed of a planar three-port radiator with two
varactor diodes terminating the passive ports. Pattern reconfiguration is used
to encode the MIMO information onto orthogonal virtual basis patterns in the
far-field. A measurement campaign was conducted to compare the performance of
the beam-space MIMO system with a conventional 2-by-?2 MIMO system under
realistic propagation conditions. Propagation measurements were conducted for
both systems and the mutual information and symbol error rates were estimated
from Monte-Carlo simulations over the measured channel matrices. The results
show the beam-space MIMO system and the conventional MIMO system exhibit
similar finite-constellation capacity and error performance in NLOS scenarios
when there is sufficient scattering in the channel. In comparison, in LOS
channels, the capacity performance is observed to depend on the relative
polarization of the receiving antennas.
</dc:description>
 <dc:description>Comment: 31 pages, 23 figures</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08644</dc:identifier>
 <dc:identifier>doi:10.1109/TAP.2016.2624138</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08646</identifier>
 <datestamp>2017-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LiRa: A New Likelihood-Based Similarity Score for Collaborative
  Filtering</dc:title>
 <dc:creator>Strnadova-Neeley, Veronika</dc:creator>
 <dc:creator>Buluc, Aydin</dc:creator>
 <dc:creator>Gilbert, John R.</dc:creator>
 <dc:creator>Oliker, Leonid</dc:creator>
 <dc:creator>Ouyang, Weimin</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Recommender system data presents unique challenges to the data mining,
machine learning, and algorithms communities. The high missing data rate, in
combination with the large scale and high dimensionality that is typical of
recommender systems data, requires new tools and methods for efficient data
analysis. Here, we address the challenge of evaluating similarity between two
users in a recommender system, where for each user only a small set of ratings
is available. We present a new similarity score, that we call LiRa, based on a
statistical model of user similarity, for large-scale, discrete valued data
with many missing values. We show that this score, based on a ratio of
likelihoods, is more effective at identifying similar users than traditional
similarity scores in user-based collaborative filtering, such as the Pearson
correlation coefficient. We argue that our approach has significant potential
to improve both accuracy and scalability in collaborative filtering.
</dc:description>
 <dc:description>Comment: - added acknowledgments - fixed typos (results unchanged) 8 pages</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2017-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08646</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08648</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using parallelism techniques to improve sequential and multi-core
  sorting performance</dc:title>
 <dc:creator>Gerbessiotis, Alexandros V</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68W99, 68W40</dc:subject>
 <dc:description>  We propose new sequential sorting operations by adapting techniques and
methods used for designing parallel sorting algorithms. Although the norm is to
parallelize a sequential algorithm to improve performance, we adapt a
contrarian approach: we employ parallel computing techniques to speed up
sequential sorting. Our methods can also work for multi-core sorting with minor
adjustments that do not necessarily require full parallelization of the
original sequential algorithm. The proposed approach leads to the development
of asymptotically efficient deterministic and randomized sorting operations
whose practical sequential and multi-core performance, as witnessed by an
experimental study, matches or surpasses existing optimized sorting algorithm
implementations.
  We utilize parallel sorting techniques such as deterministic regular sampling
and random oversampling. We extend the notion of deterministic regular sampling
into deterministic regular oversampling for sequential and multi-core sorting
and demonstrate its potential. We then show how these techniques can be used
for sequential sorting and also lead to better multi-core sorting algorithm
performance as witnessed by the undertaken experimental study.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08658</identifier>
 <datestamp>2016-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Devito: automated fast finite difference computation</dc:title>
 <dc:creator>Kukreja, Navjot</dc:creator>
 <dc:creator>Louboutin, Mathias</dc:creator>
 <dc:creator>Vieira, Felippe</dc:creator>
 <dc:creator>Luporini, Fabio</dc:creator>
 <dc:creator>Lange, Michael</dc:creator>
 <dc:creator>Gorman, Gerard</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Domain specific languages have successfully been used in a variety of fields
to cleanly express scientific problems as well as to simplify implementation
and performance opti- mization on different computer architectures. Although a
large number of stencil languages are available, finite differ- ence domain
specific languages have proved challenging to design because most practical use
cases require additional features that fall outside the finite difference
abstraction. Inspired by the complexity of real-world seismic imaging problems,
we introduce Devito, a domain specific language in which high level equations
are expressed using symbolic expressions from the SymPy package. Complex
equations are automatically manipulated, optimized, and translated into highly
optimized C code that aims to perform compa- rably or better than hand-tuned
code. All this is transpar- ent to users, who only see concise symbolic
mathematical expressions.
</dc:description>
 <dc:description>Comment: Accepted at WolfHPC 2016</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2016-10-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08660</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tunable QoS-Aware Network Survivability</dc:title>
 <dc:creator>Yallouz, Jose</dc:creator>
 <dc:creator>Orda, Ariel</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Coping with network failures has been recognized as an issue of major
importance in terms of social security, stability and prosperity. It has become
clear that current networking standards fall short of coping with the complex
challenge of surviving failures. The need to address this challenge has become
a focal point of networking research. In particular, the concept of
\textbf{\emph{tunable survivability}} offers major performance improvements
over traditional approaches. Indeed, while the traditional approach aims at
providing full (100\%) protection against network failures through disjoint
paths, it was realized that this requirement is too restrictive in practice.
Tunable survivability provides a quantitative measure for specifying the
desired level (0\%-100\%) of survivability and offers flexibility in the choice
of the routing paths. Previous work focused on the simpler class of
&quot;bottleneck&quot; criteria, such as bandwidth. In this study, we focus on the
important and much more complex class of \emph{additive} criteria, such as
delay and cost. First, we establish some (in part, counter-intuitive)
properties of the optimal solution. Then, we establish efficient algorithmic
schemes for optimizing the level of survivability under additive end-to-end QoS
bounds. Subsequently, through extensive simulations, we show that, at the price
of \emph{negligible} reduction in the level of survivability, a major
improvement (up to a factor of $2$) is obtained in terms of end-to-end QoS
performance. Finally, we exploit the above findings in the context of a network
design problem, in which, for a given investment budget, we aim to improve the
survivability of the network links.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08662</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hanani-Tutte for Radial Planarity II</dc:title>
 <dc:creator>Fulek, Radoslav</dc:creator>
 <dc:creator>Pelsmajer, Michael</dc:creator>
 <dc:creator>Schaefer, Marcus</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  A drawing of a graph $G$ is radial if the vertices of $G$ are placed on
concentric circles $C_1, \ldots, C_k$ with common center $c$, and edges are
drawn radially: every edge intersects every circle centered at $c$ at most
once. $G$ is radial planar if it has a radial embedding, that is, a
crossing-free radial drawing. If the vertices of $G$ are ordered or partitioned
into ordered levels (as they are for leveled graphs), we require that the
assignment of vertices to circles corresponds to the given ordering or
leveling. A pair of edges $e$ and $f$ in a graph is independent if $e$ and $f$
do not share a vertex.
  We show that a graph $G$ is radial planar if $G$ has a radial drawing in
which every two independent edges cross an even number of times; the radial
embedding has the same leveling as the radial drawing. In other words, we
establish the strong Hanani-Tutte theorem for radial planarity. This
characterization yields a very simple algorithm for radial planarity testing.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08663</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lopsided Approximation of Amoebas</dc:title>
 <dc:creator>Forsg&#xe5;rd, Jens</dc:creator>
 <dc:creator>Matusevich, Laura Felicia</dc:creator>
 <dc:creator>Mehlhop, Nathan</dc:creator>
 <dc:creator>de Wolff, Timo</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Mathematics - Commutative Algebra</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>13P15, 14Q20, 14T05 (Primary), 90C59, 90C90 (Secondary)</dc:subject>
 <dc:description>  The amoeba of a Laurent polynomial is the image of the corresponding
hypersurface under the coordinatewise log absolute value map. In this article,
we demonstrate that a theoretical amoeba approximation method due to Purbhoo
can be used efficiently in practice. To do this, we resolve the main bottleneck
in Purbhoo's method by exploiting relations between cyclic resultants. We use
the same approach to give an approximation of the Log preimage of the amoeba of
a Laurent polynomial using semi-algebraic sets. We also provide a SINGULAR/SAGE
implementation of these algorithms, which shows a significant speedup when our
specialized cyclic resultant computation is used, versus a general purpose
resultant algorithm.
</dc:description>
 <dc:description>Comment: Minor revision; final version; 15 pages, 2 figures, 2 tables</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2017-09-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08663</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08678</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Recovery With Integrality Constraints</dc:title>
 <dc:creator>Lange, Jan-Hendrik</dc:creator>
 <dc:creator>Pfetsch, Marc E.</dc:creator>
 <dc:creator>Seib, Bianca M.</dc:creator>
 <dc:creator>Tillmann, Andreas M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, we investigate conditions for the unique recoverability of
sparse integer-valued signals from few linear measurements. Both the objective
of minimizing the number of nonzero components, the so-called $\ell_0$-norm, as
well as its popular substitute, the $\ell_1$-norm, are covered. Furthermore,
integer constraints and possible bounds on the variables are investigated. Our
results show that the additional prior knowledge of signal integrality allows
for recovering more signals than what can be guaranteed by the established
recovery conditions from (continuous) compressed sensing. Moreover, even though
the considered problems are NP-hard in general (even with an
$\ell_1$-objective), we investigate testing the $\ell_0$-recovery conditions
via some numerical experiments; it turns out that the corresponding problems
are quite hard to solve in practice. However, medium-sized instances of
$\ell_0$- and $\ell_1$-minimization with binary variables can be solved exactly
within reasonable time.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08679</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Roughly Polynomial Time: A Concept of Tractability Covering All Known
  Natural NP-complete Problems</dc:title>
 <dc:creator>Farago, Andras</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We introduce a concept of efficiency for which we can prove that it applies
to all paddable languages, but still does not conflict with potential worst
case intractability. Note that the family of paddable languages apparently
includes all known natural NP-complete problems. We call our concept Roughly
Polynomial Time (RoughP). A language $L,$ over an at least 2-symbol alphabet,
is in RoughP, if the following hold: (1) there exists a bijective encoding
$\alpha$ of strings, such that both $\alpha$ and its inverse are computable in
polynomial time; (2) there is a polynomial time algorithm $\cal A$, which is an
errorless heuristic for $L,$ with exponentially vanishing failure rate relative
to the $\alpha$-spheres $S^{(\alpha)}_n=\{\alpha(x)\,|\;\, |x|=n\}$. It means,
$\cal A$ always correctly decides whether $x\in L$ or $x\notin L$, whenever it
outputs a decision. For some inputs, however, it may not output a decision,
rather it may return a special sign, meaning &quot;don't know.&quot; But the latter can
happen only on an exponentially small fraction of each $\alpha$-sphere. We
prove that RoughP contains all paddable languages. This may contribute to the
explanation of the often observed gap between practical algorithm performance
and theoretical worst case analysis for hard problems. Furthermore, the proof
also provides a general method to construct the desired encoding and the
errorless heuristic. Additionally, we also show how to use it for efficiently
generating large, random, guaranteed positive and negative test instances for
any paddable language, including all known natural NP-complete problems. In
fact, it appears that every practical decision task (whether in NP or not) can
be represented by paddable languages, and, therefore, our RoughP framework
applies to all of them. We also explore some connections between RoughP and
other complexity classes.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08679</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08682</identifier>
 <datestamp>2016-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Colored Petri Net Model of Simulation for Performance Evaluation for
  IEEE 802.22 based Network</dc:title>
 <dc:creator>Vasconcelos, Eduardo M.</dc:creator>
 <dc:creator>Dias, Kelvin L.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Cognitive Radio is a new concept that allows radio devices access to licensed
bands since they do not cause harmful interferences to systems that hold the
license of use. The main motivation for the increase of research on Cognitive
Radio is the scarcity of non-licensed bands due to the large employment of
wireless networks on cities. In this paper, we describe a Cognitive Radio Model
of Simulation designed through the Colored Petri Net Formalism. This represents
an effort to deliver to scientific community a model of simulation that is
easily extensible and graphically validated. Through comparison with
literature, we have demonstrated that this model is not invalid.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, 1 table and 1 Algorithm</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2016-09-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08683</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Invariance Control Synthesis for Switched Systems: An Interval Analysis
  Approach</dc:title>
 <dc:creator>Li, Yinan</dc:creator>
 <dc:creator>Liu, Jun</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper focuses on the invariance control problem for discrete-time
switched nonlinear systems. The proposed approach computes controlled invariant
sets in a finite number of iterations and directly yields a partition-based
invariance controller using the information recorded during the computation. In
contrast with Lyapunov-based control methods, this method does not require the
subsystems to have common equilibrium points. Algorithms are developed for
computing both outer and inner approximations of the maximal controlled
invariant sets, which are represented as finite unions of intervals. The
general convergence results of interval methods allow us to obtain arbitrarily
precise approximations without any stability assumptions. In addition,
invariant inner approximations can be computed provided that the switched
system satisfies a robustly controlled invariance condition. Under the same
condition, we also prove the existence of an invariance controller based on
partitions of the state space. Our method is illustrated with three examples
drawn from different applications and compared with existing work in the
literature.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08687</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lattice based integration algorithms: Kronecker sequences and rank-1
  lattices</dc:title>
 <dc:creator>Dick, Josef</dc:creator>
 <dc:creator>Pillichshammer, Friedrich</dc:creator>
 <dc:creator>Suzuki, Kosuke</dc:creator>
 <dc:creator>Ullrich, Mario</dc:creator>
 <dc:creator>Yoshiki, Takehito</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>65D30, 65D32, 11K31</dc:subject>
 <dc:description>  We prove upper bounds on the order of convergence of lattice based algorithms
for numerical integration in function spaces of dominating mixed smoothness on
the unit cube with homogeneous boundary condition. More precisely, we study
worst-case integration errors for Besov spaces of dominating mixed smoothness
$\mathring{\mathbf{B}}^s_{p,\theta}$, which also comprise the concept of
Sobolev spaces of dominating mixed smoothness $\mathring{\mathbf{H}}^s_{p}$ as
special cases. The considered algorithms are quasi-Monte Carlo rules with
underlying nodes from $T_N(\mathbb{Z}^d) \cap [0,1)^d$, where $T_N$ is a real
invertible generator matrix of size $d$. For such rules the worst-case error
can be bounded in terms of the Zaremba index of the lattice
$\mathbb{X}_N=T_N(\mathbb{Z}^d)$. We apply this result to Kronecker lattices
and to rank-1 lattice point sets, which both lead to optimal error bounds up to
$\log N$-factors for arbitrary smoothness $s$. The advantage of Kronecker
lattices and classical lattice point sets is that the run-time of algorithms
generating these point sets is very short.
</dc:description>
 <dc:description>Comment: 19 pages</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08687</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08689</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deleting Powers in Words</dc:title>
 <dc:creator>Machacek, John</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>68Q42, 68Q45, 68R15</dc:subject>
 <dc:subject>F.4.2</dc:subject>
 <dc:subject>F.4.3</dc:subject>
 <dc:description>  We consider the language consisting of all words such that it is possible to
obtain the empty word by iteratively deleting powers. It turns out that in the
case of deleting squares in binary words this language is regular, and in the
case of deleting squares in words over a larger alphabet the language is not
regular. However, for deleting squares over any alphabet we find that this
language can be generated by a linear index grammar which is a mildly context
sensitive grammar formalism. In the general case we show that this language is
generated by an indexed grammar.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2017-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08689</dc:identifier>
 <dc:identifier>Journal of Automata, Languages and Combinatorics 21 (2016) 4,
  339--349</dc:identifier>
 <dc:identifier>doi:10.25596/jalc-2016-339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08691</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One-Minute Derivation of The Conjugate Gradient Algorithm</dc:title>
 <dc:creator>Anjum, Muhammad Ali Raza</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  One of the great triumphs in the history of numerical methods was the
discovery of the Conjugate Gradient (CG) algorithm. It could solve a symmetric
positive-definite system of linear equations of dimension N in exactly N steps.
As many practical problems at that time belonged to this category, CG algorithm
became rapidly popular. It remains popular even today due to its immense
computational power. But despite its amazing computational ability, mathematics
of this algorithm is not easy to learn. Lengthy derivations, redundant
notations, and over-emphasis on formal presentation make it much difficult for
a beginner to master this algorithm. This paper aims to serve as a starting
point for such readers. It provides a curt, easy-to-follow but minimalist
derivation of the algorithm by keeping the sufficient steps only, maintaining a
uniform notation, and focusing entirely on the ease of reader.
</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08691</dc:identifier>
 <dc:identifier>Journal of Telematics and Informatics, Vol 4, No 1 (2016): March
  2016</dc:identifier>
 <dc:identifier>doi:10.12928/jti.v4i1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08698</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reconstructing parameters of spreading models from partial observations</dc:title>
 <dc:creator>Lokhov, Andrey Y.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Spreading processes are often modelled as a stochastic dynamics occurring on
top of a given network with edge weights corresponding to the transmission
probabilities. Knowledge of veracious transmission probabilities is essential
for prediction, optimization, and control of diffusion dynamics. Unfortunately,
in most cases the transmission rates are unknown and need to be reconstructed
from the spreading data. Moreover, in realistic settings it is impossible to
monitor the state of each node at every time, and thus the data is highly
incomplete. We introduce an efficient dynamic message-passing algorithm, which
is able to reconstruct parameters of the spreading model given only partial
information on the activation times of nodes in the network. The method is
generalizable to a large class of dynamic models, as well to the case of
temporal graphs.
</dc:description>
 <dc:description>Comment: Accepted to NIPS 2016</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08698</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08704</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-Optimal Lower Bounds on Quantifier Depth and Weisfeiler-Leman
  Refinement Steps</dc:title>
 <dc:creator>Berkholz, Christoph</dc:creator>
 <dc:creator>Nordstr&#xf6;m, Jakob</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>F.2.3</dc:subject>
 <dc:description>  We prove near-optimal trade-offs for quantifier depth versus number of
variables in first-order logic by exhibiting pairs of $n$-element structures
that can be distinguished by a $k$-variable first-order sentence but where
every such sentence requires quantifier depth at least $n^{\Omega(k/\log k)}$.
Our trade-offs also apply to first-order counting logic, and by the known
connection to the $k$-dimensional Weisfeiler--Leman algorithm imply
near-optimal lower bounds on the number of refinement iterations.
  A key component in our proof is the hardness condensation technique recently
introduced by [Razborov '16] in the context of proof complexity. We apply this
method to reduce the domain size of relational structures while maintaining the
minimal quantifier depth to distinguish them in finite variable logics.
</dc:description>
 <dc:description>Comment: This is the full-length version of a paper with the same title which
  appeared in Proceedings of the 31st Annual ACM/IEEE Symposium on Logic in
  Computer Science (LICS '16)</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08704</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08710</identifier>
 <datestamp>2017-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pruning Filters for Efficient ConvNets</dc:title>
 <dc:creator>Li, Hao</dc:creator>
 <dc:creator>Kadav, Asim</dc:creator>
 <dc:creator>Durdanovic, Igor</dc:creator>
 <dc:creator>Samet, Hanan</dc:creator>
 <dc:creator>Graf, Hans Peter</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The success of CNNs in various applications is accompanied by a significant
increase in the computation and parameter storage costs. Recent efforts toward
reducing these overheads involve pruning and compressing the weights of various
layers without hurting original accuracy. However, magnitude-based pruning of
weights reduces a significant number of parameters from the fully connected
layers and may not adequately reduce the computation costs in the convolutional
layers due to irregular sparsity in the pruned networks. We present an
acceleration method for CNNs, where we prune filters from CNNs that are
identified as having a small effect on the output accuracy. By removing whole
filters in the network together with their connecting feature maps, the
computation costs are reduced significantly. In contrast to pruning weights,
this approach does not result in sparse connectivity patterns. Hence, it does
not need the support of sparse convolution libraries and can work with existing
efficient BLAS libraries for dense matrix multiplications. We show that even
simple filter pruning techniques can reduce inference costs for VGG-16 by up to
34% and ResNet-110 by up to 38% on CIFAR10 while regaining close to the
original accuracy by retraining the networks.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2017</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:date>2017-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08711</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Engagement Detection in Meetings</dc:title>
 <dc:creator>Frank, Maria</dc:creator>
 <dc:creator>Tofighi, Ghassem</dc:creator>
 <dc:creator>Gu, Haisong</dc:creator>
 <dc:creator>Fruchter, Renate</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Group meetings are frequent business events aimed to develop and conduct
project work, such as Big Room design and construction project meetings. To be
effective in these meetings, participants need to have an engaged mental state.
The mental state of participants however, is hidden from other participants,
and thereby difficult to evaluate. Mental state is understood as an inner
process of thinking and feeling, that is formed of a conglomerate of mental
representations and propositional attitudes. There is a need to create
transparency of these hidden states to understand, evaluate and influence them.
Facilitators need to evaluate the meeting situation and adjust for higher
engagement and productivity. This paper presents a framework that defines a
spectrum of engagement states and an array of classifiers aimed to detect the
engagement state of participants in real time. The Engagement Framework
integrates multi-modal information from 2D and 3D imaging and sound. Engagement
is detected and evaluated at participants and aggregated at group level. We use
empirical data collected at the lab of Konica Minolta, Inc. to test initial
applications of this framework. The paper presents examples of the tested
engagement classifiers, which are based on research in psychology,
communication, and human computer interaction. Their accuracy is illustrated in
dyadic interaction for engagement detection. In closing we discuss the
potential extension to complex group collaboration settings and future feedback
implementations.
</dc:description>
 <dc:description>Comment: The paper has been published on ICCCBE 2016.
  http://www.see.eng.osaka-u.ac.jp/seeit/icccbe2016/
  http://www.see.eng.osaka-u.ac.jp/seeit/icccbe2016/download/Tentative_Time_Table_ICCCBE2016_2016-05-10.pdf</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08716</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring Machine Intelligence Through Visual Question Answering</dc:title>
 <dc:creator>Zitnick, C. Lawrence</dc:creator>
 <dc:creator>Agrawal, Aishwarya</dc:creator>
 <dc:creator>Antol, Stanislaw</dc:creator>
 <dc:creator>Mitchell, Margaret</dc:creator>
 <dc:creator>Batra, Dhruv</dc:creator>
 <dc:creator>Parikh, Devi</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  As machines have become more intelligent, there has been a renewed interest
in methods for measuring their intelligence. A common approach is to propose
tasks for which a human excels, but one which machines find difficult. However,
an ideal task should also be easy to evaluate and not be easily gameable. We
begin with a case study exploring the recently popular task of image captioning
and its limitations as a task for measuring machine intelligence. An
alternative and more promising task is Visual Question Answering that tests a
machine's ability to reason about language and vision. We describe a dataset
unprecedented in size created for the task that contains over 760,000 human
generated questions about images. Using around 10 million human generated
answers, machines may be easily evaluated.
</dc:description>
 <dc:description>Comment: AI Magazine, 2016</dc:description>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08724</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Programming Language With a POMDP Inside</dc:title>
 <dc:creator>Lin, Christopher H.</dc:creator>
 <dc:creator>Mausam</dc:creator>
 <dc:creator>Weld, Daniel S.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We present POAPS, a novel planning system for defining Partially Observable
Markov Decision Processes (POMDPs) that abstracts away from POMDP details for
the benefit of non-expert practitioners. POAPS includes an expressive adaptive
programming language based on Lisp that has constructs for choice points that
can be dynamically optimized. Non-experts can use our language to write
adaptive programs that have partially observable components without needing to
specify belief/hidden states or reason about probabilities. POAPS is also a
compiler that defines and performs the transformation of any program written in
our language into a POMDP with control knowledge. We demonstrate the generality
and power of POAPS in the rapidly growing domain of human computation by
describing its expressiveness and simplicity by writing several POAPS programs
for common crowdsourcing tasks.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08725</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Making On-Demand Routing Efficient with Route-Request Aggregation</dc:title>
 <dc:creator>Mirzazad-Barijough, Maziar</dc:creator>
 <dc:creator>Garcia-Luna-Aceves, J. J.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In theory, on-demand routing is very attractive for mobile ad hoc networks
(MANET), because it induces signaling only for those destinations for which
there is data traffic. However, in practice, the signaling overhead of existing
on-demand routing protocols becomes excessive as the rate of topology changes
increases due to mobility or other causes. We introduce the first on-demand
routing approach that eliminates the main limitation of on-demand routing by
aggregating route requests (RREQ) for the same destinations. The approach can
be applied to any existing on-demand routing protocol, and we introduce the
Ad-hoc Demand-Aggregated Routing with Adaptation (ADARA) as an example of how
RREQ aggregation can be used. ADARA is compared to AODV and OLSR using
discrete-event simulations, and the results show that aggregating RREQs can
make on-demand routing more efficient than existing proactive or on-demand
routing protocols.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08725</dc:identifier>
 <dc:identifier>doi:10.1145/2988287.2989155</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08729</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Medium Access Control for Full-Duplex Networks with
  Half-Duplex Clients</dc:title>
 <dc:creator>Chen, Shih-Ying</dc:creator>
 <dc:creator>Huang, Ting-Feng</dc:creator>
 <dc:creator>Lin, Kate Ching-Ju</dc:creator>
 <dc:creator>Hong, H. -W. Peter</dc:creator>
 <dc:creator>Sabharwal, Ashutosh</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The feasibility of practical in-band full-duplex radios has recently been
demonstrated experimentally. One way to leverage full-duplex in a network
setting is to enable three-node full-duplex, where a full- duplex access point
(AP) transmits data to one node yet simultaneously receives data from another
node. Such three-node full-duplex communication however introduces inter-client
interference, directly impacting the full-duplex gain. It hence may not always
be beneficial to enable three-node full-duplex transmissions. In this paper, we
present a distributed full-duplex medium access control (MAC) protocol that
allows an AP to adaptively switch between full-duplex and half-duplex modes. We
formulate a model that determines the probabilities of full-duplex and
half-duplex access so as to maximize the expected network throughput. A MAC
protocol is further proposed to enable the AP and clients to contend for either
full-duplex or half-duplex transmissions based on their assigned probabilities
in a distributed way. Our evaluation shows that, by combining the advantages of
centralized probabilistic scheduling and distributed random access, our design
improves the overall throughput by 2.70x and 1.53x, on average, as compared to
half-duplex 802.11 and greedy downlink-uplink client pairing.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08736</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collective Intelligence for Smarter API Recommendations in Python</dc:title>
 <dc:creator>D'Souza, Andrea Renika</dc:creator>
 <dc:creator>Yang, Di</dc:creator>
 <dc:creator>Lopes, Cristina V.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Software developers use Application Programming Interfaces (APIs) of
libraries and frameworks extensively while writing programs. In this context,
the recommendations provided in code completion pop-ups help developers choose
the desired methods. The candidate lists recommended by these tools, however,
tend to be large, ordered alphabetically and sometimes even incomplete. A fair
amount of work has been done recently to improve the relevance of these code
completion results, especially for statically typed languages like Java.
However, these proposed techniques rely on the static type of the object and
are therefore inapplicable for a dynamically typed language like Python. In
this paper, we present PyReco, an intelligent code completion system for Python
which uses the mined API usages from open source repositories to order the
results based on relevance rather than the conventional alphabetic order. To
recommend suggestions that are relevant for a working context, a nearest
neighbor classifier is used to identify the best matching usage among all the
extracted usage patterns. To evaluate the effectiveness of our system, the code
completion queries are automatically extracted from projects and tested
quantitatively using a ten-fold cross validation technique. The evaluation
shows that our approach outperforms the alphabetically ordered API
recommendation systems in recommending APIs for standard, as well as,
third-party libraries.
</dc:description>
 <dc:description>Comment: 10 pages, SCAM 2016</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08736</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08738</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Dictionary-based Approach to Racism Detection in Dutch Social Media</dc:title>
 <dc:creator>Tulkens, St&#xe9;phan</dc:creator>
 <dc:creator>Hilte, Lisa</dc:creator>
 <dc:creator>Lodewyckx, Elise</dc:creator>
 <dc:creator>Verhoeven, Ben</dc:creator>
 <dc:creator>Daelemans, Walter</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a dictionary-based approach to racism detection in Dutch social
media comments, which were retrieved from two public Belgian social media sites
likely to attract racist reactions. These comments were labeled as racist or
non-racist by multiple annotators. For our approach, three discourse
dictionaries were created: first, we created a dictionary by retrieving
possibly racist and more neutral terms from the training data, and then
augmenting these with more general words to remove some bias. A second
dictionary was created through automatic expansion using a \texttt{word2vec}
model trained on a large corpus of general Dutch text. Finally, a third
dictionary was created by manually filtering out incorrect expansions. We
trained multiple Support Vector Machines, using the distribution of words over
the different categories in the dictionaries as features. The best-performing
model used the manually cleaned dictionary and obtained an F-score of 0.46 for
the racist class on a test set consisting of unseen Dutch comments, retrieved
from the same sites used for the training set. The automated expansion of the
dictionary only slightly boosted the model's performance, and this increase in
performance was not statistically significant. The fact that the coverage of
the expanded dictionaries did increase indicates that the words that were
automatically added did occur in the corpus, but were not able to meaningfully
impact performance. The dictionaries, code, and the procedure for requesting
the corpus are available at: https://github.com/clips/hades
</dc:description>
 <dc:description>Comment: 7 pages, presented at the first workshop on Text Analytics for
  Cybersecurity and Online Safety (TA-COS), collocated with LREC 2016</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08738</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08740</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>1700 Forests</dc:title>
 <dc:creator>Dershowitz, Nachum</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Since ordered trees and Dyck paths are equinumerous, so are ordered forests
and grand-Dyck paths that start with an upwards step.
</dc:description>
 <dc:description>Comment: For OEIS entry</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08742</identifier>
 <datestamp>2018-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Polar Coding Scheme for the Interference Channel</dc:title>
 <dc:creator>Zheng, Mengfan</dc:creator>
 <dc:creator>Ling, Cong</dc:creator>
 <dc:creator>Chen, Wen</dc:creator>
 <dc:creator>Tao, Meixia</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Existing polar coding schemes for the two-user interference channel follow
the original idea of Han and Kobayashi, in which component messages are encoded
independently and then mapped by some deterministic functions (i.e.,
homogeneous superposition coding). In this paper, we propose a new polar coding
scheme for the interference channel based on the heterogeneous superposition
coding approach of Chong, Motani and Garg. We prove that fully joint decoding
(the receivers simultaneously decode both senders' common messages and the
intended sender's private message) in the Han-Kobayashi strategy can be
simplified to two types of partially joint decoders, which are friendly to
polar coding with practical decoding algorithms. The proposed coding scheme
requires less auxiliary random variables and no deterministic functions.
Further, we extend this result to interference networks and show that the
proposed partially joint decoding scheme is a general method for designing
heterogeneous superposition polar coding schemes in interference networks.
</dc:description>
 <dc:description>Comment: 48 pages, 5 figures, submitted to IEEE Transactions on Information
  Theory</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2018-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08744</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Economic Analysis of Crowdsourced Wireless Community Networks</dc:title>
 <dc:creator>Ma, Qian</dc:creator>
 <dc:creator>Gao, Lin</dc:creator>
 <dc:creator>Liu, Ya-Feng</dc:creator>
 <dc:creator>Huang, Jianwei</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Crowdsourced wireless community networks can effectively alleviate the
limited coverage issue of Wi-Fi access points (APs), by encouraging individuals
(users) to share their private residential Wi-Fi APs with others. In this
paper, we provide a comprehensive economic analysis for such a crowdsourced
network, with the particular focus on the users' behavior analysis and the
community network operator's pricing design. Specifically, we formulate the
interactions between the network operator and users as a two-layer Stackelberg
model, where the operator determining the pricing scheme in Layer I, and then
users determining their Wi-Fi sharing schemes in Layer II. First, we analyze
the user behavior in Layer II via a two-stage membership selection and network
access game, for both small-scale networks and large-scale networks. Then, we
design a partial price differentiation scheme for the operator in Layer I,
which generalizes both the complete price differentiation scheme and the single
pricing scheme (i.e., no price differentiation). We show that the proposed
partial pricing scheme can achieve a good tradeoff between the revenue and the
implementation complexity. Numerical results demonstrate that when using the
partial pricing scheme with only two prices, we can increase the operator's
revenue up to 124.44% comparing with the single pricing scheme, and can achieve
an average of 80% of the maximum operator revenue under the complete price
differentiation scheme.
</dc:description>
 <dc:description>Comment: This manuscript serves as the online technical report for the article
  published in the IEEE Transactions on Mobile Computing (TMC), 2016</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08744</dc:identifier>
 <dc:identifier>doi:10.1109/TMC.2016.2606390</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08749</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary Particle Swarm Optimization versus Hybrid Genetic Algorithm for
  Inferring Well Supported Phylogenetic Trees</dc:title>
 <dc:creator>AlKindy, Bassam</dc:creator>
 <dc:creator>Al-Nuaimi, Bashar</dc:creator>
 <dc:creator>Guyeux, Christophe</dc:creator>
 <dc:creator>Couchot, Jean-Fran&#xe7;ois</dc:creator>
 <dc:creator>Salomon, Michel</dc:creator>
 <dc:creator>Alsrraj, Reem</dc:creator>
 <dc:creator>Philippe, Laurent</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:description>  The amount of completely sequenced chloroplast genomes increases rapidly
every day, leading to the possibility to build large-scale phylogenetic trees
of plant species. Considering a subset of close plant species defined according
to their chloroplasts, the phylogenetic tree that can be inferred by their core
genes is not necessarily well supported, due to the possible occurrence of
problematic genes (i.e., homoplasy, incomplete lineage sorting, horizontal gene
transfers, etc.) which may blur the phylogenetic signal. However, a trustworthy
phylogenetic tree can still be obtained provided such a number of blurring
genes is reduced. The problem is thus to determine the largest subset of core
genes that produces the best-supported tree. To discard problematic genes and
due to the overwhelming number of possible combinations, this article focuses
on how to extract the largest subset of sequences in order to obtain the most
supported species tree. Due to computational complexity, a distributed Binary
Particle Swarm Optimization (BPSO) is proposed in sequential and distributed
fashions. Obtained results from both versions of the BPSO are compared with
those computed using an hybrid approach embedding both genetic algorithms and
statistical tests. The proposal has been applied to different cases of plant
families, leading to encouraging results for these families.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08749</dc:identifier>
 <dc:identifier>Lecture Notes in Bioinformatics LNBI series, 9874, 165--179, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08753</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Look, no Beacons! Optimal All-in-One EchoSLAM</dc:title>
 <dc:creator>Krekovic, Miranda</dc:creator>
 <dc:creator>Dokmanic, Ivan</dc:creator>
 <dc:creator>Vetterli, Martin</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We study the problem of simultaneously reconstructing a polygonal room and a
trajectory of a device equipped with a (nearly) collocated omnidirectional
source and receiver. The device measures arrival times of echoes of pulses
emitted by the source and picked up by the receiver. No prior knowledge about
the device's trajectory is required. Most existing approaches addressing this
problem assume multiple sources or receivers, or they assume that some of these
are static, serving as beacons. Unlike earlier approaches, we take into account
the measurement noise and various constraints on the geometry by formulating
the solution as a minimizer of a cost function similar to \emph{stress} in
multidimensional scaling. We study uniqueness of the reconstruction from
first-order echoes, and we show that in addition to the usual invariance to
rigid motions, new ambiguities arise for important classes of rooms and
trajectories. We support our theoretical developments with a number of
numerical experiments.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures, submitted to Asilomar Conference on Signals,
  Systems, and Computers Website</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08753</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08754</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Concolic Testing for Hybrid Systems</dc:title>
 <dc:creator>Kong, Pingfan</dc:creator>
 <dc:creator>Li, Yi</dc:creator>
 <dc:creator>Chen, Xiaohong</dc:creator>
 <dc:creator>Sun, Jun</dc:creator>
 <dc:creator>Sun, Meng</dc:creator>
 <dc:creator>Wang, Jingyi</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Hybrid systems exhibit both continuous and discrete behavior. Analyzing
hybrid systems is known to be hard. Inspired by the idea of concolic testing
(of programs), we investigate whether we can combine random sampling and
symbolic execution in order to effectively verify hybrid systems. We identify a
sufficient condition under which such a combination is more effective than
random sampling. Furthermore, we analyze different strategies of combining
random sampling and symbolic execution and propose an algorithm which allows us
to dynamically switch between them so as to reduce the overall cost. Our method
has been implemented as a web-based checker named HyChecker. HyChecker has been
evaluated with benchmark hybrid systems and a water treatment system in order
to test its effectiveness.
</dc:description>
 <dc:description>Comment: Full paper accepted by Formal Methods Europe 2016 containing appendix</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08761</identifier>
 <datestamp>2016-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>hi-RF: Incremental Learning Random Forest for large-scale multi-class
  Data Classification</dc:title>
 <dc:creator>Xie, Tingting</dc:creator>
 <dc:creator>Peng, Yuxing</dc:creator>
 <dc:creator>Wang, Changjian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In recent years, dynamically growing data and incrementally growing number of
classes pose new challenges to large-scale data classification research. Most
traditional methods struggle to balance the precision and computational burden
when data and its number of classes increased. However, some methods are with
weak precision, and the others are time-consuming. In this paper, we propose an
incremental learning method, namely, heterogeneous incremental Nearest Class
Mean Random Forest (hi-RF), to handle this issue. It is a heterogeneous method
that either replaces trees or updates trees leaves in the random forest
adaptively, to reduce the computational time in comparable performance, when
data of new classes arrive. Specifically, to keep the accuracy, one proportion
of trees are replaced by new NCM decision trees; to reduce the computational
load, the rest trees are updated their leaves probabilities only. Most of all,
out-of-bag estimation and out-of-bag boosting are proposed to balance the
accuracy and the computational efficiency. Fair experiments were conducted and
demonstrated its comparable precision with much less computational time.
</dc:description>
 <dc:description>Comment: Accepted by AIIE2016</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2016-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08761</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08779</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid and Subexponential Linear Logics Technical Report</dc:title>
 <dc:creator>Despeyroux, Jo&#xeb;lle</dc:creator>
 <dc:creator>Olarte, Carlos</dc:creator>
 <dc:creator>Pimentel, Elaine</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  HyLL (Hybrid Linear Logic) and SELL (Subexponential Linear Logic) are logical
frameworks that have been extensively used for specifying systems that exhibit
modalities such as temporal or spatial ones. Both frameworks have linear logic
(LL) as a common ground and they admit (cut-free) complete focused proof
systems. The difference between the two logics relies on the way modalities are
handled. In HyLL, truth judgments are labelled by worlds and hybrid connectives
relate worlds with formulas. In SELL, the linear logic exponentials (!, ?) are
decorated with labels representing locations, and an ordering on such labels
defines the provability relation among resources in those locations. It is well
known that SELL, as a logical framework, is strictly more expressive than LL.
However, so far, it was not clear whether HyLL is more expressive than LL
and/or SELL. In this paper, we show an encoding of the HyLL's logical rules
into LL with the highest level of adequacy, hence showing that HyLL is as
expressive as LL. We also propose an encoding of HyLL into SELL $\doublecup$
(SELL plus quantification over locations) that gives better insights about the
meaning of worlds in HyLL. We conclude our expressiveness study by showing that
previous attempts of encoding Computational Tree Logic (CTL) operators into
HyLL cannot be extended to consider the whole set of temporal connectives. We
show that a system of LL with fixed points is indeed needed to faithfully
encode the behavior of such temporal operators.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08779</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08782</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training Deep Spiking Neural Networks using Backpropagation</dc:title>
 <dc:creator>Lee, Jun Haeng</dc:creator>
 <dc:creator>Delbruck, Tobi</dc:creator>
 <dc:creator>Pfeiffer, Michael</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deep spiking neural networks (SNNs) hold great potential for improving the
latency and energy efficiency of deep neural networks through event-based
computation. However, training such networks is difficult due to the
non-differentiable nature of asynchronous spike events. In this paper, we
introduce a novel technique, which treats the membrane potentials of spiking
neurons as differentiable signals, where discontinuities at spike times are
only considered as noise. This enables an error backpropagation mechanism for
deep SNNs, which works directly on spike signals and membrane potentials. Thus,
compared with previous methods relying on indirect training and conversion, our
technique has the potential to capture the statics of spikes more precisely.
Our novel framework outperforms all previously reported results for SNNs on the
permutation invariant MNIST benchmark, as well as the N-MNIST benchmark
recorded with event-based vision sensors.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08782</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08787</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Security checklist for IaaS cloud deployments</dc:title>
 <dc:creator>H&#xe9;der, M.</dc:creator>
 <dc:creator>Bisztray, F.</dc:creator>
 <dc:creator>Lakatos, Gy.</dc:creator>
 <dc:creator>Malasits, G.</dc:creator>
 <dc:creator>Ormos, P.</dc:creator>
 <dc:creator>Prunk-&#xc9;ger, E.</dc:creator>
 <dc:creator>Rig&#xf3;, J.</dc:creator>
 <dc:creator>Tenczer, Sz.</dc:creator>
 <dc:creator>Rig&#xf3;, E.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this article, we provide a cloud-security checklist for IaaS cloud
deployments. The elements of the checklist are established by surveying the
related literature on cloud-threat models and various security recommendations.
We define the elements of the list on a level of abstraction that helps keep
the size of the list manageable while preserving the list's practical
applicability.
</dc:description>
 <dc:description>Comment: 8 pages, 8 tables</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08791</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monotone Simultaneous Embeddings of Paths in R^d</dc:title>
 <dc:creator>Bremner, David</dc:creator>
 <dc:creator>Devillers, Olivier</dc:creator>
 <dc:creator>Glisse, Marc</dc:creator>
 <dc:creator>Lazard, Sylvain</dc:creator>
 <dc:creator>Liotta, Giuseppe</dc:creator>
 <dc:creator>Mchedlidze, Tamara</dc:creator>
 <dc:creator>Whitesides, Sue</dc:creator>
 <dc:creator>Wismath, Stephen</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the following problem: Given $k$ paths that share the same vertex
set, is there a simultaneous geometric embedding of these paths such that each
individual drawing is monotone in some direction? We prove that for any
dimension $d \geq 2$, there is a set of $d+1$ paths that does not admit a
monotone simultaneous geometric embedding.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08791</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08792</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CliqueCNN: Deep Unsupervised Exemplar Learning</dc:title>
 <dc:creator>Bautista, Miguel A.</dc:creator>
 <dc:creator>Sanakoyeu, Artsiom</dc:creator>
 <dc:creator>Sutter, Ekaterina</dc:creator>
 <dc:creator>Ommer, Bj&#xf6;rn</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Exemplar learning is a powerful paradigm for discovering visual similarities
in an unsupervised manner. In this context, however, the recent breakthrough in
deep learning could not yet unfold its full potential. With only a single
positive sample, a great imbalance between one positive and many negatives, and
unreliable relationships between most samples, training of Convolutional Neural
networks is impaired. Given weak estimates of local distance we propose a
single optimization problem to extract batches of samples with mutually
consistent relations. Conflicting relations are distributed over different
batches and similar samples are grouped into compact cliques. Learning exemplar
similarities is framed as a sequence of clique categorization tasks. The CNN
then consolidates transitivity relations within and between cliques and learns
a single representation for all samples without the need for labels. The
proposed unsupervised approach has shown competitive performance on detailed
posture analysis and object classification.
</dc:description>
 <dc:description>Comment: Accepted for publication at NIPS 2016</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08799</identifier>
 <datestamp>2017-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QoS constrained Large Scale Web Service Composition using Abstraction
  Refinement</dc:title>
 <dc:creator>Chattopadhyay, Soumi</dc:creator>
 <dc:creator>Banerjee, Ansuman</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Efficient service composition in real time while providing necessary Quality
of Service (QoS) guarantees has been a challenging research problem with ever
growing complexity. Several heuristic based approaches with diverse proposals
for taming the scale and complexity of web service composition, have been
proposed in literature. In this paper, we present a new approach for efficient
service composition based on abstraction refinement. Instead of considering
individual services during composition, we propose several abstractions to form
service groups and the composition is done on these abstract services.
Abstraction reduces the search space significantly and thereby can be done
reasonably fast. While this can expedite solution construction to a great
extent, this also entails a possibility that it may fail to generate any
solution satisfying the QoS constraints, though the individual services
construct a valid solution. Hence, we propose to refine an abstraction to
generate the composite solution with desired QoS values. A QoS satisfying
solution, if one exists, can be constructed with multiple iterations of
abstraction refinement. While in the worst case, this approach may end up
exploring the complete composition graph constructed on individual services, on
an average, the solution can be achieved on the abstract graph. The abstraction
refinement techniques give a significant speed-up compared to the traditional
composition techniques. Experimental results on real benchmarks show the
efficiency of our proposed mechanism in terms of time and the number of
services considered for composition.
</dc:description>
 <dc:description>Comment: 14 pages, 19 figures</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2017-02-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08807</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A short review and primer on pupillometry in human computer interaction
  applications</dc:title>
 <dc:creator>Barral, Oswald</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The application of psychophysiological signals in human-computer interaction
is a growing field with significant potential for future smart personalised
systems. Working in this emerging field requires comprehension of an array of
physiological signals and analysis techniques.
  Pupillometry has been studied for over a century, but it has just recently
started being used in human-computer interaction setups. Traditionally, pupil
size has been used as an indicator of cognitive workload and mental effort.
However, pupil size has been linked to other cognitive processes as well,
ranging from attention to affective processing. We present a short review on
the application of pupillometry in human-computer interaction.
  This paper aims to serve as a primer for the novice, enabling rapid
familiarisation with the latest core concepts. We put special emphasis on
everyday human-computer interface applications to distinguish from the more
common clinical or sports uses of psychophysiology.
  This paper is an extract from a comprehensive review of the entire field of
ambulatory psychophysiology, including 12 similar chapters, plus application
guidelines and systematic review. Thus any citation should be made using the
following reference: B. Cowley, M. Filetti, K. Lukander, J. Torniainen, A.
Henelius, L. Ahonen, O. Barral, I. Kosunen, T. Valtonen, M. Huotilainen, N.
Ravaja, G. Jacucci. The Psychophysiology Primer: a guide to methods and a broad
review with a focus on human-computer interaction. Foundations and Trends in
Human-Computer Interaction, vol. 9, no. 3-4, pp. 150-307, 2016.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08807</dc:identifier>
 <dc:identifier>Foundations and Trends in Human-Computer Interaction, vol. 9, no.
  3-4, pp. 150-307, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08810</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conformity, anticonformity and polarization of opinions: insights from a
  mathematical model of opinion dynamics</dc:title>
 <dc:creator>Krueger, Tyll</dc:creator>
 <dc:creator>Szwabi&#x144;ski, Janusz</dc:creator>
 <dc:creator>Weron, Tomasz</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Understanding and quantifying polarization in social systems is important
because of many reasons. It could for instance help to avoid segregation and
conflicts in the society or to control polarized debates and predict their
outcomes. In this paper we present a version of the $q$-voter model of opinion
dynamics with two types of response to social influence: conformity (like in
original $q$-voter model) and anticonformity. We put the model on a social
network with the double-clique topology in order to check how the interplay
between those responses impacts the opinion dynamics in a population divided
into two antagonistic segments. The model is analyzed analytically, numerically
and by means of Monte Carlo simulations. Our results show that the systems
undergoes two bifurcations as the number of cross-links between cliques
changes. Below the first critical point consensus in the entire system is
possible. Thus two antagonistic cliques may share the same opinion only if they
are loosely connected. Above that point the system ends up in a polarized
state.
</dc:description>
 <dc:description>Comment: 20 pages, 11 figures. arXiv admin note: text overlap with
  arXiv:1603.07556</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2017-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08810</dc:identifier>
 <dc:identifier>doi:10.3390/e19070371</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08823</identifier>
 <datestamp>2016-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximation of Continuous-Time Infinite-Horizon Optimal Control
  Problems Arising in Model Predictive Control - Supplementary Notes</dc:title>
 <dc:creator>Muehlebach, Michael</dc:creator>
 <dc:creator>D'Andrea, Raffaello</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  These notes present preliminary results regarding two different
approximations of linear infinite-horizon optimal control problems arising in
model predictive control. Input and state trajectories are parametrized with
basis functions and a finite dimensional representation of the dynamics is
obtained via a Galerkin approach. It is shown that the two approximations
provide lower, respectively upper bounds on the optimal cost of the underlying
infinite dimensional optimal control problem. These bounds get tighter as the
number of basis functions is increased. In addition, conditions guaranteeing
convergence to the cost of the underlying problem are provided.
</dc:description>
 <dc:description>Comment: Supplementary notes, 10 pages</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08823</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08831</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatio-Colour Aspl\&quot;und 's Metric and Logarithmic Image Processing for
  Colour Images (LIPC)</dc:title>
 <dc:creator>Noyel, Guillaume</dc:creator>
 <dc:creator>Jourlin, Michel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Aspl\&quot;und 's metric, which is useful for pattern matching, consists in a
double-sided probing, i.e. the over-graph and the sub-graph of a function are
probed jointly. This paper extends the Aspl\&quot;und 's metric we previously
defined for colour and multivariate images using a marginal approach (i.e.
component by component) to the first spatio-colour Aspl\&quot;und 's metric based on
the vectorial colour LIP model (LIPC). LIPC is a non-linear model with
operations between colour images which are consistent with the human visual
system. The defined colour metric is insensitive to lighting variations and a
variant which is robust to noise is used for colour pattern matching.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08831</dc:identifier>
 <dc:identifier>C\'esar Beltr\'an-Casta\~n\'on, Ingela Nystr\&quot;om, Fazel Famili
  CIARP2016 - XXI IberoAmerican Congress on Pattern Recognition, Nov 2016,
  Lima, Peru. Springer, 10125 2017, pp.36-43, 2016, Progress in Pattern
  Recognition, Image Analysis, Computer Vision, and Applications: 21st
  Iberoamerican Congress, CIARP 2016, Lima, Peru, November 8--11, 2016,
  Proceedings</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-52277-7_5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08843</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The dimension of posets with planar cover graphs excluding two long
  incomparable chains</dc:title>
 <dc:creator>Howard, David M.</dc:creator>
 <dc:creator>Streib, Noah</dc:creator>
 <dc:creator>Trotter, William T.</dc:creator>
 <dc:creator>Walczak, Bartosz</dc:creator>
 <dc:creator>Wang, Ruidong</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>06A07, 05C35</dc:subject>
 <dc:description>  It has been known for more than 40 years that there are posets with planar
cover graphs and arbitrarily large dimension. Recently, Streib and Trotter
proved that such posets must have large height. In fact, all known
constructions of such posets have two large disjoint chains with all points in
one chain incomparable with all points in the other. Gutowski and Krawczyk
conjectured that this feature is necessary. More formally, they conjectured
that for every $k\geq 1$, there is a constant $d$ such that if $P$ is a poset
with planar cover graph and $P$ excludes $\mathbf{k}+\mathbf{k}$, then
$\dim(P)\leq d$. We settle their conjecture in the affirmative. The proof
involves some intermediate results that we believe are of independent interest.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08843</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08844</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Snapping Graph Drawings to the Grid Optimally</dc:title>
 <dc:creator>L&#xf6;ffler, Andre</dc:creator>
 <dc:creator>van Dijk, Thomas C.</dc:creator>
 <dc:creator>Wolff, Alexander</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  In geographic information systems and in the production of digital maps for
small devices with restricted computational resources one often wants to round
coordinates to a rougher grid. This removes unnecessary detail and reduces
space consumption as well as computation time. This process is called snapping
to the grid and has been investigated thoroughly from a computational-geometry
perspective. In this paper we investigate the same problem for given drawings
of planar graphs under the restriction that their combinatorial embedding must
be kept and edges are drawn straight-line. We show that the problem is NP-hard
for several objectives and provide an integer linear programming formulation.
Given a plane graph G and a positive integer w, our ILP can also be used to
draw G straight-line on a grid of width w and minimum height (if possible).
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08844</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08851</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Two-Stream Motion and Appearance 3D CNNs for Video
  Classification</dc:title>
 <dc:creator>Diba, Ali</dc:creator>
 <dc:creator>Pazandeh, Ali Mohammad</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The video and action classification have extremely evolved by deep neural
networks specially with two stream CNN using RGB and optical flow as inputs and
they present outstanding performance in terms of video analysis. One of the
shortcoming of these methods is handling motion information extraction which is
done out side of the CNNs and relatively time consuming also on GPUs. So
proposing end-to-end methods which are exploring to learn motion
representation, like 3D-CNN can achieve faster and accurate performance. We
present some novel deep CNNs using 3D architecture to model actions and motion
representation in an efficient way to be accurate and also as fast as
real-time. Our new networks learn distinctive models to combine deep motion
features into appearance model via learning optical flow features inside the
network.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08851</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08852</identifier>
 <datestamp>2016-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Mathematical Framework for Feature Selection from Real-World Data with
  Non-Linear Observations</dc:title>
 <dc:creator>Genzel, Martin</dc:creator>
 <dc:creator>Kutyniok, Gitta</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  In this paper, we study the challenge of feature selection based on a
relatively small collection of sample pairs $\{(x_i, y_i)\}_{1 \leq i \leq m}$.
The observations $y_i \in \mathbb{R}$ are thereby supposed to follow a noisy
single-index model, depending on a certain set of signal variables. A major
difficulty is that these variables usually cannot be observed directly, but
rather arise as hidden factors in the actual data vectors $x_i \in
\mathbb{R}^d$ (feature variables). We will prove that a successful variable
selection is still possible in this setup, even when the applied estimator does
not have any knowledge of the underlying model parameters and only takes the
'raw' samples $\{(x_i, y_i)\}_{1 \leq i \leq m}$ as input. The model
assumptions of our results will be fairly general, allowing for non-linear
observations, arbitrary convex signal structures as well as strictly convex
loss functions. This is particularly appealing for practical purposes, since in
many applications, already standard methods, e.g., the Lasso or logistic
regression, yield surprisingly good outcomes. Apart from a general discussion
of the practical scope of our theoretical findings, we will also derive a
rigorous guarantee for a specific real-world problem, namely sparse feature
extraction from (proteomics-based) mass spectrometry data.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08852</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08859</identifier>
 <datestamp>2016-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Paradoxical examples of social networks games with product choice</dc:title>
 <dc:creator>Raskin, M.</dc:creator>
 <dc:creator>Nikitenkov, N.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>91A43</dc:subject>
 <dc:description>  Paradox of choice occurs when permitting new strategies to some players
yields lower payoffs for all players in the new equilibrium via a sequence of
individually rational actions. We consider social network games. In these games
the payoff of each player increases when other players choose the same
strategy. The definition of games on social networks was introduced by K. Apt
and S. Simon. In an article written jointly with E. Markakis, they considered
four types of paradox of choice in such games and gave examples of three of
them. The existence of paradoxical networks of the fourth type was proven only
in a weakened form. The existence of so-called vulnerable networks in the
strong sense remained an open question. In the present paper we solve this open
question by introducing a construction, called a cascade, and use it to provide
uniform examples for all four definitions of paradoxical networks.
</dc:description>
 <dc:description>Comment: As submitted to GAMES-2016 conference</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08859</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08868</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Demographic Dialectal Variation in Social Media: A Case Study of
  African-American English</dc:title>
 <dc:creator>Blodgett, Su Lin</dc:creator>
 <dc:creator>Green, Lisa</dc:creator>
 <dc:creator>O'Connor, Brendan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Though dialectal language is increasingly abundant on social media, few
resources exist for developing NLP tools to handle such language. We conduct a
case study of dialectal language in online conversational text by investigating
African-American English (AAE) on Twitter. We propose a distantly supervised
model to identify AAE-like language from demographics associated with
geo-located messages, and we verify that this language follows well-known AAE
linguistic phenomena. In addition, we analyze the quality of existing language
identification and dependency parsing tools on AAE-like text, demonstrating
that they perform poorly on such text compared to text associated with white
speakers. We also provide an ensemble classifier for language identification
which eliminates this disparity and release a new corpus of tweets containing
AAE-like language.
</dc:description>
 <dc:description>Comment: To be published in EMNLP 2016, 15 pages</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08878</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Facial Surface Analysis using Iso-Geodesic Curves in Three Dimensional
  Face Recognition System</dc:title>
 <dc:creator>Ahdid, Rachid</dc:creator>
 <dc:creator>Barrah, El Mahdi</dc:creator>
 <dc:creator>Safi, Said</dc:creator>
 <dc:creator>Manaut, Bouzid</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we present an automatic 3D face recognition system. This
system is based on the representation of human faces surfaces as collections of
Iso-Geodesic Curves (IGC) using 3D Fast Marching algorithm. To compare two
facial surfaces, we compute a geodesic distance between a pair of facial curves
using a Riemannian geometry. In the classifying step, we use: Neural Networks
(NN), K-Nearest Neighbor (KNN) and Support Vector Machines (SVM). To test this
method and evaluate its performance, a simulation series of experiments were
performed on 3D Shape REtrieval Contest 2008 database (SHREC2008).
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08878</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08892</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gabriel Triangulations and Angle-Monotone Graphs: Local Routing and
  Recognition</dc:title>
 <dc:creator>Bonichon, Nicolas</dc:creator>
 <dc:creator>Bose, Prosenjit</dc:creator>
 <dc:creator>Carmi, Paz</dc:creator>
 <dc:creator>Kostitsyna, Irina</dc:creator>
 <dc:creator>Lubiw, Anna</dc:creator>
 <dc:creator>Verdonschot, Sander</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  A geometric graph is angle-monotone if every pair of vertices has a path
between them that---after some rotation---is $x$- and $y$-monotone.
Angle-monotone graphs are $\sqrt 2$-spanners and they are increasing-chord
graphs. Dehkordi, Frati, and Gudmundsson introduced angle-monotone graphs in
2014 and proved that Gabriel triangulations are angle-monotone graphs. We give
a polynomial time algorithm to recognize angle-monotone geometric graphs. We
prove that every point set has a plane geometric graph that is generalized
angle-monotone---specifically, we prove that the half-$\theta_6$-graph is
generalized angle-monotone. We give a local routing algorithm for Gabriel
triangulations that finds a path from any vertex $s$ to any vertex $t$ whose
length is within $1 + \sqrt 2$ times the Euclidean distance from $s$ to $t$.
Finally, we prove some lower bounds and limits on local routing algorithms on
Gabriel triangulations.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08892</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08898</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A High Speed Multi-label Classifier based on Extreme Learning Machines</dc:title>
 <dc:creator>Er, Meng Joo</dc:creator>
 <dc:creator>Venkatesan, Rajasekar</dc:creator>
 <dc:creator>Wang, Ning</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper a high speed neural network classifier based on extreme
learning machines for multi-label classification problem is proposed and
dis-cussed. Multi-label classification is a superset of traditional binary and
multi-class classification problems. The proposed work extends the extreme
learning machine technique to adapt to the multi-label problems. As opposed to
the single-label problem, both the number of labels the sample belongs to, and
each of those target labels are to be identified for multi-label classification
resulting in in-creased complexity. The proposed high speed multi-label
classifier is applied to six benchmark datasets comprising of different
application areas such as multi-media, text and biology. The training time and
testing time of the classifier are compared with those of the state-of-the-arts
methods. Experimental studies show that for all the six datasets, our proposed
technique have faster execution speed and better performance, thereby
outperforming all the existing multi-label clas-sification methods.
</dc:description>
 <dc:description>Comment: 12 pages, 2 figures, 10 tables</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08898</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-28373-9_37</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08899</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visibility Representations of Boxes in 2.5 Dimensions</dc:title>
 <dc:creator>Arleo, Alessio</dc:creator>
 <dc:creator>Binucci, Carla</dc:creator>
 <dc:creator>Di Giacomo, Emilio</dc:creator>
 <dc:creator>Evans, William S.</dc:creator>
 <dc:creator>Grilli, Luca</dc:creator>
 <dc:creator>Liotta, Giuseppe</dc:creator>
 <dc:creator>Meijer, Henk</dc:creator>
 <dc:creator>Montecchiani, Fabrizio</dc:creator>
 <dc:creator>Whitesides, Sue</dc:creator>
 <dc:creator>Wismath, Stephen</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We initiate the study of 2.5D box visibility representations (2.5D-BR) where
vertices are mapped to 3D boxes having the bottom face in the plane $z=0$ and
edges are unobstructed lines of sight parallel to the $x$- or $y$-axis. We
prove that: $(i)$ Every complete bipartite graph admits a 2.5D-BR; $(ii)$ The
complete graph $K_n$ admits a 2.5D-BR if and only if $n \leq 19$; $(iii)$ Every
graph with pathwidth at most $7$ admits a 2.5D-BR, which can be computed in
linear time. We then turn our attention to 2.5D grid box representations
(2.5D-GBR) which are 2.5D-BRs such that the bottom face of every box is a unit
square at integer coordinates. We show that an $n$-vertex graph that admits a
2.5D-GBR has at most $4n - 6 \sqrt{n}$ edges and this bound is tight. Finally,
we prove that deciding whether a given graph $G$ admits a 2.5D-GBR with a given
footprint is NP-complete. The footprint of a 2.5D-BR $\Gamma$ is the set of
bottom faces of the boxes in $\Gamma$.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08899</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08905</identifier>
 <datestamp>2016-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Online Real-time Classifier for Multi-label Data Streams</dc:title>
 <dc:creator>Venkatesan, Rajasekar</dc:creator>
 <dc:creator>Er, Meng Joo</dc:creator>
 <dc:creator>Wu, Shiqian</dc:creator>
 <dc:creator>Pratama, Mahardhika</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper, a novel extreme learning machine based online multi-label
classifier for real-time data streams is proposed. Multi-label classification
is one of the actively researched machine learning paradigm that has gained
much attention in the recent years due to its rapidly increasing real world
applications. In contrast to traditional binary and multi-class classification,
multi-label classification involves association of each of the input samples
with a set of target labels simultaneously. There are no real-time online
neural network based multi-label classifier available in the literature. In
this paper, we exploit the inherent nature of high speed exhibited by the
extreme learning machines to develop a novel online real-time classifier for
multi-label data streams. The developed classifier is experimented with
datasets from different application domains for consistency, performance and
speed. The experimental studies show that the proposed method outperforms the
existing state-of-the-art techniques in terms of speed and accuracy and can
classify multi-label data streams in real-time.
</dc:description>
 <dc:description>Comment: 8 pages, 7 tables, 3 figures. arXiv admin note: text overlap with
  arXiv:1609.00086</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08907</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Capacity of the Two-User Gaussian Interference Channel with
  Noisy Channel-Output Feedback</dc:title>
 <dc:creator>Quintero, Victor</dc:creator>
 <dc:creator>Perlaza, Samir M.</dc:creator>
 <dc:creator>Esnaola, I&#xf1;aki</dc:creator>
 <dc:creator>Gorce, Jean-Marie</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this research report, an achievability region and a converse region for
the two-user Gaussian interference channel with noisy channel-output feedback
(G-IC-NOF) are presented. The achievability region is obtained using a random
coding argument and three well-known techniques: rate splitting, superposition
coding and backward decoding. The converse region is obtained using some of the
existing perfect-output feedback outer-bounds as well as a set of new
outer-bounds that are obtained by using genie-aided models of the original
G-IC-NOF. Finally, it is shown that the achievability region and the converse
region approximate the capacity region of the G-IC-NOF to within a constant gap
in bits per channel use.
</dc:description>
 <dc:description>Comment: INRIA Research report 8861. 38 pages. 5 figures. arXiv admin note:
  text overlap with arXiv:1608.08920</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08907</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08908</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detectability thresholds of general modular graphs</dc:title>
 <dc:creator>Kawamoto, Tatsuro</dc:creator>
 <dc:creator>Kabashima, Yoshiyuki</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We investigate the detectability thresholds of various modular structures in
the stochastic block model. Our analysis reveals how the detectability
threshold is related to the details of the modular pattern, including the
hierarchy of the clusters. We show that certain planted structures are
impossible to infer regardless of their fuzziness.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2017-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08908</dc:identifier>
 <dc:identifier>Phys. Rev. E 95, 012304 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.95.012304</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08909</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Sparse Stress Model</dc:title>
 <dc:creator>Ortmann, Mark</dc:creator>
 <dc:creator>Klimenta, Mirza</dc:creator>
 <dc:creator>Brandes, Ulrik</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Force-directed layout methods constitute the most common approach to draw
general graphs. Among them, stress minimization produces layouts of
comparatively high quality but also imposes comparatively high computational
demands. We propose a speed-up method based on the aggregation of terms in the
objective function. It is akin to aggregate repulsion from far-away nodes
during spring embedding but transfers the idea from the layout space into a
preprocessing phase. An initial experimental study informs a method to select
representatives, and subsequent more extensive experiments indicate that our
method yields better approximations of minimum-stress layouts in less time than
related methods.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08909</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08918</identifier>
 <datestamp>2017-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Subcomputable Schnorr Randomness</dc:title>
 <dc:creator>Sureson, Claude</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03D25, 68Q15</dc:subject>
 <dc:description>  The notion of Schnorr randomness refers to computable reals or computable
functions. We propose a version of Schnorr randomness for subcomputable classes
and characterize it in different ways: by Martin L\&quot;of tests, martingales or
measure computable machines.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2017-04-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08918</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 2 (April 28,
  2017) lmcs:3290</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08920</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Noisy Channel-Output Feedback Capacity of the Linear Deterministic
  Interference Channel</dc:title>
 <dc:creator>Quintero, Victor</dc:creator>
 <dc:creator>Perlaza, Samir M.</dc:creator>
 <dc:creator>Gorce, Jean-Marie</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this technical report, the capacity region of the two-user linear
deterministic (LD) interference channel with noisy output feedback (IC-NOF) is
fully characterized. This result allows the identification of several
asymmetric scenarios in which implementing channel-output feedback in only one
of the transmitter-receiver pairs is as beneficial as implementing it in both
links, in terms of achievable individual rate and sum-rate improvements w.r.t.
the case without feedback. In other scenarios, the use of channel-output
feedback in any of the transmitter-receiver pairs benefits only one of the two
pairs in terms of achievable individual rate improvements or simply, it turns
out to be useless, i.e., the capacity regions with and without feedback turn
out to be identical even in the full absence of noise in the feedback links.
</dc:description>
 <dc:description>Comment: INRIA Technical Report 456, 34 pages, 18 figures. arXiv admin note:
  text overlap with arXiv:1608.08907</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08925</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recursive Partitioning for Personalization using Observational Data</dc:title>
 <dc:creator>Kallus, Nathan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the problem of learning to choose from m discrete treatment options
(e.g., news item or medical drug) the one with best causal effect for a
particular instance (e.g., user or patient) where the training data consists of
passive observations of covariates, treatment, and the outcome of the
treatment. The standard approach to this problem is regress and compare: split
the training data by treatment, fit a regression model in each split, and, for
a new instance, predict all m outcomes and pick the best. By reformulating the
problem as a single learning task rather than m separate ones, we propose a new
approach based on recursively partitioning the data into regimes where
different treatments are optimal. We extend this approach to an optimal
partitioning approach that finds a globally optimal partition, achieving a
compact, interpretable, and impactful personalization model. We develop new
tools for validating and evaluating personalization models on observational
data and use these to demonstrate the power of our novel approaches in a
personalized medicine and a job training application.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08925</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08927</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Generalized Smallest Grammar Problem</dc:title>
 <dc:creator>Siyari, Payam</dc:creator>
 <dc:creator>Gall&#xe9;, Matthias</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The Smallest Grammar Problem -- the problem of finding the smallest
context-free grammar that generates exactly one given sequence -- has never
been successfully applied to grammatical inference. We investigate the reasons
and propose an extended formulation that seeks to minimize non-recursive
grammars, instead of straight-line programs. In addition, we provide very
efficient algorithms that approximate the minimization problem of this class of
grammars. Our empirical evaluation shows that we are able to find smaller
models than the current best approximations to the Smallest Grammar Problem on
standard benchmarks, and that the inferred rules capture much better the
syntactic structure of natural language.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08927</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08933</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FEMOSAA: Feature Guided and Knee Driven Multi-Objective Optimization for
  Self-Adaptive Software at Runtime</dc:title>
 <dc:creator>Chen, Tao</dc:creator>
 <dc:creator>Li, Ke</dc:creator>
 <dc:creator>Bahsoon, Rami</dc:creator>
 <dc:creator>Yao, Xin</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Self-adaptive software (SAS) can reconfigure itself to adapt to the changing
environment at runtime. Such a behavior permits continual optimization on
various conflicting non- functional objectives, e.g., response time and energy
consumption. In this paper, we present FEMOSAA, a novel framework that
automatically synergizes the feature model and Multi-Objective Evolutionary
Algorithm (MOEA), to optimize SAS at runtime. At design time, FEMOSAA
automatically transposes the design of SAS, which is expressed as a feature
model, to the chromosome representation and the reproduction operators
(mutation and crossover) in MOEA. At runtime, the feature model serves as the
domain knowledge to guide the search, providing more chances to find better
solutions. In addition, we have designed a new method to search for the knee
solutions, which can achieve balanced trade-off. We experimentally compare
FEMOSAA with different variants and state-of-the-art approaches on a real world
SAS. The results reveal its effectiveness and superiority over the others.
</dc:description>
 <dc:description>Comment: submitted for publication, 11 pages, 7 figures, 3 tables</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08933</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08936</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of two interaction techniques for visualization of dynamic
  graphs</dc:title>
 <dc:creator>Federico, Paolo</dc:creator>
 <dc:creator>Miksch, Silvia</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:description>  Several techniques for visualization of dynamic graphs are based on different
spatial arrangements of a temporal sequence of node-link diagrams. Many studies
in the literature have investigated the importance of maintaining the user's
mental map across this temporal sequence, but usually each layout is considered
as a static graph drawing and the effect of user interaction is disregarded. We
conducted a task-based controlled experiment to assess the effectiveness of two
basic interaction techniques: the adjustment of the layout stability and the
highlighting of adjacent nodes and edges. We found that generally both
interaction techniques increase accuracy, sometimes at the cost of longer
completion times, and that the highlighting outclasses the stability adjustment
for many tasks except the most complex ones.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08936</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08940</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hash2Vec, Feature Hashing for Word Embeddings</dc:title>
 <dc:creator>Argerich, Luis</dc:creator>
 <dc:creator>Zaffaroni, Joaqu&#xed;n Torr&#xe9;</dc:creator>
 <dc:creator>Cano, Mat&#xed;as J</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper we propose the application of feature hashing to create word
embeddings for natural language processing. Feature hashing has been used
successfully to create document vectors in related tasks like document
classification. In this work we show that feature hashing can be applied to
obtain word embeddings in linear time with the size of the data. The results
show that this algorithm, that does not need training, is able to capture the
semantic meaning of words. We compare the results against GloVe showing that
they are similar. As far as we know this is the first application of feature
hashing to the word embeddings problem and the results indicate this is a
scalable technique with practical results for NLP applications.
</dc:description>
 <dc:description>Comment: ASAI 2016, 45JAIIO</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08940</dc:identifier>
 <dc:identifier>45 JAIIO - ASAI 2016 - ISSN: 2451-7585 - Pages 33-40</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08952</identifier>
 <datestamp>2016-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing NodeTrix Representations of Clustered Graphs</dc:title>
 <dc:creator>Da Lozzo, Giordano</dc:creator>
 <dc:creator>Di Battista, Giuseppe</dc:creator>
 <dc:creator>Frati, Fabrizio</dc:creator>
 <dc:creator>Patrignani, Maurizio</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  NodeTrix representations are a popular way to visualize clustered graphs;
they represent clusters as adjacency matrices and inter-cluster edges as curves
connecting the matrix boundaries. We study the complexity of constructing
NodeTrix representations focusing on planarity testing problems, and we show
several NP-completeness results and some polynomial-time algorithms. Building
on such algorithms we develop a JavaScript library for NodeTrix representations
aimed at reducing the crossings between edges incident to the same matrix.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2016-09-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08952</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08953</identifier>
 <datestamp>2017-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Allocation of Crowd Contributions for Sentiment Analysis during
  the 2016 U.S. Presidential Election</dc:title>
 <dc:creator>Sameki, Mehrnoosh</dc:creator>
 <dc:creator>Gentil, Mattia</dc:creator>
 <dc:creator>Mays, Kate K.</dc:creator>
 <dc:creator>Guo, Lei</dc:creator>
 <dc:creator>Betke, Margrit</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Opinions about the 2016 U.S. Presidential Candidates have been expressed in
millions of tweets that are challenging to analyze automatically. Crowdsourcing
the analysis of political tweets effectively is also difficult, due to large
inter-rater disagreements when sarcasm is involved. Each tweet is typically
analyzed by a fixed number of workers and majority voting. We here propose a
crowdsourcing framework that instead uses a dynamic allocation of the number of
workers. We explore two dynamic-allocation methods: (1) The number of workers
queried to label a tweet is computed offline based on the predicted difficulty
of discerning the sentiment of a particular tweet. (2) The number of crowd
workers is determined online, during an iterative crowd sourcing process, based
on inter-rater agreements between labels.We applied our approach to 1,000
twitter messages about the four U.S. presidential candidates Clinton, Cruz,
Sanders, and Trump, collected during February 2016. We implemented the two
proposed methods using decision trees that allocate more crowd efforts to
tweets predicted to be sarcastic. We show that our framework outperforms the
traditional static allocation scheme. It collects opinion labels from the crowd
at a much lower cost while maintaining labeling accuracy.
</dc:description>
 <dc:description>Comment: 10 pages, 3 figures</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2017-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08953</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08956</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Representation Analysis of Graph Mining</dc:title>
 <dc:creator>van der Hallen, Matthias</dc:creator>
 <dc:creator>Paramonov, Sergey</dc:creator>
 <dc:creator>Leuschel, Michael</dc:creator>
 <dc:creator>Janssens, Gerda</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Many problems, especially those with a composite structure, can naturally be
expressed in higher order logic. From a KR perspective modeling these problems
in an intuitive way is a challenging task. In this paper we study the graph
mining problem as an example of a higher order problem. In short, this problem
asks us to find a graph that frequently occurs as a subgraph among a set of
example graphs. We start from the problem's mathematical definition to solve it
in three state-of-the-art specification systems. For IDP and ASP, which have no
native support for higher order logic, we propose the use of encoding
techniques such as the disjoint union technique and the saturation technique.
ProB benefits from the higher order support for sets. We compare the
performance of the three approaches to get an idea of the overhead of the
higher order support.
  We propose higher-order language extensions for IDP-like specification
languages and discuss what kind of solver support is needed. Native higher
order shifts the burden of rewriting specifications using encoding techniques
from the user to the solver itself.
</dc:description>
 <dc:description>Comment: Paper presented at the 9th Workshop on Answer Set Programming and
  Other Computing Paradigms (ASPOCP 2016), New York City, USA, 16 October 2016</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08956</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08967</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robustness of classifiers: from adversarial to random noise</dc:title>
 <dc:creator>Fawzi, Alhussein</dc:creator>
 <dc:creator>Moosavi-Dezfooli, Seyed-Mohsen</dc:creator>
 <dc:creator>Frossard, Pascal</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Several recent works have shown that state-of-the-art classifiers are
vulnerable to worst-case (i.e., adversarial) perturbations of the datapoints.
On the other hand, it has been empirically observed that these same classifiers
are relatively robust to random noise. In this paper, we propose to study a
\textit{semi-random} noise regime that generalizes both the random and
worst-case noise regimes. We propose the first quantitative analysis of the
robustness of nonlinear classifiers in this general noise regime. We establish
precise theoretical bounds on the robustness of classifiers in this general
regime, which depend on the curvature of the classifier's decision boundary.
Our bounds confirm and quantify the empirical observations that classifiers
satisfying curvature constraints are robust to random noise. Moreover, we
quantify the robustness of classifiers in terms of the subspace dimension in
the semi-random noise regime, and show that our bounds remarkably interpolate
between the worst-case and random noise regimes. We perform experiments and
show that the derived bounds provide very accurate estimates when applied to
various state-of-the-art deep neural networks and datasets. This result
suggests bounds on the curvature of the classifiers' decision boundaries that
we support experimentally, and more generally offers important insights onto
the geometry of high dimensional classification problems.
</dc:description>
 <dc:description>Comment: Accepted to NIPS 2016</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08967</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08970</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>J-Viz: Sibling-First Recursive Graph Drawing for Visualizing Java
  Bytecode</dc:title>
 <dc:creator>Alam, Md. Jawaherul</dc:creator>
 <dc:creator>Goodrich, Michael T.</dc:creator>
 <dc:creator>Johnson, Timothy</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We describe a graph visualization tool for visualizing Java bytecode. Our
tool, which we call J-Viz, visualizes connected directed graphs according to a
canonical node ordering, which we call the sibling-first recursive (SFR)
numbering. The particular graphs we consider are derived from applying Shiver's
k-CFA framework to Java bytecode, and our visualizer includes helpful links
between the nodes of an input graph and the Java bytecode that produced it, as
well as a decompiled version of that Java bytecode. We show through several
case studies that the canonical drawing paradigm used in J-Viz is effective for
identifying potential security vulnerabilities and repeated use of the same
code in Java applications.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08974</identifier>
 <datestamp>2016-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Transparent AI Systems: Interpreting Visual Question Answering
  Models</dc:title>
 <dc:creator>Goyal, Yash</dc:creator>
 <dc:creator>Mohapatra, Akrit</dc:creator>
 <dc:creator>Parikh, Devi</dc:creator>
 <dc:creator>Batra, Dhruv</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep neural networks have shown striking progress and obtained
state-of-the-art results in many AI research fields in the recent years.
However, it is often unsatisfying to not know why they predict what they do. In
this paper, we address the problem of interpreting Visual Question Answering
(VQA) models. Specifically, we are interested in finding what part of the input
(pixels in images or words in questions) the VQA model focuses on while
answering the question. To tackle this problem, we use two visualization
techniques -- guided backpropagation and occlusion -- to find important words
in the question and important regions in the image. We then present qualitative
and quantitative analyses of these importance maps. We found that even without
explicit attention mechanisms, VQA models may sometimes be implicitly attending
to relevant regions in the image, and often to appropriate words in the
question.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2016-09-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08974</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.08984</identifier>
 <datestamp>2016-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Competitive Classifiers for Unbalanced Classification Problems:
  A Study on the Performance Scores</dc:title>
 <dc:creator>Ortigosa-Hern&#xe1;ndez, Jonathan</dc:creator>
 <dc:creator>Inza, I&#xf1;aki</dc:creator>
 <dc:creator>Lozano, Jose A.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Although a great methodological effort has been invested in proposing
competitive solutions to the class-imbalance problem, little effort has been
made in pursuing a theoretical understanding of this matter.
  In order to shed some light on this topic, we perform, through a novel
framework, an exhaustive analysis of the adequateness of the most commonly used
performance scores to assess this complex scenario. We conclude that using
unweighted H\&quot;older means with exponent $p \leq 1$ to average the recalls of
all the classes produces adequate scores which are capable of determining
whether a classifier is competitive.
  Then, we review the major solutions presented in the class-imbalance
literature. Since any learning task can be defined as an optimisation problem
where a loss function, usually connected to a particular score, is minimised,
our goal, here, is to find whether the learning tasks found in the literature
are also oriented to maximise the previously detected adequate scores. We
conclude that they usually maximise the unweighted H\&quot;older mean with $p = 1$
(a-mean).
  Finally, we provide bounds on the values of the studied performance scores
which guarantee a classifier with a higher recall than the random classifier in
each and every class.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.08984</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.09000</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Syntactic Program Transformations from Examples</dc:title>
 <dc:creator>Rolim, Reudismam</dc:creator>
 <dc:creator>Soares, Gustavo</dc:creator>
 <dc:creator>D'Antoni, Loris</dc:creator>
 <dc:creator>Polozov, Oleksandr</dc:creator>
 <dc:creator>Gulwani, Sumit</dc:creator>
 <dc:creator>Gheyi, Rohit</dc:creator>
 <dc:creator>Suzuki, Ryo</dc:creator>
 <dc:creator>Hartmann, Bjoern</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  IDEs, such as Visual Studio, automate common transformations, such as Rename
and Extract Method refactorings. However, extending these catalogs of
transformations is complex and time-consuming. A similar phenomenon appears in
intelligent tutoring systems where instructors have to write cumbersome code
transformations that describe &quot;common faults&quot; to fix similar student
submissions to programming assignments. We present REFAZER, a technique for
automatically generating program transformations. REFAZER builds on the
observation that code edits performed by developers can be used as examples for
learning transformations. Example edits may share the same structure but
involve different variables and subexpressions, which must be generalized in a
transformation at the right level of abstraction. To learn transformations,
REFAZER leverages state-of-the-art programming-by-example methodology using the
following key components: (a) a novel domain-specific language (DSL) for
describing program transformations, (b) domain-specific deductive algorithms
for synthesizing transformations in the DSL, and (c) functions for ranking the
synthesized transformations. We instantiate and evaluate REFAZER in two
domains. First, given examples of edits used by students to fix incorrect
programming assignment submissions, we learn transformations that can fix other
students' submissions with similar faults. In our evaluation conducted on 4
programming tasks performed by 720 students, our technique helped to fix
incorrect submissions for 87% of the students. In the second domain, we use
repetitive edits applied by developers to the same project to synthesize a
program transformation that applies these edits to other locations in the code.
In our evaluation conducted on 59 scenarios of repetitive edits taken from 3 C#
open-source projects, REFAZER learns the intended program transformation in 83%
of the cases.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.09000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.09002</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mining Half a Billion Topical Experts Across Multiple Social Networks</dc:title>
 <dc:creator>Spasojevic, Nemanja</dc:creator>
 <dc:creator>Bhattacharyya, Prantik</dc:creator>
 <dc:creator>Rao, Adithya</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Mining topical experts on social media is a problem that has gained
significant attention due to its wide-ranging applications. Here we present the
first study that combines data from four major social networks -- Twitter,
Facebook, Google+ and LinkedIn, along with the Wikipedia graph and internet
webpage text and metadata, to rank topical experts across the global population
of users. We perform an in-depth analysis of 37 features derived from various
data sources such as message text, user lists, webpages, social graphs and
wikipedia. This large-scale study includes more than 12 billion messages over a
90-day sliding window and 58 billion social graph edges. Comparison reveals
that features derived from Twitter Lists, Wikipedia, internet webpages and
Twitter Followers are especially good indicators of expertise. We train an
expertise ranking model using these features on a large ground truth dataset
containing almost 90,000 labels. This model is applied within a production
system that ranks over 650 million experts in more than 9,000 topical domains
on a daily basis. We provide results and examples on the effectiveness of our
expert ranking system, along with empirical validation. Finally, we make the
topical expertise data available through open REST APIs for wider use.
</dc:description>
 <dc:description>Comment: 20 pages, 9 figures, 6 tables</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.09002</dc:identifier>
 <dc:identifier>doi:10.1007/s13278-016-0356-7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.09005</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring the Quality of Exercises</dc:title>
 <dc:creator>Parmar, Paritosh</dc:creator>
 <dc:creator>Morris, Brendan Tran</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This work explores the problem of exercise quality measurement since it is
essential for effective management of diseases like cerebral palsy (CP). This
work examines the assessment of quality of large amplitude movement (LAM)
exercises designed to treat CP in an automated fashion. Exercise data was
collected by trained participants to generate ideal examples to use as a
positive samples for machine learning. Following that, subjects were asked to
deliberately make subtle errors during the exercise, such as restricting
movements, as is commonly seen in cases of patients suffering from CP. The
quality measurement problem was then posed as a classification to determine
whether an example exercise was either &quot;good&quot; or &quot;bad&quot;. Popular machine
learning techniques for classification, including support vector machines
(SVM), single and doublelayered neural networks (NN), boosted decision trees,
and dynamic time warping (DTW), were compared. The AdaBoosted tree performed
best with an accuracy of 94.68% demonstrating the feasibility of assessing
exercise quality.
</dc:description>
 <dc:description>Comment: EMBC'16 (The 38th Annual International Conference of the IEEE
  Engineering in Medicine and Biology Society)</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.09005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.09010</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical physics of vaccination</dc:title>
 <dc:creator>Wang, Zhen</dc:creator>
 <dc:creator>Bauch, Chris T.</dc:creator>
 <dc:creator>Bhattacharyya, Samit</dc:creator>
 <dc:creator>d'Onofrio, Alberto</dc:creator>
 <dc:creator>Manfredi, Piero</dc:creator>
 <dc:creator>Perc, Matjaz</dc:creator>
 <dc:creator>Perra, Nicola</dc:creator>
 <dc:creator>Salath&#xe9;, Marcel</dc:creator>
 <dc:creator>Zhao, Dawei</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Historically, infectious diseases caused considerable damage to human
societies, and they continue to do so today. To help reduce their impact,
mathematical models of disease transmission have been studied to help
understand disease dynamics and inform prevention strategies. Vaccination - one
of the most important preventive measures of modern times - is of great
interest both theoretically and empirically. And in contrast to traditional
approaches, recent research increasingly explores the pivotal implications of
individual behavior and heterogeneous contact patterns in populations. Our
report reviews the developmental arc of theoretical epidemiology with emphasis
on vaccination, as it led from classical models assuming homogeneously mixing
(mean-field) populations and ignoring human behavior, to recent models that
account for behavioral feedback and/or population spatial/social structure.
Many of the methods used originated in statistical physics, such as lattice and
network models, and their associated analytical frameworks. Similarly, the
feedback loop between vaccinating behavior and disease propagation forms a
coupled nonlinear system with analogs in physics. We also review the new
paradigm of digital epidemiology, wherein sources of digital data such as
online social media are mined for high-resolution information on
epidemiologically relevant individual behavior. Armed with the tools and
concepts of statistical physics, and further assisted by new sources of digital
data, models that capture nonlinear interactions between behavior and disease
dynamics offer a novel way of modeling real-world phenomena, and can help
improve health outcomes. We conclude the review by discussing open problems in
the field and promising directions for future research.
</dc:description>
 <dc:description>Comment: 150 pages, 42 figures; published in Physics Reports</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.09010</dc:identifier>
 <dc:identifier>Phys. Rep. 664 (2016) 1-113</dc:identifier>
 <dc:identifier>doi:10.1016/j.physrep.2016.10.006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1608.09014</identifier>
 <datestamp>2016-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tutorial on Online Supervised Learning with Applications to Node
  Classification in Social Networks</dc:title>
 <dc:creator>Rakhlin, Alexander</dc:creator>
 <dc:creator>Sridharan, Karthik</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We revisit the elegant observation of T. Cover '65 which, perhaps, is not as
well-known to the broader community as it should be. The first goal of the
tutorial is to explain---through the prism of this elementary result---how to
solve certain sequence prediction problems by modeling sets of solutions rather
than the unknown data-generating mechanism. We extend Cover's observation in
several directions and focus on computational aspects of the proposed
algorithms. The applicability of the methods is illustrated on several
examples, including node classification in a network.
  The second aim of this tutorial is to demonstrate the following phenomenon:
it is possible to predict as well as a combinatorial &quot;benchmark&quot; for which we
have a certain multiplicative approximation algorithm, even if the exact
computation of the benchmark given all the data is NP-hard. The proposed
prediction methods, therefore, circumvent some of the computational
difficulties associated with finding the best model given the data. These
difficulties arise rather quickly when one attempts to develop a probabilistic
model for graph-based or other problems with a combinatorial structure.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1608.09014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00004</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Importance of intrinsic and non-network contribution in PageRank
  centrality and its effect on PageRank localization</dc:title>
 <dc:creator>Deyasi, Krishanu</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  PageRank centrality is used by Google for ranking web-pages to present search
result for a user query. Here, we have shown that PageRank value of a vertex
also depends on its intrinsic, non-network contribution. If the intrinsic,
non-network contributions of the vertices are proportional to their degrees or
zeros, then their PageRank centralities become proportion to their degrees.
Some simulations and empirical data are used to support our study. In addition,
we have shown that localization of PageRank centrality depends upon the same
intrinsic, non-network contribution.
</dc:description>
 <dc:description>Comment: 10 pages, 9 figures</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00017</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Radiation Search Operations using Scene Understanding with Autonomous
  UAV and UGV</dc:title>
 <dc:creator>Christie, Gordon</dc:creator>
 <dc:creator>Shoemaker, Adam</dc:creator>
 <dc:creator>Kochersberger, Kevin</dc:creator>
 <dc:creator>Tokekar, Pratap</dc:creator>
 <dc:creator>McLean, Lance</dc:creator>
 <dc:creator>Leonessa, Alexander</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Autonomously searching for hazardous radiation sources requires the ability
of the aerial and ground systems to understand the scene they are scouting. In
this paper, we present systems, algorithms, and experiments to perform
radiation search using unmanned aerial vehicles (UAV) and unmanned ground
vehicles (UGV) by employing semantic scene segmentation. The aerial data is
used to identify radiological points of interest, generate an orthophoto along
with a digital elevation model (DEM) of the scene, and perform semantic
segmentation to assign a category (e.g. road, grass) to each pixel in the
orthophoto. We perform semantic segmentation by training a model on a dataset
of images we collected and annotated, using the model to perform inference on
images of the test area unseen to the model, and then refining the results with
the DEM to better reason about category predictions at each pixel. We then use
all of these outputs to plan a path for a UGV carrying a LiDAR to map the
environment and avoid obstacles not present during the flight, and a radiation
detector to collect more precise radiation measurements from the ground.
Results of the analysis for each scenario tested favorably. We also note that
our approach is general and has the potential to work for a variety of
different sensing tasks.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00030</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PDDL+ Planning via Constraint Answer Set Programming</dc:title>
 <dc:creator>Balduccini, Marcello</dc:creator>
 <dc:creator>Magazzeni, Daniele</dc:creator>
 <dc:creator>Maratea, Marco</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  PDDL+ is an extension of PDDL that enables modelling planning domains with
mixed discrete-continuous dynamics. In this paper we present a new approach to
PDDL+ planning based on Constraint Answer Set Programming (CASP), i.e. ASP
rules plus numerical constraints. To the best of our knowledge, ours is the
first attempt to link PDDL+ planning and logic programming. We provide an
encoding of PDDL+ models into CASP problems. The encoding can handle non-linear
hybrid domains, and represents a solid basis for applying logic programming to
PDDL+ planning. As a case study, we consider the EZCSP CASP solver and obtain
promising results on a set of PDDL+ benchmark problems.
</dc:description>
 <dc:description>Comment: Paper presented at the 9th Workshop on Answer Set Programming and
  Other Computing Paradigms (ASPOCP 2016), New York City, USA, 16 October 2016</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00036</identifier>
 <datestamp>2017-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human Pose Estimation in Space and Time using 3D CNN</dc:title>
 <dc:creator>Grinciunaite, Agne</dc:creator>
 <dc:creator>Gudi, Amogh</dc:creator>
 <dc:creator>Tasli, Emrah</dc:creator>
 <dc:creator>Uyl, Marten den</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper explores the capabilities of convolutional neural networks to deal
with a task that is easily manageable for humans: perceiving 3D pose of a human
body from varying angles. However, in our approach, we are restricted to using
a monocular vision system. For this purpose, we apply a convolutional neural
network approach on RGB videos and extend it to three dimensional convolutions.
This is done via encoding the time dimension in videos as the 3\ts{rd}
dimension in convolutional space, and directly regressing to human body joint
positions in 3D coordinate space. This research shows the ability of such a
network to achieve state-of-the-art performance on the selected Human3.6M
dataset, thus demonstrating the possibility of successfully representing
temporal data with an additional dimension in the convolutional operation.
</dc:description>
 <dc:description>Comment: Accepted at ECCV 2016 Workshop on: Brave new ideas for motion
  representations in videos</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2016-10-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00036</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-49409-8_5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00037</identifier>
 <datestamp>2016-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Good Enough Practices in Scientific Computing</dc:title>
 <dc:creator>Wilson, Greg</dc:creator>
 <dc:creator>Bryan, Jennifer</dc:creator>
 <dc:creator>Cranston, Karen</dc:creator>
 <dc:creator>Kitzes, Justin</dc:creator>
 <dc:creator>Nederbragt, Lex</dc:creator>
 <dc:creator>Teal, Tracy K.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  We present a set of computing tools and techniques that every researcher can
and should adopt. These recommendations synthesize inspiration from our own
work, from the experiences of the thousands of people who have taken part in
Software Carpentry and Data Carpentry workshops over the past six years, and
from a variety of other guides. Unlike some other guides, our recommendations
are aimed specifically at people who are new to research computing.
</dc:description>
 <dc:description>Comment: 19 pages, 1 figure</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2016-10-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00045</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Hybrid Cloud-assisted Crowdsourced Live Streaming: Measurement
  and Analysis</dc:title>
 <dc:creator>Zhang, Cong</dc:creator>
 <dc:creator>Liu, Jiangchuan</dc:creator>
 <dc:creator>Wang, Haiyang</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Crowdsourced Live Streaming (CLS), most notably Twitch.tv, has seen explosive
growth in its popularity in the past few years. In such systems, any user can
lively broadcast video content of interest to others, e.g., from a game player
to many online viewers. To fulfill the demands from both massive and
heterogeneous broadcasters and viewers, expensive server clusters have been
deployed to provide video ingesting and transcoding services. Despite the
existence of highly popular channels, a significant portion of the channels is
indeed unpopular. Yet as our measurement shows, these broadcasters are
consuming considerable system resources; in particular, 25% (resp. 30%) of
bandwidth (resp. computation) resources are used by the broadcasters who do not
have any viewers at all. In this paper, we closely examine the challenge of
handling unpopular live-broadcasting channels in CLS systems and present a
comprehensive solution for service partitioning on hybrid cloud. The
trace-driven evaluation shows that our hybrid cloud-assisted design can smartly
assign ingesting and transcoding tasks to the elastic cloud virtual machines,
providing flexible system deployment cost-effectively.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00045</dc:identifier>
 <dc:identifier>doi:10.1145/2910642.2910644</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00048</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical sketching algorithms for low-rank matrix approximation</dc:title>
 <dc:creator>Tropp, Joel A.</dc:creator>
 <dc:creator>Yurtsever, Alp</dc:creator>
 <dc:creator>Udell, Madeleine</dc:creator>
 <dc:creator>Cevher, Volkan</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Primary 65F30, Secondary 68W20</dc:subject>
 <dc:description>  This paper describes a suite of algorithms for constructing low-rank
approximations of an input matrix from a random linear image of the matrix,
called a sketch. These methods can preserve structural properties of the input
matrix, such as positive-semidefiniteness, and they can produce approximations
with a user-specified rank. The algorithms are simple, accurate, numerically
stable, and provably correct. Moreover, each method is accompanied by an
informative error bound that allows users to select parameters a priori to
achieve a given approximation quality. These claims are supported by numerical
experiments with real and synthetic data.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2018-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00048</dc:identifier>
 <dc:identifier>SIAM J. Matrix Analysis and Applications, Vol. 38, num. 4, pp.
  1454-1485, Dec. 2017</dc:identifier>
 <dc:identifier>doi:10.1137/17M1111590</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00051</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimation and Control of Quality of Service in Demand Dispatch</dc:title>
 <dc:creator>Chen, Yue</dc:creator>
 <dc:creator>Bu&#x161;i&#x107;, Ana</dc:creator>
 <dc:creator>Meyn, Sean</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>60J20, 68M20</dc:subject>
 <dc:description>  It is now well known that flexibility of energy consumption can be harnessed
for the purposes of grid-level ancillary services. In particular, through
distributed control of a collection of loads, a balancing authority regulation
signal can be tracked accurately, while ensuring that the quality of service
(QoS) for each load is acceptable {\it on average}. In this paper it is argued
that a histogram of QoS is approximately Gaussian, and consequently each load
will eventually receive poor service. Statistical techniques are developed to
estimate the mean and variance of QoS as a function of the power spectral
density of the regulation signal. It is also shown that additional local
control can eliminate risk: The histogram of QoS is {\it truncated} through
this local control, so that strict bounds on service quality are guaranteed.
While there is a tradeoff between the grid-level tracking performance (capacity
and accuracy) and the bounds imposed on QoS, it is found that the loss of
capacity is minor in typical cases.
</dc:description>
 <dc:description>Comment: Submitted for publication, August 2016. arXiv admin note: text
  overlap with arXiv:1409.6941</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00053</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of a low memory implementation of the Orthogonal Matching
  Pursuit greedy strategy</dc:title>
 <dc:creator>Rebollo-Neira, Laura</dc:creator>
 <dc:creator>Rozloznik, Miroslav</dc:creator>
 <dc:creator>Sasmal, Pradip</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The convergence and numerical analysis of a low memory implementation of the
Orthogonal Matching Pursuit greedy strategy, which is termed Self Projected
Matching Pursuit, is presented. This approach provides an iterative way of
solving the least squares problem with much less storage requirement than
direct linear algebra techniques. Hence, it is appropriate for solving large
linear systems. Furthermore, the low memory requirement of the method suits it
for massive parallelization, via Graphics Processing Unit, to tackle systems
which can be broken into a large number of subsystems of much smaller
dimension.
</dc:description>
 <dc:description>Comment: The routines for implementing the methods, as well as scripts to
  reproduce the examples in the manuscript, are available on the website:
  http://www.nonlinear-approx.info/examples/node04.html</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00056</identifier>
 <datestamp>2017-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Quadratic Mean Field Teams: Optimal and Approximately Optimal
  Decentralized Solutions</dc:title>
 <dc:creator>Arabneydi, Jalal</dc:creator>
 <dc:creator>Mahajan, Aditya</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider team optimal control of decentralized systems with linear
dynamics, quadratic costs, and arbitrary disturbance that consist of multiple
sub-populations with exchangeable agents (i.e., exchanging two agents within
the same sub-population does not affect the dynamics or the cost). Such a
system is equivalent to one where the dynamics and costs are coupled across
agents through the mean-field (or empirical mean) of the states and actions
(even when the primitive random variables are non-exchangeable). Two
information structures are investigated. In the first, all agents observe their
local state and the mean-field of all sub-populations; in the second, all
agents observe their local state but the mean-field of only a subset of the
sub-populations. Both information structures are non-classical and not
partially nested. Nonetheless, it is shown that linear control strategies are
optimal for the first and approximately optimal for the second; the
approximation error is inversely proportional to the size of the
sub-populations whose mean-fields are not observed. The corresponding gains are
determined by the solution of K+1 decoupled standard Riccati equations, where K
is the number of sub-populations. The dimensions of the Riccati equations do
not depend on the size of the sub-populations; thus the solution complexity is
independent of the number of agents. Generalizations to major-minor agents,
tracking cost, weighted mean-field, and infinite horizon are provided. The
results are illustrated using an example of demand response in smart grids.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Automatic Control, Aug 2016</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2017-09-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00056</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00062</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Full-Duplex Backscatter Interference Networks Based on Time-Hopping
  Spread Spectrum</dc:title>
 <dc:creator>Liu, Wanchun</dc:creator>
 <dc:creator>Huang, Kaibin</dc:creator>
 <dc:creator>Zhou, Xiangyun</dc:creator>
 <dc:creator>Durrani, Salman</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Future Internet-of-Things (IoT) is expected to wirelessly connect billions of
low-complexity devices. For wireless information transfer (WIT) in IoT, high
density of IoT devices and their ad hoc communication result in strong
interference which acts as a bottleneck on WIT. Furthermore, battery
replacement for the massive number of IoT devices is difficult if not
infeasible, making wireless energy transfer (WET) desirable. This motivates:
(i) the design of full-duplex WIT to reduce latency and enable efficient
spectrum utilization, and (ii) the implementation of passive IoT devices using
backscatter antennas that enable WET from one device (reader) to another (tag).
However, the resultant increase in the density of simultaneous links
exacerbates the interference issue. This issue is addressed in this paper by
proposing the design of full-duplex backscatter communication (BackCom)
networks, where a novel multiple-access scheme based on time-hopping
spread-spectrum (TH-SS) is designed to enable both one-way WET and two-way WIT
in coexisting backscatter reader-tag links. Comprehensive performance analysis
of BackCom networks is presented in this paper, including forward/backward
bit-error rates and WET efficiency and outage probabilities, which accounts for
energy harvesting at tags, non-coherent and coherent detection at tags and
readers, respectively, and the effects of asynchronous transmissions.
</dc:description>
 <dc:description>Comment: submitted for possible journal publication</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00062</dc:identifier>
 <dc:identifier>IEEE Transactions on Wireless Communications, vol. 16, no. 7, pp.
  4361-4377, Jul. 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00070</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Much is 131 Million Dollars? Putting Numbers in Perspective with
  Compositional Descriptions</dc:title>
 <dc:creator>Chaganty, Arun Tejasvi</dc:creator>
 <dc:creator>Liang, Percy</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  How much is 131 million US dollars? To help readers put such numbers in
context, we propose a new task of automatically generating short descriptions
known as perspectives, e.g. &quot;$131 million is about the cost to employ everyone
in Texas over a lunch period&quot;. First, we collect a dataset of numeric mentions
in news articles, where each mention is labeled with a set of rated
perspectives. We then propose a system to generate these descriptions
consisting of two steps: formula construction and description generation. In
construction, we compose formulae from numeric facts in a knowledge base and
rank the resulting formulas based on familiarity, numeric proximity and
semantic compatibility. In generation, we convert a formula into natural
language using a sequence-to-sequence recurrent neural network. Our system
obtains a 15.2% F1 improvement over a non-compositional baseline at formula
construction and a 12.5 BLEU point improvement over a baseline description
generation.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00070</dc:identifier>
 <dc:identifier>ACL (2016), 578-587</dc:identifier>
 <dc:identifier>doi:10.18653/v1/P16-1055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00072</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attentional Push: Augmenting Salience with Shared Attention Modeling</dc:title>
 <dc:creator>Gorji, Siavash</dc:creator>
 <dc:creator>Clark, James J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a novel visual attention tracking technique based on Shared
Attention modeling. Our proposed method models the viewer as a participant in
the activity occurring in the scene. We go beyond image salience and instead of
only computing the power of an image region to pull attention to it, we also
consider the strength with which other regions of the image push attention to
the region in question. We use the term Attentional Push to refer to the power
of image regions to direct and manipulate the attention allocation of the
viewer. An attention model is presented that incorporates the Attentional Push
cues with standard image salience-based attention modeling algorithms to
improve the ability to predict where viewers will fixate. Experimental
evaluation validates significant improvements in predicting viewers' fixations
using the proposed methodology in both static and dynamic imagery.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00074</identifier>
 <datestamp>2017-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Network Architecture Optimization through Submodularity and
  Supermodularity</dc:title>
 <dc:creator>Jin, Junqi</dc:creator>
 <dc:creator>Yan, Ziang</dc:creator>
 <dc:creator>Fu, Kun</dc:creator>
 <dc:creator>Jiang, Nan</dc:creator>
 <dc:creator>Zhang, Changshui</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep learning models' architectures, including depth and width, are key
factors influencing models' performance, such as test accuracy and computation
time. This paper solves two problems: given computation time budget, choose an
architecture to maximize accuracy, and given accuracy requirement, choose an
architecture to minimize computation time. We convert this architecture
optimization into a subset selection problem. With accuracy's submodularity and
computation time's supermodularity, we propose efficient greedy optimization
algorithms. The experiments demonstrate our algorithm's ability to find more
accurate models or faster models. By analyzing architecture evolution with
growing time budget, we discuss relationships among accuracy, time and
architecture, and give suggestions on neural network architecture design.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2017-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00076</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BLISlab: A Sandbox for Optimizing GEMM</dc:title>
 <dc:creator>Huang, Jianyu</dc:creator>
 <dc:creator>van de Geijn, Robert A.</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Matrix-matrix multiplication is a fundamental operation of great importance
to scientific computing and, increasingly, machine learning. It is a simple
enough concept to be introduced in a typical high school algebra course yet in
practice important enough that its implementation on computers continues to be
an active research topic. This note describes a set of exercises that use this
operation to illustrate how high performance can be attained on modern CPUs
with hierarchical memories (multiple caches). It does so by building on the
insights that underly the BLAS-like Library Instantiation Software (BLIS)
framework by exposing a simplified &quot;sandbox&quot; that mimics the implementation in
BLIS. As such, it also becomes a vehicle for the &quot;crowd sourcing&quot; of the
optimization of BLIS. We call this set of exercises BLISlab.
</dc:description>
 <dc:description>Comment: FLAME Working Note #80</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00078</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coupled dynamics of node and link states in complex networks: A model
  for language competition</dc:title>
 <dc:creator>Carro, Adri&#xe1;n</dc:creator>
 <dc:creator>Toral, Ra&#xfa;l</dc:creator>
 <dc:creator>Miguel, Maxi San</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  Inspired by language competition processes, we present a model of coupled
evolution of node and link states. In particular, we focus on the interplay
between the use of a language and the preference or attitude of the speakers
towards it, which we model, respectively, as a property of the interactions
between speakers (a link state) and as a property of the speakers themselves (a
node state). Furthermore, we restrict our attention to the case of two socially
equivalent languages and to socially inspired network topologies based on a
mechanism of triadic closure. As opposed to most of the previous literature,
where language extinction is an inevitable outcome of the dynamics, we find a
broad range of possible asymptotic configurations, which we classify as: frozen
extinction states, frozen coexistence states, and dynamically trapped
coexistence states. Moreover, metastable coexistence states with very long
survival times and displaying a non-trivial dynamics are found to be abundant.
Interestingly, a system size scaling analysis shows, on the one hand, that the
probability of language extinction vanishes exponentially for increasing system
sizes and, on the other hand, that the time scale of survival of the
non-trivial dynamical metastable states increases linearly with the size of the
system. Thus, non-trivial dynamical coexistence is the only possible outcome
for large enough systems. Finally, we show how this coexistence is
characterized by one of the languages becoming clearly predominant while the
other one becomes increasingly confined to &quot;ghetto-like&quot; structures: small
groups of bilingual speakers arranged in triangles, with a strong preference
for the minority language, and using it for their intra-group interactions
while they switch to the predominant language for communications with the rest
of the population.
</dc:description>
 <dc:description>Comment: 21 pages, 15 figures</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00078</dc:identifier>
 <dc:identifier>New J. Phys. 18 113056 (2016)</dc:identifier>
 <dc:identifier>doi:10.1088/1367-2630/18/11/113056</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00081</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>All Fingers are not Equal: Intensity of References in Scientific
  Articles</dc:title>
 <dc:creator>Chakraborty, Tanmoy</dc:creator>
 <dc:creator>Narayanam, Ramasuri</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Research accomplishment is usually measured by considering all citations with
equal importance, thus ignoring the wide variety of purposes an article is
being cited for. Here, we posit that measuring the intensity of a reference is
crucial not only to perceive better understanding of research endeavor, but
also to improve the quality of citation-based applications. To this end, we
collect a rich annotated dataset with references labeled by the intensity, and
propose a novel graph-based semi-supervised model, GraLap to label the
intensity of references. Experiments with AAN datasets show a significant
improvement compared to the baselines to achieve the true labels of the
references (46% better correlation). Finally, we provide four applications to
demonstrate how the knowledge of reference intensity leads to design better
real-world applications.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures, 4 tables, Conference on Empirical Methods in
  Natural Language Processing (EMNLP 2016)</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00085</identifier>
 <datestamp>2017-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Progressive Learning Technique for Multi-class Classification</dc:title>
 <dc:creator>Venkatesan, Rajasekar</dc:creator>
 <dc:creator>Er, Meng Joo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper, a progressive learning technique for multi-class
classification is proposed. This newly developed learning technique is
independent of the number of class constraints and it can learn new classes
while still retaining the knowledge of previous classes. Whenever a new class
(non-native to the knowledge learnt thus far) is encountered, the neural
network structure gets remodeled automatically by facilitating new neurons and
interconnections, and the parameters are calculated in such a way that it
retains the knowledge learnt thus far. This technique is suitable for
real-world applications where the number of classes is often unknown and online
learning from real-time data is required. The consistency and the complexity of
the progressive learning technique are analyzed. Several standard datasets are
used to evaluate the performance of the developed technique. A comparative
study shows that the developed technique is superior.
</dc:description>
 <dc:description>Comment: 23 pages, 13 tables, 11 figures</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2017-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00086</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A novel online multi-label classifier for high-speed streaming data
  applications</dc:title>
 <dc:creator>Venkatesan, Rajasekar</dc:creator>
 <dc:creator>Er, Meng Joo</dc:creator>
 <dc:creator>Dave, Mihika</dc:creator>
 <dc:creator>Pratama, Mahardhika</dc:creator>
 <dc:creator>Wu, Shiqian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper, a high-speed online neural network classifier based on extreme
learning machines for multi-label classification is proposed. In multi-label
classification, each of the input data sample belongs to one or more than one
of the target labels. The traditional binary and multi-class classification
where each sample belongs to only one target class forms the subset of
multi-label classification. Multi-label classification problems are far more
complex than binary and multi-class classification problems, as both the number
of target labels and each of the target labels corresponding to each of the
input samples are to be identified. The proposed work exploits the high-speed
nature of the extreme learning machines to achieve real-time multi-label
classification of streaming data. A new threshold-based online sequential
learning algorithm is proposed for high speed and streaming data classification
of multi-label problems. The proposed method is experimented with six different
datasets from different application domains such as multimedia, text, and
biology. The hamming loss, accuracy, training time and testing time of the
proposed technique is compared with nine different state-of-the-art methods.
Experimental studies shows that the proposed technique outperforms the existing
multi-label classifiers in terms of performance and speed.
</dc:description>
 <dc:description>Comment: 18 pages, 7 tables, 3 figures. arXiv admin note: text overlap with
  arXiv:1608.08898</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00086</dc:identifier>
 <dc:identifier>doi:10.1007/s12530-016-9162-8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00090</identifier>
 <datestamp>2017-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attribute Truss Community Search</dc:title>
 <dc:creator>Huang, Xin</dc:creator>
 <dc:creator>Lakshmanan, Laks V. S.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Recently, community search over graphs has attracted significant attention
and many algorithms have been developed for finding dense subgraphs from large
graphs that contain given query nodes. In applications such as analysis of
protein protein interaction (PPI) networks, citation graphs, and collaboration
networks, nodes tend to have attributes. Unfortunately, previously developed
community search algorithms ignore these attributes and result in communities
with poor cohesion w.r.t. their node attributes. In this paper, we study the
problem of attribute-driven community search, that is, given an undirected
graph $G$ where nodes are associated with attributes, and an input query $Q$
consisting of nodes $V_q$ and attributes $W_q$, find the communities containing
$V_q$, in which most community members are densely inter-connected and have
similar attributes.
  We formulate our problem of finding attributed truss communities (ATC), as
finding all connected and close k-truss subgraphs containing $V_q$, that are
locally maximal and have the largest attribute relevance score among such
subgraphs. We design a novel attribute relevance score function and establish
its desirable properties. The problem is shown to be NP-hard. However, we
develop an efficient greedy algorithmic framework, which finds a maximal
$k$-truss containing $V_q$, and then iteratively removes the nodes with the
least popular attributes and shrinks the graph so as to satisfy community
constraints. We also build an elegant index to maintain the known $k$-truss
structure and attribute information, and propose efficient query processing
algorithms. Extensive experiments on large real-world networks with
ground-truth communities shows the efficiency and effectiveness of our proposed
methods.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2017-02-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00090</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00091</identifier>
 <datestamp>2016-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Bisimulation and Discretization of Hybrid CSP</dc:title>
 <dc:creator>Yan, Gaogao</dc:creator>
 <dc:creator>Jiao, Li</dc:creator>
 <dc:creator>Li, Yangjia</dc:creator>
 <dc:creator>Wang, Shuling</dc:creator>
 <dc:creator>Zhan, Naijun</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Hybrid Communicating Sequential Processes (HCSP) is a powerful formal
modeling language for hybrid systems, which is an extension of CSP by
introducing differential equations for modeling continuous evolution and
interrupts for modeling interaction between continuous and discrete dynamics.
In this paper, we investigate the semantic foundation for HCSP from an
operational point of view by proposing notion of approximate bisimulation,
which provides an appropriate criterion to characterize the equivalence between
HCSP processes with continuous and discrete behaviour. We give an algorithm to
determine whether two HCSP processes are approximately bisimilar. In addition,
based on that, we propose an approach on how to discretize HCSP, i.e., given an
HCSP process A, we construct another HCSP process B which does not contain any
continuous dynamics such that A and B are approximately bisimilar with given
precisions. This provides a rigorous way to transform a verified control model
to a correct program model, which fills the gap in the design of embedded
systems.
</dc:description>
 <dc:description>Comment: FM 2016, Proof Appendix, HCSP, approximately bisimilar, hybrid
  systems, discretization</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2016-09-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00096</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image segmentation based on histogram of depth and an application in
  driver distraction detection</dc:title>
 <dc:creator>Dinh, Tran Hiep</dc:creator>
 <dc:creator>Pham, Minh Trien</dc:creator>
 <dc:creator>Phung, Manh Duong</dc:creator>
 <dc:creator>Nguyen, Duc Manh</dc:creator>
 <dc:creator>Hoang, Van Manh</dc:creator>
 <dc:creator>Tran, Quang Vinh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This study proposes an approach to segment human object from a depth image
based on histogram of depth values. The region of interest is first extracted
based on a predefined threshold for histogram regions. A region growing process
is then employed to separate multiple human bodies with the same depth
interval. Our contribution is the identification of an adaptive growth
threshold based on the detected histogram region. To demonstrate the
effectiveness of the proposed method, an application in driver distraction
detection was introduced. After successfully extracting the driver's position
inside the car, we came up with a simple solution to track the driver motion.
With the analysis of the difference between initial and current frame, a change
of cluster position or depth value in the interested region, which cross the
preset threshold, is considered as a distracted activity. The experiment
results demonstrated the success of the algorithm in detecting typical
distracted driving activities such as using phone for calling or texting,
adjusting internal devices and drinking in real time.
</dc:description>
 <dc:description>Comment: 6 pages In 13th International Conference on Control Automation
  Robotics &amp; Vision (ICARCV), 2014</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00096</dc:identifier>
 <dc:identifier>doi:10.1109/ICARCV.2014.7064437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00098</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SpECTRE: A Task-based Discontinuous Galerkin Code for Relativistic
  Astrophysics</dc:title>
 <dc:creator>Kidder, Lawrence E.</dc:creator>
 <dc:creator>Field, Scott E.</dc:creator>
 <dc:creator>Foucart, Francois</dc:creator>
 <dc:creator>Schnetter, Erik</dc:creator>
 <dc:creator>Teukolsky, Saul A.</dc:creator>
 <dc:creator>Bohn, Andy</dc:creator>
 <dc:creator>Deppe, Nils</dc:creator>
 <dc:creator>Diener, Peter</dc:creator>
 <dc:creator>H&#xe9;bert, Fran&#xe7;ois</dc:creator>
 <dc:creator>Lippuner, Jonas</dc:creator>
 <dc:creator>Miller, Jonah</dc:creator>
 <dc:creator>Ott, Christian D.</dc:creator>
 <dc:creator>Scheel, Mark A.</dc:creator>
 <dc:creator>Vincent, Trevor</dc:creator>
 <dc:subject>Astrophysics - High Energy Astrophysical Phenomena</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>General Relativity and Quantum Cosmology</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  We introduce a new relativistic astrophysics code, SpECTRE, that combines a
discontinuous Galerkin method with a task-based parallelism model. SpECTRE's
goal is to achieve more accurate solutions for challenging relativistic
astrophysics problems such as core-collapse supernovae and binary neutron star
mergers. The robustness of the discontinuous Galerkin method allows for the use
of high-resolution shock capturing methods in regions where (relativistic)
shocks are found, while exploiting high-order accuracy in smooth regions. A
task-based parallelism model allows efficient use of the largest supercomputers
for problems with a heterogeneous workload over disparate spatial and temporal
scales. We argue that the locality and algorithmic structure of discontinuous
Galerkin methods will exhibit good scalability within a task-based parallelism
framework. We demonstrate the code on a wide variety of challenging benchmark
problems in (non)-relativistic (magneto)-hydrodynamics. We demonstrate the
code's scalability including its strong scaling on the NCSA Blue Waters
supercomputer up to the machine's full capacity of 22,380 nodes using 671,400
threads.
</dc:description>
 <dc:description>Comment: 41 pages, 13 figures, and 7 tables. Ancillary data contains
  simulation input files</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2017-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00098</dc:identifier>
 <dc:identifier>doi:10.1016/j.jcp.2016.12.059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00099</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Implementation of A Network Security Management System</dc:title>
 <dc:creator>Shan, Zhiyong</dc:creator>
 <dc:creator>Liao, Bin</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In recent years, the emerged network worms and attacks have distributive
characteristic, which can spread globally in a very short time. Security
management crossing network to co-defense network-wide attacks and improve
efficiency of security administration is urgently needed. This paper proposes a
hierarchical distributed network security management system (HD-NSMS), which
can centrally manage security across networks. First describes the system in
macrostructure and microstructure; then discusses three key problems when
building HD-NSMS: device model, alert mechanism and emergency response
mechanism; at last, describes the implementation of HD-NSMS. The paper is
valuable for implementing NSMS in that it derives from a practical network
security management system (NSMS).
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00100</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Suspicious-Taint-Based Access Control for Protecting OS from Network
  Attacks</dc:title>
 <dc:creator>Shan, Zhiyong</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  Today, security threats to operating systems largely come from network.
Traditional discretionary access control mechanism alone can hardly defeat
them. Although traditional mandatory access control models can effectively
protect the security of OS, they have problems of being incompatible with
application software and complex in administration. In this paper, we propose a
new model, Suspicious-Taint-Based Access Control (STBAC) model, for defeating
network attacks while being compatible, simple and maintaining good system
performance. STBAC regards the processes using Non-Trustable-Communications as
the starting points of suspicious taint, traces the activities of the
suspiciously tainted processes by taint rules, and forbids the suspiciously
tainted processes to illegally access vital resources by protection rules. Even
in the cases when some privileged processes are subverted, STBAC can still
protect vital resources from being compromised by the intruder. We implemented
the model in the Linux kernel and evaluated it through experiments. The
evaluation showed that STBAC could protect vital resources effectively without
significant impact on compatibility and performance.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00104</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Likelihood Ratio Detector for Identifying Within-Perimeter Computer
  Network Attacks</dc:title>
 <dc:creator>Grana, Justin</dc:creator>
 <dc:creator>Wolpert, David</dc:creator>
 <dc:creator>Neil, Joshua</dc:creator>
 <dc:creator>Xie, Dongping</dc:creator>
 <dc:creator>Bhattacharya, Tanmoy</dc:creator>
 <dc:creator>Bent, Russel</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The rapid detection of attackers within firewalls of enterprise computer net-
works is of paramount importance. Anomaly detectors address this problem by
quantifying deviations from baseline statistical models of normal network
behav- ior and signaling an intrusion when the observed data deviates
significantly from the baseline model. However, many anomaly detectors do not
take into account plausible attacker behavior. As a result, anomaly detectors
are prone to a large number of false positives due to unusual but benign
activity. This paper first in- troduces a stochastic model of attacker behavior
which is motivated by real world attacker traversal. Then, we develop a
likelihood ratio detector that compares the probability of observed network
behavior under normal conditions against the case when an attacker has possibly
compromised a subset of hosts within the network. Since the likelihood ratio
detector requires integrating over the time each host be- comes compromised, we
illustrate how to use Monte Carlo methods to compute the requisite integral. We
then present Receiver Operating Characteristic (ROC) curves for various network
parameterizations that show for any rate of true posi- tives, the rate of false
positives for the likelihood ratio detector is no higher than that of a simple
anomaly detector and is often lower. We conclude by demon- strating the
superiority of the proposed likelihood ratio detector when the network
topologies and parameterizations are extracted from real-world networks.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00108</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How a user's personality influences content engagement in social media</dc:title>
 <dc:creator>Hodas, Nathan O.</dc:creator>
 <dc:creator>Butner, Ryan</dc:creator>
 <dc:creator>Corley, Court</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Social media presents an opportunity for people to share content that they
find to be significant, funny, or notable. No single piece of content will
appeal to all users, but are there systematic variations between users that can
help us better understand information propagation? We conducted an experiment
exploring social media usage during disaster scenarios, combining
electroencephalogram (EEG), personality surveys, and prompts to share social
media, we show how personality not only drives willingness to engage with
social media but also helps to determine what type of content users find
compelling. As expected, extroverts are more likely to share content. In
contrast, one of our central results is that individuals with depressive
personalities are the most likely cohort to share informative content, like
news or alerts. Because personality and mood will generally be highly
correlated between friends via homophily, our results may be an import factor
in understanding social contagion.
</dc:description>
 <dc:description>Comment: to appear in SocInfo 2016</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00108</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00109</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Complexity of (List) Edge-Coloring Reconfiguration Problem</dc:title>
 <dc:creator>Osawa, Hiroki</dc:creator>
 <dc:creator>Suzuki, Akira</dc:creator>
 <dc:creator>Ito, Takehiro</dc:creator>
 <dc:creator>Zhou, Xiao</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Let $G$ be a graph such that each edge has its list of available colors, and
assume that each list is a subset of the common set consisting of $k$ colors.
Suppose that we are given two list edge-colorings $f_0$ and $f_r$ of $G$, and
asked whether there exists a sequence of list edge-colorings of $G$ between
$f_0$ and $f_r$ such that each list edge-coloring can be obtained from the
previous one by changing a color assignment of exactly one edge. This problem
is known to be PSPACE-complete for every integer $k \ge 6$ and planar graphs of
maximum degree three, but any complexity hardness was unknown for the non-list
variant. In this paper, we first improve the known result by proving that, for
every integer $k \ge 4$, the problem remains PSPACE-complete even if an input
graph is planar, bounded bandwidth, and of maximum degree three. We then give
the first complexity hardness result for the non-list variant: for every
integer $k \ge 5$, we prove that the non-list variant is PSPACE-complete even
if an input graph is planar, of bandwidth linear in $k$, and of maximum degree
$k$.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00110</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Decomposition Method for Global Evaluation of Shannon Entropy and
  Local Estimations of Algorithmic Complexity</dc:title>
 <dc:creator>Zenil, Hector</dc:creator>
 <dc:creator>Hern&#xe1;ndez-Orozco, Santiago</dc:creator>
 <dc:creator>Kiani, Narsis A.</dc:creator>
 <dc:creator>Soler-Toscano, Fernando</dc:creator>
 <dc:creator>Rueda-Toicen, Antonio</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>H.1.1</dc:subject>
 <dc:description>  We investigate the properties of a Block Decomposition Method (BDM), which
extends the power of a Coding Theorem Method (CTM) that approximates local
estimations of algorithmic complexity based upon Solomonoff-Levin's theory of
algorithmic probability providing a closer connection to algorithmic complexity
than previous attempts based on statistical regularities e.g. as spotted by
some popular lossless compression schemes. The strategy behind BDM is to find
small computer programs that produce the components of a larger, decomposed
object. The set of short computer programs can then be artfully arranged in
sequence so as to produce the original object and to estimate an upper bound on
the length of the shortest computer program that produces said original object.
We show that the method provides efficient estimations of algorithmic
complexity but that it performs like Shannon entropy when it loses accuracy. We
estimate errors and study the behaviour of BDM for different boundary
conditions, all of which are compared and assessed in detail. The measure may
be adapted for use with more multi-dimensional objects than strings, objects
such as arrays and tensors. To test the measure we demonstrate the power of CTM
on low algorithmic-randomness objects that are assigned maximal entropy (e.g.
$\pi$) but whose numerical approximations are closer to the theoretical low
algorithmic-randomness expectation. We also test the measure on larger objects
including dual, isomorphic and cospectral graphs for which we know that
algorithmic randomness is low. We also release implementations of the methods
in most major programming languages--Mathematica, Matlab, R, Java, Perl,
Python, Pascal, C++, and Haskell-- and a free online algorithmic complexity
calculator.
</dc:description>
 <dc:description>Comment: 51 pages, 13 figures, 4 tables</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2017-10-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00110</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00115</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal State Estimation with Measurements Corrupted by Laplace Noise</dc:title>
 <dc:creator>Farokhi, Farhad</dc:creator>
 <dc:creator>Milosevic, Jezdimir</dc:creator>
 <dc:creator>Sandberg, Henrik</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Optimal state estimation for linear discrete-time systems is considered.
Motivated by the literature on differential privacy, the measurements are
assumed to be corrupted by Laplace noise. The optimal least mean square error
estimate of the state is approximated using a randomized method. The method
relies on that the Laplace noise can be rewritten as Gaussian noise scaled by
Rayleigh random variable. The probability of the event that the distance
between the approximation and the best estimate is smaller than a constant is
determined as function of the number of parallel Kalman filters that is used in
the randomized method. This estimator is then compared with the optimal linear
estimator, the maximum a posteriori (MAP) estimate of the state, and the
particle filter.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00116</identifier>
 <datestamp>2016-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Coarse-Graining: Extracting slowly-varying latent degrees of
  freedom with neural networks</dc:title>
 <dc:creator>Guttenberg, Nicholas</dc:creator>
 <dc:creator>Biehl, Martin</dc:creator>
 <dc:creator>Kanai, Ryota</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a loss function for neural networks that encompasses an idea of
trivial versus non-trivial predictions, such that the network jointly
determines its own prediction goals and learns to satisfy them. This permits
the network to choose sub-sets of a problem which are most amenable to its
abilities to focus on solving, while discarding 'distracting' elements that
interfere with its learning. To do this, the network first transforms the raw
data into a higher-level categorical representation, and then trains a
predictor from that new time series to its future. To prevent a trivial
solution of mapping the signal to zero, we introduce a measure of
non-triviality via a contrast between the prediction error of the learned model
with a naive model of the overall signal statistics. The transform can learn to
discard uninformative and unpredictable components of the signal in favor of
the features which are both highly predictive and highly predictable. This
creates a coarse-grained model of the time-series dynamics, focusing on
predicting the slowly varying latent parameters which control the statistics of
the time-series, rather than predicting the fast details directly. The result
is a semi-supervised algorithm which is capable of extracting latent
parameters, segmenting sections of time-series with differing statistics, and
building a higher-level representation of the underlying dynamics from
unlabeled data.
</dc:description>
 <dc:description>Comment: 9 pages, 5 figures, 3 tables</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00116</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00117</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Group Rotation Type Crowdsourcing</dc:title>
 <dc:creator>Kumai, Katsumi</dc:creator>
 <dc:creator>Shiraishi, Yuhki</dc:creator>
 <dc:creator>Zhang, Jianwei</dc:creator>
 <dc:creator>Kitagawa, Hiroyuki</dc:creator>
 <dc:creator>Morishima, Atsuyuki</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  A common workflow to perform a continuous human task stream is to divide
workers into groups, have one group perform the newly-arrived task, and rotate
the groups. We call this type of workflow the group rotation. This paper
addresses the problem of how to manage Group Rotation Type Crowdsourcing, the
group rotation in a crowdsourcing setting. In the group-rotation type
crowdsourcing, we must change the group structure dynamically because workers
come in and leave frequently. This paper proposes an approach to explore a
design space of methods for group restructuring in the group rotation type
crowdsourcing.
</dc:description>
 <dc:description>Comment: 2 non-reference pages + reference-only page, HCOMP2016, WiP paper</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00118</identifier>
 <datestamp>2016-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An algebra of synchronous atomic steps</dc:title>
 <dc:creator>Hayes, Ian J.</dc:creator>
 <dc:creator>Colvin, Robert</dc:creator>
 <dc:creator>Meinicke, Larissa</dc:creator>
 <dc:creator>Winter, Kirsten</dc:creator>
 <dc:creator>Velykis, Andrius</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This research started with an algebra for reasoning about rely/guarantee
concurrency for a shared memory model. The approach taken led to a more
abstract algebra of atomic steps, in which atomic steps synchronise (rather
than interleave) when composed in parallel. The algebra of rely/guarantee
concurrency then becomes an interpretation of the more abstract algebra. Many
of the core properties needed for rely/guarantee reasoning can be shown to hold
in the abstract algebra where their proofs are simpler and hence allow a higher
degree of automation. Moreover, the realisation that the synchronisation
mechanisms of standard process algebras, such as CSP and CCS/SCCS, can be
interpreted in our abstract algebra gives evidence of its unifying power. The
algebra has been encoded in Isabelle/HOL to provide a basis for tool support.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2016-10-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00119</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometrically Exact Finite Element Formulations for Curved Slender
  Beams: Kirchhoff-Love Theory vs. Simo-Reissner Theory</dc:title>
 <dc:creator>Meier, Christoph</dc:creator>
 <dc:creator>Wall, Wolfgang A.</dc:creator>
 <dc:creator>Popp, Alexander</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  The present work focuses on geometrically exact finite elements for highly
slender beams. It aims at the proposal of novel formulations of Kirchhoff-Love
type, a detailed review of existing formulations of Kirchhoff-Love and
Simo-Reissner type as well as a careful evaluation and comparison of the
proposed and existing formulations. Two different rotation interpolation
schemes with strong or weak Kirchhoff constraint enforcement, respectively, as
well as two different choices of nodal triad parametrizations in terms of
rotation or tangent vectors are proposed. The combination of these schemes
leads to four novel finite element variants, all of them based on a
C1-continuous Hermite interpolation of the beam centerline. Essential
requirements such as representability of general 3D, large-deformation, dynamic
problems involving slender beams with arbitrary initial curvatures and
anisotropic cross-section shapes or preservation of objectivity and
path-independence will be investigated analytically and verified numerically
for the different formulations. It will be shown that the geometrically exact
Kirchhoff-Love beam elements proposed in this work are the first ones of this
type that fulfill all the considered requirements. On the contrary,
Simo-Reissner type formulations fulfilling these requirements can be found in
the literature very well. However, it will be argued that the shear-free
Kirchhoff-Love formulations can provide considerable numerical advantages when
applied to highly slender beams. Concretely, several representative numerical
test cases confirm that the proposed Kirchhoff-Love formulations exhibit a
lower discretization error level as well as a considerably improved nonlinear
solver performance in the range of high beam slenderness ratios as compared to
two representative Simo-Reissner element formulations from the literature.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00126</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PPCU: Proportional Per-packet Consistent Updates for Software Defined
  Networks - A Technical Report</dc:title>
 <dc:creator>Sukapuram, Radhika</dc:creator>
 <dc:creator>Barua, Gautam</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>C.2.3</dc:subject>
 <dc:description>  In Software Defined Networks, where the network control plane can be
programmed by updating switch rules, consistently updating switches is a
challenging problem. In a per-packet consistent update (PPC), a packet either
matches the new rules added or the old rules to be deleted, throughout the
network, but not a combination of both. PPC must be preserved during an update
to prevent packet drops and loops, provide waypoint invariance and to apply
policies consistently. No algorithm exists today that confines changes required
during an update to only the affected switches, yet preserves PPC and does not
restrict applicable scenarios. We propose a general update algorithm called
PPCU that preserves PPC, is concurrent and provides an all-or-nothing semantics
for an update, irrespective of the execution speeds of switches and links,
while confining changes to only the affected switches and affected rules. We
use data plane time stamps to identify when the switches must move from the old
rules to the new rules. For this, we use the powerful programming features
provided to the data plane by the emerging programmable switches, which also
guarantee line rate. We prove the algorithm, identify its significant
parameters and analyze the parameters with respect to other algorithms in the
literature.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00126</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00129</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grid Loss: Detecting Occluded Faces</dc:title>
 <dc:creator>Opitz, Michael</dc:creator>
 <dc:creator>Waltner, Georg</dc:creator>
 <dc:creator>Poier, Georg</dc:creator>
 <dc:creator>Possegger, Horst</dc:creator>
 <dc:creator>Bischof, Horst</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Detection of partially occluded objects is a challenging computer vision
problem. Standard Convolutional Neural Network (CNN) detectors fail if parts of
the detection window are occluded, since not every sub-part of the window is
discriminative on its own. To address this issue, we propose a novel loss layer
for CNNs, named grid loss, which minimizes the error rate on sub-blocks of a
convolution layer independently rather than over the whole feature map. This
results in parts being more discriminative on their own, enabling the detector
to recover if the detection window is partially occluded. By mapping our loss
layer back to a regular fully connected layer, no additional computational cost
is incurred at runtime compared to standard CNNs. We demonstrate our method for
face detection on several public face detection benchmarks and show that our
method outperforms regular CNNs, is suitable for realtime applications and
achieves state-of-the-art performance.
</dc:description>
 <dc:description>Comment: accepted to ECCV 2016</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00129</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00130</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transparent Live Code Offloading on FPGA</dc:title>
 <dc:creator>Rigamonti, Roberto</dc:creator>
 <dc:creator>Delporte, Baptiste</dc:creator>
 <dc:creator>Convers, Anthony</dc:creator>
 <dc:creator>Dassatti, Alberto</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Even though it seems that FPGAs have finally made the transition from
research labs to the consumer devices' market, programming them remains
challenging. Despite the improvements made by High-Level Synthesis (HLS), which
removed the language and paradigm barriers that prevented many computer
scientists from working with them, producing a new design typically requires at
least several hours, making data- and context-dependent adaptations virtually
impossible.
  In this paper we present a new framework that off-loads, on-the-fly and
transparently to both the user and the developer, computationally-intensive
code fragments to FPGAs. While the performance should not surpass that of
hand-crafted HDL code, or even code produced by HLS, our results come with no
additional development costs and do not require producing and deploying a new
bit-stream to the FPGA each time a change is made. Moreover, since
optimizations are made at run-time, they may fit particular datasets or usage
scenarios, something which is rarely foreseeable at design or compile time.
  Our proposal revolves around an overlay architecture that is pre-programmed
on the FPGA and dynamically reconfigured by our framework to execute code
fragments extracted from the Data Flow Graph (DFG) of computational intensive
routines. We validated our solution using standard benchmarks and proved we are
able to off-load to FPGAs without developer's intervention.
</dc:description>
 <dc:description>Comment: 9 pages in FPGAs for Software Programmers (FSP 2016)</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00130</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00132</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Axiomatization of if-then-else over possibly non-halting programs and
  tests</dc:title>
 <dc:creator>Panicker, Gayatri</dc:creator>
 <dc:creator>Krishna, K. V.</dc:creator>
 <dc:creator>Bhaduri, Purandar</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>08A70, 03G25, 68N15</dc:subject>
 <dc:description>  In order to study the axiomatization of the if-then-else construct over
possibly non-halting programs and tests, this paper introduces the notion of
$C$-sets by considering the tests from an abstract $C$-algebra. When the
$C$-algebra is an ada, the axiomatization is shown to be complete by obtaining
a subdirect representation of $C$-sets. Further, this paper considers the
equality test with the if-then-else construct and gives a complete
axiomatization through the notion of agreeable $C$-sets.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00133</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>dr0wned - Cyber-Physical Attack with Additive Manufacturing</dc:title>
 <dc:creator>Belikovetsky, Sofia</dc:creator>
 <dc:creator>Yampolskiy, Mark</dc:creator>
 <dc:creator>Toh, Jinghui</dc:creator>
 <dc:creator>Elovici, Yuval</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Additive manufacturing (AM), or 3D printing, is an emerging manufacturing
technology that is expected to have far-reaching socioeconomic, environmental,
and geopolitical implications. As use of this technology increases, it will
become more common to produce functional parts, including components for
safety-critical systems. AM's dependence on computerization raises the concern
that the manufactured part's quality can be compromised by sabotage. This paper
demonstrates the validity of this concern, as we present the very first full
chain of attack involving AM, beginning with a cyber attack aimed at
compromising a benign AM component, continuing with malicious modification of a
manufactured object's blueprint, leading to the sabotage of the manufactured
functional part, and resulting in the physical destruction of a cyber-physical
system that employs this part. The contributions of this paper are as follows.
We propose a systematic approach to identify opportunities for an attack
involving AM that enables an adversary to achieve his/her goals. Then we
propose a methodology to assess the level of difficulty of an attack, thus
enabling differentiation between possible attack chains. Finally, to
demonstrate the experimental proof for the entire attack chain, we sabotage the
3D printed propeller of a quadcopter UAV, causing the quadcopter to literally
fall from the sky.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00142</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Performance of Multihop-Intervehicular Communications Systems
  over n*Rayleigh Fading Channels</dc:title>
 <dc:creator>Alghorani, Yahia</dc:creator>
 <dc:creator>Kaddoum, Georges</dc:creator>
 <dc:creator>Muhaidat, Sami</dc:creator>
 <dc:creator>Pierre, Samuel</dc:creator>
 <dc:creator>Al-Dhahir, Naofal</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We investigate the performance of multihop-intervehicular communication
systems with regenerative and nonregenerative relaying. We consider the
so-called &quot;n*Rayleigh distribution&quot; as an adequate multipath fading channel
model for vehicle-to-vehicle communication scenarios. We derive a novel
approximation for the outage probability of maximum ratio combining (MRC)
diversity reception. In addition, we analyze the amount of fading and optimize
the power allocation for the investigated scenario. Numerical results show that
regenerative systems are more efficient than nonregenerative systems when the
cascading order (n) is small; however, for large n, our results demonstrate
that the performance of both relaying techniques is rather similar.
</dc:description>
 <dc:description>Comment: 4 pages, 5 figures</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00142</dc:identifier>
 <dc:identifier>IEEE Wireless Communications Letters (Volume: 5, Issue: 2, April
  2016)</dc:identifier>
 <dc:identifier>doi:10.1109/LWC.2015.2505308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00147</identifier>
 <datestamp>2016-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-connected spanning subgraphs with at most $\frac{10}{7}$OPT edges</dc:title>
 <dc:creator>Heeger, Klaus</dc:creator>
 <dc:creator>Vygen, Jens</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present a $\frac{10}{7}$-approximation algorithm for the minimum
two-vertex-connected spanning subgraph problem.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00149</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Community Detection to Community Deception</dc:title>
 <dc:creator>Fionda, Valeria</dc:creator>
 <dc:creator>Pirr&#xf2;, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The community deception problem is about how to hide a target community C
from community detection algorithms. The need for deception emerges whenever a
group of entities (e.g., activists, police enforcements) want to cooperate
while concealing their existence as a community. In this paper we introduce and
formalize the community deception problem. To solve this problem, we describe
algorithms that carefully rewire the connections of C's members. We
experimentally show how several existing community detection algorithms can be
deceived, and quantify the level of deception by introducing a deception score.
We believe that our study is intriguing since, while showing how deception can
be realized it raises awareness for the design of novel detection algorithms
robust to deception techniques.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00150</identifier>
 <datestamp>2017-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reward Augmented Maximum Likelihood for Neural Structured Prediction</dc:title>
 <dc:creator>Norouzi, Mohammad</dc:creator>
 <dc:creator>Bengio, Samy</dc:creator>
 <dc:creator>Chen, Zhifeng</dc:creator>
 <dc:creator>Jaitly, Navdeep</dc:creator>
 <dc:creator>Schuster, Mike</dc:creator>
 <dc:creator>Wu, Yonghui</dc:creator>
 <dc:creator>Schuurmans, Dale</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A key problem in structured output prediction is direct optimization of the
task reward function that matters for test evaluation. This paper presents a
simple and computationally efficient approach to incorporate task reward into a
maximum likelihood framework. By establishing a link between the log-likelihood
and expected reward objectives, we show that an optimal regularized expected
reward is achieved when the conditional distribution of the outputs given the
inputs is proportional to their exponentiated scaled rewards. Accordingly, we
present a framework to smooth the predictive probability of the outputs using
their corresponding rewards. We optimize the conditional log-probability of
augmented outputs that are sampled proportionally to their exponentiated scaled
rewards. Experiments on neural sequence to sequence models for speech
recognition and machine translation show notable improvements over a maximum
likelihood baseline by using reward augmented maximum likelihood (RAML), where
the rewards are defined as the negative edit distance between the outputs and
the ground truth labels.
</dc:description>
 <dc:description>Comment: NIPS 2016</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2017-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00150</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00151</identifier>
 <datestamp>2017-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Several Proofs of Security for a Tokenization Algorithm</dc:title>
 <dc:creator>Longo, Riccardo</dc:creator>
 <dc:creator>Sala, Massimiliano</dc:creator>
 <dc:creator>Aragona, Riccardo</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A60</dc:subject>
 <dc:description>  In this paper we propose a tokenization algorithm of Reversible Hybrid type,
as defined in PCI DSS guidelines for designing a tokenization solution, based
on a block cipher with a secret key and (possibly public) additional input. We
provide some formal proofs of security for it, which imply our algorithm
satisfies the most significant security requirements described in PCI DSS
tokenization guidelines. Finally, we give an instantiation with concrete
cryptographic primitives and fixed length of the PAN, and we analyze its
efficiency and security.
</dc:description>
 <dc:description>Comment: to appear in Applicable Algebra in Engineering, Communication and
  Computing</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2017-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00153</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly Supervised PatchNets: Describing and Aggregating Local Patches
  for Scene Recognition</dc:title>
 <dc:creator>Wang, Zhe</dc:creator>
 <dc:creator>Wang, Limin</dc:creator>
 <dc:creator>Wang, Yali</dc:creator>
 <dc:creator>Zhang, Bowen</dc:creator>
 <dc:creator>Qiao, Yu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Traditional feature encoding scheme (e.g., Fisher vector) with local
descriptors (e.g., SIFT) and recent convolutional neural networks (CNNs) are
two classes of successful methods for image recognition. In this paper, we
propose a hybrid representation, which leverages the discriminative capacity of
CNNs and the simplicity of descriptor encoding schema for image recognition,
with a focus on scene recognition. To this end, we make three main
contributions from the following aspects. First, we propose a patch-level and
end-to-end architecture to model the appearance of local patches, called {\em
PatchNet}. PatchNet is essentially a customized network trained in a weakly
supervised manner, which uses the image-level supervision to guide the
patch-level feature extraction. Second, we present a hybrid visual
representation, called {\em VSAD}, by utilizing the robust feature
representations of PatchNet to describe local patches and exploiting the
semantic probabilities of PatchNet to aggregate these local patches into a
global representation. Third, based on the proposed VSAD representation, we
propose a new state-of-the-art scene recognition approach, which achieves an
excellent performance on two standard benchmarks: MIT Indoor67 (86.2\%) and
SUN397 (73.0\%).
</dc:description>
 <dc:description>Comment: To appear in IEEE Transactions on Image Processing. Code and model
  available at https://github.com/wangzheallen/vsad</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2017-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00153</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2017.2666739</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00161</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Clustering of Graphs for Anonymization and Recommender Systems</dc:title>
 <dc:creator>Prost, Frederic</dc:creator>
 <dc:creator>Yoon, Jisang</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  Graph clustering is widely used in many data analysis applications. In this
paper we propose several parallel graph clustering algorithms based on Monte
Carlo simulations and expectation maximization in the context of stochastic
block models. We apply those algorithms to the specific problems of recommender
systems and social network anonymization. We compare the experimental results
to previous propositions.
</dc:description>
 <dc:description>Comment: submitted to VLDB'17</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00162</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transferring Object-Scene Convolutional Neural Networks for Event
  Recognition in Still Images</dc:title>
 <dc:creator>Wang, Limin</dc:creator>
 <dc:creator>Wang, Zhe</dc:creator>
 <dc:creator>Qiao, Yu</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Event recognition in still images is an intriguing problem and has potential
for real applications. This paper addresses the problem of event recognition by
proposing a convolutional neural network that exploits knowledge of objects and
scenes for event classification (OS2E-CNN). Intuitively, it stands to reason
that there exists a correlation among the concepts of objects, scenes, and
events. We empirically demonstrate that the recognition of objects and scenes
substantially contributes to the recognition of events. Meanwhile, we propose
an iterative selection method to identify a subset of object and scene classes,
which help to more efficiently and effectively transfer their deep
representations to event recognition. Specifically, we develop three types of
transferring techniques: (1) initialization-based transferring, (2)
knowledge-based transferring, and (3) data-based transferring. These newly
designed transferring techniques exploit multi-task learning frameworks to
incorporate extra knowledge from other networks and additional datasets into
the training procedure of event CNNs. These multi-task learning frameworks turn
out to be effective in reducing the effect of over-fitting and improving the
generalization ability of the learned CNNs. With OS2E-CNN, we design a
multi-ratio and multi-scale cropping strategy, and propose an end-to-end event
recognition pipeline. We perform experiments on three event recognition
benchmarks: the ChaLearn Cultural Event Recognition dataset, the Web Image
Dataset for Event Recognition (WIDER), and the UIUC Sports Event dataset. The
experimental results show that our proposed algorithm successfully adapts
object and scene representations towards the event dataset and that it achieves
the current state-of-the-art performance on these challenging datasets.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00169</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Equivalence Checking a Floating-point Unit against a High-level C Model
  (Extended Version)</dc:title>
 <dc:creator>Mukherjee, Rajdeep</dc:creator>
 <dc:creator>Joshi, Saurabh</dc:creator>
 <dc:creator>Griesmayer, Andreas</dc:creator>
 <dc:creator>Kroening, Daniel</dc:creator>
 <dc:creator>Melham, Tom</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Semiconductor companies have increasingly adopted a methodology that starts
with a system-level design specification in C/C++/SystemC. This model is
extensively simulated to ensure correct functionality and performance. Later, a
Register Transfer Level (RTL) implementation is created in Verilog, either
manually by a designer or automatically by a high-level synthesis tool. It is
essential to check that the C and Verilog programs are consistent. In this
paper, we present a two-step approach, embodied in two equivalence checking
tools, VERIFOX and HW-CBMC, to validate designs at the software and RTL levels,
respectively. VERIFOX is used for equivalence checking of an untimed software
model in C against a high-level reference model in C. HW-CBMC verifies the
equivalence of a Verilog RTL implementation against an untimed software model
in C. To evaluate our tools, we applied them to a commercial floating-point
arithmetic unit (FPU) from ARM and an open-source dual-path floating-point
adder.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00177</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Continuous-Time Model of an Autonomous Aerial Vehicle to Inform and
  Validate Formal Verification Methods</dc:title>
 <dc:creator>Ireland, Murray L.</dc:creator>
 <dc:creator>Hoffmann, Ruth</dc:creator>
 <dc:creator>Miller, Alice</dc:creator>
 <dc:creator>Norman, Gethin</dc:creator>
 <dc:creator>Veres, Sandor M.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  If autonomous vehicles are to be widely accepted, we need to ensure their
safe operation. For this reason, verification and validation (V&amp;V) approaches
must be developed that are suitable for this domain. Model checking is a formal
technique which allows us to exhaustively explore the paths of an abstract
model of a system. Using a probabilistic model checker such as PRISM, we may
determine properties such as the expected time for a mission, or the
probability that a specific mission failure occurs. However, model checking of
complex systems is difficult due to the loss of information during abstraction.
This is especially so when considering systems such as autonomous vehicles
which are subject to external influences. An alternative solution is the use of
Monte Carlo simulation to explore the results of a continuous-time model of the
system. The main disadvantage of this approach is that the approach is not
exhaustive as not all executions of the system are analysed. We are therefore
interested in developing a framework for formal verification of autonomous
vehicles, using Monte Carlo simulation to inform and validate our symbolic
models during the initial stages of development. In this paper, we present a
continuous-time model of a quadrotor unmanned aircraft undertaking an
autonomous mission. We employ this model in Monte Carlo simulation to obtain
specific mission properties which will inform the symbolic models employed in
formal verification.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00177</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00183</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A short review and primer on electroencephalography in human computer
  interaction applications</dc:title>
 <dc:creator>Ahonen, Lauri</dc:creator>
 <dc:creator>Cowley, Benjamin</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  The application of psychophysiology in human-computer interaction is a
growing field with significant potential for future smart personalised systems.
Working in this emerging field requires comprehension of an array of
physiological signals and analysis techniques.
  Methods to study central nervous system (CNS) are usually expensive and
laborious. However, electroencephalography (EEG) is one of the most affordable
and ambulatory methodologies for CNS research. It is in use in various clinical
studies and have been broadly studied over decades. Despite that the recorded
EEG signals are quite prone to noise and environmental factors it is the most
widely used method in study of brain-computer interaction (BCI). Here we
discuss briefly on various aspects of the recorded signals, their
interpretation, and usage in the field of interaction studies.
  This paper aims to serve as a primer for the novice, enabling rapid
familiarisation with the latest core concepts. We put special emphasis on
everyday human-computer interface applications to distinguish from the more
common clinical or sports uses of psychophysiology.
  This paper is an extract from a comprehensive review of the entire field of
ambulatory psychophysiology, including 12 similar chapters, plus application
guidelines and systematic review. Thus any citation should be made using the
following reference:
  B. Cowley, M. Filetti, K. Lukander, J. Torniainen, A. Henelius, L. Ahonen, O.
Barral, I. Kosunen, T. Valtonen, M. Huotilainen, N. Ravaja, G. Jacucci. The
Psychophysiology Primer: a guide to methods and a broad review with a focus on
human-computer interaction. Foundations and Trends in Human-Computer
Interaction, vol. 9, no. 3-4, pp. 150--307, 2016.
</dc:description>
 <dc:description>Comment: 13 pages, 1 figure. Part of a journal</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2016-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00183</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00189</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual Capacity Upper Bounds for Noisy Runlength Constrained Channels</dc:title>
 <dc:creator>Thangaraj, Andrew</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Binary-input memoryless channels with a runlength constrained input are
considered. Upper bounds to the capacity of such noisy runlength constrained
channels are derived using the dual capacity method with Markov test
distributions satisfying the Karush-Kuhn-Tucker (KKT) conditions for the
capacity-achieving output distribution. Simplified algebraic characterizations
of the bounds are presented for the binary erasure channel (BEC) and the binary
symmetric channel (BSC). These upper bounds are very close to achievable rates,
and improve upon previously known feedback-based bounds for a large range of
channel parameters. For the binary-input Additive White Gaussian Noise (AWGN)
channel, the upper bound is simplified to a small-scale numerical optimization
problem. These results provide some of the simplest upper bounds for an open
capacity problem that has theoretical and practical relevance.
</dc:description>
 <dc:description>Comment: Expanded version of a paper in IEEE Information Theory Workshop 2017,
  Cambridge, UK, Sep 11-14, 2017</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2016-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00189</dc:identifier>
 <dc:identifier>doi:10.1109/ITW.2016.7606811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00195</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing a semantic model for a wide-spectrum language with concurrency</dc:title>
 <dc:creator>Colvin, Robert J.</dc:creator>
 <dc:creator>Hayes, Ian J.</dc:creator>
 <dc:creator>Meinicke, Larissa A.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  A wide-spectrum language integrates specification constructs into a
programming language in a manner that treats a specification command just like
any other command. This paper investigates a semantic model for a wide-spectrum
language that supports concurrency and a refinement calculus. In order to
handle specifications with rely and guarantee conditions, the model includes
explicit environment steps as well as program steps. A novelty of our approach
is that we define a set of primitive commands and operators, from which more
complex specification and programming language commands are built. The
primitives have simple algebraic properties which support proof using algebraic
reasoning. The model is general enough to specify notions as diverse as
rely-guarantee reasoning, temporal logic, and progress properties of programs,
and supports refining specifications to code. It also forms an instance of an
abstract concurrent program algebra, which facilitates reasoning about
properties of the model at a high level of abstraction.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00195</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00203</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Employing traditional machine learning algorithms for big data streams
  analysis: the case of object trajectory prediction</dc:title>
 <dc:creator>Valsamis, Angelos</dc:creator>
 <dc:creator>Tserpes, Konstantinos</dc:creator>
 <dc:creator>Zissis, Dimitrios</dc:creator>
 <dc:creator>Anagnostopoulos, Dimosthenis</dc:creator>
 <dc:creator>Varvarigou, Theodora</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we model the trajectory of sea vessels and provide a service
that predicts in near-real time the position of any given vessel in 4', 10',
20' and 40' time intervals. We explore the necessary tradeoffs between
accuracy, performance and resource utilization are explored given the large
volume and update rates of input data. We start with building models based on
well-established machine learning algorithms using static datasets and
multi-scan training approaches and identify the best candidate to be used in
implementing a single-pass predictive approach, under real-time constraints.
The results are measured in terms of accuracy and performance and are compared
against the baseline kinematic equations. Results show that it is possible to
efficiently model the trajectory of multiple vessels using a single model,
which is trained and evaluated using an adequately large, static dataset, thus
achieving a significant gain in terms of resource usage while not compromising
accuracy.
</dc:description>
 <dc:description>Comment: 14 pages, 2 figures, 3 tables, 31 references</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00203</dc:identifier>
 <dc:identifier>doi:10.1016/j.jss.2016.06.016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00214</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Separability of Reachability Sets of Vector Addition Systems</dc:title>
 <dc:creator>Clemente, Lorenzo</dc:creator>
 <dc:creator>Czerwi&#x144;ski, Wojciech</dc:creator>
 <dc:creator>Lasota, S&#x142;awomir</dc:creator>
 <dc:creator>Paperman, Charles</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Given two families of sets $\mathcal{F}$ and $\mathcal{G}$, the $\mathcal{F}$
separability problem for $\mathcal{G}$ asks whether for two given sets $U, V
\in \mathcal{G}$ there exists a set $S \in \mathcal{F}$, such that $U$ is
included in $S$ and $V$ is disjoint with $S$. We consider two families of sets
$\mathcal{F}$: modular sets $S \subseteq \mathbb{N}^d$, defined as unions of
equivalence classes modulo some natural number $n \in \mathbb{N}$, and unary
sets. Our main result is decidability of modular and unary separability for the
class $\mathcal{G}$ of reachability sets of Vector Addition Systems, Petri
Nets, Vector Addition Systems with States, and for sections thereof.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00221</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Segmentation Free Object Discovery in Video</dc:title>
 <dc:creator>Cuffaro, Giovanni</dc:creator>
 <dc:creator>Becattini, Federico</dc:creator>
 <dc:creator>Baecchi, Claudio</dc:creator>
 <dc:creator>Seidenari, Lorenzo</dc:creator>
 <dc:creator>Del Bimbo, Alberto</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we present a simple yet effective approach to extend without
supervision any object proposal from static images to videos. Unlike previous
methods, these spatio-temporal proposals, to which we refer as tracks, are
generated relying on little or no visual content by only exploiting bounding
boxes spatial correlations through time. The tracks that we obtain are likely
to represent objects and are a general-purpose tool to represent meaningful
video content for a wide variety of tasks. For unannotated videos, tracks can
be used to discover content without any supervision. As further contribution we
also propose a novel and dataset-independent method to evaluate a generic
object proposal based on the entropy of a classifier output response. We
experiment on two competitive datasets, namely YouTube Objects and ILSVRC-2015
VID.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00221</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00222</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ternary Neural Networks for Resource-Efficient AI Applications</dc:title>
 <dc:creator>Alemdar, Hande</dc:creator>
 <dc:creator>Leroy, Vincent</dc:creator>
 <dc:creator>Prost-Boucle, Adrien</dc:creator>
 <dc:creator>P&#xe9;trot, Fr&#xe9;d&#xe9;ric</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The computation and storage requirements for Deep Neural Networks (DNNs) are
usually high. This issue limits their deployability on ubiquitous computing
devices such as smart phones, wearables and autonomous drones. In this paper,
we propose ternary neural networks (TNNs) in order to make deep learning more
resource-efficient. We train these TNNs using a teacher-student approach based
on a novel, layer-wise greedy methodology. Thanks to our two-stage training
procedure, the teacher network is still able to use state-of-the-art methods
such as dropout and batch normalization to increase accuracy and reduce
training time. Using only ternary weights and activations, the student ternary
network learns to mimic the behavior of its teacher network without using any
multiplication. Unlike its -1,1 binary counterparts, a ternary neural network
inherently prunes the smaller weights by setting them to zero during training.
This makes them sparser and thus more energy-efficient. We design a
purpose-built hardware architecture for TNNs and implement it on FPGA and ASIC.
We evaluate TNNs on several benchmark datasets and demonstrate up to 3.1x
better energy efficiency with respect to the state of the art while also
improving accuracy.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00225</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random-Training-Assisted Pilot Spoofing Detection and Secure
  Transmission</dc:title>
 <dc:creator>Tian, Xiaowen</dc:creator>
 <dc:creator>Li, Ming</dc:creator>
 <dc:creator>Liu, Qian</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The pilot spoofing attack is considered as an active eavesdropping activity
launched by an adversary during the reverse channel training phase. By
transmitting the same pilot signal as the legitimate user, the pilot spoofing
attack is able to degrade the quality of legitimate transmission and, more
severely, facilitate eavesdropping. In an effort to detect the pilot spoofing
attack and minimize its damages, in this paper we propose a novel
random-training-assisted (RTA) pilot spoofing detection algorithm. In
particular, we develop a new training mechanism by adding a random training
phase after the conventional pilot training phase. By examining the difference
of the estimated legitimate channels during these two phases, the pilot
spoofing attack can be detected accurately. If no spoofing attack is detected,
we present a computationally efficient channel estimation enhancement algorithm
to further improve the channel estimation accuracy. If the existence of the
pilot spoofing attack is identified, a zero-forcing (ZF)-based secure
transmission scheme is proposed to protect the confidential information from
the active eavesdropper. Extensive simulation results demonstrate that the
proposed RTA scheme can achieve efficient pilot spoofing detection, accurate
channel estimation, and secure transmission.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00263</identifier>
 <datestamp>2016-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Robust Colorings of Hamming-Distance Graphs</dc:title>
 <dc:creator>Harney, Isaiah</dc:creator>
 <dc:creator>Gluesing-Luerssen, Heide</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>05C15, 05C69, 94B05</dc:subject>
 <dc:description>  $H_q(n,d)$ is defined as the graph with vertex set ${\mathbb Z}_q^n$ and
where two vertices are adjacent if their Hamming distance is at least $d$. The
chromatic number of these graphs is presented for various sets of parameters
$(q,n,d)$. For the $4$-colorings of the graphs $H_2(n,n-1)$ a notion of
robustness is introduced. It is based on the tolerance of swapping colors along
an edge without destroying properness of the coloring. An explicit description
of the maximally robust $4$-colorings of $H_2(n,n-1)$ is presented.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2016-09-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00265</identifier>
 <datestamp>2016-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Testing $k$-Monotonicity</dc:title>
 <dc:creator>Canonne, Cl&#xe9;ment L.</dc:creator>
 <dc:creator>Grigorescu, Elena</dc:creator>
 <dc:creator>Guo, Siyao</dc:creator>
 <dc:creator>Kumar, Akash</dc:creator>
 <dc:creator>Wimmer, Karl</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A Boolean $k$-monotone function defined over a finite poset domain ${\cal D}$
alternates between the values $0$ and $1$ at most $k$ times on any ascending
chain in ${\cal D}$. Therefore, $k$-monotone functions are natural
generalizations of the classical monotone functions, which are the $1$-monotone
functions. Motivated by the recent interest in $k$-monotone functions in the
context of circuit complexity and learning theory, and by the central role that
monotonicity testing plays in the context of property testing, we initiate a
systematic study of $k$-monotone functions, in the property testing model. In
this model, the goal is to distinguish functions that are $k$-monotone (or are
close to being $k$-monotone) from functions that are far from being
$k$-monotone. Our results include the following:
  - We demonstrate a separation between testing $k$-monotonicity and testing
monotonicity, on the hypercube domain $\{0,1\}^d$, for $k\geq 3$;
  - We demonstrate a separation between testing and learning on $\{0,1\}^d$,
for $k=\omega(\log d)$: testing $k$-monotonicity can be performed with
$2^{O(\sqrt d \cdot \log d\cdot \log{1/\varepsilon})}$ queries, while learning
$k$-monotone functions requires $2^{\Omega(k\cdot \sqrt
d\cdot{1/\varepsilon})}$ queries (Blais et al. (RANDOM 2015)).
  - We present a tolerant test for functions $f\colon[n]^d\to \{0,1\}$ with
complexity independent of $n$, which makes progress on a problem left open by
Berman et al. (STOC 2014).
  Our techniques exploit the testing-by-learning paradigm, use novel
applications of Fourier analysis on the grid $[n]^d$, and draw connections to
distribution testing techniques.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2016-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00265</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00266</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Retrofitting Applications with Provenance-Based Security Monitoring</dc:title>
 <dc:creator>Bates, Adam</dc:creator>
 <dc:creator>Butler, Kevin</dc:creator>
 <dc:creator>Dobra, Alin</dc:creator>
 <dc:creator>Reaves, Brad</dc:creator>
 <dc:creator>Cable, Patrick</dc:creator>
 <dc:creator>Moyer, Thomas</dc:creator>
 <dc:creator>Schear, Nabil</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Data provenance is a valuable tool for detecting and preventing cyber attack,
providing insight into the nature of suspicious events. For example, an
administrator can use provenance to identify the perpetrator of a data leak,
track an attacker's actions following an intrusion, or even control the flow of
outbound data within an organization. Unfortunately, providing relevant data
provenance for complex, heterogenous software deployments is challenging,
requiring both the tedious instrumentation of many application components as
well as a unified architecture for aggregating information between components.
  In this work, we present a composition of techniques for bringing affordable
and holistic provenance capabilities to complex application workflows, with
particular consideration for the exemplar domain of web services. We present
DAP, a transparent architecture for capturing detailed data provenance for web
service components. Our approach leverages a key insight that minimal knowledge
of open protocols can be leveraged to extract precise and efficient provenance
information by interposing on application components' communications, granting
DAP compatibility with existing web services without requiring instrumentation
or developer cooperation. We show how our system can be used in real time to
monitor system intrusions or detect data exfiltration attacks while imposing
less than 5.1 ms end-to-end overhead on web requests. Through the introduction
of a garbage collection optimization, DAP is able to monitor system activity
without suffering from excessive storage overhead. DAP thus serves not only as
a provenance-aware web framework, but as a case study in the non-invasive
deployment of provenance capabilities for complex applications workflows.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00266</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00278</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Image Based Geolocation Given a Map</dc:title>
 <dc:creator>Mousavian, Arsalan</dc:creator>
 <dc:creator>Kosecka, Jana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The problem visual place recognition is commonly used strategy for
localization. Most successful appearance based methods typically rely on a
large database of views endowed with local or global image descriptors and
strive to retrieve the views of the same location. The quality of the results
is often affected by the density of the reference views and the robustness of
the image representation with respect to viewpoint variations, clutter and
seasonal changes. In this work we present an approach for geo-locating a novel
view and determining camera location and orientation using a map and a sparse
set of geo-tagged reference views. We propose a novel technique for detection
and identification of building facades from geo-tagged reference view using the
map and geometry of the building facades. We compute the likelihood of camera
location and orientation of the query images using the detected landmark
(building) identities from reference views, 2D map of the environment, and
geometry of building facades. We evaluate our approach for building
identification and geo-localization on a new challenging outdoors urban dataset
exhibiting large variations in appearance and viewpoint.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00283</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consensus over Weighted Directed Graphs: A Robustness Perspective</dc:title>
 <dc:creator>Mukherjee, Dwaipayan</dc:creator>
 <dc:creator>Zelazo, Daniel</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The present paper investigates the robustness of the consensus protocol over
weighted directed graphs using the Nyquist criterion. The limit to which a
single weight can vary, while consensus among the agents can be achieved, is
explicitly derived. It is shown that even with a negative weight on one of the
edges, consensus may be achieved. The result obtained in this paper is applied
to a directed acyclic graph and to the directed cycle graph. Graph theoretic
interpretations of the limits are provided for the two cases. Simulations
support the theoretical results.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00283</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00288</identifier>
 <datestamp>2017-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified View of Multi-Label Performance Measures</dc:title>
 <dc:creator>Wu, Xi-Zhu</dc:creator>
 <dc:creator>Zhou, Zhi-Hua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Multi-label classification deals with the problem where each instance is
associated with multiple class labels. Because evaluation in multi-label
classification is more complicated than single-label setting, a number of
performance measures have been proposed. It is noticed that an algorithm
usually performs differently on different measures. Therefore, it is important
to understand which algorithms perform well on which measure(s) and why. In
this paper, we propose a unified margin view to revisit eleven performance
measures in multi-label classification. In particular, we define label-wise
margin and instance-wise margin, and prove that through maximizing these
margins, different corresponding performance measures will be optimized. Based
on the defined margins, a max-margin approach called LIMO is designed and
empirical results verify our theoretical findings.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2017-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00288</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00291</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Non-iterative Method for (Re)Construction of Phase from STFT Magnitude</dc:title>
 <dc:creator>Pr&#x16f;&#x161;a, Zden&#x11b;k</dc:creator>
 <dc:creator>Balazs, Peter</dc:creator>
 <dc:creator>S&#xf8;ndergaard, Peter L.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  A non-iterative method for the construction of the Short-Time Fourier
Transform (STFT) phase from the magnitude is presented. The method is based on
the direct relationship between the partial derivatives of the phase and the
logarithm of the magnitude of the un-sampled STFT with respect to the Gaussian
window. Although the theory holds in the continuous setting only, the
experiments show that the algorithm performs well even in the discretized
setting (Discrete Gabor transform) with low redundancy using the sampled
Gaussian window, the truncated Gaussian window and even other compactly
supported windows like the Hann window.
  Due to the non-iterative nature, the algorithm is very fast and it is
suitable for long audio signals. Moreover, solutions of iterative phase
reconstruction algorithms can be improved considerably by initializing them
with the phase estimate provided by the present algorithm.
  We present an extensive comparison with the state-of-the-art algorithms in a
reproducible manner.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00291</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00292</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crowdsourcing with Unsure Option</dc:title>
 <dc:creator>Ding, Yao-Xiang</dc:creator>
 <dc:creator>Zhou, Zhi-Hua</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  One of the fundamental problems in crowdsourcing is the trade-off between the
number of the workers needed for high-accuracy aggregation and the budget to
pay. For saving budget, it is important to ensure high quality of the
crowd-sourced labels, hence the total cost on label collection will be reduced.
Since the self-confidence of the workers often has a close relationship with
their abilities, a possible way for quality control is to request the workers
to return the labels only when they feel confident, by means of providing
unsure option to them. On the other hand, allowing workers to choose unsure
option also leads to the potential danger of budget waste. In this work, we
propose the analysis towards understanding when providing the unsure option
indeed leads to significant cost reduction, as well as how the confidence
threshold is set. We also propose an online mechanism, which is alternative for
threshold selection when the estimation of the crowd ability distribution is
difficult.
</dc:description>
 <dc:description>Comment: 25 pages, 1 figures</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2017-08-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00300</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QoS Provisioning with Adaptive Backoff Algorithm for IEEE 802.11ac Under
  Multipacket Reception</dc:title>
 <dc:creator>B, Arun I</dc:creator>
 <dc:creator>Venkatesh, T. G.</dc:creator>
 <dc:creator>Dappuri, Bhasker</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>C.2.5</dc:subject>
 <dc:description>  Recent advances in physical layer communication techniques, enable receivers
to decode multiple simultaneous transmissions. This technique is known as the
multipacket reception (MPR). In this paper, we propose an enhancement to the
IEEE 802.11ac EDCA protocol for channels supporting MPR for QoS provisioning.
We show that in the case of MPR, in addition to CWmin, CWmax and AIFSN, we can
use two more parameters namely (i) threshold and (ii) counter decrement value,
that can offer service differentiation. The performance evaluation of the
different metrics of the proposed protocol (throughput, delay, and jitter) is
carried out using extensive simulations.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures, In Proceedings of 9th International Symposium on
  Communication Systems, Networks &amp; Digital Sign (CSNDSP), Manchester, 2014.
  arXiv admin note: text overlap with arXiv:1308.5360</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00300</dc:identifier>
 <dc:identifier>doi:10.1109/CSNDSP.2014.6923941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00302</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sampling-based verification of Lyapunov's inequality for piecewise
  continuous nonlinear systems</dc:title>
 <dc:creator>Bobiti, Ruxandra</dc:creator>
 <dc:creator>Lazar, Mircea</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper considers a sampling-based approach to stability verification for
piecewise continuous nonlinear systems via Lyapunov functions. Depending on the
system dynamics, the candidate Lyapunov function and the set of initial states
of interest, one generally needs to handle large, possibly non-convex or
non-feasible optimization problems. To avoid such problems, we propose a
constructive and systematically applicable sampling-based method to Lyapunov's
inequality verification. This approach proposes verification of the decrease
condition for a candidate Lyapunov function on a finite sampling of a bounded
set of initial conditions and then it extends the validity of the Lyapunov
function to an infinite set of initial conditions by automatically exploiting
continuity properties. This result is based on multi-resolution sampling, to
perform efficient state- space exploration. Using hyper-rectangles as basic
sampling blocks, to account for different constraint scales on different
states, further reduces the amount of samples to be verified. Moreover, the
verification is decentralized in the sampling points, which makes the method
scalable. The proposed methodology is illustrated through examples.
</dc:description>
 <dc:description>Comment: 14 pages, 7 figures</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00306</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On-Chip Mechanisms to Reduce Effective Memory Access Latency</dc:title>
 <dc:creator>Hashemi, Milad</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  This dissertation develops hardware that automatically reduces the effective
latency of accessing memory in both single-core and multi-core systems. To
accomplish this, the dissertation shows that all last level cache misses can be
separated into two categories: dependent cache misses and independent cache
misses. Independent cache misses have all of the source data that is required
to generate the address of the memory access available on-chip, while dependent
cache misses depend on data that is located off-chip. This dissertation
proposes that dependent cache misses are accelerated by migrating the
dependence chain that generates the address of the memory access to the memory
controller for execution. Independent cache misses are accelerated using a new
mode for runahead execution that only executes filtered dependence chains. With
these mechanisms, this dissertation demonstrates a 62% increase in performance
and a 19% decrease in effective memory access latency for a quad-core processor
on a set of high memory intensity workloads.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00317</identifier>
 <datestamp>2017-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The {\kappa}-{\mu} Shadowed Fading Model with Integer Fading Parameters</dc:title>
 <dc:creator>Lopez-Martinez, F. Javier</dc:creator>
 <dc:creator>Paris, Jose F.</dc:creator>
 <dc:creator>Romero-Jerez, Juan M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We show that the popular and general {\kappa}-{\mu} shad- owed fading model
with integer fading parameters {\mu} and m can be represented as a mixture of
squared Nakagami (or Gamma) distributions. Thus, its PDF and CDF can be
expressed in closed-form in terms of a finite number of elementary functions
(powers and exponentials). The main implications arising from such connection
are then discussed, which can be summarized as: (1) the performance evaluation
of communication systems operating in {\kappa}-{\mu} shadowed fading becomes as
simple as if a Nakagami fading channel was assumed; (2) the {\kappa}-{\mu}
shadowed distribution can be used to approximate the {\kappa}-{\mu}
distribution us- ing a closed-form representation in terms of elementary
functions, by choosing a sufficiently large value of m; and (3) restricting the
parameters {\mu} and m to take integer values has limited impact in practice
when fitting the {\kappa}-{\mu} shadowed fading model to field measurements. As
an application example, the average channel capacity of communication systems
operating under {\kappa}-{\mu} shadowed fading is obtained in closed-form.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2017-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00321</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Block Crossings in Storyline Visualizations</dc:title>
 <dc:creator>van Dijk, Thomas C.</dc:creator>
 <dc:creator>Fink, Martin</dc:creator>
 <dc:creator>Fischer, Norbert</dc:creator>
 <dc:creator>Lipp, Fabian</dc:creator>
 <dc:creator>Markfelder, Peter</dc:creator>
 <dc:creator>Ravsky, Alexander</dc:creator>
 <dc:creator>Suri, Subhash</dc:creator>
 <dc:creator>Wolff, Alexander</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Storyline visualizations help visualize encounters of the characters in a
story over time. Each character is represented by an x-monotone curve that goes
from left to right. A meeting is represented by having the characters that
participate in the meeting run close together for some time. In order to keep
the visual complexity low, rather than just minimizing pairwise crossings of
curves, we propose to count block crossings, that is, pairs of intersecting
bundles of lines.
  Our main results are as follows. We show that minimizing the number of block
crossings is NP-hard, and we develop, for meetings of bounded size, a
constant-factor approximation. We also present two fixed-parameter algorithms
and, for meetings of size 2, a greedy heuristic that we evaluate
experimentally.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00322</identifier>
 <datestamp>2016-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Open Call-by-Value (Extended Version)</dc:title>
 <dc:creator>Accattoli, Beniamino</dc:creator>
 <dc:creator>Guerrieri, Giulio</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  The elegant theory of the call-by-value lambda-calculus relies on weak
evaluation and closed terms, that are natural hypotheses in the study of
programming languages. To model proof assistants, however, strong evaluation
and open terms are required, and it is well known that the operational
semantics of call-by-value becomes problematic in this case. Here we study the
intermediate setting -- that we call Open Call-by-Value -- of weak evaluation
with open terms, on top of which Gr\'egoire and Leroy designed the abstract
machine of Coq. Various calculi for Open Call-by-Value already exist, each one
with its pros and cons. This paper presents a detailed comparative study of the
operational semantics of four of them, coming from different areas such as the
study of abstract machines, denotational semantics, linear logic proof nets,
and sequent calculus. We show that these calculi are all equivalent from a
termination point of view, justifying the slogan Open Call-by-Value.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2016-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00324</identifier>
 <datestamp>2016-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uniform Penalty inversion of two-dimensional NMR Relaxation data</dc:title>
 <dc:creator>Bortolotti, V.</dc:creator>
 <dc:creator>Brown, R. J. S.</dc:creator>
 <dc:creator>Fantazzini, P.</dc:creator>
 <dc:creator>Landi, G.</dc:creator>
 <dc:creator>Zama, F.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  The inversion of two-dimensional NMR data is an ill-posed problem related to
the numerical computation of the inverse Laplace transform. In this paper we
present the 2DUPEN algorithm that extends the Uniform Penalty (UPEN) algorithm
[Borgia, Brown, Fantazzini, {\em Journal of Magnetic Resonance}, 1998] to
two-dimensional data. The UPEN algorithm, defined for the inversion of
one-dimensional NMR relaxation data, uses Tikhonov-like regularization and
optionally non-negativity constraints in order to implement locally adapted
regularization. In this paper, we analyze the regularization properties of this
approach. Moreover, we extend the one-dimensional UPEN algorithm to the
two-dimensional case and present an efficient implementation based on the
Newton Projection method. Without any a-priori information on the noise norm,
2DUPEN automatically computes the locally adapted regularization parameters and
the distribution of the unknown NMR parameters by using variable smoothing.
Results of numerical experiments on simulated and real data are presented in
order to illustrate the potential of the proposed method in reconstructing
peaks and flat regions with the same accuracy.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00324</dc:identifier>
 <dc:identifier>doi:10.1088/1361-6420/33/1/015003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00331</identifier>
 <datestamp>2016-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verifier Theory and Unverifiability</dc:title>
 <dc:creator>Yampolskiy, Roman V.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Despite significant developments in Proof Theory, surprisingly little
attention has been devoted to the concept of proof verifier. In particular, the
mathematical community may be interested in studying different types of proof
verifiers (people, programs, oracles, communities, superintelligences) as
mathematical objects. Such an effort could reveal their properties, their
powers and limitations (particularly in human mathematicians), minimum and
maximum complexity, as well as self-verification and self-reference issues. We
propose an initial classification system for verifiers and provide some
rudimentary analysis of solved and open problems in this important domain. Our
main contribution is a formal introduction of the notion of unverifiability,
for which the paper could serve as a general citation in domains of theorem
proving, as well as software and AI verification.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2016-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00331</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00344</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning Human Mind for Automated Visual Classification</dc:title>
 <dc:creator>Spampinato, Concetto</dc:creator>
 <dc:creator>Palazzo, Simone</dc:creator>
 <dc:creator>Kavasidis, Isaak</dc:creator>
 <dc:creator>Giordano, Daniela</dc:creator>
 <dc:creator>Shah, Mubarak</dc:creator>
 <dc:creator>Souly, Nasim</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  What if we could effectively read the mind and transfer human visual
capabilities to computer vision methods? In this paper, we aim at addressing
this question by developing the first visual object classifier driven by human
brain signals. In particular, we employ EEG data evoked by visual object
stimuli combined with Recurrent Neural Networks (RNN) to learn a discriminative
brain activity manifold of visual categories. Afterwards, we train a
Convolutional Neural Network (CNN)-based regressor to project images onto the
learned manifold, thus effectively allowing machines to employ human
brain-based features for automated visual classification. We use a 32-channel
EEG to record brain activity of seven subjects while looking at images of 40
ImageNet object classes. The proposed RNN based approach for discriminating
object classes using brain signals reaches an average accuracy of about 40%,
which outperforms existing methods attempting to learn EEG visual object
representations. As for automated object categorization, our human brain-driven
approach obtains competitive performance, comparable to those achieved by
powerful CNN models, both on ImageNet and CalTech 101, thus demonstrating its
classification and generalization capabilities. This gives us a real hope that,
indeed, human mind can be read and transferred to machines.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00344</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00361</identifier>
 <datestamp>2016-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Autonomous driving challenge: To Infer the property of a dynamic object
  based on its motion pattern using recurrent neural network</dc:title>
 <dc:creator>Fathollahi, Mona</dc:creator>
 <dc:creator>Kasturi, Rangachar</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In autonomous driving applications a critical challenge is to identify action
to take to avoid an obstacle on collision course. For example, when a heavy
object is suddenly encountered it is critical to stop the vehicle or change the
lane even if it causes other traffic disruptions. However,there are situations
when it is preferable to collide with the object rather than take an action
that would result in a much more serious accident than collision with the
object. For example, a heavy object which falls from a truck should be avoided
whereas a bouncing ball or a soft target such as a foam box need not be.We
present a novel method to discriminate between the motion characteristics of
these types of objects based on their physical properties such as bounciness,
elasticity, etc.In this preliminary work, we use recurrent neural net-work with
LSTM cells to train a classifier to classify objects based on their motion
trajectories. We test the algorithm on synthetic data, and, as a proof of
concept, demonstrate its effectiveness on a limited set of real-world data.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2016-09-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00365</identifier>
 <datestamp>2017-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>State Estimation for Piecewise Affine State-Space Models</dc:title>
 <dc:creator>Rui, Rafael</dc:creator>
 <dc:creator>Ardeshiri, Tohid</dc:creator>
 <dc:creator>Nurminen, Henri</dc:creator>
 <dc:creator>Bazanella, Alexandre</dc:creator>
 <dc:creator>Gustafsson, Fredrik</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We propose a filter for piecewise affine state-space (PWASS) models. In each
filtering recursion, the true filtering posterior distribution is a mixture of
truncated normal distributions. The proposed filter approximates the mixture
with a single normal distribution via moment matching. The proposed algorithm
is compared with the extended Kalman filter (EKF) in a numerical simulation
where the proposed method obtains, on average, better root mean square error
(RMSE) than the EKF.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00365</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2016.2633624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00368</identifier>
 <datestamp>2017-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ten Steps of EM Suffice for Mixtures of Two Gaussians</dc:title>
 <dc:creator>Daskalakis, Constantinos</dc:creator>
 <dc:creator>Tzamos, Christos</dc:creator>
 <dc:creator>Zampetakis, Manolis</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  The Expectation-Maximization (EM) algorithm is a widely used method for
maximum likelihood estimation in models with latent variables. For estimating
mixtures of Gaussians, its iteration can be viewed as a soft version of the
k-means clustering algorithm. Despite its wide use and applications, there are
essentially no known convergence guarantees for this method. We provide global
convergence guarantees for mixtures of two Gaussians with known covariance
matrices. We show that the population version of EM, where the algorithm is
given access to infinitely many samples from the mixture, converges
geometrically to the correct mean vectors, and provide simple, closed-form
expressions for the convergence rate. As a simple illustration, we show that,
in one dimension, ten steps of the EM algorithm initialized at infinity result
in less than 1\% error estimation of the means. In the finite sample regime, we
show that, under a random initialization, $\tilde{O}(d/\epsilon^2)$ samples
suffice to compute the unknown vectors to within $\epsilon$ in Mahalanobis
distance, where $d$ is the dimension. In particular, the error rate of the EM
based estimator is $\tilde{O}\left(\sqrt{d \over n}\right)$ where $n$ is the
number of samples, which is optimal up to logarithmic factors.
</dc:description>
 <dc:description>Comment: Accepted for presentation at Conference on Learning Theory (COLT)
  2017</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2017-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00396</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Language Classes Associated with Automata Over Matrix Groups</dc:title>
 <dc:creator>Salehi, &#xd6;zlem</dc:creator>
 <dc:creator>D'Alessandro, Flavio</dc:creator>
 <dc:creator>Say, A. C. Cem</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We investigate the language classes recognized by group automata over matrix
groups. We present a summary of the results obtained so far together with a
number of new results. We look at the computational power of time-bounded group
automata where the group under consideration has polynomial growth.
</dc:description>
 <dc:description>Comment: NCMA'16</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00396</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00408</identifier>
 <datestamp>2016-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Defeating Image Obfuscation with Deep Learning</dc:title>
 <dc:creator>McPherson, Richard</dc:creator>
 <dc:creator>Shokri, Reza</dc:creator>
 <dc:creator>Shmatikov, Vitaly</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We demonstrate that modern image recognition methods based on artificial
neural networks can recover hidden information from images protected by various
forms of obfuscation. The obfuscation techniques considered in this paper are
mosaicing (also known as pixelation), blurring (as used by YouTube), and P3, a
recently proposed system for privacy-preserving photo sharing that encrypts the
significant JPEG coefficients to make images unrecognizable by humans. We
empirically show how to train artificial neural networks to successfully
identify faces and recognize objects and handwritten digits even if the images
are protected using any of the above obfuscation techniques.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2016-09-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00408</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00419</identifier>
 <datestamp>2017-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatially Correlated Content Caching for Device-to-Device Communications</dc:title>
 <dc:creator>Malak, Derya</dc:creator>
 <dc:creator>Al-Shalash, Mazin</dc:creator>
 <dc:creator>Andrews, Jeffrey G.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We study optimal geographic content placement for device-to-device (D2D)
networks in which each file's popularity follows the Zipf distribution. The
locations of the D2D users (caches) are modeled by a Poisson point process
(PPP) and have limited communication range and finite storage. Inspired by the
Mat\'{e}rn hard-core (type II) point process that captures pairwise
interactions between nodes, we devise a novel spatially correlated caching
strategy called {\em hard-core placement} (HCP) such that the D2D nodes caching
the same file are never closer to each other than the {\em exclusion radius}.
The exclusion radius plays the role of a substitute for caching probability. We
derive and optimize the exclusion radii to maximize the {\em hit probability},
which is the probability that a given D2D node can find a desired file at
another node's cache within its communication range. Contrasting it with
independent content placement, which is used in most prior work, our HCP
strategy often yields a significantly higher cache hit probability. We further
demonstrate that the HCP strategy is effective for small cache sizes and a
small communication radius, which are likely conditions for D2D.
</dc:description>
 <dc:description>Comment: a shorter version appeared in Proc. IEEE Intl. Symposium on Info.
  Theory, Barcelona, Spain, [arXiv:1608.07856]</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2017-10-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00424</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Path Low Delay Network Codes</dc:title>
 <dc:creator>Cloud, Jason</dc:creator>
 <dc:creator>Medard, Muriel</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The capability of mobile devices to use multiple interfaces to support a
single session is becoming more prevalent. Prime examples include the desire to
implement WiFi offloading and the introduction of 5G. Furthermore, an
increasing fraction of Internet traffic is becoming delay sensitive. These two
trends drive the need to investigate methods that enable communication over
multiple parallel heterogeneous networks, while also ensuring that delay
constraints are met. This paper approaches these challenges using a multi-path
streaming code that uses forward error correction to reduce the in-order
delivery delay of packets in networks with poor link quality and transient
connectivity. A simple analysis is developed that provides a good approximation
of the in-order delivery delay. Furthermore, numerical results help show that
the delay penalty of communicating over multiple paths is insignificant when
considering the potential throughput gains obtained through the fusion of
multiple networks.
</dc:description>
 <dc:description>Comment: 7 Pages</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00425</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying Dogmatism in Social Media: Signals and Models</dc:title>
 <dc:creator>Fast, Ethan</dc:creator>
 <dc:creator>Horvitz, Eric</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We explore linguistic and behavioral features of dogmatism in social media
and construct statistical models that can identify dogmatic comments. Our model
is based on a corpus of Reddit posts, collected across a diverse set of
conversational topics and annotated via paid crowdsourcing. We operationalize
key aspects of dogmatism described by existing psychology theories (such as
over-confidence), finding they have predictive power. We also find evidence for
new signals of dogmatism, such as the tendency of dogmatic posts to refrain
from signaling cognitive processes. When we use our predictive model to analyze
millions of other Reddit posts, we find evidence that suggests dogmatism is a
deeper personality trait, present for dogmatic users across many different
domains, and that users who engage on dogmatic comments tend to show increases
in dogmatic posts themselves.
</dc:description>
 <dc:description>Comment: EMNLP 2016</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00426</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Rain Rate Statistics for Emerging Regions: Implications for Wireless
  Backhaul Planning</dc:title>
 <dc:creator>Aoki, Paul M.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:description>  As demand for broadband service increases in emerging regions, high-capacity
wireless links can accelerate and cost-reduce the deployment of new networks
(both backhaul and customer site connection). Such links are increasingly
common in developed countries, but their reliability in emerging regions is
questioned where very heavy tropical rain is present. Here, we investigate the
robustness of the standard (ITU-R P.837-6) method for estimating rain rates
using an expanded test dataset. We illustrate how bias/variance issues cause
problematic predictions at higher rain rates. We confirm (by construction) that
an improved rainfall climatology can largely address these prediction issues
without compromising standard ITU fit evaluation metrics.
</dc:description>
 <dc:description>Comment: 14 pages; 3 figures</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00426</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00427</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>No Time to Observe: Adaptive Influence Maximization with Partial
  Feedback</dc:title>
 <dc:creator>Yuan, Jing</dc:creator>
 <dc:creator>Tang, Shaojie</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Although influence maximization problem has been extensively studied over the
past ten years, majority of existing work adopt one of the following models:
\emph{full-feedback model} or \emph{zero-feedback model}. In the zero-feedback
model, we have to commit the seed users all at once in advance, this strategy
is also known as non-adaptive policy. In the full-feedback model, we select one
seed at a time and wait until the diffusion completes, before selecting the
next seed. Full-feedback model has better performance but potentially huge
delay, zero-feedback model has zero delay but poorer performance since it does
not utilize the observation that may be made during the seeding process. To
fill the gap between these two models, we propose \emph{Partial-feedback
Model}, which allows us to select a seed at any intermediate stage. We develop
a novel $\alpha$-greedy policy that, for the first time, achieves a bounded
approximation ratio.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00427</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00432</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network reconstruction from infection cascades</dc:title>
 <dc:creator>Braunstein, Alfredo</dc:creator>
 <dc:creator>Ingrosso, Alessandro</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  Accessing the network through which a propagation dynamics diffuse is
essential for understanding and controlling it. In a few cases, such
information is available through direct experiments or thanks to the very
nature of propagation data. In a majority of cases however, available
information about the network is indirect and comes from partial observations
of the dynamics, rendering the network reconstruction a fundamental inverse
problem. Here we show that it is possible to reconstruct the whole structure of
an interaction network and to simultaneously infer the complete time course of
activation spreading, relying just on single epoch (i.e. snapshot) or
time-scattered observations of a small number of activity cascades. The method
that we present is built on a Belief Propagation approximation, that has shown
impressive accuracy in a wide variety of relevant cases, and is able to infer
interactions in presence of incomplete time-series data by providing a detailed
modeling of the posterior distribution of trajectories conditioned to the
observations. Furthermore, we show by experiments that the information content
of full cascades is relatively smaller than that of sparse observations or
single snapshots.
</dc:description>
 <dc:description>Comment: 14 pages, 8 figures (main text: 10 pages, 7 figures; Appendix: 4
  pages, 1 figure)</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00432</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00435</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Citation Classification for Behavioral Analysis of a Scientific Field</dc:title>
 <dc:creator>Jurgens, David</dc:creator>
 <dc:creator>Kumar, Srijan</dc:creator>
 <dc:creator>Hoover, Raine</dc:creator>
 <dc:creator>McFarland, Dan</dc:creator>
 <dc:creator>Jurafsky, Dan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Citations are an important indicator of the state of a scientific field,
reflecting how authors frame their work, and influencing uptake by future
scholars. However, our understanding of citation behavior has been limited to
small-scale manual citation analysis. We perform the largest behavioral study
of citations to date, analyzing how citations are both framed and taken up by
scholars in one entire field: natural language processing. We introduce a new
dataset of nearly 2,000 citations annotated for function and centrality, and
use it to develop a state-of-the-art classifier and label the entire ACL
Reference Corpus. We then study how citations are framed by authors and use
both papers and online traces to track how citations are followed by readers.
We demonstrate that authors are sensitive to discourse structure and
publication venue when citing, that online readers follow temporal links to
previous and future work rather than methodological links, and that how a paper
cites related work is predictive of its citation count. Finally, we use changes
in citation roles to show that the field of NLP is undergoing a significant
increase in consensus.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00435</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00439</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Qualitative Framing of Financial Incentives - A Case of Emotion
  Annotation</dc:title>
 <dc:creator>Madjiheurem, Sephora</dc:creator>
 <dc:creator>Sintsova, Valentina</dc:creator>
 <dc:creator>Pu, Pearl</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.1.2</dc:subject>
 <dc:subject>H.5.3</dc:subject>
 <dc:description>  Online labor platforms, such as the Amazon Mechanical Turk, provide an
effective framework for eliciting responses to judgment tasks. Previous work
has shown that workers respond best to financial incentives, especially to
extra bonuses. However, most of the tested incentives involve describing the
bonus conditions in formulas instead of plain English. We believe that
different incentives given in English (or in qualitative framing) will result
in differences in workers' performance, especially when task difficulties vary.
In this paper, we report the preliminary results of a crowdsourcing experiment
comparing workers' performance using only qualitative framings of financial
incentives. Our results demonstrate a significant increase in workers'
performance using a specific well-formulated qualitative framing inspired by
the Peer Truth Serum. This positive effect is observed only when the difficulty
of the task is high, while when the task is easy there is no difference of
which incentives to use.
</dc:description>
 <dc:description>Comment: Work-in-Progress Paper in the 4th AAAI Conference on Human
  Computation and Crowdsourcing (HCOMP 2016)</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00446</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Built-in Foreground/Background Prior for Weakly-Supervised Semantic
  Segmentation</dc:title>
 <dc:creator>Saleh, Fatemehsadat</dc:creator>
 <dc:creator>Akbarian, Mohammad Sadegh Ali</dc:creator>
 <dc:creator>Salzmann, Mathieu</dc:creator>
 <dc:creator>Petersson, Lars</dc:creator>
 <dc:creator>Gould, Stephen</dc:creator>
 <dc:creator>Alvarez, Jose M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Pixel-level annotations are expensive and time consuming to obtain. Hence,
weak supervision using only image tags could have a significant impact in
semantic segmentation. Recently, CNN-based methods have proposed to fine-tune
pre-trained networks using image tags. Without additional information, this
leads to poor localization accuracy. This problem, however, was alleviated by
making use of objectness priors to generate foreground/background masks.
Unfortunately these priors either require training pixel-level
annotations/bounding boxes, or still yield inaccurate object boundaries. Here,
we propose a novel method to extract markedly more accurate masks from the
pre-trained network itself, forgoing external objectness modules. This is
accomplished using the activations of the higher-level convolutional layers,
smoothed by a dense CRF. We demonstrate that our method, based on these masks
and a weakly-supervised loss, outperforms the state-of-the-art tag-based
weakly-supervised semantic segmentation techniques. Furthermore, we introduce a
new form of inexpensive weak supervision yielding an additional accuracy boost.
</dc:description>
 <dc:description>Comment: Accepted in ECCV 2016</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00446</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00448</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Do Mathematicians, Economists and Biomedical Scientists Trace Large
  Topics More Strongly Than Physicists?</dc:title>
 <dc:creator>Li, Menghui</dc:creator>
 <dc:creator>Yang, Liying</dc:creator>
 <dc:creator>ZHang, Huina</dc:creator>
 <dc:creator>Shen, Zhesi</dc:creator>
 <dc:creator>Wu, Chensheng</dc:creator>
 <dc:creator>Wu, Jinshan</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this work, we extend our previous work on largeness tracing among
physicists to other fields, namely mathematics, economics and biomedical
science. Overall, the results confirm our previous discovery, indicating that
scientists in all these fields trace large topics. Surprisingly, however, it
seems that researchers in mathematics tend to be more likely to trace large
topics than those in the other fields. We also find that on average, papers in
top journals are less largeness-driven. We compare researchers from the USA,
Germany, Japan and China and find that Chinese researchers exhibit consistently
larger exponents, indicating that in all these fields, Chinese researchers
trace large topics more strongly than others. Further correlation analyses
between the degree of largeness tracing and the numbers of authors,
affiliations and references per paper reveal positive correlations -- papers
with more authors, affiliations or references are likely to be more
largeness-driven, with several interesting and noteworthy exceptions: in
economics, papers with more references are not necessary more largeness-driven,
and the same is true for papers with more authors in biomedical science. We
believe that these empirical discoveries may be valuable to science
policy-makers.
</dc:description>
 <dc:description>Comment: 11 papges, 6 figures</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2017-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00448</dc:identifier>
 <dc:identifier>Journal of Informetrics 11(2) 598-607 (2017)</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2017.04.004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00451</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Least Ambiguous Set-Valued Classifiers with Bounded Error Levels</dc:title>
 <dc:creator>Sadinle, Mauricio</dc:creator>
 <dc:creator>Lei, Jing</dc:creator>
 <dc:creator>Wasserman, Larry</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In most classification tasks there are observations that are ambiguous and
therefore difficult to correctly label. Set-valued classification allows the
classifiers to output a set of plausible labels rather than a single label,
thereby giving a more appropriate and informative treatment to the labeling of
ambiguous instances. We introduce a framework for multiclass set-valued
classification, where the classifiers guarantee user-defined levels of coverage
or confidence (the probability that the true label is contained in the set)
while minimizing the ambiguity (the expected size of the output). We first
derive oracle classifiers assuming the true distribution to be known. We show
that the oracle classifiers are obtained from level sets of the functions that
define the conditional probability of each class. Then we develop estimators
with good asymptotic and finite sample properties. The proposed classifiers
build on and refine many existing single-label classifiers. The optimal
classifier can sometimes output the empty set. We provide two solutions to fix
this issue that are suitable for various practical needs.
</dc:description>
 <dc:description>Comment: 35 pages</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00451</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00452</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-Scale Antenna-Assisted Grant-free Non-Orthogonal Multiple Access
  via Compressed Sensing</dc:title>
 <dc:creator>Wu, Yanlun</dc:creator>
 <dc:creator>Fang, Jun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Support massive connectivity is an important requirement in 5G wireless
communication system. For massive Machine Type Communication (MTC) scenario,
since the network is expected to accommodate a massive number of MTC devices
with sparse short message, the multiple access scheme like current LTE uplink
would not be suitable. In order to reduce the signaling overhead, we consider
an grant-free multiple access system, which requires the receiver facilitate
activity detection, channel estimation, and data decoding in &quot;one shot&quot; and
without the knowledge of active user's pilots. However, most of the &quot;one shot&quot;
communication research haven't considered the massive MIMO scenario. In this
work we propose a Multiple Measurement Model (MMV) model based Massive MIMO and
exploit the covariance matrix of the measurements to confirm a high activity
detection rate.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2017-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00452</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00457</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding resource states of measurement-based quantum computing is harder
  than quantum computing</dc:title>
 <dc:creator>Morimae, Tomoyuki</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Strongly Correlated Electrons</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Measurement-based quantum computing enables universal quantum computing with
only adaptive single-qubit measurements on certain many-qubit states, such as
the graph state, the Affleck-Kennedy-Lieb-Tasaki (AKLT) state, and several
tensor-network states. Finding new resource states of measurement-based quantum
computing is a hard task, since for a given state there are exponentially many
possible measurement patterns on the state. In this paper, we consider the
problem of deciding, for a given state and a set of unitary operators, whether
there exists a way of measurement-based quantum computing on the state that can
realize all unitaries in the set, or not. We show that the decision problem is
QCMA-hard, which means that finding new resource states of measurement-based
quantum computing is harder than quantum computing itself (unless BQP is equal
to QCMA). We also derive an upperbound of the decision problem: the problem is
in a quantum version of the second level of the polynomial hierarchy.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00457</dc:identifier>
 <dc:identifier>Phys. Rev. A 96, 052308 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevA.96.052308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00461</identifier>
 <datestamp>2017-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network clustering and community detection using modulus of families of
  loops</dc:title>
 <dc:creator>Shakeri, Heman</dc:creator>
 <dc:creator>Poggi-Corradini, Pietro</dc:creator>
 <dc:creator>Albin, Nathan</dc:creator>
 <dc:creator>Scoglio, Caterina</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We study the structure of loops in networks using the notion of modulus of
loop families. We introduce a new measure of network clustering by quantifying
the richness of families of (simple) loops. Modulus tries to minimize the
expected overlap among loops by spreading the expected link-usage optimally. We
propose weighting networks using these expected link-usages to improve
classical community detection algorithms. We show that the proposed method
enhances the performance of certain algorithms, such as spectral partitioning
and modularity maximization heuristics, on standard benchmarks.
</dc:description>
 <dc:description>Comment: 8 pages, 20 figures</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2016-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00461</dc:identifier>
 <dc:identifier>Phys. Rev. E 95, 012316 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.95.012316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00462</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A case study of algorithm selection for the traveling thief problem</dc:title>
 <dc:creator>Wagner, Markus</dc:creator>
 <dc:creator>Lindauer, Marius</dc:creator>
 <dc:creator>Misir, Mustafa</dc:creator>
 <dc:creator>Nallaperuma, Samadhi</dc:creator>
 <dc:creator>Hutter, Frank</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Many real-world problems are composed of several interacting components. In
order to facilitate research on such interactions, the Traveling Thief Problem
(TTP) was created in 2013 as the combination of two well-understood
combinatorial optimization problems.
  With this article, we contribute in four ways. First, we create a
comprehensive dataset that comprises the performance data of 21 TTP algorithms
on the full original set of 9720 TTP instances. Second, we define 55
characteristics for all TPP instances that can be used to select the best
algorithm on a per-instance basis. Third, we use these algorithms and features
to construct the first algorithm portfolios for TTP, clearly outperforming the
single best algorithm. Finally, we study which algorithms contribute most to
this portfolio.
</dc:description>
 <dc:description>Comment: 23 pages, this article is underview</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00464</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Semantic Knowledge Graph: A compact, auto-generated model for
  real-time traversal and ranking of any relationship within a domain</dc:title>
 <dc:creator>Grainger, Trey</dc:creator>
 <dc:creator>AlJadda, Khalifeh</dc:creator>
 <dc:creator>Korayem, Mohammed</dc:creator>
 <dc:creator>Smith, Andries</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper describes a new kind of knowledge representation and mining system
which we are calling the Semantic Knowledge Graph. At its heart, the Semantic
Knowledge Graph leverages an inverted index, along with a complementary
uninverted index, to represent nodes (terms) and edges (the documents within
intersecting postings lists for multiple terms/nodes). This provides a layer of
indirection between each pair of nodes and their corresponding edge, enabling
edges to materialize dynamically from underlying corpus statistics. As a
result, any combination of nodes can have edges to any other nodes materialize
and be scored to reveal latent relationships between the nodes. This provides
numerous benefits: the knowledge graph can be built automatically from a
real-world corpus of data, new nodes - along with their combined edges - can be
instantly materialized from any arbitrary combination of preexisting nodes
(using set operations), and a full model of the semantic relationships between
all entities within a domain can be represented and dynamically traversed using
a highly compact representation of the graph. Such a system has widespread
applications in areas as diverse as knowledge modeling and reasoning, natural
language processing, anomaly detection, data cleansing, semantic search,
analytics, data classification, root cause analysis, and recommendations
systems. The main contribution of this paper is the introduction of a novel
system - the Semantic Knowledge Graph - which is able to dynamically discover
and score interesting relationships between any arbitrary combination of
entities (words, phrases, or extracted concepts) through dynamically
materializing nodes and edges from a compact graphical representation built
automatically from a corpus of data representative of a knowledge domain.
</dc:description>
 <dc:description>Comment: Accepted for publication in 2016 IEEE 3rd International Conference on
  Data Science and Advanced Analytics</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2016-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00475</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>868 MHz Wireless Sensor Network - A Study</dc:title>
 <dc:creator>John, Pushpam Aji</dc:creator>
 <dc:creator>Agren, Rudolf</dc:creator>
 <dc:creator>Chen, Yu-Jung</dc:creator>
 <dc:creator>Rohner, Christian</dc:creator>
 <dc:creator>Ngai, Edith</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Today 2.4 GHz based wireless sensor networks are increasing at a tremendous
pace, and are seen in widespread applications. Product innovation and support
by many vendors in 2.4 GHz makes it a preferred choice, but the networks are
prone to issues like interference, and range issues. On the other hand, the
less popular 868 MHz in the ISM band has not seen significant usage. In this
paper we explore the use of 868 MHz channel to implement a wireless sensor
network, and study the efficacy of this channel
</dc:description>
 <dc:description>Comment: 11th Swedish National Computer Networking Workshop SNCNW 2015</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00475</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00481</identifier>
 <datestamp>2016-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Game Theory : Reduction of complexity by decomposing large games
  into partial games</dc:title>
 <dc:creator>Iwase, Tatsuya</dc:creator>
 <dc:creator>Shiga, Takahiro</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  With increasing game size, a problem of computational complexity arises. This
is especially true in real world problems such as in social systems, where
there is a significant population of players involved in the game, and the
complexity problem is critical. Previous studies in algorithmic game theory
propose succinct games that enable small descriptions of payoff matrices and
reduction of complexities. However, some of the suggested compromises lose
generality with strict assumptions such as symmetries in utility functions and
cannot be applied to the full range of real world problems that may be
presented. Graphical games are relatively promising, with a good balance
between complexity and generality. However, they assume a given graph structure
of players' interactions and cannot be applied to games without such known
graphs. This study proposes a method to identify an interaction graph between
players and subsequently decompose games into smaller components by cutting out
weak interactions for the purpose of reducing complexity. At the beginning,
players' mutual dependencies on their utilities are quantified as
variance-covariance matrices among players. Then, the interaction graphs among
players are identified by solving eigenvalue problems. Players' interactions
are further decomposed into linear combinations of games. This helps to find a
consistent equilibrium, which is a Nash equilibrium specified by the
decomposition, with reduced computational complexity. Finally, experiments on
simple example games are shown to verify the proposed method.
</dc:description>
 <dc:description>Comment: Joint Agent Workshops and Symposium 2016</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2016-09-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00483</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simultaneous Information and Energy Flow for IoT Relay Systems with
  Crowd Harvesting</dc:title>
 <dc:creator>Guo, Weisi</dc:creator>
 <dc:creator>Zhou, Sheng</dc:creator>
 <dc:creator>Chen, Yunfei</dc:creator>
 <dc:creator>Wang, Siyi</dc:creator>
 <dc:creator>Chu, Xiaoli</dc:creator>
 <dc:creator>Niu, Zhisheng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  It is expected that the number of wireless devices will grow rapidly over the
next few years due to the growing proliferation of Internet-of-Things (IoT). In
order to improve the energy efficiency of information transfer between small
devices, we review state-of-the-art research in simultaneous wireless energy
and information transfer, especially for relay based IoT systems. In
particular, we analyze simultaneous information-and-energy transfer from the
source node, and the design of time-switching and power-splitting operation
modes, as well as the associated optimization algorithms. We also investigate
the potential of crowd energy harvesting from transmission nodes that belong to
multiple radio networks. The combination of source and crowd energy harvesting
can greatly reduce the use of battery power and increase the availability and
reliability for relaying. We provide insight into the fundamental limits of
crowd energy harvesting reliability based on a case study using real city data.
Furthermore, we examine the optimization of transmissions in crowd harvesting,
especially with the use of node collaboration while guaranteeing
Quality-of-Service (QoS).
</dc:description>
 <dc:description>Comment: to appear in IEEE Communications Magazine</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00489</identifier>
 <datestamp>2016-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A deep learning model for estimating story points</dc:title>
 <dc:creator>Choetkiertikul, Morakot</dc:creator>
 <dc:creator>Dam, Hoa Khanh</dc:creator>
 <dc:creator>Tran, Truyen</dc:creator>
 <dc:creator>Pham, Trang</dc:creator>
 <dc:creator>Ghose, Aditya</dc:creator>
 <dc:creator>Menzies, Tim</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Although there has been substantial research in software analytics for effort
estimation in traditional software projects, little work has been done for
estimation in agile projects, especially estimating user stories or issues.
Story points are the most common unit of measure used for estimating the effort
involved in implementing a user story or resolving an issue. In this paper, we
offer for the \emph{first} time a comprehensive dataset for story points-based
estimation that contains 23,313 issues from 16 open source projects. We also
propose a prediction model for estimating story points based on a novel
combination of two powerful deep learning architectures: long short-term memory
and recurrent highway network. Our prediction system is \emph{end-to-end}
trainable from raw input data to prediction outcomes without any manual feature
engineering. An empirical evaluation demonstrates that our approach
consistently outperforms three common effort estimation baselines and two
alternatives in both Mean Absolute Error and the Standardized Accuracy.
</dc:description>
 <dc:description>Comment: Submitted to ICSE'17</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2016-09-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00496</identifier>
 <datestamp>2016-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Label distribution based facial attractiveness computation by deep
  residual learning</dc:title>
 <dc:creator>Liu, Shu</dc:creator>
 <dc:creator>Li, Bo</dc:creator>
 <dc:creator>Fan, Yangyu</dc:creator>
 <dc:creator>Guo, Zhe</dc:creator>
 <dc:creator>Samal, Ashok</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Two challenges lie in the facial attractiveness computation research: the
lack of true attractiveness labels (scores), and the lack of an accurate face
representation. In order to address the first challenge, this paper recasts
facial attractiveness computation as a label distribution learning (LDL)
problem rather than a traditional single-label supervised learning task. In
this way, the negative influence of the label incomplete problem can be
reduced. Inspired by the recent promising work in face recognition using deep
neural networks to learn effective features, the second challenge is expected
to be solved from a deep learning point of view. A very deep residual network
is utilized to enable automatic learning of hierarchical aesthetics
representation. Integrating these two ideas, an end-to-end deep learning
framework is established. Our approach achieves the best results on a standard
benchmark SCUT-FBP dataset compared with other state-of-the-art work.
</dc:description>
 <dc:description>Comment: 3 pages, 3 figures. The first two authors are parallel first author</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2016-09-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00507</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The 3rd Reactive Synthesis Competition (SYNTCOMP 2016): Benchmarks,
  Participants &amp; Results</dc:title>
 <dc:creator>Jacobs, Swen</dc:creator>
 <dc:creator>Bloem, Roderick</dc:creator>
 <dc:creator>Brenguier, Romain</dc:creator>
 <dc:creator>Khalimov, Ayrat</dc:creator>
 <dc:creator>Klein, Felix</dc:creator>
 <dc:creator>K&#xf6;nighofer, Robert</dc:creator>
 <dc:creator>Kreber, Jens</dc:creator>
 <dc:creator>Legg, Alexander</dc:creator>
 <dc:creator>Narodytska, Nina</dc:creator>
 <dc:creator>P&#xe9;rez, Guillermo A.</dc:creator>
 <dc:creator>Raskin, Jean-Fran&#xe7;ois</dc:creator>
 <dc:creator>Ryzhyk, Leonid</dc:creator>
 <dc:creator>Sankur, Ocan</dc:creator>
 <dc:creator>Seidl, Martina</dc:creator>
 <dc:creator>Tentrup, Leander</dc:creator>
 <dc:creator>Walker, Adam</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We report on the benchmarks, participants and results of the third reactive
synthesis competition(SYNTCOMP 2016). The benchmark library of SYNTCOMP 2016
has been extended to benchmarks in the new LTL-based temporal logic synthesis
format (TLSF), and 2 new sets of benchmarks for the existing AIGER-based format
for safety specifications. The participants of SYNTCOMP 2016 can be separated
according to these two classes of specifications, and we give an overview of
the 6 tools that entered the competition in the AIGER-based track, and the 3
participants that entered the TLSF-based track. We briefly describe the
benchmark selection, evaluation scheme and the experimental setup of SYNTCOMP
2016. Finally, we present and analyze the results of our experimental
evaluation, including a comparison to participants of previous competitions and
a legacy tool.
</dc:description>
 <dc:description>Comment: In Proceedings SYNT 2016, arXiv:1611.07178</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2016-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00507</dc:identifier>
 <dc:identifier>EPTCS 229, 2016, pp. 149-177</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.229.12</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00511</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Group Profiling for Content Customization</dc:title>
 <dc:creator>Dehghani, Mostafa</dc:creator>
 <dc:creator>Azarbonyad, Hosein</dc:creator>
 <dc:creator>Kamps, Jaap</dc:creator>
 <dc:creator>Marx, Maarten</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>68P20</dc:subject>
 <dc:description>  There is an ongoing debate on personalization, adapting results to the unique
user exploiting a user's personal history, versus customization, adapting
results to a group profile sharing one or more characteristics with the user at
hand. Personal profiles are often sparse, due to cold start problems and the
fact that users typically search for new items or information, necessitating to
back-off to customization, but group profiles often suffer from accidental
features brought in by the unique individual contributing to the group. In this
paper we propose a generalized group profiling approach that teases apart the
exact contribution of the individual user level and the &quot;abstract&quot; group level
by extracting a latent model that captures all, and only, the essential
features of the whole group. Our main findings are the followings. First, we
propose an efficient way of group profiling which implicitly eliminates the
general and specific features from users' models in a group and takes out the
abstract model representing the whole group. Second, we employ the resulting
models in the task of contextual suggestion. We analyse different grouping
criteria and we find that group-based suggestions improve the customization.
Third, we see that the granularity of groups affects the quality of group
profiling. We observe that grouping approach should compromise between the
level of customization and groups' size.
</dc:description>
 <dc:description>Comment: Short paper (4 pages) published in proceedings of ACM SIGIR
  Conference on Human Information Interaction and Retrieval (CHIIR'16)</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00511</dc:identifier>
 <dc:identifier>doi:10.1145/2854946.2855003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00512</identifier>
 <datestamp>2016-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Highway Dimension: Small Distance Labels Using Tree Skeletons</dc:title>
 <dc:creator>Kosowski, Adrian</dc:creator>
 <dc:creator>Viennot, Laurent</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The goal of a hub-based distance labeling scheme for a network G = (V, E) is
to assign a small subset S(u) $\subseteq$ V to each node u $\in$ V, in such a
way that for any pair of nodes u, v, the intersection of hub sets S(u) $\cap$
S(v) contains a node on the shortest uv-path. The existence of small hub sets,
and consequently efficient shortest path processing algorithms, for road
networks is an empirical observation. A theoretical explanation for this
phenomenon was proposed by Abraham et al. (SODA 2010) through a network
parameter they called highway dimension, which captures the size of a hitting
set for a collection of shortest paths of length at least r intersecting a
given ball of radius 2r. In this work, we revisit this explanation, introducing
a more tractable (and directly comparable) parameter based solely on the
structure of shortest-path spanning trees, which we call skeleton dimension. We
show that skeleton dimension admits an intuitive definition for both directed
and undirected graphs, provides a way of computing labels more efficiently than
by using highway dimension, and leads to comparable or stronger theoretical
bounds on hub set size.
</dc:description>
 <dc:description>Comment: SODA 2017 - 28th ACM-SIAM Symposium on Discrete Algorithms, Jan 2017,
  Barcelona, Spain. 2017</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2016-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00514</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Horizontal and Vertical Separation in Hierarchical Text
  Classification</dc:title>
 <dc:creator>Dehghani, Mostafa</dc:creator>
 <dc:creator>Azarbonyad, Hosein</dc:creator>
 <dc:creator>Kamps, Jaap</dc:creator>
 <dc:creator>Marx, Maarten</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>68P20</dc:subject>
 <dc:description>  Hierarchy is a common and effective way of organizing data and representing
their relationships at different levels of abstraction. However, hierarchical
data dependencies cause difficulties in the estimation of &quot;separable&quot; models
that can distinguish between the entities in the hierarchy. Extracting
separable models of hierarchical entities requires us to take their relative
position into account and to consider the different types of dependencies in
the hierarchy. In this paper, we present an investigation of the effect of
separability in text-based entity classification and argue that in hierarchical
classification, a separation property should be established between entities
not only in the same layer, but also in different layers. Our main findings are
the followings. First, we analyse the importance of separability on the data
representation in the task of classification and based on that, we introduce a
&quot;Strong Separation Principle&quot; for optimizing expected effectiveness of
classifiers decision based on separation property. Second, we present
Hierarchical Significant Words Language Models (HSWLM) which capture all, and
only, the essential features of hierarchical entities according to their
relative position in the hierarchy resulting in horizontally and vertically
separable models. Third, we validate our claims on real-world data and
demonstrate that how HSWLM improves the accuracy of classification and how it
provides transferable models over time. Although discussions in this paper
focus on the classification problem, the models are applicable to any
information access tasks on data that has, or can be mapped to, a hierarchical
structure.
</dc:description>
 <dc:description>Comment: Full paper (10 pages) accepted for publication in proceedings of ACM
  SIGIR International Conference on the Theory of Information Retrieval
  (ICTIR'16)</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00514</dc:identifier>
 <dc:identifier>doi:10.1145/2970398.2970408</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00523</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Euclidean 1-center of a set of static and mobile points</dc:title>
 <dc:creator>Bose, Kaustav</dc:creator>
 <dc:creator>Adhikary, Ranendu</dc:creator>
 <dc:creator>Chaudhuri, Sruti Gan</dc:creator>
 <dc:creator>Sau, Buddhadeb</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  In this paper, we consider the problem of computing the algebraic parametric
equation of the Euclidean 1-center function in $\mathbb{R}^d$, $d \geq 2$, for
a system of $n$ static points and $m$ mobile points having motion defined by
rational parametric functions. We have shown that the corresponding Euclidean
1-center function is a piecewise differentiable function and have derived its
exact parametric algebraic equation. If the positions of the static points and
the rational parametric equations of the motion of the mobile points are given,
we have proposed an algorithm that computes the parametric equation of the
Euclidean 1-center function.
</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2016-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00536</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Machine Learning Analysis of Twitter Sentiment to the Sandy Hook
  Shootings</dc:title>
 <dc:creator>Wang, Nan</dc:creator>
 <dc:creator>Varghese, Blesson</dc:creator>
 <dc:creator>Donnelly, Peter D.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Gun related violence is a complex issue and accounts for a large proportion
of violent incidents. In the research reported in this paper, we set out to
investigate the pro-gun and anti-gun sentiments expressed on a social media
platform, namely Twitter, in response to the 2012 Sandy Hook Elementary School
shooting in Connecticut, USA. Machine learning techniques are applied to
classify a data corpus of over 700,000 tweets. The sentiments are captured
using a public sentiment score that considers the volume of tweets as well as
population. A web-based interactive tool is developed to visualise the
sentiments and is available at http://www.gunsontwitter.com. The key findings
from this research are: (i) There are elevated rates of both pro-gun and
anti-gun sentiments on the day of the shooting. Surprisingly, the pro-gun
sentiment remains high for a number of days following the event but the
anti-gun sentiment quickly falls to pre-event levels. (ii) There is a different
public response from each state, with the highest pro-gun sentiment not coming
from those with highest gun ownership levels but rather from California, Texas
and New York.
</dc:description>
 <dc:description>Comment: 10 pages, accepted to IEEE eScience 2016, Baltimore, USA</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00543</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Profiling Bots in Social Media</dc:title>
 <dc:creator>Oentaryo, Richard Jayadi</dc:creator>
 <dc:creator>Murdopo, Arinto</dc:creator>
 <dc:creator>Prasetyo, Philips Kokoh</dc:creator>
 <dc:creator>Lim, Ee-Peng</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The popularity of social media platforms such as Twitter has led to the
proliferation of automated bots, creating both opportunities and challenges in
information dissemination, user engagements, and quality of services. Past
works on profiling bots had been focused largely on malicious bots, with the
assumption that these bots should be removed. In this work, however, we find
many bots that are benign, and propose a new, broader categorization of bots
based on their behaviors. This includes broadcast, consumption, and spam bots.
To facilitate comprehensive analyses of bots and how they compare to human
accounts, we develop a systematic profiling framework that includes a rich set
of features and classifier bank. We conduct extensive experiments to evaluate
the performances of different classifiers under varying time windows, identify
the key features of bots, and infer about bots in a larger Twitter population.
Our analysis encompasses more than 159K bot and human (non-bot) accounts in
Twitter. The results provide interesting insights on the behavioral traits of
both benign and malicious bots.
</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00543</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00544</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On unrooted and root-uncertain variants of several well-known
  phylogenetic network problems</dc:title>
 <dc:creator>van Iersel, Leo</dc:creator>
 <dc:creator>Kelk, Steven</dc:creator>
 <dc:creator>Stamoulis, Georgios</dc:creator>
 <dc:creator>Stougie, Leen</dc:creator>
 <dc:creator>Boes, Olivier</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The hybridization number problem requires us to embed a set of binary rooted
phylogenetic trees into a binary rooted phylogenetic network such that the
number of nodes with indegree two is minimized. However, from a biological
point of view accurately inferring the root location in a phylogenetic tree is
notoriously difficult and poor root placement can artificially inflate the
hybridization number. To this end we study a number of relaxed variants of this
problem. We start by showing that the fundamental problem of determining
whether an \emph{unrooted} phylogenetic network displays (i.e. embeds) an
\emph{unrooted} phylogenetic tree, is NP-hard. On the positive side we show
that this problem is FPT in reticulation number. In the rooted case the
corresponding FPT result is trivial, but here we require more subtle
argumentation. Next we show that the hybridization number problem for unrooted
networks (when given two unrooted trees) is equivalent to the problem of
computing the Tree Bisection and Reconnect (TBR) distance of the two unrooted
trees. In the third part of the paper we consider the &quot;root uncertain&quot; variant
of hybridization number. Here we are free to choose the root location in each
of a set of unrooted input trees such that the hybridization number of the
resulting rooted trees is minimized. On the negative side we show that this
problem is APX-hard. On the positive side, we show that the problem is FPT in
the hybridization number, via kernelization, for any number of input trees.
</dc:description>
 <dc:description>Comment: 28 pages, 8 Figures</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00544</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00549</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universal decoding using a noisy codebook</dc:title>
 <dc:creator>Merhav, Neri</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the topic of universal decoding with a decoder that does not have
direct access to the codebook, but only to noisy versions of the various
randomly generated codewords, a problem motivated by biometrical identification
systems. Both the source that generates the original (clean) codewords, and the
channel that corrupts them in generating the noisy codewords, as well as the
main channel for communicating the messages, are all modeled by non-unifilar,
finite-state systems (hidden Markov models). As in previous works on universal
decoding, here too, the average error probability of our proposed universal
decoder is shown to be as small as that of the optimal maximum likelihood (ML)
decoder, up to a multiplicative factorthat is a sub-exponential function of the
block length. It therefore has the same error exponent, whenever the ML decoder
has a positive error exponent. The universal decoding metric is based on
Lempel-Ziv (LZ) incremental parsing of each noisy codeword jointly with the
given channel output vector, but this metric is somewhat different from the one
proposed in earlier works on universal decoding for finite-state channels, by
Ziv (1985) and by Lapidoth and Ziv (1998). The reason for the difference is
that here, unlike in those earlier works, the probability distribution that
governs the (noisy) codewords is, in general, not uniform across its support.
This non-uniformity of the codeword distribution also makes our derivation more
challenging. Another reason for the more challenging analysis is the fact that
the effective induced channel between the noisy codeword of the transmitted
message and the main channel output is not a finite-state channel in general.
</dc:description>
 <dc:description>Comment: 20 pages; submitted for publication</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00552</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incorporating Clicks, Attention and Satisfaction into a Search Engine
  Result Page Evaluation Model</dc:title>
 <dc:creator>Chuklin, Aleksandr</dc:creator>
 <dc:creator>de Rijke, Maarten</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  Modern search engine result pages often provide immediate value to users and
organize information in such a way that it is easy to navigate. The core
ranking function contributes to this and so do result snippets, smart
organization of result blocks and extensive use of one-box answers or side
panels. While they are useful to the user and help search engines to stand out,
such features present two big challenges for evaluation. First, the presence of
such elements on a search engine result page (SERP) may lead to the absence of
clicks, which is, however, not related to dissatisfaction, so-called &quot;good
abandonments.&quot; Second, the non-linear layout and visual difference of SERP
items may lead to non-trivial patterns of user attention, which is not captured
by existing evaluation metrics.
  In this paper we propose a model of user behavior on a SERP that jointly
captures click behavior, user attention and satisfaction, the CAS model, and
demonstrate that it gives more accurate predictions of user actions and
self-reported satisfaction than existing models based on clicks alone. We use
the CAS model to build a novel evaluation metric that can be applied to
non-linear SERP layouts and that can account for the utility that users obtain
directly on a SERP. We demonstrate that this metric shows better agreement with
user-reported satisfaction than conventional evaluation metrics.
</dc:description>
 <dc:description>Comment: CIKM2016, Proceedings of the 25th ACM International Conference on
  Information and Knowledge Management. 2016</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00552</dc:identifier>
 <dc:identifier>doi:10.1145/2983323.2983829</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00559</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Correlation with Human Judgments by Integrating Semantic
  Similarity with Second--Order Vectors</dc:title>
 <dc:creator>McInnes, Bridget T.</dc:creator>
 <dc:creator>Pedersen, Ted</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Vector space methods that measure semantic similarity and relatedness often
rely on distributional information such as co--occurrence frequencies or
statistical measures of association to weight the importance of particular
co--occurrences. In this paper, we extend these methods by incorporating a
measure of semantic similarity based on a human curated taxonomy into a
second--order vector representation. This results in a measure of semantic
relatedness that combines both the contextual information available in a
corpus--based vector space representation with the semantic knowledge found in
a biomedical ontology. Our results show that incorporating semantic similarity
into a second order co--occurrence matrices improves correlation with human
judgments for both similarity and relatedness, and that our method compares
favorably to various different word embedding methods that have recently been
evaluated on the same reference standards we have used.
</dc:description>
 <dc:description>Comment: 10 pages, Appears in the Proceedings of the 16th Workshop on
  Biomedical Natural Language Processing (BioNLP-2017), August 2017, Vancouver,
  BC</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2017-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00565</identifier>
 <datestamp>2016-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Skipping Word: A Character-Sequential Representation based Framework for
  Question Answering</dc:title>
 <dc:creator>Meng, Lingxun</dc:creator>
 <dc:creator>Li, Yan</dc:creator>
 <dc:creator>Liu, Mengyi</dc:creator>
 <dc:creator>Shu, Peng</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recent works using artificial neural networks based on word distributed
representation greatly boost the performance of various natural language
learning tasks, especially question answering. Though, they also carry along
with some attendant problems, such as corpus selection for embedding learning,
dictionary transformation for different learning tasks, etc. In this paper, we
propose to straightforwardly model sentences by means of character sequences,
and then utilize convolutional neural networks to integrate character embedding
learning together with point-wise answer selection training. Compared with deep
models pre-trained on word embedding (WE) strategy, our character-sequential
representation (CSR) based method shows a much simpler procedure and more
stable performance across different benchmarks. Extensive experiments on two
benchmark answer selection datasets exhibit the competitive performance
compared with the state-of-the-art methods.
</dc:description>
 <dc:description>Comment: to be accepted as CIKM2016 short paper</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00565</dc:identifier>
 <dc:identifier>doi:10.1145/2983323.2983861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00585</identifier>
 <datestamp>2016-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Doubly stochastic large scale kernel learning with the empirical kernel
  map</dc:title>
 <dc:creator>Steenbergen, Nikolaas</dc:creator>
 <dc:creator>Schelter, Sebastian</dc:creator>
 <dc:creator>Bie&#xdf;mann, Felix</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  With the rise of big data sets, the popularity of kernel methods declined and
neural networks took over again. The main problem with kernel methods is that
the kernel matrix grows quadratically with the number of data points. Most
attempts to scale up kernel methods solve this problem by discarding data
points or basis functions of some approximation of the kernel map. Here we
present a simple yet effective alternative for scaling up kernel methods that
takes into account the entire data set via doubly stochastic optimization of
the emprical kernel map. The algorithm is straightforward to implement, in
particular in parallel execution settings; it leverages the full power and
versatility of classical kernel functions without the need to explicitly
formulate a kernel map approximation. We provide empirical evidence that the
algorithm works on large data sets.
</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2016-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00586</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Chemical Propagation Pattern for Molecular Communications</dc:title>
 <dc:creator>Yilmaz, H. Birkan</dc:creator>
 <dc:creator>Suk, Gee-Yong</dc:creator>
 <dc:creator>Chae, Chan-Byoung</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In a diffusion-based molecular communication system, molecules are employed
to convey information. When propagation and reception processes are considered
in a framework of first passage processes, we need to focus on absorbing
receivers. For this kind of molecular communication system, the characteristics
of the channel is also affected by the shape of the transmitter. In the
literature, most studies focus on systems with a point transmitter due to
circular symmetry. In this letter, we address propagation and reception pattern
for chemical signals emitted from a spherical transmitter. We also investigate
the directivity gain achieved by the reflecting spherical transmitter. We
quantify the power gain by measuring the received power at different angles on
a circular region. Moreover, we define three metrics, i.e., the half-power
pattern-width, the directivity gain, and the peak time of the signal, for
analyzing the received signal pattern.
</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00591</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mirror graphs: graph theoretical characterization of reflection
  arrangements and finite Coxeter groups</dc:title>
 <dc:creator>Marc, Tilen</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Mirror graphs were introduced by Bre\v{s}ar et al. in 2004 as an intriguing
class of graphs: vertex-transitive, isometrically embeddable into hypercubes,
having a strong connection with regular maps and polytope structure. In this
article we settle the structure of mirror graphs by characterizing them as
precisely the Cayley graphs of the finite Coxeter groups or equivalently the
tope graphs of reflection arrangements - well understood and classified
structures. We provide a polynomial algorithm for their recognition.
</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00591</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00594</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Gaussian MACs with Variable-Length Feedback and Non-Vanishing
  Error~Probabilities</dc:title>
 <dc:creator>Truong, Lan V.</dc:creator>
 <dc:creator>Tan, Vincent Y. F.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We characterize the fundamental limits of transmission of information over a
Gaussian multiple access channel (MAC) with the use of variable-length feedback
codes and under a non-vanishing error probability formalism. We develop new
achievability and converse techniques to handle the continuous nature of the
channel and the presence of expected power constraints. We establish the
$\varepsilon$-capacity regions and bounds on the second-order asymptotics of
the Gaussian MAC with variable-length feedback with termination (VLFT) codes
and stop-feedback codes. We show that the former outperforms the latter
significantly. Due to the multi-terminal nature of the channel model, we
leverage tools from renewal theory developed by Lai and Siegmund to bound the
asymptotic behavior of the maximum of a finite number of stopping times.
</dc:description>
 <dc:description>Comment: Accepted to IEEE Transactions on Information Theory</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00594</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00610</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling, refining and analyzing Incomplete B\&quot;uchi Automata</dc:title>
 <dc:creator>Menghi, Claudio</dc:creator>
 <dc:creator>Spoletini, Paola</dc:creator>
 <dc:creator>Ghezzi, Carlo</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Software development is an iterative process which includes a set of
development steps that transform the initial high level specification of the
system into its final, fully specified, implementation. This report discusses
the theoretical foundations that allow Incomplete B\&quot;uchi Automata (IBAs) to be
used in the iterative development of a sequential system.
</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00610</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00616</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SHA-1 and the Strict Avalanche Criterion</dc:title>
 <dc:creator>Motara, Yusuf</dc:creator>
 <dc:creator>Irwin, Barry</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The Strict Avalanche Criterion (SAC) is a measure of both confusion and
diffusion, which are key properties of a cryptographic hash function. This work
provides a working definition of the SAC, describes an experimental methodology
that can be used to statistically evaluate whether a cryptographic hash meets
the SAC, and uses this to investigate the degree to which compression function
of the SHA-1 hash meets the SAC. The results ($P &lt; 0.01$) are heartening: SHA-1
closely tracks the SAC after the first 24 rounds, and demonstrates excellent
properties of confusion and diffusion throughout.
</dc:description>
 <dc:description>Comment: 6 pages in Information Security South Africa (ISSA) 2016</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00616</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00621</identifier>
 <datestamp>2016-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Device-to-device Cooperation in Massive MIMO Systems with Cascaded
  Precoding</dc:title>
 <dc:creator>Liu, Yinsheng</dc:creator>
 <dc:creator>Li, Geoffrey Ye</dc:creator>
 <dc:creator>Han, Wei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates user cooperation in massive multiple-input
multiple-output (MIMO) systems with cascaded precoding. The high-dimensional
physical channel in massive MIMO systems can be converted into a
low-dimensional effective channel through the inner precoder to reduce the
overhead of channel estimation and feedback. The inner precoder depends on the
spatial covariance matrix of the channels, and thus the same precoder can be
used for different users as long as they have the same spatial covariance
matrix. Spatial covariance matrix is determined by the surrounding environment
of user terminals. Therefore, the users that are close to each other will share
the same spatial covariance matrix. In this situation, it is possible to
achieve user cooperation by sharing receiver information through some dedicated
link, such as device-to-device communications. To reduce the amount of
information that needs to be shared, we propose a decoding codebook based
scheme, which can achieve user cooperation without the need of channel state
information. Moreover, we also investigate the amount of bandwidth required to
achieve efficient user cooperation. Simulation results show that user
cooperation can improve the capacity compared to the non-cooperation scheme.
</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2016-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00621</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00626</identifier>
 <datestamp>2016-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SynsetRank: Degree-adjusted Random Walk for Relation Identification</dc:title>
 <dc:creator>Nakajima, Shinichi</dc:creator>
 <dc:creator>Krause, Sebastian</dc:creator>
 <dc:creator>Weissenborn, Dirk</dc:creator>
 <dc:creator>Schmeier, Sven</dc:creator>
 <dc:creator>Goernitz, Nico</dc:creator>
 <dc:creator>Xu, Feiyu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  In relation extraction, a key process is to obtain good detectors that find
relevant sentences describing the target relation. To minimize the necessity of
labeled data for refining detectors, previous work successfully made use of
BabelNet, a semantic graph structure expressing relationships between synsets,
as side information or prior knowledge. The goal of this paper is to enhance
the use of graph structure in the framework of random walk with a few
adjustable parameters. Actually, a straightforward application of random walk
degrades the performance even after parameter optimization. With the insight
from this unsuccessful trial, we propose SynsetRank, which adjusts the initial
probability so that high degree nodes influence the neighbors as strong as low
degree nodes. In our experiment on 13 relations in the FB15K-237 dataset,
SynsetRank significantly outperforms baselines and the plain random walk
approach.
</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2016-09-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00626</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00627</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smart Computing and Sensing Technologies for Animal Welfare: A
  Systematic Review</dc:title>
 <dc:creator>Jukan, Admela</dc:creator>
 <dc:creator>Masip-Bruin, Xavi</dc:creator>
 <dc:creator>Amla, Nina</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Animals play a profoundly important and intricate role in our lives today.
Dogs have been human companions for thousands of years, but they now work
closely with us to assist the disabled, and in combat and search and rescue
situations. Farm animals are a critical part of the global food supply chain,
and there is increasing consumer interest in organically fed and humanely
raised livestock, and how it impacts our health and environmental footprint.
Wild animals are threatened with extinction by human induced factors, and
shrinking and compromised habitat. This review sets the goal to systematically
survey the existing literature in smart computing and sensing technologies for
domestic, farm and wild animal welfare. We use the notion of \emph{animal
welfare} in broad terms, to review the technologies for assessing whether
animals are healthy, free of pain and suffering, and also positively stimulated
in their environment. Also the notion of \emph{smart computing and sensing} is
used in broad terms, to refer to computing and sensing systems that are not
isolated but interconnected with communication networks, and capable of remote
data collection, processing, exchange and analysis. We review smart
technologies for domestic animals, indoor and outdoor animal farming, as well
as animals in the wild and zoos. The findings of this review are expected to
motivate future research and contribute to data, information and communication
management as well as policy for animal welfare.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00629</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SEBOOST - Boosting Stochastic Learning Using Subspace Optimization
  Techniques</dc:title>
 <dc:creator>Richardson, Elad</dc:creator>
 <dc:creator>Herskovitz, Rom</dc:creator>
 <dc:creator>Ginsburg, Boris</dc:creator>
 <dc:creator>Zibulevsky, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present SEBOOST, a technique for boosting the performance of existing
stochastic optimization methods. SEBOOST applies a secondary optimization
process in the subspace spanned by the last steps and descent directions. The
method was inspired by the SESOP optimization method for large-scale problems,
and has been adapted for the stochastic learning framework. It can be applied
on top of any existing optimization method with no need to tweak the internal
algorithm. We show that the method is able to boost the performance of
different algorithms, and make them more robust to changes in their
hyper-parameters. As the boosting steps of SEBOOST are applied between large
sets of descent steps, the additional subspace optimization hardly increases
the overall computational burden. We introduce two hyper-parameters that
control the balance between the baseline method and the secondary optimization
process. The method was evaluated on several deep learning tasks, demonstrating
promising results.
</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00638</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Miuz: measuring the impact of disconnecting a node</dc:title>
 <dc:creator>Bachmann, Ivana</dc:creator>
 <dc:creator>Reyes, Patricio</dc:creator>
 <dc:creator>Silva, Alonso</dc:creator>
 <dc:creator>Bustos-Jim&#xe9;nez, Javier</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In this article we present Miuz, a robustness index for complex networks.
Miuz measures the impact of disconnecting a node from the network while
comparing the sizes of the remaining connected components. Strictly speaking,
Miuz for a node is defined as the inverse of the size of the largest connected
component divided by the sum of the sizes of the remaining ones. We tested our
index in attack strategies where the nodes are disconnected in decreasing order
of a specified metric. We considered Miuz and other well-known centrality
measures such as betweenness, degree , and harmonic centrality. All of these
metrics were compared regarding the behavior of the robust-ness (R-index)
during the attacks. In an attempt to simulate the internet backbone, the
attacks were performed in complex networks with power-law degree distributions
(scale-free networks). Preliminary results show that attacks based on
disconnecting a few number of nodes Miuz are more dangerous (decreasing the
robustness) than the same attacks based on other centrality measures. We
believe that Miuz, as well as other measures based on the size of the largest
connected component, provides a good addition to other robustness metrics for
complex networks.
</dc:description>
 <dc:description>Comment: in 34th International Conference of the Chilean Computer Science
  Society (SCCC), Nov 2015, Santiago, Chile. 2015. arXiv admin note:
  substantial text overlap with arXiv:1601.02465</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00638</dc:identifier>
 <dc:identifier>doi:10.1109/SCCC.2015.7416586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00651</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Safety Barrier Certificates for Heterogeneous Multi-Robot Systems</dc:title>
 <dc:creator>Wang, Li</dc:creator>
 <dc:creator>Ames, Aaron</dc:creator>
 <dc:creator>Egerstedt, Magnus</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper presents a formal framework for collision avoidance in multi-robot
systems, wherein an existing controller is modified in a minimally invasive
fashion to ensure safety. We build this framework through the use of control
barrier functions (CBFs) which guarantee forward invariance of a safe set;
these yield safety barrier certificates in the context of heterogeneous robot
dynamics subject to acceleration bounds. Moreover, safety barrier certificates
are extended to a distributed control framework, wherein neighboring agent
dynamics are unknown, through local parameter identification. The end result is
an optimization-based controller that formally guarantees collision free
behavior in heterogeneous multi-agent systems by minimally modifying the
desired controller via safety barrier constraints. This formal result is
verified in simulation on a multi-robot system consisting of both cumbersome
and agile robots, is demonstrated experimentally on a system with a Magellan
Pro robot and three Khepera III robots.
</dc:description>
 <dc:description>Comment: 8 pages version of 2016ACC conference paper, experimental results
  added</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00651</dc:identifier>
 <dc:identifier>American Control Conference (ACC), pages 5213-5218, July 2016</dc:identifier>
 <dc:identifier>doi:10.1109/ACC.2016.7526486</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00653</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Benchmark for the Performance of Time-varying Closed-loop Flow Control
  with Application to TCP</dc:title>
 <dc:creator>L&#xfc;bben, Ralf</dc:creator>
 <dc:creator>Fidler, Markus</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Closed-loop flow control protocols, such as the prominent implementation TCP,
are prevalent in the Internet, today. TCP has continuously been improved for
greedy traffic sources to achieve high throughput over networks with large
bandwidth delay products. Recently, the increasing use for streaming and
interactive applications, such as voice and video, has shifted the focus
towards its delay performance. Given the need for real-time communication of
non-greedy sources via TCP, we present an estimation method for performance
evaluation of closed-loop flow control protocols. We characterize an end-to-end
connection by a transfer function that provides statistical service guarantees
for arbitrary traffic. The estimation is based on end-to-end measurements at
the application level that include all effects induced by the network and by
the protocol stacks of the end systems. From our measurements, we identify
different causes for delays. We show that significant delays are due to
queueing in protocol stacks. Notably, this occurs even if the utilization is
moderate. Using our estimation method, we compare the impact of fundamental
mechanisms of TCP on delays at the application level: In detail, we analyze
parameters relevant for network dimensioning, including buffer provisioning and
active queue management, and parameters for server configuration, such as the
congestion control algorithm. By applying our method as a benchmark, we find
that a good selection can largely improve the delay performance of TCP.
</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00653</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00661</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Localization by Fusing a Group of Fingerprints via Multiple Antennas in
  Indoor Environment</dc:title>
 <dc:creator>Guo, Xiansheng</dc:creator>
 <dc:creator>Ansari, Nirwan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Most existing fingerprints-based indoor localization approaches are based on
some single fingerprints, such as received signal strength (RSS), channel
impulse response (CIR), and signal subspace. However, the localization accuracy
obtained by the single fingerprint approach is rather susceptible to the
changing environment, multi-path, and non-line-of-sight (NLOS) propagation.
Furthermore, building the fingerprints is a very time consuming process. In
this paper, we propose a novel localization framework by Fusing A Group Of
fingerprinTs (FAGOT) via multiple antennas for the indoor environment. We first
build a GrOup Of Fingerprints (GOOF), which includes five different
fingerprints, namely, RSS, covariance matrix, signal subspace, fractional low
order moment, and fourth-order cumulant, which are obtained by different
transformations of the received signals from multiple antennas in the offline
stage. Then, we design a parallel GOOF multiple classifiers based on AdaBoost
(GOOF-AdaBoost) to train each of these fingerprints in parallel as five strong
multiple classifiers. In the online stage, we input the corresponding
transformations of the real measurements into these strong classifiers to
obtain independent decisions. Finally, we propose an efficient combination
fusion algorithm, namely, MUltiple Classifiers mUltiple Samples (MUCUS) fusion
algorithm to improve the accuracy of localization by combining the predictions
of multiple classifiers with different samples. As compared with the single
fingerprint approaches, the prediction probability of our proposed approach is
improved significantly. The process for building fingerprints can also be
reduced drastically. We demonstrate the feasibility and performance of the
proposed algorithm through extensive simulations as well as via real
experimental data using a Universal Software Radio Peripheral (USRP) platform
with four antennas.
</dc:description>
 <dc:description>Comment: 11 pages,9 figures, submitted to IEEE Transactions on Vehicular
  Technology</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00664</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transparent Clouds: An Enhancement to Abstraction</dc:title>
 <dc:creator>Moghaddam, Reza Farrahi</dc:creator>
 <dc:creator>Lemieux, Yves</dc:creator>
 <dc:creator>Cheriet, Mohamed</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  With the introduction of various hardware/software technologies such as Cloud
Technologies or Virtualization technologies, there has been a great potential
to reuse ICT artifacts thanks to Abstraction and also Exchangeability features
achieved via these technologies. These technologies also provide various
advantages with respect to sustainability including resource consumption
reduction (in the use phase only or in the whole life cycle). However, there is
an additional but untapped potential associated with the anonymization of
resources introduced by both abstraction and exchangeability features. By
realizing on this potential, we can improve cloud solutions and reduce their
by-product opacity, which usually prevents leveraging on the specialized but
tweakable (i.e., nonessential modifications without changing the main function)
features of components that are captured in the component models. This is
especially a challenge in the case heterogeneous/disaggregated infrastructure
where developing models to cover everything is practically impossible. In this
work, by leveraging on the concept of pathways, we develop a few mechanisms
that enable transparency and therefore tweakability of features even in the
presence of abstraction and heterogeneity. In particular, the layered-stack
approach to system decomposition is considered because of its role in both
software defined networking (SDN) and Network Function Virtualization (NFV)
system decompositions. For a concrete example, the case of dynamic frequency
scaling of processors is considered and it is shown that the associated
consumption could be considerably reduced without requiring additional changes
to the middle components.
</dc:description>
 <dc:description>Comment: 10 pages, 11 figures</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00671</identifier>
 <datestamp>2017-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structural Convergence Results for Approximation of Dominant Subspaces
  from Block Krylov Spaces</dc:title>
 <dc:creator>Drineas, Petros</dc:creator>
 <dc:creator>Ipsen, Ilse</dc:creator>
 <dc:creator>Kontopoulou, Eugenia-Maria</dc:creator>
 <dc:creator>Magdon-Ismail, Malik</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  This paper is concerned with approximating the dominant left singular vector
space of a real matrix $A$ of arbitrary dimension, from block Krylov spaces
generated by the matrix $AA^T$ and the block vector $AX$. Two classes of
results are presented. First are bounds on the distance, in the two and
Frobenius norms, between the Krylov space and the target space. The distance is
expressed in terms of principal angles. Second are quality of approximation
bounds, relative to the best approximation in the Frobenius norm. For starting
guesses $X$ of full column-rank, the bounds depend on the tangent of the
principal angles between $X$ and the dominant right singular vector space of
$A$. The results presented here form the structural foundation for the analysis
of randomized Krylov space methods. The innovative feature is a combination of
traditional Lanczos convergence analysis with optimal approximations via least
squares problems.
</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2017-05-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00671</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00677</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection and Estimation of Multiple DoA Targets with Single Snapshot
  Measurements</dc:title>
 <dc:creator>Jagannath, Rakshith</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  In this paper, we explore the problems of detecting the number of
narrow-band, far-field targets and estimating their corresponding directions of
arrivals (DoAs) from single snapshot measurements. We use the principles of
sparse signal recovery (SSR) for detection and estimation of multiple targets.
In the SSR framework, the DoA estimation problem is grid based and can be posed
as the lasso optimization problem. The corresponding DoA detection problem
reduces to estimating the optimal regularization parameter ($\tau$) of the
lasso problem for achieving the required probability of correct detection
($P_c$). We propose finite sample and asymptotic test statistics for detecting
the number of sources with the required $P_c$ at moderate to high signal to
noise ratios. Once the number of sources are detected, or equivalently the
optimal $\hat{\tau}$ is estimated, the corresponding DoAs can be estimated by
solving the lasso with regularization parameter set to $\hat{\tau}$.
</dc:description>
 <dc:description>Comment: This version is contained in 1705.07561 and hence in redundant</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2017-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00680</identifier>
 <datestamp>2017-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accurate De Novo Prediction of Protein Contact Map by Ultra-Deep
  Learning Model</dc:title>
 <dc:creator>Wang, Sheng</dc:creator>
 <dc:creator>Sun, Siqi</dc:creator>
 <dc:creator>Li, Zhen</dc:creator>
 <dc:creator>Zhang, Renyu</dc:creator>
 <dc:creator>Xu, Jinbo</dc:creator>
 <dc:subject>Quantitative Biology - Biomolecules</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recently exciting progress has been made on protein contact prediction, but
the predicted contacts for proteins without many sequence homologs is still of
low quality and not very useful for de novo structure prediction. This paper
presents a new deep learning method that predicts contacts by integrating both
evolutionary coupling (EC) and sequence conservation information through an
ultra-deep neural network formed by two deep residual networks. This deep
neural network allows us to model very complex sequence-contact relationship as
well as long-range inter-contact correlation. Our method greatly outperforms
existing contact prediction methods and leads to much more accurate
contact-assisted protein folding. Tested on three datasets of 579 proteins, the
average top L long-range prediction accuracy obtained our method, the
representative EC method CCMpred and the CASP11 winner MetaPSICOV is 0.47, 0.21
and 0.30, respectively; the average top L/10 long-range accuracy of our method,
CCMpred and MetaPSICOV is 0.77, 0.47 and 0.59, respectively. Ab initio folding
using our predicted contacts as restraints can yield correct folds (i.e.,
TMscore&gt;0.6) for 203 test proteins, while that using MetaPSICOV- and
CCMpred-predicted contacts can do so for only 79 and 62 proteins, respectively.
Further, our contact-assisted models have much better quality than
template-based models. Using our predicted contacts as restraints, we can (ab
initio) fold 208 of the 398 membrane proteins with TMscore&gt;0.5. By contrast,
when the training proteins of our method are used as templates, homology
modeling can only do so for 10 of them. One interesting finding is that even if
we do not train our prediction models with any membrane proteins, our method
works very well on membrane protein prediction. Finally, in recent blind CAMEO
benchmark our method successfully folded 5 test proteins with a novel fold.
</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2016-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00680</dc:identifier>
 <dc:identifier>PLoS Comput Biol 13(1): e1005324, 2017</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pcbi.1005324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00682</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unifying Markov Chain Approach for Disease and Rumor Spreading in
  Complex Networks</dc:title>
 <dc:creator>de Arruda, Guilherme Ferraz</dc:creator>
 <dc:creator>Rodrigues, Francisco A.</dc:creator>
 <dc:creator>Rodriiguez, Pablo Martin</dc:creator>
 <dc:creator>Cozzo, Emanuele</dc:creator>
 <dc:creator>Moreno, Yamir</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Spreading processes are ubiquitous in natural and artificial systems. They
can be studied via a plethora of models, depending on the specific details of
the phenomena under study. Disease contagion and rumor spreading are among the
most important of these processes due to their practical relevance. However,
despite the similarities between them, current models address both spreading
dynamics separately. In this paper, we propose a general information spreading
model that is based on discrete time Markov chains. The model includes all the
transitions that are plausible for both a disease contagion process and rumor
propagation. We show that our model not only covers the traditional spreading
schemes, but that it also contains some features relevant in social dynamics,
such as apathy, forgetting, and lost/recovering of interest. The model is
evaluated analytically to obtain the spreading thresholds and the early time
dynamical behavior for the contact and reactive processes in several scenarios.
Comparison with Monte Carlo simulations shows that the Markov chain formalism
is highly accurate while it excels in computational efficiency. We round off
our work by showing how the proposed framework can be applied to the study of
spreading processes occurring on social networks.
</dc:description>
 <dc:description>Comment: 19 pages and 13 figures. APS format. Submitted for publication</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2016-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00683</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pairwise, Magnitude, or Stars: What's the Best Way for Crowds to Rate?</dc:title>
 <dc:creator>Checco, Alessandro</dc:creator>
 <dc:creator>Demartini, Gianluca</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  We compare three popular techniques of rating content: the ubiquitous five
star rating, the less used pairwise comparison, and the recently introduced (in
crowdsourcing) magnitude estimation approach. Each system has specific
advantages and disadvantages, in terms of required user effort, achievable user
preference prediction accuracy and number of ratings required.
  We design an experiment where the three techniques are compared in an
unbiased way. We collected 39'000 ratings on a popular crowdsourcing platform,
allowing us to release a dataset that will be useful for many related studies
on user rating techniques.
</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00686</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Single photon in hierarchical architecture for physical reinforcement
  learning: Photon intelligence</dc:title>
 <dc:creator>Naruse, Makoto</dc:creator>
 <dc:creator>Berthel, Martin</dc:creator>
 <dc:creator>Drezet, Aur&#xe9;lien</dc:creator>
 <dc:creator>Huant, Serge</dc:creator>
 <dc:creator>Hori, Hirokazu</dc:creator>
 <dc:creator>Kim, Song-Ju</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  Understanding and using natural processes for intelligent functionalities,
referred to as natural intelligence, has recently attracted interest from a
variety of fields, including post-silicon computing for artificial intelligence
and decision making in the behavioural sciences. In a past study, we
successfully used the wave-particle duality of single photons to solve the
two-armed bandit problem, which constitutes the foundation of reinforcement
learning and decision making. In this study, we propose and confirm a
hierarchical architecture for single-photon-based reinforcement learning and
decision making that verifies the scalability of the principle. Specifically,
the four-armed bandit problem is solved given zero prior knowledge in a
two-layer hierarchical architecture, where polarization is autonomously adapted
in order to effect adequate decision making using single-photon measurements.
In the hierarchical structure, the notion of layer-dependent decisions emerges.
The optimal solutions in the coarse layer and in the fine layer, however,
conflict with each other in some contradictive problems. We show that while
what we call a tournament strategy resolves such contradictions, the
probabilistic nature of single photons allows for the direct location of the
optimal solution even for contradictive problems, hence manifesting the
exploration ability of single photons. This study provides insights into photon
intelligence in hierarchical architectures for future artificial intelligence
as well as the potential of natural processes for intelligent functionalities.
</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00689</identifier>
 <datestamp>2016-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensemble Learned Vaccination Uptake Prediction using Web Search Queries</dc:title>
 <dc:creator>Hansen, Niels Dalum</dc:creator>
 <dc:creator>Lioma, Christina</dc:creator>
 <dc:creator>M&#xf8;lbak, K&#xe5;re</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  We present a method that uses ensemble learning to combine clinical and
web-mined time-series data in order to predict future vaccination uptake. The
clinical data is official vaccination registries, and the web data is query
frequencies collected from Google Trends. Experiments with official vaccine
records show that our method predicts vaccination uptake effectively (4.7 Root
Mean Squared Error). Whereas performance is best when combining clinical and
web data, using solely web data yields comparative performance. To our
knowledge, this is the first study to predict vaccination uptake using web data
(with and without clinical data).
</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00689</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00718</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Neural Networks for Text Categorization: Shallow
  Word-level vs. Deep Character-level</dc:title>
 <dc:creator>Johnson, Rie</dc:creator>
 <dc:creator>Zhang, Tong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper reports the performances of shallow word-level convolutional
neural networks (CNN), our earlier work (2015), on the eight datasets with
relatively large training data that were used for testing the very deep
character-level CNN in Conneau et al. (2016). Our findings are as follows. The
shallow word-level CNNs achieve better error rates than the error rates
reported in Conneau et al., though the results should be interpreted with some
consideration due to the unique pre-processing of Conneau et al. The shallow
word-level CNN uses more parameters and therefore requires more storage than
the deep character-level CNN; however, the shallow word-level CNN computes much
faster.
</dc:description>
 <dc:date>2016-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00719</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Peacock Bundles: Bundle Coloring for Graphs with Globality-Locality
  Trade-off</dc:title>
 <dc:creator>Peltonen, Jaakko</dc:creator>
 <dc:creator>Lin, Ziyuan</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Bundling of graph edges (node-to-node connections) is a common technique to
enhance visibility of overall trends in the edge structure of a large graph
layout, and a large variety of bundling algorithms have been proposed. However,
with strong bundling, it becomes hard to identify origins and destinations of
individual edges. We propose a solution: we optimize edge coloring to
differentiate bundled edges. We quantify strength of bundling in a flexible
pairwise fashion between edges, and among bundled edges, we quantify how
dissimilar their colors should be by dissimilarity of their origins and
destinations. We solve the resulting nonlinear optimization, which is also
interpretable as a novel dimensionality reduction task. In large graphs the
necessary compromise is whether to differentiate colors sharply between locally
occurring strongly bundled edges (&quot;local bundles&quot;), or also between the weakly
bundled edges occurring globally over the graph (&quot;global bundles&quot;); we allow a
user-set global-local tradeoff. We call the technique &quot;peacock bundles&quot;.
Experiments show the coloring clearly enhances comprehensibility of graph
layouts with edge bundling.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00719</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00738</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Harder-Narasimhan theory for linear codes</dc:title>
 <dc:creator>Randriambololona, Hugues</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:description>  In this text we develop some aspects of Harder-Narasimhan theory, slopes,
semistability and canonical filtration, in the setting of combinatorial
lattices. Of noticeable importance is the Harder-Narasimhan structure
associated to a Galois connection between two lattices. It applies, in
particular, to matroids.
  We then specialize this to linear codes. This could be done from at least
three different approaches: using the sphere-packing analogy, or the geometric
view, or the Galois connection construction just introduced; a remarkable fact
is that they all lead to the same notion of semistability and canonical
filtration. Relations to previous propositions towards a classification of
codes, and to Wei's generalized Hamming weight hierarchy, are also discussed.
  Last, we study the important question of the preservation of semistability
(or more generally the behaviour of slopes) under duality, and under tensor
product. The former essentially follows from Wei's duality theorem for higher
weights, which we revisit in developing analogues of the Riemann-Roch, Serre
duality, and gap theorems for codes. The latter is shown likewise to follow
from the bound on higher weights of a tensor product, conjectured by Wei and
Yang, and proved by Schaathun in the geometric language, which we reformulate
directly in terms of codes.
</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00738</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00750</identifier>
 <datestamp>2016-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Signed Edges with $O(n^{1+o(1)} \log{n})$ Queries</dc:title>
 <dc:creator>Mitzenmacher, Michael</dc:creator>
 <dc:creator>Tsourakakis, Charalampos E.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Social networks and interactions in social media involve both positive and
negative relationships. Signed graphs capture both types of relationships:
positive edges correspond to pairs of &quot;friends&quot;, and negative edges to pairs of
&quot;foes&quot;. The {\em edge sign prediction problem}, which aims to predict whether
an interaction between a pair of nodes will be positive or negative, is an
important graph mining task for which many heuristics have recently been
proposed \cite{leskovec2010predicting,leskovec2010signed}.
  Motivated by social balance theory, we model the edge sign prediction problem
as a noisy correlation clustering problem with two clusters. We are allowed to
query each pair of nodes whether they belong to the same cluster or not, but
the answer to the query is corrupted with some probability $0&lt;q&lt;\frac{1}{2}$.
Let $c=\frac{1}{2}-q$ be the gap. We provide an algorithm that recovers the
clustering with high probability in the presence of noise for any constant gap
$c$ with $O(n^{1+\tfrac{1}{\log\log{n}}}\log{n})$ queries. Our algorithm uses
simple breadth first search as its main algorithmic primitive. Finally, we
provide a novel generalization to $k \geq 3$ clusters and prove that our
techniques can recover the clustering if the gap is constant in this
generalized setting.
</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2016-10-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00750</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00754</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A heuristic extending the Squarified treemapping algorithm</dc:title>
 <dc:creator>Cesarano, Antonio</dc:creator>
 <dc:creator>Ferrucci, FIlomena</dc:creator>
 <dc:creator>Torre, Mario</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  A heuristic extending the Squarified Treemap technique for the representation
of hierarchical information as treemaps is presented. The original technique
gives high quality treemap views, since items are laid out with rectangles that
approximate squares, allowing easy comparison and selection operations. New key
steps, with a low computational impact, have been introduced to yield treemaps
with even better aspect ratios and higher homogeneity among items.
</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00755</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms for Visualizing Phylogenetic Networks</dc:title>
 <dc:creator>Tollis, Ioannis G.</dc:creator>
 <dc:creator>Kakoulis, Konstantinos G.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the problem of visualizing phylogenetic networks, which are
extensions of the Tree of Life in biology. We use a space filling visualization
method, called DAGmaps, in order to obtain clear visualizations using limited
space. In this paper, we restrict our attention to galled trees and galled
networks and present linear time algorithms for visualizing them as DAGmaps.
</dc:description>
 <dc:description>Comment: Appears in the Proceedings of the 24th International Symposium on
  Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00755</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00759</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A MIP Backend for the IDP System</dc:title>
 <dc:creator>Pham, San</dc:creator>
 <dc:creator>Devriendt, Jo</dc:creator>
 <dc:creator>Bruynooghe, Maurice</dc:creator>
 <dc:creator>De Causmaecker, Patrick</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The IDP knowledge base system currently uses MiniSAT(ID) as its backend
Constraint Programming (CP) solver. A few similar systems have used a Mixed
Integer Programming (MIP) solver as backend. However, so far little is known
about when the MIP solver is preferable. This paper explores this question. It
describes the use of CPLEX as a backend for IDP and reports on experiments
comparing both backends.
</dc:description>
 <dc:description>Comment: internal report, 10 pages, 2 figures</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00759</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00767</identifier>
 <datestamp>2017-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Brazilian Congress structural balance analysis</dc:title>
 <dc:creator>Levorato, Mario</dc:creator>
 <dc:creator>Frota, Yuri</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In this work, we study the behavior of Brazilian politicians and political
parties with the help of clustering algorithms for signed social networks. For
this purpose, we extract and analyze a collection of signed networks
representing voting sessions of the lower house of Brazilian National Congress.
We process all available voting data for the period between 2011 and 2016, by
considering voting similarities between members of the Congress to define
weighted signed links. The solutions obtained by solving Correlation Clustering
(CC) problems are the basis for investigating deputies voting networks as well
as questions about loyalty, leadership, coalitions, political crisis, and
social phenomena such as mediation and polarization.
</dc:description>
 <dc:description>Comment: 27 pages, 15 tables, 6 figures; entire article was revised, new
  references added (including international press); correcting typing errors</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2017-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00767</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00775</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Error Covariance Splitting Technique for Multi-User MIMO Interference
  Environment</dc:title>
 <dc:creator>Sarker, Md. Abdul Latif</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates an error covariance matrix splitting technique for
multiuser multiple input and multiple output (MIMO) interference downlink
channel. Most of the related work has thus far considered the traditional error
covariance matrix which has not been well-shaped for maximizing the system
capacity. Thus, we split and propose a new iterative error covariance matrix to
mitigate the system error and maximize the system capacity in this paper.
Numerical results illustrate that our proposed method is strictly better than
the traditional method.
</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00775</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00777</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards End-to-End Reinforcement Learning of Dialogue Agents for
  Information Access</dc:title>
 <dc:creator>Dhingra, Bhuwan</dc:creator>
 <dc:creator>Li, Lihong</dc:creator>
 <dc:creator>Li, Xiujun</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:creator>Chen, Yun-Nung</dc:creator>
 <dc:creator>Ahmed, Faisal</dc:creator>
 <dc:creator>Deng, Li</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper proposes KB-InfoBot -- a multi-turn dialogue agent which helps
users search Knowledge Bases (KBs) without composing complicated queries. Such
goal-oriented dialogue agents typically need to interact with an external
database to access real-world knowledge. Previous systems achieved this by
issuing a symbolic query to the KB to retrieve entries based on their
attributes. However, such symbolic operations break the differentiability of
the system and prevent end-to-end training of neural dialogue agents. In this
paper, we address this limitation by replacing symbolic queries with an induced
&quot;soft&quot; posterior distribution over the KB that indicates which entities the
user is interested in. Integrating the soft retrieval process with a
reinforcement learner leads to higher task success rate and reward in both
simulations and against real users. We also present a fully neural end-to-end
agent, trained entirely from user feedback, and discuss its application towards
personalized dialogue agents. The source code is available at
https://github.com/MiuLab/KB-InfoBot.
</dc:description>
 <dc:description>Comment: Accepted at ACL 2017</dc:description>
 <dc:date>2016-09-02</dc:date>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00777</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00790</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Betweenness Centrality Maximization via Sampling</dc:title>
 <dc:creator>Mahmoody, Ahmad</dc:creator>
 <dc:creator>Tsourakakis, Charalampos E.</dc:creator>
 <dc:creator>Upfal, Eli</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Betweenness centrality is a fundamental centrality measure in social network
analysis. Given a large-scale network, how can we find the most central nodes?
This question is of key importance to numerous important applications that rely
on betweenness centrality, including community detection and understanding
graph vulnerability. Despite the large amount of work on designing scalable
approximation algorithms for betweenness centrality, estimating it on
large-scale networks remains a computational challenge.
  In this paper, we study the Betweenness Centrality Maximization problem:
given a graph $G=(V,E)$ and a positive integer $k$, find a set $S^* \subseteq
V$ that maximizes betweenness centrality subject to the cardinality constraint
$|S^*| \leq k$. We present an efficient randomized algorithm that provides a
$(1-1/e-\epsilon)$-approximation with high probability, where $\epsilon&gt;0$. Our
results improve the current state-of-the-art result by
Yoshida~\cite{yoshida2014almost}. Furthermore, we provide theoretical evidence
for the validity of a crucial assumption in the literature of betweenness
centrality estimation, namely that in real-world networks $O(|V|^2)$ shortest
paths pass through the top-$k$ central nodes, where $k$ is a constant. On the
experimental side, we perform an extensive experimental analysis of our method
on real-world networks, demonstrate its accuracy and scalability, and study
different properties of central nodes. Finally, we provide three graph mining
applications of our method.
</dc:description>
 <dc:description>Comment: Accepted in KDD 2016</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00790</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00791</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reprowd: Crowdsourced Data Processing Made Reproducible</dc:title>
 <dc:creator>Jiang, Ruochen</dc:creator>
 <dc:creator>Wang, Jiannan</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Crowdsourcing is a multidisciplinary research area including disciplines like
artificial intelligence, human-computer interaction, database, and social
science. To facilitate cooperation across disciplines, reproducibility is a
crucial factor, but unfortunately, it has not gotten enough attention in the
HCOMP community. In this paper, we present Reprowd, a system aiming to make it
easy to reproduce crowdsourced data processing research. We have open sourced
Reprowd at http://sfu-db.github.io/reprowd/.
</dc:description>
 <dc:description>Comment: HCOMP 2016 Work in Progress</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00791</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00799</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lexical-Morphological Modeling for Legal Text Analysis</dc:title>
 <dc:creator>Carvalho, Danilo S.</dc:creator>
 <dc:creator>Nguyen, Minh-Tien</dc:creator>
 <dc:creator>Chien, Tran Xuan</dc:creator>
 <dc:creator>Nguyen, Minh Le</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>14J30 (Primary)</dc:subject>
 <dc:subject>H.3, H.3.3, I.2.7</dc:subject>
 <dc:description>  In the context of the Competition on Legal Information Extraction/Entailment
(COLIEE), we propose a method comprising the necessary steps for finding
relevant documents to a legal question and deciding on textual entailment
evidence to provide a correct answer. The proposed method is based on the
combination of several lexical and morphological characteristics, to build a
language model and a set of features for Machine Learning algorithms. We
provide a detailed study on the proposed method performance and failure cases,
indicating that it is competitive with state-of-the-art approaches on Legal
Information Retrieval and Question Answering, while not needing extensive
training data nor depending on expert produced knowledge. The proposed method
achieved significant results in the competition, indicating a substantial level
of adequacy for the tasks addressed.
</dc:description>
 <dc:description>Comment: 16 pages, 5 figures, Lecture notes in computer science: New Frontiers
  in Artificial Intelligence, 2016/03</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00804</identifier>
 <datestamp>2016-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomized Prediction Games for Adversarial Machine Learning</dc:title>
 <dc:creator>Bul&#xf2;, Samuel Rota</dc:creator>
 <dc:creator>Biggio, Battista</dc:creator>
 <dc:creator>Pillai, Ignazio</dc:creator>
 <dc:creator>Pelillo, Marcello</dc:creator>
 <dc:creator>Roli, Fabio</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In spam and malware detection, attackers exploit randomization to obfuscate
malicious data and increase their chances of evading detection at test time;
e.g., malware code is typically obfuscated using random strings or byte
sequences to hide known exploits. Interestingly, randomization has also been
proposed to improve security of learning algorithms against evasion attacks, as
it results in hiding information about the classifier to the attacker. Recent
work has proposed game-theoretical formulations to learn secure classifiers, by
simulating different evasion attacks and modifying the classification function
accordingly. However, both the classification function and the simulated data
manipulations have been modeled in a deterministic manner, without accounting
for any form of randomization. In this work, we overcome this limitation by
proposing a randomized prediction game, namely, a non-cooperative
game-theoretic formulation in which the classifier and the attacker make
randomized strategy selections according to some probability distribution
defined over the respective strategy set. We show that our approach allows one
to improve the trade-off between attack detection and false alarms with respect
to state-of-the-art secure classifiers, even against attacks that are different
from those hypothesized during design, on application examples including
handwritten digit recognition, spam and malware detection.
</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00804</dc:identifier>
 <dc:identifier>IEEE Transactions on Neural Networks and Learning Systems, 2016</dc:identifier>
 <dc:identifier>doi:10.1109/TNNLS.2016.2593488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00810</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Greedy MAXCUT Algorithms and their Information Content</dc:title>
 <dc:creator>Bian, Yatao</dc:creator>
 <dc:creator>Gronskiy, Alexey</dc:creator>
 <dc:creator>Buhmann, Joachim M.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  MAXCUT defines a classical NP-hard problem for graph partitioning and it
serves as a typical case of the symmetric non-monotone Unconstrained Submodular
Maximization (USM) problem. Applications of MAXCUT are abundant in machine
learning, computer vision and statistical physics. Greedy algorithms to
approximately solve MAXCUT rely on greedy vertex labelling or on an edge
contraction strategy. These algorithms have been studied by measuring their
approximation ratios in the worst case setting but very little is known to
characterize their robustness to noise contaminations of the input data in the
average case. Adapting the framework of Approximation Set Coding, we present a
method to exactly measure the cardinality of the algorithmic approximation sets
of five greedy MAXCUT algorithms. Their information contents are explored for
graph instances generated by two different noise models: the edge reversal
model and Gaussian edge weights model. The results provide insights into the
robustness of different greedy heuristics and techniques for MAXCUT, which can
be used for algorithm design of general USM problems.
</dc:description>
 <dc:description>Comment: This is a longer version of the paper published in 2015 IEEE
  Information Theory Workshop (ITW)</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00810</dc:identifier>
 <dc:identifier>doi:10.1109/ITW.2015.7133122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00813</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance of Adaptive Link Selection with Buffer-Aided Relays in
  Underlay Cognitive Networks</dc:title>
 <dc:creator>Kumar, Bhupendra</dc:creator>
 <dc:creator>Prakriya, Shankar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate the performance of a three-node dual-hop
cognitive radio network (CRN) with a half-duplex (HD) decode-and-forward (DF)
buffer-aided relay. We derive expressions for the average rate and symbol error
rate (SER) performance of an adaptive link selection based channel-aware
buffer-aided relay (CABR) scheme that imposes peak-power and peak-interference
constraints on the secondary nodes, and compare them with those of conventional
non-buffer-aided relay (CNBR) and conventional buffer-aided relay (CBR) schemes
for a delay-tolerant system. For finite-delay systems, we analyze the
performance of a modified threshold-based scheme for fixed-rate transmission,
and demonstrate that use of a last-in-first-out buffer is advantageous in some
situations. We bring out the trade-offs between delay, throughput and SER.
Computer simulation results are presented to demonstrate accuracy of the
derived expressions.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE Transaction of Vehicular
  Technology for possible publication</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00817</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Learning of Multi-Instance Dictionary for Earth Mover's
  Distance based Histogram Comparison</dc:title>
 <dc:creator>Fan, Jihong</dc:creator>
 <dc:creator>Liang, Ru-Ze</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Dictionary plays an important role in multi-instance data representation. It
maps bags of instances to histograms. Earth mover's distance (EMD) is the most
effective histogram distance metric for the application of multi-instance
retrieval. However, up to now, there is no existing multi-instance dictionary
learning methods designed for EMD based histogram comparison. To fill this gap,
we develop the first EMD-optimal dictionary learning method using stochastic
optimization method. In the stochastic learning framework, we have one triplet
of bags, including one basic bag, one positive bag, and one negative bag. These
bags are mapped to histograms using a multi-instance dictionary. We argue that
the EMD between the basic histogram and the positive histogram should be
smaller than that between the basic histogram and the negative histogram. Base
on this condition, we design a hinge loss. By minimizing this hinge loss and
some regularization terms of the dictionary, we update the dictionary
instances. The experiments over multi-instance retrieval applications shows its
effectiveness when compared to other dictionary learning methods over the
problems of medical image retrieval and natural language relation
classification.
</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00829</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient computation of Laguerre polynomials</dc:title>
 <dc:creator>Gil, A.</dc:creator>
 <dc:creator>Segura, J.</dc:creator>
 <dc:creator>Temme, N. M.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Mathematics - Classical Analysis and ODEs</dc:subject>
 <dc:description>  An efficient algorithm and a Fortran 90 module (LaguerrePol) for computing
Laguerre polynomials $L^{(\alpha)}_n(z)$ are presented. The standard three-term
recurrence relation satisfied by the polynomials and different types of
asymptotic expansions valid for $n$ large and $\alpha$ small, are used
depending on the parameter region.
  Based on tests of contiguous relations in the parameter $\alpha$ and the
degree $n$ satisfied by the polynomials, we claim that a relative accuracy
close or better than $10^{-12}$ can be obtained using the module LaguerrePol
for computing the functions $L^{(\alpha)}_n(z)$ in the parameter range $z \ge
0$, $-1 &lt; \alpha \le 5$, $n \ge 0$.
</dc:description>
 <dc:description>Comment: To appear in Computer Physics Communications</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00829</dc:identifier>
 <dc:identifier>doi:10.1016/j.cpc.2016.09.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00831</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic beats fixed: On phase-based algorithms for file migration</dc:title>
 <dc:creator>Bienkowski, Marcin</dc:creator>
 <dc:creator>Byrka, Jaroslaw</dc:creator>
 <dc:creator>Mucha, Marcin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we construct a deterministic 4-competitive algorithm for the
online file migration problem, beating the currently best 20-year old,
4.086-competitive MTLM algorithm by Bartal et al. (SODA 1997). Like MTLM, our
algorithm also operates in phases, but it adapts their lengths dynamically
depending on the geometry of requests seen so far. The improvement was obtained
by carefully analyzing a linear model (factor-revealing LP) of a single phase
of the algorithm. We also show that if an online algorithm operates in phases
of fixed length and the adversary is able to modify the graph between phases,
no algorithm can beat the competitive ratio of 4.086.
</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:date>2017-04-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00831</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00832</identifier>
 <datestamp>2016-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Measures, Inequalities and Performance Bounds for Parameter
  Estimation in Impulsive Noise Environments</dc:title>
 <dc:creator>Fahs, Jihad</dc:creator>
 <dc:creator>Abou-Faycal, Ibrahim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Recent studies found that many channels are affected by additive noise that
is impulsive in nature and is best explained by heavy-tailed symmetric
alpha-stable distributions. Dealing with impulsive noise environments comes
with an added complexity with respect to the standard Gaussian environment: the
alpha-stable probability density functions have an infinite second moment and
the &quot;nice&quot; Hilbert space structure of the space of random variables having a
finite second moment is lost along with its tools and methodologies. This is
indeed the case in estimation theory where classical tools to quantify
performance of an estimator are tightly related to the assumption of finite
variance variables. In alpha-stable environments, expressions such as the mean
square error and the Cramer-Rao bound are hence problematic. In this work, we
tackle the parameter estimation problem in impulsive noise environments and
develop novel tools that are tailored to the alpha-stable and heavy-tailed
noise environments, tools that coincide with the standard ones adopted in the
Gaussian setup, namely a generalized &quot;power&quot; measure and a generalized Fisher
information. We generalize known information inequalities commonly used in the
Gaussian context: the de Bruijn's identity, the data processing inequality, the
Fisher information inequality, the isoperimetric inequality for entropies and
the Cramer-Rao bound. Additionally, we derive upper bounds on the differential
entropy of independent sums having a stable component. Finally, the new &quot;power&quot;
measure is used to shed some light on the additive alpha-stable noise channel
capacity in a setup that generalizes the linear average power constrained AWGN
channel. Our theoretical findings are paralleled with numerical evaluations of
various quantities and bounds using developed {\em Matlab} packages.
</dc:description>
 <dc:description>Comment: 42 pages, 5 figures, submitted to the IEEE transactions on
  information theory for peer review</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:date>2016-10-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00832</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00833</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Upper Bound on the Sum Capacity of the Downlink Multicell Processing
  with Finite Backhaul Capacity</dc:title>
 <dc:creator>Yang, Tianyu</dc:creator>
 <dc:creator>Liu, Nan</dc:creator>
 <dc:creator>Kang, Wei</dc:creator>
 <dc:creator>Shamai, Shlomo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study upper bounds on the sum capacity of the downlink
multicell processing model with finite backhaul capacity for the simple case of
2 base stations and 2 mobile users. It is modelled as a two-user multiple
access diamond channel. It consists of a first hop from the central processor
to the base stations via orthogonal links of finite capacity, and the second
hop from the base stations to the mobile users via a Gaussian interference
channel. The converse is derived using the converse tools of the multiple
access diamond channel and that of the Gaussian MIMO broadcast channel. Through
numerical results, it is shown that our upper bound improves upon the existing
upper bound greatly in the medium backhaul capacity range, and as a result, the
gap between the upper bounds and the sum rate of the time-sharing of the known
achievable schemes is significantly reduced.
</dc:description>
 <dc:description>Comment: 23 pages, 4 figures</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00833</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00836</identifier>
 <datestamp>2016-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Segmenting Consumer Stereo Videos: Benchmark, Baselines and
  Ensembles</dc:title>
 <dc:creator>Chiu, Wei-Chen</dc:creator>
 <dc:creator>Galasso, Fabio</dc:creator>
 <dc:creator>Fritz, Mario</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Are we ready to segment consumer stereo videos? The amount of this data type
is rapidly increasing and encompasses rich information of appearance, motion
and depth cues. However, the segmentation of such data is still largely
unexplored. First, we propose therefore a new benchmark: videos, annotations
and metrics to measure progress on this emerging challenge. Second, we evaluate
several state of the art segmentation methods and propose a novel ensemble
method based on recent spectral theory. This combines existing image and video
segmentation techniques in an efficient scheme. Finally, we propose and
integrate into this model a novel regressor, learnt to optimize the stereo
segmentation performance directly via a differentiable proxy. The regressor
makes our segmentation ensemble adaptive to each stereo video and outperforms
the segmentations of the ensemble as well as a most recent RGB-D segmentation
technique.
</dc:description>
 <dc:description>Comment: accepted by ACCV 2016</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:date>2016-09-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00836</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00843</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Online Universal Classifier for Binary, Multi-class and Multi-label
  Classification</dc:title>
 <dc:creator>Er, Meng Joo</dc:creator>
 <dc:creator>Venkatesan, Rajasekar</dc:creator>
 <dc:creator>Wang, Ning</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Classification involves the learning of the mapping function that associates
input samples to corresponding target label. There are two major categories of
classification problems: Single-label classification and Multi-label
classification. Traditional binary and multi-class classifications are
sub-categories of single-label classification. Several classifiers are
developed for binary, multi-class and multi-label classification problems, but
there are no classifiers available in the literature capable of performing all
three types of classification. In this paper, a novel online universal
classifier capable of performing all the three types of classification is
proposed. Being a high speed online classifier, the proposed technique can be
applied to streaming data applications. The performance of the developed
classifier is evaluated using datasets from binary, multi-class and multi-label
problems. The results obtained are compared with state-of-the-art techniques
from each of the classification types.
</dc:description>
 <dc:description>Comment: 6 pages, 6 tables</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00843</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00845</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph-Based Active Learning: A New Look at Expected Error Minimization</dc:title>
 <dc:creator>Jun, Kwang-Sung</dc:creator>
 <dc:creator>Nowak, Robert</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In graph-based active learning, algorithms based on expected error
minimization (EEM) have been popular and yield good empirical performance. The
exact computation of EEM optimally balances exploration and exploitation. In
practice, however, EEM-based algorithms employ various approximations due to
the computational hardness of exact EEM. This can result in a lack of either
exploration or exploitation, which can negatively impact the effectiveness of
active learning. We propose a new algorithm TSA (Two-Step Approximation) that
balances between exploration and exploitation efficiently while enjoying the
same computational complexity as existing approximations. Finally, we
empirically show the value of balancing between exploration and exploitation in
both toy and real-world datasets where our method outperforms several
state-of-the-art methods.
</dc:description>
 <dc:description>Comment: Submitted to GlobalSIP 2016</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00852</identifier>
 <datestamp>2017-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Caching and Pricing Strategies for Popular Content in Information
  Centric Networks</dc:title>
 <dc:creator>Hajimirsadeghi, Mohammad</dc:creator>
 <dc:creator>Mandayam, Narayan B.</dc:creator>
 <dc:creator>Reznik, Alex</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We develop an analytical framework for distribution of popular content in an
Information Centric Network (ICN) that comprises of Access ICNs, a Transit ICN
and a Content Provider. Using a generalized Zipf distribution to model content
popularity, we devise a game theoretic approach to jointly determine caching
and pricing strategies in such an ICN. Under the assumption that the caching
cost of the access and transit ICNs is inversely proportional to popularity, we
show that the Nash caching strategies in the ICN are 0-1 (all or nothing)
strategies. Further, for the case of symmetric Access ICNs, we show that the
Nash equilibrium is unique and the caching policy (0 or 1) is determined by a
threshold on the popularity of the content (reflected by the Zipf probability
metric), i.e., all content more popular than the threshold value is cached. We
also show that the resulting threshold of the Access and Transit ICNs, as well
as all prices can be obtained by a decomposition of the joint caching and
pricing problem into two independent caching only and pricing only problems.
</dc:description>
 <dc:description>Comment: Accepted to be published in Journal of Selected Area in
  Communication(JSAC special issue on game theory in networks)</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:date>2017-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00852</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00856</identifier>
 <datestamp>2016-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral Efficiency Bounds for Interference-Limited SVD-MIMO Cellular
  Communication Systems</dc:title>
 <dc:creator>Choi, Jinseok</dc:creator>
 <dc:creator>Park, Jeonghun</dc:creator>
 <dc:creator>Evans, Brian L.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The ergodic spectral efficiency (SE) in interference-limited multiple-input
multiple-output (MIMO) downlink cellular systems is characterized based on
stochastic geometry. A single user is served by using singular value
decomposition precoding and combining. By approximating the expectations of the
channel eigenvalues, we derive upper and lower bounds on the ergodic SE. The
obtained upper bound is the best possible system-level performance of any MIMO
strategy in non-cooperative cellular networks. We validate our analytical
results through simulation. We also conjecture that there exists the optimal
number of streams being proportional to the pathloss exponent.
</dc:description>
 <dc:description>Comment: submitted to IEEE Wireless Communications Letters</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:date>2016-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00856</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00864</identifier>
 <datestamp>2017-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifiability of linear dynamic networks</dc:title>
 <dc:creator>Weerts, Harm H. M.</dc:creator>
 <dc:creator>Hof, Paul M. J. Van den</dc:creator>
 <dc:creator>Dankers, Arne G.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Dynamic networks are structured interconnections of dynamical systems
(modules) driven by external excitation and disturbance signals. In order to
identify their dynamical properties and/or their topology consistently from
measured data, we need to make sure that the network model set is identifiable.
We introduce the notion of network identifiability, as a property of a
parameterized model set, that ensures that different network models can be
distinguished from each other when performing identification on the basis of
measured data. Different from the classical notion of (parameter)
identifiability, we focus on the distinction between network models in terms of
their transfer functions. For a given structured model set with a pre-chosen
topology, identifiability typically requires conditions on the presence and
location of excitation signals, and on presence, location and correlation of
disturbance signals. Because in a dynamic network, disturbances cannot always
be considered to be of full-rank, the reduced-rank situation is also covered,
meaning that the number of driving white noise processes can be strictly less
than the number of disturbance variables. This includes the situation of having
noise-free nodes.
</dc:description>
 <dc:description>Comment: Provisionally accepted for publication in Automatica</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:date>2017-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00866</identifier>
 <datestamp>2017-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep-Anomaly: Fully Convolutional Neural Network for Fast Anomaly
  Detection in Crowded Scenes</dc:title>
 <dc:creator>Sabokrou, Mohammad</dc:creator>
 <dc:creator>Fayyaz, Mohsen</dc:creator>
 <dc:creator>Fathy, Mahmood</dc:creator>
 <dc:creator>Moayedd, Zahra</dc:creator>
 <dc:creator>klette, Reinhard</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The detection of abnormal behaviours in crowded scenes has to deal with many
challenges. This paper presents an efficient method for detection and
localization of anomalies in videos. Using fully convolutional neural networks
(FCNs) and temporal data, a pre-trained supervised FCN is transferred into an
unsupervised FCN ensuring the detection of (global) anomalies in scenes. High
performance in terms of speed and accuracy is achieved by investigating the
cascaded detection as a result of reducing computation complexities. This
FCN-based architecture addresses two main tasks, feature representation and
cascaded outlier detection. Experimental results on two benchmarks suggest that
detection and localization of the proposed method outperforms existing methods
in terms of accuracy.
</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:date>2017-04-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00867</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Updating the Number of Crossings in Rectilinear Drawings of the Complete
  Graph</dc:title>
 <dc:creator>Duque, Frank</dc:creator>
 <dc:creator>Fabila-Monroy, Ruy</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Let $S$ be a set of $n$ points in general position in the plane. Join every
pair of points in $S$ with a straight line segment. Let $\overline{cr}(S)$ be
number of pairs of these edges that intersect in their interior. Suppose that
this number is known. In this paper we consider the problem of computing
$\overline{cr}(S')$, where $S'$ comes from adding, deleting or moving a point
from $S$.
</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00875</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compatible and Usable Mandatory Access Control for Good-enough OS
  Security</dc:title>
 <dc:creator>Shan, Zhiyong</dc:creator>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  OS compromise is one of the most serious computer security problems today,
but still not being resolved. Although people proposed different kinds of
methods, they could not be accepted by most users who are non-expert due to the
lack of compatibility and usability. In this paper, we introduce a kind of new
mandatory access control model, named CUMAC, that aims to achieve good-enough
security, high compatibility and usability. It has two novel features. One is
access control based on tracing potential intrusion that can reduce false
negatives and facilitate security configuration, in order to improve both
compatibility and usability; the other is automatically figuring out all of the
compatibility exceptions that usually incurs incompatible problems. The
experiments performed on the prototype show that CUMAC can defense attacks from
network, mobile disk and local untrustable users while keeping good
compatibility and usability.
</dc:description>
 <dc:description>Comment: Electronic Commerce and Security, 2009. ISECS '09. Second
  International Symposium on</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00875</dc:identifier>
 <dc:identifier>doi:10.1109/ISECS.2009.29</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00878</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Probabilistic Optimum-Path Forest Classifier for Binary Classification
  Problems</dc:title>
 <dc:creator>Fernandes, Silas E. N.</dc:creator>
 <dc:creator>Pereira, Danillo R.</dc:creator>
 <dc:creator>Ramos, Caio C. O.</dc:creator>
 <dc:creator>Souza, Andre N.</dc:creator>
 <dc:creator>Papa, Joao P.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Probabilistic-driven classification techniques extend the role of traditional
approaches that output labels (usually integer numbers) only. Such techniques
are more fruitful when dealing with problems where one is not interested in
recognition/identification only, but also into monitoring the behavior of
consumers and/or machines, for instance. Therefore, by means of probability
estimates, one can take decisions to work better in a number of scenarios. In
this paper, we propose a probabilistic-based Optimum Path Forest (OPF)
classifier to handle with binary classification problems, and we show it can be
more accurate than naive OPF in a number of datasets. In addition to being just
more accurate or not, probabilistic OPF turns to be another useful tool to the
scientific community.
</dc:description>
 <dc:description>Comment: Submitted to Neural Processing Letters</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00878</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00881</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CryptoImg: Privacy Preserving Processing Over Encrypted Images</dc:title>
 <dc:creator>Ziad, M. Tarek Ibn</dc:creator>
 <dc:creator>Alanwar, Amr</dc:creator>
 <dc:creator>Alzantot, Moustafa</dc:creator>
 <dc:creator>Srivastava, Mani</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Cloud computing services provide a scalable solution for the storage and
processing of images and multimedia files. However, concerns about privacy
risks prevent users from sharing their personal images with third-party
services. In this paper, we describe the design and implementation of
CryptoImg, a library of modular privacy preserving image processing operations
over encrypted images. By using homomorphic encryption, CryptoImg allows the
users to delegate their image processing operations to remote servers without
any privacy concerns. Currently, CryptoImg supports a subset of the most
frequently used image processing operations such as image adjustment, spatial
filtering, edge sharpening, histogram equalization and others. We implemented
our library as an extension to the popular computer vision library OpenCV.
CryptoImg can be used from either mobile or desktop clients. Our experimental
results demonstrate that CryptoImg is efficient while performing operations
over encrypted images with negligible error and reasonable time overheads on
the supported platforms
</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00881</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00887</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attack Allocation on Remote State Estimation in Multi-Systems:
  Structural Results and Asymptotic Solution</dc:title>
 <dc:creator>Ren, Xiaoqiang</dc:creator>
 <dc:creator>Wu, Junfeng</dc:creator>
 <dc:creator>Dey, Subhrakanti</dc:creator>
 <dc:creator>Shi, Ling</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper considers optimal attack attention allocation on remote state
estimation in multi-systems. Suppose there are $\mathtt{M}$ independent
systems, each of which has a remote sensor monitoring the system and sending
its local estimates to a fusion center over a packet-dropping channel. An
attacker may generate noises to exacerbate the communication channels between
sensors and the fusion center. Due to capacity limitation, at each time the
attacker can exacerbate at most $\mathtt{N}$ of the $\mathtt{M}$ channels. The
goal of the attacker side is to seek an optimal policy maximizing the
estimation error at the fusion center. The problem is formulated as a Markov
decision process (MDP) problem, and the existence of an optimal deterministic
and stationary policy is proved. We further show that the optimal policy has a
threshold structure, by which the computational complexity is reduced
significantly. Based on the threshold structure, a myopic policy is proposed
for homogeneous models and its optimality is established. To overcome the curse
of dimensionality of MDP algorithms for general heterogeneous models, we
further provide an asymptotically (as $\mathtt{M}$ and $\mathtt{N}$ go to
infinity) optimal solution, which is easy to compute and implement. Numerical
examples are given to illustrate the main results.
</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00889</identifier>
 <datestamp>2017-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Power Control for Delay Optimization in Energy Harvesting
  Cooperative Relay Networks</dc:title>
 <dc:creator>Hakami, Vesal</dc:creator>
 <dc:creator>Dehghan, Mehdi</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider cooperative communications with energy harvesting (EH) relays,
and develop a distributed power control mechanism for the relaying terminals.
Unlike prior art which mainly deal with single-relay systems with saturated
traffic flow, we address the case of bursty data arrival at the source
cooperatively forwarded by multiple half-duplex EH relays. We aim at optimizing
the long-run average delay of the source packets under the energy neutrality
constraint on power consumption of each relay. While EH relay systems have been
predominantly optimized using either offline or online methodologies, we take
on a more realistic learning-theoretic approach. Hence, our scheme can be
deployed for real-time operation without assuming acausal information on
channel realizations, data/energy arrivals as required by offline optimization,
nor does it rely on precise statistics of the system processes as is the case
with online optimization. We formulate the problem as a partially observable
identical payoff stochastic game (PO-IPSG) with factored controllers, in which
the power control policy of each relay is adaptive to its local
source-to-relay/relay-to-destination channel states, its local energy state as
well as to the source buffer state information. We derive a multi-agent
reinforcement learning algorithm which is convergent to a locally optimal
solution of the formulated PO-IPSG. The proposed algorithm operates without
explicit message exchange between the relays, while inducing only little
source-relay signaling overhead. By simulation, we contrast the delay
performance of the proposed method against existing heuristics for throughput
maximization. It is shown that compared with these heuristics, the systematic
approach adopted in this paper has a smaller sub-optimality gap once evaluated
against a centralized optimal policy armed with perfect statistics.
</dc:description>
 <dc:description>Comment: 13 pages, 6 figures, IEEE Transactions on Vehicular Technology</dc:description>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00889</dc:identifier>
 <dc:identifier>IEEE Transactions on Vehicular Technology, Vol. 66, No. 6, June
  2017</dc:identifier>
 <dc:identifier>doi:10.1109/TVT.2016.2610444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00893</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Rank Tensor Networks for Dimensionality Reduction and Large-Scale
  Optimization Problems: Perspectives and Challenges PART 1</dc:title>
 <dc:creator>Cichocki, A.</dc:creator>
 <dc:creator>Lee, N.</dc:creator>
 <dc:creator>Oseledets, I. V.</dc:creator>
 <dc:creator>Phan, A. -H.</dc:creator>
 <dc:creator>Zhao, Q.</dc:creator>
 <dc:creator>Mandic, D.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Machine learning and data mining algorithms are becoming increasingly
important in analyzing large volume, multi-relational and multi--modal
datasets, which are often conveniently represented as multiway arrays or
tensors. It is therefore timely and valuable for the multidisciplinary research
community to review tensor decompositions and tensor networks as emerging tools
for large-scale data analysis and data mining. We provide the mathematical and
graphical representations and interpretation of tensor networks, with the main
focus on the Tucker and Tensor Train (TT) decompositions and their extensions
or generalizations.
  Keywords: Tensor networks, Function-related tensors, CP decomposition, Tucker
models, tensor train (TT) decompositions, matrix product states (MPS), matrix
product operators (MPO), basic tensor operations, multiway component analysis,
multilinear blind source separation, tensor completion, linear/multilinear
dimensionality reduction, large-scale optimization problems, symmetric
eigenvalue decomposition (EVD), PCA/SVD, huge systems of linear equations,
pseudo-inverse of very large matrices, Lasso and Canonical Correlation Analysis
(CCA) (This is Part 1)
</dc:description>
 <dc:description>Comment: 176 pages</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:date>2017-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00893</dc:identifier>
 <dc:identifier>Foundations and Trends in Machine Learning, vol. 9, no. 4-5, pp.
  249-429, 2016</dc:identifier>
 <dc:identifier>doi:10.1561/2200000059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00896</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Robust Sparse Fourier Transform in the Continuous Setting</dc:title>
 <dc:creator>Price, Eric</dc:creator>
 <dc:creator>Song, Zhao</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In recent years, a number of works have studied methods for computing the
Fourier transform in sublinear time if the output is sparse. Most of these have
focused on the discrete setting, even though in many applications the input
signal is continuous and naive discretization significantly worsens the
sparsity level.
  We present an algorithm for robustly computing sparse Fourier transforms in
the continuous setting. Let $x(t) = x^*(t) + g(t)$, where $x^*$ has a
$k$-sparse Fourier transform and $g$ is an arbitrary noise term. Given sample
access to $x(t)$ for some duration $T$, we show how to find a
$k$-Fourier-sparse reconstruction $x'(t)$ with
  $$\frac{1}{T}\int_0^T |x'(t) - x(t) |^2 \mathrm{d} t \lesssim
\frac{1}{T}\int_0^T | g(t)|^2 \mathrm{d}t.$$
  The sample complexity is linear in $k$ and logarithmic in the signal-to-noise
ratio and the frequency resolution. Previous results with similar sample
complexities could not tolerate an infinitesimal amount of i.i.d. Gaussian
noise, and even algorithms with higher sample complexities increased the noise
by a polynomial factor. We also give new results for how precisely the
individual frequencies of $x^*$ can be recovered.
</dc:description>
 <dc:description>Comment: FOCS 2015</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00896</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00904</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High Dimensional Human Guided Machine Learning</dc:title>
 <dc:creator>Holloway, Eric</dc:creator>
 <dc:creator>Marks II, Robert</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Have you ever looked at a machine learning classification model and thought,
I could have made that? Well, that is what we test in this project, comparing
XGBoost trained on human engineered features to training directly on data. The
human engineered features do not outperform XGBoost trained di- rectly on the
data, but they are comparable. This project con- tributes a novel method for
utilizing human created classifi- cation models on high dimensional datasets.
</dc:description>
 <dc:description>Comment: 3 pages, 1 figure, HCOMP 2016 submission, work in progress</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00919</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Mutual Explicit Induction Proof in Separation Logic</dc:title>
 <dc:creator>Ta, Quang-Trung</dc:creator>
 <dc:creator>Le, Ton Chanh</dc:creator>
 <dc:creator>Khoo, Siau-Cheng</dc:creator>
 <dc:creator>Chin, Wei-Ngan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We present a sequent-based deductive system for automatically proving
entailments in separation logic by using mathematical induction. Our technique,
called mutual explicit induction proof, is an instance of Noetherian induction.
Specifically, we propose a novel induction principle on a well-founded relation
of separation logic model and follow the explicit induction methods to
implement this principle as inference rules, so that it can be easily
integrated into a deductive system. We also support mutual induction, a natural
feature of implicit induction, where the goal entailment and other entailments
derived during the proof search can be used as hypotheses to prove each other.
We have implemented a prototype prover and evaluated it on a benchmark of
handcrafted entailments as well as benchmarks from a separation logic
competition.
</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:date>2016-09-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00921</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decoding visual stimuli in human brain by using Anatomical Pattern
  Analysis on fMRI images</dc:title>
 <dc:creator>Yousefnezhad, Muhammad</dc:creator>
 <dc:creator>Zhang, Daoqiang</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  A universal unanswered question in neuroscience and machine learning is
whether computers can decode the patterns of the human brain. Multi-Voxels
Pattern Analysis (MVPA) is a critical tool for addressing this question.
However, there are two challenges in the previous MVPA methods, which include
decreasing sparsity and noises in the extracted features and increasing the
performance of prediction. In overcoming mentioned challenges, this paper
proposes Anatomical Pattern Analysis (APA) for decoding visual stimuli in the
human brain. This framework develops a novel anatomical feature extraction
method and a new imbalance AdaBoost algorithm for binary classification.
Further, it utilizes an Error-Correcting Output Codes (ECOC) method for
multi-class prediction. APA can automatically detect active regions for each
category of the visual stimuli. Moreover, it enables us to combine homogeneous
datasets for applying advanced classification. Experimental studies on 4 visual
categories (words, consonants, objects and scrambled photos) demonstrate that
the proposed approach achieves superior performance to state-of-the-art
methods.
</dc:description>
 <dc:description>Comment: The 8th International Conference on Brain Inspired Cognitive Systems
  (BICS'16), Beijing, China, Nov/28-30/2016</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00932</identifier>
 <datestamp>2017-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral learning of dynamic systems from nonequilibrium data</dc:title>
 <dc:creator>Wu, Hao</dc:creator>
 <dc:creator>No&#xe9;, Frank</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Observable operator models (OOMs) and related models are one of the most
important and powerful tools for modeling and analyzing stochastic systems.
They exactly describe dynamics of finite-rank systems and can be efficiently
and consistently estimated through spectral learning under the assumption of
identically distributed data. In this paper, we investigate the properties of
spectral learning without this assumption due to the requirements of analyzing
large-time scale systems, and show that the equilibrium dynamics of a system
can be extracted from nonequilibrium observation data by imposing an
equilibrium constraint. In addition, we propose a binless extension of spectral
learning for continuous data. In comparison with the other continuous-valued
spectral algorithms, the binless algorithm can achieve consistent estimation of
equilibrium dynamics with only linear complexity.
</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:date>2017-06-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00932</dc:identifier>
 <dc:identifier>Proceedings of the 29th conference on Neural Information
  Processing Systems (NIPS), Barcelona, Spain, 2016, pp. 4179-4187</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00934</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dispersion Compensation using High-Positive Dispersive Optical Fibers</dc:title>
 <dc:creator>Hadi, Mohammad</dc:creator>
 <dc:creator>Marvasti, Farokh</dc:creator>
 <dc:creator>Pakravan, Mohammad Reza</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The common and traditional method for dispersion compensation in optical
domain is concatenating the transmit optical fiber by a compensating optical
fiber having high-negative dispersion coefficient. In this paper, we take an
opposite direction and show how an optical fiber with high-positive dispersion
coefficient can also be used for dispersion compensation. Our optical
dispersion compensating structure is the optical implementation of an iterative
algorithm in signal processing. The proposed dispersion compensating system is
constructed by cascading a number of compensating sub-systems and its
compensation capability is improved by increasing the number of embedded
sub-systems. We also show that the compensation capability is a trade-off
between transmission length and bandwidth. We use simulation results to
validate the performance of the introduced dispersion compensating module.
Photonic crystal fibers with high-positive dispersion coefficient can be used
for constructing the proposed optical dispersion compensating module.
</dc:description>
 <dc:description>Comment: 5 pages, 5 figures</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00945</identifier>
 <datestamp>2016-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MmmTurkey: A Crowdsourcing Framework for Deploying Tasks and Recording
  Worker Behavior on Amazon Mechanical Turk</dc:title>
 <dc:creator>Dang, Brandon</dc:creator>
 <dc:creator>Hutson, Miles</dc:creator>
 <dc:creator>Lease, Matt</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Internal HITs on Mechanical Turk can be programmatically restrictive, and as
a result, many requesters turn to using external HITs as a more flexible
alternative. However, creating such HITs can be redundant and time-consuming.
We present MmmTurkey, a framework that enables researchers to not only quickly
create and manage external HITs, but more significantly also capture and record
detailed worker behavioral data characterizing how each worker completes a
given task.
</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:date>2016-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00951</identifier>
 <datestamp>2017-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Convergence Analysis of the Multiplicative Update Algorithm
  for Regularized Nonnegative Matrix Factorization</dc:title>
 <dc:creator>Zhao, Renbo</dc:creator>
 <dc:creator>Tan, Vincent Y. F.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The multiplicative update (MU) algorithm has been extensively used to
estimate the basis and coefficient matrices in nonnegative matrix factorization
(NMF) problems under a wide range of divergences and regularizers. However,
theoretical convergence guarantees have only been derived for a few special
divergences without regularization. In this work, we provide a conceptually
simple, self-contained, and unified proof for the convergence of the MU
algorithm applied on NMF with a wide range of divergences and regularizers. Our
main result shows the sequence of iterates (i.e., pairs of basis and
coefficient matrices) produced by the MU algorithm converges to the set of
stationary points of the non-convex NMF optimization problem. Our proof
strategy has the potential to open up new avenues for analyzing similar
problems in machine learning and signal processing.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:date>2017-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00958</identifier>
 <datestamp>2016-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient ray tracing on 3D regular grids for fast generation of
  digitally reconstructed radiographs in iterative tomographic reconstruction
  techniques</dc:title>
 <dc:creator>Dittmann, Jonas</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Cone beam projection is an essential and particularly time consuming part of
any iterative tomographic reconstruction algorithm. On current graphics
hardware especially the amount and pattern of memory accesses is a limiting
factor when read-only textures cannot be used. With the final objective of
accelerating iterative reconstruction techniques, a non-oversampling
Joseph-like raytracing projection algorithm for three dimensions featuring both
a branchless sampling loop and a cache friendly memory access pattern is
presented. An interpretation of the employed interpolation scheme is given with
respect to the effective beam and voxel models implied. The method is further
compared to existing techniques, and the modifications required to implement
further voxel and beam shape models are outlined. Both memory access rates and
total run time are benchmarked on a current consumer grade graphics processing
unit and explicitly compared to the performance of a classic Digital
Differential Analyzer (DDA) algorithm. The presented raytracer achieves memory
access rates of 292 GB/s in read-and-write memory and 502 GB/s in read-only
texture memory. It outperforms the DDA in terms of total run time by a factor
of up to five and achives 170 to 300 projections of a $512^{3}$ voxel volume
per second.
</dc:description>
 <dc:description>Comment: manuscript for review</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00967</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vanishing point detection with convolutional neural networks</dc:title>
 <dc:creator>Borji, Ali</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Inspired by the finding that vanishing point (road tangent) guides driver's
gaze, in our previous work we showed that vanishing point attracts gaze during
free viewing of natural scenes as well as in visual search (Borji et al.,
Journal of Vision 2016). We have also introduced improved saliency models using
vanishing point detectors (Feng et al., WACV 2016). Here, we aim to predict
vanishing points in naturalistic environments by training convolutional neural
networks in an end-to-end manner over a large set of road images downloaded
from Youtube with vanishing points annotated. Results demonstrate effectiveness
of our approach compared to classic approaches of vanishing point detection in
the literature.
</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00967</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00969</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Distributional Extensions to DFR Ranking</dc:title>
 <dc:creator>Petersen, Casper</dc:creator>
 <dc:creator>Simonsen, Jakob Grue</dc:creator>
 <dc:creator>Jarvelin, Kalervo</dc:creator>
 <dc:creator>Lioma, Christina</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Divergence From Randomness (DFR) ranking models assume that informative terms
are distributed in a corpus differently than non-informative terms. Different
statistical models (e.g. Poisson, geometric) are used to model the distribution
of non-informative terms, producing different DFR models. An informative term
is then detected by measuring the divergence of its distribution from the
distribution of non-informative terms. However, there is little empirical
evidence that the distributions of non-informative terms used in DFR actually
fit current datasets. Practically this risks providing a poor separation
between informative and non-informative terms, thus compromising the
discriminative power of the ranking model. We present a novel extension to DFR,
which first detects the best-fitting distribution of non-informative terms in a
collection, and then adapts the ranking computation to this best-fitting
distribution. We call this model Adaptive Distributional Ranking (ADR) because
it adapts the ranking to the statistics of the specific dataset being processed
each time. Experiments on TREC data show ADR to outperform DFR models (and
their extensions) and be comparable in performance to a query likelihood
language model (LM).
</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00978</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Maxima in the Likelihood of Gaussian Mixture Models: Structural
  Results and Algorithmic Consequences</dc:title>
 <dc:creator>Jin, Chi</dc:creator>
 <dc:creator>Zhang, Yuchen</dc:creator>
 <dc:creator>Balakrishnan, Sivaraman</dc:creator>
 <dc:creator>Wainwright, Martin J.</dc:creator>
 <dc:creator>Jordan, Michael</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We provide two fundamental results on the population (infinite-sample)
likelihood function of Gaussian mixture models with $M \geq 3$ components. Our
first main result shows that the population likelihood function has bad local
maxima even in the special case of equally-weighted mixtures of well-separated
and spherical Gaussians. We prove that the log-likelihood value of these bad
local maxima can be arbitrarily worse than that of any global optimum, thereby
resolving an open question of Srebro (2007). Our second main result shows that
the EM algorithm (or a first-order variant of it) with random initialization
will converge to bad critical points with probability at least
$1-e^{-\Omega(M)}$. We further establish that a first-order variant of EM will
not converge to strict saddle points almost surely, indicating that the poor
performance of the first-order method can be attributed to the existence of bad
local maxima rather than bad saddle points. Overall, our results highlight the
necessity of careful initialization when using the EM algorithm in practice,
even when applied in highly favorable settings.
</dc:description>
 <dc:description>Comment: Neural Information Processing Systems (NIPS) 2016</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00978</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00988</identifier>
 <datestamp>2017-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A clustering-based data reduction for very large spatio-temporal
  datasets</dc:title>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:creator>Bue, Martin</dc:creator>
 <dc:creator>Whelan, Michael</dc:creator>
 <dc:creator>Kechadi, Tahar</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Today, huge amounts of data are being collected with spatial and temporal
components from sources such as meteorological, satellite imagery etc.
Efficient visualisation as well as discovery of useful knowledge from these
datasets is therefore very challenging and becoming a massive economic need.
Data Mining has emerged as the technology to discover hidden knowledge in very
large amounts of data. Furthermore, data mining techniques could be applied to
decrease the large size of raw data by retrieving its useful knowledge as
representatives. As a consequence, instead of dealing with a large size of raw
data, we can use these representatives to visualise or to analyse without
losing important information. This paper presents a new approach based on
different clustering techniques for data reduction to help analyse very large
spatio-temporal data. We also present and discuss preliminary results of this
approach.
</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:date>2017-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00990</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A data mining-based solution for detecting suspicious money laundering
  cases in an investment bank</dc:title>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:creator>Markos, Sammer</dc:creator>
 <dc:creator>Kechadi, Tahar</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Today, money laundering poses a serious threat not only to financial
institutions but also to the nation. This criminal activity is becoming more
and more sophisticated and seems to have moved from the clichy of drug
trafficking to financing terrorism and surely not forgetting personal gain.
Most international financial institutions have been implementing anti-money
laundering solutions to fight investment fraud. However, traditional
investigative techniques consume numerous man-hours. Recently, data mining
approaches have been developed and are considered as well-suited techniques for
detecting money laundering activities. Within the scope of a collaboration
project for the purpose of developing a new solution for the anti-money
laundering Units in an international investment bank, we proposed a simple and
efficient data mining-based solution for anti-money laundering. In this paper,
we present this solution developed as a tool and show some preliminary
experiment results with real transaction datasets.
</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00990</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00992</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Evaluation of a Natural Language Processing approach applied
  in White Collar crime investigation</dc:title>
 <dc:creator>Banerveld, Maarten</dc:creator>
 <dc:creator>Le-Khac, Nhien-An</dc:creator>
 <dc:creator>Kechadi, Tahar</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In today world we are confronted with increasing amounts of information every
day coming from a large variety of sources. People and co-operations are
producing data on a large scale, and since the rise of the internet, e-mail and
social media the amount of produced data has grown exponentially. From a law
enforcement perspective we have to deal with these huge amounts of data when a
criminal investigation is launched against an individual or company. Relevant
questions need to be answered like who committed the crime, who were involved,
what happened and on what time, who were communicating and about what? Not only
the amount of available data to investigate has increased enormously, but also
the complexity of this data has increased. When these communication patterns
need to be combined with for instance a seized financial administration or
corporate document shares a complex investigation problem arises. Recently,
criminal investigators face a huge challenge when evidence of a crime needs to
be found in the Big Data environment where they have to deal with large and
complex datasets especially in financial and fraud investigations. To tackle
this problem, a financial and fraud investigation unit of a European country
has developed a new tool named LES that uses Natural Language Processing (NLP)
techniques to help criminal investigators handle large amounts of textual
information in a more efficient and faster way. In this paper, we present
briefly this tool and we focus on the evaluation its performance in terms of
the requirements of forensic investigation: speed, smarter and easier for
investigators. In order to evaluate this LES tool, we use different performance
metrics. We also show experimental results of our evaluation with large and
complex datasets from real-world application.
</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.00999</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Generation of Vectorized Montgomery Algorithm</dc:title>
 <dc:creator>Meng, Lingchuan</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Modular arithmetic is widely used in crytography and symbolic computation.
This paper presents a vectorized Montgomery algorithm for modular
multiplication, the key to fast modular arithmetic, that fully utilizes the
SIMD instructions. We further show how the vectorized algorithm can be
automatically generated by the {\SPIRAL} system, as part of the effort for
automatic generation of a modular polynomial multiplication library.
</dc:description>
 <dc:description>Comment: 14 pages, 5 figures, based on the thesis work by Lingchuan Meng</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.00999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.01000</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convexified Convolutional Neural Networks</dc:title>
 <dc:creator>Zhang, Yuchen</dc:creator>
 <dc:creator>Liang, Percy</dc:creator>
 <dc:creator>Wainwright, Martin J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We describe the class of convexified convolutional neural networks (CCNNs),
which capture the parameter sharing of convolutional neural networks in a
convex manner. By representing the nonlinear convolutional filters as vectors
in a reproducing kernel Hilbert space, the CNN parameters can be represented as
a low-rank matrix, which can be relaxed to obtain a convex optimization
problem. For learning two-layer convolutional neural networks, we prove that
the generalization error obtained by a convexified CNN converges to that of the
best possible CNN. For learning deeper networks, we train CCNNs in a layer-wise
manner. Empirically, CCNNs achieve performance competitive with CNNs trained by
backpropagation, SVMs, fully-connected neural networks, stacked denoising
auto-encoders, and other baseline methods.
</dc:description>
 <dc:description>Comment: 29 pages</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.01000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.01002</identifier>
 <datestamp>2017-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Catching a fast robber on the grid</dc:title>
 <dc:creator>Balister, Paul</dc:creator>
 <dc:creator>Bollob&#xe1;s, B&#xe9;la</dc:creator>
 <dc:creator>Narayanan, Bhargav</dc:creator>
 <dc:creator>Shaw, Amy</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C57 (Primary) 05C35 (Secondary)</dc:subject>
 <dc:description>  We study the problem of cops and robbers on the grid where the robber is
allowed to move faster than the cops. It is well known that two cops are
necessary and sufficient to catch the robber on any finite grid when the robber
has unit speed. Here, we prove that when the speed of the robber is a
sufficiently large constant, the number of cops needed to catch the robber on
an $n \times n$ grid is $\exp(\Omega(\log n / \log \log n))$.
</dc:description>
 <dc:description>Comment: 15 pages, Journal of Combinatorial Theory, Series A</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:date>2017-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.01002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.01006</identifier>
 <datestamp>2016-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Fully Convolutional and Recurrent Neural Networks for 3D
  Biomedical Image Segmentation</dc:title>
 <dc:creator>Chen, Jianxu</dc:creator>
 <dc:creator>Yang, Lin</dc:creator>
 <dc:creator>Zhang, Yizhe</dc:creator>
 <dc:creator>Alber, Mark</dc:creator>
 <dc:creator>Chen, Danny Z.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Segmentation of 3D images is a fundamental problem in biomedical image
analysis. Deep learning (DL) approaches have achieved state-of-the-art
segmentation perfor- mance. To exploit the 3D contexts using neural networks,
known DL segmentation methods, including 3D convolution, 2D convolution on
planes orthogonal to 2D image slices, and LSTM in multiple directions, all
suffer incompatibility with the highly anisotropic dimensions in common 3D
biomedical images. In this paper, we propose a new DL framework for 3D image
segmentation, based on a com- bination of a fully convolutional network (FCN)
and a recurrent neural network (RNN), which are responsible for exploiting the
intra-slice and inter-slice contexts, respectively. To our best knowledge, this
is the first DL framework for 3D image segmentation that explicitly leverages
3D image anisotropism. Evaluating using a dataset from the ISBI Neuronal
Structure Segmentation Challenge and in-house image stacks for 3D fungus
segmentation, our approach achieves promising results comparing to the known
DL-based 3D segmentation approaches.
</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:date>2016-09-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.01006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.01010</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Library Generation for Modular Polynomial Multiplication</dc:title>
 <dc:creator>Meng, Lingchuan</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  Polynomial multiplication is a key algorithm underlying computer algebra
systems (CAS) and its efficient implementation is crucial for the performance
of CAS. In this paper we design and implement algorithms for polynomial
multiplication using approaches based the fast Fourier transform (FFT) and the
truncated Fourier transform (TFT). We improve on the state-of-the-art in both
theoretical and practical performance. The {\SPIRAL} library generation system
is extended and used to automatically generate and tune the performance of a
polynomial multiplication library that is optimized for memory hierarchy,
vectorization and multi-threading, using new and existing algorithms. The
performance tuning has been aided by the use of automation where many code
choices are generated and intelligent search is utilized to find the &quot;best&quot;
implementation on a given architecture. The performance of autotuned
implementations is comparable to, and in some cases better than, the best
hand-tuned code.
</dc:description>
 <dc:description>Comment: 15 pages, 3 figures, based on the thesis work of Lingchuan Meng</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.01010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1609.01017</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crowdsourcing Information Extraction for Biomedical Systematic Reviews</dc:title>
 <dc:creator>Sun, Yalin</dc:creator>
 <dc:creator>Cheng, Pengxiang</dc:creator>
 <dc:creator>Wang, Shengwei</dc:creator>
 <dc:creator>Lyu, Hao</dc:creator>
 <dc:creator>Lease, Matthew</dc:creator>
 <dc:creator>Marshall, Iain</dc:creator>
 <dc:creator>Wallace, Byron C.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Information extraction is a critical step in the practice of conducting
biomedical systematic literature reviews. Extracted structured data can be
aggregated via methods such as statistical meta-analysis. Typically highly
trained domain experts extract data for systematic reviews. The high expense of
conducting biomedical systematic reviews has motivated researchers to explore
lower cost methods that achieve similar rigor without compromising quality.
Crowdsourcing represents one such promising approach. In this work-in-progress
study, we designed a crowdsourcing task for biomedical information extraction.
We briefly report the iterative design process and the results of two pilot
testings. We found that giving more concrete examples in the task instruction
can help workers better understand the task, especially for concepts that are
abstract and confusing. We found a few workers completed most of the work, and
our payment level appeared more attractive to workers from low-income
countries. In the future, we will further evaluate our results with reference
to gold standard extractions, thus assessing the feasibility of tasking crowd
workers with extracting biomedical intervention information for systematic
reviews.
</dc:description>
 <dc:description>Comment: HCOMP 2016 Work-in-Progress paper</dc:description>
 <dc:date>2016-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1609.01017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="104000" completeListSize="155308">2369777|105001</resumptionToken>
</ListRecords>
</OAI-PMH>
