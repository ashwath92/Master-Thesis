<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2018-01-29T02:53:59Z</responseDate>
<request verb="ListRecords" resumptionToken="2369777|75001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1503.06958</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Developing Educational Computer Animation Based on Human Personality
  Types</dc:title>
 <dc:creator>Musa, Sajid</dc:creator>
 <dc:creator>Ziatdinov, Rushan</dc:creator>
 <dc:creator>Sozcu, Omer Faruk</dc:creator>
 <dc:creator>Griffiths, Carol</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Computer animation in the past decade has become one of the most noticeable
features of technology-based learning environments. With today's high
educational demands as well as the lack of time provided for certain courses,
classical educational methods have shown deficiencies in keeping up with the
drastic changes observed in the digital era. Without taking into account
various significant factors such as gender, age, level of interest and memory
level, educational animation may turn out to be insufficient for learners or
fail to meet their needs. However, we have noticed that the applications of
animation for education have been given only inadequate attention, and
students' personality types have never been taken into account. We suggest
there is an interesting relationship here, and propose essential factors in
creating educational animations based on students' personality types.
Particularly, we investigate how information in computer animation may be
presented in a preferable way based on the fundamental elements of computer
animation. The present study believes that it is likely to have wide benefits
in the field of education. Considering the personality types in designing
educational computer animations with the aid of gathered empirical results
might be a promising avenue to enhance the learning process.
</dc:description>
 <dc:description>Comment: 19 pages, 19 figures, 18 tables</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.06958</dc:identifier>
 <dc:identifier>European Journal of Contemporary Education, 2015, Vol. 11, Issue
  1, pp. 52-71</dc:identifier>
 <dc:identifier>doi:10.13187/ejced.2015.11.52</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.06959</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast keypoint detection in video sequences</dc:title>
 <dc:creator>Baroffio, Luca</dc:creator>
 <dc:creator>Cesana, Matteo</dc:creator>
 <dc:creator>Redondi, Alessandro</dc:creator>
 <dc:creator>Tagliasacchi, Marco</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  A number of computer vision tasks exploit a succinct representation of the
visual content in the form of sets of local features. Given an input image,
feature extraction algorithms identify a set of keypoints and assign to each of
them a description vector, based on the characteristics of the visual content
surrounding the interest point. Several tasks might require local features to
be extracted from a video sequence, on a frame-by-frame basis. Although
temporal downsampling has been proven to be an effective solution for mobile
augmented reality and visual search, high temporal resolution is a key
requirement for time-critical applications such as object tracking, event
recognition, pedestrian detection, surveillance. In recent years, more and more
computationally efficient visual feature detectors and decriptors have been
proposed. Nonetheless, such approaches are tailored to still images. In this
paper we propose a fast keypoint detection algorithm for video sequences, that
exploits the temporal coherence of the sequence of keypoints. According to the
proposed method, each frame is preprocessed so as to identify the parts of the
input frame for which keypoint detection and description need to be performed.
Our experiments show that it is possible to achieve a reduction in
computational time of up to 40%, without significantly affecting the task
accuracy.
</dc:description>
 <dc:description>Comment: submitted to IEEE International Conference on Image Processing 2015</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.06959</dc:identifier>
 <dc:identifier>doi:10.1109/ICASSP.2016.7471895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.06960</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sample compression schemes for VC classes</dc:title>
 <dc:creator>Moran, Shay</dc:creator>
 <dc:creator>Yehudayoff, Amir</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Sample compression schemes were defined by Littlestone and Warmuth (1986) as
an abstraction of the structure underlying many learning algorithms. Roughly
speaking, a sample compression scheme of size $k$ means that given an arbitrary
list of labeled examples, one can retain only $k$ of them in a way that allows
to recover the labels of all other examples in the list. They showed that
compression implies PAC learnability for binary-labeled classes, and asked
whether the other direction holds. We answer their question and show that every
concept class $C$ with VC dimension $d$ has a sample compression scheme of size
exponential in $d$. The proof uses an approximate minimax phenomenon for binary
matrices of low VC dimension, which may be of interest in the context of game
theory.
</dc:description>
 <dc:description>Comment: 14 pages. The previous version of this text contained an error;
  Theorem 2.1 in it is false. This error only affects the statement for
  multi-labeled classes, and the construction for binary-labeled classes still
  holds. In the new version of the text, we added a relevant discussion in
  Section 4</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.06960</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.06962</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Binary-Mask Cocktail-Party Source Separation in a
  Convolutional Deep Neural Network</dc:title>
 <dc:creator>Simpson, Andrew J. R.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>68Txx</dc:subject>
 <dc:description>  Separation of competing speech is a key challenge in signal processing and a
feat routinely performed by the human auditory brain. A long standing benchmark
of the spectrogram approach to source separation is known as the ideal binary
mask. Here, we train a convolutional deep neural network, on a two-speaker
cocktail party problem, to make probabilistic predictions about binary masks.
Our results approach ideal binary mask performance, illustrating that
relatively simple deep neural networks are capable of robust binary mask
prediction. We also illustrate the trade-off between prediction statistics and
separation quality.
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.06962</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.06966</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multicast Multigroup Beamforming for Per-antenna Power Constrained
  Large-scale Arrays</dc:title>
 <dc:creator>Christopoulos, Dimitrios</dc:creator>
 <dc:creator>Chatzinotas, Symeon</dc:creator>
 <dc:creator>Ottersten, Bjorn</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Large in the number of transmit elements, multi-antenna arrays with
per-element limitations are in the focus of the present work. In this context,
physical layer multigroup multicasting under per-antenna power constrains, is
investigated herein. To address this complex optimization problem
low-complexity alternatives to semi-definite relaxation are proposed. The goal
is to optimize the per-antenna power constrained transmitter in a maximum
fairness sense, which is formulated as a non-convex quadratically constrained
quadratic problem. Therefore, the recently developed tool of feasible point
pursuit and successive convex approximation is extended to account for
practical per-antenna power constraints. Interestingly, the novel iterative
method exhibits not only superior performance in terms of approaching the
relaxed upper bound but also a significant complexity reduction, as the
dimensions of the optimization variables increase. Consequently, multicast
multigroup beamforming for large-scale array transmitters with per-antenna
dedicated amplifiers is rendered computationally efficient and accurate. A
preliminary performance evaluation in large-scale systems for which the
semi-definite relaxation constantly yields non rank-1 solutions is presented.
</dc:description>
 <dc:description>Comment: submitted to IEEE SPAWC 2015. arXiv admin note: substantial text
  overlap with arXiv:1406.7557</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.06966</dc:identifier>
 <dc:identifier>doi:10.1109/SPAWC.2015.7227042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.06970</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Straight Line Triangle Representations</dc:title>
 <dc:creator>Aerts, Nieke</dc:creator>
 <dc:creator>Felsner, Stefan</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A straight line triangle representation (SLTR) of a planar graph is a
straight line drawing such that all the faces including the outer face have
triangular shape. Such a drawing can be viewed as a tiling of a triangle using
triangles with the input graph as skeletal structure. In this paper we present
a characterization of graphs that have an SLTR. The characterization is based
on flat angle assignments, i.e., selections of angles of the graph that have
size~$\pi$ in the representation. We also provide a second characterization in
terms of contact systems of pseudosegments. With the aid of discrete harmonic
functions we show that contact systems of pseudosegments that respect certain
conditions are stretchable. The stretching procedure is then used to get
straight line triangle representations. Since the discrete harmonic function
approach is quite flexible it allows further applications, we mention some of
them. The drawback of the characterization of SLTRs is that we are not able to
effectively check whether a given graph admits a flat angle assignment that
fulfills the conditions. Hence it is still open to decide whether the
recognition of graphs that admit straight line triangle representation is
polynomially tractable.
</dc:description>
 <dc:description>Comment: An extended abstract of this paper was presented at GD2013</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.06970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.06973</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Slime Mould Inspired Generalised Voronoi Diagrams with Repulsive Fields</dc:title>
 <dc:creator>Jones, Jeff</dc:creator>
 <dc:creator>Adamatzky, Andrew</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  The giant single-celled amoeboid organism Physarum polycephalum constructs
minimising transport networks but can also approximate the Voronoi diagram
using two different mechanisms. In the first method Voronoi bisectors are rep-
resented by deformation of a pre-existing plasmodial network by repellent
sources acting as generating points. In the second method generating points act
as inoculation sites for grow- ing plasmodia and Voronoi bisectors are
represented by vacant regions before the plasmodia fuse. To explore the
behaviour of minimising networks in the presence of repulsion fields we utilise
a computational model of Physarum as a distributed virtual computing material.
We characterise the different types of computational behaviours elicited by
attraction and repulsion stimuli and demonstrate the approximation Voronoi
diagrams using growth towards attractants, avoidance of repellents, and
combinations of both. Approximation of Voronoi diagrams for point data sources,
complex planar shapes and circle sets is demonstrated. By altering repellent
con- centration we found that partition of data sources was maintained but the
internal network connectivity was minimised by the contractile force of the
transport network. To conclude, we find that the repertoire of unconventional
computation methods is enhanced by the addition of stimuli presented by
repellent fields, suggesting novel approaches to plane-division, packing, and
minimisation problems.
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.06973</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.06974</identifier>
 <datestamp>2015-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Challenges and Recommendations for Preparing HPC Applications for
  Exascale</dc:title>
 <dc:creator>Abraham, Erika</dc:creator>
 <dc:creator>Bekas, Costas</dc:creator>
 <dc:creator>Brandic, Ivona</dc:creator>
 <dc:creator>Genaim, Samir</dc:creator>
 <dc:creator>Johnsen, Einar Broch</dc:creator>
 <dc:creator>Kondov, Ivan</dc:creator>
 <dc:creator>Pllana, Sabri</dc:creator>
 <dc:creator>Streit, Achim</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  While the HPC community is working towards the development of the first
Exaflop computer (expected around 2020), after reaching the Petaflop milestone
in 2008 still only few HPC applications are able to fully exploit the
capabilities of Petaflop systems. In this paper we argue that efforts for
preparing HPC applications for Exascale should start before such systems become
available. We identify challenges that need to be addressed and recommend
solutions in key areas of interest, including formal modeling, static analysis
and optimization, runtime analysis and optimization, and autonomic computing.
Furthermore, we outline a conceptual framework for porting HPC applications to
future Exascale computing systems and propose steps for its implementation.
</dc:description>
 <dc:description>Comment: 18th International Conference on Network-Based Information Systems
  (NBiS 2015). 2-4 September 2015 in Tamkang, Taiwan</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2015-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.06974</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.06980</identifier>
 <datestamp>2016-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Event-Triggered Control over Unreliable Networks Subject to Jamming
  Attacks</dc:title>
 <dc:creator>Cetinkaya, Ahmet</dc:creator>
 <dc:creator>Ishii, Hideaki</dc:creator>
 <dc:creator>Hayakawa, Tomohisa</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Event-triggered networked control of a linear dynamical system is
investigated. Specifically, the dynamical system and the controller are assumed
to be connected through a communication channel. State and control input
information packets between the system and the controller are attempted to be
exchanged over the network only at time instants when certain triggering
conditions are satisfied. We provide a probabilistic characterization for the
link failures which allows us to model random packet losses due to
unreliability in transmissions as well as those caused by malicious jamming
attacks. We obtain conditions for the almost sure stability of the closed-loop
system, and we illustrate the efficacy of our approach with a numerical
example.
</dc:description>
 <dc:description>Comment: Presented at IEEE CDC 2015; Corrected author names in references
  [7],[11]; Corrected ranges of rho and tilde{p} in Lemma A.1; Corrected
  indices in (51)</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2016-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.06980</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.06981</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coordinated Multibeam Satellite Co-location: The Dual Satellite Paradigm</dc:title>
 <dc:creator>Christopoulos, Dimitrios</dc:creator>
 <dc:creator>Sharma, Shree Krishna</dc:creator>
 <dc:creator>Chatzinotas, Symeon</dc:creator>
 <dc:creator>Ottersten, Jens Krauseand Bjorn</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In the present article, a new system architecture for the next generation of
satellite communication (SatComs) is presented. The key concept lies in the
collaboration between multibeam satellites that share one orbital position.
Multi-satellite constellations in unique orbital slots offer gradual deployment
to cover unpredictable traffic patterns and redundancy to hardware failure
advantages. They are also of high relevance during the satellite replacement
phases or necessitated by constraints in the maximum communications payload
that a single satellite can bear. In this context, the potential gains of
advanced architectures, that is architectures enabled by the general class of
cooperative and cognitive techniques, are exhibited via a simple paradigm. More
specifically, the scenario presented herein, involves two co-existing multibeam
satellites which illuminate overlapping coverage areas. Based on this scenario,
specific types of cooperative and cognitive techniques are herein considered as
candidate technologies that can boost the performance of multibeam satellite
constellations. These techniques are compared to conventional frequency
splitting configurations in terms of three different criteria, namely the
spectral efficiency, the power efficiency and the fairness. Consequently,
insightful guidelines for the design of future high throughput constellations
of multibeam satellites are given.
</dc:description>
 <dc:description>Comment: Submitted to the IEEE wirless. Comms. Magazine</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.06981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.06982</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Output Feedback Control of Inhomogeneous Parabolic PDEs with Point
  Actuation and Point Measurement using SOS and Semi-Separable Kernels</dc:title>
 <dc:creator>Gahlawat, Aditya</dc:creator>
 <dc:creator>Peet, Matthew M.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper we use SOS and SDP to design output feedback controllers for a
class of one-dimensional parabolic partial differential equations with point
measurements and point actuation. Our approach is based on the use of SOS to
search for positive quadratic Lyapunov functions, controllers and observers.
These Lyapunov functions, controllers and observers are parameterized by linear
operators which are defined by SOS polynomials. The main result of the paper is
the development of an improved class of observer-based controllers and evidence
which indicates that when the system is controllable and observable, these
methods will find a observer-based controller for sufficiently high polynomial
degree (similar to well-known results from backstepping).
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.06982</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.06995</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpolation of a spline developable surface between a curve and two
  rulings</dc:title>
 <dc:creator>Cant&#xf3;n, A.</dc:creator>
 <dc:creator>Fern&#xe1;ndez-Jambrina, L.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65D17, 68U07</dc:subject>
 <dc:description>  In this paper we address the problem of interpolating a spline developable
patch bounded by a given spline curve and the first and the last rulings of the
developable surface. In order to complete the boundary of the patch a second
spline curve is to be given. Up to now this interpolation problem could be
solved, but without the possibility of choosing both endpoints for the rulings.
We circumvent such difficulty here by resorting to degree elevation of the
developable surface. This is useful not only to solve this problem, but also
other problems dealing with triangular developable patches.
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.06995</dc:identifier>
 <dc:identifier>Frontiers of Information Technology &amp; Electronic Engineering 16,
  173-190 (2015)</dc:identifier>
 <dc:identifier>doi:10.1631/FITEE.14a0210</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07000</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Thermal Covert Channels on Multi-core Platforms</dc:title>
 <dc:creator>Masti, Ramya Jayaram</dc:creator>
 <dc:creator>Rai, Devendra</dc:creator>
 <dc:creator>Ranganathan, Aanjhan</dc:creator>
 <dc:creator>M&#xfc;ller, Christian</dc:creator>
 <dc:creator>Thiele, Lothar</dc:creator>
 <dc:creator>Capkun, Srdjan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Side channels remain a challenge to information flow control and security in
modern computing platforms. Resource partitioning techniques that minimise the
number of shared resources among processes are often used to address this
challenge. In this work, we focus on multi-core platforms and we demonstrate
that even seemingly strong isolation techniques based on dedicated cores and
memory can be circumvented through the use of thermal side channels.
Specifically, we show that the processor core temperature can be used both as a
side channel as well as a covert communication channel even when the system
implements strong spatial and temporal partitioning. Our experiments on an
x86-based platform demonstrate covert thermal channels that achieve up to 12.5
bps and a weak side channel that can detect processes executed on neighbouring
cores. This work therefore shows a limitation in the isolation that can be
achieved on existing multi-core systems.
</dc:description>
 <dc:description>Comment: 15 pages, 9 figures</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07001</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GerAPlanO - A new building design tool: design generation, thermal
  assessment and performance optimization</dc:title>
 <dc:creator>Rodrigues, Eug&#xe9;nio</dc:creator>
 <dc:creator>Amaral, Ana Rita</dc:creator>
 <dc:creator>Gaspar, Ad&#xe9;lio Rodrigues</dc:creator>
 <dc:creator>Gomes, &#xc1;lvaro</dc:creator>
 <dc:creator>da Silva, Manuel Carlos Gameiro</dc:creator>
 <dc:creator>Antunes, Carlos Henggeler</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>68N01</dc:subject>
 <dc:description>  Building practitioners (architects, engineers, energy managers) are showing a
growing interest in the design of more energy efficient and livable buildings.
The best way to predict how a building will behave regarding energy consumption
and thermal comfort is to use a dynamic simulation tool. However, the use of
this kind of tools is difficult on a daily basis practice due to the heuristic
and exploratory nature of the architectural design process. To deal with this
difficulty, the University of Coimbra and three companies have been working on
the development of a prototype design aiding tool, specifically devoted to the
space planning phase of building design, under the project GerAPlanO (Automatic
Generation of Architecture Floor plans with Energy Optimization). This project
aims to combine the capabilities of design generation techniques, thermal
assessment programs, and design optimization methods to provide assistance to
decision makers. This paper presents the overall concept, as well as the
current status of development of this tool.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, Proceedings of Energy for Sustainability 2015
  Conference: Sustainable Cities: Designing for People and the Planet, Coimbra,
  14-15 May, 2015</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07015</identifier>
 <datestamp>2015-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Monaural Speech Enhancement Based on Periodicity Analysis and A
  Priori SNR Estimation</dc:title>
 <dc:creator>Chen, Zhangli</dc:creator>
 <dc:creator>Hohmann, Volker</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  This paper describes an online algorithm for enhancing monaural noisy speech.
Firstly, a novel phase-corrected low-delay gammatone filterbank is derived for
signal subband decomposition and resynthesis; the subband signals are then
analyzed frame by frame. Secondly, a novel feature named periodicity degree
(PD) is proposed to be used for detecting and estimating the fundamental period
(P0) in each frame and for estimating the signal-to-noise ratio (SNR) in each
frame-subband signal unit. The PD is calculated in each unit as the
multiplication of the normalized autocorrelation and the comb filter ratio, and
shown to be robust in various low-SNR conditions. Thirdly, the noise energy
level in each signal unit is estimated recursively based on the estimated SNR
for units with high PD and based on the noisy signal energy level for units
with low PD. Then the a priori SNR is estimated using a decision-directed
approach with the estimated noise level. Finally, a revised Wiener gain is
calculated, smoothed, and applied to each unit; the processed units are summed
across subbands and frames to form the enhanced signal. The P0 detection
accuracy of the algorithm was evaluated on two corpora and showed comparable
performance on one corpus and better performance on the other corpus when
compared to a recently published pitch detection algorithm. The speech
enhancement effect of the algorithm was evaluated on one corpus with two
objective criteria and showed better performance in one highly non-stationary
noise and comparable performance in two other noises when compared to a
state-of-the-art statistical-model based algorithm.
</dc:description>
 <dc:description>Comment: 13 pages, 12 figures</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2015-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07016</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A parametric study of window-to-floor ratio of three window types using
  dynamic simulation</dc:title>
 <dc:creator>Amaral, Ana Rita</dc:creator>
 <dc:creator>Rodrigues, Eug&#xe9;nio</dc:creator>
 <dc:creator>Gaspar, Ad&#xe9;lio Rodrigues</dc:creator>
 <dc:creator>Gomes, &#xc1;lvaro</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>68U20</dc:subject>
 <dc:description>  The windows can be responsible for unnecessary energy consumption in a
building, if incorrectly designed, shadowed or oriented. Considering an annual
thermal comfort assessment of a space, if windows are over-dimensioned, they
can contribute to the increase of the heating needs due to heat losses, and
also to the increase of cooling needs due to over-exposure to solar radiation.
When under-dimensioned, the same space may benefit from reduced heat losses
through the glazing surface but does not benefit from solar radiation gains.
Therefore, it is important to find the optimum design that minimizes both the
heating and cooling needs. This paper presents a parametric study of window
type (single, double and triple glazing), orientation and opening size, located
in the city of Coimbra, Portugal. An annual and a seasonal assessment were
done, in order to obtain the set of optimum values around 360 degree
orientation.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures, Proceedings of Energy for Sustainability 2015
  Conference: Sustainable Cities: Designing for People and the Planet, Coimbra,
  14-15 May, 2015</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07017</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Emergence of Norms via Contextual Agreements in Open Societies</dc:title>
 <dc:creator>Vouros, George</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  This paper explores the emergence of norms in agents' societies when agents
play multiple -even incompatible- roles in their social contexts
simultaneously, and have limited interaction ranges. Specifically, this article
proposes two reinforcement learning methods for agents to compute agreements on
strategies for using common resources to perform joint tasks. The computation
of norms by considering agents' playing multiple roles in their social contexts
has not been studied before. To make the problem even more realistic for open
societies, we do not assume that agents share knowledge on their common
resources. So, they have to compute semantic agreements towards performing
their joint actions. %The paper reports on an empirical study of whether and
how efficiently societies of agents converge to norms, exploring the proposed
social learning processes w.r.t. different society sizes, and the ways agents
are connected. The results reported are very encouraging, regarding the speed
of the learning process as well as the convergence rate, even in quite complex
settings.
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07021</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimal Reachability Problems</dc:title>
 <dc:creator>Tzoumas, Vasileios</dc:creator>
 <dc:creator>Jadbabaie, Ali</dc:creator>
 <dc:creator>Pappas, George J.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we address a collection of state space reachability problems,
for linear time-invariant systems, using a minimal number of actuators. In
particular, we design a zero-one diagonal input matrix B, with a minimal number
of non-zero entries, so that a specified state vector is reachable from a given
initial state. Moreover, we design a B so that a system can be steered either
into a given subspace, or sufficiently close to a desired state. This work
extends the recent results of Olshevsky and Pequito, where a zero-one diagonal
or column matrix B is constructed so that the involved system is controllable.
Specifically, we prove that the first two of our aforementioned problems are
NP-hard; these results hold for a zero-one column matrix B as well. Then, we
provide efficient polynomial time algorithms for their general solution, along
with their worst case approximation guarantees. Finally, we illustrate their
performance over large random networks.
</dc:description>
 <dc:description>Comment: Final version (with missing proofs) that appeared in CDC 2015</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07025</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Property-based Polynomial Invariant Generation using Sums-of-Squares
  Optimization</dc:title>
 <dc:creator>Adj&#xe9;, Assal&#xe9;</dc:creator>
 <dc:creator>Garoche, Pierre-Lo&#xef;c</dc:creator>
 <dc:creator>Magron, Victor</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  While abstract interpretation is not theoretically restricted to specific
kinds of properties, it is, in practice, mainly developed to compute linear
over-approximations of reachable sets, aka. the collecting semantics of the
program. The verification of user-provided properties is not easily compatible
with the usual forward fixpoint computation using numerical abstract domains.
We propose here to rely on sums-of-squares programming to characterize a
property-driven polynomial invariant. This invariant generation can be guided
by either boundedness, or in contrary, a given zone of the state space to
avoid. While the target property is not necessarily inductive with respect to
the program semantics, our method identifies a stronger inductive polynomial
invariant using numerical optimization. Our method applies to a wide set of
programs: a main while loop composed of a disjunction (if-then-else) of
polynomial updates e.g. piecewise polynomial controllers. It has been evaluated
on various programs.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1409.3941</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07026</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A new model-free design for vehicle control and its validation through
  an advanced simulation platform</dc:title>
 <dc:creator>Menhour, Lghani</dc:creator>
 <dc:creator>D'Andr&#xe9;a-Novel, Brigitte</dc:creator>
 <dc:creator>Fliess, Michel</dc:creator>
 <dc:creator>Gruyer, Dominique</dc:creator>
 <dc:creator>Mounier, Hugues</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  A new model-free setting and the corresponding &quot;intelligent&quot; P and PD
controllers are employed for the longitudinal and lateral motions of a vehicle.
This new approach has been developed and used in order to ensure simultaneously
a best profile tracking for the longitudinal and lateral behaviors. The
longitudinal speed and the derivative of the lateral deviation, on one hand,
the driving/braking torque and the steering angle, on the other hand, are
respectively the output and the input variables. Let us emphasize that a &quot;good&quot;
mathematical modeling, which is quite difficult, if not impossible to obtain,
is not needed for such a design. An important part of this publication is
focused on the presentation of simulation results with actual and virtual data.
The actual data, used in Matlab as reference trajectories, have been obtained
from a properly instrumented car (Peugeot 406). Other virtual sets of data have
been generated through the interconnected platform SiVIC/RTMaps. It is a
dedicated virtual simulation platform for prototyping and validation of
advanced driving assistance systems. Keywords- Longitudinal and lateral vehicle
control, model-free control, intelligent P controller (i-P controller),
algebraic estimation, ADAS (Advanced Driving Assistance Systems).
</dc:description>
 <dc:description>Comment: in 14th European Control Conference, Jul 2015, Linz, Austria. 2015</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07027</identifier>
 <datestamp>2016-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence radius and sample complexity of ITKM algorithms for
  dictionary learning</dc:title>
 <dc:creator>Schnass, Karin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work we show that iterative thresholding and K-means (ITKM)
algorithms can recover a generating dictionary with K atoms from noisy $S$
sparse signals up to an error $\tilde \varepsilon$ as long as the
initialisation is within a convergence radius, that is up to a $\log K$ factor
inversely proportional to the dynamic range of the signals, and the sample size
is proportional to $K \log K \tilde \varepsilon^{-2}$. The results are valid
for arbitrary target errors if the sparsity level is of the order of the square
root of the signal dimension $d$ and for target errors down to $K^{-\ell}$ if
$S$ scales as $S \leq d/(\ell \log K)$.
</dc:description>
 <dc:description>Comment: 34 pages, 2 figures</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2016-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07038</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A QoS aware Novel Probabilistic strategy for Dynamic Resource Allocation</dc:title>
 <dc:creator>Kumar, G Arun</dc:creator>
 <dc:creator>Saha, Snehanshu</dc:creator>
 <dc:creator>Sundaresan, Aravind</dc:creator>
 <dc:creator>Goswami, Bidisha</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The paper proposes a two player game based strategy for resource allocation
in service computing domain such as cloud, grid etc. The players are modeled as
demand/workflows for the resource and represent multiple types of qualitative
and quantitative factors. The proposed strategy will classify them in two
classes. The proposed system would forecast outcome using a priori information
available and measure/estimate existing parameters such as utilization and
delay in an optimal load-balanced paradigm.
  Keywords: Load balancing; service computing; Logistic Regression;
probabilistic estimation
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07073</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Overhauling SC Atomics in C11 and OpenCL</dc:title>
 <dc:creator>Batty, Mark</dc:creator>
 <dc:creator>Donaldson, Alastair F.</dc:creator>
 <dc:creator>Wickerson, John</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  Despite the conceptual simplicity of sequential consistency (SC), the
semantics of SC atomic operations and fences in the C11 and OpenCL memory
models is subtle, leading to convoluted prose descriptions that translate to
complex axiomatic formalisations. We conduct an overhaul of SC atomics in C11,
reducing the associated axioms in both number and complexity. A consequence of
our simplification is that the SC operations in an execution no longer need to
be totally ordered. This relaxation enables, for the first time, efficient and
exhaustive simulation of litmus tests that use SC atomics. We extend our
improved C11 model to obtain the first rigorous memory model formalisation for
OpenCL (which extends C11 with support for heterogeneous many-core
programming). In the OpenCL setting, we refine the SC axioms still further to
give a sensible semantics to SC operations that employ a 'memory scope' to
restrict their visibility to specific threads. Our overhaul requires slight
strengthenings of both the C11 and the OpenCL memory models, causing some
behaviours to become disallowed. We argue that these strengthenings are
natural, and that all of the formalised C11 and OpenCL compilation schemes of
which we are aware (Power and x86 CPUs for C11, AMD GPUs for OpenCL) remain
valid in our revised models. Using the Herd memory model simulator, we show
that our overhaul leads to an exponential improvement in simulation time for
C11 litmus tests compared with the original model, making exhaustive simulation
competitive, time-wise, with the non-exhaustive CDSChecker tool.
</dc:description>
 <dc:description>Comment: Published in the proceedings of the 43rd Annual ACM SIGPLAN-SIGACT
  Symposium on Principles of Programming Languages (POPL), 2016</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07073</dc:identifier>
 <dc:identifier>ACM SIGPLAN Notices - POPL '16. Volume 51, Issue 1, January 2016</dc:identifier>
 <dc:identifier>doi:10.1145/2837614.2837637</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07077</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rotation-invariant convolutional neural networks for galaxy morphology
  prediction</dc:title>
 <dc:creator>Dieleman, Sander</dc:creator>
 <dc:creator>Willett, Kyle W.</dc:creator>
 <dc:creator>Dambre, Joni</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Astrophysics - Astrophysics of Galaxies</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Measuring the morphological parameters of galaxies is a key requirement for
studying their formation and evolution. Surveys such as the Sloan Digital Sky
Survey (SDSS) have resulted in the availability of very large collections of
images, which have permitted population-wide analyses of galaxy morphology.
Morphological analysis has traditionally been carried out mostly via visual
inspection by trained experts, which is time-consuming and does not scale to
large ($\gtrsim10^4$) numbers of images.
  Although attempts have been made to build automated classification systems,
these have not been able to achieve the desired level of accuracy. The Galaxy
Zoo project successfully applied a crowdsourcing strategy, inviting online
users to classify images by answering a series of questions. Unfortunately,
even this approach does not scale well enough to keep up with the increasing
availability of galaxy images.
  We present a deep neural network model for galaxy morphology classification
which exploits translational and rotational symmetry. It was developed in the
context of the Galaxy Challenge, an international competition to build the best
model for morphology classification based on annotated images from the Galaxy
Zoo project.
  For images with high agreement among the Galaxy Zoo participants, our model
is able to reproduce their consensus with near-perfect accuracy ($&gt; 99\%$) for
most questions. Confident model predictions are highly accurate, which makes
the model suitable for filtering large collections of images and forwarding
challenging images to experts for manual annotation. This approach greatly
reduces the experts' workload without affecting accuracy. The application of
these algorithms to larger sets of training data will be critical for analysing
results from future surveys such as the LSST.
</dc:description>
 <dc:description>Comment: Accepted for publication in MNRAS. 20 pages, 14 figures</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07077</dc:identifier>
 <dc:identifier>doi:10.1093/mnras/stv632</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07082</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recognition and Complexity of Point Visibility Graphs</dc:title>
 <dc:creator>Cardinal, Jean</dc:creator>
 <dc:creator>Hoffmann, Udo</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  A point visibility graph is a graph induced by a set of points in the plane,
where every vertex corresponds to a point, and two vertices are adjacent
whenever the two corresponding points are visible from each other, that is, the
open segment between them does not contain any other point of the set. We study
the recognition problem for point visibility graphs: given a simple undirected
graph, decide whether it is the visibility graph of some point set in the
plane. We show that the problem is complete for the existential theory of the
reals. Hence the problem is as hard as deciding the existence of a real
solution to a system of polynomial inequalities. The proof involves simple
substructures forcing collinearities in all realizations of some visibility
graphs, which are applied to the algebraic universality constructions of Mn\&quot;ev
and Richter-Gebert. This solves a longstanding open question and paves the way
for the analysis of other classes of visibility graphs. Furthermore, as a
corollary of one of our construction, we show that there exist point visibility
graphs that do not admit any geometric realization with points having integer
coordinates.
</dc:description>
 <dc:description>Comment: 16 pages, 10 figures. To appear in Proceedings of SoCG 2015</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07082</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07092</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Big Data and the Internet of Things</dc:title>
 <dc:creator>Shah, Mohak</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Advances in sensing and computing capabilities are making it possible to
embed increasing computing power in small devices. This has enabled the sensing
devices not just to passively capture data at very high resolution but also to
take sophisticated actions in response. Combined with advances in
communication, this is resulting in an ecosystem of highly interconnected
devices referred to as the Internet of Things - IoT. In conjunction, the
advances in machine learning have allowed building models on this ever
increasing amounts of data. Consequently, devices all the way from heavy assets
such as aircraft engines to wearables such as health monitors can all now not
only generate massive amounts of data but can draw back on aggregate analytics
to &quot;improve&quot; their performance over time. Big data analytics has been
identified as a key enabler for the IoT. In this chapter, we discuss various
avenues of the IoT where big data analytics either is already making a
significant impact or is on the cusp of doing so. We also discuss social
implications and areas of concern.
</dc:description>
 <dc:description>Comment: 33 pages. draft of upcoming book chapter in Japkowicz and Stefanowski
  (eds.) Big Data Analysis: New algorithms for a new society, Springer Series
  on Studies in Big Data, to appear</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07093</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Complexity of Nondeterministically Testable Hypergraph Parameters</dc:title>
 <dc:creator>Karpinski, Marek</dc:creator>
 <dc:creator>Mark&#xf3;, Roland</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The paper proves the equivalence of the notions of nondeterministic and
deterministic parameter testing for uniform dense hypergraphs of arbitrary
order. It generalizes the result previously known only for the case of simple
graphs. By a similar method we establish also the equivalence between
nondeterministic and deterministic hypergraph property testing, answering the
open problem in the area. We introduce a new notion of a cut norm for
hypergraphs of higher order, and employ regularity techniques combined with the
ultralimit method.
</dc:description>
 <dc:description>Comment: 33 pages</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07104</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Spectrum Occupancy Using Machine Learning Algorithms</dc:title>
 <dc:creator>Azmat, Freeha</dc:creator>
 <dc:creator>Chen, Yunfei</dc:creator>
 <dc:creator>Stocks, Nigel</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we analyze the spectrum occupancy using different machine
learning techniques. Both supervised techniques (naive Bayesian classifier
(NBC), decision trees (DT), support vector machine (SVM), linear regression
(LR)) and unsupervised algorithm (hidden markov model (HMM)) are studied to
find the best technique with the highest classification accuracy (CA). A
detailed comparison of the supervised and unsupervised algorithms in terms of
the computational time and classification accuracy is performed. The classified
occupancy status is further utilized to evaluate the probability of secondary
user outage for the future time slots, which can be used by system designers to
define spectrum allocation and spectrum sharing policies. Numerical results
show that SVM is the best algorithm among all the supervised and unsupervised
classifiers. Based on this, we proposed a new SVM algorithm by combining it
with fire fly algorithm (FFA), which is shown to outperform all other
algorithms.
</dc:description>
 <dc:description>Comment: 21 pages, 6 figures</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07118</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Reverse Pinsker Inequalities</dc:title>
 <dc:creator>Sason, Igal</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  New upper bounds on the relative entropy are derived as a function of the
total variation distance. One bound refines an inequality by Verd\'{u} for
general probability measures. A second bound improves the tightness of an
inequality by Csisz\'{a}r and Talata for arbitrary probability measures that
are defined on a common finite set. The latter result is further extended, for
probability measures on a finite set, leading to an upper bound on the
R\'{e}nyi divergence of an arbitrary non-negative order (including $\infty$) as
a function of the total variation distance. Another lower bound by Verd\'{u} on
the total variation distance, expressed in terms of the distribution of the
relative information, is tightened and it is attained under some conditions.
The effect of these improvements is exemplified.
</dc:description>
 <dc:description>Comment: Version 3 has been submitted to the IEEE Trans. on Information
  Theory, March 2015. Version 4 includes a refinement of the inequalities in
  Theorems 3 and 4 with a new appendix that is included for this purpose, and a
  revision of Section III-B (in respect to these latter refinements). There is
  a text overlap with arXiv:1503.03417 and 1502.06428</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07122</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On damping created by heterogeneous yielding in the numerical analysis
  of nonlinear reinforced concrete frame elements</dc:title>
 <dc:creator>Jehel, Pierre</dc:creator>
 <dc:creator>Cottereau, R&#xe9;gis</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  In the dynamic analysis of structural engineering systems, it is common
practice to introduce damping models to reproduce experimentally observed
features. These models, for instance Rayleigh damping, account for the damping
sources in the system altogether and often lack physical basis. We report on an
alternative path for reproducing damping coming from material nonlinear
response through the consideration of the heterogeneous character of material
mechanical properties. The parameterization of that heterogeneity is performed
through a stochastic model. It is shown that such a variability creates the
patterns in the concrete cyclic response that are classically regarded as
source of damping.
</dc:description>
 <dc:date>2015-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07122</dc:identifier>
 <dc:identifier>Computers &amp; Structures, Elsevier, 2015, pp.2015.03.001</dc:identifier>
 <dc:identifier>doi:10.1016/j.compstruc.2015.03.001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07125</identifier>
 <datestamp>2016-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Attack Detection in Cyber-Physical Systems with Side Initial
  State Information</dc:title>
 <dc:creator>Chen, Yuan</dc:creator>
 <dc:creator>Kar, Soummya</dc:creator>
 <dc:creator>Moura, Jose' M. F.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper studies the impact of side initial state information on the
detectability of data deception attacks against cyber-physical systems. We
assume the attack detector has access to a linear function of the initial
system state that cannot be altered by an attacker. First, we provide a
necessary and sufficient condition for an attack to be undetectable by any
dynamic attack detector under each specific side information pattern. Second,
we characterize attacks that can be sustained for arbitrarily long periods
without being detected. Third, we define the zero state inducing attack, the
only type of attack that remains dynamically undetectable regardless of the
side initial state information available to the attack detector. Finally, we
design a dynamic attack detector that detects detectable attacks.
</dc:description>
 <dc:description>Comment: Submitted. Initial Submission: Mar. 2015</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2016-06-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07132</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pragmatic Requirements for Adaptive Systems: a Goal-Driven Modelling and
  Analysis Approach</dc:title>
 <dc:creator>Guimar&#xe3;es, Felipe Pontes</dc:creator>
 <dc:creator>Rodrigues, Genaina Nunes</dc:creator>
 <dc:creator>Ali, Raian</dc:creator>
 <dc:creator>Batista, Daniel Mac&#xea;do</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Goal-models (GM) have been used in adaptive systems engineering for their
ability to capture the different ways to fulfill the requirements. Contextual
GM (CGM) extend these models with the notion of context and context-dependent
applicability of goals. In this paper, we observe that the interpretation of a
goal achievement is itself context-dependent. Thus, we introduce the notion of
Pragmatic Goals which have a dynamic satisfaction criteria. We also developed
and evaluated an algorithm to decide the Pragmatic CGM's achievability.
Finally, we performed several experiments to evaluate and to compare our
algorithm against human judgment and concluded that the specification of
context-dependent goals' applicability and interpretations make it hard for
domain stakeholders to decide whether the model covers all possibilities, both
in terms of time and accuracy, thus showing the importance and contribution of
our algorithm.
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07133</identifier>
 <datestamp>2015-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cost-Optimal Switching Protection Strategy in Adaptive Networks</dc:title>
 <dc:creator>Ogura, Masaki</dc:creator>
 <dc:creator>Preciado, Victor M.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, we study a model of network adaptation mechanism to control
spreading processes over switching contact networks, called adaptive
susceptible-infected-susceptible model. The edges in the network model are
randomly removed or added depending on the risk of spread through them. By
analyzing the joint evolution of the spreading dynamics &quot;in the network&quot; and
the structural dynamics &quot;of the network&quot;, we derive conditions on the
adaptation law to control the dynamics of the spread in the resulting switching
network. In contrast with the results in the literature, we allow the initial
topology of the network to be an arbitrary graph. Furthermore, assuming there
is a cost associated to switching edges in the network, we propose an
optimization framework to find the cost-optimal network adaptation law, i.e.,
the cost-optimal edge switching probabilities. Under certain conditions on the
switching costs, we show that the optimal adaptation law can be found using
convex optimization. We illustrate our results with numerical simulations.
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2015-09-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07139</identifier>
 <datestamp>2015-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparing Asynchronous $l$-Complete Approximations and Quotient Based
  Abstractions</dc:title>
 <dc:creator>Schmuck, Anne-Kathrin</dc:creator>
 <dc:creator>Tabuada, Paulo</dc:creator>
 <dc:creator>Raisch, J&#xf6;rg</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This paper is concerned with a detailed comparison of two different
abstraction techniques for the construction of finite state symbolic models for
controller synthesis of hybrid systems. Namely, we compare quotient based
abstractions (QBA), with different realizations of strongest (asynchronous)
$l$-complete approximations (SAlCA) Even though the idea behind their
construction is very similar, we show that they are generally incomparable both
in terms of behavioral inclusion and similarity relations. We therefore derive
necessary and sufficient conditions for QBA to coincide with particular
realizations of SAlCA. Depending on the original system, either QBA or SAlCA
can be a tighter abstraction.
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2015-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07143</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Connectivity Analysis for Multi-Agent Systems</dc:title>
 <dc:creator>Boskos, Dimitris</dc:creator>
 <dc:creator>Dimarogonas, Dimos V.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this report we provide a decentralized robust control approach, which
guarantees that connectivity of a multi-agent network is maintained when
certain bounded input terms are added to the control strategy. Our main
motivation for this framework is to determine abstractions for multi-agent
systems under coupled constraints which are further exploited for high level
plan generation.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07143</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07150</identifier>
 <datestamp>2015-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Acoustic event detection for multiple overlapping similar sources</dc:title>
 <dc:creator>Stowell, Dan</dc:creator>
 <dc:creator>Clayton, David</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Many current paradigms for acoustic event detection (AED) are not adapted to
the organic variability of natural sounds, and/or they assume a limit on the
number of simultaneous sources: often only one source, or one source of each
type, may be active. These aspects are highly undesirable for applications such
as bird population monitoring. We introduce a simple method modelling the
onsets, durations and offsets of acoustic events to avoid intrinsic limits on
polyphony or on inter-event temporal patterns. We evaluate the method in a case
study with over 3000 zebra finch calls. In comparison against a HMM-based
method we find it more accurate at recovering acoustic events, and more robust
for estimating calling rates.
</dc:description>
 <dc:description>Comment: Accepted for WASPAA 2015</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2015-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07150</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07158</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-Driven Power Control for State Estimation: A Bayesian Inference
  Approach</dc:title>
 <dc:creator>Wu, Junfeng</dc:creator>
 <dc:creator>Li, Yuzhe</dc:creator>
 <dc:creator>Quevedo, Daniel E.</dc:creator>
 <dc:creator>Lau, Vincent</dc:creator>
 <dc:creator>Shi, Ling</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We consider sensor transmission power control for state estimation, using a
Bayesian inference approach. A sensor node sends its local state estimate to a
remote estimator over an unreliable wireless communication channel with random
data packet drops. As related to packet dropout rate, transmission power is
chosen by the sensor based on the relative importance of the local state
estimate. The proposed power controller is proved to preserve Gaussianity of
local estimate innovation, which enables us to obtain a closed-form solution of
the expected state estimation error covariance. Comparisons with alternative
non data-driven controllers demonstrate performance improvement using our
approach.
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07158</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07159</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling context and situations in pervasive computing environments</dc:title>
 <dc:creator>Bhargava, Preeti</dc:creator>
 <dc:creator>Krishnamoorthy, Shivsubramani</dc:creator>
 <dc:creator>Agrawala, Ashok</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  In pervasive computing environments, various entities often have to cooperate
and integrate seamlessly in a \emph{situation} which can, thus, be considered
as an amalgamation of the context of several entities interacting and
coordinating with each other, and often performing one or more activities.
However, none of the existing context models and ontologies address situation
modeling. In this paper, we describe the design, structure and implementation
of a generic, flexible and extensible context ontology called Rover Context
Model Ontology (RoCoMO) for context and situation modeling in pervasive
computing systems and environments. We highlight several limitations of the
existing context models and ontologies, such as lack of provision for
provenance, traceability, quality of context, multiple representation of
contextual information, as well as support for security, privacy and
interoperability, and explain how we are addressing these limitations in our
approach. We also illustrate the applicability and utility of RoCoMO using a
practical and extensive case study.
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07160</identifier>
 <datestamp>2016-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Analytical Tractability of Hexagonal Network Model with Random
  User Location</dc:title>
 <dc:creator>Nasri, Ridha</dc:creator>
 <dc:creator>Jaziri, Aymen</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Explicit derivation of interferences in hexagonal wireless networks has been
widely considered intractable and requires extensive computations with system
level simulations. In this paper, we fundamentally tackle this problem and
explicitly evaluate the downlink Interference-to-Signal Ratio (ISR) for any
mobile location $m$ in a hexagonal wireless network, whether composed of
omni-directional or tri-sectorized sites. The explicit formula of ISR is a very
convergent series on $m$ and involves the use of Gauss hypergeometric and
Hurwitz Riemann zeta functions. Besides, we establish simple identities that
well approximate this convergent series and turn out quite useful compared to
other approximations in literature. The derived expression of ISR is easily
extended to any frequency reuse pattern. Moreover, it is also exploited in the
derivation of an explicit form of SINR distribution for any arbitrary
distribution of mobile user locations, reflecting the spatial traffic density
in the network. Knowing explicitly about interferences and SINR distribution is
very useful information in capacity and coverage planning of wireless cellular
networks and particularly for macro-cells' layer that forms almost a regular
point pattern.
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2016-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07160</dc:identifier>
 <dc:identifier>IEEE Transactions on Wireless Communications, vol. 15, no. 5, pp.
  3768-3780, 2016</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2016.2528245</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07170</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Integer Linear Programming Solution to the Telescope Network
  Scheduling Problem</dc:title>
 <dc:creator>Lampoudi, Sotiria</dc:creator>
 <dc:creator>Saunders, Eric</dc:creator>
 <dc:creator>Eastman, Jason</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Telescope networks are gaining traction due to their promise of higher
resource utilization than single telescopes and as enablers of novel
astronomical observation modes. However, as telescope network sizes increase,
the possibility of scheduling them completely or even semi-manually disappears.
In an earlier paper, a step towards software telescope scheduling was made with
the specification of the Reservation formalism, through the use of which
astronomers can express their complex observation needs and preferences. In
this paper we build on that work. We present a solution to the discretized
version of the problem of scheduling a telescope network. We derive a solvable
integer linear programming (ILP) model based on the Reservation formalism. We
show computational results verifying its correctness, and confirm that our
Gurobi-based implementation can address problems of realistic size. Finally, we
extend the ILP model to also handle the novel observation requests that can be
specified using the more advanced Compound Reservation formalism.
</dc:description>
 <dc:description>Comment: Accepted for publication in the refereed conference proceedings of
  the International Conference on Operations Research and Enterprise Systems
  (ICORES 2015)</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07170</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07189</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal control in Markov decision processes via distributed
  optimization</dc:title>
 <dc:creator>Fu, Jie</dc:creator>
 <dc:creator>Han, Shuo</dc:creator>
 <dc:creator>Topcu, Ufuk</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>90C40</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  Optimal control synthesis in stochastic systems with respect to quantitative
temporal logic constraints can be formulated as linear programming problems.
However, centralized synthesis algorithms do not scale to many practical
systems. To tackle this issue, we propose a decomposition-based distributed
synthesis algorithm. By decomposing a large-scale stochastic system modeled as
a Markov decision process into a collection of interacting sub-systems, the
original control problem is formulated as a linear programming problem with a
sparse constraint matrix, which can be solved through distributed optimization
methods. Additionally, we propose a decomposition algorithm which automatically
exploits, if exists, the modular structure in a given large-scale system. We
illustrate the proposed methods through robotic motion planning examples.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, submitted to CDC 2015 conference</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07192</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shortest-Path Queries in Planar Graphs on GPU-Accelerated Architectures</dc:title>
 <dc:creator>Chapuis, Guillaume</dc:creator>
 <dc:creator>Djidjev, Hristo</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We develop an efficient parallel algorithm for answering shortest-path
queries in planar graphs and implement it on a multi-node CPU/GPU clusters. The
algorithm uses a divide-and-conquer approach for decomposing the input graph
into small and roughly equal subgraphs and constructs a distributed data
structure containing shortest distances within each of those subgraphs and
between their boundary vertices. For a planar graph with $n$ vertices, that
data structure needs $O(n)$ storage per processor and allows queries to be
answered in $O(n^{1/4})$ time.
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07192</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07193</identifier>
 <datestamp>2015-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational methods for stochastic control with metric interval
  temporal logic specifications</dc:title>
 <dc:creator>Fu, Jie</dc:creator>
 <dc:creator>Topcu, Ufuk</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>93E20</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  This paper studies an optimal control problem for continuous-time stochastic
systems subject to reachability objectives specified in a subclass of metric
interval temporal logic specifications, a temporal logic with real-time
constraints. We propose a probabilistic method for synthesizing an optimal
control policy that maximizes the probability of satisfying a specification
based on a discrete approximation of the underlying stochastic system. First,
we show that the original problem can be formulated as a stochastic optimal
control problem in a state space augmented with finite memory and states of
some clock variables. Second, we present a numerical method for computing an
optimal policy with which the given specification is satisfied with the maximal
probability in point-based semantics in the discrete approximation of the
underlying system. We show that the policy obtained in the discrete
approximation converges to the optimal one for satisfying the specification in
the continuous or dense-time semantics as the discretization becomes finer in
both state and time. Finally, we illustrate our approach with a robotic motion
planning example.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures, submitted to IEEE CDC 2015</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2015-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07193</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07199</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting Interval Graphs for Network Science</dc:title>
 <dc:creator>Loe, Chuan Wen</dc:creator>
 <dc:creator>Jensen, Henrik Jeldtoft</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The vertices of an interval graph represent intervals over a real line where
overlapping intervals denote that their corresponding vertices are adjacent.
This implies that the vertices are measurable by a metric and there exists a
linear structure in the system. The generalization is an embedding of a graph
onto a multi-dimensional Euclidean space and it was used by scientists to study
the multi-relational complexity of ecology. However the research went out of
fashion in the 1980s and was not revisited when Network Science recently
expressed interests with multi-relational networks known as multiplexes. This
paper studies interval graphs from the perspective of Network Science.
</dc:description>
 <dc:date>2015-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07199</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07206</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometry and Determinism of Optimal Stationary Control in Partially
  Observable Markov Decision Processes</dc:title>
 <dc:creator>Montufar, Guido</dc:creator>
 <dc:creator>Ghazi-Zahedi, Keyan</dc:creator>
 <dc:creator>Ay, Nihat</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>93E20, 90C40</dc:subject>
 <dc:description>  It is well known that for any finite state Markov decision process (MDP)
there is a memoryless deterministic policy that maximizes the expected reward.
For partially observable Markov decision processes (POMDPs), optimal memoryless
policies are generally stochastic. We study the expected reward optimization
problem over the set of memoryless stochastic policies. We formulate this as a
constrained linear optimization problem and develop a corresponding geometric
framework. We show that any POMDP has an optimal memoryless policy of limited
stochasticity, which allows us to reduce the dimensionality of the search
space. Experiments demonstrate that this approach enables better and faster
convergence of the policy gradient on the evaluated systems.
</dc:description>
 <dc:description>Comment: 25 pages, 7 figures</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2016-02-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07211</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universal Approximation of Markov Kernels by Shallow Stochastic
  Feedforward Networks</dc:title>
 <dc:creator>Montufar, Guido</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>82C32</dc:subject>
 <dc:description>  We establish upper bounds for the minimal number of hidden units for which a
binary stochastic feedforward network with sigmoid activation probabilities and
a single hidden layer is a universal approximator of Markov kernels. We show
that each possible probabilistic assignment of the states of $n$ output units,
given the states of $k\geq1$ input units, can be approximated arbitrarily well
by a network with $2^{k-1}(2^{n-1}-1)$ hidden units.
</dc:description>
 <dc:description>Comment: 13 pages, 3 figures</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07217</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Test Input Generation for Android: Are We There Yet?</dc:title>
 <dc:creator>Choudhary, Shauvik Roy</dc:creator>
 <dc:creator>Gorla, Alessandra</dc:creator>
 <dc:creator>Orso, Alessandro</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Mobile applications, often simply called &quot;apps&quot;, are increasingly widespread,
and we use them daily to perform a number of activities. Like all software,
apps must be adequately tested to gain confidence that they behave correctly.
Therefore, in recent years, researchers and practitioners alike have begun to
investigate ways to automate apps testing. In particular, because of Android's
open source nature and its large share of the market, a great deal of research
has been performed on input generation techniques for apps that run on the
Android operating systems. At this point in time, there are in fact a number of
such techniques in the literature, which differ in the way they generate
inputs, the strategy they use to explore the behavior of the app under test,
and the specific heuristics they use. To better understand the strengths and
weaknesses of these existing approaches, and get general insight on ways they
could be made more effective, in this paper we perform a thorough comparison of
the main existing test input generation tools for Android. In our comparison,
we evaluate the effectiveness of these tools, and their corresponding
techniques, according to four metrics: code coverage, ability to detect faults,
ability to work on multiple platforms, and ease of use. Our results provide a
clear picture of the state of the art in input generation for Android apps and
identify future research directions that, if suitably investigated, could lead
to more effective and efficient testing tools for Android.
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07217</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07218</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring Complexity through Average Symmetry</dc:title>
 <dc:creator>Alamino, Roberto C.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This work introduces a complexity measure which addresses some conflicting
issues between existing ones by using a new principle - measuring the average
amount of symmetry broken by an object. It attributes low (although different)
complexity to either deterministic or random homogeneous densities and higher
complexity to the intermediate cases. This new measure is easily computable,
breaks the coarse graining paradigm and can be straightforwardly generalised,
including to continuous cases and general networks. By applying this measure to
a series of objects, it is shown that it can be consistently used for both
small scale structures with exact symmetry breaking and large scale patterns,
for which, differently from similar measures, it consistently discriminates
between repetitive patterns, random configurations and self-similar structures.
</dc:description>
 <dc:description>Comment: 20 pages, 6 figures</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07220</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Individual Planning in Agent Populations: Exploiting Anonymity and
  Frame-Action Hypergraphs</dc:title>
 <dc:creator>Sonu, Ekhlas</dc:creator>
 <dc:creator>Chen, Yingke</dc:creator>
 <dc:creator>Doshi, Prashant</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Interactive partially observable Markov decision processes (I-POMDP) provide
a formal framework for planning for a self-interested agent in multiagent
settings. An agent operating in a multiagent environment must deliberate about
the actions that other agents may take and the effect these actions have on the
environment and the rewards it receives. Traditional I-POMDPs model this
dependence on the actions of other agents using joint action and model spaces.
Therefore, the solution complexity grows exponentially with the number of
agents thereby complicating scalability. In this paper, we model and extend
anonymity and context-specific independence -- problem structures often present
in agent populations -- for computational gain. We empirically demonstrate the
efficiency from exploiting these problem structures by solving a new multiagent
problem involving more than 1,000 agents.
</dc:description>
 <dc:description>Comment: 8 page article plus two page appendix containing proofs in
  Proceedings of 25th International Conference on Autonomous Planning and
  Scheduling, 2015</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07220</dc:identifier>
 <dc:identifier>In Proceedings of 25th International Conference on Automated
  Planning and Scheduling, 2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07222</identifier>
 <datestamp>2015-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exponential Convergence Bounds using Integral Quadratic Constraints</dc:title>
 <dc:creator>Boczar, Ross</dc:creator>
 <dc:creator>Lessard, Laurent</dc:creator>
 <dc:creator>Recht, Benjamin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The theory of integral quadratic constraints (IQCs) allows verification of
stability and gain-bound properties of systems containing nonlinear or
uncertain elements. Gain bounds often imply exponential stability, but it can
be challenging to compute useful numerical bounds on the exponential decay
rate. In this work, we present a modification of the classical IQC results of
Megretski and Rantzer that leads to a tractable computational procedure for
finding exponential rate certificates.
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2015-10-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07224</identifier>
 <datestamp>2017-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distribution System Topology Detection Using Consumer Load and Line Flow
  Measurements</dc:title>
 <dc:creator>Sevlian, Raffi Avo</dc:creator>
 <dc:creator>Rajagopal, Ram</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This work presents a topology detection method combining home smart meter
information and sparse line flow measurements. The problem is formulated as a
spanning tree detection problem over a graph given partial nodal and edge flow
information in a deterministic and stochastic setting. In the deterministic
case of known nodal power consumption and edge flows we provide sensor
placement criterion which guarantees correct identification of all spanning
trees. We then present a detection method which is polynomial in complexity to
the size of the graph. In the stochastic case where loads are given by
forecasts derived from delayed smart meter data, we provide a combinatorial
Maximum a Posteriori (MAP) detector and a polynomial complexity approximate MAP
detector which is shown to work near optimum in low noise regime numerical
cases and moderately well in higher noise regime.
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2017-09-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07232</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on optimal experiment design for nonlinear systems using dynamic
  programming</dc:title>
 <dc:creator>Maidens, John</dc:creator>
 <dc:creator>Arcak, Murat</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We present a method of solving the T-optimal design problem for nonlinear
dynamical systems using dynamic programming. In contrast with previous dynamic
programming formulations, we avoid adding an equation for the dispersion to the
system state, allowing for more efficient solutions.
</dc:description>
 <dc:description>Comment: 4 pages, 1 figure</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07235</identifier>
 <datestamp>2015-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Formal Study on Backward Compatible Dynamic Software Updates</dc:title>
 <dc:creator>Shen, Jun</dc:creator>
 <dc:creator>Bazzi, Rida A.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  We study the dynamic software update problem for programs interacting with an
environment that is not necessarily updated. We argue that such updates should
be backward compatible. We propose a general definition of backward
compatibility and cases of backward compatible program update. Based on our
detailed study of real world program evolution, we propose classes of backward
compatible update for interactive programs, which are included at an average of
32% of all studied program changes. The definitions of update classes are
parameterized by our novel framework of program equivalence, which generalizes
existing results on program equivalence to non-terminating executions. Our
study of backward compatible updates is based on a typed extension of W
language.
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2015-09-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07236</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Isotropically Random Orthogonal Matrices: Performance of LASSO and
  Minimum Conic Singular Values</dc:title>
 <dc:creator>Thrampoulidis, Christos</dc:creator>
 <dc:creator>Hassibi, Babak</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  Recently, the precise performance of the Generalized LASSO algorithm for
recovering structured signals from compressed noisy measurements, obtained via
i.i.d. Gaussian matrices, has been characterized. The analysis is based on a
framework introduced by Stojnic and heavily relies on the use of Gordon's
Gaussian min-max theorem (GMT), a comparison principle on Gaussian processes.
As a result, corresponding characterizations for other ensembles of measurement
matrices have not been developed. In this work, we analyze the corresponding
performance of the ensemble of isotropically random orthogonal (i.r.o.)
measurements. We consider the constrained version of the Generalized LASSO and
derive a sharp characterization of its normalized squared error in the
large-system limit. When compared to its Gaussian counterpart, our result
analytically confirms the superiority in performance of the i.r.o. ensemble.
Our second result, derives an asymptotic lower bound on the minimum conic
singular values of i.r.o. matrices. This bound is larger than the corresponding
bound on Gaussian matrices. To prove our results we express i.r.o. matrices in
terms of Gaussians and show that, with some modifications, the GMT framework is
still applicable.
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07236</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07240</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regularized Minimax Conditional Entropy for Crowdsourcing</dc:title>
 <dc:creator>Zhou, Dengyong</dc:creator>
 <dc:creator>Liu, Qiang</dc:creator>
 <dc:creator>Platt, John C.</dc:creator>
 <dc:creator>Meek, Christopher</dc:creator>
 <dc:creator>Shah, Nihar B.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  There is a rapidly increasing interest in crowdsourcing for data labeling. By
crowdsourcing, a large number of labels can be often quickly gathered at low
cost. However, the labels provided by the crowdsourcing workers are usually not
of high quality. In this paper, we propose a minimax conditional entropy
principle to infer ground truth from noisy crowdsourced labels. Under this
principle, we derive a unique probabilistic labeling model jointly
parameterized by worker ability and item difficulty. We also propose an
objective measurement principle, and show that our method is the only method
which satisfies this objective measurement principle. We validate our method
through a variety of real crowdsourcing datasets with binary, multiclass or
ordinal labels.
</dc:description>
 <dc:description>Comment: 31 pages</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07241</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GraphMat: High performance graph analytics made productive</dc:title>
 <dc:creator>Sundaram, Narayanan</dc:creator>
 <dc:creator>Satish, Nadathur Rajagopalan</dc:creator>
 <dc:creator>Patwary, Md Mostofa Ali</dc:creator>
 <dc:creator>Dulloor, Subramanya R</dc:creator>
 <dc:creator>Vadlamudi, Satya Gautam</dc:creator>
 <dc:creator>Das, Dipankar</dc:creator>
 <dc:creator>Dubey, Pradeep</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Given the growing importance of large-scale graph analytics, there is a need
to improve the performance of graph analysis frameworks without compromising on
productivity. GraphMat is our solution to bridge this gap between a
user-friendly graph analytics framework and native, hand-optimized code.
GraphMat functions by taking vertex programs and mapping them to high
performance sparse matrix operations in the backend. We get the productivity
benefits of a vertex programming framework without sacrificing performance.
GraphMat is in C++, and we have been able to write a diverse set of graph
algorithms in this framework with the same effort compared to other vertex
programming frameworks. GraphMat performs 1.2-7X faster than high performance
frameworks such as GraphLab, CombBLAS and Galois. It achieves better multicore
scalability (13-15X on 24 cores) than other frameworks and is 1.2X off native,
hand-optimized code on a variety of different graph algorithms. Since GraphMat
performance depends mainly on a few scalable and well-understood sparse matrix
operations, GraphMatcan naturally benefit from the trend of increasing
parallelism on future hardware.
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07241</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07253</identifier>
 <datestamp>2016-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Safe Platooning of Unmanned Aerial Vehicles via Reachability</dc:title>
 <dc:creator>Chen, Mo</dc:creator>
 <dc:creator>Hu, Qie</dc:creator>
 <dc:creator>Mackin, Casey</dc:creator>
 <dc:creator>Fisac, Jaime F.</dc:creator>
 <dc:creator>Tomlin, Claire J.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Recently, there has been immense interest in using unmanned aerial vehicles
(UAVs) for civilian operations such as package delivery, firefighting, and fast
disaster response. As a result, UAV traffic management systems are needed to
support potentially thousands of UAVs flying simultaneously in the airspace, in
order to ensure their liveness and safety requirements are met. Hamilton-Jacobi
(HJ) reachability is a powerful framework for providing conditions under which
these requirements can be met, and for synthesizing the optimal controller for
meeting them. However, due to the curse of dimensionality, HJ reachability is
only tractable for a small number of vehicles if their set of maneuvers is
unrestricted. In this paper, we define a platoon to be a group of UAVs in a
single-file formation. We model each vehicle as a hybrid system with modes
corresponding to its role in the platoon, and specify the set of allowed
maneuvers in each mode to make the analysis tractable. We propose several
liveness controllers based on HJ reachability, and wrap a safety controller,
also based on HJ reachability, around the liveness controllers. For a single
altitude range, our approach guarantees safety for one safety breach; in the
unlikely event of multiple safety breaches, safety can be guaranteed over
multiple altitude ranges. We demonstrate the satisfaction of liveness and
safety requirements through simulations of three common scenarios.
</dc:description>
 <dc:description>Comment: 54th IEEE Conference on Decision and Control</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2016-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07253</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07261</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual Polynomials for Collision and Element Distinctness</dc:title>
 <dc:creator>Bun, Mark</dc:creator>
 <dc:creator>Thaler, Justin</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  The approximate degree of a Boolean function $f: \{-1, 1\}^n \to \{-1, 1\}$
is the minimum degree of a real polynomial that approximates $f$ to within
error $1/3$ in the $\ell_\infty$ norm. In an influential result, Aaronson and
Shi (J. ACM 2004) proved tight $\tilde{\Omega}(n^{1/3})$ and
$\tilde{\Omega}(n^{2/3})$ lower bounds on the approximate degree of the
Collision and Element Distinctness functions, respectively. Their proof was
non-constructive, using a sophisticated symmetrization argument and tools from
approximation theory.
  More recently, several open problems in the study of approximate degree have
been resolved via the construction of dual polynomials. These are explicit dual
solutions to an appropriate linear program that captures the approximate degree
of any function. We reprove Aaronson and Shi's results by constructing explicit
dual polynomials for the Collision and Element Distinctness functions.
</dc:description>
 <dc:description>Comment: 25 pages</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07266</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Controlling Refinements of Statecharts</dc:title>
 <dc:creator>Hansen, Conner</dc:creator>
 <dc:creator>Syriani, Eugene</dc:creator>
 <dc:creator>Lucio, Levi</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In incremental development strategies, modelers frequently refine Statecharts
models to satisfy requirements and changes. Although several solutions exist to
the problem of Statecharts refinement, they provide such levels of freedom that
a statechart cannot make assumptions or guarantees about its future structure.
In this paper, we propose a set of bounding rules to limit the allowable
Statecharts refinement operations such that certain assumptions will hold.
</dc:description>
 <dc:description>Comment: In Poster Proceedings of 6th Conference on Software Language
  Engineering (SLE) 2013 (http://www.sleconf.org/2013/)</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07266</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07274</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Initialization Strategies of Spatio-Temporal Convolutional Neural
  Networks</dc:title>
 <dc:creator>Mansimov, Elman</dc:creator>
 <dc:creator>Srivastava, Nitish</dc:creator>
 <dc:creator>Salakhutdinov, Ruslan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a new way of incorporating temporal information present in videos
into Spatial Convolutional Neural Networks (ConvNets) trained on images, that
avoids training Spatio-Temporal ConvNets from scratch. We describe several
initializations of weights in 3D Convolutional Layers of Spatio-Temporal
ConvNet using 2D Convolutional Weights learned from ImageNet. We show that it
is important to initialize 3D Convolutional Weights judiciously in order to
learn temporal representations of videos. We evaluate our methods on the
UCF-101 dataset and demonstrate improvement over Spatial ConvNets.
</dc:description>
 <dc:description>Comment: Technical Report</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07274</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07276</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Bernoulli Sensor-Control via Minimization of Expected Estimation
  Errors</dc:title>
 <dc:creator>Gostar, Amirali K.</dc:creator>
 <dc:creator>Hoseinnezhad, Reza</dc:creator>
 <dc:creator>Bab-Hadiashar, Alireza</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents a sensor-control method for choosing the best next state
of the sensor(s), that provide(s) accurate estimation results in a multi-target
tracking application. The proposed solution is formulated for a multi-Bernoulli
filter and works via minimization of a new estimation error-based cost
function. Simulation results demonstrate that the proposed method can
outperform the state-of-the-art methods in terms of computation time and
robustness to clutter while delivering similar accuracy.
</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07283</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Morphological Analyzer and Generator for Russian and Ukrainian Languages</dc:title>
 <dc:creator>Korobov, Mikhail</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  pymorphy2 is a morphological analyzer and generator for Russian and Ukrainian
languages. It uses large efficiently encoded lexi- cons built from OpenCorpora
and LanguageTool data. A set of linguistically motivated rules is developed to
enable morphological analysis and generation of out-of-vocabulary words
observed in real-world documents. For Russian pymorphy2 provides
state-of-the-arts morphological analysis quality. The analyzer is implemented
in Python programming language with optional C++ extensions. Emphasis is put on
ease of use, documentation and extensibility. The package is distributed under
a permissive open-source license, encouraging its use in both academic and
commercial setting.
</dc:description>
 <dc:description>Comment: AIST 2015 (http://aistconf.org/2015); 12 pages</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07283</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07284</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Rule-Based Short Query Intent Identification System</dc:title>
 <dc:creator>De, Arijit</dc:creator>
 <dc:creator>Kopparapu, Sunil Kumar</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Using SMS (Short Message System), cell phones can be used to query for
information about various topics. In an SMS based search system, one of the key
problems is to identify a domain (broad topic) associated with the user query;
so that a more comprehensive search can be carried out by the domain specific
search engine. In this paper we use a rule based approach, to identify the
domain, called Short Query Intent Identification System (SQIIS). We construct
two different rule-bases using different strategies to suit query intent
identification. We evaluate the two rule-bases experimentally.
</dc:description>
 <dc:description>Comment: 5 pages, 2010 International Conference on Signal and Image Processing
  (ICSIP)</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07284</dc:identifier>
 <dc:identifier>doi:10.1109/ICSIP.2010.5697471</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07288</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Social System Identification Problem</dc:title>
 <dc:creator>Wai, Hoi-To</dc:creator>
 <dc:creator>Scaglione, Anna</dc:creator>
 <dc:creator>Leshem, Amir</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The focus of this paper is modeling what we call a Social Radar, i.e. a
method to estimate the relative influence between social agents, by sampling
their opinions and as they evolve, after injecting in the network stubborn
agents. The stubborn agents opinion is not influenced by the peers they seek to
sway, and their opinion bias is the known input to the social network system.
The novelty is in the model presented to probe a social network and the
solution of the associated regression problem. The model allows to map the
observed opinion onto system equations that can be used to infer the social
graph and the amount of trust that characterizes the links.
</dc:description>
 <dc:description>Comment: Revised version submitted to IEEE CDC 2015, to be presented</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:date>2015-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07288</dc:identifier>
 <dc:identifier>doi:10.1109/CDC.2015.7402234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07291</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wireless Power Charging Control in Multiuser Broadband Networks</dc:title>
 <dc:creator>Bi, Suzhi</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Recent advances in wireless power transfer (WPT) technology provide a
cost-effective solution to charge wireless devices remotely without disruption
to the use. In this paper, we propose an efficient wireless charging control
method for exploiting the frequency diversity in multiuser broadband wireless
networks, to reduce energy outage and keep the system operating in an efficient
and sustainable state. In particular, we first analyze the impact of charging
control method to the operating lifetime of a WPT-enabled broadband system.
Based on the analysis, we then propose a multi-criteria charging control policy
that optimizes the transmit power allocation over frequency by jointly
considering the channel state information (CSI) and the battery state
information (BSI) of wireless devices. For practical implementation, the
proposed scheme is realized by a novel limited CSI estimation mechanism
embedded with partial BSI, which significantly reduces the energy cost of CSI
and BSI feedback. Simulation results show that the proposed method could
significantly increase the network lifetime under stringent transmit power
constraint. Reciprocally, it also consumes lower transmit power to achieve
near-perpetual network operation than other single-criterion based charging
control methods.
</dc:description>
 <dc:description>Comment: This paper had been accepted by IEEE ICC 2015, Workshop on Green
  Communications and Networks with Energy Harvesting, Smart Grids, and
  Renewable Energies</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07291</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07294</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Latent Semantic Analysis to Identify Quality in Use (QU)
  Indicators from User Reviews</dc:title>
 <dc:creator>Syn, Wendy Tan Wei</dc:creator>
 <dc:creator>How, Bong Chih</dc:creator>
 <dc:creator>Atoum, Issa</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The paper describes a novel approach to categorize users' reviews according
to the three Quality in Use (QU) indicators defined in ISO: effectiveness,
efficiency and freedom from risk. With the tremendous amount of reviews
published each day, there is a need to automatically summarize user reviews to
inform us if any of the software able to meet requirement of a company
according to the quality requirements. We implemented the method of Latent
Semantic Analysis (LSA) and its subspace to predict QU indicators. We build a
reduced dimensionality universal semantic space from Information System
journals and Amazon reviews. Next, we projected set of indicators' measurement
scales into the universal semantic space and represent them as subspace. In the
subspace, we can map similar measurement scales to the unseen reviews and
predict the QU indicators. Our preliminary study able to obtain the average of
F-measure, 0.3627.
</dc:description>
 <dc:description>Comment: 4 Figures in The International Conference on Artificial Intelligence
  and Pattern Recognition (AIPR2014),2014</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07297</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Brief Survey of Recent Edge-Preserving Smoothing Algorithms on Digital
  Images</dc:title>
 <dc:creator>Pal, Chandrajit</dc:creator>
 <dc:creator>Chakrabarti, Amlan</dc:creator>
 <dc:creator>Ghosh, Ranjan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Edge preserving filters preserve the edges and its information while blurring
an image. In other words they are used to smooth an image, while reducing the
edge blurring effects across the edge like halos, phantom etc. They are
nonlinear in nature. Examples are bilateral filter, anisotropic diffusion
filter, guided filter, trilateral filter etc. Hence these family of filters are
very useful in reducing the noise in an image making it very demanding in
computer vision and computational photography applications like denoising,
video abstraction, demosaicing, optical-flow estimation, stereo matching, tone
mapping, style transfer, relighting etc. This paper provides a concrete
introduction to edge preserving filters starting from the heat diffusion
equation in olden to recent eras, an overview of its numerous applications, as
well as mathematical analysis, various efficient and optimized ways of
implementation and their interrelationships, keeping focus on preserving the
boundaries, spikes and canyons in presence of noise. Furthermore it provides a
realistic notion for efficient implementation with a research scope for
hardware realization for further acceleration.
</dc:description>
 <dc:description>Comment: Manuscript</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07301</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring patterns in European singles charts</dc:title>
 <dc:creator>Buda, Andrzej</dc:creator>
 <dc:creator>Jarynowski, Andrzej</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Nonlinear Sciences - Pattern Formation and Solitons</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  European singles charts are important part of the music industry responsible
for creating popularity of songs. After modeling and exploring dynamics of
global album sales in previous papers, we investigate patterns of hit singles
popularity according to all data (1966-2015) from weekly charts (polls) in 12
Western European countries. The dynamics of building popularity in various
national charts is more than the economy because it depends on spread of
information. In our research we have shown how countries may be affected by
their neighbourhood and influenced by technological era. We have also computed
correlations with geographical and cultural distances between countries in
analog, digital and Internet era. We have shown that time delay between the
single premiere and the peak of popularity has become shorter under the
influence of technology and the popularity of songs depends on geographical
distances in analog (1966-1987) and Internet (2004-2015) era. On the other
hand, cultural distances between nations have influenced the peaks of
popularity, but in the Compact Disc era only (1988-2003). We have also
indicated the European countries in line with global trends e.g. The
Netherlands, the United Kingdom and outsiders like Italy and Spain.
</dc:description>
 <dc:description>Comment: 7p+appendix</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07310</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Complexity of Phylogeny Constraint Satisfaction Problems</dc:title>
 <dc:creator>Bodirsky, Manuel</dc:creator>
 <dc:creator>Jonsson, Peter</dc:creator>
 <dc:creator>Van Pham, Trung</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We systematically study the computational complexity of a broad class of
computational problems in phylogenetic reconstruction. The class contains for
example the rooted triple consistency problem, forbidden subtree problems, the
quartet consistency problem, and many other problems studied in the
bioinformatics literature. The studied problems can be described as
\emph{constraint satisfaction problems} where the constraints have a
first-order definition over the rooted triple relation. We show that every such
phylogeny problem can be solved in polynomial time or is NP-complete. On the
algorithmic side, we generalize a well-known polynomial-time algorithm of Aho,
Sagiv, Szymanski, and Ullman for the rooted triple consistency problem. Our
algorithm repeatedly solves linear equation systems to construct a solution in
polynomial time. We then show that every phylogeny problem that cannot be
solved by our algorithm is NP-complete. Our classification establishes a
dichotomy for a large class of infinite structures that we believe is of
independent interest in universal algebra, model theory, and topology. The
proof of our main result combines results and techniques from various research
areas: a recent classification of the model-complete cores of the reducts of
the homogeneous binary branching C-relation, Leeb's Ramsey theorem for rooted
trees, and universal algebra.
</dc:description>
 <dc:description>Comment: 48 pages, 2 figures. In this version we fix several bugs in the
  proofs of the previous versions</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:date>2017-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07310</dc:identifier>
 <dc:identifier>ACM Transactions on Computational Logic (TOCL), 18(3), 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07321</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fractional Pilot Reuse in Massive MIMO Systems</dc:title>
 <dc:creator>Atzeni, Italo</dc:creator>
 <dc:creator>Arnau, Jes&#xfa;s</dc:creator>
 <dc:creator>Debbah, M&#xe9;rouane</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Pilot contamination is known to be one of the main impairments for massive
MIMO multi-cell communications. Inspired by the concept of fractional frequency
reuse and by recent contributions on pilot reutilization among non-adjacent
cells, we propose a new pilot allocation scheme to mitigate this effect. The
key idea is to allow users in neighboring cells that are closest to their base
stations to reuse the same pilot sequences. Focusing on the uplink, we obtain
expressions for the overall spectral efficiency per cell for different linear
combining techniques at the base station and use them to obtain both the
optimal pilot reuse parameters and the optimal number of scheduled users.
Numerical results show a remarkable improvement in terms of spectral efficiency
with respect to the existing techniques.
</dc:description>
 <dc:description>Comment: Paper presented at the IEEE ICC 2015 Workshop on 5G &amp; Beyond -
  Enabling Technologies and Applications</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:date>2015-06-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07321</dc:identifier>
 <dc:identifier>doi:10.1109/ICCW.2015.7247312</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07341</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Experiment on Using Bayesian Networks for Process Mining</dc:title>
 <dc:creator>Moreira, Catarina</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Process mining is a technique that performs an automatic analysis of business
processes from a log of events with the promise of understanding how processes
are executed in an organisation.
  Several models have been proposed to address this problem, however, here we
propose a different approach to deal with uncertainty. By uncertainty, we mean
estimating the probability of some sequence of tasks occurring in a business
process, given that only a subset of tasks may be observable.
  In this sense, this work proposes a new approach to perform process mining
using Bayesian Networks. These structures can take into account the probability
of a task being present or absent in the business process. Moreover, Bayesian
Networks are able to automatically learn these probabilities through mechanisms
such as the maximum likelihood estimate and EM clustering.
  Experiments made over a Loan Application Case study suggest that Bayesian
Networks are adequate structures for process mining and enable a deep analysis
of the business process model that can be used to answer queries about that
process.
</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07342</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One-Step Stochastic Processes Simulation Software Package</dc:title>
 <dc:creator>Eferina, E. G.</dc:creator>
 <dc:creator>Korolkova, A. V.</dc:creator>
 <dc:creator>Gevorkyan, M. N.</dc:creator>
 <dc:creator>Kulyabov, D. S.</dc:creator>
 <dc:creator>Sevastyanov, L. A.</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  Background. It is assumed that the introduction of stochastic in mathematical
model makes it more adequate. But there is virtually no methods of coordinated
(depended on structure of the system) stochastic introduction into
deterministic models. Authors have improved the method of stochastic models
construction for the class of one-step processes and illustrated by models of
population dynamics. Population dynamics was chosen for study because its
deterministic models were sufficiently well explored that allows to compare the
results with already known ones.
  Purpose. To optimize the models creation as much as possible some routine
operations should be automated. In this case, the process of drawing up the
model equations can be algorithmized and implemented in the computer algebra
system. Furthermore, on the basis of these results a set of programs for
numerical experiment can be obtained.
  Method. The computer algebra system Axiom is used for analytical calculations
implementation. To perform the numerical experiment FORTRAN and Julia languages
are used. The method Runge--Kutta method for stochastic differential equations
is used as numerical method.
  Results. The program compex for creating stochastic one-step processes models
is constructed. Its application is illustrated by the predator-prey population
dynamic system.
  Conclusions. Computer algebra systems are very convenient for the purposes of
rapid prototyping in mathematical models design and analysis.
</dc:description>
 <dc:description>Comment: in Russian; in English</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07342</dc:identifier>
 <dc:identifier>Bulletin of PFUR. Series Mathematics. Information Sciences.
  Physics (3) (2014) 46-59</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07356</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mixed polarity reversible Peres gates</dc:title>
 <dc:creator>Moraga, Claudio</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>B.1.2</dc:subject>
 <dc:subject>B.6.1</dc:subject>
 <dc:subject>B.6.3</dc:subject>
 <dc:subject>G.2.3</dc:subject>
 <dc:description>  Reversible Peres gates with more than two all over binary-valued control
signals are discussed. Methods are disclosed for the low cost realization of
this kind of Peres gates without requiring ancillary lines. Proper distribution
of the controlled gates and their inverses allow driving the reversible Peres
gate with control signals of different polarities.
</dc:description>
 <dc:description>Comment: 2 pages, 5 figures</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07356</dc:identifier>
 <dc:identifier>Electronics Letters 50 (14):987-989, 2014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07372</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Two-user Causal Cognitive Interference Channel: Novel Outer Bounds
  and Constant Gap Result for the Symmetric Gaussian Noise Channel in Weak
  Interference</dc:title>
 <dc:creator>Cardone, Martina</dc:creator>
 <dc:creator>Tuninetti, Daniela</dc:creator>
 <dc:creator>Knopp, Raymond</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies the two-user Causal Cognitive Interference Channel (CCIC),
where two transmitters aim to communicate independent messages to two different
receivers via a common channel. One source, referred to as the cognitive, is
capable of overhearing the other source, referred to as the primary, through a
noisy in-band link and thus can assist in sending the primary's data. Two novel
outer bounds of the type $2R_p+R_c$ and $R_p+2R_c$ are derived for the class of
injective semi-deterministic CCICs where the noises at the different
source-destination pairs are independent. An achievable rate region is derived
based on Gelfand-Pinsker binning, superposition coding and simultaneous
decoding at the receivers.
  The lower and outer bounds are then specialized to the practically relevant
Gaussian noise case. The authors of this paper recently characterized to within
a constant gap the capacity of the symmetric Gaussian CCIC in (a) the strong
interference regime, and (b) for a subset of the weak interference regime when
the cooperation link is larger than a given threshold. This work characterizes
to within a constant gap the capacity for the symmetric Gaussian CCIC in the
regime that was still open. In particular, it is shown that the novel outer
bounds are necessary to characterize the capacity to within a constant gap when
the cooperation link is weaker than the direct links, that is, in this regime
unilateral cooperation leaves some system resources underutilized.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Information Theory</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07372</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2016.2584619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07376</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global Tracking Passivity--based PI Control of Bilinear Systems and its
  Application to the Boost and Modular Multilevel Converters</dc:title>
 <dc:creator>Cisneros, R.</dc:creator>
 <dc:creator>Pirro, M.</dc:creator>
 <dc:creator>Bergna, G.</dc:creator>
 <dc:creator>Ortega, R.</dc:creator>
 <dc:creator>Ippoliti, G.</dc:creator>
 <dc:creator>Molinas, M.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper deals with the problem of trajectory tracking of a class of
bilinear systems with time--varying measurable disturbance. A set of matrices
{A,B_i} has been identified, via a linear matrix inequality, for which it is
possible to ensure global tracking of (admissible, differentiable) trajectories
with a simple linear time--varying PI controller. Instrumental to establish the
result is the construction of an output signal with respect to which the
incremental model is passive. The result is applied to the boost and the
modular multilevel converter for which experimental results are given.
</dc:description>
 <dc:description>Comment: 9 pages, 10 figures</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07377</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tale of Two Mechanisms: Incentivizing Investments in Security Games</dc:title>
 <dc:creator>Naghizadeh, Parinaz</dc:creator>
 <dc:creator>Liu, Mingyan</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In a system of interdependent users, the security of an entity is affected
not only by that user's investment in security measures, but also by the
positive externality of the security decisions of (some of) the other users.
The provision of security in such system is therefore modeled as a public good
provision problem, and is referred to as a security game. In this paper, we
compare two well-known incentive mechanisms in this context for incentivizing
optimal security investments among users, namely the Pivotal and the
Externality mechanisms. The taxes in a Pivotal mechanism are designed to ensure
users' voluntary participation, while those in an Externality mechanism are
devised to maintain a balanced budget. We first show the more general result
that, due to the non-excludable nature of security, no mechanism can
incentivize the socially optimal investment profile, while at the same time
ensuring voluntary participation and maintaining a balanced budget for all
instances of security games. To further illustrate, we apply the Pivotal and
Externality mechanisms to the special case of weighted total effort
interdependence models, and identify some of the effects of varying
interdependency between users on the budget deficit in the Pivotal mechanism,
as well as on the participation incentives in the Externality mechanism.
</dc:description>
 <dc:description>Comment: 45 pages, 7 figures</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07384</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressed sensing MRI using masked DCT and DFT measurements</dc:title>
 <dc:creator>Hot, Elma</dc:creator>
 <dc:creator>Sekuli&#x107;, Petar</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents modification of the TwIST algorithm for Compressive
Sensing MRI images reconstruction. Compressive Sensing is new approach in
signal processing whose basic idea is recovering signal form small set of
available samples. The application of the Compressive Sensing in biomedical
imaging has found great importance. It allows significant lowering of the
acquisition time, and therefore, save the patient from the negative impact of
the MR apparatus. TwIST is commonly used algorithm for 2D signals
reconstruction using Compressive Sensing principle. It is based on the Total
Variation minimization. Standard version of the TwIST uses masked 2D Discrete
Fourier Transform coefficients as Compressive Sensing measurements. In this
paper, different masks and different transformation domains for coefficients
selection are tested. Certain percent of the measurements is used from the
mask, as well as small number of coefficients outside the mask. Comparative
analysis using 2D DFT and 2D DCT coefficients, with different mask shapes is
performed. The theory is proved with experimental results.
</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07384</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07387</identifier>
 <datestamp>2017-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vectorized VByte Decoding</dc:title>
 <dc:creator>Plaisance, Jeff</dc:creator>
 <dc:creator>Kurz, Nathan</dc:creator>
 <dc:creator>Lemire, Daniel</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  We consider the ubiquitous technique of VByte compression, which represents
each integer as a variable length sequence of bytes. The low 7 bits of each
byte encode a portion of the integer, and the high bit of each byte is reserved
as a continuation flag. This flag is set to 1 for all bytes except the last,
and the decoding of each integer is complete when a byte with a high bit of 0
is encountered. VByte decoding can be a performance bottleneck especially when
the unpredictable lengths of the encoded integers cause frequent branch
mispredictions. Previous attempts to accelerate VByte decoding using SIMD
vector instructions have been disappointing, prodding search engines such as
Google to use more complicated but faster-to-decode formats for
performance-critical code. Our decoder (Masked VByte) is 2 to 4 times faster
than a conventional scalar VByte decoder, making the format once again
competitive with regard to speed.
</dc:description>
 <dc:description>Comment: First International Symposium on Web Algorithms (June 2015)</dc:description>
 <dc:date>2015-02-20</dc:date>
 <dc:date>2017-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07387</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07389</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sorting in Networks: Adversity and Structure</dc:title>
 <dc:creator>Bjerre-Nielsen, Andreas</dc:creator>
 <dc:subject>Quantitative Finance - Economics</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  People choose friendships with people similar to themselves, i.e. they sort
by resemblence. Economic studies have shown when sorting is optimal and
constitute an equilibrium, however, this presumes lack of beneficial
spillovers. We investigate formation of economic and social networks where
agents may form or cut ties. We combine a setup with link formation where
agents have types that determine the value of a connection. We provide
conditions for sorting in friendships, i.e. that agents tend to partner only
with those with those sufficiently similar to themselves. Conditions are
provided with and without beneficial spillovers from indirect connections. We
show that sorting may be suboptimal, yet a socially stable outcome, despite
otherwise obeying the conditions for sorting in Becker (1973). We analyze
policy tools to mitigate suboptimal sorting. Another feature is that agents
with higher value are more central in networks under certain conditions; a side
effect is sorting by degree centrality under certain conditions. Finally we
illustrate the limits to patterns of sorting and centrality.
</dc:description>
 <dc:description>Comment: 49 pages, 3 figures</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07389</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07401</identifier>
 <datestamp>2016-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Manual Character Transmission by Presenting Trajectories of 7mm-high
  Letters in One Second</dc:title>
 <dc:creator>Hasegawa, Keisuke</dc:creator>
 <dc:creator>Sakurai, Tatsuma</dc:creator>
 <dc:creator>Makino, Yasutoshi</dc:creator>
 <dc:creator>Shinoda, Hiroyuki</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  In this paper, we report a method of intuitively transmitting symbolic
information to untrained users via only their hands without using any visual or
auditory cues. Our simple concept is presenting three-dimensional letter
trajectories to the user's hand via a stylus which is mechanically manipulated.
By this simple method, in our experiments, participants were able to read 14
mm-high lower-case letters displayed at a rate of one letter per second with an
accuracy rate of 71.9% in their first trials, which was improved to 91.3% after
a five-minute training period. These results showed small individual
differences among participants (standard deviation of 12.7% in the first trials
and 6.7% after training). We also found that this accuracy was still retained
to a high level (85.1% with SD of 8.2%) even when the letters were reduced to a
height of 7 mm. Thus, we revealed that sighted adults potentially possess the
ability to read small letters accurately at normal writing speed using their
hands.
</dc:description>
 <dc:description>Comment: Submitted in IEEE Transactions on Haptics</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:date>2015-10-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07401</dc:identifier>
 <dc:identifier>doi:10.1109/TOH.2016.2517625</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07405</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Making the Most of Tweet-Inherent Features for Social Spam Detection on
  Twitter</dc:title>
 <dc:creator>Wang, Bo</dc:creator>
 <dc:creator>Zubiaga, Arkaitz</dc:creator>
 <dc:creator>Liakata, Maria</dc:creator>
 <dc:creator>Procter, Rob</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Social spam produces a great amount of noise on social media services such as
Twitter, which reduces the signal-to-noise ratio that both end users and data
mining applications observe. Existing techniques on social spam detection have
focused primarily on the identification of spam accounts by using extensive
historical and network-based data. In this paper we focus on the detection of
spam tweets, which optimises the amount of data that needs to be gathered by
relying only on tweet-inherent features. This enables the application of the
spam detection system to a large set of tweets in a timely fashion, potentially
applicable in a real-time or near real-time setting. Using two large
hand-labelled datasets of tweets containing spam, we study the suitability of
five classification algorithms and four different feature sets to the social
spam detection task. Our results show that, by using the limited set of
features readily available in a tweet, we can achieve encouraging results which
are competitive when compared against existing spammer detection systems that
make use of additional, costly user features. Our study is the first that
attempts at generalising conclusions on the optimal classifiers and sets of
features for social spam detection over different datasets.
</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07414</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparing Graphs via Persistence Distortion</dc:title>
 <dc:creator>Dey, Tamal K.</dc:creator>
 <dc:creator>Shi, Dayu</dc:creator>
 <dc:creator>Wang, Yusu</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Metric graphs are ubiquitous in science and engineering. For example, many
data are drawn from hidden spaces that are graph-like, such as the cosmic web.
A metric graph offers one of the simplest yet still meaningful ways to
represent the non-linear structure hidden behind the data. In this paper, we
propose a new distance between two finite metric graphs, called the
persistence-distortion distance, which draws upon a topological idea. This
topological perspective along with the metric space viewpoint provide a new
angle to the graph matching problem. Our persistence-distortion distance has
two properties not shared by previous methods: First, it is stable against the
perturbations of the input graph metrics. Second, it is a continuous distance
measure, in the sense that it is defined on an alignment of the underlying
spaces of input graphs, instead of merely their nodes. This makes our
persistence-distortion distance robust against, for example, different
discretizations of the same underlying graph. Despite considering the input
graphs as continuous spaces, that is, taking all points into account, we show
that we can compute the persistence-distortion distance in polynomial time. The
time complexity for the discrete case where only graph nodes are considered is
much faster. We also provide some preliminary experimental results to
demonstrate the use of the new distance measure.
</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:date>2017-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07424</identifier>
 <datestamp>2015-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressed sensing with combinatorial designs: theory and simulations</dc:title>
 <dc:creator>Bryant, Darryn</dc:creator>
 <dc:creator>Colbourn, Charles</dc:creator>
 <dc:creator>Horsley, Daniel</dc:creator>
 <dc:creator>Cath&#xe1;in, Padraig &#xd3;</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05B05, 94A12, 94A15</dc:subject>
 <dc:description>  In 'An asymptotic result on compressed sensing matrices', a new construction
for compressed sensing matrices using combinatorial design theory was
introduced. In this paper, we use deterministic and probabilistic methods to
analyse the performance of matrices obtained from this construction. We provide
new theoretical results and detailed simulations. These simulations indicate
that the construction is competitive with Gaussian random matrices, and that
recovery is tolerant to noise. A new recovery algorithm tailored to the
construction is also given.
</dc:description>
 <dc:description>Comment: 18 pages, 3 figures</dc:description>
 <dc:date>2015-03-23</dc:date>
 <dc:date>2015-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07426</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Approximation Mechanism Design without Money for Facility
  Games</dc:title>
 <dc:creator>Cheng, Yukun</dc:creator>
 <dc:creator>Zhou, Sanming</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C57, 91A43, 91A46</dc:subject>
 <dc:description>  In a facility game one or more facilities are placed in a metric space to
serve a set of selfish agents whose addresses are their private information. In
a classical facility game, each agent wants to be as close to a facility as
possible, and the cost of an agent can be defined as the distance between her
location and the closest facility. In an obnoxious facility game, each agent
wants to be far away from all facilities, and her utility is the distance from
her location to the facility set. The objective of each agent is to minimize
her cost or maximize her utility. An agent may lie if, by doing so, more
benefit can be obtained. We are interested in social choice mechanisms that do
not utilize payments. The game designer aims at a mechanism that is
strategy-proof, in the sense that any agent cannot benefit by misreporting her
address, or, even better, group strategy-proof, in the sense that any coalition
of agents cannot all benefit by lying. Meanwhile, it is desirable to have the
mechanism to be approximately optimal with respect to a chosen objective
function. Several models for such approximation mechanism design without money
for facility games have been proposed. In this paper we briefly review these
models and related results for both deterministic and randomized mechanisms,
and meanwhile we present a general framework for approximation mechanism design
without money for facility games.
</dc:description>
 <dc:date>2015-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07426</dc:identifier>
 <dc:identifier>Advances in Global Optimization, Springer Proceedings in
  Mathematics &amp; Statistics Volume 95, 2015, pp 117-128</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-08377-3_13</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07431</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coordination and Efficiency in Decentralized Collaboration</dc:title>
 <dc:creator>Romero, Daniel M.</dc:creator>
 <dc:creator>Huttenlocher, Dan</dc:creator>
 <dc:creator>Kleinberg, Jon</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Environments for decentralized on-line collaboration are now widespread on
the Web, underpinning open-source efforts, knowledge creation sites including
Wikipedia, and other experiments in joint production. When a distributed group
works together in such a setting, the mechanisms they use for coordination can
play an important role in the effectiveness of the group's performance.
  Here we consider the trade-offs inherent in coordination in these on-line
settings, balancing the benefits to collaboration with the cost in effort that
could be spent in other ways. We consider two diverse domains that each contain
a wide range of collaborations taking place simultaneously -- Wikipedia and
GitHub -- allowing us to study how coordination varies across different
projects. We analyze trade-offs in coordination along two main dimensions,
finding similar effects in both our domains of study: first we show that, in
aggregate, high-status projects on these sites manage the coordination
trade-off at a different level than typical projects; and second, we show that
projects use a different balance of coordination when they are &quot;crowded,&quot; with
relatively small size but many participants. We also develop a stylized
theoretical model for the cost-benefit trade-off inherent in coordination and
show that it qualitatively matches the trade-offs we observe between
crowdedness and coordination.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures, ICWSM 2015, in Proc. 9th International AAAI
  Conference on Weblogs and Social Media</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07439</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Overlapping Community Detection Using Neighborhood-Inflated Seed
  Expansion</dc:title>
 <dc:creator>Whang, Joyce Jiyoung</dc:creator>
 <dc:creator>Gleich, David F.</dc:creator>
 <dc:creator>Dhillon, Inderjit S.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Community detection is an important task in network analysis. A community
(also referred to as a cluster) is a set of cohesive vertices that have more
connections inside the set than outside. In many social and information
networks, these communities naturally overlap. For instance, in a social
network, each vertex in a graph corresponds to an individual who usually
participates in multiple communities. In this paper, we propose an efficient
overlapping community detection algorithm using a seed expansion approach. The
key idea of our algorithm is to find good seeds, and then greedily expand these
seeds based on a community metric. Within this seed expansion method, we
investigate the problem of how to determine good seed nodes in a graph. In
particular, we develop new seeding strategies for a personalized PageRank
clustering scheme that optimizes the conductance community score. Experimental
results show that our seed expansion algorithm outperforms other
state-of-the-art overlapping community detection methods in terms of producing
cohesive clusters and identifying ground-truth communities. We also show that
our new seeding strategies are better than existing strategies, and are thus
effective in finding good overlapping communities in real-world networks.
</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07444</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building Efficient and Compact Data Structures for Simplicial Complexes</dc:title>
 <dc:creator>Boissonnat, Jean-Daniel</dc:creator>
 <dc:creator>S., Karthik C.</dc:creator>
 <dc:creator>Tavenas, S&#xe9;bastien</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The Simplex Tree (ST) is a recently introduced data structure that can
represent abstract simplicial complexes of any dimension and allows efficient
implementation of a large range of basic operations on simplicial complexes. In
this paper, we show how to optimally compress the Simplex Tree while retaining
its functionalities. In addition, we propose two new data structures called the
Maximal Simplex Tree (MxST) and the Simplex Array List (SAL). We analyze the
compressed Simplex Tree, the Maximal Simplex Tree, and the Simplex Array List
under various settings.
</dc:description>
 <dc:description>Comment: An extended abstract appeared in the proceedings of SoCG 2015</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:date>2016-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07444</dc:identifier>
 <dc:identifier>doi:10.1007/s00453-016-0207-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07455</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sum Secrecy Rate in MISO Full-Duplex Wiretap Channel with Imperfect CSI</dc:title>
 <dc:creator>Vishwakarma, Sanjay</dc:creator>
 <dc:creator>Chockalingam, A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider the achievable sum secrecy rate in MISO
(multiple-input-single-output) {\em full-duplex} wiretap channel in the
presence of a passive eavesdropper and imperfect channel state information
(CSI). We assume that the users participating in full-duplex communication have
multiple transmit antennas, and that the users and the eavesdropper have single
receive antenna each. The users have individual transmit power constraints.
They also transmit jamming signals to improve the secrecy rates. We obtain the
achievable perfect secrecy rate region by maximizing the worst case sum secrecy
rate. We also obtain the corresponding transmit covariance matrices associated
with the message signals and the jamming signals. Numerical results that show
the impact of imperfect CSI on the achievable secrecy rate region are
presented.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1311.3918</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07455</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07460</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RANSAC based three points algorithm for ellipse fitting of spherical
  object's projection</dc:title>
 <dc:creator>Xu, Shenghui</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  As the spherical object can be seen everywhere, we should extract the ellipse
image accurately and fit it by implicit algebraic curve in order to finish the
3D reconstruction. In this paper, we propose a new ellipse fitting algorithm
which only needs three points to fit the projection of spherical object and is
different from the traditional algorithms that need at least five point. The
fitting procedure is just similar as the estimation of Fundamental Matrix
estimation by seven points, and the RANSAC algorithm has also been used to
exclude the interference of noise and scattered points.
</dc:description>
 <dc:date>2015-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07460</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07463</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing the partition function of a polynomial on the Boolean cube</dc:title>
 <dc:creator>Barvinok, Alexander</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>90C09, 68C25, 68W25, 68R05</dc:subject>
 <dc:description>  For a polynomial f: {-1, 1}^n --&gt; C, we define the partition function as the
average of e^{lambda f(x)} over all points x in {-1, 1}^n, where lambda in C is
a parameter. We present a quasi-polynomial algorithm, which, given such f,
lambda and epsilon &gt;0 approximates the partition function within a relative
error of epsilon in N^{O(ln n -ln epsilon)} time provided |lambda| &lt; 1/(2 L
sqrt{deg f}), where L=L(f) is a parameter bounding the Lipschitz constant of f
from above and N is the number of monomials in f. As a corollary, we obtain a
quasi-polynomial algorithm, which, given such an f with coefficients +1 and -1
and such that every variable enters not more than 4 monomials, approximates the
maximum of f on {-1, 1}^n within a factor of O(sqrt{deg f}/delta), provided the
maximum is N delta for some 0&lt; delta &lt;1. If every variable enters not more than
k monomials for some fixed k &gt; 4, we are able to establish a similar result
when delta &gt; (k-1)/k.
</dc:description>
 <dc:description>Comment: The final version of this paper is due to be published in the
  collection of papers &quot;A Journey through Discrete Mathematics. A Tribute to
  Jiri Matousek&quot; edited by Martin Loebl, Jaroslav Nesetril and Robin Thomas, to
  be published by Springer</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07463</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07469</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Properties of Sparse Distributed Representations and their Application
  to Hierarchical Temporal Memory</dc:title>
 <dc:creator>Ahmad, Subutai</dc:creator>
 <dc:creator>Hawkins, Jeff</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Empirical evidence demonstrates that every region of the neocortex represents
information using sparse activity patterns. This paper examines Sparse
Distributed Representations (SDRs), the primary information representation
strategy in Hierarchical Temporal Memory (HTM) systems and the neocortex. We
derive a number of properties that are core to scaling, robustness, and
generalization. We use the theory to provide practical guidelines and
illustrate the power of SDRs as the basis of HTM. Our goal is to help create a
unified mathematical and practical framework for SDRs as it relates to cortical
function.
</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07469</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07473</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Backup of Data on Remote Server</dc:title>
 <dc:creator>Raje, Manali</dc:creator>
 <dc:creator>Mukhopadhyay, Debajyoti</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Large amount of electronic data is generated in Cloud computing every day.
Efficient maintenance of this data requires proper services. Hence a method to
collect data securely, by protecting and developing backups is mentioned. The
Objective is to provide Auto Response Server, better solutions for data backup
and restoring using Cloud. Data can be collected and sent to a centralized
repository in a platform independent format without any network consideration.
This data can then be used according to the requirement. The purpose of this
particular Remote Backup Server is to collect information from any remote
location even if network connectivity is not available at that point of time
and provide proper services as well as to recover data in case of loss.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures in IJSR, Vol.3, Issue 12, December 2014, ISSN:
  2319-7064</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07474</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User Profiling Trends, Techniques and Applications</dc:title>
 <dc:creator>Kanoje, Sumitkumar</dc:creator>
 <dc:creator>Girase, Sheetal</dc:creator>
 <dc:creator>Mukhopadhyay, Debajyoti</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The Personalization of information has taken recommender systems at a very
high level. With personalization these systems can generate user specific
recommendations accurately and efficiently. User profiling helps
personalization, where information retrieval is done to personalize a scenario
which maintains a separate user profile for individual user. The main objective
of this paper is to explore this field of personalization in context of user
profiling, to help researchers make aware of the user profiling. Various
trends, techniques and Applications have been discussed in paper which will
fulfill this motto.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure in IJAFRC, Vol.1, Issue 11, November 2014, ISSN:
  2348-4853. arXiv admin note: text overlap with arXiv:1503.06555</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07474</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07475</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Role of Matrix Factorization Model in Collaborative Filtering Algorithm:
  A Survey</dc:title>
 <dc:creator>Bokde, Dheeraj kumar</dc:creator>
 <dc:creator>Girase, Sheetal</dc:creator>
 <dc:creator>Mukhopadhyay, Debajyoti</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Recommendation Systems apply Information Retrieval techniques to select the
online information relevant to a given user. Collaborative Filtering is
currently most widely used approach to build Recommendation System. CF
techniques uses the user behavior in form of user item ratings as their
information source for prediction. There are major challenges like sparsity of
rating matrix and growing nature of data which is faced by CF algorithms. These
challenges are been well taken care by Matrix Factorization. In this paper we
attempt to present an overview on the role of different MF model to address the
challenges of CF algorithms, which can be served as a roadmap for research in
this area.
</dc:description>
 <dc:description>Comment: 8 pages, 1 figure in IJAFRC, Vol.1, Issue 12, December 2014</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07475</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07477</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Classification Techniques in the Area of Big Data</dc:title>
 <dc:creator>Koturwar, Praful</dc:creator>
 <dc:creator>Girase, Sheetal</dc:creator>
 <dc:creator>Mukhopadhyay, Debajyoti</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Big Data concern large-volume, growing data sets that are complex and have
multiple autonomous sources. Earlier technologies were not able to handle
storage and processing of huge data thus Big Data concept comes into existence.
This is a tedious job for users unstructured data. So, there should be some
mechanism which classify unstructured data into organized form which helps user
to easily access required data. Classification techniques over big
transactional database provide required data to the users from large datasets
more simple way. There are two main classification techniques, supervised and
unsupervised. In this paper we focused on to study of different supervised
classification techniques. Further this paper shows a advantages and
limitations.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures, 2 tables in IJAFRC, Vol.1, Issue 11, November
  2014, ISSN: 2348-4853</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07487</identifier>
 <datestamp>2015-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On coefficients of powers of polynomials and their compositions over
  finite fields</dc:title>
 <dc:creator>Mullen, Gary L.</dc:creator>
 <dc:creator>Muratovi&#x107;-Ribi&#x107;, Amela</dc:creator>
 <dc:creator>Wang, Qiang</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>11T06, 11T35, 15B33</dc:subject>
 <dc:description>  For any given polynomial $f$ over the finite field $\mathbb{F}_q$ with degree
at most $q-1$, we associate it with a $q\times q$ matrix $A(f)=(a_{ik})$
consisting of coefficients of its powers $(f(x))^k=\sum_{i=0}^{q-1}a_{ik} x^i$
modulo $x^q -x$ for $k=0,1,\ldots,q-1$. This matrix has some interesting
properties such as $A(g\circ f)=A(f)A(g)$ where $(g\circ f)(x) = g(f(x))$ is
the composition of the polynomial $g$ with the polynomial $f$. In particular,
$A(f^{(k)})=(A(f))^k$ for any $k$-th composition $f^{(k)}$ of $f$ with $k \geq
0$. As a consequence, we prove that the rank of $A(f)$ gives the cardinality of
the value set of $f$. Moreover, if $f$ is a permutation polynomial then the
matrix associated with its inverse $A(f^{(-1)})=A(f)^{-1}=PA(f)P$ where $P$ is
an antidiagonal permutation matrix. As an application, we study the period of a
nonlinear congruential pseduorandom sequence $\bar{a} = \{a_0, a_1, a_2, ...
\}$ generated by $a_n = f^{(n)}(a_0)$ with initial value $a_0$, in terms of the
order of the associated matrix. Finally we show that $A(f)$ is diagonalizable
in some extension field of $\mathbb{F}_q$ when $f$ is a permutation polynomial
over $\mathbb{F}_q$.
</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:date>2015-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07487</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07490</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sensitivity Analysis for additive STDP rule</dc:title>
 <dc:creator>Sengupta, Subhajit</dc:creator>
 <dc:creator>Gurumoorthy, Karthik S.</dc:creator>
 <dc:creator>Banerjee, Arunava</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>91E40, 68T05, 92C42</dc:subject>
 <dc:description>  Spike Timing Dependent Plasticity (STDP) is a Hebbian like synaptic learning
rule. The basis of STDP has strong experimental evidences and it depends on
precise input and output spike timings. In this paper we show that under
biologically plausible spiking regime, slight variability in the spike timing
leads to drastically different evolution of synaptic weights when its dynamics
are governed by the additive STDP rule.
</dc:description>
 <dc:description>Comment: On Computational Neuroscience/ 11 pages</dc:description>
 <dc:date>2015-02-28</dc:date>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07496</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>P-score: A Publication-based Metric for Academic Productivity</dc:title>
 <dc:creator>Ribas, Sabir</dc:creator>
 <dc:creator>Ribeiro-Neto, Berthier</dc:creator>
 <dc:creator>Silva, Edmundo de Souza e</dc:creator>
 <dc:creator>Ueda, Alberto</dc:creator>
 <dc:creator>Ziviani, Nivio</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  In this work we propose a metric to assess academic productivity based on
publication outputs. We are interested in knowing how well a research group in
an area of knowledge is doing relatively to a pre-selected set of reference
groups, where each group is composed by academics or researchers. To assess
academic productivity we propose a new metric, which we call P-score. Our
metric P-score assigns weights to venues using only the publication patterns of
selected reference groups. This implies that P-score does not depend on
citation data and thus, that it is simpler to compute particularly in contexts
in which citation data is not easily available. Also, preliminary experiments
suggest that P-score preserves strong correlation with citation-based metrics.
</dc:description>
 <dc:description>Comment: 3 pages, 1 figure</dc:description>
 <dc:date>2015-03-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07496</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07508</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stable Feature Selection from Brain sMRI</dc:title>
 <dc:creator>Xin, Bo</dc:creator>
 <dc:creator>Hu, Lingjing</dc:creator>
 <dc:creator>Wang, Yizhou</dc:creator>
 <dc:creator>Gao, Wen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Neuroimage analysis usually involves learning thousands or even millions of
variables using only a limited number of samples. In this regard, sparse
models, e.g. the lasso, are applied to select the optimal features and achieve
high diagnosis accuracy. The lasso, however, usually results in independent
unstable features. Stability, a manifest of reproducibility of statistical
results subject to reasonable perturbations to data and the model, is an
important focus in statistics, especially in the analysis of high dimensional
data. In this paper, we explore a nonnegative generalized fused lasso model for
stable feature selection in the diagnosis of Alzheimer's disease. In addition
to sparsity, our model incorporates two important pathological priors: the
spatial cohesion of lesion voxels and the positive correlation between the
features and the disease labels. To optimize the model, we propose an efficient
algorithm by proving a novel link between total variation and fast network flow
algorithms via conic duality. Experiments show that the proposed nonnegative
model performs much better in exploring the intrinsic structure of data via
selecting stable features compared with other state-of-the-arts.
</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07508</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07542</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Efficient Adaptive Power Allocation for Incremental MIMO Systems</dc:title>
 <dc:creator>Chaitanya, Tumula V. K.</dc:creator>
 <dc:creator>Le-Ngoc, Tho</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider energy-efficient adaptive power allocation for three incremental
multiple-input multiple-output (IMIMO) systems employing ARQ, hybrid ARQ (HARQ)
with Chase combining (CC), and HARQ with incremental redundancy (IR), to
minimize their rate-outage probability (or equivalently packet drop rate) under
a constraint on average energy consumption per data packet. We first provide
the rate-outage probability expressions for the three IMIMO systems, and then
propose methods to convert them into a tractable form and formulate the
corresponding non-convex optimization problems that can be solved by an
interior-point algorithm for finding a local optimum. To further reduce the
solution complexity, using an asymptotically equivalent approximation of the
rate-outage probability expressions, we approximate the non-convex optimization
problems as a unified geometric programming problem (GPP), for which we derive
the closed-form solution. Illustrative results indicate that the proposed power
allocation (PPA) offers significant gains in energy savings as compared to the
equal-power allocation (EPA), and the simple closed-form GPP solution can
provide closer performance to the exact method at lower values of rate-outage
probability, for the three IMIMO systems.
</dc:description>
 <dc:description>Comment: Submitted IEEE Transactions on Vehicular Technology</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07542</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07545</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Investigation into the Correlation between a Presidents Approval
  Rating and the Performance of His Party in the Midterm Elections</dc:title>
 <dc:creator>George, Pandya</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Over the years, American politics have become increasingly polarized. In the
current political landscape, a president cannot easily collaborate with the
opposite party and pass legislature. Ideologies between parties have drifted
apart to the point that one party generally stonewalls any legislature proposed
by the other party. Because of this political landscape, it is paramount for a
president to have a majority of his party in Congress. Political parties invest
a great deal of time and effort into making sure that first their Presidential
candidate wins and is popular, and then their congressional candidates win
seats in Congress. In this study, the effect of the former on the latter was
investigated - how the approval rating of the president influences the number
of seats won or lost in Congress during the midterm elections. The data used
was collected from Gallup. An analysis of the data yielded the statistically
significant linear model y = -107.423+1.594x, where x is the approval rating of
the president and y is the number of Congressional seats won or lost by the
party of the president. Further analysis yielded a 20 percent more
statistically useful model for approval ratings greater than 50 percent: y =
-275.461+4.37551x. As of the eve of the 2014 Midterms, President Barrack Obama
had an approval rating of 44 percent. Using the originally derived linear
model, it can be said with 95 percent confidence that the Democratic Party will
lose between 27 and 48 seats in Congress, rounded to the nearest whole seat.
This prediction has since been proven correct.
</dc:description>
 <dc:date>2015-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07545</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07551</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Low-throughput Wavelet-based Steganography Audio Scheme</dc:title>
 <dc:creator>Carrion, P.</dc:creator>
 <dc:creator>de Oliveira, H. M.</dc:creator>
 <dc:creator>de Souza, R. M. Campello</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This paper presents the preliminary of a novel scheme of steganography, and
introduces the idea of combining two secret keys in the operation. The first
secret key encrypts the text using a standard cryptographic scheme (e.g. IDEA,
SAFER+, etc.) prior to the wavelet audio decomposition. The way in which the
cipher text is embedded in the file requires another key, namely a stego-key,
which is associated with features of the audio wavelet analysis.
</dc:description>
 <dc:description>Comment: 2 pages, 1 figure, conference: 8th Brazilian Symposium on Information
  and Computer System Security, 2008, Gramado, RS, Brazil</dc:description>
 <dc:date>2015-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07551</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07554</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Analytical Formulation of Power System Oscillation Frequency</dc:title>
 <dc:creator>Wang, Bin</dc:creator>
 <dc:creator>Sun, Kai</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This letter proposes an analytical approach to formulate the power system
oscillation frequency under a large disturbance. A fact is revealed that the
oscillation frequency is only the function of the oscillation amplitude when
the system's model and operating condition are fixed. Case studies also show
that this function is damping-insensitive and could be applied to an inter-area
model of a multi-machine power system.
</dc:description>
 <dc:description>Comment: 2 pages</dc:description>
 <dc:date>2015-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07554</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07561</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Primal robustness and semidefinite cones</dc:title>
 <dc:creator>You, Seungil</dc:creator>
 <dc:creator>Gattami, Ather</dc:creator>
 <dc:creator>Doyle, John C.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper reformulates and streamlines the core tools of robust stability
and performance for LTI systems using now-standard methods in convex
optimization. In particular, robustness analysis can be formulated directly as
a primal convex (semidefinite program or SDP) optimization problem using sets
of gramians whose closure is a semidefinite cone. This allows various
constraints such as structured uncertainty to be included directly, and
worst-case disturbances and perturbations constructed directly from the primal
variables. Well known results such as the KYP lemma and various scaled small
gain tests can also be obtained directly through standard SDP duality. To
readers familiar with robustness and SDPs, the framework should appear obvious,
if only in retrospect. But this is also part of its appeal and should enhance
pedagogy, and we hope suggest new research. There is a key lemma proving
closure of a grammian that is also obvious but our current proof appears
unnecessarily cumbersome, and a final aim of this paper is to enlist the help
of experts in robust control and convex optimization in finding simpler
alternatives.
</dc:description>
 <dc:description>Comment: A shorter version submitted to CDC 15</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07563</identifier>
 <datestamp>2015-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mind the Gap</dc:title>
 <dc:creator>Amir, Amihood</dc:creator>
 <dc:creator>Kopelowitz, Tsvi</dc:creator>
 <dc:creator>Levy, Avivit</dc:creator>
 <dc:creator>Pettie, Seth</dc:creator>
 <dc:creator>Porat, Ely</dc:creator>
 <dc:creator>Shalom, B. Riva</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We examine the complexity of the online Dictionary Matching with One Gap
Problem (DMOG) which is the following. Preprocess a dictionary $D$ of $d$
patterns, where each pattern contains a special gap symbol that can match any
string, so that given a text that arrives online, a character at a time, we can
report all of the patterns from $D$ that are suffixes of the text that has
arrived so far, before the next character arrives. In more general versions the
gap symbols are associated with bounds determining the possible lengths of
matching strings. Finding efficient algorithmic solutions for (online) DMOG has
proven to be a difficult algorithmic challenge. We demonstrate that the
difficulty in obtaining efficient solutions for the DMOG problem even, in the
offline setting, can be traced back to the infamous 3SUM conjecture.
Interestingly, our reduction deviates from the known reduction paths that
follow from 3SUM. In particular, most reductions from 3SUM go through the
set-disjointness problem, which corresponds to the problem of preprocessing a
graph to answer edge-triangles queries. We use a new path of reductions by
considering the complementary, although structurally very different,
vertex-triangles queries. Using this new path we show a conditional lower bound
of $\Omega(\delta(G_D)+op)$ time per text character, where $G_D$ is a bipartite
graph that captures the structure of $D$, $\delta(G_D)$ is the degeneracy of
this graph, and $op$ is the output size. We also provide matching upper-bounds
(up to sub-polynomial factors) for the vertex-triangles problem, and then
extend these techniques to the online DMOG problem. In particular, we introduce
algorithms whose time cost depends linearly on $\delta(G_D)$. Our algorithms
make use of graph orientations, together with some additional techniques.
Finally, when $\delta(G_D)$ is large we are able to obtain even more efficient
solutions.
</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:date>2015-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07568</identifier>
 <datestamp>2016-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Router-level community structure of the Internet Autonomous Systems</dc:title>
 <dc:creator>Beir&#xf3;, Mariano G.</dc:creator>
 <dc:creator>Grynberg, Sebasti&#xe1;n P.</dc:creator>
 <dc:creator>Alvarez-Hamelin, J. Ignacio</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>68U99, 05C85</dc:subject>
 <dc:subject>I.5.3</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  The Internet is composed of routing devices connected between them and
organized into independent administrative entities: the Autonomous Systems. The
existence of different types of Autonomous Systems (like large connectivity
providers, Internet Service Providers or universities) together with
geographical and economical constraints, turns the Internet into a complex
modular and hierarchical network. This organization is reflected in many
properties of the Internet topology, like its high degree of clustering and its
robustness.
  In this work, we study the modular structure of the Internet router-level
graph in order to assess to what extent the Autonomous Systems satisfy some of
the known notions of community structure. We show that the modular structure of
the Internet is much richer than what can be captured by the current community
detection methods, which are severely affected by resolution limits and by the
heterogeneity of the Autonomous Systems. Here we overcome this issue by using a
multiresolution detection algorithm combined with a small sample of nodes. We
also discuss recent work on community structure in the light of our results.
</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07568</dc:identifier>
 <dc:identifier>doi:10.1140/epjds/s13688-015-0048-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07576</identifier>
 <datestamp>2016-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SIRS Epidemics on Complex Networks: Concurrence of Exact Markov Chain
  and Approximated Models</dc:title>
 <dc:creator>Ruhi, Navid Azizan</dc:creator>
 <dc:creator>Hassibi, Babak</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We study the SIRS (Susceptible-Infected-Recovered-Susceptible) spreading
processes over complex networks, by considering its exact $3^n$-state Markov
chain model. The Markov chain model exhibits an interesting connection with its
$2n$-state nonlinear &quot;mean-field&quot; approximation and the latter's corresponding
linear approximation. We show that under the specific threshold where the
disease-free state is a globally stable fixed point of both the linear and
nonlinear models, the exact underlying Markov chain has an $O(\log n)$ mixing
time, which means the epidemic dies out quickly. In fact, the epidemic
eradication condition coincides for all the three models. Furthermore, when the
threshold condition is violated, which indicates that the linear model is not
stable, we show that there exists a unique second fixed point for the nonlinear
model, which corresponds to the endemic state. We also investigate the effect
of adding immunization to the SIRS epidemics by introducing two different
models, depending on the efficacy of the vaccine. Our results indicate that
immunization improves the threshold of epidemic eradication. Furthermore, the
common threshold for fast-mixing of the Markov chain and global stability of
the disease-free fixed point improves by the same factor for the
vaccination-dominant model.
</dc:description>
 <dc:description>Comment: A short version of this paper has been submitted to CDC 2015</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07576</dc:identifier>
 <dc:identifier>doi:10.1109/CDC.2015.7402660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07587</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universal Psychometrics Tasks: difficulty, composition and decomposition</dc:title>
 <dc:creator>Hernandez-Orallo, Jose</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This note revisits the concepts of task and difficulty. The notion of
cognitive task and its use for the evaluation of intelligent systems is still
replete with issues. The view of tasks as MDP in the context of reinforcement
learning has been especially useful for the formalisation of learning tasks.
However, this alternate interaction does not accommodate well for some other
tasks that are usual in artificial intelligence and, most especially, in animal
and human evaluation. In particular, we want to have a more general account of
episodes, rewards and responses, and, most especially, the computational
complexity of the algorithm behind an agent solving a task. This is crucial for
the determination of the difficulty of a task as the (logarithm of the) number
of computational steps required to acquire an acceptable policy for the task,
which includes the exploration of policies and their verification. We introduce
a notion of asynchronous-time stochastic tasks. Based on this interpretation,
we can see what task difficulty is, what instance difficulty is (relative to a
task) and also what task compositions and decompositions are.
</dc:description>
 <dc:description>Comment: 30 pages</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07590</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Precoder Design with Limited Feedback and Backhauling for Joint
  Transmission</dc:title>
 <dc:creator>Lakshmana, T. R.</dc:creator>
 <dc:creator>T&#xf6;lli, A.</dc:creator>
 <dc:creator>Devassy, R.</dc:creator>
 <dc:creator>Svensson, T.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A centralized coordinated multipoint downlink joint transmission in a
frequency division duplex system requires channel state information (CSI) to be
fed back from the cell-edge users to their serving BS, and aggregated at the
central coordination node for precoding, so that interference can be mitigated.
The control signals comprising of CSI and the precoding weights can easily
overwhelm the backhaul resources. Relative thresholding has been proposed to
alleviate the burden; however, this is at the cost of reduction in throughput.
In this paper, we propose utilizing the long term channel statistics comprising
of pathloss and shadow fading in the precoder design to model the statistical
interference for the unknown CSI. In this regard, a successive second order
cone programming (SSOCP) based precoder for maximizing the weighted sum rate is
proposed. The accuracy of the solution obtained is bounded with the branch and
bound technique. An alternative optimization framework via weighted mean square
error minimization is also derived. Both these approaches provide an efficient
solution close to the optimal, and also achieve efficient backhauling, in a
sense that the precoding weights are generated only for the active links. For
comparison, a stochastic approach based on particle swarm optimization is also
considered.
</dc:description>
 <dc:description>Comment: Under Review IEEE Transactions on Wireless Communications, Feb. 2015</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07590</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07604</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simultaneous Bidirectional Link Selection in Full Duplex MIMO Systems</dc:title>
 <dc:creator>Zhou, Mingxin</dc:creator>
 <dc:creator>Song, Lingyang</dc:creator>
 <dc:creator>Li, Yonghui</dc:creator>
 <dc:creator>Li, Xuelong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, we consider a point to point full duplex (FD) MIMO
communication system. We assume that each node is equipped with an arbitrary
number of antennas which can be used for transmission or reception. With FD
radios, bidirectional information exchange between two nodes can be achieved at
the same time. In this paper we design bidirectional link selection schemes by
selecting a pair of transmit and receive antenna at both ends for
communications in each direction to maximize the weighted sum rate or minimize
the weighted sum symbol error rate (SER). The optimal selection schemes require
exhaustive search, so they are highly complex. To tackle this problem, we
propose a Serial-Max selection algorithm, which approaches the exhaustive
search methods with much lower complexity. In the Serial-Max method, the
antenna pairs with maximum &quot;obtainable SINR&quot; at both ends are selected in a
two-step serial way. The performance of the proposed Serial-Max method is
analyzed, and the closed-form expressions of the average weighted sum rate and
the weighted sum SER are derived. The analysis is validated by simulations.
Both analytical and simulation results show that as the number of antennas
increases, the Serial-Max method approaches the performance of the
exhaustive-search schemes in terms of sum rate and sum SER.
</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07609</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Evolutionary Algorithm for Error-Driven Learning via Reinforcement</dc:title>
 <dc:creator>Liu, Yanping</dc:creator>
 <dc:creator>Reichle, Erik D.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Although different learning systems are coordinated to afford complex
behavior, little is known about how this occurs. This article describes a
theoretical framework that specifies how complex behaviors that might be
thought to require error-driven learning might instead be acquired through
simple reinforcement. This framework includes specific assumptions about the
mechanisms that contribute to the evolution of (artificial) neural networks to
generate topologies that allow the networks to learn large-scale complex
problems using only information about the quality of their performance. The
practical and theoretical implications of the framework are discussed, as are
possible biological analogs of the approach.
</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07609</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07612</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Omnidirectional Path Loss Models for Millimeter-Wave
  Outdoor Communications</dc:title>
 <dc:creator>Samimi, Mathew K.</dc:creator>
 <dc:creator>Rappaport, Theodore S.</dc:creator>
 <dc:creator>MacCartney Jr, George R.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This letter presents a probabilistic omnidirectional millimeter-wave path
loss model based on real-world 28 GHz and 73 GHz measurements collected in New
York City. The probabilistic path loss approach uses a free space line-of-sight
propagation model, and for non-line-of-sight conditions uses either a close-in
free space reference distance path loss model or a floating-intercept path loss
model. The probabilistic model employs a weighting function that specifies the
line-of-sight probability for a given transmitter-receiver separation distance.
Results show that the probabilistic path loss model offers virtually identical
results whether one uses a non-line-of-sight close-in free space reference
distance path loss model, with a reference distance of 1 meter, or a
floating-intercept path loss model. This letter also shows that site-specific
environmental information may be used to yield the probabilistic weighting
function for choosing between line-of-sight and non-line-of-sight conditions.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures, IEEE Wireless Communications Letters (March 2015)</dc:description>
 <dc:date>2015-03-25</dc:date>
 <dc:date>2015-06-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07612</dc:identifier>
 <dc:identifier>doi:10.1109/LWC.2015.2417559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07613</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised authorship attribution</dc:title>
 <dc:creator>Fifield, David</dc:creator>
 <dc:creator>Follan, Torbj&#xf8;rn</dc:creator>
 <dc:creator>Lunde, Emil</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We describe a technique for attributing parts of a written text to a set of
unknown authors. Nothing is assumed to be known a priori about the writing
styles of potential authors. We use multiple independent clusterings of an
input text to identify parts that are similar and dissimilar to one another. We
describe algorithms necessary to combine the multiple clusterings into a
meaningful output. We show results of the application of the technique on texts
having multiple writing styles.
</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07619</identifier>
 <datestamp>2015-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shared Autonomy via Hindsight Optimization</dc:title>
 <dc:creator>Javdani, Shervin</dc:creator>
 <dc:creator>Srinivasa, Siddhartha S.</dc:creator>
 <dc:creator>Bagnell, J. Andrew</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In shared autonomy, user input and robot autonomy are combined to control a
robot to achieve a goal. Often, the robot does not know a priori which goal the
user wants to achieve, and must both predict the user's intended goal, and
assist in achieving that goal. We formulate the problem of shared autonomy as a
Partially Observable Markov Decision Process with uncertainty over the user's
goal. We utilize maximum entropy inverse optimal control to estimate a
distribution over the user's goal based on the history of inputs. Ideally, the
robot assists the user by solving for an action which minimizes the expected
cost-to-go for the (unknown) goal. As solving the POMDP to select the optimal
action is intractable, we use hindsight optimization to approximate the
solution. In a user study, we compare our method to a standard
predict-then-blend approach. We find that our method enables users to
accomplish tasks more quickly while utilizing less input. However, when asked
to rate each system, users were mixed in their assessment, citing a tradeoff
between maintaining control authority and accomplishing tasks quickly.
</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:date>2015-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07621</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Evolution of Network Entropy in Classical and Quantum Consensus
  Dynamics</dc:title>
 <dc:creator>Fu, Shuangshuang</dc:creator>
 <dc:creator>Shi, Guodong</dc:creator>
 <dc:creator>Petersen, Ian R.</dc:creator>
 <dc:creator>James, Matthew R.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we investigate the evolution of the network entropy for
consensus dynamics in classical or quantum networks. We show that in the
classical case, the network entropy decreases at the consensus limit if the
node initial values are i.i.d. Bernoulli random variables, and the network
differential entropy is monotonically non-increasing if the node initial values
are i.i.d. Gaussian. While for quantum consensus dynamics, the network's von
Neumann entropy is in contrast non-decreasing. In light of this inconsistency,
we compare several gossiping algorithms with random or deterministic
coefficients for classical or quantum networks, and show that quantum gossiping
algorithms with deterministic coefficients are physically related to classical
gossiping algorithms with random coefficients.
</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07621</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07624</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analyzing Adaptive Cache Replacement Strategies</dc:title>
 <dc:creator>Consuegra, Mario E.</dc:creator>
 <dc:creator>Martinez, Wendy A.</dc:creator>
 <dc:creator>Narasimhan, Giri</dc:creator>
 <dc:creator>Rangaswami, Raju</dc:creator>
 <dc:creator>Shao, Leo</dc:creator>
 <dc:creator>Vietri, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Adaptive Replacement Cache (ARC) and CLOCK with Adaptive Replacement (CAR)
are state-of-the- art &quot;adaptive&quot; cache replacement algorithms invented to
improve on the shortcomings of classical cache replacement policies such as
LRU, LFU and CLOCK. By separating out items that have been accessed only once
and items that have been accessed more frequently, both ARC and CAR are able to
control the harmful effect of single-access items flooding the cache and
pushing out more frequently accessed items. Both ARC and CAR have been shown to
outperform their classical and popular counterparts in practice. Both
algorithms are complex, yet popular. Even though they can be treated as online
algorithms with an &quot;adaptive&quot; twist, a theoretical proof of the competitiveness
of ARC and CAR remained unsolved for over a decade. We show that the
competitiveness ratio of CAR (and ARC) has a lower bound of N + 1 (where N is
the size of the cache) and an upper bound of 18N (4N for ARC). If the size of
cache offered to ARC or CAR is larger than the one provided to OPT, then we
show improved competitiveness ratios. The important implication of the above
results are that no &quot;pathological&quot; worst-case request sequences exist that
could deteriorate the performance of ARC and CAR by more than a constant factor
as compared to LRU.
</dc:description>
 <dc:description>Comment: 26 pages</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:date>2017-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07626</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building the distributed WPS-services execution environment</dc:title>
 <dc:creator>Bychkov, Igor</dc:creator>
 <dc:creator>Ruzhnikov, Gennady</dc:creator>
 <dc:creator>Fedorov, Roman</dc:creator>
 <dc:creator>Shumilov, Alexander</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The article describes the environment of WPS-based (Web Processing Service)
distributed services, that uses scenarios in JavaScript programming language in
order to integrate services with each other. The environment standardizes data
processing procedures, stores all services-related information and offers the
set of basic WPS-services.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07626</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07628</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Indoor Localization Algorithm For Smartphones</dc:title>
 <dc:creator>Zhang, Kaiqing</dc:creator>
 <dc:creator>Hu, Hong</dc:creator>
 <dc:creator>Dai, Wenhan</dc:creator>
 <dc:creator>Shen, Yuan</dc:creator>
 <dc:creator>Win, Moe Z.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Increasing sources of sensor measurements and prior knowledge have become
available for indoor localization on smartphones. How to effectively utilize
these sources for enhancing localization accuracy is an important yet
challenging problem. In this paper, we present an area state-aided localization
algorithm that exploits various sources of information. Specifically, we
introduce the concept of area state to indicate the area where the user is on
an indoor map. The position of the user is then estimated using inertial
measurement unit (IMU) measurements with the aid of area states. The area
states are in turn updated based on the position estimates. To avoid
accumulated errors of IMU measurements, our algorithm uses WiFi received signal
strength indicator (RSSI) to indicate the vicinity of the user to the routers.
The experiment results show that our system can achieve satisfactory
localization accuracy in a typical indoor environment.
</dc:description>
 <dc:description>Comment: 17 pages, 9 figures</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07628</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07630</identifier>
 <datestamp>2015-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Events Determine Spreading Patterns: Information Transmission via
  Internal and External Influences on Social Networks</dc:title>
 <dc:creator>Liu, Chuang</dc:creator>
 <dc:creator>Zhan, Xiu-Xiu</dc:creator>
 <dc:creator>Zhang, Zi-Ke</dc:creator>
 <dc:creator>Sun, Gui-Quan</dc:creator>
 <dc:creator>Hui, Pak Ming</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Recently, information transmission models motivated by the classical epidemic
propagation, have been applied to a wide-range of social systems, generally
assume that information mainly transmits among individuals via peer-to-peer
interactions on social networks. In this paper, we consider one more approach
for users to get information: the out-of-social-network influence. Empirical
analyses of eight typical events' diffusion on a very large micro-blogging
system, \emph{Sina Weibo}, show that the external influence has significant
impact on information spreading along with social activities. In addition, we
propose a theoretical model to interpret the spreading process via both
internal and external channels, considering three essential properties: (i)
memory effect; (ii) role of spreaders; and (iii) non-redundancy of contacts.
Experimental and mathematical results indicate that the information indeed
spreads much quicker and broader with mutual effects of the internal and
external influences. More importantly, the present model reveals that the event
characteristic would highly determine the essential spreading patterns once the
network structure is established. The results may shed some light on the
in-depth understanding of the underlying dynamics of information transmission
on real social networks.
</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07630</dc:identifier>
 <dc:identifier>doi:10.1088/1367-2630/17/11/113045</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07640</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Closed-Loop UL Power Control Scheme for Interference Mitigation in
  Dynamic TD-LTE Systems</dc:title>
 <dc:creator>Chen, Qinqin</dc:creator>
 <dc:creator>Zhao, Hui</dc:creator>
 <dc:creator>Li, Lin</dc:creator>
 <dc:creator>Long, Hang</dc:creator>
 <dc:creator>Wang, Jianquan</dc:creator>
 <dc:creator>Hou, Xiaoyue</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The TD-LTE system is envisaged to adopt dynamic time division duplexing (TDD)
transmissions for small cells to adapt their communication service to the fast
variation of downlink (DL) and uplink (UL) traffic demands. However, different
DL/UL directions for the same subframe in adjacent cells will result in new
destructive interference components, i.e., eNB-to-eNB and UE-to-UE, with levels
that can significantly differ from one subframe to another. In this paper, a
feasible UL power control mechanism is proposed to manage eNB-to-eNB
interference, where different UL power control parameters are set based on
different interference level. We consider the geometric location information
and the subframe set selection process about adjacent eNBs when the
interference level is estimated. The performance of the proposed scheme is
evaluated through system level simulations and it is shown that the scheme can
achieve preferable improvement in terms of UL average and 5%-ile packet
throughputs compared with the original scheme without power control. Also, the
UE-to-UE interference is not worse when the UE transmit power become higher.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures,conference</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07640</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07645</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Verification Of Role-Based Access Control Policies Constraints
  Using Prover9</dc:title>
 <dc:creator>Sabri, Khair Eddin</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Access control policies are used to restrict access to sensitive records for
authorized users only. One approach for specifying policies is using role based
access control (RBAC) where authorization is given to roles instead of users.
Users are assigned to roles such that each user can access all the records that
are allowed to his/her role. RBAC has a great interest because of its
flexibility. One issue in RBAC is dealing with constraints. Usually, policies
should satisfy pre-defined constraints as for example separation of duty (SOD)
which states that users are not allowed to play two conflicting roles.
Verifying the satisfiability of constraints based on policies is time consuming
and may lead to errors. Therefore, an automated verification is essential. In
this paper, we propose a theory for specifying policies and constraints in
first order logic. Furthermore, we present a comprehensive list of constraints.
We identity constraints based on the relation between users and roles, between
roles and permission on records, between users and permission on records, and
between users, roles, and permission on records. Then, we use a general purpose
theorem prover tool called Prover9 for proving the satisfaction of constraints.
</dc:description>
 <dc:description>Comment: 10 pages in International Journal of Security, Privacy and Trust
  Management (IJSPTM) Vol 4, No 1, February 2015</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07645</dc:identifier>
 <dc:identifier>doi:10.5121/ijsptm.2015.4101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07652</identifier>
 <datestamp>2015-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Upper Bound on the Capacity of a Cascade of Nonlinear and Noisy Channels</dc:title>
 <dc:creator>Kramer, Gerhard</dc:creator>
 <dc:creator>Yousefi, Mansoor I.</dc:creator>
 <dc:creator>Kschischang, Frank R.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  An upper bound on the capacity of a cascade of nonlinear and noisy channels
is presented. The cascade mimics the split-step Fourier method for computing
waveform propagation governed by the stochastic generalized nonlinear
Schroedinger equation. It is shown that the spectral efficiency of the cascade
is at most log(1+SNR), where SNR is the receiver signal-to-noise ratio. The
results may be applied to optical fiber channels. However, the definition of
bandwidth is subtle and leaves open interpretations of the bound. Some of these
interpretations are discussed.
</dc:description>
 <dc:description>Comment: The main change is to define the noise as bandlimited already in (8)
  rather than before (15). This serves to clarify subsequent steps</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:date>2015-04-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07653</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequence complexity and work extraction</dc:title>
 <dc:creator>Merhav, Neri</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a simplified version of a solvable model by Mandal and Jarzynski,
which constructively demonstrates the interplay between work extraction and the
increase of the Shannon entropy of an information reservoir which is in contact
with the physical system. We extend Mandal and Jarzynski's main findings in
several directions: First, we allow sequences of correlated bits rather than
just independent bits. Secondly, at least for the case of binary information,
we show that, in fact, the Shannon entropy is only one measure of complexity of
the information that must increase in order for work to be extracted. The
extracted work can also be upper bounded in terms of the increase in other
quantities that measure complexity, like the predictability of future bits from
past ones. Third, we provide an extension to the case of non-binary information
(i.e., a larger alphabet), and finally, we extend the scope to the case where
the incoming bits (before the interaction) form an individual sequence, rather
than a random one. In this case, the entropy before the interaction can be
replaced by the Lempel-Ziv (LZ) complexity of the incoming sequence, a fact
that gives rise to an entropic meaning of the LZ complexity, not only in
information theory, but also in physics.
</dc:description>
 <dc:description>Comment: 17 pages, 1 figure. Submitted for publication. Results of section 6
  were improved</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07653</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07659</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Loo.py: From Fortran to performance via transformation and substitution
  rules</dc:title>
 <dc:creator>Kl&#xf6;ckner, Andreas</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>D.3.4, D.1.3, G.4</dc:subject>
 <dc:description>  A large amount of numerically-oriented code is written and is being written
in legacy languages. Much of this code could, in principle, make good use of
data-parallel throughput-oriented computer architectures. Loo.py, a
transformation-based programming system targeted at GPUs and general
data-parallel architectures, provides a mechanism for user-controlled
transformation of array programs. This transformation capability is designed to
not just apply to programs written specifically for Loo.py, but also those
imported from other languages such as Fortran. It eases the trade-off between
achieving high performance, portability, and programmability by allowing the
user to apply a large and growing family of transformations to an input
program. These transformations are expressed in and used from Python and may be
applied from a variety of settings, including a pragma-like manner from other
languages.
</dc:description>
 <dc:description>Comment: ARRAY 2015 - 2nd ACM SIGPLAN International Workshop on Libraries,
  Languages and Compilers for Array Programming (ARRAY 2015)</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:date>2015-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07659</dc:identifier>
 <dc:identifier>doi:10.1145/2774959.2774969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07680</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Observer design for position and velocity bias estimation from a single
  direction output</dc:title>
 <dc:creator>Bras, Florent Le</dc:creator>
 <dc:creator>Hamel, Tarek</dc:creator>
 <dc:creator>Mahony, Robert</dc:creator>
 <dc:creator>Samson, Claude</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper addresses the problem of estimating the position of an object
moving in $R^n$ from direction and velocity measurements. After addressing
observability issues associated with this problem, a nonlinear observer is
designed so as to encompass the case where the measured velocity is corrupted
by a constant bias. Global exponential convergence of the estimation error is
proved under a condition of persistent excitation upon the direction
measurements. Simulation results illustrate the performance of the observer.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07680</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07691</identifier>
 <datestamp>2015-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sensitivity versus Certificate Complexity of Boolean Functions</dc:title>
 <dc:creator>Ambainis, Andris</dc:creator>
 <dc:creator>Pr&#x16b;sis, Kri&#x161;j&#x101;nis</dc:creator>
 <dc:creator>Vihrovs, Jevg&#x113;nijs</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Sensitivity, block sensitivity and certificate complexity are basic
complexity measures of Boolean functions. The famous sensitivity conjecture
claims that sensitivity is polynomially related to block sensitivity. However,
it has been notoriously hard to obtain even exponential bounds. Since block
sensitivity is known to be polynomially related to certificate complexity, an
equivalent of proving this conjecture would be showing that certificate
complexity is polynomially related to sensitivity. Previously, it has been
shown that $bs(f) \leq C(f) \leq 2^{s(f)-1} s(f) - (s(f)-1)$. In this work, we
give a better upper bound of $bs(f) \leq C(f) \leq
\max\left(2^{s(f)-1}\left(s(f)-\frac 1 3\right), s(f)\right)$ using a recent
theorem limiting the structure of function graphs. We also examine relations
between these measures for functions with small 1-sensitivity $s_1(f)$ and
arbitrary 0-sensitivity $s_0(f)$.
</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:date>2015-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07691</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07692</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sampled-data $H^{\infty}$ Optimization for Self-interference Suppression
  in Baseband Signal Subspaces</dc:title>
 <dc:creator>Sasahara, Hampei</dc:creator>
 <dc:creator>Nagahara, Masaaki</dc:creator>
 <dc:creator>Hayashi, Kazunori</dc:creator>
 <dc:creator>Yamamoto, Yutaka</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this article, we propose a design method of selfinterference cancelers for
wireless relay stations taking account of the baseband signal subspace. The
problem is first formulated as a sampled-data $H^{\infty}$ control problem with
a generalized sampler and a generalized hold, which can be reduced to a
discretetime $\ell^2$-induced norm minimization problem. Taking account of the
implementation of the generalized sampler and hold, we adopt the filter-sampler
structure for the generalized sampler, and the uspampler-filter-hold structure
for the generalized hold. Under these implementation constraints, we
reformulate the problem as a standard discrete-time $H^{\infty}$ control
problem by using the discrete-time lifting technique. A simulation result is
shown to illustrate the effectiveness of the proposed method.
</dc:description>
 <dc:description>Comment: submitted; 6pages, 13 figures. arXiv admin note: text overlap with
  arXiv:1503.02379</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07692</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07693</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communication Patterns in Mean Field Models for Wireless Sensor Networks</dc:title>
 <dc:creator>Talebi, Mahmoud</dc:creator>
 <dc:creator>Groote, Jan Friso</dc:creator>
 <dc:creator>Linnartz, Jean-Paul</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Wireless sensor networks are usually composed of a large number of nodes, and
with the increasing processing power and power consumption efficiency they are
expected to run more complex protocols in the future. These pose problems in
the field of verification and performance evaluation of wireless networks. In
this paper, we tailor the mean-field theory as a modeling technique to analyze
their behavior. We apply this method to the slotted ALOHA protocol, and
establish results on the long term trends of the protocol within a very large
network, specially regarding the stability of ALOHA-type protocols.
</dc:description>
 <dc:description>Comment: 22 pages, in LNCS format, Submitted to QEST'15</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07693</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07697</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Eye Centers Localization with Zero--Crossing Encoded Image
  Projections</dc:title>
 <dc:creator>Florea, Laura</dc:creator>
 <dc:creator>Florea, Corneliu</dc:creator>
 <dc:creator>Vertan, Constantin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a new framework for the eye centers localization by the
joint use of encoding of normalized image projections and a Multi Layer
Perceptron (MLP) classifier. The encoding is novel and it consists in
identifying the zero-crossings and extracting the relevant parameters from the
resulting modes. The compressed normalized projections produce feature
descriptors that are inputs to a properly-trained MLP, for discriminating among
various categories of image regions. The proposed framework forms a fast and
reliable system for the eye centers localization, especially in the context of
face expression analysis in unconstrained environments. We successfully test
the proposed method on a wide variety of databases including BioID,
Cohn-Kanade, Extended Yale B and Labelled Faces in the Wild (LFW) databases.
</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07697</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07705</identifier>
 <datestamp>2017-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Log-concavity and lower bounds for arithmetic circuits</dc:title>
 <dc:creator>Garc&#xed;a-Marco, Ignacio</dc:creator>
 <dc:creator>Koiran, Pascal</dc:creator>
 <dc:creator>Tavenas, S&#xe9;bastien</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Commutative Algebra</dc:subject>
 <dc:description>  One question that we investigate in this paper is, how can we build
log-concave polynomials using sparse polynomials as building blocks? More
precisely, let $f = \sum\_{i = 0}^d a\_i X^i \in \mathbb{R}^+[X]$ be a
polynomial satisfying the log-concavity condition $a\_i^2 \textgreater{} \tau
a\_{i-1}a\_{i+1}$ for every $i \in \{1,\ldots,d-1\},$ where $\tau
\textgreater{} 0$. Whenever $f$ can be written under the form $f = \sum\_{i =
1}^k \prod\_{j = 1}^m f\_{i,j}$ where the polynomials $f\_{i,j}$ have at most
$t$ monomials, it is clear that $d \leq k t^m$. Assuming that the $f\_{i,j}$
have only non-negative coefficients, we improve this degree bound to $d =
\mathcal O(k m^{2/3} t^{2m/3} {\rm log^{2/3}}(kt))$ if $\tau \textgreater{} 1$,
and to $d \leq kmt$ if $\tau = d^{2d}$.
  This investigation has a complexity-theoretic motivation: we show that a
suitable strengthening of the above results would imply a separation of the
algebraic complexity classes VP and VNP. As they currently stand, these results
are strong enough to provide a new example of a family of polynomials in VNP
which cannot be computed by monotone arithmetic circuits of polynomial size.
</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07705</dc:identifier>
 <dc:identifier>MFCS 2015, Part II, LNCS 9235, pp. 361-371 (2015)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07706</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pain Intensity Estimation by a Self--Taught Selection of Histograms of
  Topographical Features</dc:title>
 <dc:creator>Florea, Corneliu</dc:creator>
 <dc:creator>Florea, Laura</dc:creator>
 <dc:creator>Boia, Raluca</dc:creator>
 <dc:creator>Bandrabur, Alessandra</dc:creator>
 <dc:creator>Vertan, Constantin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Pain assessment through observational pain scales is necessary for special
categories of patients such as neonates, patients with dementia, critically ill
patients, etc. The recently introduced Prkachin-Solomon score allows pain
assessment directly from facial images opening the path for multiple assistive
applications. In this paper, we introduce the Histograms of Topographical (HoT)
features, which are a generalization of the topographical primal sketch, for
the description of the face parts contributing to the mentioned score. We
propose a semi-supervised, clustering oriented self--taught learning procedure
developed on the emotion oriented Cohn-Kanade database. We use this procedure
to improve the discrimination between different pain intensity levels and the
generalization with respect to the monitored persons, while testing on the UNBC
McMaster Shoulder Pain database.
</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07706</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07711</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ideological and Temporal Components of Network Polarization in Online
  Political Participatory Media</dc:title>
 <dc:creator>Garcia, David</dc:creator>
 <dc:creator>Abisheva, Adiya</dc:creator>
 <dc:creator>Schweighofer, Simon</dc:creator>
 <dc:creator>Serd&#xfc;lt, Uwe</dc:creator>
 <dc:creator>Schweitzer, Frank</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Political polarization is traditionally analyzed through the ideological
stances of groups and parties, but it also has a behavioral component that
manifests in the interactions between individuals. We present an empirical
analysis of the digital traces of politicians in politnetz.ch, a Swiss online
platform focused on political activity, in which politicians interact by
creating support links, comments, and likes. We analyze network polarization as
the level of intra- party cohesion with respect to inter-party connectivity,
finding that supports show a very strongly polarized structure with respect to
party alignment. The analysis of this multiplex network shows that each layer
of interaction contains relevant information, where comment groups follow
topics related to Swiss politics. Our analysis reveals that polarization in the
layer of likes evolves in time, increasing close to the federal elections of
2011. Furthermore, we analyze the internal social network of each party through
metrics related to hierarchical structures, information efficiency, and social
resilience. Our results suggest that the online social structure of a party is
related to its ideology, and reveal that the degree of connectivity across two
parties increases when they are close in the ideological space of a multi-party
system.
</dc:description>
 <dc:description>Comment: 35 pages, 11 figures, Internet, Policy &amp; Politics Conference,
  University of Oxford, Oxford, UK, 25-26 September 2014</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07711</dc:identifier>
 <dc:identifier>Policy &amp; Internet, 7(1) (2015)</dc:identifier>
 <dc:identifier>doi:10.1002/poi3.82</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07713</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A method for business process reengineering based on enterprise ontology</dc:title>
 <dc:creator>Bahramnejad, Pedram</dc:creator>
 <dc:creator>Sharafi, Sayed Mehran</dc:creator>
 <dc:creator>Nabiollahi, Akbar</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Business Process Reengineering increases enterprise's chance to survive in
competition among organizations , but failure rate among reengineering efforts
is high, so new methods that decrease failure, are needed, in this paper a
business process reengineering method is presented that uses Enterprise
Ontology for modelling the current system and its goal is to improve analysing
current system and decreasing failure rate of BPR, and cost and time of
performing processes, In this method instead of just modelling processes,
processes with their : interactions and relations, environment, staffs and
customers will be modelled in enterprise ontology. Also in choosing processes
for reengineering step, after choosing them, processes which, according to the
enterprise ontology, has the most connection with the chosen ones, will also be
chosen to reengineer, finally this method is implemented on a company and As-Is
and To-Be processes are simulated and compared by ARIS tools, Report and
Simulation Experiment
</dc:description>
 <dc:description>Comment: 15 pages, published in IJSEA</dc:description>
 <dc:date>2015-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07713</dc:identifier>
 <dc:identifier>doi:10.5121/ijsea.2015.6103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07715</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Computational Theory of Intelligence: Data Aggregation</dc:title>
 <dc:creator>Kovach, Daniel</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>68T27, 97C40, 97R40</dc:subject>
 <dc:subject>I.2.0</dc:subject>
 <dc:subject>I.2.1</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  In this paper, we will expound upon the concepts proffered in [1], where we
proposed an information theoretic approach to intelligence in the computational
sense. We will examine data and meme aggregation, and study the effect of
limited resources on the resulting meme amplitudes.
</dc:description>
 <dc:description>Comment: Published in IJMNTA</dc:description>
 <dc:date>2014-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07715</dc:identifier>
 <dc:identifier>doi:10.4236/ijmnta.2014.34016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07716</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Review of Popular Applications on Google Play - Do They Cater to
  Visually Impaired Users?</dc:title>
 <dc:creator>Venugopal, Gayatri</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The number of applications on online mobile application stores is increasing
at a rapid rate. Smart-phones are used by a wide range of people varying in
age, and also in the ability to use a smart phone. With the increasing
dependency on smart-phones, the paper aims to determine whether the popular
applications on Google Play, the official store for Android applications, can
be used by people with vision impairment. The accessibility of the applications
was tested using an external keyboard, and TalkBack, an accessibility tool
developed by Google. It was found that several popular applications on the
store were not designed keeping accessibility in mind. It was observed that
there exists a weak positive relationship between the popularity of the
application and its accessibility. A framework is proposed that can be used by
developers to improve the accessibility of an application. The paper also
discusses the programming aspects to be considered while developing an Android
application, so that the application can be used by sighted as well as visually
impaired users.
</dc:description>
 <dc:description>Comment: 19 pages, 1 figure, 3 tables</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07716</dc:identifier>
 <dc:identifier>Indian Journal of Science and Technology, Vol 8 S4, 221 to 239,
  February 2015</dc:identifier>
 <dc:identifier>doi:10.17485/ijst/2015/v8iS4/61436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07717</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ASPeRiX, a First Order Forward Chaining Approach for Answer Set
  Computing</dc:title>
 <dc:creator>Lef&#xe8;vre, Claire</dc:creator>
 <dc:creator>B&#xe9;atrix, Christopher</dc:creator>
 <dc:creator>St&#xe9;phan, Igor</dc:creator>
 <dc:creator>Garcia, Laurent</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>68Txx</dc:subject>
 <dc:description>  The natural way to use Answer Set Programming (ASP) to represent knowledge in
Artificial Intelligence or to solve a combinatorial problem is to elaborate a
first order logic program with default negation. In a preliminary step this
program with variables is translated in an equivalent propositional one by a
first tool: the grounder. Then, the propositional program is given to a second
tool: the solver. This last one computes (if they exist) one or many answer
sets (stable models) of the program, each answer set encoding one solution of
the initial problem. Until today, almost all ASP systems apply this two steps
computation. In this article, the project ASPeRiX is presented as a first order
forward chaining approach for Answer Set Computing. This project was amongst
the first to introduce an approach of answer set computing that escapes the
preliminary phase of rule instantiation by integrating it in the search
process. The methodology applies a forward chaining of first order rules that
are grounded on the fly by means of previously produced atoms. Theoretical
foundations of the approach are presented, the main algorithms of the ASP
solver ASPeRiX are detailed and some experiments and comparisons with existing
systems are provided.
</dc:description>
 <dc:description>Comment: 50 pages. To appear in Theory and Practice of Logic Programming
  (TPLP)</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07717</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07722</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequential evacuation strategy for multiple rooms toward the same means
  of egress</dc:title>
 <dc:creator>Parisi, Daniel R.</dc:creator>
 <dc:creator>Negri, Pablo A.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  This paper examines different evacuation strategies for systems where several
rooms evacuate trough the same means of egress, using microscopic pedestrian
simulation.As a case study, a medium-rise office building is considered. It was
found that the standard strategy, whereby the simultaneous evacuation of all
levels is performed, can be improved by a sequential evacuation, beginning with
the lowest floor and continuing successively with each one of the upper floors
after a certain delay. The importance of the present research is that it
provides the basis for the design and implementation of new evacuation
strategies and alarm systems that could significantly improve the evacuation of
multiple rooms trough a common means of escape.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures</dc:description>
 <dc:date>2014-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07722</dc:identifier>
 <dc:identifier>Papers in Physics 6, 060013 (2014)</dc:identifier>
 <dc:identifier>doi:10.4279/PIP.060013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07723</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Voting Behaviour and Power in Online Democracy: A Study of
  LiquidFeedback in Germany's Pirate Party</dc:title>
 <dc:creator>Kling, Christoph Carl</dc:creator>
 <dc:creator>Kunegis, Jerome</dc:creator>
 <dc:creator>Hartmann, Heinrich</dc:creator>
 <dc:creator>Strohmaier, Markus</dc:creator>
 <dc:creator>Staab, Steffen</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>K.4.1</dc:subject>
 <dc:description>  In recent years, political parties have adopted Online Delegative Democracy
platforms such as LiquidFeedback to organise themselves and their political
agendas via a grassroots approach. A common objection against the use of these
platforms is the delegation system, where a user can delegate his vote to
another user, giving rise to so-called super-voters, i.e. powerful users who
receive many delegations. It has been asserted in the past that the presence of
these super-voters undermines the democratic process, and therefore delegative
democracy should be avoided. In this paper, we look at the emergence of
super-voters in the largest delegative online democracy platform worldwide,
operated by Germany's Pirate Party. We investigate the distribution of power
within the party systematically, study whether super-voters exist, and explore
the influence they have on the outcome of votings conducted online. While we
find that the theoretical power of super-voters is indeed high, we also observe
that they use their power wisely. Super-voters do not fully act on their power
to change the outcome of votes, but they vote in favour of proposals with the
majority of voters in many cases thereby exhibiting a stabilising effect on the
system. We use these findings to present a novel class of power indices that
considers observed voting biases and gives significantly better predictions
than state-of-the-art measures.
</dc:description>
 <dc:description>Comment: 11 pages, 11 figures, appeared in ICWSM 2015</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07723</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07737</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Business Rule Mining from Spreadsheets</dc:title>
 <dc:creator>Roy, Sohon</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Business rules represent the knowledge that guides the operations of a
business organization. They are implemented in software applications used by
organizations, and the activity of extracting them from software is known as
business rule mining. It has various purposes amongst which migration and
generating documentation are the most common. However, apart from conventional
software, organizations also use spreadsheets for a large part of their
operations and decision-making activities. Therefore we believe that
spreadsheets are also rich in business rules. We thus propose to develop an
automated system for extracting business rules from spreadsheets in a human
comprehensible natural language format. This position paper describes our
motivation, the problem description, related work, and challenges we foresee.
</dc:description>
 <dc:description>Comment: In Proceedings of the 2nd Workshop on Software Engineering Methods in
  Spreadsheets (http://spreadsheetlab.org/sems15/)</dc:description>
 <dc:date>2015-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07737</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07757</identifier>
 <datestamp>2016-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geographies of an online social network</dc:title>
 <dc:creator>Lengyel, Bal&#xe1;zs</dc:creator>
 <dc:creator>Varga, Attila</dc:creator>
 <dc:creator>S&#xe1;gv&#xe1;ri, Bence</dc:creator>
 <dc:creator>Jakobi, &#xc1;kos</dc:creator>
 <dc:creator>Kert&#xe9;sz, J&#xe1;nos</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  How is online social media activity structured in the geographical space?
Recent studies have shown that in spite of earlier visions about the &quot;death of
distance&quot;, physical proximity is still a major factor in social tie formation
and maintenance in virtual social networks. Yet, it is unclear, what are the
characteristics of the distance dependence in online social networks. In order
to explore this issue the complete network of the former major Hungarian online
social network is analyzed. We find that the distance dependence is weaker for
the online social network ties than what was found earlier for phone
communication networks. For a further analysis we introduced a coarser
granularity: We identified the settlements with the nodes of a network and
assigned two kinds of weights to the links between them. When the weights are
proportional to the number of contacts we observed weakly formed, but spatially
based modules resembling to the borders of macro-regions, the highest level of
regional administration in the country. If the weights are defined relative to
an uncorrelated null model, the next level of administrative regions, counties
are reflected.
</dc:description>
 <dc:description>Comment: 19 pages pdf file. Minor changes mainly about users abroad plus maps
  redrawn</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:date>2015-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07757</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0137248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07759</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-scale Biological Meta-database Management</dc:title>
 <dc:creator>Pedersen, Edvard</dc:creator>
 <dc:creator>Bongo, Lars Ailo</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Up-to-date meta-databases are vital for the analysis of biological data.
However,the current exponential increase in biological data leads to
exponentially increasing meta-database sizes. Large-scale meta-database
management is therefore an important challenge for production platforms
providing services for biological data analysis. In particular, there is often
a need either to run an analysis with a particular version of a meta-database,
or to rerun an analysis with an updated meta-database. We present our GeStore
approach for biological meta-database management. It provides efficient storage
and runtime generation of specific meta-database versions, and efficient
incremental updates for biological data analysis tools. The approach is
transparent to the tools, and we provide a framework that makes it easy to
integrate GeStore with biological data analysis frameworks. We present the
GeStore system, an evaluation of the performance characteristics of the system,
and an evaluation of the benefits for a biological data analysis workflow.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures, 4 tables</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:date>2016-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07759</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07768</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NeuCoin: the First Secure, Cost-efficient and Decentralized
  Cryptocurrency</dc:title>
 <dc:creator>Davarpanah, Kourosh</dc:creator>
 <dc:creator>Kaufman, Dan</dc:creator>
 <dc:creator>Pubellier, Ophelie</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  NeuCoin is a decentralized peer-to-peer cryptocurrency derived from Sunny
King's Peercoin, which itself was derived from Satoshi Nakamoto's Bitcoin. As
with Peercoin, proof-of-stake replaces proof-of-work as NeuCoin's security
model, effectively replacing the operating costs of Bitcoin miners
(electricity, computers) with the capital costs of holding the currency.
Proof-of-stake also avoids proof-of-work's inherent tendency towards
centralization resulting from competition for coinbase rewards among miners
based on lowest cost electricity and hash power.
  NeuCoin increases security relative to Peercoin and other existing
proof-of-stake currencies in numerous ways, including: (1) incentivizing nodes
to continuously stake coins over time through substantially higher mining
rewards and lower minimum stake age; (2) abandoning the use of coin age in the
mining formula; (3) causing the stake modifier parameter to change over time
for each stake; and (4) utilizing a client that punishes nodes that attempt to
mine on multiple branches with duplicate stakes.
  This paper demonstrates how NeuCoin's proof-of-stake implementation addresses
all commonly raised &quot;nothing at stake&quot; objections to generic proof-of-stake
systems. It also reviews many of the flaws of proof-of-work designs to
highlight the potential for an alternate cryptocurrency that solves these
flaws.
</dc:description>
 <dc:description>Comment: 39 pages, 10 figures</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07768</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07780</identifier>
 <datestamp>2015-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mapping ceramics research and its evolution</dc:title>
 <dc:creator>Deville, Sylvain</dc:creator>
 <dc:creator>Stevenson, Adam J.</dc:creator>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  We show here how a simple data mining of bibliographic records can be used to
follow and help understand the evolution of a research domain, at a level that
cannot be captured by reading individual papers in a field of this size. We
illustrate the approach by investigating 43 years of research on ceramic
materials, covered by 253k bibliographic records. The patterns of keywords used
reveal the trends and the evolution of research ideas and priorities within the
field. Simple, interactive tools based on co-word network analysis help us
better appreciate the organization and relationships of ideas or individuals,
and hopefully allow identification of unexplored concepts, connections, or
approaches on a given topic.
</dc:description>
 <dc:description>Comment: 15 pages, 8 figures, 4 supplementary materials figures. We are
  looking for a journal to publish this paper. If you are an editor and are
  interested that we submit this paper to your journal, please contact us</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07780</dc:identifier>
 <dc:identifier>Journal of the American Ceramic Society Volume 98, Issue 8, pages
  2324-2332, August 2015</dc:identifier>
 <dc:identifier>doi:10.1111/jace.13699</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07783</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Learning free Naive Bayes Nearest Neighbor-based Domain
  Adaptation</dc:title>
 <dc:creator>Saeedan, Faraz</dc:creator>
 <dc:creator>Caputo, Barbara</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  As of today, object categorization algorithms are not able to achieve the
level of robustness and generality necessary to work reliably in the real
world. Even the most powerful convolutional neural network we can train fails
to perform satisfactorily when trained and tested on data from different
databases. This issue, known as domain adaptation and/or dataset bias in the
literature, is due to a distribution mismatch between data collections. Methods
addressing it go from max-margin classifiers to learning how to modify the
features and obtain a more robust representation. Recent work showed that by
casting the problem into the image-to-class recognition framework, the domain
adaptation problem is significantly alleviated \cite{danbnn}. Here we follow
this approach, and show how a very simple, learning free Naive Bayes Nearest
Neighbor (NBNN)-based domain adaptation algorithm can significantly alleviate
the distribution mismatch among source and target data, especially when the
number of classes and the number of sources grow. Experiments on standard
benchmarks used in the literature show that our approach (a) is competitive
with the current state of the art on small scale problems, and (b) achieves the
current state of the art as the number of classes and sources grows, with
minimal computational requirements.
</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07790</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transductive Multi-label Zero-shot Learning</dc:title>
 <dc:creator>Fu, Yanwei</dc:creator>
 <dc:creator>Yang, Yongxin</dc:creator>
 <dc:creator>Hospedales, Tim</dc:creator>
 <dc:creator>Xiang, Tao</dc:creator>
 <dc:creator>Gong, Shaogang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Zero-shot learning has received increasing interest as a means to alleviate
the often prohibitive expense of annotating training data for large scale
recognition problems. These methods have achieved great success via learning
intermediate semantic representations in the form of attributes and more
recently, semantic word vectors. However, they have thus far been constrained
to the single-label case, in contrast to the growing popularity and importance
of more realistic multi-label data. In this paper, for the first time, we
investigate and formalise a general framework for multi-label zero-shot
learning, addressing the unique challenge therein: how to exploit multi-label
correlation at test time with no training data for those classes? In
particular, we propose (1) a multi-output deep regression model to project an
image into a semantic word space, which explicitly exploits the correlations in
the intermediate semantic layer of word vectors; (2) a novel zero-shot learning
algorithm for multi-label data that exploits the unique compositionality
property of semantic word vector representations; and (3) a transductive
learning strategy to enable the regression model learned from seen classes to
generalise well to unseen classes. Our zero-shot learning experiments on a
number of standard multi-label datasets demonstrate that our method outperforms
a variety of baselines.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures, Accepted to BMVC 2014 (oral)</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07790</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07792</identifier>
 <datestamp>2015-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental Computation with Names</dc:title>
 <dc:creator>Hammer, Matthew A.</dc:creator>
 <dc:creator>Dunfield, Joshua</dc:creator>
 <dc:creator>Headley, Kyle</dc:creator>
 <dc:creator>Labich, Nicholas</dc:creator>
 <dc:creator>Foster, Jeffrey S.</dc:creator>
 <dc:creator>Hicks, Michael</dc:creator>
 <dc:creator>Van Horn, David</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  Over the past thirty years, there has been significant progress in developing
general-purpose, language-based approaches to incremental computation, which
aims to efficiently update the result of a computation when an input is
changed. A key design challenge in such approaches is how to provide efficient
incremental support for a broad range of programs. In this paper, we argue that
first-class names are a critical linguistic feature for efficient incremental
computation. Names identify computations to be reused across differing runs of
a program, and making them first class gives programmers a high level of
control over reuse. We demonstrate the benefits of names by presenting NOMINAL
ADAPTON, an ML-like language for incremental computation with names. We
describe how to use NOMINAL ADAPTON to efficiently incrementalize several
standard programming patterns---including maps, folds, and unfolds---and show
how to build efficient, incremental probabilistic trees and tries. Since
NOMINAL ADAPTON's implementation is subtle, we formalize it as a core calculus
and prove it is from-scratch consistent, meaning it always produces the same
answer as simply re-running the computation. Finally, we demonstrate that
NOMINAL ADAPTON can provide large speedups over both from-scratch computation
and ADAPTON, a previous state-of-the-art incremental computation system.
</dc:description>
 <dc:description>Comment: OOPSLA '15, October 25-30, 2015, Pittsburgh, PA, USA</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:date>2015-10-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07792</dc:identifier>
 <dc:identifier>doi:10.1145/2814270.2814305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07793</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gibbs Sampling with Low-Power Spiking Digital Neurons</dc:title>
 <dc:creator>Das, Srinjoy</dc:creator>
 <dc:creator>Pedroni, Bruno Umbria</dc:creator>
 <dc:creator>Merolla, Paul</dc:creator>
 <dc:creator>Arthur, John</dc:creator>
 <dc:creator>Cassidy, Andrew S.</dc:creator>
 <dc:creator>Jackson, Bryan L.</dc:creator>
 <dc:creator>Modha, Dharmendra</dc:creator>
 <dc:creator>Cauwenberghs, Gert</dc:creator>
 <dc:creator>Kreutz-Delgado, Ken</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Restricted Boltzmann Machines and Deep Belief Networks have been successfully
used in a wide variety of applications including image classification and
speech recognition. Inference and learning in these algorithms uses a Markov
Chain Monte Carlo procedure called Gibbs sampling. A sigmoidal function forms
the kernel of this sampler which can be realized from the firing statistics of
noisy integrate-and-fire neurons on a neuromorphic VLSI substrate. This paper
demonstrates such an implementation on an array of digital spiking neurons with
stochastic leak and threshold properties for inference tasks and presents some
key performance metrics for such a hardware-based sampler in both the
generative and discriminative contexts.
</dc:description>
 <dc:description>Comment: Accepted at ISCAS 2015</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07795</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Labeled Classification of Demographic Attributes of Patients: a
  case study of diabetics patients</dc:title>
 <dc:creator>Cotha, Naveen Kumar Parachur</dc:creator>
 <dc:creator>Sokolova, Marina</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Automated learning of patients demographics can be seen as multi-label
problem where a patient model is based on different race and gender groups. The
resulting model can be further integrated into Privacy-Preserving Data Mining,
where it can be used to assess risk of identification of different patient
groups. Our project considers relations between diabetes and demographics of
patients as a multi-labelled problem. Most research in this area has been done
as binary classification, where the target class is finding if a person has
diabetes or not. But very few, and maybe no work has been done in multi-labeled
analysis of the demographics of patients who are likely to be diagnosed with
diabetes. To identify such groups, we applied ensembles of several multi-label
learning algorithms.
</dc:description>
 <dc:description>Comment: 16 pages, 9 tables</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07795</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07798</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ICONA: Inter Cluster ONOS Network Application</dc:title>
 <dc:creator>Gerola, M.</dc:creator>
 <dc:creator>Santuari, M.</dc:creator>
 <dc:creator>Salvadori, E.</dc:creator>
 <dc:creator>Salsano, S.</dc:creator>
 <dc:creator>Campanella, M.</dc:creator>
 <dc:creator>Ventre, P. L.</dc:creator>
 <dc:creator>Al-Shabibi, A.</dc:creator>
 <dc:creator>Snow, W.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Several Network Operating Systems (NOS) have been proposed in the last few
years for Software Defined Networks; however, a few of them are currently
offering the resiliency, scalability and high availability required for
production environments. Open Networking Operating System (ONOS) is an open
source NOS, designed to be reliable and to scale up to thousands of managed
devices. It supports multiple concurrent instances (a cluster of controllers)
with distributed data stores. A tight requirement of ONOS is that all instances
must be close enough to have negligible communication delays, which means they
are typically installed within a single datacenter or a LAN network. However in
certain wide area network scenarios, this constraint may limit the speed of
responsiveness of the controller toward network events like failures or
congested links, an important requirement from the point of view of a Service
Provider. This paper presents ICONA, a tool developed on top of ONOS and
designed in order to extend ONOS capability in network scenarios where there
are stringent requirements in term of control plane responsiveness. In
particular the paper describes the architecture behind ICONA and provides some
initial evaluation obtained on a preliminary version of the tool.
</dc:description>
 <dc:description>Comment: Paper submitted to a conference</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07809</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numerical solution of moving plate problem with uncertain parameters</dc:title>
 <dc:creator>Nayak, S.</dc:creator>
 <dc:creator>Chakraverty, S.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  This paper deals with uncertain parabolic fluid flow problem where the
uncertainty occurs due to the initial conditions and parameters involved in the
system. Uncertain values are considered as fuzzy and these are handled through
a recently developed method. Here the concepts of fuzzy numbers are combined
with Finite Difference Method (FDM) and then Fuzzy Finite Difference Method
(FFDM) has been proposed. The proposed FFDM has been used to solve the fluid
flow problem bounded by two parallel plates. Finally sensitivity of the fuzzy
parameters has also been analysed.
</dc:description>
 <dc:date>2015-03-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07816</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Content-Based Bird Retrieval using Shape context, Color moments and Bag
  of Features</dc:title>
 <dc:creator>Abdelkhalak, Bahri</dc:creator>
 <dc:creator>Zouaki, Hamid</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In this paper we propose a new descriptor for birds search. First, our work
was carried on the choice of a descriptor. This choice is usually driven by the
application requirements such as robustness to noise, stability with respect to
bias, the invariance to geometrical transformations or tolerance to occlusions.
In this context, we introduce a descriptor which combines the shape and color
descriptors to have an effectiveness description of birds. The proposed
descriptor is an adaptation of a descriptor based on the contours defined in
article Belongie et al. [5] combined with color moments [19]. Specifically,
points of interest are extracted from each image and information's in the
region in the vicinity of these points are represented by descriptors of shape
context concatenated with color moments. Thus, the approach bag of visual words
is applied to the latter. The experimental results show the effectiveness of
our descriptor for the bird search by content.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures, IJCSI</dc:description>
 <dc:date>2015-03-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07826</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fusing Censored Dependent Data for Distributed Detection</dc:title>
 <dc:creator>He, Hao</dc:creator>
 <dc:creator>Varshney, Pramod K.</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider a distributed detection problem for a censoring
sensor network where each sensor's communication rate is significantly reduced
by transmitting only &quot;informative&quot; observations to the Fusion Center (FC), and
censoring those deemed &quot;uninformative&quot;. While the independence of data from
censoring sensors is often assumed in previous research, we explore spatial
dependence among observations. Our focus is on designing the fusion rule under
the Neyman-Pearson (NP) framework that takes into account the spatial
dependence among observations. Two transmission scenarios are considered, one
where uncensored observations are transmitted directly to the FC and second
where they are first quantized and then transmitted to further improve
transmission efficiency. Copula-based Generalized Likelihood Ratio Test (GLRT)
for censored data is proposed with both continuous and discrete messages
received at the FC corresponding to different transmission strategies. We
address the computational issues of the copula-based GLRTs involving
multidimensional integrals by presenting more efficient fusion rules, based on
the key idea of injecting controlled noise at the FC before fusion. Although,
the signal-to-noise ratio (SNR) is reduced by introducing controlled noise at
the receiver, simulation results demonstrate that the resulting noise-aided
fusion approach based on adding artificial noise performs very closely to the
exact copula-based GLRTs. Copula-based GLRTs and their noise-aided counterparts
by exploiting the spatial dependence greatly improve detection performance
compared with the fusion rule under independence assumption.
</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07826</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07828</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Manoeuvring Target Tracking Methods</dc:title>
 <dc:creator>Pulford, Graham W.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>05C85, 60J10, 60J27, 60J28, 60K15, 62F03, 62L12, 62M02, 62M05,
  68W27, 65C50, 65D10, 60G35, 93C05, 93C30, 93C15, 93C55, 93C57, 93C85, 93C95,
  93E10, 93E11, 93E14, 94A13</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>G.2.3</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>I.4.3</dc:subject>
 <dc:subject>I.4.4</dc:subject>
 <dc:subject>I.4.8</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:description>  A comprehensive review of the literature on manoeuvring target tracking for
both uncluttered and cluttered measurements is presented. Various discrete-time
dynamical models including non-random input, random-input and switching or
hybrid system manoeuvre models are presented. The problem of manoeuvre
detection is covered. Classical and current filtering methods for manoeuvre
tracking are presented including multi-level process noise, input estimation,
variable dimension filtering, two-stage filter, the interacting multiple model
algorithm, and generalised pseudo-Bayesian algorithms. Various extensions of
these algorithms to the case of cluttered measurements are also described and
these include: joint manoeuvre and measurement association, probabilistic data
association and multi-hypothesis tracking. Smoothing schemes, including IMM
smoothing and batch expectation-maximisation using the Viterbi algorithm, are
also described. The use of amplitude information for target measurement
discrimination is discussed. It is noted that although many manoeuvre tacking
techniques exist, the literature contains surprisingly few performance
comparisons to guide the design engineer although a performance benchmark has
recently been introduced.
</dc:description>
 <dc:description>Comment: 38 pages, 6 figures. Original manuscript dated 23/12/1998. Submitted
  to IEEE Transactions on Aerospace &amp; Electronic Systems. Withdrawn following a
  review process lasting 3 years. By the end of this period, this survey paper
  was out of date</dc:description>
 <dc:date>2015-03-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07828</dc:identifier>
 <dc:identifier>doi:10.13140/2.1.4994.3846</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07845</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Averaged Hausdorff Approximations of Pareto Fronts based on
  Multiobjective Estimation of Distribution Algorithms</dc:title>
 <dc:creator>Marti, Luis</dc:creator>
 <dc:creator>Grimme, Christian</dc:creator>
 <dc:creator>Kerschke, Pascal</dc:creator>
 <dc:creator>Trautmann, Heike</dc:creator>
 <dc:creator>Rudolph, G&#xfc;nter</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>I.2.m</dc:subject>
 <dc:description>  In the a posteriori approach of multiobjective optimization the Pareto front
is approximated by a finite set of solutions in the objective space. The
quality of the approximation can be measured by different indicators that take
into account the approximation's closeness to the Pareto front and its
distribution along the Pareto front. In particular, the averaged Hausdorff
indicator prefers an almost uniform distribution. An observed drawback of
multiobjective estimation of distribution algorithms (MEDAs) is that - as
common for randomized metaheuristics - the final population usually is not
uniformly distributed along the Pareto front. Therefore, we propose a
postprocessing strategy which consists of applying the averaged Hausdorff
indicator to the complete archive of generated solutions after optimization in
order to select a uniformly distributed subset of nondominated solutions from
the archive. In this paper, we put forward a strategy for extracting the above
described subset. The effectiveness of the proposal is contrasted in a series
of experiments that involve different MEDAs and filtering techniques.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07881</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ringo: Interactive Graph Analytics on Big-Memory Machines</dc:title>
 <dc:creator>Perez, Yonathan</dc:creator>
 <dc:creator>Sosic, Rok</dc:creator>
 <dc:creator>Banerjee, Arijit</dc:creator>
 <dc:creator>Puttagunta, Rohan</dc:creator>
 <dc:creator>Raison, Martin</dc:creator>
 <dc:creator>Shah, Pararth</dc:creator>
 <dc:creator>Leskovec, Jure</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:description>  We present Ringo, a system for analysis of large graphs. Graphs provide a way
to represent and analyze systems of interacting objects (people, proteins,
webpages) with edges between the objects denoting interactions (friendships,
physical interactions, links). Mining graphs provides valuable insights about
individual objects as well as the relationships among them.
  In building Ringo, we take advantage of the fact that machines with large
memory and many cores are widely available and also relatively affordable. This
allows us to build an easy-to-use interactive high-performance graph analytics
system. Graphs also need to be built from input data, which often resides in
the form of relational tables. Thus, Ringo provides rich functionality for
manipulating raw input data tables into various kinds of graphs. Furthermore,
Ringo also provides over 200 graph analytics functions that can then be applied
to constructed graphs.
  We show that a single big-memory machine provides a very attractive platform
for performing analytics on all but the largest graphs as it offers excellent
performance and ease of use as compared to alternative approaches. With Ringo,
we also demonstrate how to integrate graph analytics with an iterative process
of trial-and-error data exploration and rapid experimentation, common in data
mining workloads.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07881</dc:identifier>
 <dc:identifier>doi:10.1145/2723372.2735369</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07884</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transductive Multi-class and Multi-label Zero-shot Learning</dc:title>
 <dc:creator>Fu, Yanwei</dc:creator>
 <dc:creator>Yang, Yongxin</dc:creator>
 <dc:creator>Hospedales, Timothy M.</dc:creator>
 <dc:creator>Xiang, Tao</dc:creator>
 <dc:creator>Gong, Shaogang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, zero-shot learning (ZSL) has received increasing interest. The key
idea underpinning existing ZSL approaches is to exploit knowledge transfer via
an intermediate-level semantic representation which is assumed to be shared
between the auxiliary and target datasets, and is used to bridge between these
domains for knowledge transfer. The semantic representation used in existing
approaches varies from visual attributes to semantic word vectors and semantic
relatedness. However, the overall pipeline is similar: a projection mapping
low-level features to the semantic representation is learned from the auxiliary
dataset by either classification or regression models and applied directly to
map each instance into the same semantic representation space where a zero-shot
classifier is used to recognise the unseen target class instances with a single
known 'prototype' of each target class. In this paper we discuss two related
lines of work improving the conventional approach: exploiting transductive
learning ZSL, and generalising ZSL to the multi-label case.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures, ECCV 2014 Workshop on Parts and Attributes</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07884</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07889</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Implementation of an Inertial Navigation System for
  Pedestrians Based on a Low-Cost MEMS IMU</dc:title>
 <dc:creator>Montorsi, Francesco</dc:creator>
 <dc:creator>Pancaldi, Fabrizio</dc:creator>
 <dc:creator>Vitetta, Giorgio M.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Inertial navigation systems for pedestrians are infrastructure-less and can
achieve sub-meter accuracy in the short/medium period. However, when low-cost
inertial measurement units (IMU) are employed for their implementation, they
suffer from a slowly growing drift between the true pedestrian position and the
corresponding estimated position. In this paper we illustrate a novel solution
to mitigate such a drift by: a) using only accelerometer and gyroscope
measurements (no magnetometers required); b) including the sensor error model
parameters in the state vector of an extended Kalman filter; c) adopting a
novel soft heuristic for foot stance detection and for zero-velocity updates.
Experimental results evidence that our inertial-only navigation system can
achieve similar or better performance with respect to pedestrian dead-reckoning
systems presented in related studies, although the adopted IMU is less accurate
than more expensive counterparts.
</dc:description>
 <dc:date>2015-03-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07901</identifier>
 <datestamp>2016-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Robust and Efficient Method for Solving Point Distance Problems by
  Homotopy</dc:title>
 <dc:creator>Imbach, R&#xe9;mi</dc:creator>
 <dc:creator>Mathis, Pascal</dc:creator>
 <dc:creator>Schreck, Pascal</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  The goal of Point Distance Solving Problems is to find 2D or 3D placements of
points knowing distances between some pairs of points. The common guideline is
to solve them by a numerical iterative method (\emph{e.g.} Newton-Raphson
method). A sole solution is obtained whereas many exist. However the number of
solutions can be exponential and methods should provide solutions close to a
sketch drawn by the user.Geometric reasoning can help to simplify the
underlying system of equations by changing a few equations and triangularizing
it.This triangularization is a geometric construction of solutions, called
construction plan. We aim at finding several solutions close to the sketch on a
one-dimensional path defined by a global parameter-homotopy using a
construction plan. Some numerical instabilities may be encountered due to
specific geometric configurations. We address this problem by changing
on-the-fly the construction plan.Numerical results show that this hybrid method
is efficient and robust.
</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:date>2016-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07901</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07903</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Codes from Jacobian surfaces</dc:title>
 <dc:creator>Haloui, Safia</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:description>  This paper is concerned with some Algebraic Geometry codes on Jacobians of
genus 2 curves. We derive a lower bound for the minimum distance of these codes
from an upper &quot;Weil type&quot; bound for the number of rational points on
irreducible (possibly singular or non-absolutely irreducible) curves lying on
an abelian surface over a finite field.
</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07905</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>D3-Tree: A Dynamic Distributed Deterministic Load - Balancer for
  decentralized tree structures</dc:title>
 <dc:creator>Sourla, Efrosini</dc:creator>
 <dc:creator>Sioutas, Spyros</dc:creator>
 <dc:creator>Tsichlas, Kostas</dc:creator>
 <dc:creator>Zaroliagis, Christos</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this work, we propose D3-Tree, a dynamic distributed deterministic
structure for data management in decentralized networks. We present in brief
the theoretical algorithmic analysis, in which our proposed structure is based
on, and we describe thoroughly the key aspects of the implementation.
Conducting experiments, we verify that the implemented structure outperforms
other well-known hierarchical tree-based structures, since it provides better
complexities regarding load-balancing operations. More specifically, the
structure achieves a logarithmic amortized bound, using an efficient
deterministic load-balancing mechanism, which is general enough to be applied
to other hierarchical tree-based structures. Moreover, we investigate the
structure's fault tolerance, which hasn't been sufficiently tackled in previous
work, both theoretically and through rigorous experimentation. We prove that
D3-Tree is highly fault tolerant, since, even for massive node failures, it
achieves a significant success rate in element queries. Afterwards we go one
step further, in order to achieve sub-logarithmic complexity and propose the
ART+ structure (Autonomous Range Tree), exploiting the excellent performance of
D3-Tree. ART+ is a fully dynamic and fault-tolerant structure, which achieves
sub-logarithmic performance for query and update operations and performs
load-balancing in sub-logarithmic amortized cost.
</dc:description>
 <dc:description>Comment: 32 pages, 21 figures</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07906</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized K-fan Multimodal Deep Model with Shared Representations</dc:title>
 <dc:creator>Chen, Gang</dc:creator>
 <dc:creator>Srihari, Sargur N.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>68T10</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Multimodal learning with deep Boltzmann machines (DBMs) is an generative
approach to fuse multimodal inputs, and can learn the shared representation via
Contrastive Divergence (CD) for classification and information retrieval tasks.
However, it is a 2-fan DBM model, and cannot effectively handle multiple
prediction tasks. Moreover, this model cannot recover the hidden
representations well by sampling from the conditional distribution when more
than one modalities are missing. In this paper, we propose a K-fan deep
structure model, which can handle the multi-input and muti-output learning
problems effectively. In particular, the deep structure has K-branch for
different inputs where each branch can be composed of a multi-layer deep model,
and a shared representation is learned in an discriminative manner to tackle
multimodal tasks. Given the deep structure, we propose two objective functions
to handle two multi-input and multi-output tasks: joint visual restoration and
labeling, and the multi-view multi-calss object recognition tasks. To estimate
the model parameters, we initialize the deep model parameters with CD to
maximize the joint distribution, and then we use backpropagation to update the
model according to specific objective function. The experimental results
demonstrate that the model can effectively leverages multi-source information
and predict multiple tasks well over competitive baselines.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07906</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07911</identifier>
 <datestamp>2015-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Event-triggered control under time-varying rates and channel blackouts</dc:title>
 <dc:creator>Tallapragada, Pavankumar</dc:creator>
 <dc:creator>Franceschetti, Massimo</dc:creator>
 <dc:creator>Cortes, Jorge</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper studies event-triggered stabilization of linear time-invariant
systems over time-varying rate-limited communication channels. We explicitly
account for the possibility of channel blackouts, i.e., intervals of time when
the communication channel is unavailable for feedback. Assuming prior knowledge
of the channel evolution, we study the data capacity, which is the maximum
total number of bits that could be communicated over a given time interval, and
provide an efficient real-time algorithm to lower bound it for a deterministic
time-slotted model of channel evolution. Building on these results, we design
an event-triggering strategy that guarantees Zeno-free, exponential
stabilization at a desired convergence rate even in the presence of
intermittent channel blackouts. The contributions are the notion of channel
blackouts, the effective event-triggered control despite their occurrence, and
the analysis and quantification of the data capacity for a class of
time-varying continuous-time channels. Various simulations illustrate the
results.
</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:date>2015-10-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07919</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BitWhisper: Covert Signaling Channel between Air-Gapped Computers using
  Thermal Manipulations</dc:title>
 <dc:creator>Guri, Mordechai</dc:creator>
 <dc:creator>Monitz, Matan</dc:creator>
 <dc:creator>Mirski, Yisroel</dc:creator>
 <dc:creator>Elovici, Yuval</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  It has been assumed that the physical separation (air-gap) of computers
provides a reliable level of security, such that should two adjacent computers
become compromised, the covert exchange of data between them would be
impossible. In this paper, we demonstrate BitWhisper, a method of bridging the
air-gap between adjacent compromised computers by using their heat emissions
and built-in thermal sensors to create a covert communication channel. Our
method is unique in two respects: it supports bidirectional communication, and
it requires no additional dedicated peripheral hardware. We provide
experimental results based on implementation of BitWhisper prototype, and
examine the channel properties and limitations. Our experiments included
different layouts, with computers positioned at varying distances from one
another, and several sensor types and CPU configurations (e.g., Virtual
Machines). We also discuss signal modulation and communication protocols,
showing how BitWhisper can be used for the exchange of data between two
computers in a close proximity (at distance of 0-40cm) at an effective rate of
1-8 bits per hour, a rate which makes it possible to infiltrate brief commands
and exfiltrate small amount of data (e.g., passwords) over the covert channel.
</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07921</identifier>
 <datestamp>2015-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Breaking the News: First Impressions Matter on Online News</dc:title>
 <dc:creator>Reis, Julio</dc:creator>
 <dc:creator>Benevenuto, Fabr&#x131;cio</dc:creator>
 <dc:creator>de Melo, Pedro O. S. Vaz</dc:creator>
 <dc:creator>Prates, Raquel</dc:creator>
 <dc:creator>Kwak, Haewoon</dc:creator>
 <dc:creator>An, Jisun</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  A growing number of people are changing the way they consume news, replacing
the traditional physical newspapers and magazines by their virtual online
versions or/and weblogs. The interactivity and immediacy present in online news
are changing the way news are being produced and exposed by media corporations.
News websites have to create effective strategies to catch people's attention
and attract their clicks. In this paper we investigate possible strategies used
by online news corporations in the design of their news headlines. We analyze
the content of 69,907 headlines produced by four major global media
corporations during a minimum of eight consecutive months in 2014. In order to
discover strategies that could be used to attract clicks, we extracted features
from the text of the news headlines related to the sentiment polarity of the
headline. We discovered that the sentiment of the headline is strongly related
to the popularity of the news and also with the dynamics of the posted comments
on that particular news.
</dc:description>
 <dc:description>Comment: The paper appears in ICWSM 2015</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:date>2015-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07931</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Are Markov Models Effective for Storage Reliability Modelling?</dc:title>
 <dc:creator>Karmakar, Prasenjit</dc:creator>
 <dc:creator>Gopinath, K.</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Continuous Time Markov Chains (CTMC) have been used extensively to model
reliability of storage systems. While the exponentially distributed sojourn
time of Markov models is widely known to be unrealistic (and it is necessary to
consider Weibull-type models for components such as disks), recent work has
also highlighted some additional infirmities with the CTMC model, such as the
ability to handle repair times. Due to the memoryless property of these models,
any failure or repair of one component resets the &quot;clock&quot; to zero with any
partial repair or aging in some other subsystem forgotten. It has therefore
been argued that simulation is the only accurate technique available for
modelling the reliability of a storage system with multiple components.
  We show how both the above problematic aspects can be handled when we
consider a careful set of approximations in a detailed model of the system. A
detailed model has many states, and the transitions between them and the
current state captures the &quot;memory&quot; of the various components. We model a
non-exponential distribution using a sum of exponential distributions, along
with the use of a CTMC solver in a probabilistic model checking tool that has
support for reducing large state spaces. Furthermore, it is possible to get
results close to what is obtained through simulation and at much lower cost.
</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07931</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07932</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SecureFind: Secure and Privacy-Preserving Object Finding via Mobile
  Crowdsourcing</dc:title>
 <dc:creator>Sun, Jingchao</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:creator>Jin, Xiaocong</dc:creator>
 <dc:creator>Zhang, Yanchao</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The plummeting cost of Bluetooth tags and the ubiquity of mobile devices are
revolutionizing the traditional lost-and-found service. This paper presents
SecureFind, a secure and privacy-preserving object-finding system via mobile
crowdsourcing. In SecureFind, a unique Bluetooth tag is attached to every
valuable object, and the owner of a lost object submits an object-finding
request to many mobile users via the SecureFind service provider. Each mobile
user involved searches his vicinity for the lost object on behalf of the object
owner who can infer the location of his lost object based on the responses from
mobile users. SecureFind is designed to ensure strong object security such that
only the object owner can discover the location of his lost object as well as
offering strong location privacy to mobile users involved. The high efficacy
and efficiency of SecureFind are confirmed by extensive simulations.
</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07932</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07933</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Limits of Dense Packing of Equal Spheres in a Cube</dc:title>
 <dc:creator>Tatarevic, Milos</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>52C17, 05B40</dc:subject>
 <dc:description>  We examine packing of $n$ congruent spheres in a cube when $n$ is close but
less than the number of spheres in a regular cubic close-packed (ccp)
arrangement of $\lceil p^{3}/2\rceil$ spheres. For this family of packings, the
previous best-known arrangements were usually derived from a ccp by omission of
a certain number of spheres without changing the initial structure. In this
paper, we show that better arrangements exist for all $n\leq\lceil
p^{3}/2\rceil-2$. We introduce an optimization method to reveal improvements of
these packings, and present many new improvements for $n\leq4629$.
</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07933</dc:identifier>
 <dc:identifier>The Electronic Journal of Combinatorics 22(1) (2015) #P1.35</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07939</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust State Feedback Control Design with Probabilistic System
  Parameters</dc:title>
 <dc:creator>Bhattacharya, Raktim</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, a new polynomial chaos based framework for analyzing linear
systems with probabilistic parameters is presented. Stability analysis and
synthesis of optimal quadratically stabilizing controllers for such systems are
presented as convex optimization problems, with exponential mean square
stability guarantees. A Monte-Carlo approach for analysis and synthesis is also
presented, which is used to benchmark the polynomial chaos based approach. The
computational advantage of the polynomial chaos approach is shown with an
example based on the design of an optimal EMS-stabilizing controller, for an
F-16 aircraft model.
</dc:description>
 <dc:description>Comment: Published in CDC 2014</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07940</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Competitive Distribution Estimation</dc:title>
 <dc:creator>Orlitsky, Alon</dc:creator>
 <dc:creator>Suresh, Ananda Theertha</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  Estimating an unknown distribution from its samples is a fundamental problem
in statistics. The common, min-max, formulation of this goal considers the
performance of the best estimator over all distributions in a class. It shows
that with $n$ samples, distributions over $k$ symbols can be learned to a KL
divergence that decreases to zero with the sample size $n$, but grows
unboundedly with the alphabet size $k$.
  Min-max performance can be viewed as regret relative to an oracle that knows
the underlying distribution. We consider two natural and modest limits on the
oracle's power. One where it knows the underlying distribution only up to
symbol permutations, and the other where it knows the exact distribution but is
restricted to use natural estimators that assign the same probability to
symbols that appeared equally many times in the sample.
  We show that in both cases the competitive regret reduces to
$\min(k/n,\tilde{\mathcal{O}}(1/\sqrt n))$, a quantity upper bounded uniformly
for every alphabet size. This shows that distributions can be estimated nearly
as well as when they are essentially known in advance, and nearly as well as
when they are completely known in advance but need to be estimated via a
natural estimator. We also provide an estimator that runs in linear time and
incurs competitive regret of $\tilde{\mathcal{O}}(\min(k/n,1/\sqrt n))$, and
show that for natural estimators this competitive regret is inevitable. We also
demonstrate the effectiveness of competitive estimators using simulations.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07943</identifier>
 <datestamp>2015-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Polynomial Chaos Framework for Designing Linear Parameter Varying
  Control Systems</dc:title>
 <dc:creator>Bhattacharya, Raktim</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Here we use polynomial chaos framework to design controllers for linear
parameter varying (LPV) dynamical systems. We assume the scheduling variable to
be random and use polynomial chaos approach to synthesize the controller for
the resulting linear stochastic dynamical system. The stability of the LPV
system is formulated as an exponential mean-square (EMS) stability problem. Two
algorithms are presented that guarantee EMS stability of the stochastic system
and correspond to parameter dependent and independent Lyapunov functions,
respectively. LPV controllers from the polynomial chaos based framework is
shown to outperform LPV controller from classical design for an example
nonlinear system.
</dc:description>
 <dc:description>Comment: Published in ACC 2015</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:date>2015-05-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07943</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07948</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Spectrum Sharing of LTE Co-existing with WLAN in Unlicensed
  Frequency Bands</dc:title>
 <dc:creator>Xing, Minyao</dc:creator>
 <dc:creator>Peng, Yuexing</dc:creator>
 <dc:creator>Xia, Teng</dc:creator>
 <dc:creator>Long, Hang</dc:creator>
 <dc:creator>Zheng, Kan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  With the increase of wireless communication demands, licensed spectrum for
long term evolution (LTE) is no longer enough. The research effort has focused
on implementing LTE to unlicensed frequency bands in recent years, which
unavoidably brings the problem of LTE co-existence with other existing systems
on the same band. This paper proposes an adaptive co-existence mechanism for
LTE and wireless local area networks (WLAN) to enable a significant system
performance of WLAN while LTE does not lose much as well. LTE realizes the
co-existence by allocating time resources dynamically according to the traffic
load of WLAN system.
</dc:description>
 <dc:description>Comment: 5 pages, 7 figures, conference</dc:description>
 <dc:date>2015-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07970</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Cross Validation and WAIC for Predictive Prior Design in
  Regular Asymptotic Theory</dc:title>
 <dc:creator>Watanabe, Sumio</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Prior design is one of the most important problems in both statistics and
machine learning. The cross validation (CV) and the widely applicable
information criterion (WAIC) are predictive measures of the Bayesian
estimation, however, it has been difficult to apply them to find the optimal
prior because their mathematical properties in prior evaluation have been
unknown and the region of the hyperparameters is too wide to be examined. In
this paper, we derive a new formula by which the theoretical relation among CV,
WAIC, and the generalization loss is clarified and the optimal hyperparameter
can be directly found.
  By the formula, three facts are clarified about predictive prior design.
Firstly, CV and WAIC have the same second order asymptotic expansion, hence
they are asymptotically equivalent to each other as the optimizer of the
hyperparameter. Secondly, the hyperparameter which minimizes CV or WAIC makes
the average generalization loss to be minimized asymptotically but does not the
random generalization loss. And lastly, by using the mathematical relation
between priors, the variances of the optimized hyperparameters by CV and WAIC
are made smaller with small computational costs. Also we show that the
optimized hyperparameter by DIC or the marginal likelihood does not minimize
the average or random generalization loss in general.
</dc:description>
 <dc:description>Comment: 33 pages, 3 tables</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07989</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discriminative Bayesian Dictionary Learning for Classification</dc:title>
 <dc:creator>Akhtar, Naveed</dc:creator>
 <dc:creator>Shafait, Faisal</dc:creator>
 <dc:creator>Mian, Ajmal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>68T10</dc:subject>
 <dc:description>  We propose a Bayesian approach to learn discriminative dictionaries for
sparse representation of data. The proposed approach infers probability
distributions over the atoms of a discriminative dictionary using a Beta
Process. It also computes sets of Bernoulli distributions that associate class
labels to the learned dictionary atoms. This association signifies the
selection probabilities of the dictionary atoms in the expansion of
class-specific data. Furthermore, the non-parametric character of the proposed
approach allows it to infer the correct size of the dictionary. We exploit the
aforementioned Bernoulli distributions in separately learning a linear
classifier. The classifier uses the same hierarchical Bayesian model as the
dictionary, which we present along the analytical inference solution for Gibbs
sampling. For classification, a test instance is first sparsely encoded over
the learned dictionary and the codes are fed to the classifier. We performed
experiments for face and action recognition; and object and scene-category
classification using five public datasets and compared the results with
state-of-the-art discriminative sparse representation approaches. Experiments
show that the proposed Bayesian approach consistently outperforms the existing
approaches.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07991</identifier>
 <datestamp>2016-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leader Election and Shape Formation with Self-Organizing Programmable
  Matter</dc:title>
 <dc:creator>Daymude, Joshua J.</dc:creator>
 <dc:creator>Derakhshandeh, Zahra</dc:creator>
 <dc:creator>Gmyr, Robert</dc:creator>
 <dc:creator>Strothmann, Thim</dc:creator>
 <dc:creator>Bazzi, Rida</dc:creator>
 <dc:creator>Richa, Andr&#xe9;a W.</dc:creator>
 <dc:creator>Scheideler, Christian</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  We consider programmable matter consisting of simple computational elements,
called particles, that can establish and release bonds and can actively move in
a self-organized way, and we investigate the feasibility of solving fundamental
problems relevant for programmable matter. As a suitable model for such
self-organizing particle systems, we will use a generalization of the geometric
amoebot model first proposed in SPAA 2014. Based on the geometric model, we
present efficient local-control algorithms for leader election and line
formation requiring only particles with constant size memory, and we also
discuss the limitations of solving these problems within the general amoebot
model.
</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:date>2016-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07994</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>iPrivacy: a Distributed Approach to Privacy on the Cloud</dc:title>
 <dc:creator>Damiani, Ernesto</dc:creator>
 <dc:creator>Pagano, Francesco</dc:creator>
 <dc:creator>Pagano, Davide</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The increasing adoption of Cloud storage poses a number of privacy issues.
Users wish to preserve full control over their sensitive data and cannot accept
that it to be accessible by the remote storage provider. Previous research was
made on techniques to protect data stored on untrusted servers; however we
argue that the cloud architecture presents a number of open issues. To handle
them, we present an approach where confidential data is stored in a highly
distributed database, partly located on the cloud and partly on the clients.
Data is shared in a secure manner using a simple grant-and-revoke permission of
shared data and we have developed a system test implementation, using an
in-memory RDBMS with row-level data encryption for fine-grained data access
control
</dc:description>
 <dc:description>Comment: 13 pages, International Journal on Advances in Security 2011 vol.4 no
  3 &amp; 4. arXiv admin note: substantial text overlap with arXiv:1012.0759,
  arXiv:1109.3555</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07994</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.07998</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-time multi-view deconvolution</dc:title>
 <dc:creator>Schmid, Benjamin</dc:creator>
 <dc:creator>Huisken, Jan</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In light-sheet microscopy, overall image content and resolution are improved
by acquiring and fusing multiple views of the sample from different directions.
State-of-the-art multi-view (MV) deconvolution employs the point spread
functions (PSF) of the different views to simultaneously fuse and deconvolve
the images in 3D, but processing takes a multiple of the acquisition time and
constitutes the bottleneck in the imaging pipeline. Here we show that MV
deconvolution in 3D can finally be achieved in real-time by reslicing the
acquired data and processing cross-sectional planes individually on the
massively parallel architecture of a graphics processing unit (GPU).
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, submitted to Bioinformatics</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.07998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08007</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vibration Control Design for Nonlinear Systems using Frequency Response
  Function</dc:title>
 <dc:creator>Thenozhi, Suresh</dc:creator>
 <dc:creator>Tang, Yu</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  A nonlinear frequency response based adaptive vibration controller is
proposed for a class of nonlinear mechanical systems. In order to obtain the
nonlinear Frequency Response Function (FRF), the convergence properties of the
system are studied by using the convergence (contraction) theory. If the system
under consideration is: 1) convergent, it directly enables to derive a
nonlinear FRF for a band of excitation inputs, 2) non-convergent, first a
controller is used to obtain the convergence and then the corresponding FRF for
a band of excitation inputs is derived. Now the gains of the proposed adaptive
controller are tuned such that a desired closed-loop frequency response, in the
presence of excitation inputs is achieved. Finally, a building structure with
nonlinear cubic stiffness and a satellite system are considered to illustrate
the theoretical results.
</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08012</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring robustness of community structure in complex networks</dc:title>
 <dc:creator>Li, Hui-Jia</dc:creator>
 <dc:creator>Wang, Hao</dc:creator>
 <dc:creator>Chen, Luonan</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The theory of community structure is a powerful tool for real networks, which
can simplify their topological and functional analysis considerably. However,
since community detection methods have random factors and real social networks
obtained from complex systems always contain error edges, evaluating the
robustness of community structure is an urgent and important task. In this
letter, we employ the critical threshold of resolution parameter in Hamiltonian
function, $\gamma_C$, to measure the robustness of a network. According to
spectral theory, a rigorous proof shows that the index we proposed is inversely
proportional to robustness of community structure. Furthermore, by utilizing
the co-evolution model, we provides a new efficient method for computing the
value of $\gamma_C$. The research can be applied to broad clustering problems
in network analysis and data mining due to its solid mathematical basis and
experimental effects.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures. arXiv admin note: text overlap with
  arXiv:1303.7434 by other authors</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08012</dc:identifier>
 <dc:identifier>EPL (Europhysics Letters),108(6),2015</dc:identifier>
 <dc:identifier>doi:10.1209/0295-5075/108/68009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08018</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of stability of community structure across multiple
  hierarchical levels</dc:title>
 <dc:creator>Li, Hui-Jia</dc:creator>
 <dc:creator>Zhang, Xiang-Sun</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The analysis of stability of community structure is an important problem for
scientists from many fields. Here, we propose a new framework to reveal hidden
properties of community structure by quantitatively analyzing the dynamics of
Potts model. Specifically we model the Potts procedure of community structure
detection by a Markov process, which has a clear mathematical explanation.
Critical topological information regarding to multivariate spin configuration
could also be inferred from the spectral significance of the Markov process. We
test our framework on some example networks and find it doesn't have resolute
limitation problem at all. Results have shown the model we proposed is able to
uncover hierarchical structure in different scales effectively and efficiently.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08018</dc:identifier>
 <dc:identifier>EPL (Europhysics Letters),103(5),2013</dc:identifier>
 <dc:identifier>doi:10.1209/0295-5075/103/58002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08019</identifier>
 <datestamp>2016-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimality of Fast Matching Algorithms for Random Networks with
  Applications to Structural Controllability</dc:title>
 <dc:creator>Faradonbeh, Mohamad Kazem Shirani</dc:creator>
 <dc:creator>Tewari, Ambuj</dc:creator>
 <dc:creator>Michailidis, George</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Statistics - Other Statistics</dc:subject>
 <dc:description>  Network control refers to a very large and diverse set of problems including
controllability of linear time-invariant dynamical systems, where the objective
is to select an appropriate input to steer the network to a desired state.
There are many notions of controllability, one of them being structural
controllability, which is intimately connected to finding maximum matchings on
the underlying network topology. In this work, we study fast, scalable
algorithms for finding maximum matchings for a large class of random networks.
First, we illustrate that degree distribution random networks are realistic
models for real networks in terms of structural controllability. Subsequently,
we analyze a popular, fast and practical heuristic due to Karp and Sipser as
well as a simplification of it. For both heuristics, we establish asymptotic
optimality and provide results concerning the asymptotic size of maximum
matchings for an extensive class of random networks.
</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:date>2016-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08024</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying overlapping communities in social networks using multi-scale
  local information expansion</dc:title>
 <dc:creator>Li, Hui-Jia</dc:creator>
 <dc:creator>Zhang, Junhua</dc:creator>
 <dc:creator>Liu, Zhi-Ping</dc:creator>
 <dc:creator>Chen, Luonan</dc:creator>
 <dc:creator>Zhang, Xiang-Sun</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Most existing approaches for community detection require complete information
of the graph in a specific scale, which is impractical for many social
networks. We propose a novel algorithm that does not embrace the universal
approach but instead of trying to focus on local social ties and modeling
multi-scales of social interactions occurring in those networks. Our method for
the first time optimizes the topological entropy of a network and uncovers
communities through a novel dynamic system converging to a local minimum by
simply updating the membership vector with very low computational complexity.
It naturally supports overlapping communities through associating each node
with a membership vector which describes node's involvement in each community.
This way, in addition to uncover overlapping communities, we can also describe
different multi-scale partitions by tuning the characteristic size of modules
from the optimal partition. Because of the high efficiency and accuracy of the
algorithm, it is feasible to be used for the accurate detection of community
structure in real networks.
</dc:description>
 <dc:description>Comment: 15 pages, 8 figures. arXiv admin note: text overlap with
  arXiv:1004.4268, arXiv:cond-mat/0308217 by other authors; text overlap with
  arXiv:1104.5247 by other authors without attribution</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08024</dc:identifier>
 <dc:identifier>European Physical Journal B, 85(6), 109, 2012</dc:identifier>
 <dc:identifier>doi:10.1140/epjb/e2012-30015-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08035</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Potts model based on a Markov process computation solves the community
  structure problem effectively</dc:title>
 <dc:creator>Li, Hui-Jia</dc:creator>
 <dc:creator>Wang, Yong</dc:creator>
 <dc:creator>Wu, Ling-Yun</dc:creator>
 <dc:creator>Zhang, Junhua</dc:creator>
 <dc:creator>Zhang, Xiang-Sun</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Potts model is a powerful tool to uncover community structure in complex
networks. Here, we propose a new framework to reveal the optimal number of
communities and stability of network structure by quantitatively analyzing the
dynamics of Potts model. Specifically we model the community structure
detection Potts procedure by a Markov process, which has a clear mathematical
explanation. Then we show that the local uniform behavior of spin values across
multiple timescales in the representation of the Markov variables could
naturally reveal the network's hierarchical community structure. In addition,
critical topological information regarding to multivariate spin configuration
could also be inferred from the spectral signatures of the Markov process.
Finally an algorithm is developed to determine fuzzy communities based on the
optimal number of communities and the stability across multiple timescales. The
effectiveness and efficiency of our algorithm are theoretically analyzed as
well as experimentally validated.
</dc:description>
 <dc:description>Comment: 23 pages, 8 figures. arXiv admin note: text overlap with
  arXiv:0911.2308 by other authors</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08035</dc:identifier>
 <dc:identifier>Physical Review E, 86(1), 012801, 2012</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.86.016109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08039</identifier>
 <datestamp>2015-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social significance of community structure: Statistical view</dc:title>
 <dc:creator>Li, Hui-Jia</dc:creator>
 <dc:creator>Daniels, J J.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Community structure analysis is a powerful tool for social networks, which
can simplify their topological and functional analysis considerably. However,
since community detection methods have random factors and real social networks
obtained from complex systems always contain error edges, evaluating the
significance of community structure partitioned is an urgent and important
question. In this paper, integrating the specific characteristics of real
society, we present a novel framework analyzing the significance of social
community specially. The dynamics of social interactions are modeled by
identifying social leaders and corresponding hierarchical structures. Instead
of a direct comparison with the average outcome of a random model, we compute
the similarity of a given node with the leader by the number of common
neighbors. To determine the membership vector, an efficient community detection
algorithm is proposed based on the position of nodes and their corresponding
leaders. Then, using log-likelihood score, the tightness of community can be
derived. Based on the distribution of community tightness, we establish a new
connection between $p$-value theory and network analysis and then get a novel
statistical form significance measure. Finally, the framework is applied to
both benchmark networks and real social networks. Experimental results show
that our work can be used in many fields, such as determining the optimal
number of communities, analyzing the social significance of a given community,
comparing the performance among various algorithms and so on.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the author due to a crucial sign
  error in equation (17) and high overlapping rate</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:date>2015-05-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08039</dc:identifier>
 <dc:identifier>Physical Review E, 91(1), 012801, 2015</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.91.012801</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08040</identifier>
 <datestamp>2017-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate message-passing decoder and capacity-achieving sparse
  superposition codes</dc:title>
 <dc:creator>Barbier, Jean</dc:creator>
 <dc:creator>Krzakala, Florent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the approximate message-passing decoder for sparse superposition
coding on the additive white Gaussian noise channel and extend our preliminary
work [1]. We use heuristic statistical-physics-based tools such as the cavity
and the replica methods for the statistical analysis of the scheme. While
superposition codes asymptotically reach the Shannon capacity, we show that our
iterative decoder is limited by a phase transition similar to the one that
happens in Low Density Parity check codes. We consider two solutions to this
problem, that both allow to reach the Shannon capacity: i) a power allocation
strategy and ii) the use of spatial coupling, a novelty for these codes that
appears to be promising. We present in particular simulations suggesting that
spatial coupling is more robust and allows for better reconstruction at finite
code lengths. Finally, we show empirically that the use of a fast
Hadamard-based operator allows for an efficient reconstruction, both in terms
of computational time and memory, and the ability to deal with very large
messages.
</dc:description>
 <dc:description>Comment: 40 pages, 18 figures</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:date>2016-09-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08040</dc:identifier>
 <dc:identifier>IEEE Transactions on Information Theory, Volume: 63, Issue: 8
  (Aug. 2017)</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2017.2713833</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08048</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preferential imitation of vaccinating behavior can invalidate the
  targeted subsidy on complex network</dc:title>
 <dc:creator>Zhang, Hai-Feng</dc:creator>
 <dc:creator>Shu, Pan-Pan</dc:creator>
 <dc:creator>Tang, Ming</dc:creator>
 <dc:creator>Small, Michael</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We consider the effect of inducement to vaccinate during the spread of an
infectious disease on complex networks. Suppose that public resources are
finite and that only a small proportion of individuals can be vaccinated freely
(complete subsidy), for the remainder of the population vaccination is a
voluntary behavior --- and each vaccinated individual carries a perceived cost.
We ask whether the classical targeted subsidy strategy is definitely better
than the random strategy: does targeting subsidy at individuals perceived to be
with the greatest risk actually help? With these questions, we propose a model
to investigate the \emph{interaction effects} of the subsidy policies and
individuals responses when facing subsidy policies on the epidemic dynamics on
complex networks. In the model, a small proportion of individuals are freely
vaccinated according to either the targeted or random subsidy policy, the
remainder choose to vaccinate (or not) based on voluntary principle and update
their vaccination decision via an imitation rule. Our findings show that the
targeted strategy is only advantageous when individuals prefer to imitate the
subsidized individuals' strategy. Otherwise, the effect of the targeted policy
is worse than the random immunization, since individuals preferentially select
non-subsidized individuals as the imitation objects. More importantly, we find
that under the targeted subsidy policy, increasing the proportion of subsidized
individuals may increase the final epidemic size. We further define social cost
as the sum of the costs of vaccination and infection, and study how each of the
two policies affect the social cost. Our result shows that there exist some
optimal intermediate regions leading to the minimal social cost.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08057</identifier>
 <datestamp>2017-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coloring graphs with no even hole $\geq 6$: the triangle-free case</dc:title>
 <dc:creator>Lagoutte, Aur&#xe9;lie</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  In this paper, we prove that the class of graphs with no triangle and no
induced cycle of even length at least 6 has bounded chromatic number. It is
well-known that even-hole-free graphs are $\chi$-bounded but we allow here the
existence of $C_4$. The proof relies on the concept of Parity Changing Path, an
adaptation of Trinity Changing Path which was recently introduced by Bonamy,
Charbit and Thomass\'e to prove that graphs with no induced cycle of length
divisible by three have bounded chromatic number.
</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08078</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parameterized Complexity of Asynchronous Border Minimization</dc:title>
 <dc:creator>Ganian, Robert</dc:creator>
 <dc:creator>Kronegger, Martin</dc:creator>
 <dc:creator>Pfandler, Andreas</dc:creator>
 <dc:creator>Popa, Alexandru</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Microarrays are research tools used in gene discovery as well as disease and
cancer diagnostics. Two prominent but challenging problems related to
microarrays are the Border Minimization Problem (BMP) and the Border
Minimization Problem with given placement (P-BMP).
  In this paper we investigate the parameterized complexity of natural variants
of BMP and P-BMP under several natural parameters. We show that BMP and P-BMP
are in FPT under the following two combinations of parameters: 1) the size of
the alphabet (c), the maximum length of a sequence (string) in the input (l)
and the number of rows of the microarray (r); and, 2) the size of the alphabet
and the size of the border length (o). Furthermore, P-BMP is in FPT when
parameterized by c and l. We complement our tractability results with
corresponding hardness results.
</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08081</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proficiency of Power Values for Load Disaggregation</dc:title>
 <dc:creator>P&#xf6;chacker, Manfred</dc:creator>
 <dc:creator>Egarter, Dominik</dc:creator>
 <dc:creator>Elmenreich, Wilfried</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Load disaggregation techniques infer the operation of different power
consuming devices from a single measurement point that records the total power
draw over time. Thus, a device consuming power at the moment can be understood
as information encoded in the power draw. However, similar power draws or
similar combinations of power draws limit the ability to detect the currently
active device set. We present an information coding perspective of load
disaggregation to enable a better understanding of this process and to support
its future improvement. In typical cases of quantity and type of devices and
their respective power consumption, not all possible device configurations can
be mapped to distinguishable power values. We introduce the term of proficiency
to describe the suitability of a device set for load disaggregation. We provide
the notion and calculation of entropy of initial device states, mutual
information of power values and the resulting uncertainty coefficient or
proficiency. We show that the proficiency is highly dependent from the device
running probability especially for devices with multiple states of power
consumption. The application of the concept is demonstrated by exemplary
artificial data as well as with actual power consumption data from real-world
power draw datasets.
</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08085</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolutionary Poisson Games for Controlling Large Population Behaviors</dc:title>
 <dc:creator>Hayel, Yezekael</dc:creator>
 <dc:creator>Zhu, Quanyan</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Emerging applications in engineering such as crowd-sourcing and
(mis)information propagation involve a large population of heterogeneous users
or agents in a complex network who strategically make dynamic decisions. In
this work, we establish an evolutionary Poisson game framework to capture the
random, dynamic and heterogeneous interactions of agents in a holistic fashion,
and design mechanisms to control their behaviors to achieve a system-wide
objective. We use the antivirus protection challenge in cyber security to
motivate the framework, where each user in the network can choose whether or
not to adopt the software. We introduce the notion of evolutionary Poisson
stable equilibrium for the game, and show its existence and uniqueness. Online
algorithms are developed using the techniques of stochastic approximation
coupled with the population dynamics, and they are shown to converge to the
optimal solution of the controller problem. Numerical examples are used to
illustrate and corroborate our results.
</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08090</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Sums-of-Squares Extension of Policy Iterations</dc:title>
 <dc:creator>Adj&#xe9;, Assal&#xe9;</dc:creator>
 <dc:creator>Garoche, Pierre-Lo&#xef;c</dc:creator>
 <dc:creator>Magron, Victor</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In order to address the imprecision often introduced by widening operators in
static analysis, policy iteration based on min-computations amounts to
considering the characterization of reachable value set of a program as an
iterative computation of policies, starting from a post-fixpoint. Computing
each policy and the associated invariant relies on a sequence of numerical
optimizations. While the early research efforts relied on linear programming
(LP) to address linear properties of linear programs, the current state of the
art is still limited to the analysis of linear programs with at most quadratic
invariants, relying on semidefinite programming (SDP) solvers to compute
policies, and LP solvers to refine invariants.
  We propose here to extend the class of programs considered through the use of
Sums-of-Squares (SOS) based optimization. Our approach enables the precise
analysis of switched systems with polynomial updates and guards. The analysis
presented has been implemented in Matlab and applied on existing programs
coming from the system control literature, improving both the range of
analyzable systems and the precision of previously handled ones.
</dc:description>
 <dc:description>Comment: 29 pages, 4 figures</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08090</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08104</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating Asymmetric Multicore Systems-on-Chip using Iso-Metrics</dc:title>
 <dc:creator>Chalios, Charalampos</dc:creator>
 <dc:creator>Nikolopoulos, Dimitrios S.</dc:creator>
 <dc:creator>Quintana-Orti, Enrique S.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>C.1.3</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:description>  The end of Dennard scaling has pushed power consumption into a first order
concern for current systems, on par with performance. As a result,
near-threshold voltage computing (NTVC) has been proposed as a potential means
to tackle the limited cooling capacity of CMOS technology. Hardware operating
in NTV consumes significantly less power, at the cost of lower frequency, and
thus reduced performance, as well as increased error rates. In this paper, we
investigate if a low-power systems-on-chip, consisting of ARM's asymmetric
big.LITTLE technology, can be an alternative to conventional high performance
multicore processors in terms of power/energy in an unreliable scenario. For
our study, we use the Conjugate Gradient solver, an algorithm representative of
the computations performed by a large range of scientific and engineering
codes.
</dc:description>
 <dc:description>Comment: Presented at HiPEAC EEHCO '15, 6 pages</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08109</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spread-Spectrum Based on Finite Field Fourier Transforms</dc:title>
 <dc:creator>de Oliveira, H. M.</dc:creator>
 <dc:creator>Miranda, J. P. C. L.</dc:creator>
 <dc:creator>de Souza, R. M. Campello</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Spread-spectrum systems are presented, which are based on Finite Field
Fourier Transforms. Orthogonal spreading sequences defined over a finite field
are derived. New digital multiplex schemes based on such spread-spectrum
systems are also introduced, which are multilevel Coding Division Multiplex.
These schemes termed Galois-field Division Multiplex (GDM) offer compact
bandwidth requirements because only leaders of cyclotomic cosets are needed to
be transmitted.
</dc:description>
 <dc:description>Comment: 6 pages, 7 figures. Int. Conf. on System Engineering, Comm. and.
  Info. Technol., Punta Arenas, Chile, 2001</dc:description>
 <dc:date>2015-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08115</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distributed Approach to Privacy on the Cloud</dc:title>
 <dc:creator>Pagano, Francesco</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The increasing adoption of Cloud-based data processing and storage poses a
number of privacy issues. Users wish to preserve full control over their
sensitive data and cannot accept it to be fully accessible to an external
storage provider. Previous research in this area was mostly addressed at
techniques to protect data stored on untrusted database servers; however, I
argue that the Cloud architecture presents a number of specific problems and
issues. This dissertation contains a detailed analysis of open issues. To
handle them, I present a novel approach where confidential data is stored in a
highly distributed partitioned database, partly located on the Cloud and partly
on the clients. In my approach, data can be either private or shared; the
latter is shared in a secure manner by means of simple grant-and-revoke
permissions. I have developed a proof-of-concept implementation using an
in-memory RDBMS with row-level data encryption in order to achieve fine-grained
data access control. This type of approach is rarely adopted in conventional
outsourced RDBMSs because it requires several complex steps. Benchmarks of my
proofof-concept implementation show that my approach overcomes most of the
problems.
</dc:description>
 <dc:description>Comment: PhD Thesis in Computer Science at University of Milan - Italy 2012
  March 6th</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08131</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formation of Robust Multi-Agent Networks Through Self-Organizing Random
  Regular Graphs</dc:title>
 <dc:creator>Yazicioglu, A. Yasin</dc:creator>
 <dc:creator>Egerstedt, Magnus</dc:creator>
 <dc:creator>Shamma, Jeff S.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Multi-agent networks are often modeled as interaction graphs, where the nodes
represent the agents and the edges denote some direct interactions. The
robustness of a multi-agent network to perturbations such as failures, noise,
or malicious attacks largely depends on the corresponding graph. In many
applications, networks are desired to have well-connected interaction graphs
with relatively small number of links. One family of such graphs is the random
regular graphs. In this paper, we present a decentralized scheme for
transforming any connected interaction graph with a possibly non-integer
average degree of k into a connected random m-regular graph for some m in [k, k
+ 2]. Accordingly, the agents improve the robustness of the network with a
minimal change in the overall sparsity by optimizing the graph connectivity
through the proposed local operations.
</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08131</dc:identifier>
 <dc:identifier>doi:10.1109/TNSE.2015.2503983</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08134</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context-Aware Wireless Small Cell Networks: How to Exploit User
  Information for Resource Allocation</dc:title>
 <dc:creator>Khanafer, Ali</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Ba&#x15f;ar, Tamer</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>91A10</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  In this paper, a novel context-aware approach for resource allocation in
two-tier wireless small cell networks~(SCNs) is proposed. In particular, the
SCN's users are divided into two types: frequent users, who are regular users
of certain small cells, and occasional users, who are one-time or infrequent
users of a particular small cell. Given such \emph{context} information, each
small cell base station (SCBS) aims to maximize the overall performance
provided to its frequent users, while ensuring that occasional users are also
well serviced. We formulate the problem as a noncooperative game in which the
SCBSs are the players. The strategy of each SCBS is to choose a proper power
allocation so as to optimize a utility function that captures the tradeoff
between the users' quality-of-service gains and the costs in terms of resource
expenditures. We provide a sufficient condition for the existence and
uniqueness of a pure strategy Nash equilibrium for the game, and we show that
this condition is independent of the number of users in the network. Simulation
results show that the proposed context-aware resource allocation game yields
significant performance gains, in terms of the average utility per SCBS,
compared to conventional techniques such as proportional fair allocation and
sum-rate maximization.
</dc:description>
 <dc:description>Comment: To be presented at the IEEE International Conference on
  Communications (ICC), London, U.K., 2015</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08134</dc:identifier>
 <dc:identifier>doi:10.1109/ICC.2015.7248840</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08139</identifier>
 <datestamp>2016-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounds on entanglement distillation and secret key agreement for quantum
  broadcast channels</dc:title>
 <dc:creator>Seshadreesan, Kaushik P.</dc:creator>
 <dc:creator>Takeoka, Masahiro</dc:creator>
 <dc:creator>Wilde, Mark M.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The squashed entanglement of a quantum channel is an additive function of
quantum channels, which finds application as an upper bound on the rate at
which secret key and entanglement can be generated when using a quantum channel
a large number of times in addition to unlimited classical communication. This
quantity has led to an upper bound of $\log((1+\eta)/(1-\eta))$ on the capacity
of a pure-loss bosonic channel for such a task, where $\eta$ is the average
fraction of photons that make it from the input to the output of the channel.
The purpose of the present paper is to extend these results beyond the
single-sender single-receiver setting to the more general case of a single
sender and multiple receivers (a quantum broadcast channel). We employ
multipartite generalizations of the squashed entanglement to constrain the
rates at which secret key and entanglement can be generated between any subset
of the users of such a channel, along the way developing several new properties
of these measures. We apply our results to the case of a pure-loss broadcast
channel with one sender and two receivers.
</dc:description>
 <dc:description>Comment: 35 pages, 1 figure, accepted for publication in IEEE Transactions on
  Information Theory</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:date>2016-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08139</dc:identifier>
 <dc:identifier>IEEE Transactions on Information Theory, vol. 62, no. 5, pages
  2849-2866, May 2016</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2016.2544803</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08141</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisable Justified Belief: Preliminary Report</dc:title>
 <dc:creator>Baltag, Alexandru</dc:creator>
 <dc:creator>Renne, Bryan</dc:creator>
 <dc:creator>Smets, Sonja</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The theory $\mathsf{CDL}$ of Conditional Doxastic Logic is the single-agent
version of Board's multi-agent theory $\mathsf{BRSIC}$ of conditional belief.
$\mathsf{CDL}$ may be viewed as a version of AGM belief revision theory in
which Boolean combinations of revisions are expressible in the language. We
introduce a theory $\mathsf{JCDL}$ of Justified Conditional Doxastic Logic that
replaces conditional belief formulas $B^\psi\varphi$ by expressions
$t{\,:^{\psi}}\varphi$ made up of a term $t$ whose syntactic structure suggests
a derivation of the belief $\varphi$ after revision by $\psi$. This allows us
to think of terms $t$ as reasons justifying a belief in various formulas after
a revision takes place. We show that $\mathsf{JCDL}$-theorems are the exact
analogs of $\mathsf{CDL}$-theorems, and that this result holds the other way
around as well. This allows us to think of $\mathsf{JCDL}$ as a theory of
revisable justified belief.
</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08154</identifier>
 <datestamp>2016-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Joint Entropy of $d$-Wise-Independent Variables</dc:title>
 <dc:creator>Gavinsky, Dmitry</dc:creator>
 <dc:creator>Pudl&#xe1;k, Pavel</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  How low can the joint entropy of $n$ $d$-wise independent (for $d\ge2$)
discrete random variables be, subject to given constraints on the individual
distributions (say, no value may be taken by a variable with probability
greater than $p$, for $p&lt;1$)? This question has been posed and partially
answered in a recent work of Babai.
  In this paper we improve some of his bounds, prove new bounds in a wider
range of parameters and show matching upper bounds in some special cases. In
particular, we prove tight lower bounds for the min-entropy (as well as the
entropy) of pairwise and three-wise independent balanced binary variables for
infinitely many values of $n$.
</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:date>2016-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08155</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Embedding Representations for Knowledge Inference on Imperfect
  and Incomplete Repositories</dc:title>
 <dc:creator>Fan, Miao</dc:creator>
 <dc:creator>Zhou, Qiang</dc:creator>
 <dc:creator>Zheng, Thomas Fang</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper considers the problem of knowledge inference on large-scale
imperfect repositories with incomplete coverage by means of embedding entities
and relations at the first attempt. We propose IIKE (Imperfect and Incomplete
Knowledge Embedding), a probabilistic model which measures the probability of
each belief, i.e. $\langle h,r,t\rangle$, in large-scale knowledge bases such
as NELL and Freebase, and our objective is to learn a better low-dimensional
vector representation for each entity ($h$ and $t$) and relation ($r$) in the
process of minimizing the loss of fitting the corresponding confidence given by
machine learning (NELL) or crowdsouring (Freebase), so that we can use $||{\bf
h} + {\bf r} - {\bf t}||$ to assess the plausibility of a belief when
conducting inference. We use subsets of those inexact knowledge bases to train
our model and test the performances of link prediction and triplet
classification on ground truth beliefs, respectively. The results of extensive
experiments show that IIKE achieves significant improvement compared with the
baseline and state-of-the-art approaches.
</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08155</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08158</identifier>
 <datestamp>2015-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Secure Intelligent Decision Support System for Prescribing Medication</dc:title>
 <dc:creator>Omotosho, Adebayo</dc:creator>
 <dc:creator>Justice, Emuoyibofarhe</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The process of electronic approach to writing and sending medical
prescription promises to improve patient safety, health outcomes, maintaining
patients privacy, promoting clinician acceptance and prescription security when
compared with the customary paper method. Traditionally, medical prescriptions
are typically handwritten or printed on paper and hand-delivered to
pharmacists. Paper-based medical prescriptions are generating major concerns as
the incidences of prescription errors have been increasing and causing minor to
serious problems to patients, including deaths. In this paper, intelligent
eprescription model that comprises a knowledge base of drug details and an
inference engine that can help in decision making when writing a prescription
was developed. The research implements the e-prescription model with
multifactor authentication techniques which comprises password and biometric
technology. Microsoft Visual Studio 2008, using C-Sharp programming language,
and Microsoft SQL Server 2005 database were employed in developing the systems
front end and back end respectively. This work implements a knowledge base to
the e-prescription system which has added intelligence for validating doctors
prescription and also added security feature to the e-prescription system.
</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08158</dc:identifier>
 <dc:identifier>CISDI 3:3 9-18</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08163</identifier>
 <datestamp>2015-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Development of an Electronic Medical Image Archiving System for Health
  Care in Nigeria</dc:title>
 <dc:creator>Olaniyi, Mikail</dc:creator>
 <dc:creator>Omotosho, Adebayo</dc:creator>
 <dc:creator>Robert, Jane</dc:creator>
 <dc:creator>Oke, Alice</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Medical images require immediate access by several physicians in different
places within a medical facility and access to a critically injured persons
medical image, such as the x-ray, on time can be a key factor in the diagnosis
and treatment of the patient. The electronic medical image archive system can
help to solve the problem faced in previous physical medium archiving, thus
increasing productivity and time which patients are attended to. In this paper,
simple but functional electronic medical image archive architecture was
proposed and implemented. The system was further evaluated in a hospital
setting by medical experts using sample patient image data. Results of the
system evaluation shows that electronic medical image archiving systems can
actually promote efficiency, quality improvement, provide timely availability
of radiologic images, image consultation, and image interpretation in emergent
and no emergent clinical care areas among other benefits
</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08163</dc:identifier>
 <dc:identifier>International Journal of Computer and Information
  Technology,Volume 02, Issue 04, 2013 p.706-711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08167</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Normalization of Non-Standard Words in Croatian Texts</dc:title>
 <dc:creator>Beliga, Slobodan</dc:creator>
 <dc:creator>Pobar, Miran</dc:creator>
 <dc:creator>Martin&#x10d;i&#x107;-Ip&#x161;i&#x107;, Sanda</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents text normalization which is an integral part of any
text-to-speech synthesis system. Text normalization is a set of methods with a
task to write non-standard words, like numbers, dates, times, abbreviations,
acronyms and the most common symbols, in their full expanded form are
presented. The whole taxonomy for classification of non-standard words in
Croatian language together with rule-based normalization methods combined with
a lookup dictionary are proposed. Achieved token rate for normalization of
Croatian texts is 95%, where 80% of expanded words are in correct morphological
form.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures in Text, Speech and Dialogue extension to Lecture
  Notes in Artificial Intelligence LNAI6836. Hebernal, Ivan; Matou\v{s}ek,
  V\'aclav (ed). - Plzen: University of West Bohemia, 2011. 1-8 (ISBN:
  987-80-261-0069-0)</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08169</identifier>
 <datestamp>2016-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RankMap: A Platform-Aware Framework for Distributed Learning from Dense
  Datasets</dc:title>
 <dc:creator>Mirhoseini, Azalia</dc:creator>
 <dc:creator>Dyer, Eva L.</dc:creator>
 <dc:creator>Songhori, Ebrahim. M.</dc:creator>
 <dc:creator>Baraniuk, Richard G.</dc:creator>
 <dc:creator>Koushanfar, Farinaz</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper introduces RankMap, a platform-aware end-to-end framework for
efficient execution of a broad class of iterative learning algorithms for
massive and dense datasets. Our framework exploits data structure to factorize
it into an ensemble of lower rank subspaces. The factorization creates sparse
low-dimensional representations of the data, a property which is leveraged to
devise effective mapping and scheduling of iterative learning algorithms on the
distributed computing machines. We provide two APIs, one matrix-based and one
graph-based, which facilitate automated adoption of the framework for
performing several contemporary learning applications. To demonstrate the
utility of RankMap, we solve sparse recovery and power iteration problems on
various real-world datasets with up to 1.8 billion non-zeros. Our evaluations
are performed on Amazon EC2 and IBM iDataPlex servers using up to 244 cores.
The results demonstrate up to two orders of magnitude improvements in memory
usage, execution speed, and bandwidth compared with the best reported prior
work, while achieving the same level of learning accuracy.
</dc:description>
 <dc:description>Comment: 13 pages, 10 figures</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:date>2016-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08175</identifier>
 <datestamp>2015-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Evaluation and Convergence of Self-Appraisals in Social
  Networks</dc:title>
 <dc:creator>Chen, Xudong</dc:creator>
 <dc:creator>Liu, Ji</dc:creator>
 <dc:creator>Belabbas, M. -A.</dc:creator>
 <dc:creator>Xu, Zhi</dc:creator>
 <dc:creator>Basar, Tamer</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We consider in this paper a networked system of opinion dynamics in
continuous time, where the agents are able to evaluate their self-appraisals in
a distributed way. In the model we formulate, the underlying network topology
is described by a rooted digraph. For each ordered pair of agents $(i,j)$, we
assign a function of self-appraisal to agent $i$, which measures the level of
importance of agent $i$ to agent $j$. Thus, by communicating only with her
neighbors, each agent is able to calculate the difference between her level of
importance to others and others' level of importance to her. The dynamical
system of self-appraisals is then designed to drive these differences to zero.
We show that for almost all initial conditions, the trajectory generated by
this dynamical system asymptotically converges to an equilibrium point which is
exponentially stable.
</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:date>2015-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08192</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Estimation of Graph Spectrum</dc:title>
 <dc:creator>Yang, Mu</dc:creator>
 <dc:creator>Tang, Choon Yik</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this paper, we develop a two-stage distributed algorithm that enables
nodes in a graph to cooperatively estimate the spectrum of a matrix $W$
associated with the graph, which includes the adjacency and Laplacian matrices
as special cases. In the first stage, the algorithm uses a discrete-time linear
iteration and the Cayley-Hamilton theorem to convert the problem into one of
solving a set of linear equations, where each equation is known to a node. In
the second stage, if the nodes happen to know that $W$ is cyclic, the algorithm
uses a Lyapunov approach to asymptotically solve the equations with an
exponential rate of convergence. If they do not know whether $W$ is cyclic, the
algorithm uses a random perturbation approach and a structural controllability
result to approximately solve the equations with an error that can be made
small. Finally, we provide simulation results that illustrate the algorithm.
</dc:description>
 <dc:description>Comment: 15 pages, 2 figures</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08192</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08196</identifier>
 <datestamp>2016-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance analysis of spatial smoothing schemes in the context of
  large arrays</dc:title>
 <dc:creator>Pham, Gia-Thuy</dc:creator>
 <dc:creator>Loubaton, Philippe</dc:creator>
 <dc:creator>Vallet, Pascal</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  This paper adresses the statistical behaviour of spatial smoothing subspace
DoA estimation schemes using a sensor array in the case where the number of
observations $N$ is significantly smaller than the number of sensors $M$, and
that the smoothing parameter $L$ is such that $M$ and $NL$ are of the same
order of magnitude. This context is modelled by an asymptotic regime in which
$NL$ and $M$ both converge towards $\infty$ at the same rate. As in recent
works devoted to the study of (unsmoothed) subspace methods in the case where
$M$ and $N$ are of the same order of magnitude, it is shown that it is still
possible to derive improved DoA estimators termed as Generalized-MUSIC with
spatial smoothing (G-MUSIC SS). The key ingredient of this work is a technical
result showing that the largest singular values and corresponding singular
vectors of low rank deterministic perturbation of certain Gaussian block-Hankel
large random matrices behave as if the entries of the latter random matrices
were independent identically distributed. This allows to conclude that when the
number of sources and their DoA do not scale with $M,N,L,$ a situation
modelling widely spaced DoA scenarios, then both traditional and Generalized
spatial smoothing subspace methods provide consistent DoA estimators whose
convergence speed is faster than $\frac{1}{M}$. The case of DoA that are spaced
of the order of a beamwidth, which models closely spaced sources, is also
considered. It is shown that the convergence speed of G-MUSIC SS estimates is
unchanged, but that it is no longer the case for MUSIC SS ones.
</dc:description>
 <dc:description>Comment: 28 pages, 5 figures</dc:description>
 <dc:date>2015-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08196</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2015.2480044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08223</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A System View of the Recognition and Interpretation of Observed Human
  Shape, Pose and Action</dc:title>
 <dc:creator>Arathorn, David W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  There is physiological evidence that our ability to interpret human pose and
action from 2D visual imagery (binocular or monocular) engages the circuitry of
the motor cortices as well as the visual areas of the brain. This implies that
the capability of the motor cortices to solve inverse kinematics is flexible
enough to apply to both motion planning as well as serving as a generative
model for the visual processing of human figures, despite the differing
functional requirements of the two tasks. This paper provides a computational
model of the cooperation between visual and motor areas: in other words, a
system view of an important class of brain computations. The model unifies the
solution of the separate inverse problems involved in the task, visual
transformation discovery, inverse kinematics, and adaptation to morphology
variations, using several instances of the Map-seeking Circuit algorithm. While
the paper is weighted toward the exposition of a neurobiological hypothesis,
from mathematical formalization of the problem to neuronal circuitry, the
algorithmic expression of the solution is also a functional machine vision
system for human figure recognition, and 3D pose and body morphology
reconstruction from monocular, perspective-less input imagery. With an inverse
kinematic generative model capable of imposing a variety of endogenous and
exogenous constraints the machine vision implementation acquires
characteristics currently unique among such systems.
</dc:description>
 <dc:description>Comment: 41 pages, 17 figures</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08227</identifier>
 <datestamp>2015-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Harmonized Cellular and Distributed Massive MIMO: Load Balancing and
  Scheduling</dc:title>
 <dc:creator>Ye, Qiaoyang</dc:creator>
 <dc:creator>Bursalioglu, Ozgun Y.</dc:creator>
 <dc:creator>Papadopoulos, Haralabos C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Multi-tier networks with large-array base stations (BSs) that are able to
operate in the &quot;massive MIMO&quot; regime are envisioned to play a key role in
meeting the exploding wireless traffic demands. Operated over small cells with
reciprocity-based training, massive MIMO promises large spectral efficiencies
per unit area with low overheads. Also, near-optimal user-BS association and
resource allocation are possible in cellular massive MIMO HetNets using simple
admission control mechanisms and rudimentary BS schedulers, since scheduled
user rates can be predicted a priori with massive MIMO.
  Reciprocity-based training naturally enables coordinated multi-point
transmission (CoMP), as each uplink pilot inherently trains antenna arrays at
all nearby BSs. In this paper we consider a distributed-MIMO form of CoMP,
which improves cell-edge performance without requiring channel state
information exchanges among cooperating BSs. We present methods for harmonized
operation of distributed and cellular massive MIMO in the downlink that
optimize resource allocation at a coarser time scale across the network. We
also present scheduling policies at the resource block level which target
approaching the optimal allocations. Simulations reveal that the proposed
methods can significantly outperform the network-optimized cellular-only
massive MIMO operation (i.e., operation without CoMP), especially at the cell
edge.
</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:date>2015-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08227</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08237</identifier>
 <datestamp>2016-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resource Allocation and Rate Gains in Practical Full-Duplex Systems</dc:title>
 <dc:creator>Mara&#x161;evi&#x107;, Jelena</dc:creator>
 <dc:creator>Zhou, Jin</dc:creator>
 <dc:creator>Krishnaswamy, Harish</dc:creator>
 <dc:creator>Zhong, Yuan</dc:creator>
 <dc:creator>Zussman, Gil</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Full-duplex communication has the potential to substantially increase the
throughput in wireless networks. However, the benefits of full-duplex are still
not well understood. In this paper, we characterize the full-duplex rate gains
in both single-channel and multi-channel use cases. For the single-channel
case, we quantify the rate gain as a function of the remaining
self-interference and SNR values. We also provide a sufficient condition under
which the sum of uplink and downlink rates on a full-duplex channel is concave
in the transmission power levels. Building on these results, we consider the
multi-channel case. For that case, we introduce a new realistic model of a
small form-factor (e.g., smartphone) full-duplex receiver and demonstrate its
accuracy via measurements. We study the problem of jointly allocating power
levels to different channels and selecting the frequency of maximum
self-interference suppression, where the objective is maximizing the sum of the
rates over uplink and downlink OFDM channels. We develop a polynomial time
algorithm which is nearly optimal in practice under very mild restrictions. To
reduce the running time, we develop an efficient nearly-optimal algorithm under
the high SINR approximation. Finally, we demonstrate via numerical evaluations
the capacity gains in the different use cases and obtain insights into the
impact of the remaining self-interference and wireless channel states on the
performance.
</dc:description>
 <dc:description>Comment: Partial and preliminary version appeared in ACM SIGMETRICS'15. A
  shorter version of v2 is to appear in IEEE/ACM Transactions on Networking</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:date>2016-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08237</dc:identifier>
 <dc:identifier>doi:10.1109/TNET.2016.2575016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08244</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distribution System Outage Detection using Consumer Load and Line Flow
  Measurements</dc:title>
 <dc:creator>Sevlian, Raffi</dc:creator>
 <dc:creator>Zhao, Yue</dc:creator>
 <dc:creator>Goldsmith, Andrea</dc:creator>
 <dc:creator>Rajagopal, Ram</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  An outage detection framework for power distribution networks is proposed.
Given the tree structure of the distribution system, a method is developed
combining the use of real-time power flow measurements on edges of the tree
with load forecasts at the nodes of the tree. A maximum a posteriori detector
{\color{black} (MAP)} is formulated for arbitrary number and location of
outages on trees which is shown to have an efficient detector. A framework
relying on the maximum missed detection probability is used for optimal sensor
placement and is solved for tree networks. Finally, a set of case studies is
considered using feeder data from the Pacific Northwest National Laboratories.
We show that a 10\% loss in mean detection reliability network wide reduces the
required sensor density by 60 \% for a typical feeder if efficient use of
measurements is performed.
</dc:description>
 <dc:description>Comment: Complete rework of results</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08248</identifier>
 <datestamp>2016-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Socializing the Semantic Gap: A Comparative Survey on Image Tag
  Assignment, Refinement and Retrieval</dc:title>
 <dc:creator>Li, Xirong</dc:creator>
 <dc:creator>Uricchio, Tiberio</dc:creator>
 <dc:creator>Ballan, Lamberto</dc:creator>
 <dc:creator>Bertini, Marco</dc:creator>
 <dc:creator>Snoek, Cees G. M.</dc:creator>
 <dc:creator>Del Bimbo, Alberto</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  Where previous reviews on content-based image retrieval emphasize on what can
be seen in an image to bridge the semantic gap, this survey considers what
people tag about an image. A comprehensive treatise of three closely linked
problems, i.e., image tag assignment, refinement, and tag-based image retrieval
is presented. While existing works vary in terms of their targeted tasks and
methodology, they rely on the key functionality of tag relevance, i.e.
estimating the relevance of a specific tag with respect to the visual content
of a given image and its social context. By analyzing what information a
specific method exploits to construct its tag relevance function and how such
information is exploited, this paper introduces a taxonomy to structure the
growing literature, understand the ingredients of the main works, clarify their
connections and difference, and recognize their merits and limitations. For a
head-to-head comparison between the state-of-the-art, a new experimental
protocol is presented, with training sets containing 10k, 100k and 1m images
and an evaluation on three test sets, contributed by various research groups.
Eleven representative works are implemented and evaluated. Putting all this
together, the survey aims to provide an overview of the past and foster
progress for the near future.
</dc:description>
 <dc:description>Comment: to appear in ACM Computing Surveys</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:date>2016-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08248</dc:identifier>
 <dc:identifier>ACM Computing Surveys, Volume 49 Issue 1, 14:1-14:39, June 2016</dc:identifier>
 <dc:identifier>doi:10.1145/2906152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08263</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CRF Learning with CNN Features for Image Segmentation</dc:title>
 <dc:creator>Liu, Fayao</dc:creator>
 <dc:creator>Lin, Guosheng</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Conditional Random Rields (CRF) have been widely applied in image
segmentations. While most studies rely on hand-crafted features, we here
propose to exploit a pre-trained large convolutional neural network (CNN) to
generate deep features for CRF learning. The deep CNN is trained on the
ImageNet dataset and transferred to image segmentations here for constructing
potentials of superpixels. Then the CRF parameters are learnt using a
structured support vector machine (SSVM). To fully exploit context information
in inference, we construct spatially related co-occurrence pairwise potentials
and incorporate them into the energy function. This prefers labelling of object
pairs that frequently co-occur in a certain spatial layout and at the same time
avoids implausible labellings during the inference. Extensive experiments on
binary and multi-class segmentation benchmarks demonstrate the promise of the
proposed method. We thus provide new baselines for the segmentation performance
on the Weizmann horse, Graz-02, MSRC-21, Stanford Background and PASCAL VOC
2011 datasets.
</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08264</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collective Dynamics of Hierarchical Networks</dc:title>
 <dc:creator>Hossain, Liaquat</dc:creator>
 <dc:creator>Wigand, Rolf T.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In an increasingly complex, mobile and interconnected world, we face growing
threats of disasters, whether by chance or deliberately. Disruption of
coordinated response and recovery efforts due to organizational, technical,
procedural, random or deliberate attack could result in the risk of massive
loss of life. This requires urgent action to explore the development of optimal
information-sharing environments for promoting collective disaster response and
preparedness using multijurisdictional hierarchical networks. Innovative
approaches to information flow modeling and analysis for dealing with
challenges of coordinating across multi layered agency structures as well as
development of early warnings through social systems using social media
analytics may be pivotal to timely responses to dealing with large scale
disasters where response strategies need to be viewed as a shared
responsibility. How do facilitate the development of collective disaster
response in a multijurisdictional setting? How do we develop and test the level
and effectiveness of shared multijurisdictional hierarchical networks for
improved preparedness and response? What is the role of multi layered training
and exercises in building the shared learning space for collective disaster
preparedness and response? The aim of this is therefore to determine factors
that may be responsible for affecting disaster response.
</dc:description>
 <dc:description>Comment: 43 pages, 17 figures, 10 tables, journal</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08265</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Network Topology for Crisis Informetrics</dc:title>
 <dc:creator>Hossain, Liaquat</dc:creator>
 <dc:creator>Wigand, Rolf T.</dc:creator>
 <dc:creator>Uddin, Shahadat</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Crisis informetrics is considered to be a relatively new and emerging area of
research, which deals with the application of analytical approaches of network
and information science combined with experimental learning approaches of
statistical mechanics to explore communication and information flow, robustness
as well as tolerance of complex crisis networks under threats. In this paper,
we discuss the scale free network property of an organizational communication
network and test both traditional (static) and dynamic topology of social
networks during organizational crises Both types of topologies exhibit similar
characteristics of prominent actors reinforcing the power law distribution
nature of scale free networks. There are no significant fluctuations among the
actor prominence in daily and aggregated networks. We found that email
communication network display a high degree of scale free behavior described by
power law.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures, journal</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08265</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08271</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Problem of Peak-to-Average Power Ratio in OFDM Systems</dc:title>
 <dc:creator>Paredes, Martha C. Paredes</dc:creator>
 <dc:creator>Garc&#xed;a, M. Julia Fern&#xe1;ndez-Getino</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Orthogonal Frequency Division Multiplexing (OFDM) is widely used in many
digital communication systems due to its advantages such us high bit rate,
strong immunity to multipath and high spectral efficiency but it suffers a high
Peak-to-Average Power Ratio (PAPR) at the transmitted signal. It is very
important to deal with PAPR reduction in OFDM systems to avoid signal
degradation. Currently, the PAPR problem is an active area of research and in
this paper we present several techniques and that mathematically analyzed.
Moreover their advantages and disadvantages have been enumerated in order to
provide the readers the actual situation of the PAPR problem.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08271</dc:identifier>
 <dc:identifier>Revista Digital Facultad de Ingenier\'ia de Sistemas, ReDiFIS,
  Departamento de Inform\'atica y Ciencias de la Computaci\'on - Escuela
  Polit\'ecnica Nacional, (Quito - Ecuador), Volumen 1, No. 2, 2012. ISSN:
  1390:7239</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08275</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy Management in Storage-Augmented, Grid-Connected Prosumer
  Buildings and Neighbourhoods Using a Modified Simulated Annealing
  Optimization</dc:title>
 <dc:creator>Velik, Rosemarie</dc:creator>
 <dc:creator>Nicolay, Pascal</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This article introduces a modified simulated annealing optimization approach
for automatically determining optimal energy management strategies in
grid-connected, storage-augmented, photovoltaics-supplied prosumer buildings
and neighbourhoods based on user-specific goals. For evaluating the modified
simulated annealing optimizer, a number of test scenarios in the field of
energy self-consumption maximization are defined and results are compared to a
gradient descent and a total state space search approach. The benchmarking
against these two reference methods demonstrates that the modified simulated
annealing approach is able to find significantly better solutions than the
gradient descent algorithm - being equal or very close to the global optimum -
with significantly less computational effort and processing time than the total
state space search approach.
</dc:description>
 <dc:description>Comment: Computers &amp; Operations Research, 2015</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08286</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Necessary And Sufficient Condition for Generalized Demixing</dc:title>
 <dc:creator>Kuo, Chun-Yen</dc:creator>
 <dc:creator>Lin, Gang-Xuan</dc:creator>
 <dc:creator>Lu, Chun-Shien</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Demixing is the problem of identifying multiple structured signals from a
superimposed observation. This work analyzes a general framework, based on
convex optimization, for solving demixing problems. We present a new solution
to determine whether or not a specific convex optimization problem built for
generalized demixing is successful. This solution will also bring about the
possibility to estimate the probability of success by the approximate kinematic
formula.
</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08286</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08289</identifier>
 <datestamp>2016-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recent advances on inconsistency indices for pairwise comparisons - a
  commentary</dc:title>
 <dc:creator>Brunelli, Matteo</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper recalls the definition of consistency for pairwise comparison
matrices and briefly presents the concept of inconsistency index in connection
to other aspects of the theory of pairwise comparisons. By commenting on a
recent contribution by Koczkodaj and Szwarc, it will be shown that the
discussion on inconsistency indices is far from being over, and the ground is
still fertile for debates.
</dc:description>
 <dc:description>Comment: 13 pages, 2 figures</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:date>2016-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08289</dc:identifier>
 <dc:identifier>Fundamenta Informaticae, 144(3-4), 321-332, 2016</dc:identifier>
 <dc:identifier>doi:10.3233/FI-2016-1338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08294</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multi-signal Variant for the GPU-based Parallelization of Growing
  Self-Organizing Networks</dc:title>
 <dc:creator>Parigi, Giacomo</dc:creator>
 <dc:creator>Stramieri, Angelo</dc:creator>
 <dc:creator>Pau, Danilo</dc:creator>
 <dc:creator>Piastra, Marco</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Among the many possible approaches for the parallelization of self-organizing
networks, and in particular of growing self-organizing networks, perhaps the
most common one is producing an optimized, parallel implementation of the
standard sequential algorithms reported in the literature. In this paper we
explore an alternative approach, based on a new algorithm variant specifically
designed to match the features of the large-scale, fine-grained parallelism of
GPUs, in which multiple input signals are processed at once. Comparative tests
have been performed, using both parallel and sequential implementations of the
new algorithm variant, in particular for a growing self-organizing network that
reconstructs surfaces from point clouds. The experimental results show that
this approach allows harnessing in a more effective way the intrinsic
parallelism that the self-organizing networks algorithms seem intuitively to
suggest, obtaining better performances even with networks of smaller size.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08294</dc:identifier>
 <dc:identifier>Informatics in Control, Automation and Robotics - 9th
  International Conference, ICINCO 2012 Rome, Italy, July 28-31, 2012 Revised
  Selected Papers. Part I, pp. 83-100</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-03500-0_6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08310</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strong-majority bootstrap percolation on regular graphs with low
  dissemination threshold</dc:title>
 <dc:creator>Mitsche, Dieter</dc:creator>
 <dc:creator>P&#xe9;rez-Gim&#xe9;nez, Xavier</dc:creator>
 <dc:creator>Pra&#x142;at, Pawe&#x142;</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Consider the following model of strong-majority bootstrap percolation on a
graph. Let r be some positive integer, and p in [0,1]. Initially, every vertex
is active with probability p, independently from all other vertices. Then, at
every step of the process, each vertex v of degree deg(v) becomes active if at
least (deg(v)+r)/2 of its neighbours are active. Given any arbitrarily small
p&gt;0 and any integer r, we construct a family of d=d(p,r)-regular graphs such
that with high probability all vertices become active in the end. In
particular, the case r=1 answers a question and disproves a conjecture of
Rapaport, Suchan, Todinca, and Verstraete (Algorithmica, 2011).
</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08312</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Population Model for the Academic Ecosystem</dc:title>
 <dc:creator>Wu, Yan</dc:creator>
 <dc:creator>Venkatramanan, Srinivasan</dc:creator>
 <dc:creator>Chiu, Dah Ming</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In recent times, the academic ecosystem has seen a tremendous growth in
number of authors and publications. While most temporal studies in this area
focus on evolution of co-author and citation network structure, this systemic
inflation has received very little attention. In this paper, we address this
issue by proposing a population model for academia, derived from publication
records in the Computer Science domain. We use a generalized branching process
as an overarching framework, which enables us to describe the evolution and
composition of the research community in a systematic manner. Further, the
observed patterns allow us to shed light on researchers' lifecycle encompassing
arrival, academic life expectancy, activity, productivity and offspring
distribution in the ecosystem. We believe such a study will help develop better
bibliometric indices which account for the inflation, and also provide insights
into sustainable and efficient resource management for academia.
</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08312</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08316</identifier>
 <datestamp>2015-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Variance Reduced Stochastic Newton Method</dc:title>
 <dc:creator>Lucchi, Aurelien</dc:creator>
 <dc:creator>McWilliams, Brian</dc:creator>
 <dc:creator>Hofmann, Thomas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Quasi-Newton methods are widely used in practise for convex loss minimization
problems. These methods exhibit good empirical performance on a wide variety of
tasks and enjoy super-linear convergence to the optimal solution. For
large-scale learning problems, stochastic Quasi-Newton methods have been
recently proposed. However, these typically only achieve sub-linear convergence
rates and have not been shown to consistently perform well in practice since
noisy Hessian approximations can exacerbate the effect of high-variance
stochastic gradient estimates. In this work we propose Vite, a novel stochastic
Quasi-Newton algorithm that uses an existing first-order technique to reduce
this variance. Without exploiting the specific form of the approximate Hessian,
we show that Vite reaches the optimum at a geometric rate with a constant
step-size when dealing with smooth strongly convex functions. Empirically, we
demonstrate improvements over existing stochastic Quasi-Newton and variance
reduced stochastic gradient methods.
</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:date>2015-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08322</identifier>
 <datestamp>2015-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Some Further Evidence about Magnification and Shape in Neural Gas</dc:title>
 <dc:creator>Parigi, Giacomo</dc:creator>
 <dc:creator>Pedrini, Andrea</dc:creator>
 <dc:creator>Piastra, Marco</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Neural gas (NG) is a robust vector quantization algorithm with a well-known
mathematical model. According to this, the neural gas samples the underlying
data distribution following a power law with a magnification exponent that
depends on data dimensionality only. The effects of shape in the input data
distribution, however, are not entirely covered by the NG model above, due to
the technical difficulties involved. The experimental work described here shows
that shape is indeed relevant in determining the overall NG behavior; in
particular, some experiments reveal richer and complex behaviors induced by
shape that cannot be explained by the power law alone. Although a more
comprehensive analytical model remains to be defined, the evidence collected in
these experiments suggests that the NG algorithm has an interesting potential
for detecting complex shapes in noisy datasets.
</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08322</dc:identifier>
 <dc:identifier>doi:10.1109/IJCNN.2015.7280550</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08323</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Counting independent sets via Divide Measure and Conquer method</dc:title>
 <dc:creator>Junosza-Szaniawski, Konstanty</dc:creator>
 <dc:creator>Tuczynski, Michal</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C15</dc:subject>
 <dc:subject>G.1.2</dc:subject>
 <dc:description>  In this paper we give an algorithm for counting the number of all independent
sets in a given graph which works in time $O^*(1.1394^n)$ for subcubic graphs
and in time $O^*(1.2369^n)$ for general graphs, where $n$ is the number of
vertices in the instance graph, and polynomial space. The result comes from
combining two well known methods &quot;Divide and Conquer&quot; and &quot;Measure and
Conquer&quot;. We introduce this new concept of Divide, Measure and Conquer method
and expect it will find applications in other problems.
  The algorithm of Bj\&quot;orklund, Husfeldt and Koivisto for graph colouring with
our algorithm used as a subroutine has complexity $O^*(2.2369^n)$ and is
currently the fastest graph colouring algorithm in polynomial space.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08323</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08329</identifier>
 <datestamp>2015-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Risk Bounds for the Majority Vote: From a PAC-Bayesian Analysis to a
  Learning Algorithm</dc:title>
 <dc:creator>Germain, Pascal</dc:creator>
 <dc:creator>Lacasse, Alexandre</dc:creator>
 <dc:creator>Laviolette, Fran&#xe7;ois</dc:creator>
 <dc:creator>Marchand, Mario</dc:creator>
 <dc:creator>Roy, Jean-Francis</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose an extensive analysis of the behavior of majority votes in binary
classification. In particular, we introduce a risk bound for majority votes,
called the C-bound, that takes into account the average quality of the voters
and their average disagreement. We also propose an extensive PAC-Bayesian
analysis that shows how the C-bound can be estimated from various observations
contained in the training data. The analysis intends to be self-contained and
can be used as introductory material to PAC-Bayesian statistical learning
theory. It starts from a general PAC-Bayesian perspective and ends with
uncommon PAC-Bayesian bounds. Some of these bounds contain no Kullback-Leibler
divergence and others allow kernel functions to be used as voters (via the
sample compression setting). Finally, out of the analysis, we propose the MinCq
learning algorithm that basically minimizes the C-bound. MinCq reduces to a
simple quadratic program. Aside from being theoretically grounded, MinCq
achieves state-of-the-art performance, as shown in our extensive empirical
comparison with both AdaBoost and the Support Vector Machine.
</dc:description>
 <dc:description>Comment: Published in JMLR http://jmlr.org/papers/v16/germain15a.html</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:date>2015-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08329</dc:identifier>
 <dc:identifier>Journal of Machine Learning Research 2015, vol. 16, p. 787-860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08345</identifier>
 <datestamp>2015-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implementing an intelligent version of the classical sliding-puzzle game
  for unix terminals using Golang's concurrency primitives</dc:title>
 <dc:creator>Singh, Pravendra</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  An intelligent version of the sliding-puzzle game is developed using the new
Go programming language, which uses a concurrent version of the A* Informed
Search Algorithm to power solver-bot that runs in the background. The game runs
in computer system's terminals. Mainly, it was developed for UNIX-type systems
but it works pretty well in nearly all the operating systems because of
cross-platform compatibility of the programming language used. The game uses
language's concurrency primitives to simplify most of the hefty parts of the
game. A real-time notification delivery architecture is developed using
language's built-in concurrency support, which performs similar to event based
context aware invocations like we see on the web platform.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:date>2015-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08348</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Linear Regression With Missing Data</dc:title>
 <dc:creator>Ganti, Ravi</dc:creator>
 <dc:creator>Willett, Rebecca M.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  This paper proposes a fast and accurate method for sparse regression in the
presence of missing data. The underlying statistical model encapsulates the
low-dimensional structure of the incomplete data matrix and the sparsity of the
regression coefficients, and the proposed algorithm jointly learns the
low-dimensional structure of the data and a linear regressor with sparse
coefficients. The proposed stochastic optimization method, Sparse Linear
Regression with Missing Data (SLRM), performs an alternating minimization
procedure and scales well with the problem size. Large deviation inequalities
shed light on the impact of the various problem-dependent parameters on the
expected squared loss of the learned regressor. Extensive simulations on both
synthetic and real datasets show that SLRM performs better than competing
algorithms in a variety of contexts.
</dc:description>
 <dc:description>Comment: 14 pages, 7 figures</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08348</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08360</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Do current lattice Boltzmann methods for diffusion and diffusion-type
  equations respect maximum principles and the non-negative constraint?</dc:title>
 <dc:creator>Karimi, S.</dc:creator>
 <dc:creator>Nakshatrala, K. B.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:description>  The lattice Boltzmann method (LBM) has established itself as a valid
numerical method in computational fluid dynamics. Recently,
multiple-relaxation-time LBM has been proposed to simulate anisotropic
advection-diffusion processes. The governing differential equations of
advective-diffusive systems are known to satisfy maximum principles, comparison
principles, the non-negative constraint, and the decay property. In this paper,
it will be shown that current single- and multiple-relaxation-time lattice
Boltzmann methods fail to preserve these mathematical properties for transient
diffusion-type equations. It will also be shown that the discretization of
Dirichlet boundary conditions will affect the performance of lattice Boltzmann
methods in meeting these mathematical principles. A new way of discretizing the
Dirichlet boundary conditions is also proposed. Several benchmark problems have
been solved to illustrate the performance of lattice Boltzmann methods and the
effect of discretization of boundary conditions with respect to the
aforementioned mathematical properties for transient diffusion and
advection-diffusion equations.
</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08360</dc:identifier>
 <dc:identifier>doi:10.4208/cicp.181015.270416a</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08363</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Model Aggregation via Stochastic Mirror Descent</dc:title>
 <dc:creator>Ganti, Ravi</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the problem of learning convex aggregation of models, that is as
good as the best convex aggregation, for the binary classification problem.
Working in the stream based active learning setting, where the active learner
has to make a decision on-the-fly, if it wants to query for the label of the
point currently seen in the stream, we propose a stochastic-mirror descent
algorithm, called SMD-AMA, with entropy regularization. We establish an excess
risk bounds for the loss of the convex aggregate returned by SMD-AMA to be of
the order of $O\left(\sqrt{\frac{\log(M)}{{T^{1-\mu}}}}\right)$, where $\mu\in
[0,1)$ is an algorithm dependent parameter, that trades-off the number of
labels queried, and excess risk.
</dc:description>
 <dc:description>Comment: 12 pages, 20 figures, 3 tables</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08370</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global Bandits</dc:title>
 <dc:creator>Atan, Onur</dc:creator>
 <dc:creator>Tekin, Cem</dc:creator>
 <dc:creator>van der Schaar, Mihaela</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Multi-armed bandits (MAB) model sequential decision making problems, in which
a learner sequentially chooses arms with unknown reward distributions in order
to maximize its cumulative reward. Most of the prior work on MAB assumes that
the reward distributions of each arm are independent. But in a wide variety of
decision problems -- from drug dosage to dynamic pricing -- the expected
rewards of different arms are correlated, so that selecting one arm provides
information about the expected rewards of other arms as well. We propose and
analyze a class of models of such decision problems, which we call global
bandits. In the case in which rewards of all arms are deterministic functions
of a single unknown parameter, we construct a greedy policy that achieves
bounded regret, with a bound that depends on the single true parameter of the
problem. Hence, this policy selects suboptimal arms only finitely many times
with probability one. For this case we also obtain a bound on regret that is
independent of the true parameter; this bound is sub-linear, with an exponent
that depends on the informativeness of the arms (which measures the strength of
correlation between expected arm rewards). We also prove matching lower bounds
for the worst-case regret of the greedy policy.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1410.7890</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:date>2017-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08376</identifier>
 <datestamp>2015-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Assessing Excel VBA Suitability for Monte Carlo Simulation</dc:title>
 <dc:creator>Botchkarev, Alexei</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  Monte Carlo (MC) simulation includes a wide range of stochastic techniques
used to quantitatively evaluate the behavior of complex systems or processes.
Microsoft Excel spreadsheets with Visual Basic for Applications (VBA) software
is, arguably, the most commonly employed general purpose tool for MC
simulation. Despite the popularity of the Excel in many industries and
educational institutions, it has been repeatedly criticized for its flaws and
often described as questionable, if not completely unsuitable, for statistical
problems. The purpose of this study is to assess suitability of the Excel
(specifically its 2010 and 2013 versions) with VBA programming as a tool for MC
simulation. The results of the study indicate that Microsoft Excel (versions
2010 and 2013) is a strong Monte Carlo simulation application offering a solid
framework of core simulation components including spreadsheets for data input
and output, VBA development environment and summary statistics functions. This
framework should be complemented with an external high-quality pseudo-random
number generator added as a VBA module. A large and diverse category of Excel
incidental simulation components that includes statistical distributions,
linear and non-linear regression and other statistical, engineering and
business functions require execution of due diligence to determine their
suitability for a specific MC project.
</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08376</dc:identifier>
 <dc:identifier>Spreadsheets in Education (eJSiE): 2015, Vol. 8: Iss. 2, Article 3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08379</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consider Uncertain Parameters based on Sensitivity Matrix</dc:title>
 <dc:creator>Lou, Taishan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Uncertain parameters of state-space models have always been a considerable
problem. Consider Kalman filter (CKF) and desensitized Kalman filter (DKF) are
two methods to solve this problem. Based on the sensitivity matrix respected to
the uncertain parameter vector, a special DKF with an analytical gain is given
and a new form of the CKF is derived. The mathematical equivalence between the
special DKF and the CKF is demonstrated when the sensitivity-weighting matrix
is set to the covariance of the uncertain parameter and the problem how to
select and obtain the sensitivity-weighting matrix in the DKF is solved.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08381</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Shockingly Easy Structured Classification: A Search-based
  Probabilistic Online Learning Framework</dc:title>
 <dc:creator>Sun, Xu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  There are two major approaches for structured classification. One is the
probabilistic gradient-based methods such as conditional random fields (CRF),
which has high accuracy but with drawbacks: slow training, and no support of
search-based optimization (which is important in many cases). The other one is
the search-based learning methods such as perceptrons and margin infused
relaxed algorithm (MIRA), which have fast training but also with drawbacks: low
accuracy, no probabilistic information, and non-convergence in real-world
tasks. We propose a novel and &quot;shockingly easy&quot; solution, a search-based
probabilistic online learning method, to address most of those issues. This
method searches the output candidates, derives probabilities, and conduct
efficient online learning. We show that this method is with fast training,
support search-based optimization, very easy to implement, with top accuracy,
with probabilities, and with theoretical guarantees of convergence. Experiments
on well-known tasks show that our method has better accuracy than CRF and
almost as fast training speed as perceptron and MIRA. Results also show that
SAPO can easily beat the state-of-the-art systems on those highly-competitive
tasks, achieving record-breaking accuracies.
</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08383</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stability of Interconnected DC Converters</dc:title>
 <dc:creator>Cezar, Gustavo</dc:creator>
 <dc:creator>Rajagopal, Ram</dc:creator>
 <dc:creator>Zhang, Baosen</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper addresses stability issues of DC networks with constant power
loads (CPL). Common DC networks, such as automotive electrical systems and DC
microgrids, typically have a step-up/down converter connected in one side to
the main bus and, on the other, to the load. When load is constant power it can
generate destabilizing effects if not proper controlled. This paper shows that
converters driving CPLs can make the system unstable, even if they are
individually stable, depending on network parameters. We mitigate this problem
by means of passive components externally connected to the converter/CPL
subsystem. The analysis is verified through simulations. We are able to show
that certain converter circuit configurations achieve the so called
plug-and-play property, which stabilizes the interconnected system for all
network parameters. This property is desirable since it is does not require the
knowledge of detailed system topology and parameters, which can be time varying
and difficult to obtain. This method also contrasts to existing practices of
load augmentation, which can lead to severe efficiency losses.
</dc:description>
 <dc:description>Comment: Submitted to CDC 2015</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08393</identifier>
 <datestamp>2015-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SLOPE is Adaptive to Unknown Sparsity and Asymptotically Minimax</dc:title>
 <dc:creator>Su, Weijie</dc:creator>
 <dc:creator>Candes, Emmanuel</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider high-dimensional sparse regression problems in which we observe
$y = X \beta + z$, where $X$ is an $n \times p$ design matrix and $z$ is an
$n$-dimensional vector of independent Gaussian errors, each with variance
$\sigma^2$. Our focus is on the recently introduced SLOPE estimator ((Bogdan et
al., 2014)), which regularizes the least-squares estimates with the
rank-dependent penalty $\sum_{1 \le i \le p} \lambda_i |\hat \beta|_{(i)}$,
where $|\hat \beta|_{(i)}$ is the $i$th largest magnitude of the fitted
coefficients. Under Gaussian designs, where the entries of $X$ are
i.i.d.~$\mathcal{N}(0, 1/n)$, we show that SLOPE, with weights $\lambda_i$ just
about equal to $\sigma \cdot \Phi^{-1}(1-iq/(2p))$ ($\Phi^{-1}(\alpha)$ is the
$\alpha$th quantile of a standard normal and $q$ is a fixed number in $(0,1)$)
achieves a squared error of estimation obeying \[ \sup_{\| \beta\|_0 \le k}
\,\, \mathbb{P} \left(\| \hat{\beta}_{\text{SLOPE}} - \beta \|^2 &gt; (1+\epsilon)
\, 2\sigma^2 k \log(p/k) \right) \longrightarrow 0 \] as the dimension $p$
increases to $\infty$, and where $\epsilon &gt; 0$ is an arbitrary small constant.
This holds under a weak assumption on the $\ell_0$-sparsity level, namely, $k/p
\rightarrow 0$ and $(k\log p)/n \rightarrow 0$, and is sharp in the sense that
this is the best possible error any estimator can achieve. A remarkable feature
is that SLOPE does not require any knowledge of the degree of sparsity, and yet
automatically adapts to yield optimal total squared errors over a wide range of
$\ell_0$-sparsity classes. We are not aware of any other estimator with this
property.
</dc:description>
 <dc:description>Comment: To appear in the Annals of Statistics</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:date>2015-09-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08395</identifier>
 <datestamp>2016-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards More Efficient SPSD Matrix Approximation and CUR Matrix
  Decomposition</dc:title>
 <dc:creator>Wang, Shusen</dc:creator>
 <dc:creator>Zhang, Zhihua</dc:creator>
 <dc:creator>Zhang, Tong</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Symmetric positive semi-definite (SPSD) matrix approximation methods have
been extensively used to speed up large-scale eigenvalue computation and kernel
learning methods. The standard sketch based method, which we call the prototype
model, produces relatively accurate approximations, but is inefficient on large
square matrices. The Nystr\&quot;om method is highly efficient, but can only achieve
low accuracy. In this paper we propose a novel model that we call the {\it fast
SPSD matrix approximation model}. The fast model is nearly as efficient as the
Nystr\&quot;om method and as accurate as the prototype model. We show that the fast
model can potentially solve eigenvalue problems and kernel learning problems in
linear time with respect to the matrix size $n$ to achieve $1+\epsilon$
relative-error, whereas both the prototype model and the Nystr\&quot;om method cost
at least quadratic time to attain comparable error bound. Empirical comparisons
among the prototype model, the Nystr\&quot;om method, and our fast model demonstrate
the superiority of the fast model. We also contribute new understandings of the
Nystr\&quot;om method. The Nystr\&quot;om method is a special instance of our fast model
and is approximation to the prototype model. Our technique can be
straightforwardly applied to make the CUR matrix decomposition more efficiently
computed without much affecting the accuracy.
</dc:description>
 <dc:description>Comment: Journal of Machine Learning Research 2016</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:date>2016-12-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08395</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08396</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flow Demands Oriented Node Placement in Multi-Hop Wireless Networks</dc:title>
 <dc:creator>Yuan, Zimu</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In multi-hop wireless networks, flow demands mean that some nodes have
routing demands of transmitting their data to other nodes with a certain level
of transmission rate. When a set of nodes have been deployed with flow demands,
it is worth to know how to construct paths to satisfy these flow demands with
nodes placed as few as possible. In this paper, we study this flow demands
oriented node placement problem that has not been addressed before. In
particular, we divide and conquer the problem by three steps: calculating the
maximal flow for single routing demand, calculating the maximal flow for
multiple routing demands, and finding the minimal number of nodes for multiple
routing demands with flow requirement. During the above solving procedure, we
prove that the second and third step are NP-hard and propose two algorithms
that have polynomial-time complexity. The proposed algorithms are evaluated
under practical scenarios. The experiments show that the proposed algorithms
can achieve satisfactory results on both flow demands and total number of
wireless nodes.
</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08396</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08398</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Cyber-Human Interaction Based System on Mobile Phone for Indoor
  Localization</dc:title>
 <dc:creator>Yuan, Zimu</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  In this article, we study the Cyber-Human Interaction (CHI) based approach
that the &quot;Human&quot; part sets a list of location-based objectives and makes the
pathway decision whereas the &quot;Cyber&quot; part provides the pathway suggestion,
infer heuristics from the environment along the pathway and incrementally
resolve the location-based objectives with new heuristics for indoor
localization. For this study, we implement a CHI-based system on mobile phone.
The CHI-based system offers the pathway suggestion and the solution of the
location-based objectives based on its trajectory management. Without any
priori knowledge on the area of interest and any aid from other equipments, a
laborer can achieve his location-based objectives by walking through the area
of interest and simultaneously online interacting with the CHI-based system
installed in his phone. In evaluation, we conduct the experiments and show the
advantage CHI in reducing the time cost and the expense cost for the laborer.
</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08398</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08400</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Query Scheduling on Source Permutation for Big Data Integration</dc:title>
 <dc:creator>Yuan, Zimu</dc:creator>
 <dc:creator>Guo, Shusheng</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Big data integration could involve a large number of sources with
unpredictable redundancy information between them. The approach of building a
central warehousing to integrate big data from all sources then becomes
infeasible because of so large number of sources and continuous updates
happening. A practical approach is to apply online query scheduling that
inquires data from sources at runtime upon receiving a query. In this paper, we
address the Time-Cost Minimization Problem for online query scheduling, and
tackle the challenges of source permutation and statistics estimation to
minimize the time cost of retrieving answers for the real-time receiving query.
We propose the online scheduling strategy that enables the improvement of
statistics, the construction of source permutation and the execution of query
working in parallel. Experimental results show high efficiency and scalability
of our scheduling strategy.
</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08404</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beacon Node Placement for Minimal Localization Error</dc:title>
 <dc:creator>Yuan, Zimu</dc:creator>
 <dc:creator>Li, Wei</dc:creator>
 <dc:creator>Xu, Zhiwei</dc:creator>
 <dc:creator>Zhao, Wei</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Beacon node placement, node-to-node measurement, and target node positioning
are the three key steps for a localization process. However, compared with the
other two steps, beacon node placement still lacks a comprehensive, systematic
study in research literatures. To fill this gap, we address the Beacon Node
Placment (BNP) problem that deploys beacon nodes for minimal localization error
in this paper. BNP is difficult in that the localization error is determined by
a complicated combination of factors, i.e., the localization error differing
greatly under a different environment, with a different algorithm applied, or
with a different type of beacon node used. In view of the hardness of BNP, we
propose an approximate function to reduce time cost in localization error
calculation, and also prove its time complexity and error bound. By
approximation, a sub-optimal distribution of beacon nodes could be found within
acceptable time cost for placement. In the experiment, we test our method and
compare it with other node placement methods under various settings and
environments. The experimental results show feasibility and effectiveness of
our method in practice.
</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08407</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CIUV: Collaborating Information Against Unreliable Views</dc:title>
 <dc:creator>Yuan, Zimu</dc:creator>
 <dc:creator>Xu, Zhiwei</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  In many real world applications, the information of an object can be obtained
from multiple sources. The sources may provide different point of views based
on their own origin. As a consequence, conflicting pieces of information are
inevitable, which gives rise to a crucial problem: how to find the truth from
these conflicts. Many truth-finding methods have been proposed to resolve
conflicts based on information trustworthy (i.e. more appearance means more
trustworthy) as well as source reliability. However, the factor of men's
involvement, i.e., information may be falsified by men with malicious
intension, is more or less ignored in existing methods. Collaborating the
possible relationship between information's origins and men's participation are
still not studied in research. To deal with this challenge, we propose a method
-- Collaborating Information against Unreliable Views (CIUV) --- in dealing
with men's involvement for finding the truth. CIUV contains 3 stages for
interactively mitigating the impact of unreliable views, and calculate the
truth by weighting possible biases between sources. We theoretically analyze
the error bound of CIUV, and conduct intensive experiments on real dataset for
evaluation. The experimental results show that CIUV is feasible and has the
smallest error compared with other methods.
</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08407</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08413</identifier>
 <datestamp>2016-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Multiple Access Channel with Asynchronous Cognition</dc:title>
 <dc:creator>Yemini, Michal</dc:creator>
 <dc:creator>Somekh-Baruch, Anelia</dc:creator>
 <dc:creator>Leshem, Amir</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we introduce the two-user asynchronous cognitive multiple
access channel (ACMAC). This channel model includes two transmitters, an
uninformed one, and an informed one which knows prior to the beginning of a
transmission the message which the uninformed transmitter is about to send. We
assume that the channel from the uninformed transmitter to the receiver suffers
a fixed but unknown delay. We further introduce a modified model, referred to
as the asynchronous codeword cognitive multiple access channel (ACC-MAC), which
differs from the ACMAC in that the informed user knows the signal that is to be
transmitted by the other user, rather than the message that it is about to
transmit. We state inner and outer bounds on the ACMAC and the ACC-MAC capacity
regions, and we specialize the results to the Gaussian case. Further, we
characterize the capacity regions of these channels in terms of multi-letter
expressions. Finally, we provide an example which instantiates the difference
between message side-information and codeword side-information.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1402.1617</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:date>2016-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08421</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Resilient Behaviors in Computational Systems and Environments</dc:title>
 <dc:creator>De Florio, Vincenzo</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The present article introduces a reference framework for discussing
resilience of computational systems. Rather than a property that may or may not
be exhibited by a system, resilience is interpreted here as the emerging result
of a dynamic process. Said process represents the dynamic interplay between the
behaviors exercised by a system and those of the environment it is set to
operate in. As a result of this interpretation, coherent definitions of several
aspects of resilience can be derived and proposed, including elasticity, change
tolerance, and antifragility. Definitions are also provided for measures of the
risk of unresilience as well as for the optimal match of a given resilient
design with respect to the current environmental conditions. Finally, a
resilience strategy based on our model is exemplified through a simple
scenario.
</dc:description>
 <dc:description>Comment: The final publication is available at Springer via
  http://dx.doi.org/10.1007/s40860-015-0002-6 The paper considerably extends
  the results of two conference papers that are available at http://ow.ly/KWfkj
  and http://ow.ly/KWfgO. Text and formalism in those papers has been used or
  adapted in the herewith submitted paper</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08421</dc:identifier>
 <dc:identifier>doi:10.1007/s40860-015-0002-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08434</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Full-Duplex Radio for Uplink/Downlink Transmission with Spatial
  Randomness</dc:title>
 <dc:creator>Mohammadi, Mohammadali</dc:creator>
 <dc:creator>Suraweera, Himal A.</dc:creator>
 <dc:creator>Krikidis, Ioannis</dc:creator>
 <dc:creator>Tellambura, Chintha</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a wireless system with a full-duplex (FD) access point (AP) that
transmits to a scheduled user in the downlink (DL) channel, while receiving
data from an user in the uplink (UL) channel at the same time on the same
frequency. In this system, loopback interference (LI) at the AP and inter user
interference between the uplink (UL) user and downlink (DL) user can cause
performance degradation. In order to characterize the effects of LI and inter
user interference, we derive closed-form expressions for the outage probability
and achievable sum rate of the system. In addition an asymptotic analysis that
reveals insights into the system behavior and performance degradation is
presented. Our results indicate that under certain conditions, FD transmissions
yield performance gains over half-duplex (HD) mode of operation.
</dc:description>
 <dc:description>Comment: Accepted for the IEEE International Conference on Communications (ICC
  2015)</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08434</dc:identifier>
 <dc:identifier>doi:10.1109/ICC.2015.7248604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08436</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of Residual Transmit RF Impairments on Training-Based MIMO
  Systems</dc:title>
 <dc:creator>Zhang, Xinlin</dc:creator>
 <dc:creator>Matthaiou, Michail</dc:creator>
 <dc:creator>Coldrey, Mikael</dc:creator>
 <dc:creator>Bj&#xf6;rnson, Emil</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Radio-frequency (RF) impairments, which intimately exist in wireless
communication systems, can severely limit the performance of multiple-input
multiple-output (MIMO) systems. Although we can resort to compensation schemes
to mitigate part of these impairments, a certain amount of residual impairments
always persists. In this paper, we consider a training-based point-to-point
MIMO system with residual transmit RF impairments (RTRI) using spatial
multiplexing transmission. Specifically, we derive a new linear channel
estimator for the proposed model, and show that RTRI create an estimation error
floor in the high signal-to-noise ratio (SNR) regime. Moreover, we derive
closed-form expressions for the signal-to-noise-and-interference ratio (SINR)
distributions, along with analytical expressions for the ergodic achievable
rates of zero-forcing, maximum ratio combining, and minimum mean-squared error
receivers, respectively. In addition, we optimize the ergodic achievable rates
with respect to the training sequence length, and demonstrate that finite
dimensional systems with RTRI generally require more training at high SNRs than
those with ideal hardware. At last, we extend our analysis to large-scale MIMO
configurations, and derive deterministic equivalents of the ergodic achievable
rates. It is shown that, by deploying large receive antenna arrays, the extra
training requirements due to RTRI can be eliminated. In fact, with sufficiently
large number of receive antennas, systems with RTRI may even need less training
than systems with ideal hardware.
</dc:description>
 <dc:description>Comment: 31 pages, submitted to the IEEE Transactions on Communications</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08453</identifier>
 <datestamp>2016-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum walk, entanglement and thermodynamic laws</dc:title>
 <dc:creator>Romanelli, Alejandro</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>00</dc:subject>
 <dc:description>  We consider an special dynamics of a quantum walk (QW) on a line. Initially,
the walker localized at the origin of the line with arbitrary chirality,
evolves to an asymptotic stationary state. In this stationary state a
measurement is performed and the state resulting from this measurement is used
to start a second QW evolution to achieve a second asymptotic stationary state.
In previous works, we developed the thermodynamics associated with the
entanglement between the coin and position degrees of freedom in the QW. Here
we study the application of the first and second laws of thermodynamics to the
process between the two stationary states mentioned above. We show that: i) the
entropy change has upper and lower bounds that are obtained analytically as a
function of the initial conditions. ii) the energy change is associated to a
heat-transfer process.
</dc:description>
 <dc:description>Comment: It was accepted to publish in Physica A</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08453</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2015.03.084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08454</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Efficient Axiom Pinpointing of EL+ Ontologies</dc:title>
 <dc:creator>Arif, M. Fareed</dc:creator>
 <dc:creator>Marques-Silva, Joao</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The EL family of Description Logics (DLs) has been the subject of interest in
recent years. On the one hand, these DLs are tractable, but fairly
inexpressive. On the other hand, these DLs can be used for designing different
classes of ontologies, most notably ontologies from the medical domain.
Unfortunately, building ontologies is error-prone. As a result, inferable
subsumption relations among concepts may be unintended. In recent years, the
problem of axiom pinpointing has been studied with the purpose of providing
minimal sets of axioms that explain unintended subsumption relations. For the
concrete case of EL and EL+, the most efficient approaches consist of encoding
the problem into propositional logic, specifically as a Horn formula, which is
then analyzed with a dedicated algorithm. This paper builds on this earlier
work, but exploits the important relationship between minimal axioms sets and
minimal unsatisfiable subformulas in the propositional domain. In turn, this
relationship allows applying a vast body of recent work in the propositional
domain to the concrete case of axiom pinpointing for EL and its variants. From
a practical perspective, the algorithms described in this paper are often
several orders of magnitude more efficient that the current state of the art in
axiom pinpointing for the EL family of DLs.
</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08454</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08463</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Modified Apriori Approach for Web Document Clustering</dc:title>
 <dc:creator>Roul, Rajendra Kumar</dc:creator>
 <dc:creator>Varshneya, Saransh</dc:creator>
 <dc:creator>Kalra, Ashu</dc:creator>
 <dc:creator>Sahay, Sanjay Kumar</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The traditional apriori algorithm can be used for clustering the web
documents based on the association technique of data mining. But this algorithm
has several limitations due to repeated database scans and its weak association
rule analysis. In modern world of large databases, efficiency of traditional
apriori algorithm would reduce manifolds. In this paper, we proposed a new
modified apriori approach by cutting down the repeated database scans and
improving association analysis of traditional apriori algorithm to cluster the
web documents. Further we improve those clusters by applying Fuzzy C-Means
(FCM), K-Means and Vector Space Model (VSM) techniques separately. For
experimental purpose, we use Classic3 and Classic4 datasets of Cornell
University having more than 10,000 documents and run both traditional apriori
and our modified apriori approach on it. Experimental results show that our
approach outperforms the traditional apriori algorithm in terms of database
scan and improvement on association of analysis. We found out that FCM is
better than K-Means and VSM in terms of F-measure of clusters of different
sizes.
</dc:description>
 <dc:description>Comment: 11 Pages, 5 Figures</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08463</dc:identifier>
 <dc:identifier>Springer, Smart Innovation Systems and Technologies, Vol. 33,
  2015, p. 159-171; Proceedings of the ICCIDM, Dec. 2014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08471</identifier>
 <datestamp>2015-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-validation of matching correlation analysis by resampling matching
  weights</dc:title>
 <dc:creator>Shimodaira, Hidetoshi</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The strength of association between a pair of data vectors is represented by
a nonnegative real number, called matching weight. For dimensionality
reduction, we consider a linear transformation of data vectors, and define a
matching error as the weighted sum of squared distances between transformed
vectors with respect to the matching weights. Given data vectors and matching
weights, the optimal linear transformation minimizing the matching error is
solved by the spectral graph embedding of Yan et al. (2007). This method is a
generalization of the canonical correlation analysis, and will be called as
matching correlation analysis (MCA). In this paper, we consider a novel
sampling scheme where the observed matching weights are randomly sampled from
underlying true matching weights with small probability, whereas the data
vectors are treated as constants. We then investigate a cross-validation by
resampling the matching weights. Our asymptotic theory shows that the
cross-validation, if rescaled properly, computes an unbiased estimate of the
matching error with respect to the true matching weights. Existing ideas of
cross-validation for resampling data vectors, instead of resampling matching
weights, are not applicable here. MCA can be used for data vectors from
multiple domains with different dimensions via an embarrassingly simple idea of
coding the data vectors. This method will be called as cross-domain matching
correlation analysis (CDMCA), and an interesting connection to the classical
associative memory model of neural networks is also discussed.
</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:date>2015-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08471</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08473</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bearing-Based Distributed Control and Estimation of Multi-Agent Systems</dc:title>
 <dc:creator>Zhao, Shiyu</dc:creator>
 <dc:creator>Zelazo, Daniel</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper studies the distributed control and estimation of multi-agent
systems based on bearing information. In particular, we consider two problems:
(i) the distributed control of bearing-constrained formations using relative
position measurements and (ii) the distributed localization of sensor networks
using bearing measurements. Both of the two problems are considered in
arbitrary dimensional spaces. The analyses of the two problems rely on the
recently developed bearing rigidity theory. We show that the two problems have
the same mathematical formulation and can be solved by identical protocols. The
proposed controller and estimator can globally solve the two problems without
ambiguity. The results are supported with illustrative simulations.
</dc:description>
 <dc:description>Comment: 6 pages, to appear in the 2015 European Control Conference</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08476</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guided Grammar Convergence</dc:title>
 <dc:creator>Zaytsev, Vadim</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>F.4.2</dc:subject>
 <dc:subject>F.4.3</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  Relating formal grammars is a hard problem that balances between language
equivalence (which is known to be undecidable) and grammar identity (which is
trivial). In this paper, we investigate several milestones between those two
extremes and propose a methodology for inconsistency management in grammar
engineering. While conventional grammar convergence is a practical approach
relying on human experts to encode differences as transformation steps, guided
grammar convergence is a more narrowly applicable technique that infers such
transformation steps automatically by normalising the grammars and establishing
a structural equivalence relation between them. This allows us to perform a
case study with automatically inferring bidirectional transformations between
11 grammars (in a broad sense) of the same artificial functional language:
parser specifications with different combinator libraries, definite clause
grammars, concrete syntax definitions, algebraic data types, metamodels, XML
schemata, object models.
</dc:description>
 <dc:description>Comment: In Poster Proceedings of 6th Conference on Software Language
  Engineering (SLE) 2013, http://www.sleconf.org/2013/</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08479</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Authentication on Mobile Devices via Stylometry, Application
  Usage, Web Browsing, and GPS Location</dc:title>
 <dc:creator>Fridman, Lex</dc:creator>
 <dc:creator>Weber, Steven</dc:creator>
 <dc:creator>Greenstadt, Rachel</dc:creator>
 <dc:creator>Kam, Moshe</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Active authentication is the problem of continuously verifying the identity
of a person based on behavioral aspects of their interaction with a computing
device. In this study, we collect and analyze behavioral biometrics data from
200subjects, each using their personal Android mobile device for a period of at
least 30 days. This dataset is novel in the context of active authentication
due to its size, duration, number of modalities, and absence of restrictions on
tracked activity. The geographical colocation of the subjects in the study is
representative of a large closed-world environment such as an organization
where the unauthorized user of a device is likely to be an insider threat:
coming from within the organization. We consider four biometric modalities: (1)
text entered via soft keyboard, (2) applications used, (3) websites visited,
and (4) physical location of the device as determined from GPS (when outdoors)
or WiFi (when indoors). We implement and test a classifier for each modality
and organize the classifiers as a parallel binary decision fusion architecture.
We are able to characterize the performance of the system with respect to
intruder detection time and to quantify the contribution of each modality to
the overall performance.
</dc:description>
 <dc:description>Comment: Accepted for Publication in the IEEE Systems Journal</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08479</dc:identifier>
 <dc:identifier>doi:10.1109/JSYST.2015.2472579</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08482</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Exascale Scientific Metadata Management</dc:title>
 <dc:creator>Blanas, Spyros</dc:creator>
 <dc:creator>Byna, Surendra</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Advances in technology and computing hardware are enabling scientists from
all areas of science to produce massive amounts of data using large-scale
simulations or observational facilities. In this era of data deluge, effective
coordination between the data production and the analysis phases hinges on the
availability of metadata that describe the scientific datasets. Existing
workflow engines have been capturing a limited form of metadata to provide
provenance information about the identity and lineage of the data. However,
much of the data produced by simulations, experiments, and analyses still need
to be annotated manually in an ad hoc manner by domain scientists. Systematic
and transparent acquisition of rich metadata becomes a crucial prerequisite to
sustain and accelerate the pace of scientific innovation. Yet, ubiquitous and
domain-agnostic metadata management infrastructure that can meet the demands of
extreme-scale science is notable by its absence.
  To address this gap in scientific data management research and practice, we
present our vision for an integrated approach that (1) automatically captures
and manipulates information-rich metadata while the data is being produced or
analyzed and (2) stores metadata within each dataset to permeate
metadata-oblivious processes and to query metadata through established and
standardized data access interfaces. We motivate the need for the proposed
integrated approach using applications from plasma physics, climate modeling
and neuroscience, and then discuss research challenges and possible solutions.
</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08485</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fair Scheduling Policies Exploiting Multiuser Diversity in Cellular
  Systems with Device-to-Device Communications</dc:title>
 <dc:creator>Nguyen, PhuongBang</dc:creator>
 <dc:creator>Rao, Bhaskar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We consider the resource allocation problem in cellular networks which
support Device-to-Device Communications (D2D). For systems that enable D2D via
only orthogonal resource sharing, we propose and analyze two resource
allocation policies that guarantee access fairness among all users, while
taking advantage of multi-user diversity and local D2D communications, to
provide marked improvements over existing cellular-only policies. The first
policy, the Cellular Fairness Scheduling (CFS) Policy, provides the simplest
D2D extension to existing cellular systems, while the second policy, the D2D
Fairness Scheduling (DFS) Policy, harnesses maximal performance from
D2D-enabled systems under the orthogonal sharing setting. For even higher
spectral efficiency, cellular systems with D2D can schedule the same frequency
resource for more than one D2D pairs. Under this non-orthogonal sharing
environment, we propose a novel group scheduling policy, the Group Fairness
Scheduling (GFS) Policy, that exploits both spatial frequency reuse and
multiuser diversity in order to deliver dramatic improvements to system
performance with perfect fairness among the users, regardless of whether they
are cellular or D2D users.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08485</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08490</identifier>
 <datestamp>2016-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differentially Private State Estimation in Distribution Networks with
  Smart Meters</dc:title>
 <dc:creator>Sandberg, Henrik</dc:creator>
 <dc:creator>D&#xe1;n, Gy&#xf6;rgy</dc:creator>
 <dc:creator>Thobaben, Ragnar</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  State estimation is routinely being performed in high-voltage power
transmission grids in order to assist in operation and to detect faulty
equipment. In low- and medium-voltage power distribution grids, on the other
hand, few real-time measurements are traditionally available, and operation is
often conducted based on predicted and historical data. Today, in many parts of
the world, smart meters have been deployed at many customers, and their
measurements could in principle be shared with the operators in real time to
enable improved state estimation. However, customers may feel reluctance in
doing so due to privacy concerns. We therefore propose state estimation schemes
for a distribution grid model, which ensure differential privacy to the
customers. In particular, the state estimation schemes optimize different
performance criteria, and a trade-off between a lower bound on the estimation
performance versus the customers' differential privacy is derived. The proposed
framework is general enough to be applicable also to other distribution
networks, such as water and gas networks.
</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08490</dc:identifier>
 <dc:identifier>doi:10.1109/CDC.2015.7402921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08498</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual pivot Quicksort</dc:title>
 <dc:creator>Iliopoulos, Vasileios</dc:creator>
 <dc:creator>Penman, David B.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68W40, 60F05</dc:subject>
 <dc:description>  In this paper, we analyse the dual pivot Quicksort, a variant of the standard
Quicksort algorithm, in which two pivots are used for the partitioning of the
array. We are solving recurrences of the expected number of key comparisons and
exchanges performed by the algorithm, obtaining the exact and asymptotic total
average values contributing to its time complexity. Further, we compute the
average number of partitioning stages and the variance of the number of key
comparisons. In terms of mean values, dual pivot Quicksort does not appear to
be faster than ordinary algorithm.
</dc:description>
 <dc:description>Comment: Post print of the article &quot;Dual pivot Quicksort&quot; published on 1
  August of 2012 in the journal of Discrete Mathematics, Algorithms and
  Applications</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08498</dc:identifier>
 <dc:identifier>Discrete Math. Algorithm. Appl. 04, 1250041 (2012) [13 pages]</dc:identifier>
 <dc:identifier>doi:10.1142/S1793830912500413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08504</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigating the Impact of Metric Aggregation Techniques on Defect
  Prediction</dc:title>
 <dc:creator>Assi, Rawad Abou</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Code metrics collected at the method level are often aggregated using
summation to capture system properties at higher levels (e.g., file- or
package-level). Since defect data is often available at these higher levels,
this aggregation allows researchers to build defect prediction models. Recent
findings by Landman et al. indicate that aggregation is likely to inflate the
correlation between size and complexity metrics. In this paper, we explore the
effect of nine aggregation techniques on the correlation between three types of
code metrics, namely Lines of Code, McCabe, and Halstead metrics. In addition
to summation, we study aggregation techniques that are measures of: (1) central
tendency (average and median), (2) dispersion (standard deviation and
inter-quartile range), (3) shape (skewness and kurtosis), and (4) income
inequality (Theil index and Gini coefficient). Our results show that defect
prediction models built using summation outperform those built using other
aggregation techniques. We also find that more complex aggregations are no
different than much simpler ones and that incorporating all aggregation types
in the same model does not provide a significant improvement over using
summation alone.
</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08504</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08509</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Finite Element Based P3M Method for N-body Problems</dc:title>
 <dc:creator>Beams, Natalie N.</dc:creator>
 <dc:creator>Olson, Luke N.</dc:creator>
 <dc:creator>Freund, Jonathan B.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>7008, 70F10, 65N30, 65N99</dc:subject>
 <dc:subject>G.1.0</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:description>  We introduce a fast mesh-based method for computing N-body interactions that
is both scalable and accurate. The method is founded on a
particle-particle--particle-mesh P3M approach, which decomposes a potential
into rapidly decaying short-range interactions and smooth, mesh-resolvable
long-range interactions. However, in contrast to the traditional approach of
using Gaussian screen functions to accomplish this decomposition, our method
employs specially designed polynomial bases to construct the screened
potentials. Because of this form of the screen, the long-range component of the
potential is then solved exactly with a finite element method, leading
ultimately to a sparse matrix problem that is solved efficiently with standard
multigrid methods. Moreover, since this system represents an exact
discretization, the optimal resolution properties of the FFT are unnecessary,
though the short-range calculation is now more involved than P3M/PME methods.
We introduce the method, analyze its key properties, and demonstrate the
accuracy of the algorithm.
</dc:description>
 <dc:description>Comment: 20 pages, submitted to SISC</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08513</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hiding Symbols and Functions: New Metrics and Constructions for
  Information-Theoretic Security</dc:title>
 <dc:creator>Calmon, Flavio du Pin</dc:creator>
 <dc:creator>M&#xe9;dard, Muriel</dc:creator>
 <dc:creator>Varia, Mayank</dc:creator>
 <dc:creator>Duffy, Ken R.</dc:creator>
 <dc:creator>Christiansen, Mark M.</dc:creator>
 <dc:creator>Zeger, Linda M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present information-theoretic definitions and results for analyzing
symmetric-key encryption schemes beyond the perfect secrecy regime, i.e. when
perfect secrecy is not attained. We adopt two lines of analysis, one based on
lossless source coding, and another akin to rate-distortion theory. We start by
presenting a new information-theoretic metric for security, called symbol
secrecy, and derive associated fundamental bounds. We then introduce
list-source codes (LSCs), which are a general framework for mapping a key
length (entropy) to a list size that an eavesdropper has to resolve in order to
recover a secret message. We provide explicit constructions of LSCs, and
demonstrate that, when the source is uniformly distributed, the highest level
of symbol secrecy for a fixed key length can be achieved through a construction
based on minimum-distance separable (MDS) codes. Using an analysis related to
rate-distortion theory, we then show how symbol secrecy can be used to
determine the probability that an eavesdropper correctly reconstructs functions
of the original plaintext. We illustrate how these bounds can be applied to
characterize security properties of symmetric-key encryption schemes, and, in
particular, extend security claims based on symbol secrecy to a functional
setting.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Information Theory</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08518</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Dual Diameter of Triangulations</dc:title>
 <dc:creator>Korman, Matias</dc:creator>
 <dc:creator>Langerman, Stefan</dc:creator>
 <dc:creator>Mulzer, Wolfgang</dc:creator>
 <dc:creator>Pilz, Alexander</dc:creator>
 <dc:creator>Saumell, Maria</dc:creator>
 <dc:creator>Vogtenhuber, Birgit</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Let $\Poly$ be a simple polygon with $n$ vertices. The \emph{dual graph}
$\triang^*$ of a triangulation~$\triang$ of~$\Poly$ is the graph whose vertices
correspond to the bounded faces of $\triang$ and whose edges connect those
faces of~$\triang$ that share an edge. We consider triangulations of~$\Poly$
that minimize or maximize the diameter of their dual graph. We show that both
triangulations can be constructed in $O(n^3\log n)$ time using dynamic
programming. If $\Poly$ is convex, we show that any minimizing triangulation
has dual diameter exactly $2\cdot\lceil\log_2(n/3)\rceil$ or
$2\cdot\lceil\log_2(n/3)\rceil -1$, depending on~$n$. Trivially, in this case
any maximizing triangulation has dual diameter $n-2$. Furthermore, we
investigate the relationship between the dual diameter and the number of
\emph{ears} (triangles with exactly two edges incident to the boundary of
$\Poly$) in a triangulation. For convex $\Poly$, we show that there is always a
triangulation that simultaneously minimizes the dual diameter and maximizes the
number of ears. In contrast, we give examples of general simple polygons where
every triangulation that maximizes the number of ears has dual diameter that is
quadratic in the minimum possible value. We also consider the case of point
sets in general position in the plane. We show that for any such set of $n$
points there are triangulations with dual diameter in~$O(\log n)$ and
in~$\Omega(\sqrt n)$.
</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:date>2015-10-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08518</dc:identifier>
 <dc:identifier>Computational Geometry: Theory and Applications (CGTA), 68, 2018,
  pp. 243-252</dc:identifier>
 <dc:identifier>doi:10.1016/j.comgeo.2017.06.008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08528</identifier>
 <datestamp>2015-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Average Distance Queries through Weighted Samples in Graphs and Metric
  Spaces: High Scalability with Tight Statistical Guarantees</dc:title>
 <dc:creator>Chechik, Shiri</dc:creator>
 <dc:creator>Cohen, Edith</dc:creator>
 <dc:creator>Kaplan, Haim</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The average distance from a node to all other nodes in a graph, or from a
query point in a metric space to a set of points, is a fundamental quantity in
data analysis. The inverse of the average distance, known as the (classic)
closeness centrality of a node, is a popular importance measure in the study of
social networks. We develop novel structural insights on the sparsifiability of
the distance relation via weighted sampling. Based on that, we present highly
practical algorithms with strong statistical guarantees for fundamental
problems. We show that the average distance (and hence the centrality) for all
nodes in a graph can be estimated using $O(\epsilon^{-2})$ single-source
distance computations. For a set $V$ of $n$ points in a metric space, we show
that after preprocessing which uses $O(n)$ distance computations we can compute
a weighted sample $S\subset V$ of size $O(\epsilon^{-2})$ such that the average
distance from any query point $v$ to $V$ can be estimated from the distances
from $v$ to $S$. Finally, we show that for a set of points $V$ in a metric
space, we can estimate the average pairwise distance using $O(n+\epsilon^{-2})$
distance computations. The estimate is based on a weighted sample of
$O(\epsilon^{-2})$ pairs of points, which is computed using $O(n)$ distance
computations. Our estimates are unbiased with normalized mean square error
(NRMSE) of at most $\epsilon$. Increasing the sample size by a $O(\log n)$
factor ensures that the probability that the relative error exceeds $\epsilon$
is polynomially small.
</dc:description>
 <dc:description>Comment: 21 pages, will appear in the Proceedings of RANDOM 2015</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:date>2015-06-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08528</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08535</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Infinite Author Topic Model based on Mixed Gamma-Negative Binomial
  Process</dc:title>
 <dc:creator>Xuan, Junyu</dc:creator>
 <dc:creator>Lu, Jie</dc:creator>
 <dc:creator>Zhang, Guangquan</dc:creator>
 <dc:creator>Da Xu, Richard Yi</dc:creator>
 <dc:creator>Luo, Xiangfeng</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Incorporating the side information of text corpus, i.e., authors, time
stamps, and emotional tags, into the traditional text mining models has gained
significant interests in the area of information retrieval, statistical natural
language processing, and machine learning. One branch of these works is the
so-called Author Topic Model (ATM), which incorporates the authors's interests
as side information into the classical topic model. However, the existing ATM
needs to predefine the number of topics, which is difficult and inappropriate
in many real-world settings. In this paper, we propose an Infinite Author Topic
(IAT) model to resolve this issue. Instead of assigning a discrete probability
on fixed number of topics, we use a stochastic process to determine the number
of topics from the data itself. To be specific, we extend a gamma-negative
binomial process to three levels in order to capture the
author-document-keyword hierarchical structure. Furthermore, each document is
assigned a mixed gamma process that accounts for the multi-author's
contribution towards this document. An efficient Gibbs sampling inference
algorithm with each conditional distribution being closed-form is developed for
the IAT model. Experiments on several real-world datasets show the capabilities
of our IAT model to learn the hidden topics, authors' interests on these topics
and the number of topics simultaneously.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures, submitted to KDD conference</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08535</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08542</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonparametric Relational Topic Models through Dependent Gamma Processes</dc:title>
 <dc:creator>Xuan, Junyu</dc:creator>
 <dc:creator>Lu, Jie</dc:creator>
 <dc:creator>Zhang, Guangquan</dc:creator>
 <dc:creator>Da Xu, Richard Yi</dc:creator>
 <dc:creator>Luo, Xiangfeng</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Traditional Relational Topic Models provide a way to discover the hidden
topics from a document network. Many theoretical and practical tasks, such as
dimensional reduction, document clustering, link prediction, benefit from this
revealed knowledge. However, existing relational topic models are based on an
assumption that the number of hidden topics is known in advance, and this is
impractical in many real-world applications. Therefore, in order to relax this
assumption, we propose a nonparametric relational topic model in this paper.
Instead of using fixed-dimensional probability distributions in its generative
model, we use stochastic processes. Specifically, a gamma process is assigned
to each document, which represents the topic interest of this document.
Although this method provides an elegant solution, it brings additional
challenges when mathematically modeling the inherent network structure of
typical document network, i.e., two spatially closer documents tend to have
more similar topics. Furthermore, we require that the topics are shared by all
the documents. In order to resolve these challenges, we use a subsampling
strategy to assign each document a different gamma process from the global
gamma process, and the subsampling probabilities of documents are assigned with
a Markov Random Field constraint that inherits the document network structure.
Through the designed posterior inference algorithm, we can discover the hidden
topics and its number simultaneously. Experimental results on both synthetic
and real-world network datasets demonstrate the capabilities of learning the
hidden topics and, more importantly, the number of topics.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08542</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08548</identifier>
 <datestamp>2017-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hitting Times in Markov Chains with Restart and their Application to
  Network Centrality</dc:title>
 <dc:creator>Avrachenkov, Konstantin</dc:creator>
 <dc:creator>Piunovskiy, Alexey</dc:creator>
 <dc:creator>Zhang, Yi</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Motivated by applications in telecommunications, computer scienceand physics,
we consider a discrete-time Markov process withrestart. At each step the
process eitherwith a positive probability restarts from a given distribution,
orwith the complementary probability continues according to a Markovtransition
kernel. The main contribution of the present work is thatwe obtain an explicit
expression for the expectation of the hittingtime (to a given target set) of
the process with restart.The formula is convenient when considering the problem
of optimizationof the expected hitting time with respect to the restart
probability.We illustrate our results with two examplesin uncountable and
countable state spaces andwith an application to network centrality.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2017-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08550</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact bounds of the M{\&quot;o}bius inverse of monotone set functions</dc:title>
 <dc:creator>Grabisch, Michel</dc:creator>
 <dc:creator>Miranda, Pedro</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We give the exact upper and lower bounds of the M{\&quot;o}bius inverse of
monotone and normalized set functions (a.k.a. normalized capacities) on a
finite set of n elements. We find that the absolute value of the bounds tend to
4 n/2 $\sqrt$ $\pi$n/2 when n is large. We establish also the exact bounds of
the interaction transform and Banzhaf interaction transform, as well as the
exact bounds of the M{\&quot;o}bius inverse for the subfamilies of k-additive
normalized capacities and p-symmetric normalized capacities.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08550</dc:identifier>
 <dc:identifier>Discrete Applied Mathematics, Elsevier, 2015, pp.7-12</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08551</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Clause set Schema Aided by Automated Theorem Proving: A Case
  Study [Extended Paper]</dc:title>
 <dc:creator>Cerna, David</dc:creator>
 <dc:creator>Leitsch, Alexander</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The schematic CERES method [8] is a recently developed method of cut
elimination for proof schemata, that is a sequence of proofs with a recursive
construction. Proof schemata can be thought of as a way to circumvent adding an
induction rule to the LK-calculus. In this work, we formalize a schematic
version of the infinitary pigeonhole principle, which we call the
Non-injectivity Assertion schema (NiA-schema), in the LKS-calculus [8], and
analyse the clause set schema extracted from the NiA-schema using some of the
structure provided by the schematic CERES method. To the best of our knowledge,
this is the first appli- cation of the constructs built for proof analysis of
proof schemata to a mathematical argument since its publication. We discuss the
role of Automated Theorem Proving (ATP) in schematic proof analysis, as well as
the shortcomings of the schematic CERES method concerning the formalization of
the NiA-schema, namely, the expressive power of the schematic resolution
calculus. We conclude with a discussion concerning the usage of ATP in
schematic proof analysis.
</dc:description>
 <dc:description>Comment: Submitted to Cade 2015. if published, will be published without
  appendix. Full paper, as provided here, is 23 pages. Published will be 15
  pages</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08551</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08558</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Whittle Index Policy for Crawling Ephemeral Content</dc:title>
 <dc:creator>Avrachenkov, Konstantin</dc:creator>
 <dc:creator>Borkar, Vivek</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We consider a task of scheduling a crawler to retrieve content from several
sites with ephemeral content. A user typically loses interest in ephemeral
content, like news or posts at social network groups, after several days or
hours. Thus, development of timely crawling policy for such ephemeral
information sources is very important. We first formulate this problem as an
optimal control problem with average reward. The reward can be measured in the
number of clicks or relevant search requests. The problem in its initial
formulation suffers from the curse of dimensionality and quickly becomes
intractable even with moderate number of information sources. Fortunately, this
problem admits a Whittle index, which leads to problem decomposition and to a
very simple and efficient crawling policy. We derive the Whittle index and
provide its theoretical justification.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08570</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uniform Information Exchange in Multi-channel Wireless Ad Hoc Networks</dc:title>
 <dc:creator>Ning, Li</dc:creator>
 <dc:creator>Yu, Dongxiao</dc:creator>
 <dc:creator>Zhang, Yong</dc:creator>
 <dc:creator>Wang, Yuexuan</dc:creator>
 <dc:creator>Lau, Francis C. M.</dc:creator>
 <dc:creator>Feng, Shenzhong</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In the information exchange problem, k packets that are initially maintained
by k nodes need to be disseminated to the whole network as quickly as possible.
We consider this problem in single-hop multi- channel networks of n nodes, and
propose a uniform protocol that with high probability accomplishes the
dissemination in O(k/F + F \cdot log n) rounds, assuming F available channels
and collision detection. This result is asymptotically optimal when k is large
(k \geq F^2 \cdot log n). To our knowledge, this is the first uniform protocol
for information exchange in multi-channel networks.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08570</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08572</identifier>
 <datestamp>2016-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discrete Temporal Constraint Satisfaction Problems</dc:title>
 <dc:creator>Bodirsky, Manuel</dc:creator>
 <dc:creator>Martin, Barnaby</dc:creator>
 <dc:creator>Mottet, Antoine</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>03C99</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  A discrete temporal constraint satisfaction problem is a constraint
satisfaction problem (CSP) whose constraint language consists of relations that
are first-order definable over $(\Bbb Z,&lt;)$. Our main result says that every
distance CSP is in Ptime or NP-complete, unless it can be formulated as a
finite domain CSP in which case the computational complexity is not known in
general.
</dc:description>
 <dc:description>Comment: 41 pages</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2016-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08572</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08577</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Spikes Deconvolution on Thin Grids</dc:title>
 <dc:creator>Duval, Vincent</dc:creator>
 <dc:creator>Peyr&#xe9;, Gabriel</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This article analyzes the recovery performance of two popular finite
dimensional approximations of the sparse spikes deconvolution problem over
Radon measures. We examine in a unified framework both the L1 regularization
(often referred to as Lasso or Basis-Pursuit) and the Continuous Basis-Pursuit
(C-BP) methods. The Lasso is the de-facto standard for the sparse
regularization of inverse problems in imaging. It performs a nearest neighbor
interpolation of the spikes locations on the sampling grid. The C-BP method,
introduced by Ekanadham, Tranchina and Simoncelli, uses a linear interpolation
of the locations to perform a better approximation of the infinite-dimensional
optimization problem, for positive measures. We show that, in the small noise
regime, both methods estimate twice the number of spikes as the number of
original spikes. Indeed, we show that they both detect two neighboring spikes
around the locations of an original spikes. These results for deconvolution
problems are based on an abstract analysis of the so-called extended support of
the solutions of L1-type problems (including as special cases the Lasso and
C-BP for deconvolution), which are of an independent interest. They precisely
characterize the support of the solutions when the noise is small and the
regularization parameter is selected accordingly. We illustrate these findings
to analyze for the first time the support instability of compressed sensing
recovery when the number of measurements is below the critical limit (well
documented in the literature) where the support is provably stable.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08581</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LSHTC: A Benchmark for Large-Scale Text Classification</dc:title>
 <dc:creator>Partalas, Ioannis</dc:creator>
 <dc:creator>Kosmopoulos, Aris</dc:creator>
 <dc:creator>Baskiotis, Nicolas</dc:creator>
 <dc:creator>Artieres, Thierry</dc:creator>
 <dc:creator>Paliouras, George</dc:creator>
 <dc:creator>Gaussier, Eric</dc:creator>
 <dc:creator>Androutsopoulos, Ion</dc:creator>
 <dc:creator>Amini, Massih-Reza</dc:creator>
 <dc:creator>Galinari, Patrick</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  LSHTC is a series of challenges which aims to assess the performance of
classification systems in large-scale classification in a a large number of
classes (up to hundreds of thousands). This paper describes the dataset that
have been released along the LSHTC series. The paper details the construction
of the datsets and the design of the tracks as well as the evaluation measures
that we implemented and a quick overview of the results. All of these datasets
are available online and runs may still be submitted on the online server of
the challenges.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08585</identifier>
 <datestamp>2015-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Complexity-Rate Tradeoff of Centralized Radio Access Networks</dc:title>
 <dc:creator>Rost, Peter</dc:creator>
 <dc:creator>Talarico, Salvatore</dc:creator>
 <dc:creator>Valenti, Matthew C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>94A05</dc:subject>
 <dc:description>  In a centralized RAN, the signals from multiple RAPs are processed centrally
in a data center. Centralized RAN enables advanced interference coordination
strategies while leveraging the elastic provisioning of data processing
resources. It is particularly well suited for dense deployments, such as within
a large building where the RAPs are connected via fibre and many cells are
underutilized. This paper considers the computational requirements of
centralized RAN with the goal of illuminating the benefits of pooling
computational resources. A new analytical framework is proposed for quantifying
the computational load associated with the centralized processing of uplink
signals in the presence of block Rayleigh fading, distance-dependent path-loss,
and fractional power control. Several new performance metrics are defined,
including computational outage probability, outage complexity, computational
gain, computational diversity, and the complexity-rate tradeoff. The validity
of the analytical framework is confirmed by comparing it numerically with a
simulator compliant with the 3GPP LTE standard. Using the developed metrics, it
is shown that centralizing the computing resources provides a higher net
throughput per computational resource as compared to local processing.
</dc:description>
 <dc:description>Comment: 13 pages, 8 figures, 25 references, accepted to IEEE Transactions on
  Wireless Communications</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2015-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08585</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2015.2449321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08596</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Optimal Transport Averaging of Neuroimaging Data</dc:title>
 <dc:creator>Gramfort, Alexandre</dc:creator>
 <dc:creator>Peyr&#xe9;, Gabriel</dc:creator>
 <dc:creator>Cuturi, Marco</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Knowing how the Human brain is anatomically and functionally organized at the
level of a group of healthy individuals or patients is the primary goal of
neuroimaging research. Yet computing an average of brain imaging data defined
over a voxel grid or a triangulation remains a challenge. Data are large, the
geometry of the brain is complex and the between subjects variability leads to
spatially or temporally non-overlapping effects of interest. To address the
problem of variability, data are commonly smoothed before group linear
averaging. In this work we build on ideas originally introduced by Kantorovich
to propose a new algorithm that can average efficiently non-normalized data
defined over arbitrary discrete domains using transportation metrics. We show
how Kantorovich means can be linked to Wasserstein barycenters in order to take
advantage of an entropic smoothing approach. It leads to a smooth convex
optimization problem and an algorithm with strong convergence guarantees. We
illustrate the versatility of this tool and its empirical behavior on
functional neuroimaging data, functional MRI and magnetoencephalography (MEG)
source estimates, defined on voxel grids and triangulations of the folded
cortical surface.
</dc:description>
 <dc:description>Comment: Information Processing in Medical Imaging (IPMI), Jun 2015, Isle of
  Skye, United Kingdom. Springer, 2015</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08601</identifier>
 <datestamp>2016-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding a low-rank basis in a matrix subspace</dc:title>
 <dc:creator>Nakatsukasa, Yuji</dc:creator>
 <dc:creator>Soma, Tasuku</dc:creator>
 <dc:creator>Uschmajew, Andr&#xe9;</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  For a given matrix subspace, how can we find a basis that consists of
low-rank matrices? This is a generalization of the sparse vector problem. It
turns out that when the subspace is spanned by rank-1 matrices, the matrices
can be obtained by the tensor CP decomposition. For the higher rank case, the
situation is not as straightforward. In this work we present an algorithm based
on a greedy process applicable to higher rank problems. Our algorithm first
estimates the minimum rank by applying soft singular value thresholding to a
nuclear norm relaxation, and then computes a matrix with that rank using the
method of alternating projections. We provide local convergence results, and
compare our algorithm with several alternative approaches. Applications include
data compression beyond the classical truncated SVD, computing accurate
eigenvectors of a near-multiple eigenvalue, image separation and graph
Laplacian eigenproblems.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2016-06-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08602</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pairs of Languages Closed under Shuffle Projection</dc:title>
 <dc:creator>Ochsenschl&#xe4;ger, Peter</dc:creator>
 <dc:creator>Rieke, Roland</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Shuffle projection is motivated by the verification of safety properties of
special parameterized systems. Basic definitions and properties, especially
related to alphabetic homomorphisms, are presented. The relation between
iterated shuffle products and shuffle projections is shown. A special class of
multi-counter automata is introduced, to formulate shuffle projection in terms
of computations of these automata represented by transductions. This
reformulation of shuffle projection leads to construction principles for pairs
of languages closed under shuffle projection. Additionally, it is shown that
under certain conditions these transductions are rational, which implies
decidability of closure against shuffle projection. Decidability of these
conditions is proven for regular languages. Finally, without additional
conditions, decidability of the question, whether a pair of regular languages
is closed under shuffle projection, is shown. In an appendix the relation
between shuffle projection and the shuffle product of two languages is
discussed. Additionally, a kind of shuffle product for computations in
S-automata is defined.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08602</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08604</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Liquid FM: Recommending Music through Viscous Democracy</dc:title>
 <dc:creator>Boldi, Paolo</dc:creator>
 <dc:creator>Monti, Corrado</dc:creator>
 <dc:creator>Santini, Massimo</dc:creator>
 <dc:creator>Vigna, Sebastiano</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Most modern recommendation systems use the approach of collaborative
filtering: users that are believed to behave alike are used to produce
recommendations. In this work we describe an application (Liquid FM) taking a
completely different approach. Liquid FM is a music recommendation system that
makes the user responsible for the recommended items. Suggestions are the
result of a voting scheme, employing the idea of viscous democracy. Liquid FM
can also be thought of as the first testbed for this voting system. In this
paper we outline the design and architecture of the application, both from the
theoretical and from the implementation viewpoints.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08623</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fine-grained Language Composition: A Case Study</dc:title>
 <dc:creator>Barrett, Edd</dc:creator>
 <dc:creator>Bolz, Carl Friedrich</dc:creator>
 <dc:creator>Diekmann, Lukas</dc:creator>
 <dc:creator>Tratt, Laurence</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:description>  Although run-time language composition is common, it normally takes the form
of a crude Foreign Function Interface (FFI). While useful, such compositions
tend to be coarse-grained and slow. In this paper we introduce a novel
fine-grained syntactic composition of PHP and Python which allows users to
embed each language inside the other, including referencing variables across
languages. This composition raises novel design and implementation challenges.
We show that good solutions can be found to the design challenges; and that the
resulting implementation imposes an acceptable performance overhead of, at
most, 2.6x.
</dc:description>
 <dc:description>Comment: 27 pages, 4 tables, 5 figures</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08623</dc:identifier>
 <dc:identifier>European Conference on Object-Oriented Programming (ECOOP). July
  2016, Pages 3:1--3:27</dc:identifier>
 <dc:identifier>doi:10.4230/LIPIcs.ECOOP.2016.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08627</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Traffic Demand-Aware Topology Control for Enhanced Energy-Efficiency of
  Cellular Networks</dc:title>
 <dc:creator>Pollakis, Emmanuel</dc:creator>
 <dc:creator>Cavalcante, Renato L. G.</dc:creator>
 <dc:creator>Sta&#x144;czak, S&#x142;awomir</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The service provided by mobile networks operated today is not adapted to
spatio-temporal fluctuations in traffic demand, although such fluctuations
offer opportunities for energy savings. In particular, significant gains in
energy efficiency are realizable by disengaging temporarily redundant hardware
components of base stations. We therefore propose a novel optimization
framework that considers both the load-dependent energy radiated by the
antennas and the remaining forms of energy needed for operating the base
stations. The objective is to reduce the energy consumption of mobile networks,
while ensuring that the data rate requirements of the users are met throughout
the coverage area. Building upon sparse optimization techniques, we develop a
majorization-minimization algorithm with the ability to identify
energy-efficient network configurations. The iterative algorithm is load-aware,
has low computational complexity, and can be implemented in an online fashion
to exploit load fluctuations on a short time scale. Simulations show that the
algorithm can find network configurations with the energy consumption similar
to that obtained with global optimization tools, which cannot be applied to
real large networks. Although we consider only one currently deployed cellular
technology, the optimization framework is general, potentially applicable to a
large class of access technologies.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Journal on Selected Areas in Communications - Green
  Communications and Networking</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08627</dc:identifier>
 <dc:identifier>doi:10.1186/s13638-016-0539-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08636</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design &amp; Implementation Approach for Error Free Clinical Data Repository
  for the Medical Practitioners</dc:title>
 <dc:creator>Ray, Kisor</dc:creator>
 <dc:creator>Ghosh, Santanu</dc:creator>
 <dc:creator>Das, Mridul</dc:creator>
 <dc:creator>Ray, Bhaswati</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>H.4.0</dc:subject>
 <dc:description>  The modern treatment of any disease is heavily dependent on the medical
diagnosis. Clinical data obtained through the diagnostics tests need to be
collected and entered into the computer database in order to make a clinical
data repository. In most of the cases, manual entry is an absolute necessity.
However, manual entry can cause errors also, leading to wrong diagnosis. This
paper explains how data could be entered free of error to reduce the chances of
wrong diagnosis by designing and implementation of a simple database driven
application.
</dc:description>
 <dc:description>Comment: 04 pages, 04 Figures, International Journal of Computer Trends and
  Technology, Volume-21 Number-2,2015, ISSN 2231-2803</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08636</dc:identifier>
 <dc:identifier>doi:10.14445/22312803/IJCTT-V21P113</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08639</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse plus low-rank autoregressive identification in neuroimaging time
  series</dc:title>
 <dc:creator>Li&#xe9;geois, Rapha&#xeb;l</dc:creator>
 <dc:creator>Mishra, Bamdev</dc:creator>
 <dc:creator>Zorzi, Mattia</dc:creator>
 <dc:creator>Sepulchre, Rodolphe</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper considers the problem of identifying multivariate autoregressive
(AR) sparse plus low-rank graphical models. Based on the corresponding problem
formulation recently presented, we use the alternating direction method of
multipliers (ADMM) to efficiently solve it and scale it to sizes encountered in
neuroimaging applications. We apply this decomposition on synthetic and real
neuroimaging datasets with a specific focus on the information encoded in the
low-rank structure of our model. In particular, we illustrate that this
information captures the spatio-temporal structure of the original data,
generalizing classical component analysis approaches.
</dc:description>
 <dc:description>Comment: 6 pages paper submitted to CDC 2015</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08642</identifier>
 <datestamp>2015-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Integral Siding Mode Manifold Design: A Sum of Squares
  Approach</dc:title>
 <dc:creator>Sanjari, S.</dc:creator>
 <dc:creator>Ozgoli, S.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a general form of integral sliding mode manifold, and
proposes an algorithmic approach based on Sum of Squares (SOS) programming to
design generalized integral sliding mode manifold and controller for nonlinear
systems with both matched and unmatched uncertainties. The approach also gives
a sufficient condition for successful design of controller and manifold
parameters. The result of the paper is then verified by several simulation
examples and two practical applications, namely Glucose-insulin regulation
problem and the unicycle dynamics steering problem are considered.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2015-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08643</identifier>
 <datestamp>2015-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strong and weak separability conditions for two-qubits density matrices</dc:title>
 <dc:creator>Ben-Aryeh, Y.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Explicit separable density matrices, for mixed two qubits states, are derived
by the use of Hilbert Schmidt decompositions and Peres Horodecki criterion. A
strongly separable two qubits mixed state is defined by multiplications of two
density matrices given with pure states while weakly separable two qubits state
is defined by multiplications of two density matrices which includes non-pure
states. We find the sufficient and necessary condition for separability of
two-qubits density matrices and show that under this condition the two-qubit
density matrices are strongly separable.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2015-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08643</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08644</identifier>
 <datestamp>2015-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Capacity of the Wiener Phase-Noise Channel: Bounds and Capacity
  Achieving Distributions</dc:title>
 <dc:creator>Khanzadi, M. Reza</dc:creator>
 <dc:creator>Krishnan, Rajet</dc:creator>
 <dc:creator>S&#xf6;der, Johan</dc:creator>
 <dc:creator>Eriksson, Thomas</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, the capacity of the additive white Gaussian noise (AWGN)
channel, affected by time-varying Wiener phase noise is investigated. Tight
upper and lower bounds on the capacity of this channel are developed. The upper
bound is obtained by using the duality approach, and considering a specific
distribution over the output of the channel. In order to lower-bound the
capacity, first a family of capacity-achieving input distributions is found by
solving a functional optimization of the channel mutual information. Then,
lower bounds on the capacity are obtained by drawing samples from the proposed
distributions through Monte-Carlo simulations. The proposed capacity-achieving
input distributions are circularly symmetric, non-Gaussian, and the input
amplitudes are correlated over time. The evaluated capacity bounds are tight
for a wide range of signal-to-noise-ratio (SNR) values, and thus they can be
used to quantify the capacity. Specifically, the bounds follow the well-known
AWGN capacity curve at low SNR, while at high SNR, they coincide with the
high-SNR capacity result available in the literature for the phase-noise
channel.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Communications, 2015</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2015-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08644</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2015.2465389</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08650</identifier>
 <datestamp>2017-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparison of Bayesian predictive methods for model selection</dc:title>
 <dc:creator>Piironen, Juho</dc:creator>
 <dc:creator>Vehtari, Aki</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The goal of this paper is to compare several widely used Bayesian model
selection methods in practical model selection problems, highlight their
differences and give recommendations about the preferred approaches. We focus
on the variable subset selection for regression and classification and perform
several numerical experiments using both simulated and real world data. The
results show that the optimization of a utility estimate such as the
cross-validation (CV) score is liable to finding overfitted models due to
relatively high variance in the utility estimates when the data is scarce. This
can also lead to substantial selection induced bias and optimism in the
performance evaluation for the selected model. From a predictive viewpoint,
best results are obtained by accounting for model uncertainty by forming the
full encompassing model, such as the Bayesian model averaging solution over the
candidate models. If the encompassing model is too complex, it can be robustly
simplified by the projection method, in which the information of the full model
is projected onto the submodels. This approach is substantially less prone to
overfitting than selection based on CV-score. Overall, the projection method
appears to outperform also the maximum a posteriori model and the selection of
the most probable variables. The study also demonstrates that the model
selection can greatly benefit from using cross-validation outside the searching
process both for guiding the model size selection and assessing the predictive
performance of the finally selected model.
</dc:description>
 <dc:description>Comment: A few minor changes; added a few sentences, corrected some
  grammatical errors and modified Figure 7</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2016-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08650</dc:identifier>
 <dc:identifier>Statistics and Computing, 2017, Volume 27, Issue 3, 711-735</dc:identifier>
 <dc:identifier>doi:10.1007/s11222-016-9649-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08659</identifier>
 <datestamp>2017-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary Adder Circuits of Asymptotically Minimum Depth, Linear Size, and
  Fan-Out Two</dc:title>
 <dc:creator>Held, Stephan</dc:creator>
 <dc:creator>Spirkl, Sophie Theresa</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>B.2.4</dc:subject>
 <dc:description>  We consider the problem of constructing fast and small binary adder circuits.
Among widely-used adders, the Kogge-Stone adder is often considered the
fastest, because it computes the carry bits for two $n$-bit numbers (where $n$
is a power of two) with a depth of $2\log_2 n$ logic gates, size $4 n\log_2 n$,
and all fan-outs bounded by two. Fan-outs of more than two are avoided, because
they lead to the insertion of repeaters for repowering the signal and
additional depth in the physical implementation. However, the depth bound of
the Kogge-Stone adder is off by a factor of two from the lower bound of $\log_2
n$. This bound is achieved asymptotically in two separate constructions by
Brent and Krapchenko. Brent's construction gives neither a bound on the fan-out
nor the size, while Krapchenko's adder has linear size, but can have up to
linear fan-out. With a fan-out bound of two, neither construction achieves a
depth of less than $2 \log_2 n$. In a further approach, Brent and Kung proposed
an adder with linear size and fan-out two, but twice the depth of the
Kogge-Stone adder. These results are 33-43 years old and no substantial
theoretical improvement for has been made since then.
  In this paper we integrate the individual advantages of all previous adder
circuits into a new family of full adders, the first to improve on the depth
bound of $2\log_2 n$ while maintaining a fan-out bound of two. Our adders
achieve an asymptotically optimum logic gate depth of $\log_2 n + o(\log_2 n)$
and linear size $\mathcal {O}(n)$.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2017-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08661</identifier>
 <datestamp>2015-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Cell Load and Throughput in Green Small Cell Networks with
  Generalized Cell Association</dc:title>
 <dc:creator>Liu, Chun-Hung</dc:creator>
 <dc:creator>Wang, Li-Chun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper thoroughly explored the fundamental interactions between cell
association, cell load and throughput in a green (energy-efficient) small cell
network in which all base stations form a homogeneous Poisson point process
(PPP) of intensity $\lambda_B$ and all users form another independent PPP of
intensity $\lambda_U$. Cell voidness, usually disregarded due to rarity in
cellular network modeling, is first theoretically analyzed under generalized
(channel-aware) cell association (GCA). We showed that the void cell
probability cannot be neglected any more since it is bounded above by
$\exp(-\lambda_U/\lambda_B)$ that is typically not small in a small cell
network. The accurate expression of the void cell probability for GCA was
characterized and it was used to derive the average cell and user throughputs.
We learned that cell association and cell load $\lambda_U/\lambda_B$
significantly affect these two throughputs. According to the average cell and
user throughputs, the green cell and user throughputs are defined respectively
to reflect whether the energy of a base station is efficiently used to transmit
information or not. In order to achieve satisfactory throughput with certain
level of greenness, cell load should be properly determined. We presented the
theoretical solutions of the optimal cell loads that maximize the green cell
and user throughputs, respectively, and verified their correctness by
simulation.
</dc:description>
 <dc:description>Comment: 15 pages, 8 figures</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2015-09-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08663</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Saliency Based on Multiscale Deep Features</dc:title>
 <dc:creator>Li, Guanbin</dc:creator>
 <dc:creator>Yu, Yizhou</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual saliency is a fundamental problem in both cognitive and computational
sciences, including computer vision. In this CVPR 2015 paper, we discover that
a high-quality visual saliency model can be trained with multiscale features
extracted using a popular deep learning architecture, convolutional neural
networks (CNNs), which have had many successes in visual recognition tasks. For
learning such saliency models, we introduce a neural network architecture,
which has fully connected layers on top of CNNs responsible for extracting
features at three different scales. We then propose a refinement method to
enhance the spatial coherence of our saliency results. Finally, aggregating
multiple saliency maps computed for different levels of image segmentation can
further boost the performance, yielding saliency maps better than those
generated from a single segmentation. To promote further research and
evaluation of visual saliency models, we also construct a new large database of
4447 challenging images and their pixelwise saliency annotation. Experimental
results demonstrate that our proposed method is capable of achieving
state-of-the-art performance on all public benchmarks, improving the F-Measure
by 5.0% and 13.2% respectively on the MSRA-B dataset and our new dataset
(HKU-IS), and lowering the mean absolute error by 5.7% and 35.1% respectively
on these two datasets.
</dc:description>
 <dc:description>Comment: To appear in CVPR 2015</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08663</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08665</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Linear First-Order Functional Intermediate Language for Verified
  Compilers</dc:title>
 <dc:creator>Schneider, Sigurd</dc:creator>
 <dc:creator>Smolka, Gert</dc:creator>
 <dc:creator>Hack, Sebastian</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We present the linear first-order intermediate language IL for verified
compilers. IL is a functional language with calls to a nondeterministic
environment. We give IL terms a second, imperative semantic interpretation and
obtain a register transfer language. For the imperative interpretation we
establish a notion of live variables. Based on live variables, we formulate a
decidable property called coherence ensuring that the functional and the
imperative interpretation of a term coincide. We formulate a register
assignment algorithm for IL and prove its correctness. The algorithm translates
a functional IL program into an equivalent imperative IL program. Correctness
follows from the fact that the algorithm reaches a coherent program after
consistently renaming local variables. We prove that the maximal number of live
variables in the initial program bounds the number of different variables in
the final coherent program. The entire development is formalized in Coq.
</dc:description>
 <dc:description>Comment: Addressed comments from reviewers (ITP 2015): (1) Added discussion of
  a paper in related work (2) Added definition of renamed-apart in appendix (3)
  Formulation changes in a coupe of places</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2015-06-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08677</identifier>
 <datestamp>2016-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Label-Embedding for Image Classification</dc:title>
 <dc:creator>Akata, Zeynep</dc:creator>
 <dc:creator>Perronnin, Florent</dc:creator>
 <dc:creator>Harchaoui, Zaid</dc:creator>
 <dc:creator>Schmid, Cordelia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Attributes act as intermediate representations that enable parameter sharing
between classes, a must when training data is scarce. We propose to view
attribute-based image classification as a label-embedding problem: each class
is embedded in the space of attribute vectors. We introduce a function that
measures the compatibility between an image and a label embedding. The
parameters of this function are learned on a training set of labeled samples to
ensure that, given an image, the correct classes rank higher than the incorrect
ones. Results on the Animals With Attributes and Caltech-UCSD-Birds datasets
show that the proposed framework outperforms the standard Direct Attribute
Prediction baseline in a zero-shot learning scenario. Label embedding enjoys a
built-in ability to leverage alternative sources of information instead of or
in addition to attributes, such as e.g. class hierarchies or textual
descriptions. Moreover, label embedding encompasses the whole range of learning
settings from zero-shot learning to regular learning with a large number of
labeled examples.
</dc:description>
 <dc:description>Comment: IEEE TPAMI preprint</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2015-10-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08677</dc:identifier>
 <dc:identifier>doi:10.1109/TPAMI.2015.2487986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08682</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Alternative for Traffic Hotspot Localization in Wireless Networks
  Using O&amp;M Metrics</dc:title>
 <dc:creator>Jaziri, Aymen</dc:creator>
 <dc:creator>Nasri, Ridha</dc:creator>
 <dc:creator>Chahed, Tijani</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In recent years, there has been an increasing awareness to traffic
localization techniques driven by the problematic of hotspot offloading
solutions, the emergence of heterogeneous networks (HetNet) with small cells'
deployment and the green networks. The localization of traffic hotspots with a
high accuracy is indeed of great interest to know how the congested zones can
be offloaded, where small cells should be deployed and how they can be managed
for sleep mode concept. We propose, in this paper, a new hotspot localization
technique based on the direct exploitation of five Key Performance Indicators
(KPIs) extracted from the Operation and Maintenance (O&amp;M) database of the
network. These KPIs are the Timing Advance (TA), the angle of arrival (AoA),
the neighboring cell level, the load time and two mean throughputs: arithmetic
(AMT) and harmonic (HMT). The combined use of these KPIs, projected over a
coverage map, yields a promising localization precision and can be further
optimized by exploiting commercial data on potential hotspots. This solution
can be implemented in the network at an appreciable low cost when compared with
widely used probing methods.
</dc:description>
 <dc:description>Comment: Submitted to EURASIP Journal on Wireless Communications and
  Networking (EURASIP JWCN)</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08687</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Performance of Channel Assignments in Wireless Mesh Networks
  through Statistical Interference Estimation</dc:title>
 <dc:creator>Kala, Srikant Manas</dc:creator>
 <dc:creator>Reddy, M. Pavan Kumar</dc:creator>
 <dc:creator>Tamma, Bheemarjuna Reddy</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Wireless Mesh Network (WMN) deployments are poised to reduce the reliance on
wired infrastructure especially with the advent of the multi-radio
multi-channel (MRMC) WMN architecture. But the benefits that MRMC WMNs offer
viz., augmented network capacity, uninterrupted connectivity and reduced
latency, are depreciated by the detrimental effect of prevalent interference.
Interference mitigation is thus a prime objective in WMN deployments. It is
often accomplished through prudent channel allocation (CA) schemes which
minimize the adverse impact of interference and enhance the network
performance. However, a multitude of CA schemes have been proposed in research
literature and absence of a CA performance prediction metric, which could aid
in the selection of an efficient CA scheme for a given WMN, is often felt. In
this work, we offer a fresh characterization of the interference endemic in
wireless networks. We then propose a reliable CA performance prediction metric,
which employs a statistical interference estimation approach. We carry out a
rigorous quantitative assessment of the proposed metric by validating its CA
performance predictions with experimental results, recorded from extensive
simulations run on an ns-3 802.11g environment.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2015-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08687</dc:identifier>
 <dc:identifier>CONECCT 2015, July 2015, 1 - 6</dc:identifier>
 <dc:identifier>doi:10.1109/CONECCT.2015.7383864</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08691</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Channel Estimation in Massive MIMO Systems</dc:title>
 <dc:creator>Neumann, David</dc:creator>
 <dc:creator>Joham, Michael</dc:creator>
 <dc:creator>Utschick, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We introduce novel blind and semi-blind channel estimation methods for
cellular time-division duplexing systems with a large number of antennas at
each base station. The methods are based on the maximum a-posteriori principle
given a prior for the distribution of the channel vectors and the received
signals from the uplink training and data phases. Contrary to the
state-of-the-art massive MIMO channel estimators which either perform linear
estimation based on the pilot symbols or rely on a blind principle, the
proposed semi-blind method efficiently suppresses most of the interference
caused by pilot-contamination. The simulative analysis illustrates that the
semi-blind estimator outperforms state- of-the-art linear and non-linear
approaches to the massive MIMO channel estimation problem.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08691</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08696</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graded quantization for multiple description coding of compressive
  measurements</dc:title>
 <dc:creator>Valsesia, Diego</dc:creator>
 <dc:creator>Coluccia, Giulio</dc:creator>
 <dc:creator>Magli, Enrico</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Compressed sensing (CS) is an emerging paradigm for acquisition of compressed
representations of a sparse signal. Its low complexity is appealing for
resource-constrained scenarios like sensor networks. However, such scenarios
are often coupled with unreliable communication channels and providing robust
transmission of the acquired data to a receiver is an issue. Multiple
description coding (MDC) effectively combats channel losses for systems without
feedback, thus raising the interest in developing MDC methods explicitly
designed for the CS framework, and exploiting its properties. We propose a
method called Graded Quantization (CS-GQ) that leverages the democratic
property of compressive measurements to effectively implement MDC, and we
provide methods to optimize its performance. A novel decoding algorithm based
on the alternating directions method of multipliers is derived to reconstruct
signals from a limited number of received descriptions. Simulations are
performed to assess the performance of CS-GQ against other methods in presence
of packet losses. The proposed method is successful at providing robust coding
of CS measurements and outperforms other schemes for the considered test
metrics.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08696</dc:identifier>
 <dc:identifier>IEEE Transactions on Communications, 2015</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2015.2413405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08715</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Industrial Computing Systems: A Case Study of Fault Tolerance Analysis</dc:title>
 <dc:creator>Shchurov, Andrey A.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Fault tolerance is a key factor of industrial computing systems design. But
in practical terms, these systems, like every commercial product, are under
great financial constraints and they have to remain in operational state as
long as possible due to their commercial attractiveness. This work provides an
analysis of the instantaneous failure rate of these systems at the end of their
life-time period. On the basis of this analysis, we determine the effect of a
critical increase in the system failure rate and the basic condition of its
existence. The next step determines the maintenance scheduling which can help
to avoid this effect and to extend the system life-time in fault-tolerant mode.
</dc:description>
 <dc:description>Comment: 6 figures</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08715</dc:identifier>
 <dc:identifier>International Journal of Computer Trends and Technology (IJCTT)
  V21(1):50-55, March 2015. ISSN:2231-2803</dc:identifier>
 <dc:identifier>doi:10.14445/22312803/IJCTT-V21P110</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08723</identifier>
 <datestamp>2015-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Internet comments as a barometer of public opinion</dc:title>
 <dc:creator>Oster, Elad</dc:creator>
 <dc:creator>Gilad, Erez</dc:creator>
 <dc:creator>Feigel, Alexander</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Social susceptibility is defined and analyzed using data from CNN news
website. The current models of opinion dynamics, voting, and herding in closed
communities are extended, and the community's response to the injection of a
group with predetermined and permanent opinions is calculated. A method to
estimate the values of possible response in Internet communities that follow a
specific developing subject is developed. The level of social influence in a
community follows from the statistics of responses (&quot;like&quot; and &quot;dislike&quot; votes)
to the comments written by the members of the same community. Three real cases
of developing news stories are analyzed. We suggest that Internet comments may
predict the level of social response similar to a barometer that predicts the
intensity of a coming storm in still calm environment.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08723</dc:identifier>
 <dc:identifier>doi:10.1209/0295-5075/111/28005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08726</identifier>
 <datestamp>2015-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Error-Resilient Multicasting for Multi-View 3D Videos in Wireless
  Networks</dc:title>
 <dc:creator>Lin, Chi-Heng</dc:creator>
 <dc:creator>Yang, De-Nian</dc:creator>
 <dc:creator>Lee, Ji-Tang</dc:creator>
 <dc:creator>Liao, Wanjiun</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  With the emergence of naked-eye 3D mobile devices, mobile 3D video services
are becoming increasingly important for video service providers, such as
Youtube and Netflix, while multi-view 3D videos have the potential to inspire a
variety of innovative applications. However, enabling multi-view 3D video
services may overwhelm WiFi networks when every view of a video are
multicasted. In this paper, therefore, we propose to incorporate
depth-image-based rendering (DIBR), which allows each mobile client to
synthesize the desired view from nearby left and right views, in order to
effectively reduce the bandwidth consumption. Moreover, when each client
suffers from packet losses, retransmissions incur additional bandwidth
consumption and excess delay, which in turn undermines the quality of
experience in video applications. To address the above issue, we first discover
the merit of view protection via DIBR for multi-view video multicast using a
mathematical analysis and then design a new protocol, named Multi-View Group
Management Protocol (MVGMP), to support the dynamic join and leave of users and
the change of desired views. The simulation results demonstrate that our
protocol effectively reduces bandwidth consumption and increases the
probability for each client to successfully playback the desired views in a
multi-view 3D video.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1409.8352</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2015-10-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08726</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08744</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Propositional Calculus in Coq</dc:title>
 <dc:creator>van Doorn, Floris</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  I formalize important theorems about classical propositional logic in the
proof assistant Coq. The main theorems I prove are (1) the soundness and
completeness of natural deduction calculus, (2) the equivalence between natural
deduction calculus, Hilbert systems and sequent calculus and (3) cut
elimination for sequent calculus.
</dc:description>
 <dc:description>Comment: 11 pages, project for 2014 Proof Theory class at CMU. Added ancillary
  files (Coq source files) in this version</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08744</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08758</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Demodulate-Forward Relay Protocol for Two-Way Relay Channels</dc:title>
 <dc:creator>Luo, Chunbo</dc:creator>
 <dc:creator>Peoples, Cathryn</dc:creator>
 <dc:creator>Parr, Gerard</dc:creator>
 <dc:creator>McClean, Sally</dc:creator>
 <dc:creator>Wang, Xinheng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Two-Way Relay Channel (TWRC) plays an important role in relay networks, and
efficient relaying protocols are particularly important for this model.
{\color{black} However, existing protocols may not be able to realize the
potential of TWRC if the two independent fading channels are not carefully
handled}. In this paper, a Hybrid DeModulate-Forward (HDMF) protocol is
proposed to address such a problem. {\color{black} We first introduce the two
basic components of HDMF - direct and differential DMF, and then propose the
key decision criterion for HDMF based on the corresponding log-likelihood
ratios. We further enhance the protocol so that it can be applied independently
from the modulation schemes. Through extensive mathematical analysis,
theoretical performance of the proposed protocol is investigated. By comparing
with existing protocols, the proposed HDMF has lower error rate. A novel
scheduling scheme for the proposed protocol is introduced, which has lower
length than the benchmark method. The results also reveal the protocol's
potential to improve spectrum efficiency of relay channels with unbalanced
bilateral traffic.}
</dc:description>
 <dc:description>Comment: 12 pages. 12 figures, Accepted by IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08758</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2015.2419627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08761</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intransitive Linear Temporal Logic, Knowledge from Past, Decidability,
  Admissible Rules</dc:title>
 <dc:creator>Rybakov, Vladimir</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03B70, 03B44, 03B47, 03B42, 03B60</dc:subject>
 <dc:description>  Our manuscript studies linear temporal (with UNTIL and NEXT) logic based at a
conception of intransitive time. non-transitive time. In particular, we
demonstrate how the notion of knowledge might be represented in such a
framework (here we consider logical operation NN and the operation UNTIL
(actually, the time overall) to be directed to past). The basic mathematical
problems we study are the fundamental ones for any logical system
  - decidability and decidability w.r.t. admissible rules. First, we consider
the logic with non-uniform non-transitivity, and describe how to solve the
decidability problem for this logic. Then we consider a modification of this
logic - linear temporal logic with uniform intransitivity and solve the problem
of admissibility for inference rules. A series of open problems is enumerated
in the concluding part of the paper.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1406.2783</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08761</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08768</identifier>
 <datestamp>2016-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Keeping Authorities &quot;Honest or Bust&quot; with Decentralized Witness
  Cosigning</dc:title>
 <dc:creator>Syta, Ewa</dc:creator>
 <dc:creator>Tamas, Iulia</dc:creator>
 <dc:creator>Visher, Dylan</dc:creator>
 <dc:creator>Wolinsky, David Isaac</dc:creator>
 <dc:creator>Jovanovic, Philipp</dc:creator>
 <dc:creator>Gasser, Linus</dc:creator>
 <dc:creator>Gailly, Nicolas</dc:creator>
 <dc:creator>Khoffi, Ismail</dc:creator>
 <dc:creator>Ford, Bryan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The secret keys of critical network authorities - such as time, name,
certificate, and software update services - represent high-value targets for
hackers, criminals, and spy agencies wishing to use these keys secretly to
compromise other hosts. To protect authorities and their clients proactively
from undetected exploits and misuse, we introduce CoSi, a scalable witness
cosigning protocol ensuring that every authoritative statement is validated and
publicly logged by a diverse group of witnesses before any client will accept
it. A statement S collectively signed by W witnesses assures clients that S has
been seen, and not immediately found erroneous, by those W observers. Even if S
is compromised in a fashion not readily detectable by the witnesses, CoSi still
guarantees S's exposure to public scrutiny, forcing secrecy-minded attackers to
risk that the compromise will soon be detected by one of the W witnesses.
Because clients can verify collective signatures efficiently without
communication, CoSi protects clients' privacy, and offers the first
transparency mechanism effective against persistent man-in-the-middle attackers
who control a victim's Internet access, the authority's secret key, and several
witnesses' secret keys. CoSi builds on existing cryptographic multisignature
methods, scaling them to support thousands of witnesses via signature
aggregation over efficient communication trees. A working prototype
demonstrates CoSi in the context of timestamping and logging authorities,
enabling groups of over 8,000 distributed witnesses to cosign authoritative
statements in under two seconds.
</dc:description>
 <dc:description>Comment: 20 pages, 7 figures</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2016-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08768</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08771</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Your Actions Tell Where You Are: Uncovering Twitter Users in a
  Metropolitan Area</dc:title>
 <dc:creator>Zhang, Jinxue</dc:creator>
 <dc:creator>Sun, Jingchao</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:creator>Zhang, Yanchao</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Twitter is an extremely popular social networking platform. Most Twitter
users do not disclose their locations due to privacy concerns. Although
inferring the location of an individual Twitter user has been extensively
studied, it is still missing to effectively find the majority of the users in a
specific geographical area without scanning the whole Twittersphere, and
obtaining these users will result in both positive and negative significance.
In this paper, we propose LocInfer, a novel and lightweight system to tackle
this problem. LocInfer explores the fact that user communications in Twitter
exhibit strong geographic locality, which we validate through large-scale
datasets. Based on the experiments from four representative metropolitan areas
in U.S., LocInfer can discover on average 86.6% of the users with 73.2%
accuracy in each area by only checking a small set of candidate users. We also
present a countermeasure to the users highly sensitive to location privacy and
show its efficacy by simulations.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Conference on Communications and Network Security
  (CNS) 2015</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2015-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08771</dc:identifier>
 <dc:identifier>doi:10.1109/CNS.2015.7346854</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08776</identifier>
 <datestamp>2015-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Preliminary Review of Influential Works in Data-Driven Discovery</dc:title>
 <dc:creator>Stalzer, Mark</dc:creator>
 <dc:creator>Mentzel, Chris</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - General Literature</dc:subject>
 <dc:description>  The Gordon and Betty Moore Foundation ran an Investigator Competition as part
of its Data-Driven Discovery Initiative in 2014. We received about 1,100
applications and each applicant had the opportunity to list up to five
influential works in the general field of &quot;Big Data&quot; for scientific discovery.
We collected nearly 5,000 references and 53 works were cited at least six
times. This paper contains our preliminary findings.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2015-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08776</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08778</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Covert Communication over Noisy Channels: A Resolvability Perspective</dc:title>
 <dc:creator>Bloch, Matthieu R.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the situation in which a transmitter attempts to communicate
reliably over a discrete memoryless channel while simultaneously ensuring
covertness (low probability of detection) with respect to a warden, who
observes the signals through another discrete memoryless channel. We develop a
coding scheme based on the principle of channel resolvability, which
generalizes and extends prior work in several directions. First, it shows that,
irrespective of the quality of the channels, it is possible to communicate on
the order of $\sqrt{n}$ reliable and covert bits over $n$ channel uses if the
transmitter and the receiver share on the order of $\sqrt{n}$ key bits; this
improves upon earlier results requiring on the order of $\sqrt{n}\log n$ key
bits. Second, it proves that, if the receiver's channel is &quot;better&quot; than the
warden's channel in a sense that we make precise, it is possible to communicate
on the order of $\sqrt{n}$ reliable and covert bits over $n$ channel uses
without a secret key; this generalizes earlier results established for binary
symmetric channels. We also identify the fundamental limits of covert and
secret communications in terms of the optimal asymptotic scaling of the message
size and key size, and we extend the analysis to Gaussian channels. The main
technical problem that we address is how to develop concentration inequalities
for &quot;low-weight&quot; sequences; the crux of our approach is to define suitably
modified typical sets that are amenable to concentration inequalities.
</dc:description>
 <dc:description>Comment: 30 pages, 4 figures, accepted to IEEE Transactions on Information
  Theory</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08778</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2016.2530089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08782</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Recovery of Positive Stream of Pulses</dc:title>
 <dc:creator>Bendory, Tamir</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The problem of estimating the delays and amplitudes of a positive stream of
pulses appears in many applications, such as single-molecule microscopy. This
paper suggests estimating the delays and amplitudes using a convex program,
which is robust in the presence of noise (or model mismatch). Particularly, the
recovery error is proportional to the noise level. We further show that the
error grows exponentially with the density of the delays and also depends on
the localization properties of the pulse.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2017-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08782</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08792</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graphs Identified by Logics with Counting</dc:title>
 <dc:creator>Kiefer, Sandra</dc:creator>
 <dc:creator>Schweitzer, Pascal</dc:creator>
 <dc:creator>Selman, Erkal</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>68Q19, 03C13, 05C75, 68R10</dc:subject>
 <dc:description>  We classify graphs and, more generally, finite relational structures that are
identified by C2, that is, two-variable first-order logic with counting. Using
this classification, we show that it can be decided in almost linear time
whether a structure is identified by C2. Our classification implies that for
every graph identified by this logic, all vertex-colored versions of it are
also identified. A similar statement is true for finite relational structures.
  We provide constructions that solve the inversion problem for finite
structures in linear time. This problem has previously been shown to be
polynomial time solvable by Martin Otto. For graphs, we conclude that every
C2-equivalence class contains a graph whose orbits are exactly the classes of
the C2-partition of its vertex set and which has a single automorphism
witnessing this fact.
  For general k, we show that such statements are not true by providing
examples of graphs of size linear in k which are identified by C3 but for which
the orbit partition is strictly finer than the Ck-partition. We also provide
identified graphs which have vertex-colored versions that are not identified by
Ck.
</dc:description>
 <dc:description>Comment: 33 pages, 8 Figures</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08796</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Logarithmic Additive Integrality Gap for Bin Packing</dc:title>
 <dc:creator>Hoberg, Rebecca</dc:creator>
 <dc:creator>Rothvoss, Thomas</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  For bin packing, the input consists of $n$ items with sizes $s_1,...,s_n \in
[0,1]$ which have to be assigned to a minimum number of bins of size 1.
Recently, the second author gave an LP-based polynomial time algorithm that
employed techniques from discrepancy theory to find a solution using at most
$OPT + O(\log OPT \cdot \log \log OPT)$ bins.
  In this paper, we present an approximation algorithm that has an additive gap
of only $O(\log OPT)$ bins, which matches certain combinatorial lower bounds.
Any further improvement would have to use more algebraic structure. Our
improvement is based on a combination of discrepancy theory techniques and a
novel 2-stage packing: first we pack items into containers; then we pack
containers into bins of size 1. Apart from being more effective, we believe our
algorithm is much cleaner than the one of Rothvoss.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08796</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08804</identifier>
 <datestamp>2015-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random Sampling in Computational Algebra: Helly Numbers and Violator
  Spaces</dc:title>
 <dc:creator>De Loera, Jes&#xfa;s A.</dc:creator>
 <dc:creator>Petrovi&#x107;, Sonja</dc:creator>
 <dc:creator>Stasi, Despina</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Commutative Algebra</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  This paper transfers a randomized algorithm, originally used in geometric
optimization, to computational problems in commutative algebra. We show that
Clarkson's sampling algorithm can be applied to two problems in computational
algebra: solving large-scale polynomial systems and finding small generating
sets of graded ideals. The cornerstone of our work is showing that the theory
of violator spaces of G\&quot;artner et al.\ applies to polynomial ideal problems.
To show this, one utilizes a Helly-type result for algebraic varieties. The
resulting algorithms have expected runtime linear in the number of input
polynomials, making the ideas interesting for handling systems with very large
numbers of polynomials, but whose rank in the vector space of polynomials is
small (e.g., when the number of variables and degree is constant).
</dc:description>
 <dc:description>Comment: Minor edits, added two references; results unchanged</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2015-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08804</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08809</identifier>
 <datestamp>2016-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Separable projection integrals for higher-order correlators of the
  cosmic microwave sky: Acceleration by factors exceeding 100</dc:title>
 <dc:creator>Briggs, J. P.</dc:creator>
 <dc:creator>Pennycook, S. J.</dc:creator>
 <dc:creator>Fergusson, J. R.</dc:creator>
 <dc:creator>J&#xe4;ykk&#xe4;, J.</dc:creator>
 <dc:creator>Shellard, E. P. S.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Astrophysics - Cosmology and Nongalactic Astrophysics</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  We present a case study describing efforts to optimise and modernise &quot;Modal&quot;,
the simulation and analysis pipeline used by the Planck satellite experiment
for constraining general non-Gaussian models of the early universe via the
bispectrum (or three-point correlator) of the cosmic microwave background
radiation. We focus on one particular element of the code: the projection of
bispectra from the end of inflation to the spherical shell at decoupling, which
defines the CMB we observe today. This code involves a three-dimensional inner
product between two functions, one of which requires an integral, on a
non-rectangular domain containing a sparse grid. We show that by employing
separable methods this calculation can be reduced to a one-dimensional
summation plus two integrations, reducing the overall dimensionality from four
to three. The introduction of separable functions also solves the issue of the
non-rectangular sparse grid. This separable method can become unstable in
certain cases and so the slower non-separable integral must be calculated
instead. We present a discussion of the optimisation of both approaches. We
show significant speed-ups of ~100x, arising from a combination of algorithmic
improvements and architecture-aware optimisations targeted at improving thread
and vectorisation behaviour. The resulting MPI/OpenMP hybrid code is capable of
executing on clusters containing processors and/or coprocessors, with
strong-scaling efficiency of 98.6% on up to 16 nodes. We find that a single
coprocessor outperforms two processor sockets by a factor of 1.3x and that
running the same code across a combination of both microarchitectures improves
performance-per-node by a factor of 3.38x. By making bispectrum calculations
competitive with those for the power spectrum (or two-point correlator) we are
now able to consider joint analysis for cosmological science exploitation of
new data.
</dc:description>
 <dc:description>Comment: Accepted by Journal of Computational Physics</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2016-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08809</dc:identifier>
 <dc:identifier>doi:10.1016/j.jcp.2016.01.019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08810</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A probabilistic version of the game of Zombies and Survivors on graphs</dc:title>
 <dc:creator>Bonato, Anthony</dc:creator>
 <dc:creator>Mitsche, Dieter</dc:creator>
 <dc:creator>P&#xe9;rez-Gim&#xe9;nez, Xavier</dc:creator>
 <dc:creator>Pra&#x142;at, Pawe&#x142;</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>(Primary) 05C57, (Secondary) 05C80</dc:subject>
 <dc:description>  We consider a new probabilistic graph searching game played on graphs,
inspired by the familiar game of Cops and Robbers. In Zombies and Survivors, a
set of zombies attempts to eat a lone survivor loose on a given graph. The
zombies randomly choose their initial location, and during the course of the
game, move directly toward the survivor. At each round, they move to the
neighbouring vertex that minimizes the distance to the survivor; if there is
more than one such vertex, then they choose one uniformly at random. The
survivor attempts to escape from the zombies by moving to a neighbouring vertex
or staying on his current vertex. The zombies win if eventually one of them
eats the survivor by landing on their vertex; otherwise, the survivor wins. The
zombie number of a graph is the minimum number of zombies needed to play such
that the probability that they win is strictly greater than 1/2. We present
asymptotic results for the zombie numbers of several graph families, such as
cycles, hypercubes, incidence graphs of projective planes, and Cartesian and
toroidal grids.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08818</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Founding Digital Currency on Imprecise Commodity</dc:title>
 <dc:creator>Yuan, Zimu</dc:creator>
 <dc:creator>Xu, Zhiwei</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Current digital currency schemes provide instantaneous exchange on precise
commodity, in which &quot;precise&quot; means a buyer can possibly verify the function of
the commodity without error. However, imprecise commodities, e.g. statistical
data, with error existing are abundant in digital world. Existing digital
currency schemes do not offer a mechanism to help the buyer for payment
decision on precision of commodity, which may lead the buyer to a dilemma
between having to buy and being unconfident. In this paper, we design a
currency schemes IDCS for imprecise digital commodity. IDCS completes a trade
in three stages of handshake between a buyer and providers. We present an IDCS
prototype implementation that assigns weights on the trustworthy of the
providers, and calculates a confidence level for the buyer to decide the
quality of a imprecise commodity. In experiment, we characterize the
performance of IDCS prototype under varying impact factors.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1503.08407</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08818</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08819</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FPGA based High Speed Data Acquisition System for High Energy Physics
  Application</dc:title>
 <dc:creator>Mandal, Swagata</dc:creator>
 <dc:creator>Sau, Suman</dc:creator>
 <dc:creator>Chakrabarti, Amlan</dc:creator>
 <dc:creator>Chattopadhyay, Subhasis</dc:creator>
 <dc:subject>Physics - Instrumentation and Detectors</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>High Energy Physics - Experiment</dc:subject>
 <dc:description>  In high energy physics experiments (HEP), high speed and fault resilient data
communication is needed between detectors/sensors and the host PC. Transient
faults can occur in the communication hardware due to various external effects
like presence of charged particles, noise in the environment or radiation
effects in HEP experiments and that leads to single/multiple bit error. In
order to keep the communication system functional in such a radiation
environment where direct intervention of human is not possible, a high speed
data acquisition (DAQ) architecture is necessary which supports error recovery.
This design presents an efficient implementation of field programmable gate
array (FPGA) based high speed DAQ system with optical communication link
supported by multi-bit error correcting model. The design has been implemented
on Xilinx Kintex-7 board and is tested for board to board communication as well
as for PC communication using PCI (Peripheral Component Interconnect express).
Data communication speed up to 4.8 Gbps has been achieved in board to board and
board to PC communication and estimation of resource utilization and critical
path delay are also measured.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08843</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Globally Tuned Cascade Pose Regression via Back Propagation with
  Application in 2D Face Pose Estimation and Heart Segmentation in 3D CT Images</dc:title>
 <dc:creator>Sun, Peng</dc:creator>
 <dc:creator>Min, James K.</dc:creator>
 <dc:creator>Xiong, Guanglei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, a successful pose estimation algorithm, called Cascade Pose
Regression (CPR), was proposed in the literature. Trained over Pose Index
Feature, CPR is a regressor ensemble that is similar to Boosting. In this paper
we show how CPR can be represented as a Neural Network. Specifically, we adopt
a Graph Transformer Network (GTN) representation and accordingly train CPR with
Back Propagation (BP) that permits globally tuning. In contrast, previous CPR
literature only took a layer wise training without any post fine tuning. We
empirically show that global training with BP outperforms layer-wise
(pre-)training. Our CPR-GTN adopts a Multi Layer Percetron as the regressor,
which utilized sparse connection to learn local image feature representation.
We tested the proposed CPR-GTN on 2D face pose estimation problem as in
previous CPR literature. Besides, we also investigated the possibility of
extending CPR-GTN to 3D pose estimation by doing experiments using 3D Computed
Tomography dataset for heart segmentation.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08843</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08847</identifier>
 <datestamp>2015-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Sizes of DPDAs, PDAs, LBAs</dc:title>
 <dc:creator>Beigel, Richard</dc:creator>
 <dc:creator>Gasarch, William</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:description>  There are languages A such that there is a Pushdown Automata (PDA) that
recognizes A which is much smaller than any Deterministic Pushdown Automata
(DPDA) that recognizes A. There are languages A such that there is a Linear
Bounded Automata (Linear Space Turing Machine, henceforth LBA) that recognizes
A which is much smaller than ny PDA that recognizes A. There are languages A
such that both A and compliment(A) are recognizable by a PDA, but the PDA for A
is much smaller than the PDA for compliment(A). There are languages A1, A2 such
that A1,A2,A1 INTERSECT A_2 are recognizable by a PDA, but the PDA for A1 and
A2 are much smaller than the PDA for A1 INTERSECT A2. We investigate these
phenomenon and show that, in all these cases, the size difference is captured
by a function whose Turing degree is on the second level of the arithmetic
hierarchy.
  Our theorems lead to infinitely-often results. For example: for infinitely
many $n$ there exists a language An recognized by a DPDA such that there is a
small PDA for An, but any DPDA for An is large. We look at cases where we can
get almost-all results, though with much smaller size differences.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2015-07-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08847</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08853</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reconciling saliency and object center-bias hypotheses in explaining
  free-viewing fixations</dc:title>
 <dc:creator>Borji, Ali</dc:creator>
 <dc:creator>Tanner, James</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Predicting where people look in natural scenes has attracted a lot of
interest in computer vision and computational neuroscience over the past two
decades. Two seemingly contrasting categories of cues have been proposed to
influence where people look: \textit{low-level image saliency} and
\textit{high-level semantic information}. Our first contribution is to take a
detailed look at these cues to confirm the hypothesis proposed by
Henderson~\cite{henderson1993eye} and Nuthmann \&amp;
Henderson~\cite{nuthmann2010object} that observers tend to look at the center
of objects. We analyzed fixation data for scene free-viewing over 17 observers
on 60 fully annotated images with various types of objects. Images contained
different types of scenes, such as natural scenes, line drawings, and 3D
rendered scenes. Our second contribution is to propose a simple combined model
of low-level saliency and object center-bias that outperforms each individual
component significantly over our data, as well as on the OSIE dataset by Xu et
al.~\cite{xu2014predicting}. The results reconcile saliency with object
center-bias hypotheses and highlight that both types of cues are important in
guiding fixations. Our work opens new directions to understand strategies that
humans use in observing scenes and objects, and demonstrates the construction
of combined models of low-level saliency and high-level object-based
information.
</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08855</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decentralized learning for wireless communications and networking</dc:title>
 <dc:creator>Giannakis, Georgios B.</dc:creator>
 <dc:creator>Ling, Qing</dc:creator>
 <dc:creator>Mateos, Gonzalo</dc:creator>
 <dc:creator>Schizas, Ioannis D.</dc:creator>
 <dc:creator>Zhu, Hao</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This chapter deals with decentralized learning algorithms for in-network
processing of graph-valued data. A generic learning problem is formulated and
recast into a separable form, which is iteratively minimized using the
alternating-direction method of multipliers (ADMM) so as to gain the desired
degree of parallelization. Without exchanging elements from the distributed
training sets and keeping inter-node communications at affordable levels, the
local (per-node) learners consent to the desired quantity inferred globally,
meaning the one obtained if the entire training data set were centrally
available. Impact of the decentralized learning framework to contemporary
wireless communications and networking tasks is illustrated through case
studies including target tracking using wireless sensor networks, unveiling
Internet traffic anomalies, power system state estimation, as well as spectrum
cartography for wireless cognitive radio networks.
</dc:description>
 <dc:description>Comment: Contributed chapter to appear in Splitting Methods in Communication
  and Imaging, Science and Engineering, R. Glowinski, S. Osher, and W. Yin,
  Editors, New York, Springer, 2015</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08866</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Data-Driven Hierarchical Surgical Skill Analysis</dc:title>
 <dc:creator>Li, Bin</dc:creator>
 <dc:creator>Mettler, Berenice</dc:creator>
 <dc:creator>Kowalewski, Timonthy M.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  This paper evaluates methods of hierarchical skill analysis developed in
aerospace to the problem of surgical skill assessment and modeling. The
analysis employs tool motion data of Fundamental of Laparoscopic Skills (FLS)
tasks collected from clinicians of various skill levels at three different
clinical teaching hospitals in the United States. Outcomes are evaluated based
on their ability to provide relevant information about the underlying processes
across the entire system hierarchy including control, guidance and planning.
</dc:description>
 <dc:description>Comment: M2CAI 2014</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08873</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Label Embeddings for Extremely Large Output Spaces</dc:title>
 <dc:creator>Mineiro, Paul</dc:creator>
 <dc:creator>Karampatziakis, Nikos</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Many modern multiclass and multilabel problems are characterized by
increasingly large output spaces. For these problems, label embeddings have
been shown to be a useful primitive that can improve computational and
statistical efficiency. In this work we utilize a correspondence between rank
constrained estimation and low dimensional label embeddings that uncovers a
fast label embedding algorithm which works in both the multiclass and
multilabel settings. The result is a randomized algorithm for partial least
squares, whose running time is exponentially faster than naive algorithms. We
demonstrate our techniques on two large-scale public datasets, from the Large
Scale Hierarchical Text Challenge and the Open Directory Project, where we
obtain state of the art results.
</dc:description>
 <dc:description>Comment: Accepted as a workshop contribution at ICLR 2015</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08873</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08877</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Falkirk Wheel: Rollback Recovery for Dataflow Systems</dc:title>
 <dc:creator>Isard, Michael</dc:creator>
 <dc:creator>Abadi, Mart&#xed;n</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We present a new model for rollback recovery in distributed dataflow systems.
We explain existing rollback schemes by assigning a logical time to each event
such as a message delivery. If some processors fail during an execution, the
system rolls back by selecting a set of logical times for each processor. The
effect of events at times within the set is retained or restored from saved
state, while the effect of other events is undone and re-executed. We show
that, by adopting different logical time &quot;domains&quot; at different processors, an
application can adopt appropriate checkpointing schemes for different parts of
its computation. We illustrate with an example of an application that combines
batch processing with low-latency streaming updates. We show rules, and an
algorithm, to determine a globally consistent state for rollback in a system
that uses multiple logical time domains. We also introduce selective rollback
at a processor, which can selectively preserve the effect of events at some
logical times and not others, independent of the original order of execution of
those events. Selective rollback permits new checkpointing policies that are
particularly well suited to iterative streaming algorithms. We report on an
implementation of our new framework in the context of the Naiad system.
</dc:description>
 <dc:description>Comment: DRAFT work in progress</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08877</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08880</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A composite constraints approach to declarative agent-based modeling</dc:title>
 <dc:creator>Borenstein, David Bruce</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>I.6.8</dc:subject>
 <dc:subject>I.6.2</dc:subject>
 <dc:description>  Agent-based models (ABMs) are ubiquitous in research and industry. Currently,
simulating ABMs involves at least some imperative (step-by-step) computer
instructions. An alternative approach is declarative programming, in which a
set of requirements is described at a high level of abstraction. Here we
describe a fully declarative approach to the automated construction of
simulations for ABMs. In this framework, logic for ABM simulations is
encapsulated into predefined components. The user specifies a set of
requirements describing the desired functionality. Additionally, each component
has a set of consistency requirements. The framework iteratively seeks a
simulation design that satisfies both user and system requirements. This
approach allows the user to omit most details from the simulation
specification, simplifying simulation design.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08880</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08889</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interference Prediction in Mobile Ad Hoc Networks with a General
  Mobility Model</dc:title>
 <dc:creator>Cong, Yirui</dc:creator>
 <dc:creator>Zhou, Xiangyun</dc:creator>
 <dc:creator>Kennedy, Rodney A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In a mobile ad hoc network (MANET), effective prediction of time-varying
interferences can enable adaptive transmission designs and therefore improve
the communication performance. This paper investigates interference prediction
in MANETs with a finite number of nodes by proposing and using a general-order
linear model for node mobility. The proposed mobility model can well
approximate node dynamics of practical MANETs. In contrast to previous studies
on interference statistics, we are able through this model to give a best
estimate of the time-varying interference at any time rather than long-term
average effects. Specifically, we propose a compound Gaussian point process
functional as a general framework to obtain analytical results on the mean
value and moment-generating function of the interference prediction. With a
series form of this functional, we give the necessary and sufficient condition
for when the prediction is essentially equivalent to that from a Binomial Point
Process (BPP) network in the limit as time goes to infinity. These conditions
permit one to rigorously determine when the commonly used BPP approximations
are valid. Finally, our simulation results corroborate the effectiveness and
accuracy of the analytical results on interference prediction and also show the
advantages of our method in dealing with complex mobilities.
</dc:description>
 <dc:description>Comment: 14 pages, 9 figures, accepted for publication in IEEE Transactions on
  Wireless Communications</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08889</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2015.2418763</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08895</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-To-End Memory Networks</dc:title>
 <dc:creator>Sukhbaatar, Sainbayar</dc:creator>
 <dc:creator>Szlam, Arthur</dc:creator>
 <dc:creator>Weston, Jason</dc:creator>
 <dc:creator>Fergus, Rob</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We introduce a neural network with a recurrent attention model over a
possibly large external memory. The architecture is a form of Memory Network
(Weston et al., 2015) but unlike the model in that work, it is trained
end-to-end, and hence requires significantly less supervision during training,
making it more generally applicable in realistic settings. It can also be seen
as an extension of RNNsearch to the case where multiple computational steps
(hops) are performed per output symbol. The flexibility of the model allows us
to apply it to tasks as diverse as (synthetic) question answering and to
language modeling. For the former our approach is competitive with Memory
Networks, but with less supervision. For the latter, on the Penn TreeBank and
Text8 datasets our approach demonstrates comparable performance to RNNs and
LSTMs. In both cases we show that the key concept of multiple computational
hops yields improved results.
</dc:description>
 <dc:description>Comment: Accepted to NIPS 2015</dc:description>
 <dc:date>2015-03-30</dc:date>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08909</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Short Snippets: Deep Networks for Video Classification</dc:title>
 <dc:creator>Ng, Joe Yue-Hei</dc:creator>
 <dc:creator>Hausknecht, Matthew</dc:creator>
 <dc:creator>Vijayanarasimhan, Sudheendra</dc:creator>
 <dc:creator>Vinyals, Oriol</dc:creator>
 <dc:creator>Monga, Rajat</dc:creator>
 <dc:creator>Toderici, George</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural networks (CNNs) have been extensively applied for image
recognition problems giving state-of-the-art results on recognition, detection,
segmentation and retrieval. In this work we propose and evaluate several deep
neural network architectures to combine image information across a video over
longer time periods than previously attempted. We propose two methods capable
of handling full length videos. The first method explores various convolutional
temporal feature pooling architectures, examining the various design choices
which need to be made when adapting a CNN for this task. The second proposed
method explicitly models the video as an ordered sequence of frames. For this
purpose we employ a recurrent neural network that uses Long Short-Term Memory
(LSTM) cells which are connected to the output of the underlying CNN. Our best
networks exhibit significant performance improvements over previously published
results on the Sports 1 million dataset (73.1% vs. 60.9%) and the UCF-101
datasets with (88.6% vs. 88.0%) and without additional optical flow information
(82.6% vs. 72.8%).
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08909</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08913</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decoding LDPC codes via Noisy Gradient Descent Bit-Flipping with
  Re-Decoding</dc:title>
 <dc:creator>Tithi, Tasnuva</dc:creator>
 <dc:creator>Winstead, Chris</dc:creator>
 <dc:creator>Sundararajan, Gopalakrishnan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider the performance of the Noisy Gradient Descent Bit
Flipping (NGDBF) algorithm under re-decoding of failed frames. NGDBF is a
recent algorithm that uses a non-deterministic gradient descent search to
decode low-density parity check (LDPC) codes. The proposed re-decode procedure
obtains improved performance because the perturbations are independent at each
re-decoding phase, therefore increasing the likelihood of successful decoding.
We examine the benefits of re-decoding for an LDPC code from the IEEE 802.3an
standard, and find that only a small fraction of re-decoded frames are needed
to obtain significant performance benefits. When re-decoding is used, the NGDBF
performance is very close to a benchmark offset min-sum decoder for the 802.3an
code.
</dc:description>
 <dc:description>Comment: 4 pages, 8 figures</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08913</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08925</identifier>
 <datestamp>2017-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometry of Interaction for MALL via Hughes-vanGlabbeek Proof-Nets</dc:title>
 <dc:creator>Hamano, Masahiro</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  This paper presents, for the first time, a Geometry of Interaction (GoI)
interpretation using Hughes-vanGlabbeek (HvG) proof-nets for multiplicative
additive linear logic (MALL). Our GoI captures dynamically HvG's geometric
correctness criterion --the toggling cycle condition--in terms of algebraic
operators. Our new ingredient is a scalar extension of the *-algebra in
Girard's *-ring of partial isometries over a boolean polynomial ring with
literals of eigenweights as indeterminates. In order to capture feedback
arising from cuts, we construct a finer grained execution formula. The
expansion of this execution formula is longer than that for collections of
slices for multiplicative GoI, hence is harder to prove termination. Our GoI
gives a dynamical, semantical account of boolean valuations (in particular,
pruning sub-proofs), conversion of weights (in particular, alpha-conversion),
and additive (co)contraction, peculiar to additive proof-theory. Termination of
our execution formula is shown to correspond to HvG's toggling criterion. The
slice-wise restriction of our execution formula (by collapsing the boolean
structure) yields the well known correspondence, explicit or implicit in
previous works on multiplicative GoI, between the convergence of execution
formulas and acyclicity of proof-nets. Feedback arising from the execution
formula by restricting to the boolean polynomial structure yields autonomous
definability of eigenweights among cuts from the rest of the eigenweights.
</dc:description>
 <dc:description>Comment: 30 pages</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2017-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08925</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08928</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-Optimal Modulo-and-Forward Scheme for the Untrusted Relay Channel</dc:title>
 <dc:creator>Zhang, Shengli</dc:creator>
 <dc:creator>Fan, Lisheng</dc:creator>
 <dc:creator>Peng, Mugen</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies an untrusted relay channel, in which the destination sends
artificial noise simultaneously with the source sending a message to the relay,
in order to protect the source's confidential message. The traditional
amplify-and-forward (AF) scheme shows poor performance in this situation
because of the interference power dilemma: providing better security by using
stronger artificial noise will decrease the confidential message power from the
relay to the destination. To solve this problem, a modulo-and-forward (MF)
operation at the relay with nested lattice encoding at the source is proposed.
For this system with full channel state information at the transmitter (CSIT),
theoretical analysis shows that the proposed MF scheme approaches the secrecy
capacity within 1/2 bit for any channel realization, and hence achieves full
generalized security degrees of freedom (G-SDoF). In contrast, the AF scheme
can only achieve a small fraction of the G-SDoF. For this system without any
CSIT, the total outage event, defined as either connection outage or secrecy
outage, is introduced. Based on this total outage definition, analysis shows
that the proposed MF scheme achieves the full generalized secure diversity gain
(G-SDG) of order one. On the other hand, the AF scheme can only achieve a G-SDG
of 1/2 at most.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08934</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Index ARQ Protocol for Reliable Contents Distribution over Broadcast
  Channels</dc:title>
 <dc:creator>Oshima, Takahiro</dc:creator>
 <dc:creator>Wadayama, Tadashi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In the present paper, we propose a broadcast ARQ protocol based on the
concept of index coding. In the proposed scenario, a server wishes to transmit
a finite sequence of packets to multiple receivers via a broadcast channel with
packet erasures until all of the receivers successfully receive all of the
packets. In the retransmission phase, the server produces a coded packet as a
retransmitted packet based on the side-information sent from the receivers via
feedback channels. A notable feature of the proposed protocol is that the
decoding process at the receiver side has low decoding complexity because only
a small number of addition operations are needed in order to recover an
intended packet. This feature may be preferable for reducing the power
consumption of receivers. The throughput performance of the proposed protocol
is close to that of the ideal FEC throughput performance when the erasure
probability is less than $0.1$. This implies that the proposed protocol
provides almost optimal throughput performance in such a regime.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08936</identifier>
 <datestamp>2016-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A model-theoretic characterization of monadic second order logic on
  infinite words</dc:title>
 <dc:creator>Ghilardi, Silvio</dc:creator>
 <dc:creator>van Gool, Samuel J.</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Monadic second order logic and linear temporal logic are two logical
formalisms that can be used to describe classes of infinite words, i.e.,
first-order models based on the natural numbers with order, successor, and
finitely many unary predicate symbols.
  Monadic second order logic over infinite words (S1S) can alternatively be
described as a first-order logic interpreted in $\mathcal{P}(\omega)$, the
power set Boolean algebra of the natural numbers, equipped with modal operators
for 'initial', 'next' and 'future' states. We prove that the first-order theory
of this structure is the model companion of a class of algebras corresponding
to the appropriate version of linear temporal logic (LTL) without until.
  The proof makes crucial use of two classical, non-trivial results from the
literature, namely the completeness of LTL with respect to the natural numbers,
and the correspondence between S1S-formulas and B\&quot;uchi automata.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2016-04-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08936</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08937</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of Symmetric Mutual Information of the Simplified TDMR
  Channel Model</dc:title>
 <dc:creator>Wadayama, Tadashi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In the present paper, a simplified two-dimensional magnetic recording (TDMR)
channel model is proposed in order to capture the qualitative features of
writing and read-back processes of TDMR systems.The proposed channel model
incorporates the effects of both linear interference from adjacent bit-cells
and signal-dependent noise due to irregular grain boundaries between adjacent
bit-cells. The simplicity of the proposed model enables us to derive the closed
form of the conditional PDF representing the probabilistic nature of the
channel. The conditional PDF is Gaussian distributed and is parameterized by a
signal-dependent covariance matrix. Based on this conditional PDF, a Monte
Carlo method for approximating the symmetric mutual information of this channel
is developed. The symmetric mutual information is closely related to the areal
density limit for TDMR systems. The numerical results suggest that we may need
low-rate coding, e.g., 2/3 or 1/2, when the jitter-like noise becomes dominant.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08937</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08944</identifier>
 <datestamp>2015-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Normalization of Occurrence and Co-occurrence Matrices in
  Bibliometrics using Cosine Similarities and Ochiai Coefficients</dc:title>
 <dc:creator>Zhou, Qiuju</dc:creator>
 <dc:creator>Leydesdorff, Loet</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  We prove that Ochiai similarity of the co-occurrence matrix is equal to
cosine similarity in the underlying occurrence matrix. Neither the cosine nor
the Pearson correlation should be used for the normalization of co-occurrence
matrices because the similarity is then normalized twice, and therefore
over-estimated; the Ochiai coefficient can be used instead. Results are shown
using a small matrix (5 cases, 4 variables) for didactic reasons, and also
Ahlgren et al.'s (2003) co-occurrence matrix of 24 authors in library and
information sciences. The over-estimation is shown numerically and will be
illustrated using multidimensional scaling and cluster dendograms. If the
occurrence matrix is not available (such as in internet research or author
co-citation analysis) using Ochiai for the normalization is preferable to using
the cosine.
</dc:description>
 <dc:description>Comment: accepted for publication in the Journal of the Association for
  Information Science and Technology (JASIST)</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2015-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08944</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08945</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of Energy-Detection-Based Massive SIMO</dc:title>
 <dc:creator>Hammouda, Marwan</dc:creator>
 <dc:creator>Akin, Sami</dc:creator>
 <dc:creator>Peissig, J&#xfc;rgen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Recently, communications systems that are both energy efficient and reliable
are under investigation. In this paper, we concentrate on an
energy-detection-based transmission scheme where a communication scenario
between a transmitter with one antenna and a receiver with significantly many
antennas is considered. We assume that the receiver initially calculates the
average energy across all antennas, and then decodes the transmitted data by
exploiting the average energy level. Then, we calculate the average symbol
error probability by means of a maximum a-posteriori probability detector at
the receiver. Following that, we provide the optimal decision regions.
Furthermore, we develop an iterative algorithm that reaches the optimal
constellation diagram under a given average transmit power constraint. Through
numerical analysis, we explore the system performance.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08946</identifier>
 <datestamp>2015-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Workload-Driven Vertical Partitioning for Effective Query Processing
  over Raw Data</dc:title>
 <dc:creator>Zhao, Weijie</dc:creator>
 <dc:creator>Cheng, Yu</dc:creator>
 <dc:creator>Rusu, Florin</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Traditional databases are not equipped with the adequate functionality to
handle the volume and variety of &quot;Big Data&quot;. Strict schema definition and data
loading are prerequisites even for the most primitive query session. Raw data
processing has been proposed as a schema-on-demand alternative that provides
instant access to the data. When loading is an option, it is driven exclusively
by the current-running query, resulting in sub-optimal performance across a
query workload. In this paper, we investigate the problem of workload-driven
raw data processing with partial loading. We model loading as fully-replicated
binary vertical partitioning. We provide a linear mixed integer programming
optimization formulation that we prove to be NP-hard. We design a two-stage
heuristic that comes within close range of the optimal solution in a fraction
of the time. We extend the optimization formulation and the heuristic to
pipelined raw data processing, scenario in which data access and extraction are
executed concurrently. We provide three case-studies over real data formats
that confirm the accuracy of the model when implemented in a state-of-the-art
pipelined operator for raw data processing.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2015-05-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08992</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid spreading mechanisms and T cell activation shape the dynamics of
  HIV-1 infection</dc:title>
 <dc:creator>Zhang, Changwang</dc:creator>
 <dc:creator>Zhou, Shi</dc:creator>
 <dc:creator>Groppelli, Elisabetta</dc:creator>
 <dc:creator>Pellegrino, Pierre</dc:creator>
 <dc:creator>Williams, Ian</dc:creator>
 <dc:creator>Borrow, Persephone</dc:creator>
 <dc:creator>Chain, Benjamin M.</dc:creator>
 <dc:creator>Jolly, Clare</dc:creator>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Biological Physics</dc:subject>
 <dc:subject>Quantitative Biology - Cell Behavior</dc:subject>
 <dc:description>  HIV-1 can disseminate between susceptible cells by two mechanisms: cell-free
infection following fluid-phase diffusion of virions and by highly-efficient
direct cell-to-cell transmission at immune cell contacts. The contribution of
this hybrid spreading mechanism, which is also a characteristic of some
important computer worm outbreaks, to HIV-1 progression in vivo remains
unknown. Here we present a new mathematical model that explicitly incorporates
the ability of HIV-1 to use hybrid spreading mechanisms and evaluate the
consequences for HIV-1 pathogenenesis. The model captures the major phases of
the HIV-1 infection course of a cohort of treatment naive patients and also
accurately predicts the results of the Short Pulse Anti-Retroviral Therapy at
Seroconversion (SPARTAC) trial. Using this model we find that hybrid spreading
is critical to seed and establish infection, and that cell-to-cell spread and
increased CD4+ T cell activation are important for HIV-1 progression. Notably,
the model predicts that cell-to-cell spread becomes increasingly effective as
infection progresses and thus may present a considerable treatment barrier.
Deriving predictions of various treatments' influence on HIV-1 progression
highlights the importance of earlier intervention and suggests that treatments
effectively targeting cell-to-cell HIV-1 spread can delay progression to AIDS.
This study suggests that hybrid spreading is a fundamental feature of HIV
infection, and provides the mathematical framework incorporating this feature
with which to evaluate future therapeutic strategies.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08992</dc:identifier>
 <dc:identifier>PLOS Computational Biology. 2015 Apr 2;11(4):e1004179</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pcbi.1004179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.08994</identifier>
 <datestamp>2015-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Resource Allocation with Joint Carrier Aggregation for
  Multi-Carrier Cellular Networks</dc:title>
 <dc:creator>Shajaiah, Haya</dc:creator>
 <dc:creator>Abdelhadi, Ahmed</dc:creator>
 <dc:creator>Clancy, T. Charles</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, we present a novel approach for robust optimal resource
allocation with joint carrier aggregation to allocate multiple carriers
resources optimally among users with elastic and inelastic traffic in cellular
networks. We use utility proportional fairness allocation policy, where the
fairness among users is in utility percentage of the application running on the
user equipment (UE). Each UE is assigned an application utility function based
on the type of its application. Our objective is to allocate multiple carriers
resources optimally among users subscribing for mobile services. In addition,
each user is guaranteed a minimum quality of service (QoS) that varies based on
the user's application type. We present a robust algorithm that solves the
drawback in the algorithm presented in [1] by preventing the fluctuations in
the resource allocation process, in the case of scarce resources, and allocates
optimal rates for both high-traffic and low-traffic situations. Our distributed
resource allocation algorithm allocates an optimal rate to each user from all
carriers in its range while providing the minimum price for the allocated rate.
In addition, we analyze the convergence of the algorithm with different network
traffic densities and show that our algorithm provides traffic dependent
pricing for network providers. Finally, we present simulation results for the
performance of our resource allocation algorithm.
</dc:description>
 <dc:description>Comment: Submitted to IEEE. Part of this work has been uploaded to
  arXiv:1405.6448</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2015-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.08994</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09002</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressed Channel Feedback for Correlated Massive MIMO Systems</dc:title>
 <dc:creator>Sim, Min Soo</dc:creator>
 <dc:creator>Park, Jeonghun</dc:creator>
 <dc:creator>Chae, Chan-Byoung</dc:creator>
 <dc:creator>Heath Jr, Robert W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Massive multiple-input multiple-output (MIMO) is a promising approach for
cellular communication due to its energy efficiency and high achievable data
rate. These advantages, however, can be realized only when channel state
information (CSI) is available at the transmitter. Since there are many
antennas, CSI is too large to feed back without compression. To compress CSI,
prior work has applied compressive sensing (CS) techniques and the fact that
CSI can be sparsified. The adopted sparsifying bases fail, however, to reflect
the spatial correlation and channel conditions or to be feasible in practice.
In this paper, we propose a new sparsifying basis that reflects the long-term
characteristics of the channel, and needs no change as long as the spatial
correlation model does not change. We propose a new reconstruction algorithm
for CS, and also suggest dimensionality reduction as a compression method. To
feed back compressed CSI in practice, we propose a new codebook for the
compressed channel quantization assuming no other-cell interference. Numerical
results confirm that the proposed channel feedback mechanisms show better
performance in point-to-point (single-user) and point-to-multi-point
(multi-user) scenarios.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09006</identifier>
 <datestamp>2015-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast, Multicore-Scalable, Low-Fragmentation Memory Allocation through
  Large Virtual Memory and Global Data Structures</dc:title>
 <dc:creator>Aigner, Martin</dc:creator>
 <dc:creator>Kirsch, Christoph M.</dc:creator>
 <dc:creator>Lippautz, Michael</dc:creator>
 <dc:creator>Sokolova, Ana</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.4.2</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:description>  We demonstrate that general-purpose memory allocation involving many threads
on many cores can be done with high performance, multicore scalability, and low
memory consumption. For this purpose, we have designed and implemented scalloc,
a concurrent allocator that generally performs and scales in our experiments
better than other allocators while using less memory, and is still competitive
otherwise. The main ideas behind the design of scalloc are: uniform treatment
of small and big objects through so-called virtual spans, efficiently and
effectively reclaiming free memory through fast and scalable global data
structures, and constant-time (modulo synchronization) allocation and
deallocation operations that trade off memory reuse and spatial locality
without being subject to false sharing.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2015-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09006</dc:identifier>
 <dc:identifier>doi:10.1145/2814270.2814294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09016</identifier>
 <datestamp>2016-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On solving systems of diagonal polynomial equations over finite fields</dc:title>
 <dc:creator>Ivanyos, Gabor</dc:creator>
 <dc:creator>Santha, Miklos</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>68Q25, 68W30, 68Q12</dc:subject>
 <dc:description>  We present an algorithm to solve a system of diagonal polynomial equations
over finite fields when the number of variables is greater than some fixed
polynomial of the number of equations whose degree depends only on the degree
of the polynomial equations. Our algorithm works in time polynomial in the
number of equations and the logarithm of the size of the field, whenever the
degree of the polynomial equations is constant. As a consequence we design
polynomial time quantum algorithms for two algebraic hidden structure problems:
for the hidden subgroup problem in certain semidirect product p-groups of
constant nilpotency class, and for the multi-dimensional univariate hidden
polynomial graph problem when the degree of the polynomials is constant.
</dc:description>
 <dc:description>Comment: A preliminary extended abstract of this paper has appeared in
  Proceedings of FAW 2015, Springer LNCS vol. 9130, pp. 125-137 (2015)</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2016-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09016</dc:identifier>
 <dc:identifier>doi:10.1016/j.tcs.2016.04.045</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09021</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Morphs of Convex Drawings</dc:title>
 <dc:creator>Angelini, Patrizio</dc:creator>
 <dc:creator>Da Lozzo, Giordano</dc:creator>
 <dc:creator>Frati, Fabrizio</dc:creator>
 <dc:creator>Lubiw, Anna</dc:creator>
 <dc:creator>Patrignani, Maurizio</dc:creator>
 <dc:creator>Roselli, Vincenzo</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We give an algorithm to compute a morph between any two convex drawings of
the same plane graph. The morph preserves the convexity of the drawing at any
time instant and moves each vertex along a piecewise linear curve with linear
complexity. The linear bound is asymptotically optimal in the worst case.
</dc:description>
 <dc:description>Comment: To appear in SoCG 2015</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09022</identifier>
 <datestamp>2017-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-label Classification using Labels as Hidden Nodes</dc:title>
 <dc:creator>Read, Jesse</dc:creator>
 <dc:creator>Hollm&#xe9;n, Jaakko</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Competitive methods for multi-label classification typically invest in
learning labels together. To do so in a beneficial way, analysis of label
dependence is often seen as a fundamental step, separate and prior to
constructing a classifier. Some methods invest up to hundreds of times more
computational effort in building dependency models, than training the final
classifier itself. We extend some recent discussion in the literature and
provide a deeper analysis, namely, developing the view that label dependence is
often introduced by an inadequate base classifier, rather than being inherent
to the data or underlying concept; showing how even an exhaustive analysis of
label dependence may not lead to an optimal classification structure. Viewing
labels as additional features (a transformation of the input), we create
neural-network inspired novel methods that remove the emphasis of a prior
dependency structure. Our methods have an important advantage particular to
multi-label data: they leverage labels to create effective units in middle
layers, rather than learning these units from scratch in an unsupervised
fashion with gradient-based methods. Results are promising. The methods we
propose perform competitively, and also have very important qualities of
scalability.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2017-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09025</identifier>
 <datestamp>2015-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Definite Horn Formulas from Closure Queries</dc:title>
 <dc:creator>Arias, Marta</dc:creator>
 <dc:creator>Balc&#xe1;zar, Jos&#xe9; L.</dc:creator>
 <dc:creator>T&#xee;rn&#x103;uc&#x103;, Cristina</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  A definite Horn theory is a set of n-dimensional Boolean vectors whose
characteristic function is expressible as a definite Horn formula, that is, as
conjunction of definite Horn clauses. The class of definite Horn theories is
known to be learnable under different query learning settings, such as learning
from membership and equivalence queries or learning from entailment. We propose
yet a different type of query: the closure query. Closure queries are a natural
extension of membership queries and also a variant, appropriate in the context
of definite Horn formulas, of the so-called correction queries. We present an
algorithm that learns conjunctions of definite Horn clauses in polynomial time,
using closure and equivalence queries, and show how it relates to the canonical
Guigues-Duquenne basis for implicational systems. We also show how the
different query models mentioned relate to each other by either showing
full-fledged reductions by means of query simulation (where possible), or by
showing their connections in the context of particular algorithms that use them
for learning definite Horn formulas.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2015-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09030</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How does the core sit inside the mantle?</dc:title>
 <dc:creator>Coja-Oghlan, Amin</dc:creator>
 <dc:creator>Cooley, Oliver</dc:creator>
 <dc:creator>Kang, Mihyun</dc:creator>
 <dc:creator>Skubch, Kathrin</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>05C80</dc:subject>
 <dc:description>  The $k$-core, defined as the largest subgraph of minimum degree $k$, of the
random graph $G(n,p)$ has been studied extensively. In a landmark paper Pittel,
Wormald and Spencer [JCTB 67 (1996) 111--151] determined the threshold $d_k$
for the appearance of an extensive $k$-core. Here we derive a multi-type
Galton-Watson branching process that describes precisely how the $k$-core is
embedded into the random graph for any $k\geq3$ and any fixed average degree
$d=np&gt;d_k$. This generalises prior results on, e.g., the internal structure of
the $k$-core.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09039</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Operational Region of D2D Communications for Enhancing Cellular Network
  Performance</dc:title>
 <dc:creator>Stefanatos, Stelios</dc:creator>
 <dc:creator>Gotsis, Antonis G.</dc:creator>
 <dc:creator>Alexiou, Angeliki</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  An important enabler towards the successful deployment of any new
element/feature to the cellular network is the investigation and
characterization of the operational conditions where its introduction will
enhance performance. Even though there has been significant research activity
on the potential of device-to-device (D2D) communications, there are currently
no clear indications of whether D2D communications are actually able to provide
benefits for a wide range of operational conditions, thus justifying their
introduction to the system. This paper attempts to fill this gap by taking a
stochastic geometry approach on characterizing the set (region) of operational
conditions for which D2D communications enhance performance in terms of average
user rate. For the practically interesting case of a heavy loaded network, the
operational region is provided in closed form as a function of a variety of
parameters such as maximum D2D link distances and user densities, reflecting a
wide range of operational conditions (points). It is shown that under the
appropriate deployment scheme, D2D communications can indeed be beneficial not
only for the usually considered regime of &quot;proximal communications&quot; but to a
wide range of operational conditions that include D2D link distances comparable
to the distance to the cellular access point and considerably large user
densities.
</dc:description>
 <dc:description>Comment: to appear in IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2015-06-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09039</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2015.2446974</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09052</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extending Eventually Consistent Cloud Databases for Enforcing Numeric
  Invariants</dc:title>
 <dc:creator>Balegas, Valter</dc:creator>
 <dc:creator>Serra, Diogo</dc:creator>
 <dc:creator>Duarte, S&#xe9;rgio</dc:creator>
 <dc:creator>Ferreira, Carla</dc:creator>
 <dc:creator>Rodrigues, Rodrigo</dc:creator>
 <dc:creator>Pregui&#xe7;a, Nuno</dc:creator>
 <dc:creator>Shapiro, Marc</dc:creator>
 <dc:creator>Najafzadeh, Mahsa</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Geo-replicated databases often operate under the principle of eventual
consistency to offer high-availability with low latency on a simple key/value
store abstraction. Recently, some have adopted commutative data types to
provide seamless reconciliation for special purpose data types, such as
counters. Despite this, the inability to enforce numeric invariants across all
replicas still remains a key shortcoming of relying on the limited guarantees
of eventual consistency storage. We present a new replicated data type, called
bounded counter, which adds support for numeric invariants to eventually
consistent geo-replicated databases. We describe how this can be implemented on
top of existing cloud stores without modifying them, using Riak as an example.
Our approach adapts ideas from escrow transactions to devise a solution that is
decentralized, fault-tolerant and fast. Our evaluation shows much lower latency
and better scalability than the traditional approach of using strong
consistency to enforce numeric invariants, thus alleviating the tension between
consistency and availability.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09059</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blind Estimation of Effective Downlink Channel Gains in Massive MIMO</dc:title>
 <dc:creator>Ngo, Hien Quoc</dc:creator>
 <dc:creator>Larsson, Erik G.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the massive MIMO downlink with time-division duplex (TDD)
operation and conjugate beamforming transmission. To reliably decode the
desired signals, the users need to know the effective channel gain. In this
paper, we propose a blind channel estimation method which can be applied at the
users and which does not require any downlink pilots. We show that our proposed
scheme can substantially outperform the case where each user has only
statistical channel knowledge, and that the difference in performance is
particularly large in certain types of channel, most notably keyhole channels.
Compared to schemes that rely on downlink pilots, our proposed scheme yields
more accurate channel estimates for a wide range of signal-to-noise ratios and
avoid spending time-frequency resources on pilots.
</dc:description>
 <dc:description>Comment: IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP) 2015</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09060</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tutorial Introduction to the Lambda Calculus</dc:title>
 <dc:creator>Rojas, Raul</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  This paper is a concise and painless introduction to the $\lambda$-calculus.
This formalism was developed by Alonzo Church as a tool for studying the
mathematical properties of effectively computable functions. The formalism
became popular and has provided a strong theoretical foundation for the family
of functional programming languages. This tutorial shows how to perform
arithmetical and logical computations using the $\lambda$-calculus and how to
define recursive functions, even though $\lambda$-calculus functions are
unnamed and thus cannot refer explicitly to themselves.
</dc:description>
 <dc:description>Comment: 4 figures</dc:description>
 <dc:date>2015-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09062</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On data skewness, stragglers, and MapReduce progress indicators</dc:title>
 <dc:creator>Coppa, Emilio</dc:creator>
 <dc:creator>Finocchi, Irene</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  We tackle the problem of predicting the performance of MapReduce
applications, designing accurate progress indicators that keep programmers
informed on the percentage of completed computation time during the execution
of a job. Through extensive experiments, we show that state-of-the-art progress
indicators (including the one provided by Hadoop) can be seriously harmed by
data skewness, load unbalancing, and straggling tasks. This is mainly due to
their implicit assumption that the running time depends linearly on the input
size. We thus design a novel profile-guided progress indicator, called
NearestFit, that operates without the linear hypothesis assumption and exploits
a careful combination of nearest neighbor regression and statistical curve
fitting techniques. Our theoretical progress model requires fine-grained
profile data, that can be very difficult to manage in practice. To overcome
this issue, we resort to computing accurate approximations for some of the
quantities used in our model through space- and time-efficient data streaming
algorithms. We implemented NearestFit on top of Hadoop 2.6.0. An extensive
empirical assessment over the Amazon EC2 platform on a variety of real-world
benchmarks shows that NearestFit is practical w.r.t. space and time overheads
and that its accuracy is generally very good, even in scenarios where
competitors incur non-negligible errors and wide prediction fluctuations.
Overall, NearestFit significantly improves the current state-of-art on progress
analysis for MapReduce.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09066</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MORE: Merged Opinions Reputation Model</dc:title>
 <dc:creator>Osman, Nardine</dc:creator>
 <dc:creator>Provetti, Alessandro</dc:creator>
 <dc:creator>Riggi, Valerio</dc:creator>
 <dc:creator>Sierra, Carles</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Reputation is generally defined as the opinion of a group on an aspect of a
thing. This paper presents a reputation model that follows a probabilistic
modelling of opinions based on three main concepts: (1) the value of an opinion
decays with time, (2) the reputation of the opinion source impacts the
reliability of the opinion, and (3) the certainty of the opinion impacts its
weight with respect to other opinions. Furthermore, the model is flexible with
its opinion sources: it may use explicit opinions or implicit opinions that can
be extracted from agent behavior in domains where explicit opinions are sparse.
We illustrate the latter with an approach to extract opinions from behavioral
information in the sports domain, focusing on football in particular. One of
the uses of a reputation model is predicting behavior. We take up the challenge
of predicting the behavior of football teams in football matches, which we
argue is a very interesting yet difficult approach for evaluating the model.
</dc:description>
 <dc:description>Comment: 12th European Conference on Multi-Agent Systems (EUMAS 2014)</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09066</dc:identifier>
 <dc:identifier>Multi-Agent Systems Springer Lecture Notes in Computer Science,
  Vol. 8953, 2015</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-17130-2_5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09076</identifier>
 <datestamp>2015-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Data Uploading Supported by D2D Communications in LTE-A
  Systems</dc:title>
 <dc:creator>Orsino, Antonino</dc:creator>
 <dc:creator>Militano, Leonardo</dc:creator>
 <dc:creator>Araniti, Giuseppe</dc:creator>
 <dc:creator>Molinaro, Antonella</dc:creator>
 <dc:creator>Iera, Antonio</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The reference scenario in this paper is a single cell in a Long Term
Evolution-Advanced (LTE-A) system, where multiple user equipments (UEs) aim at
uploading some data to a central server or to the Cloud. The traditional
uploading technique used in cellular systems, i.e., with separate links from
each UE to the eNodeB, is compared to innovative \textit{relay-based} schemes
that exploit Device-to-Device (D2D) communications between two (or more) UEs in
proximity to each other. Differences in the channel quality experienced by the
UEs offer an opportunity to develop D2D-based solutions, where \textit{(i)} the
UE with a poor direct link to the eNodeB will forward data to a nearby UE over
a high-quality D2D link; and \textit{(ii)} the receiving UE then uploads its
own generated data and the relayed data to the eNodeB over a good uplink
channel. A straightforward gain in the data uploading time can be obtained for
the first UE. To extend the benefits, also to the relaying UE, enhanced
D2D-based solutions are proposed that decrease the uploading time of this UE
based on the cooperative sharing of the resources allocated by the eNodeB to
the cooperating devices. Finally, preliminary results are also presented for a
multihop study case, where a chain of devices exploits D2D communications to
upload data to the eNodeB.
</dc:description>
 <dc:description>Comment: We just realized that the submitted version is not compliant with the
  final version of the manuscript. In addition, there are also crucial error in
  the formulation of the analytical results</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2015-10-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09079</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analytic solutions for the Burgers equation with source terms</dc:title>
 <dc:creator>Montecinos, Gino I.</dc:creator>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Analytic solutions for Burgers equations with source terms, possibly stiff,
represent an important element to assess numerical schemes. Here we present a
procedure, based on the characteristic technique to obtain analytic solutions
for these equations with smooth initial conditions.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures</dc:description>
 <dc:date>2015-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09079</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09082</identifier>
 <datestamp>2016-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Categorization Axioms</dc:title>
 <dc:creator>Yu, Jian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Categorization axioms have been proposed to axiomatizing clustering results,
which offers a hint of bridging the difference between human recognition system
and machine learning through an intuitive observation: an object should be
assigned to its most similar category. However, categorization axioms cannot be
generalized into a general machine learning system as categorization axioms
become trivial when the number of categories becomes one. In order to
generalize categorization axioms into general cases, categorization input and
categorization output are reinterpreted by inner and outer category
representation. According to the categorization reinterpretation, two category
representation axioms are presented. Category representation axioms and
categorization axioms can be combined into a generalized categorization
axiomatic framework, which accurately delimit the theoretical categorization
constraints and overcome the shortcoming of categorization axioms. The proposed
axiomatic framework not only discuses categorization test issue but also
reinterprets many results in machine learning in a unified way, such as
dimensionality reduction,density estimation, regression, clustering and
classification.
</dc:description>
 <dc:description>Comment: 16 pages. Dimensionality reduction, density estimation, regression,
  clustering and classification are represented in a unified way, where
  unsupervised dimensionality reduction, density estimation, regression are
  considered as one category problem, clustering and classification are
  considered as multiple category problem</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2016-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09082</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09087</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual Decomposition-Based Privacy-Preserving Multi-Horizon
  Utility-Community Decision Making Paradigms</dc:title>
 <dc:creator>Disfani, Vahid. R</dc:creator>
 <dc:creator>Miao, Zhixin</dc:creator>
 <dc:creator>Fan, Lingling</dc:creator>
 <dc:creator>Zeng, Bo</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Two types of privacy-preserving decision making paradigms for
utility-community interactions for multi-horizon operation are examined in this
paper. In both designs, communities with renewable energy sources, distributed
generators, and energy storage systems minimize their costs with limited
information exchange with the utility. The utility makes decision based on the
information provided from the communities. Through an iterative process, all
parties achieve agreement. The authors' previous research results on
subgradient and lower-upper-bound switching (LUBS)-based distributed
optimization oriented multi-agent control strategies are examined and the
convergence analysis of both strategies are provided. The corresponding
decision making architectures, including information flow among agents and
learning (or iteration) procedure, are developed for multi-horizon decision
making scenarios. Numerical results illustrate the decision making procedures
and demonstrate their feasibility of practical implementation. The two decision
making architectures are compared for their implementation requirements as well
as performance.
</dc:description>
 <dc:description>Comment: 8 pages, 15 figures, submitted to IEEE trans. Power Systems</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09087</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09092</identifier>
 <datestamp>2015-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficiently decoding Reed-Muller codes from random errors</dc:title>
 <dc:creator>Saptharishi, Ramprasad</dc:creator>
 <dc:creator>Shpilka, Amir</dc:creator>
 <dc:creator>Volk, Ben Lee</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Reed-Muller codes encode an $m$-variate polynomial of degree $r$ by
evaluating it on all points in $\{0,1\}^m$. We denote this code by $RM(m,r)$.
The minimal distance of $RM(m,r)$ is $2^{m-r}$ and so it cannot correct more
than half that number of errors in the worst case. For random errors one may
hope for a better result.
  In this work we give an efficient algorithm (in the block length $n=2^m$) for
decoding random errors in Reed-Muller codes far beyond the minimal distance.
Specifically, for low rate codes (of degree $r=o(\sqrt{m})$) we can correct a
random set of $(1/2-o(1))n$ errors with high probability. For high rate codes
(of degree $m-r$ for $r=o(\sqrt{m/\log m})$), we can correct roughly $m^{r/2}$
errors.
  More generally, for any integer $r$, our algorithm can correct any error
pattern in $RM(m,m-(2r+2))$ for which the same erasure pattern can be corrected
in $RM(m,m-(r+1))$. The results above are obtained by applying recent results
of Abbe, Shpilka and Wigderson (STOC, 2015), Kumar and Pfister (2015) and
Kudekar et al. (2015) regarding the ability of Reed-Muller codes to correct
random erasures.
  The algorithm is based on solving a carefully defined set of linear equations
and thus it is significantly different than other algorithms for decoding
Reed-Muller codes that are based on the recursive structure of the code. It can
be seen as a more explicit proof of a result of Abbe et al. that shows a
reduction from correcting erasures to correcting errors, and it also bares some
similarities with the famous Berlekamp-Welch algorithm for decoding
Reed-Solomon codes.
</dc:description>
 <dc:description>Comment: 18 pages, 2 figures</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2015-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09097</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Open Transactions on Shared Memory</dc:title>
 <dc:creator>Miculan, Marino</dc:creator>
 <dc:creator>Peressotti, Marco</dc:creator>
 <dc:creator>Toneguzzo, Andrea</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Transactional memory has arisen as a good way for solving many of the issues
of lock-based programming. However, most implementations admit isolated
transactions only, which are not adequate when we have to coordinate
communicating processes. To this end, in this paper we present OCTM, an
Haskell-like language with open transactions over shared transactional memory:
processes can join transactions at runtime just by accessing to shared
variables. Thus a transaction can co-operate with the environment through
shared variables, but if it is rolled-back, also all its effects on the
environment are retracted. For proving the expressive power of TCCS we give an
implementation of TCCS, a CCS-like calculus with open transactions.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09097</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-19282-6_14</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09105</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two Timescale Stochastic Approximation with Controlled Markov noise and
  Off-policy temporal difference learning</dc:title>
 <dc:creator>Karmakar, Prasenjit</dc:creator>
 <dc:creator>Bhatnagar, Shalabh</dc:creator>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present for the first time an asymptotic convergence analysis of two
time-scale stochastic approximation driven by `controlled' Markov noise. In
particular, both the faster and slower recursions have non-additive controlled
Markov noise components in addition to martingale difference noise. We analyze
the asymptotic behavior of our framework by relating it to limiting
differential inclusions in both time-scales that are defined in terms of the
ergodic occupation measures associated with the controlled Markov processes.
Finally, we present a solution to the off-policy convergence problem for
temporal difference learning with linear function approximation, using our
results.
</dc:description>
 <dc:description>Comment: 23 pages (relaxed some important assumptions from the previous
  version), accepted in Mathematics of Operations Research in Feb, 2017</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09112</identifier>
 <datestamp>2016-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Combinatorics of Palindromes and Antipalindromes</dc:title>
 <dc:creator>Guo, Chuan</dc:creator>
 <dc:creator>Shallit, Jeffrey</dc:creator>
 <dc:creator>Shur, Arseny M.</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>68R15</dc:subject>
 <dc:description>  We prove a number of results on the structure and enumeration of palindromes
and antipalindromes. In particular, we study conjugates of palindromes,
palindromic pairs, rich words, and the counterparts of these notions for
antipalindromes.
</dc:description>
 <dc:description>Comment: 13 pages/ submitted to DLT 2015</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09112</dc:identifier>
 <dc:identifier>doi:10.1016/j.ipl.2016.07.001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09129</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Encoding Spike Patterns in Multilayer Spiking Neural Networks</dc:title>
 <dc:creator>Gardner, Brian</dc:creator>
 <dc:creator>Sporea, Ioana</dc:creator>
 <dc:creator>Gr&#xfc;ning, Andr&#xe9;</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Information encoding in the nervous system is supported through the precise
spike-timings of neurons; however, an understanding of the underlying processes
by which such representations are formed in the first place remains unclear.
Here we examine how networks of spiking neurons can learn to encode for input
patterns using a fully temporal coding scheme. To this end, we introduce a
learning rule for spiking networks containing hidden neurons which optimizes
the likelihood of generating desired output spiking patterns. We show the
proposed learning rule allows for a large number of accurate input-output spike
pattern mappings to be learnt, which outperforms other existing learning rules
for spiking neural networks: both in the number of mappings that can be learnt
as well as the complexity of spike train encodings that can be utilised. The
learning rule is successful even in the presence of input noise, is
demonstrated to solve the linearly non-separable XOR computation and
generalizes well on an example dataset. We further present a biologically
plausible implementation of backpropagated learning in multilayer spiking
networks, and discuss the neural mechanisms that might underlie its function.
Our approach contributes both to a systematic understanding of how pattern
encodings might take place in the nervous system, and a learning rule that
displays strong technical capability.
</dc:description>
 <dc:description>Comment: 31 pages, 14 figures</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09129</dc:identifier>
 <dc:identifier>doi:10.1162/NECO_a_00790</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09137</identifier>
 <datestamp>2015-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formalising Hypothesis Virtues in Knowledge Graphs: A General
  Theoretical Framework and its Validation in Literature-Based Discovery
  Experiments</dc:title>
 <dc:creator>Novacek, Vit</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We introduce an approach to discovery informatics that uses so called
knowledge graphs as the essential representation structure. Knowledge graph is
an umbrella term that subsumes various approaches to tractable representation
of large volumes of loosely structured knowledge in a graph form. It has been
used primarily in the Web and Linked Open Data contexts, but is applicable to
any other area dealing with knowledge representation. In the perspective of our
approach motivated by the challenges of discovery informatics, knowledge graphs
correspond to hypotheses. We present a framework for formalising so called
hypothesis virtues within knowledge graphs. The framework is based on a classic
work in philosophy of science, and naturally progresses from mostly informative
foundational notions to actionable specifications of measures corresponding to
particular virtues. These measures can consequently be used to determine
refined sub-sets of knowledge graphs that have large relative potential for
making discoveries. We validate the proposed framework by experiments in
literature-based discovery. The experiments have demonstrated the utility of
our work and its superiority w.r.t. related approaches.
</dc:description>
 <dc:description>Comment: Pre-print of an article submitted to Artificial Intelligence Journal
  (after the manuscript has been refused by the editors of Journal of Web
  Semantics before the peer review process due to being out of scope for that
  journal)</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2015-04-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09144</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Using Machine Translation Techniques to Induce Multilingual
  Lexica of Discourse Markers</dc:title>
 <dc:creator>Lopes, Ant&#xf3;nio</dc:creator>
 <dc:creator>de Matos, David Martins</dc:creator>
 <dc:creator>Cabarr&#xe3;o, Vera</dc:creator>
 <dc:creator>Ribeiro, Ricardo</dc:creator>
 <dc:creator>Moniz, Helena</dc:creator>
 <dc:creator>Trancoso, Isabel</dc:creator>
 <dc:creator>Mata, Ana Isabel</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Discourse markers are universal linguistic events subject to language
variation. Although an extensive literature has already reported language
specific traits of these events, little has been said on their cross-language
behavior and on building an inventory of multilingual lexica of discourse
markers. This work describes new methods and approaches for the description,
classification, and annotation of discourse markers in the specific domain of
the Europarl corpus. The study of discourse markers in the context of
translation is crucial due to the idiomatic nature of these structures.
Multilingual lexica together with the functional analysis of such structures
are useful tools for the hard task of translating discourse markers into
possible equivalents from one language to another. Using Daniel Marcu's
validated discourse markers for English, extracted from the Brown Corpus, our
purpose is to build multilingual lexica of discourse markers for other
languages, based on machine translation techniques. The major assumption in
this study is that the usage of a discourse marker is independent of the
language, i.e., the rhetorical function of a discourse marker in a sentence in
one language is equivalent to the rhetorical function of the same discourse
marker in another language.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09156</identifier>
 <datestamp>2015-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting the long-term citation impact of recent publications</dc:title>
 <dc:creator>Stegehuis, Clara</dc:creator>
 <dc:creator>Litvak, Nelly</dc:creator>
 <dc:creator>Waltman, Ludo</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  A fundamental problem in citation analysis is the prediction of the long-term
citation impact of recent publications. We propose a model to predict a
probability distribution for the future number of citations of a publication.
Two predictors are used: The impact factor of the journal in which a
publication has appeared and the number of citations a publication has received
one year after its appearance. The proposed model is based on quantile
regression. We employ the model to predict the future number of citations of a
large set of publications in the field of physics. Our analysis shows that both
predictors (i.e., impact factor and early citations) contribute to the accurate
prediction of long-term citation impact. We also analytically study the
behavior of the quantile regression coefficients for high quantiles of the
distribution of citations. This is done by linking the quantile regression
approach to a quantile estimation technique from extreme value theory. Our work
provides insight into the influence of the impact factor and early citations on
the long-term citation impact of a publication, and it takes a step toward a
methodology that can be used to assess research institutions based on their
most recently published work.
</dc:description>
 <dc:description>Comment: 17 pages, 17 figures</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09156</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2015.06.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09163</identifier>
 <datestamp>2017-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Equivalence of Deterministic Top-Down Tree-to-String Transducers is
  Decidable</dc:title>
 <dc:creator>Seidl, Helmut</dc:creator>
 <dc:creator>Maneth, Sebastian</dc:creator>
 <dc:creator>Kemper, Gregor</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We show that equivalence of deterministic top-down tree-to-string transducers
is decidable, thus solving a long standing open problem in formal language
theory. We also present efficient algorithms for subclasses: polynomial time
for total transducers with unary output alphabet (over a given top-down regular
domain language), and co-randomized polynomial time for linear transducers;
these results are obtained using techniques from multi-linear algebra.
  For our main result, we prove that equivalence can be certified by means of
inductive invariants using polynomial ideals. This allows us to construct two
semi-algorithms, one searching for a proof of equivalence, one for a witness of
non-equivalence. Furthermore, we extend our result to deterministic top-down
tree-to-string transducers which produce output not in a free monoid but in a
free group.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2017-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09163</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09166</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fixed Point Realization of Iterative LR-Aided Soft MIMO Decoding
  Algorithm</dc:title>
 <dc:creator>Rahman, Mehnaz</dc:creator>
 <dc:creator>Choi, Gwan S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Multiple-input multiple-output (MIMO) systems have been widely acclaimed in
order to provide high data rates. Recently Lattice Reduction (LR) aided
detectors have been proposed to achieve near Maximum Likelihood (ML)
performance with low complexity. In this paper, we develop the fixed point
design of an iterative soft decision based LR-aided K-best decoder, which
reduces the complexity of existing sphere decoder. A simulation based
word-length optimization is presented for physical implementation of the K-best
decoder. Simulations show that the fixed point result of 16 bit precision can
keep bit error rate (BER) degradation within 0.3 dB for 8x8 MIMO systems with
different modulation schemes.
</dc:description>
 <dc:description>Comment: submitted to SPIJ (Signal Processing: An International
  Journal),(under review), 10 pages, 5 figures</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09166</dc:identifier>
 <dc:identifier>SPIJ (Signal Processing: An International Journal), vol. 9, issue
  2, pp. 14-24, May 2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09168</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Convergence and Threshold Properties of Discrete Lotka-Volterra
  Population Protocols</dc:title>
 <dc:creator>Czyzowicz, Jurek</dc:creator>
 <dc:creator>Gasieniec, Leszek</dc:creator>
 <dc:creator>Kosowski, Adrian</dc:creator>
 <dc:creator>Kranakis, Evangelos</dc:creator>
 <dc:creator>Spirakis, Paul G.</dc:creator>
 <dc:creator>Uznanski, Przemyslaw</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this work we focus on a natural class of population protocols whose
dynamics are modelled by the discrete version of Lotka-Volterra equations. In
such protocols, when an agent $a$ of type (species) $i$ interacts with an agent
$b$ of type (species) $j$ with $a$ as the initiator, then $b$'s type becomes
$i$ with probability $P\_{ij}$. In such an interaction, we think of $a$ as the
predator, $b$ as the prey, and the type of the prey is either converted to that
of the predator or stays as is. Such protocols capture the dynamics of some
opinion spreading models and generalize the well-known Rock-Paper-Scissors
discrete dynamics. We consider the pairwise interactions among agents that are
scheduled uniformly at random. We start by considering the convergence time and
show that any Lotka-Volterra-type protocol on an $n$-agent population converges
to some absorbing state in time polynomial in $n$, w.h.p., when any pair of
agents is allowed to interact. By contrast, when the interaction graph is a
star, even the Rock-Paper-Scissors protocol requires exponential time to
converge. We then study threshold effects exhibited by Lotka-Volterra-type
protocols with 3 and more species under interactions between any pair of
agents. We start by presenting a simple 4-type protocol in which the
probability difference of reaching the two possible absorbing states is
strongly amplified by the ratio of the initial populations of the two other
types, which are transient, but &quot;control&quot; convergence. We then prove that the
Rock-Paper-Scissors protocol reaches each of its three possible absorbing
states with almost equal probability, starting from any configuration
satisfying some sub-linear lower bound on the initial size of each species.
That is, Rock-Paper-Scissors is a realization of a &quot;coin-flip consensus&quot; in a
distributed system. Some of our techniques may be of independent value.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09169</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Collaborations in Neuroscientist Community</dc:title>
 <dc:creator>Mirbel, Isabelle</dc:creator>
 <dc:creator>Crescenzo, Pierre</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In this paper, we present our approach, called SATIS (Semantically AnnotaTed
Intentions for Services), relying on intentional process modeling and semantic
web technologies and models, to assist collaboration among the members of a
neurosciences community. The main expected result of this work is to derive and
share semantic web service specifications from a neuro-scientists point of view
in order to operationalise image analysis pipelines with web services.
</dc:description>
 <dc:description>Comment: {\'e}galement rapport de recherche I3S/RR--2009-05--FR</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09169</dc:identifier>
 <dc:identifier>International Journal of Web Portals, IGI Global, 2011, 1 (3),
  pp.33-49</dc:identifier>
 <dc:identifier>doi:10.1109/WI-IAT.2009.351</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09170</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximizing Energy Efficiency in Multiple Access Channels by Exploiting
  Packet Dropping and Transmitter Buffering</dc:title>
 <dc:creator>Butt, M. Majid</dc:creator>
 <dc:creator>Jorswieck, Eduard A.</dc:creator>
 <dc:creator>Ottersten, Bjorn</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Quality of service (QoS) for a network is characterized in terms of various
parameters specifying packet delay and loss tolerance requirements for the
application. The unpredictable nature of the wireless channel demands for
application of certain mechanisms to meet the QoS requirements. Traditionally,
medium access control (MAC) and network layers perform these tasks. However,
these mechanisms do not take (fading) channel conditions into account. In this
paper, we investigate the problem using cross layer techniques where
information flow and joint optimization of higher and physical layer is
permitted. We propose a scheduling scheme to optimize the energy consumption of
a multiuser multi-access system such that QoS constraints in terms of packet
loss are fulfilled while the system is able to maximize the advantages emerging
from multiuser diversity. Specifically, this work focuses on modeling and
analyzing the effects of packet buffering capabilities of the transmitter on
the system energy for a packet loss tolerant application. We discuss low
complexity schemes which show comparable performance to the proposed scheme.
The numerical evaluation reveals useful insights about the coupling effects of
different QoS parameters on the system energy consumption and validates our
analytical results.
</dc:description>
 <dc:description>Comment: in IEEE trans. Wireless communications, 2015</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09170</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2015.2417151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1503.09178</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constant Envelope Precoding with Adaptive Receiver Constellation in MISO
  Fading Channel</dc:title>
 <dc:creator>Zhang, Shuowen</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:creator>Lim, Teng Joon</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Constant envelope (CE) precoding is an appealing transmission technique which
enables the realization of high power amplifier (PA) efficiency. For CE
precoding in a single-user multiple-input single-output (MISO) channel, a
desired constellation is feasible at the receiver if and only if it can be
scaled to lie in an annulus, whose boundaries are characterized by the
instantaneous channel realization. Therefore, if a fixed receiver constellation
is used for CE precoding in a fading channel, where the annulus is
time-varying, there is in general a non-zero probability of encountering a
channel that makes CE precoding infeasible, thereby causing a high probability
of error. To tackle this problem, this paper studies the adaptive receiver
constellation design for CE precoding in a single-user MISO flat-fading channel
with an arbitrary number of antennas at the transmitter. We first investigate
the fixed-rate adaptive receiver constellation design to minimize the symbol
error rate (SER). Specifically, an efficient algorithm is proposed to find the
optimal amplitude-and-phase shift keying (APSK) constellation with two rings
that is both feasible and of the maximum minimum Euclidean distance (MED), for
any given constellation size and instantaneous channel realization. Numerical
results show that by using the optimized fixed-rate adaptive receiver
constellation, our proposed scheme achieves significantly improved SER
performance over CE precoding with a fixed receiver constellation. Furthermore,
based on the family of optimal fixed-rate adaptive two-ring APSK constellation
sets, a variable-rate CE transmission scheme is proposed and numerically
examined.
</dc:description>
 <dc:description>Comment: This is a longer version of a paper to appear in IEEE Transactions on
  Wireless Communications</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2016-07-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1503.09178</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2016.2592899</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00028</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-World Font Recognition Using Deep Network and Domain Adaptation</dc:title>
 <dc:creator>Wang, Zhangyang</dc:creator>
 <dc:creator>Yang, Jianchao</dc:creator>
 <dc:creator>Jin, Hailin</dc:creator>
 <dc:creator>Shechtman, Eli</dc:creator>
 <dc:creator>Agarwala, Aseem</dc:creator>
 <dc:creator>Brandt, Jonathan</dc:creator>
 <dc:creator>Huang, Thomas S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We address a challenging fine-grain classification problem: recognizing a
font style from an image of text. In this task, it is very easy to generate
lots of rendered font examples but very hard to obtain real-world labeled
images. This real-to-synthetic domain gap caused poor generalization to new
real data in previous methods (Chen et al. (2014)). In this paper, we refer to
Convolutional Neural Networks, and use an adaptation technique based on a
Stacked Convolutional Auto-Encoder that exploits unlabeled real-world images
combined with synthetic data. The proposed method achieves an accuracy of
higher than 80% (top-5) on a real-world dataset.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00037</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On partial order semantics for SAT/SMT-based symbolic encodings of weak
  memory concurrency</dc:title>
 <dc:creator>Horn, Alex</dc:creator>
 <dc:creator>Kroening, Daniel</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Concurrent systems are notoriously difficult to analyze, and technological
advances such as weak memory architectures greatly compound this problem. This
has renewed interest in partial order semantics as a theoretical foundation for
formal verification techniques. Among these, symbolic techniques have been
shown to be particularly effective at finding concurrency-related bugs because
they can leverage highly optimized decision procedures such as SAT/SMT solvers.
This paper gives new fundamental results on partial order semantics for
SAT/SMT-based symbolic encodings of weak memory concurrency. In particular, we
give the theoretical basis for a decision procedure that can handle a fragment
of concurrent programs endowed with least fixed point operators. In addition,
we show that a certain partial order semantics of relaxed sequential
consistency is equivalent to the conjunction of three extensively studied weak
memory axioms by Alglave et al. An important consequence of this equivalence is
an asymptotically smaller symbolic encoding for bounded model checking which
has only a quadratic number of partial order constraints compared to the
state-of-the-art cubic-size encoding.
</dc:description>
 <dc:description>Comment: 15 pages, 3 figures</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00039</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantitative Approximation of the Probability Distribution of a Markov
  Process by Formal Abstractions</dc:title>
 <dc:creator>Soudjani, Sadegh Esmaeil Zadeh</dc:creator>
 <dc:creator>Abate, Alessandro</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The goal of this work is to formally abstract a Markov process evolving in
discrete time over a general state space as a finite-state Markov chain, with
the objective of precisely approximating its state probability distribution in
time, which allows for its approximate, faster computation by that of the
Markov chain. The approach is based on formal abstractions and employs an
arbitrary finite partition of the state space of the Markov process, and the
computation of average transition probabilities between partition sets. The
abstraction technique is formal, in that it comes with guarantees on the
introduced approximation that depend on the diameters of the partitions: as
such, they can be tuned at will. Further in the case of Markov processes with
unbounded state spaces, a procedure for precisely truncating the state space
within a compact set is provided, together with an error bound that depends on
the asymptotic properties of the transition kernel of the original process. The
overall abstraction algorithm, which practically hinges on piecewise constant
approximations of the density functions of the Markov process, is extended to
higher-order function approximations: these can lead to improved error bounds
and associated lower computational requirements. The approach is practically
tested to compute probabilistic invariance of the Markov process under study,
and is compared to a known alternative approach from the literature.
</dc:description>
 <dc:description>Comment: 29 pages, Journal of Logical Methods in Computer Science</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2015-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00039</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 11, Issue 3 (September
  4, 2015) lmcs:1584</dc:identifier>
 <dc:identifier>doi:10.2168/LMCS-11(3:8)2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00041</identifier>
 <datestamp>2015-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimality of Treating Interference as Noise: A Combinatorial
  Perspective</dc:title>
 <dc:creator>Yi, Xinping</dc:creator>
 <dc:creator>Caire, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  For single-antenna Gaussian interference channels, we re-formulate the
problem of determining the Generalized Degrees of Freedom (GDoF) region
achievable by treating interference as Gaussian noise (TIN) derived in [3] from
a combinatorial perspective. We show that the TIN power control problem can be
cast into an assignment problem, such that the globally optimal power
allocation variables can be obtained by well-known polynomial time algorithms.
Furthermore, the expression of the TIN-Achievable GDoF region (TINA region) can
be substantially simplified with the aid of maximum weighted matchings. We also
provide conditions under which the TINA region is a convex polytope that relax
those in [3]. For these new conditions, together with a channel connectivity
(i.e., interference topology) condition, we show TIN optimality for a new class
of interference networks that is not included, nor includes, the class found in
[3].
  Building on the above insights, we consider the problem of joint link
scheduling and power control in wireless networks, which has been widely
studied as a basic physical layer mechanism for device-to-device (D2D)
communications. Inspired by the relaxed TIN channel strength condition as well
as the assignment-based power allocation, we propose a low-complexity
GDoF-based distributed link scheduling and power control mechanism (ITLinQ+)
that improves upon the ITLinQ scheme proposed in [4] and further improves over
the heuristic approach known as FlashLinQ. It is demonstrated by simulation
that ITLinQ+ provides significant average network throughput gains over both
ITLinQ and FlashLinQ, and yet still maintains the same level of implementation
complexity. More notably, the energy efficiency of the newly proposed ITLinQ+
is substantially larger than that of ITLinQ and FlashLinQ, which is desirable
for D2D networks formed by battery-powered devices.
</dc:description>
 <dc:description>Comment: A short version has been presented at IEEE International Symposium on
  Information Theory (ISIT 2015), Hong Kong</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2015-09-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00045</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly Supervised Learning of Objects, Attributes and their Associations</dc:title>
 <dc:creator>Shi, Zhiyuan</dc:creator>
 <dc:creator>Yang, Yongxin</dc:creator>
 <dc:creator>Hospedales, Timothy M.</dc:creator>
 <dc:creator>Xiang, Tao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  When humans describe images they tend to use combinations of nouns and
adjectives, corresponding to objects and their associated attributes
respectively. To generate such a description automatically, one needs to model
objects, attributes and their associations. Conventional methods require strong
annotation of object and attribute locations, making them less scalable. In
this paper, we model object-attribute associations from weakly labelled images,
such as those widely available on media sharing sites (e.g. Flickr), where only
image-level labels (either object or attributes) are given, without their
locations and associations. This is achieved by introducing a novel weakly
supervised non-parametric Bayesian model. Once learned, given a new image, our
model can describe the image, including objects, attributes and their
associations, as well as their locations and segmentation. Extensive
experiments on benchmark datasets demonstrate that our weakly supervised model
performs at par with strongly supervised models on tasks such as image
description and retrieval based on object-attribute associations.
</dc:description>
 <dc:description>Comment: 14 pages, Accepted to ECCV 2014</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00045</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00052</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Error Bounds Based on Worst Likely Assignments</dc:title>
 <dc:creator>Bax, Eric</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Error bounds based on worst likely assignments use permutation tests to
validate classifiers. Worst likely assignments can produce effective bounds
even for data sets with 100 or fewer training examples. This paper introduces a
statistic for use in the permutation tests of worst likely assignments that
improves error bounds, especially for accurate classifiers, which are typically
the classifiers of interest.
</dc:description>
 <dc:description>Comment: IJCNN 2015</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00057</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Power Flow with Weighted Chance Constraints and General Policies
  for Generation Control</dc:title>
 <dc:creator>Roald, Line</dc:creator>
 <dc:creator>Misra, Sidhant</dc:creator>
 <dc:creator>Chertkov, Michael</dc:creator>
 <dc:creator>Andersson, G&#xf6;ran</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Due to the increasing amount of electricity generated from renewable sources,
uncertainty in power system operation will grow. This has implications for
tools such as Optimal Power Flow (OPF), an optimization problem widely used in
power system operations and planning, which should be adjusted to account for
this uncertainty. One way to handle the uncertainty is to formulate a Chance
Constrained OPF (CC-OPF) which limits the probability of constraint violation
to a predefined value. However, existing CC-OPF formulations and solutions are
not immune to drawbacks. On one hand, they only consider affine policies for
generation control, which are not always realistic and may be sub-optimal. On
the other hand, the standard CC-OPF formulations do not distinguish between
large and small violations, although those might carry significantly different
risk. In this paper, we introduce the Weighted CC-OPF (WCC-OPF) that can handle
general control policies while preserving convexity and allowing for efficient
computation. The weighted chance constraints account for the size of violations
through a weighting function, which assigns a higher risk to a higher
overloads. We prove that the problem remains convex for any convex weighting
function, and for very general generation control policies. In a case study, we
compare the performance of the new WCC-OPF and the standard CC-OPF and
demonstrate that WCC-OPF effectively reduces the number of severe overloads.
Furthermore, we compare an affine generation control policy with a more general
policy, and show that the additional flexibility allow for a lower cost while
maintaining the same level of risk.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00060</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Belief and Intent Prediction for Collision Avoidance in Autonomous
  Vehicles</dc:title>
 <dc:creator>Hamlet, Alan J.</dc:creator>
 <dc:creator>Crane, Carl D.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper describes a novel method for allowing an autonomous ground vehicle
to predict the intent of other agents in an urban environment. This method,
termed the cognitive driving framework, models both the intent and the
potentially false beliefs of an obstacle vehicle. By modeling the relationships
between these variables as a dynamic Bayesian network, filtering can be
performed to calculate the intent of the obstacle vehicle as well as its belief
about the environment. This joint knowledge can be exploited to plan safer and
more efficient trajectories when navigating in an urban environment. Simulation
results are presented that demonstrate the ability of the proposed method to
calculate the intent of obstacle vehicles as an autonomous vehicle navigates a
road intersection such that preventative maneuvers can be taken to avoid
imminent collisions.
</dc:description>
 <dc:description>Comment: 5 pages, Florida Conference on Recent Advances in Robotics, 2015</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00062</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Top Tips to Make Your Research Irreproducible</dc:title>
 <dc:creator>Hong, Neil P. Chue</dc:creator>
 <dc:creator>Crick, Tom</dc:creator>
 <dc:creator>Gent, Ian P.</dc:creator>
 <dc:creator>Kotthoff, Lars</dc:creator>
 <dc:creator>Takeda, Kenji</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  It is an unfortunate convention of science that research should pretend to be
reproducible; our top tips will help you mitigate this fussy conventionality,
enabling you to enthusiastically showcase your irreproducible work.
</dc:description>
 <dc:description>Comment: 2 pages, LaTeX</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00064</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crowdsourcing Feature Discovery via Adaptively Chosen Comparisons</dc:title>
 <dc:creator>Zou, James Y.</dc:creator>
 <dc:creator>Chaudhuri, Kamalika</dc:creator>
 <dc:creator>Kalai, Adam Tauman</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce an unsupervised approach to efficiently discover the underlying
features in a data set via crowdsourcing. Our queries ask crowd members to
articulate a feature common to two out of three displayed examples. In addition
we also ask the crowd to provide binary labels to the remaining examples based
on the discovered features. The triples are chosen adaptively based on the
labels of the previously discovered features on the data set. In two natural
models of features, hierarchical and independent, we show that a simple
adaptive algorithm, using &quot;two-out-of-three&quot; similarity queries, recovers all
features with less labor than any nonadaptive algorithm. Experimental results
validate the theoretical findings.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00064</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00065</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimality of the Laplace Mechanism in Differential Privacy</dc:title>
 <dc:creator>Koufogiannis, Fragkiskos</dc:creator>
 <dc:creator>Han, Shuo</dc:creator>
 <dc:creator>Pappas, George J.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In the highly interconnected realm of Internet of Things, exchange of
sensitive information raises severe privacy concerns. The Laplace mechanism --
adding Laplace-distributed artificial noise to sensitive data -- is one of the
widely used methods of providing privacy guarantees within the framework of
differential privacy. In this work, we present Lipschitz privacy, a slightly
tighter version of differential privacy. We prove that the Laplace mechanism is
optimal in the sense that it minimizes the mean-squared error for identity
queries which provide privacy with respect to the $\ell_{1}$-norm. In addition
to the $\ell_{1}$-norm which respects individuals' participation, we focus on
the use of the $\ell_{2}$-norm which provides privacy of high-dimensional data.
A variation of the Laplace mechanism is proven to have the optimal mean-squared
error from the identity query. Finally, the optimal mechanism for the scenario
in which individuals submit their high-dimensional sensitive data is derived.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00082</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Scheme for Two-Receiver Broadcast Channels with Receiver
  Message Side Information</dc:title>
 <dc:creator>Asadi, Behzad</dc:creator>
 <dc:creator>Ong, Lawrence</dc:creator>
 <dc:creator>Johnson, Sarah J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates the capacity regions of two-receiver broadcast
channels where each receiver (i) has both common and private-message requests,
and (ii) knows part of the private message requested by the other receiver as
side information. We first propose a transmission scheme and derive an inner
bound for the two-receiver memoryless broadcast channel. We next prove that
this inner bound is tight for the deterministic channel and the more capable
channel, thereby establishing their capacity regions. We show that this inner
bound is also tight for all classes of two-receiver broadcast channels whose
capacity regions were known prior to this work. Our proposed scheme is
consequently a unified capacity-achieving scheme for these classes of broadcast
channels.
</dc:description>
 <dc:description>Comment: accepted and to be presented at the 2015 IEEE International Symposium
  on Information Theory (ISIT 2015)</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2015-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00082</dc:identifier>
 <dc:identifier>doi:10.1109/ISIT.2015.7282482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00083</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Theory of Feature Learning</dc:title>
 <dc:creator>van Rooyen, Brendan</dc:creator>
 <dc:creator>Williamson, Robert C.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Feature Learning aims to extract relevant information contained in data sets
in an automated fashion. It is driving force behind the current deep learning
trend, a set of methods that have had widespread empirical success. What is
lacking is a theoretical understanding of different feature learning schemes.
This work provides a theoretical framework for feature learning and then
characterizes when features can be learnt in an unsupervised fashion. We also
provide means to judge the quality of features via rate-distortion theory and
its generalizations.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00086</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A remark on weaken restricted isometry property in compressed sensing</dc:title>
 <dc:creator>Zhang, Hui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The restricted isometry property (RIP) has become well-known in the
compressed sensing community. Recently, a weaken version of RIP was proposed
for exact sparse recovery under weak moment assumptions. In this note, we prove
that the weaken RIP is also sufficient for \textsl{stable and robust} sparse
recovery by linking it with a recently introduced robust width property in
compressed sensing. Moreover, we show that it can be widely apply to other
compressed sensing instances as well.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00087</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantization of compressive samples with stable and robust recovery</dc:title>
 <dc:creator>Saab, Rayan</dc:creator>
 <dc:creator>Wang, Rongrong</dc:creator>
 <dc:creator>Yilmaz, Ozgur</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we study the quantization stage that is implicit in any
compressed sensing signal acquisition paradigm. We propose using Sigma-Delta
quantization and a subsequent reconstruction scheme based on convex
optimization. We prove that the reconstruction error due to quantization decays
polynomially in the number of measurements. Our results apply to arbitrary
signals, including compressible ones, and account for measurement noise.
Additionally, they hold for sub-Gaussian (including Gaussian and Bernoulli)
random compressed sensing measurements, as well as for both high bit-depth and
coarse quantizers, and they extend to 1-bit quantization. In the noise-free
case, when the signal is strictly sparse we prove that by optimizing the order
of the quantization scheme one can obtain root-exponential decay in the
reconstruction error due to quantization.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00087</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00088</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>State Estimation for the Individual and the Population in Mean Field
  Control with Application to Demand Dispatch</dc:title>
 <dc:creator>Chen, Yue</dc:creator>
 <dc:creator>Bu&#x161;i&#x107;, Ana</dc:creator>
 <dc:creator>Meyn, Sean</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>93E20, 62M05, 93E10, 68W15</dc:subject>
 <dc:description>  This paper concerns state estimation problems in a mean field control
setting. In a finite population model, the goal is to estimate the joint
distribution of the population state and the state of a typical individual. The
observation equations are a noisy measurement of the population.
  The general results are applied to demand dispatch for regulation of the
power grid, based on randomized local control algorithms. In prior work by the
authors it has been shown that local control can be carefully designed so that
the aggregate of loads behaves as a controllable resource with accuracy
matching or exceeding traditional sources of frequency regulation. The
operational cost is nearly zero in many cases.
  The information exchange between grid and load is minimal, but it is assumed
in the overall control architecture that the aggregate power consumption of
loads is available to the grid operator. It is shown that the Kalman filter can
be constructed to reduce these communication requirements,
</dc:description>
 <dc:description>Comment: To appear, IEEE Trans. Auto. Control. Preliminary version appeared in
  the 54rd IEEE Conference on Decision and Control, 2015</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2016-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00088</dc:identifier>
 <dc:identifier>doi:10.1109/TAC.2016.2572880</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00091</identifier>
 <datestamp>2015-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning in the Presence of Corruption</dc:title>
 <dc:creator>van Rooyen, Brendan</dc:creator>
 <dc:creator>Williamson, Robert C.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In supervised learning one wishes to identify a pattern present in a joint
distribution $P$, of instances, label pairs, by providing a function $f$ from
instances to labels that has low risk $\mathbb{E}_{P}\ell(y,f(x))$. To do so,
the learner is given access to $n$ iid samples drawn from $P$. In many real
world problems clean samples are not available. Rather, the learner is given
access to samples from a corrupted distribution $\tilde{P}$ from which to
learn, while the goal of predicting the clean pattern remains. There are many
different types of corruption one can consider, and as of yet there is no
general means to compare the relative ease of learning under these different
corruption processes. In this paper we develop a general framework for tackling
such problems as well as introducing upper and lower bounds on the risk for
learning in the presence of corruption. Our ultimate goal is to be able to make
informed economic decisions in regards to the acquisition of data sets. For a
certain subclass of corruption processes (those that are
\emph{reconstructible}) we achieve this goal in a particular sense. Our lower
bounds are in terms of the coefficient of ergodicity, a simple to calculate
property of stochastic matrices. Our upper bounds proceed via a generalization
of the method of unbiased estimators appearing in recent work of Natarajan et
al and implicit in the earlier work of Kearns.
</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:date>2015-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00097</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conformal Surface Morphing with Applications on Facial Expressions</dc:title>
 <dc:creator>Yueh, Mei-Heng</dc:creator>
 <dc:creator>Gu, Xianfeng David</dc:creator>
 <dc:creator>Lin, Wen-Wei</dc:creator>
 <dc:creator>Wu, Chin-Tien</dc:creator>
 <dc:creator>Yau, Shing-Tung</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Morphing is the process of changing one figure into another. Some numerical
methods of 3D surface morphing by deformable modeling and conformal mapping are
shown in this study. It is well known that there exists a unique Riemann
conformal mapping from a simply connected surface into a unit disk by the
Riemann mapping theorem. The dilation and relative orientations of the 3D
surfaces can be linked through the M\&quot;obius transformation due to the conformal
characteristic of the Riemann mapping. On the other hand, a 3D surface
deformable model can be built via various approaches such as mutual
parameterization from direct interpolation or surface matching using landmarks.
In this paper, we take the advantage of the unique representation of 3D
surfaces by the mean curvatures and the conformal factors associated with the
Riemann mapping. By registering the landmarks on the conformal parametric
domains, the correspondence of the mean curvatures and the conformal factors
for each surfaces can be obtained. As a result, we can construct the 3D
deformation field from the surface reconstruction algorithm proposed by Gu and
Yau. Furthermore, by composition of the M\&quot;obius transformation and the 3D
deformation field, the morphing sequence can be generated from the mean
curvatures and the conformal factors on a unified mesh structure by using the
cubic spline homotopy. Several numerical experiments of the face morphing are
presented to demonstrate the robustness of our approach.
</dc:description>
 <dc:description>Comment: 8 pages, 13 figures</dc:description>
 <dc:date>2015-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00097</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00110</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Libra Toolkit for Probabilistic Models</dc:title>
 <dc:creator>Lowd, Daniel</dc:creator>
 <dc:creator>Rooshenas, Amirmohammad</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The Libra Toolkit is a collection of algorithms for learning and inference
with discrete probabilistic models, including Bayesian networks, Markov
networks, dependency networks, and sum-product networks. Compared to other
toolkits, Libra places a greater emphasis on learning the structure of
tractable models in which exact inference is efficient. It also includes a
variety of algorithms for learning graphical models in which inference is
potentially intractable, and for performing exact and approximate inference.
Libra is released under a 2-clause BSD license to encourage broad use in
academia and industry.
</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00110</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00126</identifier>
 <datestamp>2016-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conjugate-Root Offset-QAM for Orthogonal Multicarrier Transmission</dc:title>
 <dc:creator>Matth&#xe9;, Maximilian</dc:creator>
 <dc:creator>Fettweis, Gerhard</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Current implementations of OFDM/OQAM are restricted to band-limited symmetric
filters. To circumvent this, non-symmetric conjugate root (CR) filters are
proposed for OQAM modulation. The system is applied to Generalized Frequency
Division Multiplexing (GFDM) and a method for achieving transmit diversity with
OQAM modulation is presented. The proposal reduces implementation complexity
compared to existing works and provides a more regular phase space.
GFDM/CR-OQAM outperforms conventional GFDM in terms of symbol error rate in
fading multipath channels and provides a more localized spectrum compared to
conventional OQAM.
</dc:description>
 <dc:description>Comment: 4pages, revised version submitted to IEEE WCL</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:date>2015-06-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00126</dc:identifier>
 <dc:identifier>doi:10.1186/s13634-016-0342-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00134</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Haar to Lebesgue via Domain Theory, Revised version</dc:title>
 <dc:creator>Brian, Will</dc:creator>
 <dc:creator>Mislove, Michael</dc:creator>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:description>  If ${\mathcal C}\simeq 2^{\mathbb N}$ denotes the Cantor set realized as the
infinite product of two-point groups, then a folklore result says the Cantor
map from ${\mathcal C}$ into $[0,1]$ sends Haar measure to Lebesgue measure on
the interval. In fact, ${\mathcal C}$ admits many distinct topological group
structures. In this note, we show that the Haar measures induced by these
distinct group structures are share this property. We prove this by showing
that Haar measure for any group structure is the same as Haar measure induced
by a related abelian group structure. Moreover, each abelian group structure on
${\mathcal C}$ supports a natural total order that determines a map onto the
unit interval that is monotone, and hence sends intervals in ${\mathcal C}$ to
subintervals of the unit interval. Using techniques from domain theory, we show
this implies this map sends Haar measure on ${\mathcal C}$ to Lebesgue measure
on the interval, and we then use this to contract a Borel isomorphism between
any two group structures on ${\mathcal C}$.
</dc:description>
 <dc:description>Comment: This is a revised version of an earlier paper. The original claimed
  that all Haar measures on C are the same, which is not true. This version
  corrects that error</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00136</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge reduction of dynamic covering decision information systems
  with immigration of more objects</dc:title>
 <dc:creator>Lang, Guangming</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In practical situations, it is of interest to investigate computing
approximations of sets as an important step of knowledge reduction of dynamic
covering decision information systems. In this paper, we present incremental
approaches to computing the type-1 and type-2 characteristic matrices of
dynamic coverings whose cardinalities increase with immigration of more
objects. We also present the incremental algorithms of computing the second and
sixth lower and upper approximations of sets in dynamic covering approximation
spaces.
</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00143</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully explicit large deviation inequalities for empirical processes with
  applications to information-based complexity</dc:title>
 <dc:creator>Aistleitner, Christoph</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>60F10, 62G30, 65D32, 65C05, 52C17, 11K38</dc:subject>
 <dc:description>  In the present paper we obtain fully explicit large deviation inequalities
for empirical processes indexed by a Vapnik--Chervonenkis class of sets (or
functions). Furthermore we illustrate the importance of such results for the
theory of information-based complexity.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00143</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00150</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering Restricted Regular Expressions with Interleaving</dc:title>
 <dc:creator>Peng, Feifei</dc:creator>
 <dc:creator>Chen, Haiming</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Discovering a concise schema from given XML documents is an important problem
in XML applications. In this paper, we focus on the problem of learning an
unordered schema from a given set of XML examples, which is actually a problem
of learning a restricted regular expression with interleaving using positive
example strings. Schemas with interleaving could present meaningful knowledge
that cannot be disclosed by previous inference techniques. Moreover, inference
of the minimal schema with interleaving is challenging. The problem of finding
a minimal schema with interleaving is shown to be NP-hard. Therefore, we
develop an approximation algorithm and a heuristic solution to tackle the
problem using techniques different from known inference algorithms. We do
experiments on real-world data sets to demonstrate the effectiveness of our
approaches. Our heuristic algorithm is shown to produce results that are very
close to optimal.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00150</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00151</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bi-polynomial rank and determinantal complexity</dc:title>
 <dc:creator>Yabe, Akihiro</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The permanent vs. determinant problem is one of the most important problems
in theoretical computer science, and is the main target of geometric complexity
theory proposed by Mulmuley and Sohoni. The current best lower bound for the
determinantal complexity of the d by d permanent polynomial is d^2/2, due to
Mignon and Ressayre in 2004. Inspired by their proof method, we introduce a
natural rank concept of polynomials, called the bi-polynomial rank. The
bi-polynomial rank is related to width of an arithmetic branching program. The
bi-polynomial rank of a homogeneous polynomial p of even degree 2k is defined
as the minimum n such that p can be written as a summation of n products of
polynomials of degree k. We prove that the bi-polynomial rank gives a lower
bound of the determinantal complexity. As a consequence, the above Mignon and
Ressayre bound is improved to (d-1)^2 + 1 over the field of reals. We show that
the computation of the bi-polynomial rank is formulated as a rank minimization
problem. Applying the concave minimization technique, we reduce the problem of
lower-bounding determinantal complexity to that of proving the positive
semidefiniteness of matrices, and this is a new approach for the permanent vs.
determinant problem. We propose a computational approach for giving a lower
bound of this rank minimization, via techniques of the concave minimization.
This also yields a new strategy to attack the permanent vs. determinant
problem.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00154</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Repair Operator for Multi-objective Evolutionary Algorithm in
  Constrained Optimization Problems</dc:title>
 <dc:creator>Fan, Zhun</dc:creator>
 <dc:creator>Li, Wenji</dc:creator>
 <dc:creator>Cai, Xinye</dc:creator>
 <dc:creator>Lin, Huibiao</dc:creator>
 <dc:creator>Xie, Shuxiang</dc:creator>
 <dc:creator>Goodman, Erik</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>68Q01</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  In this paper, we design a set of multi-objective constrained optimization
problems (MCOPs) and propose a new repair operator to address them. The
proposed repair operator is used to fix the solutions that violate the box
constraints. More specifically, it employs a reversed correction strategy that
can effectively avoid the population falling into local optimum. In addition,
we integrate the proposed repair operator into two classical multi-objective
evolutionary algorithms MOEA/D and NSGA-II. The proposed repair operator is
compared with other two kinds of commonly used repair operators on benchmark
problems CTPs and MCOPs. The experiment results demonstrate that our proposed
approach is very effective in terms of convergence and diversity.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00156</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Graph Algorithmic Approach to Separate Direct from Indirect Neural
  Interactions</dc:title>
 <dc:creator>Wollstadt, Patricia</dc:creator>
 <dc:creator>Meyer, Ulrich</dc:creator>
 <dc:creator>Wibral, Michael</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:subject>H.1.1</dc:subject>
 <dc:description>  Network graphs have become a popular tool to represent complex systems
composed of many interacting subunits; especially in neuroscience, network
graphs are increasingly used to represent and analyze functional interactions
between neural sources. Interactions are often reconstructed using pairwise
bivariate analyses, overlooking their multivariate nature: it is neglected that
investigating the effect of one source on a target necessitates to take all
other sources as potential nuisance variables into account; also combinations
of sources may act jointly on a given target. Bivariate analyses produce
networks that may contain spurious interactions, which reduce the
interpretability of the network and its graph metrics. A truly multivariate
reconstruction, however, is computationally intractable due to combinatorial
explosion in the number of potential interactions. Thus, we have to resort to
approximative methods to handle the intractability of multivariate interaction
reconstruction, and thereby enable the use of networks in neuroscience. Here,
we suggest such an approximative approach in the form of an algorithm that
extends fast bivariate interaction reconstruction by identifying potentially
spurious interactions post-hoc: the algorithm flags potentially spurious edges,
which may then be pruned from the network. This produces a statistically
conservative network approximation that is guaranteed to contain non-spurious
interactions only. We describe the algorithm and present a reference
implementation to test its performance. We discuss the algorithm in relation to
other approximative multivariate methods and highlight suitable application
scenarios. Our approach is a tractable and data-efficient way of reconstructing
approximative networks of multivariate interactions. It is preferable if
available data are limited or if fully multivariate approaches are
computationally infeasible.
</dc:description>
 <dc:description>Comment: 24 pages, 8 figures, published in PLOS One</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00156</dc:identifier>
 <dc:identifier>PLoS ONE 10(10): e0140530 (2015)</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0140530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00169</identifier>
 <datestamp>2015-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universal Simulation of Automata Networks</dc:title>
 <dc:creator>Castillo-Ramirez, Alonso</dc:creator>
 <dc:creator>Gadouleau, Maximilien</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:description>  Let $A$ be a finite set and $n \geq 2$. This paper introduces the concept of
universal simulation in the context of semigroups of transformations of $A^n$,
also known as finite state-homogeneous automata networks. For $m \geq n$, a
transformation of $A^m$ is defined as $n$-universal of size $m$ if it may
simulate every transformation of $A^n$ by updating one coordinate (or register)
at a time. Using tools from memoryless computation, it is established that
there is no $n$-universal transformation of size $n$, but there is such a
transformation of size $n+2$. An $n$-universal transformation is defined as
complete if it may sequentially simulate every finite sequence of
transformations of $A^n$; in this case, minimal examples and bounds for the
size and time of simulation are determined. It is also shown that there is no
$n$-universal transformation that updates all the registers in parallel, but
that there exists a complete one that updates all but one register in parallel.
This illustrates the strengths and weaknesses of parallel models of
computation, such as cellular automata.
</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:date>2015-04-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00182</identifier>
 <datestamp>2015-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The nonassociative algebras used to build fast-decodable space-time
  block codes</dc:title>
 <dc:creator>Pumpluen, Susanne</dc:creator>
 <dc:creator>Steele, Andrew</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>17A35, 94B05</dc:subject>
 <dc:description>  Let $K/F$ and $K/L$ be two cyclic Galois field extensions and
$D=(K/F,\sigma,c)$ a cyclic algebra. Given an invertible element $d\in D$, we
present three families of unital nonassociative algebras over $L\cap F$ defined
on the direct sum of $n$ copies of $D$. Two of these families appear either
explicitly or implicitly in the designs of fast-decodable space-time block
codes in papers by Srinath, Rajan, Markin, Oggier, and the authors. We present
conditions for the algebras to be division and propose a construction for fully
diverse fast decodable space-time block codes of rate-$m$ for $nm$ transmit and
$m$ receive antennas. We present a DMT-optimal rate-3 code for 6 transmit and 3
receive antennas which is fast-decodable, with ML-decoding complexity at most
$\mathcal{O}(M^{15})$.
</dc:description>
 <dc:description>Comment: Final version, to appear in Advances in Mathematics of
  Communications. Contains updated contact details for second author</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:date>2015-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00182</dc:identifier>
 <dc:identifier>doi:10.3934/amc.2015.9.449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00190</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on linear codes and nonassociative algebras obtained from
  skew-polynomial rings</dc:title>
 <dc:creator>Pumpluen, Susanne</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Rings and Algebras</dc:subject>
 <dc:subject>94B05, 94B15, 16S36, 17A35</dc:subject>
 <dc:description>  Different approaches to construct linear codes using skew polynomials can be
unified by using the nonassociative algebras built from skew-polynomial rings
by Petit.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00191</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Document Indexing via Intelligent Hierarchical Clustering: A
  Novel Approach</dc:title>
 <dc:creator>Roul, Rajendra Kumar</dc:creator>
 <dc:creator>Asthana, Shubham Rohan</dc:creator>
 <dc:creator>Sahay, Sanjay Kumar</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  With the rising quantity of textual data available in electronic format, the
need to organize it become a highly challenging task. In the present paper, we
explore a document organization framework that exploits an intelligent
hierarchical clustering algorithm to generate an index over a set of documents.
The framework has been designed to be scalable and accurate even with large
corpora. The advantage of the proposed algorithm lies in the need for minimal
inputs, with much of the hierarchy attributes being decided in an automated
manner using statistical methods. The use of topic modeling in a pre-processing
stage ensures robustness to a range of variations in the input data. For
experimental work 20-Newsgroups dataset has been used. The F- measure of the
proposed approach has been compared with the traditional K-Means and K-Medoids
clustering algorithms. Test results demonstrate the applicability, efficiency
and effectiveness of our proposed approach. After extensive experimentation, we
conclude that the framework shows promise for further research and specialized
commercial applications.
</dc:description>
 <dc:description>Comment: 6 Pages, 3 Figures. IEEE Xplore, ICHPCA-2014</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00191</dc:identifier>
 <dc:identifier>doi:10.1109/ICHPCA.2014.7045347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00198</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conditioning in Probabilistic Programming</dc:title>
 <dc:creator>Gretz, Friedrich</dc:creator>
 <dc:creator>Jansen, Nils</dc:creator>
 <dc:creator>Kaminski, Benjamin Lucien</dc:creator>
 <dc:creator>Katoen, Joost-Pieter</dc:creator>
 <dc:creator>McIver, Annabelle</dc:creator>
 <dc:creator>Olmedo, Federico</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We investigate the semantic intricacies of conditioning, a main feature in
probabilistic programming. We provide a weakest (liberal) pre-condition (w(l)p)
semantics for the elementary probabilistic programming language pGCL extended
with conditioning. We prove that quantitative weakest (liberal) pre-conditions
coincide with conditional (liberal) expected rewards in Markov chains and show
that semantically conditioning is a truly conservative extension. We present
two program transformations which entirely eliminate conditioning from any
program and prove their correctness using the w(l)p-semantics. Finally, we show
how the w(l)p-semantics can be used to determine conditional probabilities in a
parametric anonymity protocol and show that an inductive w(l)p-semantics for
conditioning in non-deterministic probabilistic programs cannot exist.
</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00203</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deterministic Cramer-Rao bound for strictly non-circular sources and
  analytical analysis of the achievable gains</dc:title>
 <dc:creator>Steinwandt, Jens</dc:creator>
 <dc:creator>Roemer, Florian</dc:creator>
 <dc:creator>Haardt, Martin</dc:creator>
 <dc:creator>Del Galdo, Giovanni</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Recently, several high-resolution parameter estimation algorithms have been
developed to exploit the structure of strictly second-order (SO) non-circular
(NC) signals. They achieve a higher estimation accuracy and can resolve up to
twice as many signal sources compared to the traditional methods for arbitrary
signals. In this paper, as a benchmark for these NC methods, we derive the
closed-form deterministic R-D NC Cramer-Rao bound (NC CRB) for the
multi-dimensional parameter estimation of strictly non-circular (rectilinear)
signal sources. Assuming a separable centro-symmetric R-D array, we show that
in some special cases, the deterministic R-D NC CRB reduces to the existing
deterministic R-D CRB for arbitrary signals. This suggests that no gain from
strictly non-circular sources (NC gain) can be achieved in these cases. For
more general scenarios, finding an analytical expression of the NC gain for an
arbitrary number of sources is very challenging. Thus, in this paper, we
simplify the derived NC CRB and the existing CRB for the special case of two
closely-spaced strictly non-circular sources captured by a uniform linear array
(ULA). Subsequently, we use these simplified CRB expressions to analytically
compute the maximum achievable asymptotic NC gain for the considered two source
case. The resulting expression only depends on the various physical parameters
and we find the conditions that provide the largest NC gain for two sources.
Our analysis is supported by extensive simulation results.
</dc:description>
 <dc:description>Comment: submitted to IEEE Transactions on Signal Processing, 13 pages, 4
  figures</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00203</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2566603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00204</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster linearizability checking via $P$-compositionality</dc:title>
 <dc:creator>Horn, Alex</dc:creator>
 <dc:creator>Kroening, Daniel</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Linearizability is a well-established consistency and correctness criterion
for concurrent data types. An important feature of linearizability is Herlihy
and Wing's locality principle, which says that a concurrent system is
linearizable if and only if all of its constituent parts (so-called objects)
are linearizable. This paper presents $P$-compositionality, which generalizes
the idea behind the locality principle to operations on the same concurrent
data type. We implement $P$-compositionality in a novel linearizability
checker. Our experiments with over nine implementations of concurrent sets,
including Intel's TBB library, show that our linearizability checker is one
order of magnitude faster and/or more space efficient than the state-of-the-art
algorithm.
</dc:description>
 <dc:description>Comment: 15 pages, 2 figures</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00215</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Controlled Remote State Preparation via General Pure Three-Qubit State</dc:title>
 <dc:creator>Zhang, Zhi-Hua</dc:creator>
 <dc:creator>Shu, Lan</dc:creator>
 <dc:creator>Zheng, Jun</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The protocols for controlled remote state preparation of a single qubit and a
general two-qubit state are presented in this paper. The general pure
three-qubit states are chosen as shared quantum channel, which are not LOCC
equivalent to the mostly used GHZ-state. It is the first time to introduce
general pure three-qubit states to complete remote state preparation. The
probability of successful preparation is presented. Moreover, in some special
cases, the successful probability could reach unit.
</dc:description>
 <dc:description>Comment: 12 pages, 2 figures</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00221</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparative study of the two versions of the Microsoft Kinect$^{\rm TM}$
  sensor in regard to the analysis of human motion</dc:title>
 <dc:creator>Malinowski, M. J.</dc:creator>
 <dc:creator>Matsinos, E.</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The present paper is part of a broader programme, exploring the possibility
of involving the Microsoft Kinect$^{\rm TM}$ sensor in the analysis of human
motion. In this study, the output obtained from the two available versions of
this sensor is critically examined. We demonstrate that the two outputs differ
in regard to the variation of the physical quantities involved in the modelling
of the human motion. As the original sensor has been found unsuitable for
applications requiring high precision, the observed differences in the output
of the two sensors call for the validation of the upgraded sensor on the basis
of a marker-based system.
</dc:description>
 <dc:description>Comment: 18 pages, 1 table, 6 figures. arXiv admin note: substantial text
  overlap with arXiv:1412.2032</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00221</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00222</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Exact and Approximate Eigenvalue Distribution for Sum of Wishart
  Matrices</dc:title>
 <dc:creator>Kumar, S.</dc:creator>
 <dc:creator>Pivaro, G. F.</dc:creator>
 <dc:creator>Fraidenraich, G.</dc:creator>
 <dc:creator>Dias, C. F.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A15, 94A17, 15A18, 15B52</dc:subject>
 <dc:description>  The sum of Wishart matrices has an important role in multiuser communication
employing multiantenna elements, such as multiple-input multiple-output (MIMO)
multiple access channel (MAC), MIMO Relay channel, and other multiuser channels
where the mathematical model is best described using random matrices. In this
paper, the distribution of linear combination of complex Wishart distributed
matrices has been studied. We present a new closed form expression for the
marginal distribution of the eigenvalues of a weighted sum of K complex central
Wishart matrices having covariance matrices proportional to the identity
matrix. The expression is general and allows for any set of linear
coefficients. As an application example, we have used the marginal distribution
expression to obtain the ergodic sum-rate capacity for the MIMO-MAC network,
and the cut-set upper bound for the MIMO-Relay case, both as closed form
expressions. We also present a very simple expression to approximate the sum of
Wishart matrices by one equivalent Wishart matrix. All of our results are
validated by means of Monte Carlo simulations. As expected, the agreement
between the exact eigenvalue distribution and simulations is perfect, whereas
for the approximate solution the difference is indistinguishable.
</dc:description>
 <dc:description>Comment: 18 pages, 8 figures, 1 table</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00229</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling and Managing SSD Write-amplification</dc:title>
 <dc:creator>Dayan, Niv</dc:creator>
 <dc:creator>Bouganim, Luc</dc:creator>
 <dc:creator>Bonnet, Philippe</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  How stable is the performance of your flash-based Solid State Drives (SSDs)?
This question is central for database designers and administrators, cloud
service providers, and SSD constructors. The answer depends on
write-amplification, i.e., garbage collection overhead. More specifically, the
answer depends on how write-amplification evolves in time.
  How then can one model and manage write-amplification, especially when
application workloads change? This is the focus of this paper. Managing
write-amplification boils down to managing the surplus physical space, called
over-provisioned space. Modern SSDs essentially separate the physical space
into several partitions, based on the update frequency of the pages they
contain, and divide the over-provisioned space among the groups so as to
minimize write-amplification. We introduce Wolf, a block manager that allocates
over-provisioned space to SSD partitions using a near-optimal closed-form
expression, based on the sizes and update frequencies of groups of pages. Our
evaluation shows that Wolf is robust to workloads change, with an improvement
factor of 2 with respect to the state-of-the-art. We also show that Wolf
performs comparably and even slightly better than the state of the art with
stable workloads (over 20% improvement with a TPC-C workload).
</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00229</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00231</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Single Projection Kaczmarz Extended Algorithms</dc:title>
 <dc:creator>Petra, Stefania</dc:creator>
 <dc:creator>Popa, Constantin</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>65F10, 65F20, 90C06, 90C25</dc:subject>
 <dc:subject>G.1.3</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  To find the least squares solution of a very large and inconsistent system of
equations, one can employ the extended Kaczmarz algorithm. This method
simultaneously removes the error term, such that a consistent system is
asymptotically obtained, and applies Kaczmarz iterations for the current
approximation of this system. For random corrections of the right hand side and
Kaczmarz updates selected at random, convergence to the least squares solution
has been shown. We consider the deterministic control strategies, and show
convergence to a least squares solution when row and column updates are chosen
according to the almost-cyclic or maximal-residual choice.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00233</identifier>
 <datestamp>2015-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Information Processing with Finite Resources - Mathematical
  Foundations</dc:title>
 <dc:creator>Tomamichel, Marco</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:description>  One of the predominant challenges when engineering future quantum information
processors is that large quantum systems are notoriously hard to maintain and
control accurately. It is therefore of immediate practical relevance to
investigate quantum information processing with limited physical resources, for
example to ask: How well can we perform information processing tasks if we only
have access to a small quantum device? Can we beat fundamental limits imposed
on information processing with classical resources? This book will introduce
the reader to the mathematical framework required to answer such questions.
  A strong emphasis is given to information measures that are essential for the
study of devices of finite size, including R\'enyi entropies and smooth
entropies. The presentation is self-contained and includes rigorous and concise
proofs of the most important properties of these measures. The first chapters
will introduce the formalism of quantum mechanics, with particular emphasis on
norms and metrics for quantum states. This is necessary to explore quantum
generalizations of R\'enyi divergence and conditional entropy, information
measures that lie at the core of information theory. The smooth entropy
framework is discussed next and provides a natural means to lift many arguments
from information theory to the quantum setting. Finally selected applications
of the theory to statistics and cryptography are discussed.
</dc:description>
 <dc:description>Comment: 135 pages, partly based on arXiv:1203.2142, v3: minor fixes,
  published version, SpringerBriefs in Mathematical Physics (2016)</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:date>2015-10-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00233</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-21891-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00234</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-layer Energy-Efficiency Optimization of Packet Based Wireless MIMO
  Communication Systems</dc:title>
 <dc:creator>Senning, Christian</dc:creator>
 <dc:creator>Karakonstantis, Georgios</dc:creator>
 <dc:creator>Burg, Andreas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Energy in today's short-range wireless communication is mostly spent on the
analog- and digital hardware rather than on radiated power. Hence, purely
information-theoretic considerations fail to achieve the lowest energy per
information bit and the optimization process must carefully consider the
overall transceiver. In this paper, we propose to perform cross-layer
optimization, based on an energy-aware rate adaptation scheme combined with a
physical layer that is able to properly adjust its processing effort to the
data rate and the channel conditions to minimize the energy consumption per
information bit. This energy proportional behavior is enabled by extending the
classical system modes with additional configuration parameters at the various
layers. Fine grained models of the power consumption of the hardware are
developed to provide awareness of the physical layer capabilities to the medium
access control layer. The joint application of the proposed energy-aware rate
adaptation and modifications to the physical layer of an IEEE 802.11n system,
improves energy-efficiency (averaged over many noise and channel realizations)
in all considered scenarios by up to 44%.
</dc:description>
 <dc:description>Comment: Accepted for publication in The Journal of Signal Processing Systems</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00241</identifier>
 <datestamp>2016-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time Centrality in Dynamic Complex Networks</dc:title>
 <dc:creator>Costa, Eduardo Chinelate</dc:creator>
 <dc:creator>Vieira, Alex Borges</dc:creator>
 <dc:creator>Wehmuth, Klaus</dc:creator>
 <dc:creator>Ziviani, Artur</dc:creator>
 <dc:creator>da Silva, Ana Paula Couto</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  There is an ever-increasing interest in investigating dynamics in
time-varying graphs (TVGs). Nevertheless, so far, the notion of centrality in
TVG scenarios usually refers to metrics that assess the relative importance of
nodes along the temporal evolution of the dynamic complex network. For some TVG
scenarios, however, more important than identifying the central nodes under a
given node centrality definition is identifying the key time instants for
taking certain actions. In this paper, we thus introduce and investigate the
notion of time centrality in TVGs. Analogously to node centrality, time
centrality evaluates the relative importance of time instants in dynamic
complex networks. In this context, we present two time centrality metrics
related to diffusion processes. We evaluate the two defined metrics using both
a real-world dataset representing an in-person contact dynamic network and a
synthetically generated randomized TVG. We validate the concept of time
centrality showing that diffusion starting at the best classified time instants
(i.e. the most central ones), according to our metrics, can perform a faster
and more efficient diffusion process.
</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:date>2015-09-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00241</dc:identifier>
 <dc:identifier>Advances in Complex Systems (ACS), vol. 18, no. 07n08, November &amp;
  December 2015</dc:identifier>
 <dc:identifier>doi:10.1142/S021952591550023X</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00247</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Overlapping Community Structure in Co-authorship Networks: a Case Study</dc:title>
 <dc:creator>Jebabli, Malek</dc:creator>
 <dc:creator>Cherifi, Hocine</dc:creator>
 <dc:creator>Cherifi, Chantal</dc:creator>
 <dc:creator>Hamouda, Atef</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Community structure is one of the key properties of real-world complex
networks. It plays a crucial role in their behaviors and topology. While an
important work has been done on the issue of community detection, very little
attention has been devoted to the analysis of the community structure. In this
paper, we present an extensive investigation of the overlapping community
network deduced from a large-scale co-authorship network. The nodes of the
overlapping community network represent the functional communities of the
co-authorship network, and the links account for the fact that communities
share some nodes in the co-authorship network. The comparative evaluation of
the topological properties of these two networks shows that they share similar
topological properties. These results are very interesting. Indeed, the network
of communities seems to be a good representative of the original co-authorship
network. With its smaller size, it may be more practical in order to realize
various analyses that cannot be performed easily in large-scale real-world
networks.
</dc:description>
 <dc:description>Comment: 2014 7th International Conference on u- and e- Service, Science and
  Technology</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00249</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sense of Community: How Important is this Quality in Blended Courses</dc:title>
 <dc:creator>Tayebinik, Maryam</dc:creator>
 <dc:creator>Puteh, Marlia</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Combining online classes with the traditional classes foster the advantages
of both learning environments.The aim of this study was to examine the effects
of integrating face to face classes in fully online courses.Forty eight
undergraduate students studying at the e-learning center of a public university
in Iran were the subjects of this study.They were required to provide their
feedback on the inclusion of face to face component in their e-learning
classes.Data collected through open ended questions indicated that the most
dominant outcome of such a hybrid course on the students was the perception on
the sense of community.The findings suggest that students' high satisfaction on
blended learning courses was due to the fact that it promoted their sense of
community.This supports another conclusion of the study that face to face
classes and online classes are complementary and provide a balanced pedagogical
role for each other.
</dc:description>
 <dc:description>Comment: 10 pages, Conference proceeding: Proceeding of the International
  Conference on Education and Management Innovation,2012,Singapore</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00253</identifier>
 <datestamp>2016-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tables of the existence of equiangular tight frames</dc:title>
 <dc:creator>Fickus, Matthew</dc:creator>
 <dc:creator>Mixon, Dustin G.</dc:creator>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A Grassmannian frame is a collection of unit vectors which are optimally
incoherent. To date, the vast majority of explicit Grassmannian frames are
equiangular tight frames (ETFs). This paper surveys every known construction of
ETFs and tabulates existence for sufficiently small dimensions.
</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:date>2016-06-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00253</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00280</identifier>
 <datestamp>2015-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilevel beamforming for high data rate communication in 5G networks</dc:title>
 <dc:creator>Tall, Abdoulaye</dc:creator>
 <dc:creator>Altman, Zwi</dc:creator>
 <dc:creator>Altman, Eitan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Large antenna arrays can be used to generate highly focused beams that
support very high data rates and reduced energy consumption. However, optimal
beam focusing requires large amount of feedback from the users in order to
choose the best beam, especially in Frequency Division Duplex (FDD) mode. This
paper develops a methodology for designing a multilevel codebook of beams in an
environment with low number of multipaths. The antenna design supporting the
focused beams is formulated as an optimization problem. A multilevel codebook
of beams is constructed according to the coverage requirements. An iterative
beam scheduling is proposed that searches through the codebook to select the
best beam for a given user. The methodology is applied to a mass event and to a
rural scenario, both analyzed using an event-based network simulator. Very
significant gains are obtained for both scenarios. It is shown that the more
dominant the Line of Sight (LoS) component, the higher the gain achieved by the
multilevel beamforming.
</dc:description>
 <dc:description>Comment: Orange Labs Report</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:date>2015-10-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00280</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00284</identifier>
 <datestamp>2015-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Vision of Collaborative Active Learning</dc:title>
 <dc:creator>Calma, Adrian</dc:creator>
 <dc:creator>Reitmaier, Tobias</dc:creator>
 <dc:creator>Sick, Bernhard</dc:creator>
 <dc:creator>Lukowicz, Paul</dc:creator>
 <dc:creator>Embrechts, Mark</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Active learning (AL) is a learning paradigm where an active learner has to
train a model (e.g., a classifier) which is in principal trained in a
supervised way, but in AL it has to be done by means of a data set with
initially unlabeled samples. To get labels for these samples, the active
learner has to ask an oracle (e.g., a human expert) for labels. The goal is to
maximize the performance of the model and to minimize the number of queries at
the same time. In this article, we first briefly discuss the state of the art
and own, preliminary work in the field of AL. Then, we propose the concept of
collaborative active learning (CAL). With CAL, we will overcome some of the
harsh limitations of current AL. In particular, we envision scenarios where an
expert may be wrong for various reasons, there might be several or even many
experts with different expertise, the experts may label not only samples but
also knowledge at a higher level such as rules, and we consider that the
labeling costs depend on many conditions. Moreover, in a CAL process human
experts will profit by improving their own knowledge, too.
</dc:description>
 <dc:description>Comment: 16 pages, 6 Figures</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:date>2015-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00284</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00304</identifier>
 <datestamp>2015-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ricci-Ollivier Curvature of the Rooted Phylogenetic
  Subtree-Prune-Regraft Graph</dc:title>
 <dc:creator>Whidden, Chris</dc:creator>
 <dc:creator>Matsen IV, Frederick A.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  Statistical phylogenetic inference methods use tree rearrangement operations
to perform either hill-climbing local search or Markov chain Monte Carlo across
tree topologies. The canonical class of such moves are the
subtree-prune-regraft (SPR) moves that remove a subtree and reattach it
somewhere else via the cut edge of the subtree. Phylogenetic trees and such
moves naturally form the vertices and edges of a graph, such that tree search
algorithms perform a (potentially stochastic) traversal of this SPR graph.
Despite the centrality of such graphs in phylogenetic inference, rather little
is known about their large-scale properties. In this paper we learn about the
rooted-tree version of the graph, known as the rSPR graph, by calculating the
Ricci-Ollivier curvature for pairs of vertices in the rSPR graph with respect
to two simple random walks on the rSPR graph. By proving theorems and direct
calculation with novel algorithms, we find a remarkable diversity of different
curvatures on the rSPR graph for pairs of vertices separated by the same
distance. We confirm using simulation that degree and curvature have the
expected impact on mean access time distributions, demonstrating relevance of
these curvature results to stochastic tree search. This indicates significant
structure of the rSPR graph beyond that which was previously understood in
terms of pairwise distances and vertex degrees; a greater understanding of
curvature could ultimately lead to improved strategies for tree search.
</dc:description>
 <dc:description>Comment: 17 2-column pages, 6 figures, 2 tables. To appear in the Proceedings
  of the Thirteenth Workshop on Analytic Algorithmics and Combinatorics
  (ANALCO)</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:date>2015-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00304</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00305</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Study the effectiveness of genetic algorithm for documentary subject
  search</dc:title>
 <dc:creator>Ivanov, V. K.</dc:creator>
 <dc:creator>Palyukh, B. V.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  This article presents results of experimental studies the effectiveness of
the genetic algorithm that was applied to effective queries creation and
relevant document selection. Studies were carried out to the comparative
analysis of the semantic relevance and quality ranking of the documents found
on the Internet in various ways. Analysis of the results shows that the
greatest effect of presented technology is achieved by finding new documents
for skilled users in the initial stages of the study of the topic.
Additionally, the number of unique and relevant results is significantly
increased.
</dc:description>
 <dc:description>Comment: 7 pages, in Russian</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00305</dc:identifier>
 <dc:identifier>OSTIS-2015 1 (2015) 471-476</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00316</identifier>
 <datestamp>2016-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using IKAROS to provide Scalable I/O bandwidth</dc:title>
 <dc:creator>Filippidis, Christos</dc:creator>
 <dc:creator>Cotronis, Yiannis</dc:creator>
 <dc:creator>Markou, Christos</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We present IKAROS as a utility that permit us to form scalable storage
platforms. IKAROS enable us to create ad-hoc nearby storage formations and use
a huge number of I/O nodes in order to increase the available bandwidth. We
measure the performance and scalability of IKAROS versus the IBMs General
Parallel File System (GPFS) under a variety of conditions. The measurements are
based on benchmark programs that allow us to vary block sizes and to measure
aggregate throughput rates.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the author, it needs more in-depth
  analysis</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:date>2016-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00325</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Microsoft COCO Captions: Data Collection and Evaluation Server</dc:title>
 <dc:creator>Chen, Xinlei</dc:creator>
 <dc:creator>Fang, Hao</dc:creator>
 <dc:creator>Lin, Tsung-Yi</dc:creator>
 <dc:creator>Vedantam, Ramakrishna</dc:creator>
 <dc:creator>Gupta, Saurabh</dc:creator>
 <dc:creator>Dollar, Piotr</dc:creator>
 <dc:creator>Zitnick, C. Lawrence</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper we describe the Microsoft COCO Caption dataset and evaluation
server. When completed, the dataset will contain over one and a half million
captions describing over 330,000 images. For the training and validation
images, five independent human generated captions will be provided. To ensure
consistency in evaluation of automatic caption generation algorithms, an
evaluation server is used. The evaluation server receives candidate captions
and scores them using several popular metrics, including BLEU, METEOR, ROUGE
and CIDEr. Instructions for using the evaluation server are provided.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1411.4952</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00331</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Apache VXQuery: A Scalable XQuery Implementation</dc:title>
 <dc:creator>Carman Jr., E. Preston</dc:creator>
 <dc:creator>Westmann, Till</dc:creator>
 <dc:creator>Borkar, Vinayak R.</dc:creator>
 <dc:creator>Carey, Michael J.</dc:creator>
 <dc:creator>Tsotras, Vassilis J.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The wide use of XML for document management and data exchange has created the
need to query large repositories of XML data. To efficiently query such large
data collections and take advantage of parallelism, we have implemented Apache
VXQuery, an open-source scalable XQuery processor. The system builds upon two
other open-source frameworks -- Hyracks, a parallel execution engine, and
Algebricks, a language agnostic compiler toolbox. Apache VXQuery extends these
two frameworks and provides an implementation of the XQuery specifics (data
model, data-model dependent functions and optimizations, and a parser). We
describe the architecture of Apache VXQuery, its integration with Hyracks and
Algebricks, and the XQuery optimization rules applied to the query plan to
improve path expression efficiency and to enable query parallelism. An
experimental evaluation using a real 500GB dataset with various selection,
aggregation and join XML queries shows that Apache VXQuery performs well both
in terms of scale-up and speed-up. Our experiments show that it is about 3x
faster than Saxon (an open-source and commercial XQuery processor) on a 4-core,
single node implementation, and around 2.5x faster than Apache MRQL (a
MapReduce-based parallel query processor) on an eight (4-core) node cluster.
</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00331</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00337</identifier>
 <datestamp>2016-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding SAT is in P</dc:title>
 <dc:creator>Guinea, Alejandro Sanchez</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We introduce the idea of an understanding with respect to a set of clauses as
a satisfying truth assignment explained by the contexts of the literals in the
clauses. Following this idea, we present a mechanical process that obtains, if
it exists, an understanding with respect to a 3-SAT problem instance based on
the contexts of each literal in the instance, otherwise it determines that none
exists. We demonstrate that our process is correct and efficient in solving
3-SAT.
</dc:description>
 <dc:description>Comment: 10 pages, the paper is completely changed from previous versions
  while the main idea is the same, correctness and time complexity proofs are
  included</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:date>2016-09-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00337</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00341</identifier>
 <datestamp>2015-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A linear time algorithm to compute the impact of all the articulation
  points</dc:title>
 <dc:creator>Farina, Gabriele</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The articulation points of an undirected connected graphs are those vertices
whose removal increases the number of connected components of the graph, i.e.
the vertices whose removal disconnects the graph. However, not all the
articulation points are equal: the removal of some of them might end in a
single vertex disconnected from the graph, whilst in other cases the graph can
be split in several small pieces. In order to measure the effect of the removal
of an articulation point, in \cite{AFL12} has been proposed the impact, defined
as the number of vertices that get disconnected from the main (largest)
surviving connected component (CC). In this paper we present the first linear
time algorithm ($\mathcal{O}(m+n)$ for a graph with $n$ vertices and $m$ edges)
to compute the impact of all the articulation points of the graph, thus
improving from the $\mathcal{O}(a(m+n))\approx\mathcal{O}(nm+n^2)$ of the
na\&quot;ive algorithm, with $a$ being the number of articulation points of the
graph.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures. Accepted for YR-ICALP 2015</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:date>2015-05-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00353</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Latency Software Polar Decoders</dc:title>
 <dc:creator>Giard, Pascal</dc:creator>
 <dc:creator>Sarkis, Gabi</dc:creator>
 <dc:creator>Leroux, Camille</dc:creator>
 <dc:creator>Thibeault, Claude</dc:creator>
 <dc:creator>Gross, Warren J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Polar codes are a new class of capacity-achieving error-correcting codes with
low encoding and decoding complexity. Their low-complexity decoding algorithms
rendering them attractive for use in software-defined radio applications where
computational resources are limited. In this work, we present low-latency
software polar decoders that exploit modern processor capabilities. We show how
adapting the algorithm at various levels can lead to significant improvements
in latency and throughput, yielding polar decoders that are suitable for
high-performance software-defined radio applications on modern desktop
processors and embedded-platform processors. These proposed decoders have an
order of magnitude lower latency and memory footprint compared to
state-of-the-art decoders, while maintaining comparable throughput. In
addition, we present strategies and results for implementing polar decoders on
graphical processing units. Finally, we show that the energy efficiency of the
proposed decoders is comparable to state-of-the-art software polar decoders.
</dc:description>
 <dc:description>Comment: 13 pages, 9 figures, to appear in Springer's Journal of Signal
  Processing Systems</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:date>2016-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00353</dc:identifier>
 <dc:identifier>doi:10.1007/s11265-016-1157-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00377</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Clustering of Shapes of Curves</dc:title>
 <dc:creator>Zhang, Zhengwu</dc:creator>
 <dc:creator>Pati, Debdeep</dc:creator>
 <dc:creator>Srivastava, Anuj</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Unsupervised clustering of curves according to their shapes is an important
problem with broad scientific applications. The existing model-based clustering
techniques either rely on simple probability models (e.g., Gaussian) that are
not generally valid for shape analysis or assume the number of clusters. We
develop an efficient Bayesian method to cluster curve data using an elastic
shape metric that is based on joint registration and comparison of shapes of
curves. The elastic-inner product matrix obtained from the data is modeled
using a Wishart distribution whose parameters are assigned carefully chosen
prior distributions to allow for automatic inference on the number of clusters.
Posterior is sampled through an efficient Markov chain Monte Carlo procedure
based on the Chinese restaurant process to infer (1) the posterior distribution
on the number of clusters, and (2) clustering configuration of shapes. This
method is demonstrated on a variety of synthetic data and real data examples on
protein structure analysis, cell shape analysis in microscopy images, and
clustering of shaped from MPEG7 database.
</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00386</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Signatures of Infinity: Nonergodicity and Resource Scaling in
  Prediction, Complexity, and Learning</dc:title>
 <dc:creator>Crutchfield, James P.</dc:creator>
 <dc:creator>Marzen, Sarah</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce a simple analysis of the structural complexity of
infinite-memory processes built from random samples of stationary, ergodic
finite-memory component processes. Such processes are familiar from the well
known multi-arm Bandit problem. We contrast our analysis with
computation-theoretic and statistical inference approaches to understanding
their complexity. The result is an alternative view of the relationship between
predictability, complexity, and learning that highlights the distinct ways in
which informational and correlational divergences arise in complex ergodic and
nonergodic processes. We draw out consequences for the resource divergences
that delineate the structural hierarchy of ergodic processes and for processes
that are themselves hierarchical.
</dc:description>
 <dc:description>Comment: 8 pages, 1 figure; http://csc.ucdavis.edu/~cmg/compmech/pubs/soi.pdf</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00390</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Blacklisting Memory Scheduler: Balancing Performance, Fairness and
  Complexity</dc:title>
 <dc:creator>Subramanian, Lavanya</dc:creator>
 <dc:creator>Lee, Donghyuk</dc:creator>
 <dc:creator>Seshadri, Vivek</dc:creator>
 <dc:creator>Rastogi, Harsha</dc:creator>
 <dc:creator>Mutlu, Onur</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In a multicore system, applications running on different cores interfere at
main memory. This inter-application interference degrades overall system
performance and unfairly slows down applications. Prior works have developed
application-aware memory schedulers to tackle this problem. State-of-the-art
application-aware memory schedulers prioritize requests of applications that
are vulnerable to interference, by ranking individual applications based on
their memory access characteristics and enforcing a total rank order.
  In this paper, we observe that state-of-the-art application-aware memory
schedulers have two major shortcomings. First, such schedulers trade off
hardware complexity in order to achieve high performance or fairness, since
ranking applications with a total order leads to high hardware complexity.
Second, ranking can unfairly slow down applications that are at the bottom of
the ranking stack. To overcome these shortcomings, we propose the Blacklisting
Memory Scheduler (BLISS), which achieves high system performance and fairness
while incurring low hardware complexity, based on two observations. First, we
find that, to mitigate interference, it is sufficient to separate applications
into only two groups. Second, we show that this grouping can be efficiently
performed by simply counting the number of consecutive requests served from
each application.
  We evaluate BLISS across a wide variety of workloads/system configurations
and compare its performance and hardware complexity, with five state-of-the-art
memory schedulers. Our evaluations show that BLISS achieves 5% better system
performance and 25% better fairness than the best-performing previous scheduler
while greatly reducing critical path latency and hardware area cost of the
memory scheduler (by 79% and 43%, respectively), thereby achieving a good
trade-off between performance, fairness and hardware complexity.
</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00390</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00416</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonnegative Multi-level Network Factorization for Latent Factor Analysis</dc:title>
 <dc:creator>Xuan, Junyu</dc:creator>
 <dc:creator>Lu, Jie</dc:creator>
 <dc:creator>Luo, Xiangfeng</dc:creator>
 <dc:creator>Zhang, Guangquan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Nonnegative Matrix Factorization (NMF) aims to factorize a matrix into two
optimized nonnegative matrices and has been widely used for unsupervised
learning tasks such as product recommendation based on a rating matrix.
However, although networks between nodes with the same nature exist, standard
NMF overlooks them, e.g., the social network between users. This problem leads
to comparatively low recommendation accuracy because these networks are also
reflections of the nature of the nodes, such as the preferences of users in a
social network. Also, social networks, as complex networks, have many different
structures. Each structure is a composition of links between nodes and reflects
the nature of nodes, so retaining the different network structures will lead to
differences in recommendation performance. To investigate the impact of these
network structures on the factorization, this paper proposes four multi-level
network factorization algorithms based on the standard NMF, which integrates
the vertical network (e.g., rating matrix) with the structures of horizontal
network (e.g., user social network). These algorithms are carefully designed
with corresponding convergence proofs to retain four desired network
structures. Experiments on synthetic data show that the proposed algorithms are
able to preserve the desired network structures as designed. Experiments on
real-world data show that considering the horizontal networks improves the
accuracy of document clustering and recommendation with standard NMF, and
various structures show their differences in performance on these two tasks.
These results can be directly used in document clustering and recommendation
systems.
</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00427</identifier>
 <datestamp>2016-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Influence Maximization under The Non-progressive Linear Threshold Model</dc:title>
 <dc:creator>Chan, T. -H. Hubert</dc:creator>
 <dc:creator>Ning, Li</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In the problem of influence maximization in information networks, the
objective is to choose a set of initially active nodes subject to some budget
constraints such that the expected number of active nodes over time is
maximized. The linear threshold model has been introduced to study the opinion
cascading behavior, for instance, the spread of products and innovations. In
this paper, we we extends the classic linear threshold model [18] to capture
the non-progressive be- havior. The information maximization problem under our
model is proved to be NP-Hard, even for the case when the underlying network
has no directed cycles. The first result of this paper is negative. In general,
the objective function of the extended linear threshold model is no longer
submodular, and hence the hill climbing approach that is commonly used in the
existing studies is not applicable. Next, as the main result of this paper, we
prove that if the underlying information network is directed acyclic, the
objective function is submodular (and monotone). Therefore, in directed acyclic
networks with a specified budget we can achieve 1/2 -approximation on
maximizing the number of active nodes over a certain period of time by a
deterministic algorithm, and achieve the (1 - 1/e )-approximation by a
randomized algorithm.
</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00427</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00429</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gradual Release of Sensitive Data under Differential Privacy</dc:title>
 <dc:creator>Koufogiannis, Fragkiskos</dc:creator>
 <dc:creator>Han, Shuo</dc:creator>
 <dc:creator>Pappas, George J.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We introduce the problem of releasing sensitive data under differential
privacy when the privacy level is subject to change over time. Existing work
assumes that privacy level is determined by the system designer as a fixed
value before sensitive data is released. For certain applications, however,
users may wish to relax the privacy level for subsequent releases of the same
data after either a re-evaluation of the privacy concerns or the need for
better accuracy. Specifically, given a database containing sensitive data, we
assume that a response $y_1$ that preserves $\epsilon_{1}$-differential privacy
has already been published. Then, the privacy level is relaxed to $\epsilon_2$,
with $\epsilon_2 &gt; \epsilon_1$, and we wish to publish a more accurate response
$y_2$ while the joint response $(y_1, y_2)$ preserves $\epsilon_2$-differential
privacy. How much accuracy is lost in the scenario of gradually releasing two
responses $y_1$ and $y_2$ compared to the scenario of releasing a single
response that is $\epsilon_{2}$-differentially private? Our results show that
there exists a composite mechanism that achieves \textit{no loss} in accuracy.
We consider the case in which the private data lies within $\mathbb{R}^{n}$
with an adjacency relation induced by the $\ell_{1}$-norm, and we focus on
mechanisms that approximate identity queries. We show that the same accuracy
can be achieved in the case of gradual release through a mechanism whose
outputs can be described by a \textit{lazy Markov stochastic process}. This
stochastic process has a closed form expression and can be efficiently sampled.
Our results are applicable beyond identity queries. To this end, we demonstrate
that our results can be applied in several cases, including Google's RAPPOR
project, trading of sensitive data, and controlled transmission of private data
in a social network.
</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00429</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00430</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Direct l_(2,p)-Norm Learning for Feature Selection</dc:title>
 <dc:creator>Peng, Hanyang</dc:creator>
 <dc:creator>Fan, Yong</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a novel sparse learning based feature selection
method that directly optimizes a large margin linear classification model
sparsity with l_(2,p)-norm (0 &lt; p &lt; 1)subject to data-fitting constraints,
rather than using the sparsity as a regularization term. To solve the direct
sparsity optimization problem that is non-smooth and non-convex when 0&lt;p&lt;1, we
provide an efficient iterative algorithm with proved convergence by converting
it to a convex and smooth optimization problem at every iteration step. The
proposed algorithm has been evaluated based on publicly available datasets, and
extensive comparison experiments have demonstrated that our algorithm could
achieve feature selection performance competitive to state-of-the-art
algorithms.
</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00430</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00434</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coordinated Multi-cell Beamforming for Massive MIMO: A Random Matrix
  Approach</dc:title>
 <dc:creator>Lakshminarayana, Subhash</dc:creator>
 <dc:creator>Assaad, Mohamad</dc:creator>
 <dc:creator>Debbah, Merouane</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of coordinated multi- cell downlink beamforming in
massive multiple input multiple output (MIMO) systems consisting of N cells, Nt
antennas per base station (BS) and K user terminals (UTs) per cell.
Specifically, we formulate a multi-cell beamforming algorithm for massive MIMO
systems which requires limited amount of information exchange between the BSs.
The design objective is to minimize the aggregate transmit power across all the
BSs subject to satisfying the user signal to interference noise ratio (SINR)
constraints. The algorithm requires the BSs to exchange parameters which can be
computed solely based on the channel statistics rather than the instantaneous
CSI. We make use of tools from random matrix theory to formulate the
decentralized algorithm. We also characterize a lower bound on the set of
target SINR values for which the decentralized multi-cell beamforming algorithm
is feasible. We further show that the performance of our algorithm
asymptotically matches the performance of the centralized algorithm with full
CSI sharing. While the original result focuses on minimizing the aggregate
transmit power across all the BSs, we formulate a heuristic extension of this
algorithm to incorporate a practical constraint in multi-cell systems, namely
the individual BS transmit power constraints. Finally, we investigate the
impact of imperfect CSI and pilot contamination effect on the performance of
the decentralized algorithm, and propose a heuristic extension of the algorithm
to accommodate these issues. Simulation results illustrate that our algorithm
closely satisfies the target SINR constraints and achieves minimum power in the
regime of massive MIMO systems. In addition, it also provides substantial power
savings as compared to zero-forcing beamforming when the number of antennas per
BS is of the same orders of magnitude as the number of UTs per cell.
</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00434</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00442</identifier>
 <datestamp>2015-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Refuting Unique Game Conjecture</dc:title>
 <dc:creator>Cui, Peng</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  In this short note, the author shows that the gap problem of some $k$-CSPs
with the support of its predicate the ground of a balanced pairwise independent
distribution can be solved by a modified version of Hast's Algorithm BiLin that
calls Charikar\&amp;Wirth's SDP algorithm for two rounds in polynomial time, when
$k$ is sufficiently large, the support of its predicate is combined by the
grounds of three biased homogeneous distributions and the three biases satisfy
certain conditions. To conclude, the author refutes Unique Game Conjecture,
assuming $P\ne NP$.
</dc:description>
 <dc:description>Comment: 6 pages, short note. arXiv admin note: substantial text overlap with
  arXiv:1401.6520</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:date>2015-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00442</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00450</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recent Development in Analog Computation - A Brief Overview</dc:title>
 <dc:creator>Xue, Yang</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  The recent development in analog computation is reviewed in this paper.
Analog computation was used in many applications where power and energy
efficiency is of paramount importance. It is shown that by using innovative
architecture and circuit design, analog computation systems can achieve much
higher energy efficiency than their digital counterparts, as they are able to
exploit the computational power inherent to the devices and physics. However,
these systems do suffer from some disadvantages, such as lower accuracy and
speed, and designers have come up with novel approaches to overcome them. The
paper provides an overview of analog computation systems, from basic components
such as memory and arithmetic elements, to architecture and system design.
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00450</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00457</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-automatic identification of counterfeit offers in online shopping
  platforms</dc:title>
 <dc:creator>Wartner, Christian</dc:creator>
 <dc:creator>Arnold, Patrick</dc:creator>
 <dc:creator>Rahm, Erhard</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Product counterfeiting is a serious problem causing the industry estimated
losses of billions of dollars every year. With the increasing spread of
e-commerce, the number of counterfeit products sold online increased
substantially. We propose the adoption of a semi-automatic workflow to identify
likely counterfeit offers in online platforms and to present these offers to a
domain expert for manual verification. The workflow includes steps to generate
search queries for relevant product offers, to match and cluster similar
product offers, and to assess the counterfeit suspiciousness based on different
criteria. The goal is to support the periodic identification of many
counterfeit offers with a limited amount of manual effort. We explain how the
proposed approach can be realized. We also present a preliminary evaluation of
its most important steps on a case study using the eBay platform.
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00457</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00458</identifier>
 <datestamp>2016-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information cascade on networks</dc:title>
 <dc:creator>Hisakado, Masato</dc:creator>
 <dc:creator>Mori, Shintaro</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this paper, we discuss a voting model by considering three different kinds
of networks: a random graph, the Barab\'{a}si-Albert(BA) model, and a fitness
model. A voting model represents the way in which public perceptions are
conveyed to voters. Our voting model is constructed by using two types of
voters--herders and independents--and two candidates. Independents conduct
voting based on their fundamental values; on the other hand, herders base their
voting on the number of previous votes. Hence, herders vote for the majority
candidates and obtain information relating to previous votes from their
networks. We discuss the difference between the phases on which the networks
depend. Two kinds of phase transitions, an information cascade transition and a
super-normal transition, were identified. The first of these is a transition
between a state in which most voters make the correct choices and a state in
which most of them are wrong. The second is a transition of convergence speed.
The information cascade transition prevails when herder effects are stronger
than the super-normal transition. In the BA and fitness models, the critical
point of the information cascade transition is the same as that of the random
network model. However, the critical point of the super-normal transition
disappears when these two models are used. In conclusion, the influence of
networks is shown to only affect the convergence speed and not the information
cascade transition. We are therefore able to conclude that the influence of
hubs on voters' perceptions is limited.
</dc:description>
 <dc:description>Comment: 31 pages, 7 figures. arXiv admin note: text overlap with
  arXiv:1203.3274</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2015-12-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00458</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2015.12.090</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00474</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identification of highly susceptible individuals in complex networks</dc:title>
 <dc:creator>Tang, Shaoting</dc:creator>
 <dc:creator>Teng, Xian</dc:creator>
 <dc:creator>Pei, Sen</dc:creator>
 <dc:creator>Yan, Shu</dc:creator>
 <dc:creator>Zheng, Zhiming</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Identifying highly susceptible individuals in spreading processes is of great
significance in controlling outbreaks. In this paper, we explore the
susceptibility of people in susceptible-infectious-recovered (SIR) and rumor
spreading dynamics. We first study the impact of community structure on
people's susceptibility. Despite that the community structure can reduce the
infected population given same infection rates, it will not deterministically
affect nodes' susceptibility. We find the susceptibility of individuals is
sensitive to the choice of spreading dynamics. For SIR spreading, since the
susceptibility is highly correlated to nodes' influence, the topological
indicator k-shell can better identify highly susceptible individuals,
outperforming degree, betweenness centrality and PageRank. In contrast, in
rumor spreading model, where nodes' susceptibility and influence have no clear
correlation, degree performs the best among considered topological measures.
Our finding highlights the significance of both topological features and
spreading mechanisms in identifying highly susceptible population.
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2015-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00474</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2015.03.046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00481</identifier>
 <datestamp>2015-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Dissemination Problem in Wireless Networks</dc:title>
 <dc:creator>Kubjas, Ivo</dc:creator>
 <dc:creator>Skachek, Vitaly</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, we formulate and study a data dissemination problem, which can
be viewed as a generalization of the index coding problem and of the data
exchange problem to networks with an arbitrary topology. We define $r$-solvable
networks, in which data dissemination can be achieved in $r &gt; 0$ communications
rounds. We show that the optimum number of transmissions for any one-round
communications scheme is given by the minimum rank of a certain constrained
family of matrices. For a special case of this problem, called bipartite data
dissemination problem, we present lower and upper graph-theoretic bounds on the
optimum number of transmissions. For general $r$-solvable networks, we derive
an upper bound on the minimum number of transmissions in any scheme with $\geq
r$ rounds. We experimentally compare the obtained upper bound to a simple lower
bound.
</dc:description>
 <dc:description>Comment: Notation clarification</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2015-10-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00495</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring the complex pattern of information spreading in online blog
  communities</dc:title>
 <dc:creator>Pei, Sen</dc:creator>
 <dc:creator>Muchnik, Lev</dc:creator>
 <dc:creator>Tang, Shaoting</dc:creator>
 <dc:creator>Zheng, Zhiming</dc:creator>
 <dc:creator>Makse, Hernan A.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Information spreading in online social communities has attracted tremendous
attention due to its utmost practical values in applications. Despite that
several individual-level diffusion data have been investigated, we still lack
the detailed understanding of the spreading pattern of information. Here, by
comparing information flows and social links in a blog community, we find that
the diffusion processes are induced by three different spreading mechanisms:
social spreading, self-promotion and broadcast. Although numerous previous
studies have employed epidemic spreading models to simulate information
diffusion, we observe that such models fail to reproduce the realistic
diffusion pattern. In respect to users behaviors, strikingly, we find that most
users would stick to one specific diffusion mechanism. Moreover, our
observations indicate that the social spreading is not only crucial for the
structure of diffusion trees, but also capable of inducing more subsequent
individuals to acquire the information. Our findings suggest new directions for
modeling of information diffusion in social systems and could inform design of
efficient propagation strategies based on users behaviors.
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00502</identifier>
 <datestamp>2017-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting the Influence of Spreading in Social Networks with Excitable
  Sensor Networks</dc:title>
 <dc:creator>Pei, Sen</dc:creator>
 <dc:creator>Tang, Shaoting</dc:creator>
 <dc:creator>Zheng, Zhiming</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Detecting spreading outbreaks in social networks with sensors is of great
significance in applications. Inspired by the formation mechanism of human's
physical sensations to external stimuli, we propose a new method to detect the
influence of spreading by constructing excitable sensor networks. Exploiting
the amplifying effect of excitable sensor networks, our method can better
detect small-scale spreading processes. At the same time, it can also
distinguish large-scale diffusion instances due to the self-inhibition effect
of excitable elements. Through simulations of diverse spreading dynamics on
typical real-world social networks (facebook, coauthor and email social
networks), we find that the excitable senor networks are capable of detecting
and ranking spreading processes in a much wider range of influence than other
commonly used sensor placement methods, such as random, targeted, acquaintance
and distance strategies. In addition, we validate the efficacy of our method
with diffusion data from a real-world online social system, Twitter. We find
that our method can detect more spreading topics in practice. Our approach
provides a new direction in spreading detection and should be useful for
designing effective detection methods.
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00502</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0124848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00512</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Causality in Event Structures (Technical Report)</dc:title>
 <dc:creator>Arbach, Youssef</dc:creator>
 <dc:creator>Karcher, David</dc:creator>
 <dc:creator>Peters, Kirstin</dc:creator>
 <dc:creator>Nestmann, Uwe</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In [1] we present an extension of Prime Event Structures by a mechanism to
express dynamicity in the causal relation. More precisely we add the
possibility that the occurrence of an event can add or remove causal
dependencies between events and analyse the expressive power of the resulting
Event Structures w.r.t. to some well-known Event Structures from the
literature. This technical report contains some additional information and the
missing proofs of [1].
</dc:description>
 <dc:description>Comment: Proofs and additional information for the FORTE'15 paper 'Dynamic
  Causality in Event Structures'</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00513</identifier>
 <datestamp>2016-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Minimum Wiener Connector</dc:title>
 <dc:creator>Ruchansky, Natali</dc:creator>
 <dc:creator>Bonchi, Francesco</dc:creator>
 <dc:creator>Garcia-Soriano, David</dc:creator>
 <dc:creator>Gullo, Francesco</dc:creator>
 <dc:creator>Kourtellis, Nicolas</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The Wiener index of a graph is the sum of all pairwise shortest-path
distances between its vertices. In this paper we study the novel problem of
finding a minimum Wiener connector: given a connected graph $G=(V,E)$ and a set
$Q\subseteq V$ of query vertices, find a subgraph of $G$ that connects all
query vertices and has minimum Wiener index.
  We show that The Minimum Wiener Connector admits a polynomial-time (albeit
impractical) exact algorithm for the special case where the number of query
vertices is bounded. We show that in general the problem is NP-hard, and has no
PTAS unless $\mathbf{P} = \mathbf{NP}$. Our main contribution is a
constant-factor approximation algorithm running in time
$\widetilde{O}(|Q||E|)$.
  A thorough experimentation on a large variety of real-world graphs confirms
that our method returns smaller and denser solutions than other methods, and
does so by adding to the query set $Q$ a small number of important vertices
(i.e., vertices with high centrality).
</dc:description>
 <dc:description>Comment: Published in Proceedings of the 2015 ACM SIGMOD International
  Conference on Management of Data</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2016-10-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00513</dc:identifier>
 <dc:identifier>doi:10.1145/2723372.2749449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00522</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monte Carlo Localization in Hand-Drawn Maps</dc:title>
 <dc:creator>Behzadian, Bahram</dc:creator>
 <dc:creator>Agarwal, Pratik</dc:creator>
 <dc:creator>Burgard, Wolfram</dc:creator>
 <dc:creator>Tipaldi, Gian Diego</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Robot localization is a one of the most important problems in robotics. Most
of the existing approaches assume that the map of the environment is available
beforehand and focus on accurate metrical localization. In this paper, we
address the localization problem when the map of the environment is not present
beforehand, and the robot relies on a hand-drawn map from a non-expert user. We
addressed this problem by expressing the robot pose in the pixel coordinate and
simultaneously estimate a local deformation of the hand-drawn map. Experiments
show that we are able to localize the robot in the correct room with a
robustness up to 80%
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00523</identifier>
 <datestamp>2015-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Spectral Low Rank Matrix Approximation</dc:title>
 <dc:creator>Ye, Haishan</dc:creator>
 <dc:creator>Zhang, Zhihua</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  First, we extend the results of approximate matrix multiplication from the
Frobenius norm to the spectral norm. Second, We develop a class of fast
approximate generalized linear regression algorithms with respect to the
spectral norm. Finally, We give a fast approximate SVD.
</dc:description>
 <dc:description>Comment: This paper has some error in proof</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2015-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00527</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Functional Programming is Free</dc:title>
 <dc:creator>Sergeraert, Francis</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>14Q20, 55-04</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  A paper has recently been published in SIAM-JC. This paper is faulty: 1) The
standard requirements about the definition of an algorithm are not respected,
2) The main point in the complexity study, namely the functional programming
component, is absent. The Editorial Board of the SIAM JC had been warned a
confirmed publication would be openly commented, it is the role of this text.
</dc:description>
 <dc:description>Comment: 26 pages</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00527</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00532</identifier>
 <datestamp>2015-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A general framework for compressed sensing and parallel MRI using
  annihilating filter based low-rank Hankel matrix</dc:title>
 <dc:creator>Jin, Kyong Hwan</dc:creator>
 <dc:creator>Lee, Dongwook</dc:creator>
 <dc:creator>Ye, Jong Chul</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Parallel MRI (pMRI) and compressed sensing MRI (CS-MRI) have been considered
as two distinct reconstruction problems. Inspired by recent k-space
interpolation methods, an annihilating filter based low-rank Hankel matrix
approach (ALOHA) is proposed as a general framework for sparsity-driven k-space
interpolation method which unifies pMRI and CS-MRI. Specifically, our framework
is based on the fundamental duality between the transform domain sparsity in
the primary space and the low-rankness of weighted Hankel matrix in the
reciprocal space, which converts pMRI and CS-MRI to a k-space interpolation
problem using structured matrix completion. Using theoretical results from the
latest compressed sensing literatures, we showed that the required sampling
rates for ALOHA may achieve the optimal rate. Experimental results with in vivo
data for single/multi-coil imaging as well as dynamic imaging confirmed that
the proposed method outperforms the state-of-the-art pMRI and CS-MRI.
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2015-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00532</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00542</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Composition in the Function-Behaviour-Structure Framework</dc:title>
 <dc:creator>Diertens, Bob</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  We introduce composition in the function-behaviour-structure framework for
design, as described by John Gero, in order to deal with complexity. We do this
by connecting the frameworks for the design of several models, in which one is
constrained by the others. The result is a framework for the design of an
object that supports modularity. This framework can easily be extended for the
design of an object with more than one layer of modularity.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1309.2489</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00542</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00545</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bulk-Parallel Priority Queue in External Memory with STXXL</dc:title>
 <dc:creator>Bingmann, Timo</dc:creator>
 <dc:creator>Keh, Thomas</dc:creator>
 <dc:creator>Sanders, Peter</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>D.4.2</dc:subject>
 <dc:description>  We propose the design and an implementation of a bulk-parallel external
memory priority queue to take advantage of both shared-memory parallelism and
high external memory transfer speeds to parallel disks. To achieve higher
performance by decoupling item insertions and extractions, we offer two
parallelization interfaces: one using &quot;bulk&quot; sequences, the other by defining
&quot;limit&quot; items. In the design, we discuss how to parallelize insertions using
multiple heaps, and how to calculate a dynamic prediction sequence to prefetch
blocks and apply parallel multiway merge for extraction. Our experimental
results show that in the selected benchmarks the priority queue reaches 75% of
the full parallel I/O bandwidth of rotational disks and and 65% of SSDs, or the
speed of sorting in external memory when bounded by computation.
</dc:description>
 <dc:description>Comment: extended version of SEA'15 conference paper</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00545</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00548</identifier>
 <datestamp>2016-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Understand Phrases by Embedding the Dictionary</dc:title>
 <dc:creator>Hill, Felix</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:creator>Korhonen, Anna</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Distributional models that learn rich semantic word representations are a
success story of recent NLP research. However, developing models that learn
useful representations of phrases and sentences has proved far harder. We
propose using the definitions found in everyday dictionaries as a means of
bridging this gap between lexical and phrasal semantics. Neural language
embedding models can be effectively trained to map dictionary definitions
(phrases) to (lexical) representations of the words defined by those
definitions. We present two applications of these architectures: &quot;reverse
dictionaries&quot; that return the name of a concept given a definition or
description and general-knowledge crossword question answerers. On both tasks,
neural language embedding models trained on definitions from a handful of
freely-available lexical resources perform as well or better than existing
commercial systems that rely on significant task-specific engineering. The
results highlight the effectiveness of both neural embedding architectures and
definition-based training for developing models that understand phrases and
sentences.
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2016-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00549</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Situation-Aware Integration and Transmission of Safety Information for
  Smart Railway Vehicles</dc:title>
 <dc:creator>Yeon, Hanul</dc:creator>
 <dc:creator>Har, Dongsoo</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>94A99</dc:subject>
 <dc:description>  Recent trend of railway train development can be characterized in several
aspects : high speed, infortainment, intelligence in driving, and so on. In
particular, trend of high speed in driving is prominent and competition for
high speed amongst several techno-savvy countries is becoming severe. To
achieve high speed, engines or motors are distributed over multiple vehicles of
train to provide increased motive power, while a single engine or motor has
been mostly used for conventional trains. Increased speed and more complicated
powertrain system naturally incur much higher chance of massive accidents. From
this perspective, importance of proactive safety control before accident takes
place cannot be over-emphasized. To implement proactive safety control requires
situation-aware integration and transmission of safety information obtained
from IoT sensors. Types of critical IoT sensors depend on situational
conditions. Thus, integration and transmission of safety information should be
performed with IoT sensors providing the safety information proper for faced
situation. This brief paper is to devise a methodology how to operate IoT
sensor network enabling proactive safety control for railway vehicles and to
propose a queue management based medium access control scheme.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00553</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information-Theoretic Caching: Sequential Coding for Computing</dc:title>
 <dc:creator>Wang, Chien-Yi</dc:creator>
 <dc:creator>Lim, Sung Hoon</dc:creator>
 <dc:creator>Gastpar, Michael</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Under the paradigm of caching, partial data is delivered before the actual
requests of users are known. In this paper, this problem is modeled as a
canonical distributed source coding problem with side information, where the
side information represents the users' requests. For the single-user case, a
single-letter characterization of the optimal rate region is established, and
for several important special cases, closed-form solutions are given, including
the scenario of uniformly distributed user requests. In this case, it is shown
that the optimal caching strategy is closely related to total correlation and
Wyner's common information. Using the insight gained from the single-user case,
three two-user scenarios admitting single-letter characterization are
considered, which draw connections to existing source coding problems in the
literature: the Gray--Wyner system and distributed successive refinement.
Finally, the model studied by Maddah-Ali and Niesen is rephrased to make a
comparison with the considered information-theoretic model. Although the two
caching models have a similar behavior for the single-user case, it is shown
through a two-user example that the two caching models behave differently in
general.
</dc:description>
 <dc:description>Comment: submitted to IEEE Trans. Inf. Theory and presented in part at ISIT
  2015</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2016-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00553</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2016.2604851</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00572</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient indexing of necklaces and irreducible polynomials over finite
  fields</dc:title>
 <dc:creator>Kopparty, Swastik</dc:creator>
 <dc:creator>Kumar, Mrinal</dc:creator>
 <dc:creator>Saks, Michael</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We study the problem of indexing irreducible polynomials over finite fields,
and give the first efficient algorithm for this problem. Specifically, we show
the existence of poly(n, log q)-size circuits that compute a bijection between
{1, ... , |S|} and the set S of all irreducible, monic, univariate polynomials
of degree n over a finite field F_q. This has applications in pseudorandomness,
and answers an open question of Alon, Goldreich, H{\aa}stad and Peralta[AGHP].
  Our approach uses a connection between irreducible polynomials and necklaces
( equivalence classes of strings under cyclic rotation). Along the way, we give
the first efficient algorithm for indexing necklaces of a given length over a
given alphabet, which may be of independent interest.
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00572</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00576</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Method of Constructing Models of Peer to Peer Protocols</dc:title>
 <dc:creator>Demidova, A. V.</dc:creator>
 <dc:creator>Korolkova, A. V.</dc:creator>
 <dc:creator>Kulyabov, D. S.</dc:creator>
 <dc:creator>Sevastyanov, L. A.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The models of peer to peer protocols are presented with the help of one-step
processes. On the basis of this presentation and the method of randomization of
one-step processes described method for constructing models of peer to peer
protocols. As specific implementations of proposed method the models of
FastTrack and Bittorrent protocols are studied.
</dc:description>
 <dc:description>Comment: in Russian; in English</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00576</dc:identifier>
 <dc:identifier>6th International Congress on Ultra Modern Telecommunications and
  Control Systems and Workshops (ICUMT). 2014, IEEE, pp. 557-562</dc:identifier>
 <dc:identifier>doi:10.1109/ICUMT.2014.7002162</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00580</identifier>
 <datestamp>2016-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum image classification using principal component analysis</dc:title>
 <dc:creator>Ostaszewski, Mateusz</dc:creator>
 <dc:creator>Sadowski, Przemys&#x142;aw</dc:creator>
 <dc:creator>Gawron, Piotr</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a novel quantum algorithm for classification of images. The
algorithm is constructed using principal component analysis and von Neuman
quantum measurements. In order to apply the algorithm we present a new quantum
representation of grayscale images.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00580</dc:identifier>
 <dc:identifier>Theoretical and Applied Informatics, Vol. 27, No. 1, pp. 1-12
  (2015)</dc:identifier>
 <dc:identifier>doi:10.20904/271001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00591</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Run Time Approximation of Non-blocking Service Rates for Streaming
  Systems</dc:title>
 <dc:creator>Beard, Jonathan C.</dc:creator>
 <dc:creator>Chamberlain, Roger D.</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Stream processing is a compute paradigm that promises safe and efficient
parallelism. Modern big-data problems are often well suited for stream
processing's throughput-oriented nature. Realization of efficient stream
processing requires monitoring and optimization of multiple communications
links. Most techniques to optimize these links use queueing network models or
network flow models, which require some idea of the actual execution rate of
each independent compute kernel within the system. What we want to know is how
fast can each kernel process data independent of other communicating kernels.
This is known as the &quot;service rate&quot; of the kernel within the queueing
literature. Current approaches to divining service rates are static. Modern
workloads, however, are often dynamic. Shared cloud systems also present
applications with highly dynamic execution environments (multiple users,
hardware migration, etc.). It is therefore desirable to continuously re-tune an
application during run time (online) in response to changing conditions. Our
approach enables online service rate monitoring under most conditions,
obviating the need for reliance on steady state predictions for what are
probably non-steady state phenomena. First, some of the difficulties associated
with online service rate determination are examined. Second, the algorithm to
approximate the online non-blocking service rate is described. Lastly, the
algorithm is implemented within the open source RaftLib framework for
validation using a simple microbenchmark as well as two full streaming
applications.
</dc:description>
 <dc:description>Comment: technical report</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2015-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00591</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00593</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Approximation of the Dissimilarity Projection</dc:title>
 <dc:creator>Olivetti, Emanuele</dc:creator>
 <dc:creator>Nguyen, Thien Bao</dc:creator>
 <dc:creator>Avesani, Paolo</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Diffusion magnetic resonance imaging (dMRI) data allow to reconstruct the 3D
pathways of axons within the white matter of the brain as a tractography. The
analysis of tractographies has drawn attention from the machine learning and
pattern recognition communities providing novel challenges such as finding an
appropriate representation space for the data. Many of the current learning
algorithms require the input to be from a vectorial space. This requirement
contrasts with the intrinsic nature of the tractography because its basic
elements, called streamlines or tracks, have different lengths and different
number of points and for this reason they cannot be directly represented in a
common vectorial space. In this work we propose the adoption of the
dissimilarity representation which is an Euclidean embedding technique defined
by selecting a set of streamlines called prototypes and then mapping any new
streamline to the vector of distances from prototypes. We investigate the
degree of approximation of this projection under different prototype selection
policies and prototype set sizes in order to characterise its use on
tractography data. Additionally we propose the use of a scalable approximation
of the most effective prototype selection policy that provides fast and
accurate dissimilarity approximations of complete tractographies.
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00593</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00596</identifier>
 <datestamp>2015-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extremal properties of flood-filling games</dc:title>
 <dc:creator>Meeks, Kitty</dc:creator>
 <dc:creator>Vu, Dominik K.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  The problem of determining the number of &quot;flooding operations&quot; required to
make a given coloured graph monochromatic in the one-player combinatorial game
Flood-It has been studied extensively from an algorithmic point of view, but
basic questions about the maximum number of moves that might be required in the
worst case remain unanswered. We begin a systematic investigation of such
questions, with the goal of determining, for a given graph, the maximum number
of moves that may be required, taken over all possible colourings. We give two
upper bounds on this quantity for arbitrary graphs, which we show to be tight
for particular classes of graphs, and determine this maximum number of moves
exactly when the underlying graph is a path, cycle, or a blow-up of a path or
cycle.
</dc:description>
 <dc:description>Comment: Discussion of a further open problem added to conclusions section</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2015-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00601</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Oblivious Transfer Protocol with Verification</dc:title>
 <dc:creator>Kak, Subhash</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Although random sequences can be used to generate probability events, they
come with the risk of cheating in an unsupervised situation. In such cases, the
oblivious transfer protocol may be used and this paper presents a variation to
the DH key-exchange to serve as this protocol. A method to verify the
correctness of the procedure, without revealing the random numbers used by the
two parties, is also proposed.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00616</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Methods and Systems for Graph Compression</dc:title>
 <dc:creator>Maneth, Sebastian</dc:creator>
 <dc:creator>Peternek, Fabian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present an informal survey (meant to accompany another paper) on graph
compression methods. We focus on lossless methods, briefly list available
pproaches, and compare them where possible or give some indicators on their
compression ratios. We also mention some relevant results from the field of
lossy compression and algorithms specialized for the use on large graphs. ---
Note: The comparison is by no means complete. This document is a first draft
and will be updated and extended.
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00616</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00619</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Feasibility of Attribute-Based Encryption on Smartphone Devices</dc:title>
 <dc:creator>Ambrosin, Moreno</dc:creator>
 <dc:creator>Conti, Mauro</dc:creator>
 <dc:creator>Dargahi, Tooska</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Attribute-Based Encryption (ABE) is a powerful cryptographic tool that allows
fine-grained access control over data. Due to its features, ABE has been
adopted in several applications, such as encrypted storage or access control
systems. Recently, researchers argued about the non acceptable performance of
ABE when implemented on mobile devices. Indeed, the non feasibility of ABE on
mobile devices would hinder the deployment of novel protocols and
services--that could instead exploit the full potential of such devices.
However, we believe the conclusion of non usability was driven by a not-very
efficient implementation.
  In this paper, we want to shine a light on this concern by studying the
feasibility of applying ABE on smartphone devices. In particular, we
implemented AndrABEn, an ABE library for Android operating system. Our library
is written in the C language and implements two main ABE schemes:
Ciphertext-Policy Attribute-Based Encryption, and Key- Policy Attribute-Based
Encryption. We also run a thorough set of experimental evaluation for AndrABEn,
and compare it with the current state-of-the-art (considering the same
experimental setting). The results confirm the possibility to effectively use
ABE on smartphone devices, requiring an acceptable amount of resources in terms
of computations and energy consumption. Since the current state-of-the-art
claims the non feasibility of ABE on mobile devices, we believe that our study
(together with the AndrABEn library that we made available online) is a key
result that will pave the way for researchers and developers to design and
implement novel protocols and applications for mobile devices.
</dc:description>
 <dc:description>Comment: Accepted at the 1st International Workshop on IoT challenges in
  Mobile and Industrial Systems (IoT-Sys 2015)</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00627</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Inapproximability of Maximum Single-Sink Unsplittable, Priority and
  Confluent Flow Problems</dc:title>
 <dc:creator>Shepherd, F. Bruce</dc:creator>
 <dc:creator>Vetta, Adrian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider single-sink network flow problems. An instance consists of a
capacitated graph (directed or undirected), a sink node $t$ and a set of
demands that we want to send to the sink. Here demand $i$ is located at a node
$s_i$ and requests an amount $d_i$ of flow capacity in order to route
successfully. Two standard objectives are to maximise (i) the number of demands
(cardinality) and (ii) the total demand (throughput) that can be routed subject
to the capacity constraints. Furthermore, we examine these maximisation
problems for three specialised types of network flow: unsplittable, confluent
and priority flows.
  In the {\em unsplittable flow} problem (UFP), we have edge capacities, and
the demand for $s_i$ must be routed on a single path. In the {\em confluent
flow} problem, we have node capacities, and the final flow must induce a tree.
Both of these problems have been studied extensively, primarily in the
single-sink setting. However, most of this work imposed the {\em no-bottleneck
assumption} (that the maximum demand $d_{max}$ is at most the minimum capacity
$u_{min}$). Given the no-bottleneck assumption (NBA), there is a factor
$4.43$-approximation algorithm due to Dinitz et al. for the unsplittable flow
problem. Under the stronger assumption of uniform capacities, there is a factor
$3$-approximation algorithm due to Chen et al. for the confluent flow problem.
However, unlike the UFP, we show that a constant factor approximation algorithm
cannot be obtained for the single-sink confluent flows even {\bf with} the NBA.
  Without NBA, we show that maximum cardinality single-sink UFP is hard to
approximate to within a factor $n^{.5-\epsilon}$ even when all demands lie in a
small interval $[1,1+\Delta]$ where $\Delta&gt;0$ (but has polynomial input size).
This is very sharp since when $\Delta=0$, this becomes a maximum flow problem.
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2015-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00629</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The communication complexity of achieving SK capacity in a class of PIN
  models</dc:title>
 <dc:creator>Mukherjee, Manuj</dc:creator>
 <dc:creator>Kashyap, Navin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The communication complexity of achieving secret key (SK) capacity in the
multiterminal source model of Csisz$\'a$r and Narayan is the minimum rate of
public communication required to generate a maximal-rate SK. It is well known
that the minimum rate of communication for omniscience, denoted by
$R_{\text{CO}}$, is an upper bound on the communication complexity, denoted by
$R_{\text{SK}}$. A source model for which this upper bound is tight is called
$R_{\text{SK}}$-maximal. In this paper, we establish a sufficient condition for
$R_{\text{SK}}$-maximality within the class of pairwise independent network
(PIN) models defined on hypergraphs. This allows us to compute $R_{\text{SK}}$
exactly within the class of PIN models satisfying this condition. On the other
hand, we also provide a counterexample that shows that our condition does not
in general guarantee $R_{\text{SK}}$-maximality for sources beyond PIN models.
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00639</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Green Wireless Power Transfer Networks</dc:title>
 <dc:creator>Liu, Qingzhi</dc:creator>
 <dc:creator>Goli&#x144;ski, Micha&#x142;</dc:creator>
 <dc:creator>Pawe&#x142;czak, Przemys&#x142;aw</dc:creator>
 <dc:creator>Warnier, Martijn</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  A Wireless Power Transfer Network (WPTN) aims to support devices with
cable-less energy on-demand. Unfortunately, wireless power transfer
itself-especially through radio frequency radiation rectification-is fairly
inefficient due to decaying power with distance, antenna polarization, etc.
Consequently, idle charging needs to be minimized to reduce already large costs
of providing energy to the receivers and at the same time reduce the carbon
footprint of WPTNs. In turn, energy saving in a WPTN can be boosted by simply
switching off the energy transmitter when the received energy is too weak for
rectification. Therefore in this paper we propose, and experimentally evaluate,
two &quot;green&quot; protocols for the control plane of static charger/mobile receiver
WPTN aimed at optimizing the charger workflow to make WPTN green. Those
protocols are: 'beaconing', where receivers advertise their presence to WPTN,
and 'probing' exploiting the receiver feedback from WTPN on the level of
received energy. We demonstrate that both protocols reduce the unnecessary WTPN
uptime, however trading it for the reduced energy provision, compared to the
base case of 'WPTN charger always on'. For example, our system (in our
experiments) saves at most approx. 80% of energy and increases 5.5 times the
efficiency with only approx. 17% less energy possibly harvested.
</dc:description>
 <dc:description>Comment: submitted for possible publication.
  http://www.es.ewi.tudelft.nl/reports/ES-2015-01.pdf</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00641</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Probabilistic Theory of Deep Learning</dc:title>
 <dc:creator>Patel, Ankit B.</dc:creator>
 <dc:creator>Nguyen, Tan</dc:creator>
 <dc:creator>Baraniuk, Richard G.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  A grand challenge in machine learning is the development of computational
algorithms that match or outperform humans in perceptual inference tasks that
are complicated by nuisance variation. For instance, visual object recognition
involves the unknown object position, orientation, and scale in object
recognition while speech recognition involves the unknown voice pronunciation,
pitch, and speed. Recently, a new breed of deep learning algorithms have
emerged for high-nuisance inference tasks that routinely yield pattern
recognition systems with near- or super-human capabilities. But a fundamental
question remains: Why do they work? Intuitions abound, but a coherent framework
for understanding, analyzing, and synthesizing deep learning architectures has
remained elusive. We answer this question by developing a new probabilistic
framework for deep learning based on the Deep Rendering Model: a generative
probabilistic model that explicitly captures latent nuisance variation. By
relaxing the generative model to a discriminative one, we can recover two of
the current leading deep learning systems, deep convolutional neural networks
and random decision forests, providing insights into their successes and
shortcomings, as well as a principled route to their improvement.
</dc:description>
 <dc:description>Comment: 56 pages, 6 figures, 2 tables</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00653</identifier>
 <datestamp>2016-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Constrained Clustering: A Generalized Spectral Method</dc:title>
 <dc:creator>Cucuringu, Mihai</dc:creator>
 <dc:creator>Koutis, Ioannis</dc:creator>
 <dc:creator>Chawla, Sanjay</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We present a principled spectral approach to the well-studied constrained
clustering problem. It reduces clustering to a generalized eigenvalue problem
on Laplacians. The method works in nearly-linear time and provides concrete
guarantees for the quality of the clusters, at least for the case of 2-way
partitioning. In practice this translates to a very fast implementation that
consistently outperforms existing spectral approaches. We support this claim
with experiments on various data sets: our approach recovers correct clusters
in examples where previous methods fail, and handles data sets with millions of
data points - two orders of magnitude larger than before.
</dc:description>
 <dc:description>Comment: this paper is superseded by the article &quot;Scalable Constrained
  Clustering: A Generalized Spectral Method&quot; authored by M. Cucuring, I.
  Koutis, S. Chawla, G. Miller and R. Peng</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2016-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00653</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00657</identifier>
 <datestamp>2015-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eliciting Disease Data from Wikipedia Articles</dc:title>
 <dc:creator>Fairchild, Geoffrey</dc:creator>
 <dc:creator>De Silva, Lalindra</dc:creator>
 <dc:creator>Del Valle, Sara Y.</dc:creator>
 <dc:creator>Segre, Alberto M.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  Traditional disease surveillance systems suffer from several disadvantages,
including reporting lags and antiquated technology, that have caused a movement
towards internet-based disease surveillance systems. Internet systems are
particularly attractive for disease outbreaks because they can provide data in
near real-time and can be verified by individuals around the globe. However,
most existing systems have focused on disease monitoring and do not provide a
data repository for policy makers or researchers. In order to fill this gap, we
analyzed Wikipedia article content.
  We demonstrate how a named-entity recognizer can be trained to tag case
counts, death counts, and hospitalization counts in the article narrative that
achieves an F1 score of 0.753. We also show, using the 2014 West African Ebola
virus disease epidemic article as a case study, that there are detailed time
series data that are consistently updated that closely align with ground truth
data.
  We argue that Wikipedia can be used to create the first community-driven
open-source emerging disease detection, monitoring, and repository system.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures, 4 tables, accepted to 2015 ICWSM Wikipedia
  workshop; v2 includes author formatting fixes and a few sentences removed to
  make it 8 pages (although arXiv renders it as 9); v3 uses embedded type 1
  fonts in the figures and title-cases the title (required by AAAI); v4 fixes
  typo in abstract</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2015-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00657</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00680</identifier>
 <datestamp>2016-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Antisocial Behavior in Online Discussion Communities</dc:title>
 <dc:creator>Cheng, Justin</dc:creator>
 <dc:creator>Danescu-Niculescu-Mizil, Cristian</dc:creator>
 <dc:creator>Leskovec, Jure</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  User contributions in the form of posts, comments, and votes are essential to
the success of online communities. However, allowing user participation also
invites undesirable behavior such as trolling. In this paper, we characterize
antisocial behavior in three large online discussion communities by analyzing
users who were banned from these communities. We find that such users tend to
concentrate their efforts in a small number of threads, are more likely to post
irrelevantly, and are more successful at garnering responses from other users.
Studying the evolution of these users from the moment they join a community up
to when they get banned, we find that not only do they write worse than other
users over time, but they also become increasingly less tolerated by the
community. Further, we discover that antisocial behavior is exacerbated when
community feedback is overly harsh. Our analysis also reveals distinct groups
of users with different levels of antisocial behavior that can change over
time. We use these insights to identify antisocial users early on, a task of
high practical importance to community maintainers.
</dc:description>
 <dc:description>Comment: ICWSM 2015</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2016-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00680</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00681</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximation of non-boolean 2CSP</dc:title>
 <dc:creator>Kindler, Guy</dc:creator>
 <dc:creator>Kolla, Alexandra</dc:creator>
 <dc:creator>Trevisan, Luca</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We develop a polynomial time $\Omega\left ( \frac 1R \log R \right)$
approximate algorithm for Max 2CSP-$R$, the problem where we are given a
collection of constraints, each involving two variables, where each variable
ranges over a set of size $R$, and we want to find an assignment to the
variables that maximizes the number of satisfied constraints. Assuming the
Unique Games Conjecture, this is the best possible approximation up to constant
factors.
  Previously, a $1/R$-approximate algorithm was known, based on linear
programming. Our algorithm is based on semidefinite programming (SDP) and on a
novel rounding technique. The SDP that we use has an almost-matching
integrality gap.
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00686</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Cheeger's Inequality and Analysis of Local Graph Partitioning
  using Vertex Expansion and Expansion Profile</dc:title>
 <dc:creator>Kwok, Tsz Chiu</dc:creator>
 <dc:creator>Lau, Lap Chi</dc:creator>
 <dc:creator>Lee, Yin Tat</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We prove two generalizations of the Cheeger's inequality. The first
generalization relates the second eigenvalue to the edge expansion and the
vertex expansion of the graph G, $\lambda_2 = \Omega(\phi^V(G) \phi(G))$, where
$\phi^V(G)$ denotes the robust vertex expansion of G and $\phi(G)$ denotes the
edge expansion of G. The second generalization relates the second eigenvalue to
the edge expansion and the expansion profile of G, for all $k \ge 2$,
$\lambda_2 = \Omega(\phi_k(G) \phi(G) / k)$, where $\phi_k(G)$ denotes the
k-way expansion of G. These show that the spectral partitioning algorithm has
better performance guarantees when $\phi^V(G)$ is large (e.g. planted random
instances) or $\phi_k(G)$ is large (instances with few disjoint non-expanding
sets). Both bounds are tight up to a constant factor.
  Our approach is based on a method to analyze solutions of Laplacian systems,
and this allows us to extend the results to local graph partitioning
algorithms. In particular, we show that our approach can be used to analyze
personal pagerank vectors, and to give a local graph partitioning algorithm for
the small-set expansion problem with performance guarantees similar to the
generalizations of Cheeger's inequality. We also present a spectral approach to
prove similar results for the truncated random walk algorithm. These show that
local graph partitioning algorithms almost match the performance of the
spectral partitioning algorithm, with the additional advantages that they apply
to the small-set expansion problem and their running time could be sublinear.
Our techniques provide common approaches to analyze the spectral partitioning
algorithm and local graph partitioning algorithms.
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00693</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparative Studies of Six Programming Languages</dc:title>
 <dc:creator>Alomari, Zakaria</dc:creator>
 <dc:creator>Halimi, Oualid El</dc:creator>
 <dc:creator>Sivaprasad, Kaushik</dc:creator>
 <dc:creator>Pandit, Chitrang</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Comparison of programming languages is a common topic of discussion among
software engineers. Multiple programming languages are designed, specified, and
implemented every year in order to keep up with the changing programming
paradigms, hardware evolution, etc. In this paper we present a comparative
study between six programming languages: C++, PHP, C#, Java, Python, VB ; These
languages are compared under the characteristics of reusability, reliability,
portability, availability of compilers and tools, readability, efficiency,
familiarity and expressiveness.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1008.3434 by other authors</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00693</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00695</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trading query complexity for sample-based testing and multi-testing
  scalability</dc:title>
 <dc:creator>Fischer, Eldar</dc:creator>
 <dc:creator>Lachish, Oded</dc:creator>
 <dc:creator>Vasudev, Yadu</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We show here that every non-adaptive property testing algorithm making a
constant number of queries, over a fixed alphabet, can be converted to a
sample-based (as per [Goldreich and Ron, 2015]) testing algorithm whose average
number of queries is a fixed, smaller than $1$, power of $n$. Since the query
distribution of the sample-based algorithm is not dependent at all on the
property, or the original algorithm, this has many implications in scenarios
where there are many properties that need to be tested for concurrently, such
as testing (relatively large) unions of properties, or converting a
Merlin-Arthur Proximity proof (as per [Gur and Rothblum, 2013]) to a proper
testing algorithm.
  The proof method involves preparing the original testing algorithm for a
combinatorial analysis, which in turn involves a new result about the existence
of combinatorial structures (essentially generalized sunflowers) that allow the
sample-based tester to replace the original constant query complexity tester.
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00702</identifier>
 <datestamp>2016-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-End Training of Deep Visuomotor Policies</dc:title>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:creator>Finn, Chelsea</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Policy search methods can allow robots to learn control policies for a wide
range of tasks, but practical applications of policy search often require
hand-engineered components for perception, state estimation, and low-level
control. In this paper, we aim to answer the following question: does training
the perception and control systems jointly end-to-end provide better
performance than training each component separately? To this end, we develop a
method that can be used to learn policies that map raw image observations
directly to torques at the robot's motors. The policies are represented by deep
convolutional neural networks (CNNs) with 92,000 parameters, and are trained
using a partially observed guided policy search method, which transforms policy
search into supervised learning, with supervision provided by a simple
trajectory-centric reinforcement learning method. We evaluate our method on a
range of real-world manipulation tasks that require close coordination between
vision and control, such as screwing a cap onto a bottle, and present simulated
comparisons to a range of prior policy search methods.
</dc:description>
 <dc:description>Comment: updating with revisions for JMLR final version</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2016-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00703</identifier>
 <datestamp>2016-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The matching problem has no small symmetric SDP</dc:title>
 <dc:creator>Braun, G&#xe1;bor</dc:creator>
 <dc:creator>Brown-Cohen, Jonah</dc:creator>
 <dc:creator>Huq, Arefin</dc:creator>
 <dc:creator>Pokutta, Sebastian</dc:creator>
 <dc:creator>Raghavendra, Prasad</dc:creator>
 <dc:creator>Roy, Aurko</dc:creator>
 <dc:creator>Weitz, Benjamin</dc:creator>
 <dc:creator>Zink, Daniel</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>68Q17, 68R10</dc:subject>
 <dc:description>  Yannakakis showed that the matching problem does not have a small symmetric
linear program. Rothvo{\ss} recently proved that any, not necessarily
symmetric, linear program also has exponential size. It is natural to ask
whether the matching problem can be expressed compactly in a framework such as
semidefinite programming (SDP) that is more powerful than linear programming
but still allows efficient optimization. We answer this question negatively for
symmetric SDPs: any symmetric SDP for the matching problem has exponential
size.
  We also show that an O(k)-round Lasserre SDP relaxation for the metric
traveling salesperson problem yields at least as good an approximation as any
symmetric SDP relaxation of size $n^k$.
  The key technical ingredient underlying both these results is an upper bound
on the degree needed to derive polynomial identities that hold over the space
of matchings or traveling salesperson tours.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2016-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00703</dc:identifier>
 <dc:identifier>Proceedings of SODA 2016, 1067-1078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00704</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolution of Conversations in the Age of Email Overload</dc:title>
 <dc:creator>Kooti, Farshad</dc:creator>
 <dc:creator>Aiello, Luca Maria</dc:creator>
 <dc:creator>Grbovic, Mihajlo</dc:creator>
 <dc:creator>Lerman, Kristina</dc:creator>
 <dc:creator>Mantrach, Amin</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>H.4.3</dc:subject>
 <dc:description>  Email is a ubiquitous communications tool in the workplace and plays an
important role in social interactions. Previous studies of email were largely
based on surveys and limited to relatively small populations of email users
within organizations. In this paper, we report results of a large-scale study
of more than 2 million users exchanging 16 billion emails over several months.
We quantitatively characterize the replying behavior in conversations within
pairs of users. In particular, we study the time it takes the user to reply to
a received message and the length of the reply sent. We consider a variety of
factors that affect the reply time and length, such as the stage of the
conversation, user demographics, and use of portable devices. In addition, we
study how increasing load affects emailing behavior. We find that as users
receive more email messages in a day, they reply to a smaller fraction of them,
using shorter replies. However, their responsiveness remains intact, and they
may even reply to emails faster. Finally, we predict the time to reply, length
of reply, and whether the reply ends a conversation. We demonstrate
considerable improvement over the baseline in all three prediction tasks,
showing the significant role that the factors that we uncover play, in
determining replying behavior. We rank these factors based on their predictive
power. Our findings have important implications for understanding human
behavior and designing better email management applications for tasks like
ranking unread emails.
</dc:description>
 <dc:description>Comment: 11 page, 24th International World Wide Web Conference</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00704</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00717</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Super-Resolution of Positive Sources: the Discrete Setup</dc:title>
 <dc:creator>Morgenshtern, Veniamin I.</dc:creator>
 <dc:creator>Candes, Emmanuel J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In single-molecule microscopy it is necessary to locate with high precision
point sources from noisy observations of the spectrum of the signal at
frequencies capped by $f_c$, which is just about the frequency of natural
light. This paper rigorously establishes that this super-resolution problem can
be solved via linear programming in a stable manner. We prove that the quality
of the reconstruction crucially depends on the Rayleigh regularity of the
support of the signal; that is, on the maximum number of sources that can occur
within a square of side length about $1/f_c$. The theoretical performance
guarantee is complemented with a converse result showing that our simple convex
program convex is nearly optimal. Finally, numerical experiments illustrate our
methods.
</dc:description>
 <dc:description>Comment: 31 page, 7 figures</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00717</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00719</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rapidly computable viscous friction and no-slip rigid contact models</dc:title>
 <dc:creator>Drumwright, Evan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This article presents computationally efficient algorithms for modeling two
special cases of rigid contact---contact with only viscous friction and contact
without slip---that have particularly useful applications in robotic locomotion
and grasping. Modeling rigid contact with Coulomb friction generally exhibits
$O(n^3)$ expected time complexity in the number of contact points and
$2^{O(n)}$ worst-case complexity. The special cases we consider exhibit $O(m^3
+ m^2n)$ time complexity ($m$ is the number of independent coordinates in the
multi rigid body system) in the expected case and polynomial complexity in the
worst case; thus, asymptotic complexity is no longer driven by number of
contact points (which is conceivably limitless) but instead is more dependent
on the number of bodies in the system (which is often fixed). These special
cases also require considerably fewer constrained nonlinear optimization
variables thus yielding substantial improvements in running time. Finally,
these special cases also afford one other advantage: the nonlinear optimization
problems are numerically easier to solve.
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00719</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00724</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-Driven Approach for Distribution Network Topology Detection</dc:title>
 <dc:creator>Cavraro, Guido</dc:creator>
 <dc:creator>Arghandeh, Reza</dc:creator>
 <dc:creator>von Meier, Alexandra</dc:creator>
 <dc:creator>Poolla, Kameshwar</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper proposes a data-driven approach to detect the switching actions
and topology transitions in distribution networks. It is based on the real time
analysis of time-series voltages measurements. The analysis approach draws on
data from high-precision phasor measurement units ($\mu$PMUs or synchrophasors)
for distribution networks. The key fact is that time-series measurement data
taken from the distribution network has specific patterns representing state
transitions such as topology changes. The proposed algorithm is based on
comparison of actual voltage measurements with a library of signatures derived
from the possible topologies simulation. The IEEE 33-bus model is used for the
algorithm validation.
</dc:description>
 <dc:description>Comment: 5 Pages, Submitted to IEEE PES GM 2015, Denver, CO</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00724</dc:identifier>
 <dc:identifier>doi:10.1109/PESGM.2015.7286490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00736</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Feature Selection with Adaptive Structure Learning</dc:title>
 <dc:creator>Du, Liang</dc:creator>
 <dc:creator>Shen, Yi-Dong</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The problem of feature selection has raised considerable interests in the
past decade. Traditional unsupervised methods select the features which can
faithfully preserve the intrinsic structures of data, where the intrinsic
structures are estimated using all the input features of data. However, the
estimated intrinsic structures are unreliable/inaccurate when the redundant and
noisy features are not removed. Therefore, we face a dilemma here: one need the
true structures of data to identify the informative features, and one need the
informative features to accurately estimate the true structures of data. To
address this, we propose a unified learning framework which performs structure
learning and feature selection simultaneously. The structures are adaptively
learned from the results of feature selection, and the informative features are
reselected to preserve the refined structures of data. By leveraging the
interactions between these two essential tasks, we are able to capture accurate
structures and select more informative features. Experimental results on many
benchmark data sets demonstrate that the proposed method outperforms many state
of the art unsupervised feature selection methods.
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00736</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00744</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Algorithmic Framework for Shape Formation Problems in Self-Organizing
  Particle Systems</dc:title>
 <dc:creator>Derakhshandeh, Zahra</dc:creator>
 <dc:creator>Gmyr, Robert</dc:creator>
 <dc:creator>Richa, Andrea W.</dc:creator>
 <dc:creator>Scheideler, Christian</dc:creator>
 <dc:creator>Strothmann, Thim</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Many proposals have already been made for realizing programmable matter,
ranging from shape-changing molecules, DNA tiles, and synthetic cells to
reconfigurable modular robotics. Envisioning systems of nano-sensors devices,
we are particularly interested in programmable matter consisting of systems of
simple computational elements, called particles, that can establish and release
bonds and can actively move in a self-organized way, and in shape formation
problems relevant for programmable matter in those self-organizing particle
systems (SOPS). In this paper, we present a general algorithmic framework for
shape formation problems in SOPS, and show direct applications of this
framework to the problems of having the particle system self-organize to form a
hexagonal or triangular shape. Our algorithms utilize only local control,
require only constant-size memory particles, and are asymptotically optimal
both in terms of the total number of movements needed to reach the desired
shape configuration.
</dc:description>
 <dc:description>Comment: Corrected typos. Algorithms and results unchanged. arXiv admin note:
  text overlap with arXiv:1503.07991</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00744</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00747</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Software for Wearable Devices: Challenges and Opportunities</dc:title>
 <dc:creator>Jiang, He</dc:creator>
 <dc:creator>Chen, Xin</dc:creator>
 <dc:creator>Zhang, Shuwei</dc:creator>
 <dc:creator>Zhang, Xin</dc:creator>
 <dc:creator>Kong, Weiqiang</dc:creator>
 <dc:creator>Zhang, Tao</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Wearable devices are a new form of mobile computer system that provides
exclusive and user-personalized services. Wearable devices bring new issues and
challenges to computer science and technology. This paper summarizes the
development process and the categories of wearable devices. In addition, we
present new key issues arising in aspects of wearable devices, including
operating systems, database management system, network communication protocol,
application development platform, privacy and security, energy consumption,
human-computer interaction, software engineering, and big data.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, for Compsac 2015</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00757</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Mixed Membership Mallows Models from Pairwise Comparisons</dc:title>
 <dc:creator>Ding, Weicong</dc:creator>
 <dc:creator>Ishwar, Prakash</dc:creator>
 <dc:creator>Saligrama, Venkatesh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a novel parameterized family of Mixed Membership Mallows Models
(M4) to account for variability in pairwise comparisons generated by a
heterogeneous population of noisy and inconsistent users. M4 models individual
preferences as a user-specific probabilistic mixture of shared latent Mallows
components. Our key algorithmic insight for estimation is to establish a
statistical connection between M4 and topic models by viewing pairwise
comparisons as words, and users as documents. This key insight leads us to
explore Mallows components with a separable structure and leverage recent
advances in separable topic discovery. While separability appears to be overly
restrictive, we nevertheless show that it is an inevitable outcome of a
relatively small number of latent Mallows components in a world of large number
of items. We then develop an algorithm based on robust extreme-point
identification of convex polygons to learn the reference rankings, and is
provably consistent with polynomial sample complexity guarantees. We
demonstrate that our new model is empirically competitive with the current
state-of-the-art approaches in predicting real-world preferences.
</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00766</identifier>
 <datestamp>2015-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Every property is testable on a natural class of scale-free multigraphs</dc:title>
 <dc:creator>Ito, Hiro</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we introduce a natural class of multigraphs called
hierarchical-scale-free (HSF) multigraphs, and consider constant-time
testability on the class. We show that a very wide subclass, specifically, that
in which the power-law exponent is greater than two, of HSF is hyperfinite.
Based on this result, an algorithm for a deterministic partitioning oracle can
be constructed. We conclude by showing that every property is constant-time
testable on the above subclass of HSF. This algorithm utilizes findings by
Newman and Sohler of STOC'11. However, their algorithm is based on the
bounded-degree model, while it is known that actual scale-free networks usually
include hubs, which have a very large degree. HSF is based on scale-free
properties and includes such hubs. This is the first universal result of
constant-time testability on the general graph model, and it has the potential
to be applicable on a very wide range of scale-free networks.
</dc:description>
 <dc:description>Comment: 13 pages, one figure. Difference from ver. 1: Definitions of HSF and
  SF become more general. Typos were fixed</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:date>2015-07-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00770</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Power Splitting and Secure Beamforming Design in the
  Wireless-powered Untrusted Relay Networks</dc:title>
 <dc:creator>Zhao, Mingxiong</dc:creator>
 <dc:creator>Feng, Suili</dc:creator>
 <dc:creator>Liu, Yuan</dc:creator>
 <dc:creator>Wang, Xiangfeng</dc:creator>
 <dc:creator>Zhang, Meng</dc:creator>
 <dc:creator>Fu, Hao</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, we maximize the secrecy rate of the wireless-powered untrusted
relay network by jointly designing power splitting (PS) ratio and relay
beamforming with the proposed global optimal algorithm (GOA) and local optimal
algorithm (LOA). Different from the literature, artificial noise (AN) sent by
the destination not only degrades the channel condition of the eavesdropper to
improve the secrecy rate, but also becomes a new source of energy powering the
untrusted relay based on PS. Hence, it is of high economic benefits and
efficiency to take advantage of AN compared with the literature. Simulation
results show that LOA can achieve satisfactory secrecy rate performance
compared with that of GOA, but with less computation time.
</dc:description>
 <dc:description>Comment: Submitted to GlobeCom2015</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00770</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00774</identifier>
 <datestamp>2015-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to solve the cake-cutting problem in sublinear time</dc:title>
 <dc:creator>Ito, Hiro</dc:creator>
 <dc:creator>Ueda, Takahiro</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we show algorithms for solving the cake-cutting problem in
sublinear-time. More specifically, we preassign (simple) fair portions to o(n)
players in o(n)-time, and minimize the damage to the rest of the players. All
currently known algorithms require Omega(n)-time, even when assigning a portion
to just one player, and it is nontrivial to revise these algorithms to run in
$o(n)$-time since many of the remaining players, who have not been asked any
queries, may not be satisfied with the remaining cake. To challenge this
problem, we begin by providing a framework for solving the cake-cutting problem
in sublinear-time. Generally speaking, solving a problem in sublinear-time
requires the use of approximations. However, in our framework, we introduce the
concept of &quot;eps n-victims,&quot; which means that eps n players (victims) may not
get fair portions, where 0&lt; eps =&lt; 1 is an arbitrary constant. In our
framework, an algorithm consists of the following two parts: In the first
(Preassigning) part, it distributes fair portions to r &lt; n players in
o(n)-time. In the second (Completion) part, it distributes fair portions to the
remaining n-r players except for the eps n victims in poly}(n)-time. There are
two variations on the r players in the first part. Specifically, whether they
can or cannot be designated. We will then present algorithms in this framework.
In particular, an O(r/eps)-time algorithm for r =&lt; eps n/127 undesignated
players with eps n-victims, and an O~(r^2/eps)-time algorithm for r =&lt; eps
e^{{sqrt{ln{n}}}/{7}} designated players and eps =&lt; 1/e with eps n-victims are
presented.
</dc:description>
 <dc:description>Comment: 15 pages, no figure</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:date>2015-07-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00774</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00781</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Gram-Charlier A Series based Extended Rule-of-Thumb for Bandwidth
  Selection in Univariate and Multivariate Kernel Density Estimations</dc:title>
 <dc:creator>C, Dharmani Bhaveshkumar</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>11Kxx</dc:subject>
 <dc:subject>I.5.0</dc:subject>
 <dc:description>  The article derives a novel Gram-Charlier A (GCA) Series based Extended
Rule-of-Thumb (ExROT) for bandwidth selection in Kernel Density Estimation
(KDE). There are existing various bandwidth selection rules achieving
minimization of the Asymptotic Mean Integrated Square Error (AMISE) between the
estimated probability density function (PDF) and the actual PDF. The rules
differ in a way to estimate the integration of the squared second order
derivative of an unknown PDF $(f(\cdot))$, identified as the roughness
$R(f''(\cdot))$. The simplest Rule-of-Thumb (ROT) estimates $R(f''(\cdot))$
with an assumption that the density being estimated is Gaussian. Intuitively,
better estimation of $R(f''(\cdot))$ and consequently better bandwidth
selection rules can be derived, if the unknown PDF is approximated through an
infinite series expansion based on a more generalized density assumption. As a
demonstration and verification to this concept, the ExROT derived in the
article uses an extended assumption that the density being estimated is near
Gaussian. This helps use of the GCA expansion as an approximation to the
unknown near Gaussian PDF. The ExROT for univariate KDE is extended to that for
multivariate KDE. The required multivariate AMISE criteria is re-derived using
elementary calculus of several variables, instead of Tensor calculus. The
derivation uses the Kronecker product and the vector differential operator to
achieve the AMISE expression in vector notations. There is also derived ExROT
for kernel based density derivative estimator.
</dc:description>
 <dc:description>Comment: 30 pages</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00781</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00785</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhanced Red-Black-Tree Data Structure for Facilitating the Scheduling
  of Reservations</dc:title>
 <dc:creator>de Assuncao, Marcos Dias</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  This paper details a data structure for managing and scheduling requests for
computing resources of clusters and virtualised infrastructure such as private
clouds. The data structure uses a red-black tree whose nodes represent the
start times and/or completion times of requests. The tree is enhanced by a
double-linked list that facilitates the iteration of nodes once the start time
of a request is determined by using the tree. We describe the data structure
main features, provide an example of use, and discuss experiments that
demonstrate that the average complexity of two operations are often below 10%
of their respective theoretical worst cases.
</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00785</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00788</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Power of Both Choices: Practical Load Balancing for Distributed
  Stream Processing Engines</dc:title>
 <dc:creator>Nasir, Muhammad Anis Uddin</dc:creator>
 <dc:creator>Morales, Gianmarco De Francisci</dc:creator>
 <dc:creator>Garc&#xed;a-Soriano, David</dc:creator>
 <dc:creator>Kourtellis, Nicolas</dc:creator>
 <dc:creator>Serafini, Marco</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We study the problem of load balancing in distributed stream processing
engines, which is exacerbated in the presence of skew. We introduce Partial Key
Grouping (PKG), a new stream partitioning scheme that adapts the classical
&quot;power of two choices&quot; to a distributed streaming setting by leveraging two
novel techniques: key splitting and local load estimation. In so doing, it
achieves better load balancing than key grouping while being more scalable than
shuffle grouping. We test PKG on several large datasets, both real-world and
synthetic. Compared to standard hashing, PKG reduces the load imbalance by up
to several orders of magnitude, and often achieves nearly-perfect load balance.
This result translates into an improvement of up to 60% in throughput and up to
45% in latency when deployed on a real Storm cluster.
</dc:description>
 <dc:description>Comment: 31st IEEE International Conference on Data Engineering (ICDE), 2015</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00788</dc:identifier>
 <dc:identifier>doi:10.1109/ICDE.2015.7113279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00800</identifier>
 <datestamp>2016-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rating alternatives from pairwise comparisons by solving tropical
  optimization problems</dc:title>
 <dc:creator>Krivulin, Nikolai</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>65K10 (Primary), 15A80, 41A50, 90B50, 91B08 (Secondary)</dc:subject>
 <dc:description>  We consider problems of rating alternatives based on their pairwise
comparison under various assumptions, including constraints on the final scores
of alternatives. The problems are formulated in the framework of tropical
mathematics to approximate pairwise comparison matrices by reciprocal matrices
of unit rank, and written in a common form for both multiplicative and additive
comparison scales. To solve the unconstrained and constrained approximation
problems, we apply recent results in tropical optimization, which provide new
complete direct solutions given in a compact vector form. These solutions
extend known results and involve less computational effort. As an illustration,
numerical examples of rating alternatives are presented.
</dc:description>
 <dc:description>Comment: 16 pages. arXiv admin note: substantial text overlap with
  arXiv:1503.04003</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:date>2015-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00800</dc:identifier>
 <dc:identifier>12th Intern. Conf. on Fuzzy Systems and Knowledge Discovery (FSKD
  2015), pp. 162-167. ISBN 978-1-4673-7681-5</dc:identifier>
 <dc:identifier>doi:10.1109/FSKD.2015.7381933</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00802</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Science Gateway for Distributed Multiscale Course Management in
  e-Science and e-Learning - Use Case for Study and Investigation of
  Functionalized Nanomaterials</dc:title>
 <dc:creator>Gordienko, Yuri</dc:creator>
 <dc:creator>Stirenko, Serhii</dc:creator>
 <dc:creator>Gatsenko, Olexandr</dc:creator>
 <dc:creator>Bekenov, Lev</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:description>  The current tendency of human learning and teaching is targeted to
development and integration of digital technologies (like cloud solutions,
mobile technology, learning analytics, big data, augmented reality, natural
interaction technologies, etc.). Our Science Gateway
(http://scigate.imp.kiev.ua) in collaboration with High Performance Computing
Center (http://hpcc.kpi.ua) is aimed on the close cooperation among the main
actors in learning and researching world (teachers, students, scientists,
supporting personnel, volunteers, etc.) with industry and academia to propose
the new frameworks and interoperability requirements for the building blocks of
a digital ecosystem for learning (including informal learning) that develops
and integrates the current and new tools and systems. It is the portal for
management of distributed courses (workflows), tools, resources, and users,
which is constructed on the basis of the Liferay framework and gUSE/WS-PGRADE
technology. It is based on development of multi-level approach (as to
methods/algorithms) for effective study and research through flexible selection
and combination of unified modules (&quot;gaming&quot; with modules as with LEGO-bricks).
It allows us to provide the flexible and adjustable framework with direct
involvement in real-world and scientific use cases motivated by the educational
aims of students and real scientific aims in labs.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, 2 tables. 38th International Convention on
  Information and Communication Technology, Electronics and Microelectronics
  (MIPRO 2015); Distributed Computing, Visualization and Biomedical Engineering
  (DC VIS) May 25-29, 2015 (Opatija, Croatia)</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00802</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00806</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synergy of Volunteer Measurements and Volunteer Computing for Effective
  Data Collecting, Processing, Simulating and Analyzing on a Worldwide Scale</dc:title>
 <dc:creator>Gordienko, Nikita</dc:creator>
 <dc:creator>Lodygensky, Oleg</dc:creator>
 <dc:creator>Fedak, Gilles</dc:creator>
 <dc:creator>Gordienko, Yuri</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Instrumentation and Detectors</dc:subject>
 <dc:description>  The paper concerns the hype idea of &quot;Citizen Science&quot; and the related
paradigm shift: to go from the passive &quot;volunteer computing&quot; to other volunteer
actions like &quot;volunteer measurements&quot; under guidance of scientists. They can be
carried out by ordinary people with standard computing gadgets (smartphone,
tablet, etc.) and the various standard sensors in them. Here the special
attention is paid to the system of volunteer scientific measurements to study
air showers caused by cosmic rays. The technical implementation is based on
integration of data about registered night flashes (by radiometric software) in
shielded camera chip, synchronized time and GPS-data in ordinary gadgets: to
identify night &quot;air showers&quot; of elementary particles; to analyze the frequency
and to map the distribution of &quot;air showers&quot; in the densely populated cities.
The project currently includes the students of the National Technical
University of Ukraine &quot;KPI&quot;, which are compactly located in Kyiv city and
contribute their volunteer measurements. The technology would be very effective
for other applications also, especially if it will be automated (e.g., on the
basis of XtremWeb or/and BOINC technologies for distributed computing) and used
in some small area with many volunteers, e.g. in local communities
(Corporative/Community Crowd Computing).
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures, 1 table. 38th International Convention on
  Information and Communication Technology, Electronics and Microelectronics
  (MIPRO 2015); Distributed Computing, Visualization and Biomedical Engineering
  (DC VIS) May 25-29, 2015 (Opatija, Croatia)</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00806</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00822</identifier>
 <datestamp>2015-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Expander Codes</dc:title>
 <dc:creator>Leverrier, Anthony</dc:creator>
 <dc:creator>Tillich, Jean-Pierre</dc:creator>
 <dc:creator>Z&#xe9;mor, Gilles</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present an efficient decoding algorithm for constant rate quantum
hypergraph-product LDPC codes which provably corrects adversarial errors of
weight $\Omega(\sqrt{n})$ for codes of length $n$. The algorithm runs in time
linear in the number of qubits, which makes its performance the strongest to
date for linear-time decoding of quantum codes. The algorithm relies on
expanding properties, not of the quantum code's factor graph directly, but of
the factor graph of the original classical code it is constructed from.
</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00822</dc:identifier>
 <dc:identifier>2015 IEEE 56th Annual Symposium on Foundations of Computer Science
  (FOCS), pp. 810-824</dc:identifier>
 <dc:identifier>doi:10.1109/FOCS.2015.55</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00825</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ALEA: Fine-grain Energy Profiling with Basic Block Sampling</dc:title>
 <dc:creator>Mukhanov, Lev</dc:creator>
 <dc:creator>Nikolopoulos, Dimitrios S.</dc:creator>
 <dc:creator>de Supinski, Bronis R.</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Energy efficiency is an essential requirement for all contemporary computing
systems. We thus need tools to measure the energy consumption of computing
systems and to understand how workloads affect it. Significant recent research
effort has targeted direct power measurements on production computing systems
using on-board sensors or external instruments. These direct methods have in
turn guided studies of software techniques to reduce energy consumption via
workload allocation and scaling. Unfortunately, direct energy measurements are
hampered by the low power sampling frequency of power sensors. The coarse
granularity of power sensing limits our understanding of how power is allocated
in systems and our ability to optimize energy efficiency via workload
allocation.
  We present ALEA, a tool to measure power and energy consumption at the
granularity of basic blocks, using a probabilistic approach. ALEA provides
fine-grained energy profiling via statistical sampling, which overcomes the
limitations of power sensing instruments. Compared to state-of-the-art energy
measurement tools, ALEA provides finer granularity without sacrificing
accuracy. ALEA achieves low overhead energy measurements with mean error rates
between 1.4% and 3.5% in 14 sequential and parallel benchmarks tested on both
Intel and ARM platforms. The sampling method caps execution time overhead at
approximately 1%. ALEA is thus suitable for online energy monitoring and
optimization. Finally, ALEA is a user-space tool with a portable,
machine-independent sampling method. We demonstrate two use cases of ALEA,
where we reduce the energy consumption of a k-means computational kernel by 37%
and an ocean modelling code by 33%, compared to high-performance execution
baselines, by varying the power optimization strategy between basic blocks.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00832</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Set Covering-based Approximation Algorithm for Delay Constrained Relay
  Node Placement in Wireless Sensor Networks</dc:title>
 <dc:creator>Ma, Chaofan</dc:creator>
 <dc:creator>Liang, Wei</dc:creator>
 <dc:creator>Zheng, Meng</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Communication networks</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:description>  The Delay Constrained Relay Node Placement (DCRNP) problem in Wireless Sensor
Networks (WSNs) aims to deploy minimum relay nodes such that for each sensor
node there is a path connecting this sensor node to the sink without violating
delay constraint. As WSNs are gradually employed in time-critical applications,
the importance of the DCRNP problem becomes noticeable. For the NP-hard nature
of DCRNP problem, an approximation algorithm-Set-Covering-based Relay Node
Placement (SCA) is proposed to solve the DCRNP problem in this paper. The
proposed SCA algorithm deploys relay nodes iteratively from sink to the given
sensor nodes in hops, i.e., in the $k$th iteration SCA deploys relay nodes at
the locations that are $k$ hops apart from the sink. Specifically, in each
iteration, SCA first finds the candidate deployment locations located within 1
hop to the relay nodes and sensor nodes, which have already been connected to
the sink. Then, a subset of these candidate deployment locations, which can
guarantee the existence of paths connecting unconnected sensor nodes to the
sink within delay constraint, is selected to deploy relay nodes based on the
set covering method. As the iteration of SCA algorithm, the sensor nodes are
gradually connected to the sink with satisfying delay constraint.
  The elaborated analysis of the approximation ratio of SCA algorithm is given
out, and we also prove that the SCA is a polynomial time algorithm through
rigorous time complexity analysis. To evaluate the performance of the proposed
SCA algorithm, extensive simulations are implemented, and the simulation
results show that the SCA algorithm can significantly save the deployed relay
nodes comparing to the existing algorithms, i.e., at most 31.48% deployed relay
nodes can be saved due to SCA algorithm.
</dc:description>
 <dc:description>Comment: 11 pages, 12 figures</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00832</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00834</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The complexity of computation in bit streams</dc:title>
 <dc:creator>Clifford, Raphael</dc:creator>
 <dc:creator>Jalsenius, Markus</dc:creator>
 <dc:creator>Sach, Benjamin</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We revisit the complexity of online computation in the cell probe model. We
consider a class of problems where we are first given a fixed pattern or vector
$F$ of $n$ symbols and then one symbol arrives at a time in a stream. After
each symbol has arrived we must output some function of $F$ and the $n$-length
suffix of the arriving stream. Cell probe bounds of $\Omega(\delta\lg{n}/w)$
have previously been shown for both convolution and Hamming distance in this
setting, where $\delta$ is the size of a symbol in bits and
$w\in\Omega(\lg{n})$ is the cell size in bits. However, when $\delta$ is a
constant, as it is in many natural situations, these previous results no longer
give us non-trivial bounds.
  We introduce a new lop-sided information transfer proof technique which
enables us to prove meaningful lower bounds even for constant size input
alphabets. We use our new framework to prove an amortised cell probe lower
bound of $\Omega(\lg^2 n/(w\cdot \lg \lg n))$ time per arriving bit for an
online version of a well studied problem known as pattern matching with address
errors. This is the first non-trivial cell probe lower bound for any online
problem on bit streams that still holds when the cell sizes are large. We also
show the same bound for online convolution conditioned on a new combinatorial
conjecture related to Toeplitz matrices.
</dc:description>
 <dc:description>Comment: 24 pages</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00834</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00847</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Shannon's mutual information of a multiple antenna time and
  frequency dependent channel: an ergodic operator approach</dc:title>
 <dc:creator>Hachem, Walid</dc:creator>
 <dc:creator>Moustakas, Aris</dc:creator>
 <dc:creator>Pastur, Leonid</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:description>  Consider a random non-centered multiple antenna radio transmission channel.
Assume that the deterministic part of the channel is itself frequency
selective, and that the random multipath part is represented by an ergodic
stationary vector process. In the Hilbert space $l^2({\mathbb Z})$, one can
associate to this channel a random ergodic self-adjoint operator having a
so-called Integrated Density of States (IDS). Shannon's mutual information per
receive antenna of this channel coincides then with the integral of a $\log$
function with respect to the IDS. In this paper, it is shown that when the
numbers of antennas at the transmitter and at the receiver tend to infinity at
the same rate, the mutual information per receive antenna tends to a quantity
that can be identified and, in fact, is closely related to that obtained within
the random matrix approach. This result can be obtained by analyzing the
behavior of the Stieltjes transform of the IDS in the regime of the large
numbers of antennas.
</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00847</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00854</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation Evaluation a Monte Carlo study</dc:title>
 <dc:creator>Powers, David M. W.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Over the last decade there has been increasing concern about the biases
embodied in traditional evaluation methods for Natural Language
Processing/Learning, particularly methods borrowed from Information Retrieval.
Without knowledge of the Bias and Prevalence of the contingency being tested,
or equivalently the expectation due to chance, the simple conditional
probabilities Recall, Precision and Accuracy are not meaningful as evaluation
measures, either individually or in combinations such as F-factor. The
existence of bias in NLP measures leads to the 'improvement' of systems by
increasing their bias, such as the practice of improving tagging and parsing
scores by using most common value (e.g. water is always a Noun) rather than the
attempting to discover the correct one. The measures Cohen Kappa and Powers
Informedness are discussed as unbiased alternative to Recall and related to the
psychologically significant measure DeltaP. In this paper we will analyze both
biased and unbiased measures theoretically, characterizing the precise
relationship between all these measures as well as evaluating the evaluation
measures themselves empirically using a Monte Carlo simulation.
</dc:description>
 <dc:description>Comment: 5 pages, 14 Equations, 2 Figures, 1 Table, as submitted to European
  Conference on Artificial Intelligence (shorter version published with 2
  pages, 4 Equations, 0 Figures, 1 Table)</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00854</dc:identifier>
 <dc:identifier>ECAI 2008, pp.843-844</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00874</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Steering state statistics with output feedback</dc:title>
 <dc:creator>Chen, Yongxin</dc:creator>
 <dc:creator>Georgiou, Tryphon T.</dc:creator>
 <dc:creator>Pavon, Michele</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>93E20</dc:subject>
 <dc:description>  Consider a linear stochastic system whose initial state is a random vector
with a specified Gaussian distribution. Such a distribution may represent a
collection of particles abiding by the specified system dynamics. In recent
publications, we have shown that, provided the system is controllable, it is
always possible to steer the state covariance to any specified terminal
Gaussian distribution using state feedback. The purpose of the present work is
to show that, in the case where only partial state observation is available, a
necessary and sufficient condition for being able to steer the system to a
specified terminal Gaussian distribution for the state vector is that the
terminal state covariance be greater (in the positive-definite sense) than the
error covariance of a corresponding Kalman filter.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00874</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00905</identifier>
 <datestamp>2015-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Anomaly Detection Using Semidefinite Programming</dc:title>
 <dc:creator>Lopez, Jose A.</dc:creator>
 <dc:creator>Camps, Octavia</dc:creator>
 <dc:creator>Sznaier, Mario</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a new approach, based on polynomial optimization and the
method of moments, to the problem of anomaly detection. The proposed technique
only requires information about the statistical moments of the normal-state
distribution of the features of interest and compares favorably with existing
approaches (such as Parzen windows and 1-class SVM). In addition, it provides a
succinct description of the normal state. Thus, it leads to a substantial
simplification of the the anomaly detection problem when working with higher
dimensional datasets.
</dc:description>
 <dc:description>Comment: 13 pages, 11 figures</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:date>2015-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00907</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Discretely-Discontinuous Galerkin Coarse Grid for Domain
  Decomposition</dc:title>
 <dc:creator>Edwards, Essex</dc:creator>
 <dc:creator>Bridson, Robert</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65N55</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:description>  We present an algebraic method for constructing a highly effective coarse
grid correction to accelerate domain decomposition. The coarse problem is
constructed from the original matrix and a small set of input vectors that span
a low-degree polynomial space, but no further knowledge of meshes or continuous
functionals is used. We construct a coarse basis by partitioning the problem
into subdomains and using the restriction of each input vector to each
subdomain as its own basis function. This basis resembles a Discontinuous
Galerkin basis on subdomain-sized elements. Constructing the coarse problem by
Galerkin projection, we prove a high-order convergent error bound for the
coarse solutions. Used in a two-level symmetric multiplicative overlapping
Schwarz preconditioner, the resulting conjugate gradient solver shows optimal
scaling. Convergence requires a constant number of iterations, independent of
fine problem size, on a range of scalar and vector-valued second-order and
fourth-order PDEs.
</dc:description>
 <dc:description>Comment: 19 pages, 5 figures</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00907</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00923</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Deep Neural Network for Speaker and Language Recognition</dc:title>
 <dc:creator>Richardson, Fred</dc:creator>
 <dc:creator>Reynolds, Douglas</dc:creator>
 <dc:creator>Dehak, Najim</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Learned feature representations and sub-phoneme posteriors from Deep Neural
Networks (DNNs) have been used separately to produce significant performance
gains for speaker and language recognition tasks. In this work we show how
these gains are possible using a single DNN for both speaker and language
recognition. The unified DNN approach is shown to yield substantial performance
improvements on the the 2013 Domain Adaptation Challenge speaker recognition
task (55% reduction in EER for the out-of-domain condition) and on the NIST
2011 Language Recognition Evaluation (48% reduction in EER for the 30s test
condition).
</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00923</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00931</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Facial Reduction and SDP Methods for Systems of Polynomial Equations</dc:title>
 <dc:creator>Reid, Greg</dc:creator>
 <dc:creator>Wang, Fei</dc:creator>
 <dc:creator>Wolkowicz, Henry</dc:creator>
 <dc:creator>Wu, Wenyuan</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The real radical ideal of a system of polynomials with finitely many complex
roots is generated by a system of real polynomials having only real roots and
free of multiplicities. It is a central object in computational real algebraic
geometry and important as a preconditioner for numerical solvers. Lasserre and
co-workers have shown that the real radical ideal of real polynomial systems
with finitely many real solutions can be determined by a combination of
semi-definite programming (SDP) and geometric involution techniques. A
conjectured extension of such methods to positive dimensional polynomial
systems has been given recently by Ma, Wang and Zhi.
  We show that regularity in the form of the Slater constraint qualification
(strict feasibility) fails for the resulting SDP feasibility problems. Facial
reduction is then a popular technique whereby SDP problems that fail strict
feasibility can be regularized by projecting onto a face of the convex cone of
semi-definite problems.
  In this paper we introduce a framework for combining facial reduction with
such SDP methods for analyzing $0$ and positive dimensional real ideals of real
polynomial systems. The SDP methods are implemented in MATLAB and our geometric
involutive form is implemented in Maple. We use two approaches to find a
feasible moment matrix. We use an interior point method within the CVX package
for MATLAB and also the Douglas-Rachford (DR) projection-reflection method.
  Illustrative examples show the advantages of the DR approach for some
problems over standard interior point methods. We also see the advantage of
facial reduction both in regularizing the problem and also in reducing the
dimension of the moment matrices. Problems requiring more than one facial
reduction are also presented.
</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00931</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00932</identifier>
 <datestamp>2015-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An embedded system for real-time feedback neuroscience experiments</dc:title>
 <dc:creator>de Almeida, Lirio Onofre Baptista</dc:creator>
 <dc:creator>Matias, Paulo</dc:creator>
 <dc:creator>Guariento, Rafael Tuma</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  A complete data acquisition and signal output control system for synchronous
stimuli generation, geared towards in vivo neuroscience experiments, was
developed using the Terasic DE2i-150 board. All emotions and thoughts are an
emergent property of the chemical and electrical activity of neurons. Most of
these cells are regarded as excitable cells (spiking neurons), which produce
temporally localized electric patterns (spikes). Researchers usually consider
that only the instant of occurrence (timestamp) of these spikes encodes
information. Registering neural activity evoked by stimuli demands timing
determinism and data storage capabilities that cannot be met without dedicated
hardware and a hard real-time operational system (RTOS). Indeed, research in
neuroscience usually requires dedicated electronic instrumentation for studies
in neural coding, brain machine interfaces and closed loop in vivo or in vitro
experiments. We developed a complete embedded system solution consisting of a
hardware/software co-design with the Intel Atom processor running a free RTOS
and a FPGA communicating via a PCIe-to-Avalon bridge. Our system is capable of
registering input event timestamps with 1{\mu}s precision and digitally
generating stimuli output in hard real-time. The whole system is controlled by
a Linux-based Graphical User Interface (GUI). Collected results are
simultaneously saved in a local file and broadcasted wirelessly to mobile
device web-browsers in an user-friendly graphic format, enhanced by HTML5
technology. The developed system is low-cost and highly configurable, enabling
various neuroscience experimental setups, while the commercial off-the-shelf
systems have low availability and are less flexible to adapt to specific
experimental configurations.
</dc:description>
 <dc:description>Comment: 17 pages, 11 figures, IV Brazilian Symposium on Computing Systems
  Engineering</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00932</dc:identifier>
 <dc:identifier>doi:10.13140/RG.2.1.4077.7769</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00934</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Orthogonal Multiple Access for Visible Light Communications</dc:title>
 <dc:creator>Marshoud, Hanaa</dc:creator>
 <dc:creator>Kapinas, Vasileios M.</dc:creator>
 <dc:creator>Karagiannidis, George K.</dc:creator>
 <dc:creator>Muhaidat, Sami</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  The main limitation of visible light communication (VLC) is the narrow
modulation bandwidth, which reduces the achievable data rates. In this paper,
we apply the non-orthogonal multiple access (NOMA) scheme to enhance the
achievable throughput in high-rate VLC downlink networks. We first propose a
novel gain ratio power allocation (GRPA) strategy that takes into account the
users' channel conditions to ensure efficient and fair power allocation. Our
results indicate that GRPA significantly enhances system performance compared
to the static power allocation. We also study the effect of tuning the
transmission angles of the light emitting diodes (LEDs) and the field of views
(FOVs) of the receivers, and demonstrate that these parameters can offer new
degrees of freedom to boost NOMA performance. Simulation results reveal that
NOMA is a promising multiple access scheme for the downlink of VLC networks.
</dc:description>
 <dc:description>Comment: Published in IEEE Photonics Technology Letters. 4 pages, 5 figures</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:date>2015-09-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00934</dc:identifier>
 <dc:identifier>IEEE Photonics Technology Letters, vol. 28, no. 1, pp. 51-54, Jan.
  2016</dc:identifier>
 <dc:identifier>doi:10.1109/LPT.2015.2479600</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00941</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple Way to Initialize Recurrent Networks of Rectified Linear Units</dc:title>
 <dc:creator>Le, Quoc V.</dc:creator>
 <dc:creator>Jaitly, Navdeep</dc:creator>
 <dc:creator>Hinton, Geoffrey E.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Learning long term dependencies in recurrent networks is difficult due to
vanishing and exploding gradients. To overcome this difficulty, researchers
have developed sophisticated optimization techniques and network architectures.
In this paper, we propose a simpler solution that use recurrent neural networks
composed of rectified linear units. Key to our solution is the use of the
identity matrix or its scaled version to initialize the recurrent weight
matrix. We find that our solution is comparable to LSTM on our four benchmarks:
two toy problems involving long-range temporal structures, a large language
modeling problem and a benchmark speech recognition problem.
</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00942</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Penetration Testing in Agile Software Development Projects</dc:title>
 <dc:creator>Tomanek, Martin</dc:creator>
 <dc:creator>Klima, Tomas</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Agile development methods are commonly used to iteratively develop the
information systems and they can easily handle ever-changing business
requirements. Scrum is one of the most popular agile software development
frameworks. The popularity is caused by the simplified process framework and
its focus on teamwork. The objective of Scrum is to deliver working software
and demonstrate it to the customer faster and more frequent during the software
development project. However the security requirements for the developing
information systems have often a low priority. This requirements prioritization
issue results in the situations where the solution meets all the business
requirements but it is vulnerable to potential security threats.
  The major benefit of the Scrum framework is the iterative development
approach and the opportunity to automate penetration tests. Therefore the
security vulnerabilities can be discovered and solved more often which will
positively contribute to the overall information system protection against
potential hackers. In this research paper the authors propose how the agile
software development framework Scrum can be enriched by considering the
penetration tests and related security requirements during the software
development lifecycle. Authors apply in this paper the knowledge and expertise
from their previous work focused on development of the new information system
penetration tests methodology PETA with focus on using COBIT 4.1 as the
framework for management of these tests, and on previous work focused on
tailoring the project management framework PRINCE2 with Scrum.
</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00942</dc:identifier>
 <dc:identifier>International Journal on Cryptography and Information Security
  03/2015; 5(1):1-7</dc:identifier>
 <dc:identifier>doi:10.5121/ijcis.2015.5101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00943</identifier>
 <datestamp>2015-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deterministic Relativistic Quantum Bit Commitment</dc:title>
 <dc:creator>Adlam, Emily</dc:creator>
 <dc:creator>Kent, Adrian</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We describe new unconditionally secure bit commitment schemes whose security
is based on Minkowski causality and the monogamy of quantum entanglement. We
first describe an ideal scheme that is purely deterministic, in the sense that
neither party needs to generate any secret randomness at any stage. We also
describe a variant that allows the committer to proceed deterministically,
requires only local randomness generation from the receiver, and allows the
commitment to be verified in the neighbourhood of the unveiling point. We show
that these schemes still offer near-perfect security in the presence of losses
and errors, which can be made perfect if the committer uses an extra single
random secret bit. We discuss scenarios where these advantages are significant.
</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00943</dc:identifier>
 <dc:identifier>Int. J. Quantum Inform. 13, 1550029 (2015)</dc:identifier>
 <dc:identifier>doi:10.1142/S021974991550029X</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00944</identifier>
 <datestamp>2015-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Device-Independent Relativistic Quantum Bit Commitment</dc:title>
 <dc:creator>Adlam, Emily</dc:creator>
 <dc:creator>Kent, Adrian</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We examine the possibility of device-independent relativistic quantum bit
commitment. We note the potential threat of {\it location attacks}, in which
the behaviour of untrusted devices used in relativistic quantum cryptography
depends on their space-time location. We describe relativistic quantum bit
commitment schemes that are immune to these attacks, and show that these
schemes offer device-independent security against hypothetical post-quantum
adversaries subject only to the no-signalling principle. We compare a
relativistic classical bit commitment scheme with similar features, and note
some possible advantages of the quantum schemes.
</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00944</dc:identifier>
 <dc:identifier>Phys. Rev. A 92, 022315 (2015)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevA.92.022315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00948</identifier>
 <datestamp>2015-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Child is Father of the Man: Foresee the Success at the Early Stage</dc:title>
 <dc:creator>Li, Liangyue</dc:creator>
 <dc:creator>Tong, Hanghang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Understanding the dynamic mechanisms that drive the high-impact scientific
work (e.g., research papers, patents) is a long-debated research topic and has
many important implications, ranging from personal career development and
recruitment search, to the jurisdiction of research resources. Recent advances
in characterizing and modeling scientific success have made it possible to
forecast the long-term impact of scientific work, where data mining techniques,
supervised learning in particular, play an essential role. Despite much
progress, several key algorithmic challenges in relation to predicting
long-term scientific impact have largely remained open. In this paper, we
propose a joint predictive model to forecast the long-term scientific impact at
the early stage, which simultaneously addresses a number of these open
challenges, including the scholarly feature design, the non-linearity, the
domain-heterogeneity and dynamics. In particular, we formulate it as a
regularized optimization problem and propose effective and scalable algorithms
to solve it. We perform extensive empirical evaluations on large, real
scholarly data sets to validate the effectiveness and the efficiency of our
method.
</dc:description>
 <dc:description>Comment: Correct some typos in our KDD paper</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:date>2015-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00948</dc:identifier>
 <dc:identifier>doi:10.1145/2783258.2783340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00953</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Outage Analysis of Full-Duplex Architectures in Cellular Networks</dc:title>
 <dc:creator>Psomas, Constantinos</dc:creator>
 <dc:creator>Krikidis, Ioannis</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The implementation of full-duplex (FD) radio in wireless communications is a
potential approach for achieving higher spectral efficiency. A possible
application is its employment in the next generation of cellular networks.
However, the performance of large-scale FD multiuser networks is an area mostly
unexplored. Most of the related work focuses on the performance analysis of
small-scale networks or on loop interference cancellation schemes. In this
paper, we derive the outage probability performance of large-scale FD cellular
networks in the context of two architectures: two-node and three-node. We show
how the performance is affected with respect to the model's parameters and
provide a comparison between the two architectures.
</dc:description>
 <dc:description>Comment: to appear in Proc. IEEE VTC 2015 Spring, Glasgow</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00953</dc:identifier>
 <dc:identifier>doi:10.1109/VTCSpring.2015.7145989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00954</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximately Counting Triangles in Sublinear Time</dc:title>
 <dc:creator>Eden, Talya</dc:creator>
 <dc:creator>Levi, Amit</dc:creator>
 <dc:creator>Ron, Dana</dc:creator>
 <dc:creator>Seshadhri, C.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the problem of estimating the number of triangles in a graph.
This problem has been extensively studied in both theory and practice, but all
existing algorithms read the entire graph. In this work we design a {\em
sublinear-time\/} algorithm for approximating the number of triangles in a
graph, where the algorithm is given query access to the graph. The allowed
queries are degree queries, vertex-pair queries and neighbor queries.
  We show that for any given approximation parameter $0&lt;\epsilon&lt;1$, the
algorithm provides an estimate $\widehat{t}$ such that with high constant
probability, $(1-\epsilon)\cdot t&lt; \widehat{t}&lt;(1+\epsilon)\cdot t$, where $t$
is the number of triangles in the graph $G$. The expected query complexity of
the algorithm is $\!\left(\frac{n}{t^{1/3}} + \min\left\{m,
\frac{m^{3/2}}{t}\right\}\right)\cdot {\rm poly}(\log n, 1/\epsilon)$, where
$n$ is the number of vertices in the graph and $m$ is the number of edges, and
the expected running time is $\!\left(\frac{n}{t^{1/3}} +
\frac{m^{3/2}}{t}\right)\cdot {\rm poly}(\log n, 1/\epsilon)$. We also prove
that $\Omega\!\left(\frac{n}{t^{1/3}} + \min\left\{m,
\frac{m^{3/2}}{t}\right\}\right)$ queries are necessary, thus establishing that
the query complexity of this algorithm is optimal up to polylogarithmic factors
in $n$ (and the dependence on $1/\epsilon$).
</dc:description>
 <dc:description>Comment: To appear in the 56th Annual IEEE Symposium on Foundations of
  Computer Science (FOCS 2015)</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:date>2015-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00954</dc:identifier>
 <dc:identifier>doi:10.1109/FOCS.2015.44</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00976</identifier>
 <datestamp>2015-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convex Denoising using Non-Convex Tight Frame Regularization</dc:title>
 <dc:creator>Parekh, Ankit</dc:creator>
 <dc:creator>Selesnick, Ivan W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper considers the problem of signal denoising using a sparse
tight-frame analysis prior. The L1 norm has been extensively used as a
regularizer to promote sparsity; however, it tends to under-estimate non-zero
values of the underlying signal. To more accurately estimate non-zero values,
we propose the use of a non-convex regularizer, chosen so as to ensure
convexity of the objective function. The convexity of the objective function is
ensured by constraining the parameter of the non-convex penalty. We use ADMM to
obtain a solution and show how to guarantee that ADMM converges to the global
optimum of the objective function. We illustrate the proposed method for 1D and
2D signal denoising.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:date>2015-06-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00976</dc:identifier>
 <dc:identifier>IEEE Signal Processing Letters, 22(10):1786-1790, Oct. 2015</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2015.2432095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00977</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Declaratively solving Google Code Jam problems with Picat</dc:title>
 <dc:creator>Dymchenko, Sergii</dc:creator>
 <dc:creator>Mykhailova, Mariia</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  In this paper we present several examples of solving algorithmic problems
from the Google Code Jam programming contest with Picat programming language
using declarative techniques: constraint logic programming and tabled logic
programming. In some cases the use of Picat simplifies the implementation
compared to conventional imperative programming languages, while in others it
allows to directly convert the problem statement into an efficiently solvable
declarative problem specification without inventing an imperative algorithm.
</dc:description>
 <dc:date>2015-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00977</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-19686-2_4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00981</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ELM-Based Distributed Cooperative Learning Over Networks</dc:title>
 <dc:creator>Ai, Wu</dc:creator>
 <dc:creator>Chen, Weisheng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper investigates distributed cooperative learning algorithms for data
processing in a network setting. Specifically, the extreme learning machine
(ELM) is introduced to train a set of data distributed across several
components, and each component runs a program on a subset of the entire data.
In this scheme, there is no requirement for a fusion center in the network due
to e.g., practical limitations, security, or privacy reasons. We first
reformulate the centralized ELM training problem into a separable form among
nodes with consensus constraints. Then, we solve the equivalent problem using
distributed optimization tools. A new distributed cooperative learning
algorithm based on ELM, called DC-ELM, is proposed. The architecture of this
algorithm differs from that of some existing parallel/distributed ELMs based on
MapReduce or cloud computing. We also present an online version of the proposed
algorithm that can learn data sequentially in a one-by-one or chunk-by-chunk
mode. The novel algorithm is well suited for potential applications such as
artificial intelligence, computational biology, finance, wireless sensor
networks, and so on, involving datasets that are often extremely large,
high-dimensional and located on distributed data sources. We show simulation
results on both synthetic and real-world data sets.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the authors due to the incorrect
  proof of Theorem 2</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:date>2015-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00983</identifier>
 <datestamp>2015-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Localization of Fine-Grained Actions in Videos by Domain
  Transfer from Web Images</dc:title>
 <dc:creator>Sun, Chen</dc:creator>
 <dc:creator>Shetty, Sanketh</dc:creator>
 <dc:creator>Sukthankar, Rahul</dc:creator>
 <dc:creator>Nevatia, Ram</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:description>  We address the problem of fine-grained action localization from temporally
untrimmed web videos. We assume that only weak video-level annotations are
available for training. The goal is to use these weak labels to identify
temporal segments corresponding to the actions, and learn models that
generalize to unconstrained web videos. We find that web images queried by
action names serve as well-localized highlights for many actions, but are
noisily labeled. To solve this problem, we propose a simple yet effective
method that takes weak video labels and noisy image labels as input, and
generates localized action frames as output. This is achieved by cross-domain
transfer between video frames and web images, using pre-trained deep
convolutional neural networks. We then use the localized action frames to train
action recognition models with long short-term memory networks. We collect a
fine-grained sports action data set FGA-240 of more than 130,000 YouTube
videos. It has 240 fine-grained actions under 85 sports activities. Convincing
results are shown on the FGA-240 data set, as well as the THUMOS 2014
localization data set with untrimmed training videos.
</dc:description>
 <dc:description>Comment: Camera ready version for ACM Multimedia 2015</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:date>2015-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00983</dc:identifier>
 <dc:identifier>doi:10.1145/2733373.2806226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.00984</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse regression with highly correlated predictors</dc:title>
 <dc:creator>Ghorbani, Behrooz</dc:creator>
 <dc:creator>Yilmaz, Ozgur</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a linear regression $y=X\beta+u$ where
$X\in\mathbb{\mathbb{{R}}}^{n\times p}$, $p\gg n,$ and $\beta$ is $s$-sparse.
Motivated by examples in financial and economic data, we consider the situation
where $X$ has highly correlated and clustered columns. To perform sparse
recovery in this setting, we introduce the \emph{clustering removal algorithm}
(CRA), that seeks to decrease the correlation in $X$ by removing the cluster
structure without changing the parameter vector $\beta$. We show that as long
as certain assumptions hold about $X$, the decorrelated matrix will satisfy the
restricted isometry property (RIP) with high probability. We also provide
examples of the empirical performance of CRA and compare it with other sparse
recovery techniques.
</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.00984</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01000</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modifying the Yamaguchi Four-Component Decomposition Scattering Powers
  Using a Stochastic Distance</dc:title>
 <dc:creator>Bhattacharya, Avik</dc:creator>
 <dc:creator>Muhuri, Arnab</dc:creator>
 <dc:creator>De, Shaunak</dc:creator>
 <dc:creator>Manickam, Surendar</dc:creator>
 <dc:creator>Frery, Alejandro C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Model-based decompositions have gained considerable attention after the
initial work of Freeman and Durden. This decomposition which assumes the target
to be reflection symmetric was later relaxed in the Yamaguchi et al.
decomposition with the addition of the helix parameter. Since then many
decomposition have been proposed where either the scattering model was modified
to fit the data or the coherency matrix representing the second order
statistics of the full polarimetric data is rotated to fit the scattering
model. In this paper we propose to modify the Yamaguchi four-component
decomposition (Y4O) scattering powers using the concept of statistical
information theory for matrices. In order to achieve this modification we
propose a method to estimate the polarization orientation angle (OA) from
full-polarimetric SAR images using the Hellinger distance. In this method, the
OA is estimated by maximizing the Hellinger distance between the un-rotated and
the rotated $T_{33}$ and the $T_{22}$ components of the coherency matrix
$\mathbf{[T]}$. Then, the powers of the Yamaguchi four-component model-based
decomposition (Y4O) are modified using the maximum relative stochastic distance
between the $T_{33}$ and the $T_{22}$ components of the coherency matrix at the
estimated OA. The results show that the overall double-bounce powers over
rotated urban areas have significantly improved with the reduction of volume
powers. The percentage of pixels with negative powers have also decreased from
the Y4O decomposition. The proposed method is both qualitatively and
quantitatively compared with the results obtained from the Y4O and the Y4R
decompositions for a Radarsat-2 C-band San-Francisco dataset and an UAVSAR
L-band Hayward dataset.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE J-STARS (IEEE Journal of Selected
  Topics in Applied Earth Observations and Remote Sensing)</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01000</dc:identifier>
 <dc:identifier>doi:10.1109/JSTARS.2015.2420683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01002</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Passive Loop Interference Suppression in Large-Scale Full-Duplex
  Cellular Networks</dc:title>
 <dc:creator>Psomas, Constantinos</dc:creator>
 <dc:creator>Krikidis, Ioannis</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Loop interference (LI) in wireless communications, is a notion resulting from
the full-duplex (FD) operation. In a large-scale network, FD also increases the
multiuser interference due to the large number of active wireless links that
exist. Hence, in order to realize the FD potentials, this interference needs to
be restricted. This paper presents a stochastic geometry model of FD cellular
networks where the users and base stations employ directional antennas. Based
on previous experimental results, we model the passive suppression of the LI at
each FD terminal as a function of the angle between the two antennas and show
the significant gains that can be achieved by this method. Together with the
reduction of multiuser interference resulting from antenna directionality, our
model demonstrates that FD can potentially be implemented in large-scale
directional networks.
</dc:description>
 <dc:description>Comment: to appear in Proc. IEEE SPAWC 2015</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:date>2015-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01002</dc:identifier>
 <dc:identifier>doi:10.1109/SPAWC.2015.7227046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01004</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Managing Multi-Granular Linguistic Distribution Assessments in
  Large-Scale Multi-Attribute Group Decision Making</dc:title>
 <dc:creator>Zhang, Zhen</dc:creator>
 <dc:creator>Guo, Chonghui</dc:creator>
 <dc:creator>Mart&#xed;nez, Luis</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Linguistic large-scale group decision making (LGDM) problems are more and
more common nowadays. In such problems a large group of decision makers are
involved in the decision process and elicit linguistic information that are
usually assessed in different linguistic scales with diverse granularity
because of decision makers' distinct knowledge and background. To keep maximum
information in initial stages of the linguistic LGDM problems, the use of
multi-granular linguistic distribution assessments seems a suitable choice,
however to manage such multigranular linguistic distribution assessments, it is
necessary the development of a new linguistic computational approach. In this
paper it is proposed a novel computational model based on the use of extended
linguistic hierarchies, which not only can be used to operate with
multi-granular linguistic distribution assessments, but also can provide
interpretable linguistic results to decision makers. Based on this new
linguistic computational model, an approach to linguistic large-scale
multi-attribute group decision making is proposed and applied to a talent
selection process in universities.
</dc:description>
 <dc:description>Comment: 32 pages</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01013</identifier>
 <datestamp>2016-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient piecewise training of deep structured models for semantic
  segmentation</dc:title>
 <dc:creator>Lin, Guosheng</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Hengel, Anton van dan</dc:creator>
 <dc:creator>Reid, Ian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent advances in semantic image segmentation have mostly been achieved by
training deep convolutional neural networks (CNNs). We show how to improve
semantic segmentation through the use of contextual information; specifically,
we explore `patch-patch' context between image regions, and `patch-background'
context. For learning from the patch-patch context, we formulate Conditional
Random Fields (CRFs) with CNN-based pairwise potential functions to capture
semantic correlations between neighboring patches. Efficient piecewise training
of the proposed deep structured model is then applied to avoid repeated
expensive CRF inference for back propagation. For capturing the
patch-background context, we show that a network design with traditional
multi-scale image input and sliding pyramid pooling is effective for improving
performance. Our experimental results set new state-of-the-art performance on a
number of popular semantic segmentation datasets, including NYUDv2, PASCAL VOC
2012, PASCAL-Context, and SIFT-flow. In particular, we achieve an
intersection-over-union score of 78.0 on the challenging PASCAL VOC 2012
dataset.
</dc:description>
 <dc:description>Comment: Appearing in IEEE Conf. Computer Vision and Pattern Recognition
  (CVPR) 2016</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:date>2016-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01014</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discrete uncertainty principles and sparse signal processing</dc:title>
 <dc:creator>Bandeira, Afonso S.</dc:creator>
 <dc:creator>Lewis, Megan E.</dc:creator>
 <dc:creator>Mixon, Dustin G.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:description>  We develop new discrete uncertainty principles in terms of numerical
sparsity, which is a continuous proxy for the 0-norm. Unlike traditional
sparsity, the continuity of numerical sparsity naturally accommodates functions
which are nearly sparse. After studying these principles and the functions that
achieve exact or near equality in them, we identify certain consequences in a
number of sparse signal processing applications.
</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01018</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A parameter free similarity index based on clustering ability for link
  prediction in complex networks</dc:title>
 <dc:creator>Wu, Zhihao</dc:creator>
 <dc:creator>Lin, Youfang</dc:creator>
 <dc:creator>Zhao, Yao</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Link prediction in complex network based on solely topological information is
a challenging problem. In this paper, we propose a novel similarity index,
which is efficient and parameter free, based on clustering ability. Here
clustering ability is defined as average clustering coefficient of nodes with
the same degree. The motivation of our idea is that common-neighbors are able
to contribute to the likelihood of forming a link because they own some ability
of clustering their neighbors together, and then clustering ability defined
here is a measure for this capacity. Experimental numerical simulations on both
real-world networks and modeled networks demonstrated the high accuracy and
high efficiency of the new similarity index compared with three well-known
common-neighbor based similarity indices: CN, AA and RA.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures. arXiv admin note: text overlap with
  arXiv:0905.3558, arXiv:1010.0725 by other authors</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01019</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Total-Power Capacity of Regular-LDPC Codes with Iterative
  Message-Passing Decoders</dc:title>
 <dc:creator>Ganesan, Karthik</dc:creator>
 <dc:creator>Grover, Pulkit</dc:creator>
 <dc:creator>Rabaey, Jan</dc:creator>
 <dc:creator>Goldsmith, Andrea</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Motivated by recently derived fundamental limits on total (transmit +
decoding) power for coded communication with VLSI decoders, this paper
investigates the scaling behavior of the minimum total power needed to
communicate over AWGN channels as the target bit-error-probability tends to
zero. We focus on regular-LDPC codes and iterative message-passing decoders. We
analyze scaling behavior under two VLSI complexity models of decoding. One
model abstracts power consumed in processing elements (&quot;node model&quot;), and
another abstracts power consumed in wires which connect the processing elements
(&quot;wire model&quot;). We prove that a coding strategy using regular-LDPC codes with
Gallager-B decoding achieves order-optimal scaling of total power under the
node model. However, we also prove that regular-LDPC codes and iterative
message-passing decoders cannot meet existing fundamental limits on total power
under the wire model. Further, if the transmit energy-per-bit is bounded, total
power grows at a rate that is worse than uncoded transmission. Complementing
our theoretical results, we develop detailed physical models of decoding
implementations using post-layout circuit simulations. Our theoretical and
numerical results show that approaching fundamental limits on total power
requires increasing the complexity of both the code design and the
corresponding decoding algorithm as communication distance is increased or
error-probability is lowered.
</dc:description>
 <dc:description>Comment: 21 pages, 6 figures. To appear in JSAC Recent Advances In Capacity
  Approaching Codes</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01020</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Profit Maximizing Prior-free Multi-unit Procurement Auctions with
  Capacitated Sellers</dc:title>
 <dc:creator>Ray, Arupratan</dc:creator>
 <dc:creator>Mandal, Debmalya</dc:creator>
 <dc:creator>Narahari, Y.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  In this paper, we derive bounds for profit maximizing prior-free procurement
auctions where a buyer wishes to procure multiple units of a homogeneous item
from n sellers who are strategic about their per unit valuation. The buyer
earns the profit by reselling these units in an external consumer market. The
paper looks at three scenarios of increasing complexity. First, we look at unit
capacity sellers where per unit valuation is private information of each seller
and the revenue curve is concave. For this setting, we define two benchmarks.
We show that no randomized prior free auction can be constant competitive
against any of these two benchmarks. However, for a lightly constrained
benchmark we design a prior-free auction PEPA (Profit Extracting Procurement
Auction) which is 4-competitive and we show this bound is tight. Second, we
study a setting where the sellers have non-unit capacities that are common
knowledge and derive similar results. In particular, we propose a prior free
auction PEPAC (Profit Extracting Procurement Auction with Capacity) which is
truthful for any concave revenue curve. Third, we obtain results in the
inherently harder bi-dimensional case where per unit valuation as well as
capacities are private information of the sellers. We show that PEPAC is
truthful and constant competitive for the specific case of linear revenue
curves. We believe that this paper represents the first set of results on
single dimensional and bi-dimensional profit maximizing prior-free multi-unit
procurement auctions.
</dc:description>
 <dc:description>Comment: 16 pages, short version of the paper to be published in the
  Proceedings of International Conference on Autonomous Agents and Multiagent
  Systems 2015</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01023</identifier>
 <datestamp>2016-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite element numerical integration for first order approximations on
  multi-core architectures</dc:title>
 <dc:creator>Bana&#x15b;, Krzysztof</dc:creator>
 <dc:creator>Kru&#x17c;el, Filip</dc:creator>
 <dc:creator>Biela&#x144;ski, Jan</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  The paper presents investigations on the implementation and performance of
the finite element numerical integration algorithm for first order
approximations and three processor architectures, popular in scientific
computing, classical CPU, Intel Xeon Phi and NVIDIA Kepler GPU. A unifying
programming model and portable OpenCL implementation is considered for all
architectures. Variations of the algorithm due to different problems solved and
different element types are investigated and several optimizations aimed at
proper optimization and mapping of the algorithm to computer architectures are
demonstrated. Performance models of execution are developed for different
processors and tested in practical experiments. The results show the varying
levels of performance for different architectures, but indicate that the
algorithm can be effectively ported to all of them. The general conclusion is
that the finite element numerical integration can achieve sufficient
performance on different multi- and many-core architectures and should not
become a performance bottleneck for finite element simulation codes. Specific
observations lead to practical advises on how to optimize the kernels and what
performance can be expected for the tested architectures.
</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01023</dc:identifier>
 <dc:identifier>doi:10.1016/j.cma.2016.03.038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01025</identifier>
 <datestamp>2015-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preprint Extending Touch-less Interaction on Vision Based Wearable
  Device</dc:title>
 <dc:creator>Lv, Zhihan</dc:creator>
 <dc:creator>Feng, Liangbing</dc:creator>
 <dc:creator>Feng, Shengzhong</dc:creator>
 <dc:creator>Li, Haibo</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>H.1.2</dc:subject>
 <dc:subject>H.5.1</dc:subject>
 <dc:description>  This is the preprint version of our paper on IEEE Virtual Reality Conference
2015. A touch-less interaction technology on vision based wearable device is
designed and evaluated. Users interact with the application with dynamic
hands/feet gestures in front of the camera. Several proof-of-concept prototypes
with eleven dynamic gestures are developed based on the touch-less interaction.
At last, a comparing user study evaluation is proposed to demonstrate the
usability of the touch-less approach, as well as the impact on user's emotion,
running on a wearable framework or Google Glass.
</dc:description>
 <dc:description>Comment: This is the preprint version of our paper on IEEE Virtual Reality
  Conference 2015</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:date>2015-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01027</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mapeamento Sistematico</dc:title>
 <dc:creator>Santos, Marco</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  A systematic mapping is a way to identify, evaluate and interpret all
relevant research available to a matter of particular research. One of the
reasons for conducting systematic reviews is that it summarizes the existing
evidence regarding treatment or technology [Kitchenham, 2004].
</dc:description>
 <dc:description>Comment: in Portuguese</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01027</dc:identifier>
 <dc:language>pt</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01030</identifier>
 <datestamp>2015-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preprint A Game Based Assistive Tool for Rehabilitation of Dysphonic
  Patients</dc:title>
 <dc:creator>Lv, Zhihan</dc:creator>
 <dc:creator>Esteve, Chantal</dc:creator>
 <dc:creator>Chirivella, Javier</dc:creator>
 <dc:creator>Gagliardo, Pablo</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>I.3.7</dc:subject>
 <dc:subject>H.5.1</dc:subject>
 <dc:description>  This is the preprint version of our paper on 3rd International Workshop on
Virtual and Augmented Assistive Technology (VAAT) at IEEE Virtual Reality 2015
(VR2015). An assistive training tool for rehabilitation of dysphonic patients
is designed and developed according to the practical clinical needs. The
assistive tool employs a space flight game as the attractive logic part, and
microphone arrays as input device, which is getting rid of ambient noise by
setting a specific orientation. The therapist can guide the patient to play the
game as well as the voice training simultaneously side by side, while not
interfere the patient voice. The voice information can be recorded and
extracted for evaluating the long-time rehabilitation progress. This paper
outlines a design science approach for the development of an initial useful
software prototype of such a tool, considering 'Intuitive', 'Entertainment',
'Incentive' as main design factors.
</dc:description>
 <dc:description>Comment: This is the preprint version of our paper on 3rd International
  Workshop on Virtual and Augmented Assistive Technology (VAAT) at IEEE Virtual
  Reality 2015 (VR2015)</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:date>2015-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01033</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Watch and Learn: Optimizing from Revealed Preferences Feedback</dc:title>
 <dc:creator>Roth, Aaron</dc:creator>
 <dc:creator>Ullman, Jonathan</dc:creator>
 <dc:creator>Wu, Zhiwei Steven</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A Stackelberg game is played between a leader and a follower. The leader
first chooses an action, then the follower plays his best response. The goal of
the leader is to pick the action that will maximize his payoff given the
follower's best response. In this paper we present an approach to solving for
the leader's optimal strategy in certain Stackelberg games where the follower's
utility function (and thus the subsequent best response of the follower) is
unknown.
  Stackelberg games capture, for example, the following interaction between a
producer and a consumer. The producer chooses the prices of the goods he
produces, and then a consumer chooses to buy a utility maximizing bundle of
goods. The goal of the seller here is to set prices to maximize his
profit---his revenue, minus the production cost of the purchased bundle. It is
quite natural that the seller in this example should not know the buyer's
utility function. However, he does have access to revealed preference
feedback---he can set prices, and then observe the purchased bundle and his own
profit. We give algorithms for efficiently solving, in terms of both
computational and query complexity, a broad class of Stackelberg games in which
the follower's utility function is unknown, using only &quot;revealed preference&quot;
access to it. This class includes in particular the profit maximization
problem, as well as the optimal tolling problem in nonatomic congestion games,
when the latency functions are unknown. Surprisingly, we are able to solve
these problems even though the optimization problems are non-convex in the
leader's actions.
</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01039</identifier>
 <datestamp>2016-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graphs, Matrices, and the GraphBLAS: Seven Good Reasons</dc:title>
 <dc:creator>Kepner, Jeremy</dc:creator>
 <dc:creator>Bade, David</dc:creator>
 <dc:creator>Buluc, Ayd&#x131;n</dc:creator>
 <dc:creator>Gilbert, John</dc:creator>
 <dc:creator>Mattson, Timothy</dc:creator>
 <dc:creator>Meyerhenke, Henning</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The analysis of graphs has become increasingly important to a wide range of
applications. Graph analysis presents a number of unique challenges in the
areas of (1) software complexity, (2) data complexity, (3) security, (4)
mathematical complexity, (5) theoretical analysis, (6) serial performance, and
(7) parallel performance. Implementing graph algorithms using matrix-based
approaches provides a number of promising solutions to these challenges. The
GraphBLAS standard (istc- bigdata.org/GraphBlas) is being developed to bring
the potential of matrix based graph algorithms to the broadest possible
audience. The GraphBLAS mathematically defines a core set of matrix-based graph
operations that can be used to implement a wide class of graph algorithms in a
wide range of programming environments. This paper provides an introduction to
the GraphBLAS and describes how the GraphBLAS can be used to address many of
the challenges associated with analysis of graphs.
</dc:description>
 <dc:description>Comment: 10 pages; International Conference on Computational Science workshop
  on the Applications of Matrix Computational Methods in the Analysis of Modern
  Data</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01039</dc:identifier>
 <dc:identifier>Procedia Computer Science Volume 51, 2015, Pages 2453-2462,
  International Conference On Computational Science</dc:identifier>
 <dc:identifier>doi:10.1016/j.procs.2015.05.353</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01042</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distributed Secure Outsourcing Scheme for Solving Linear Algebraic
  Equations in Ad Hoc Clouds</dc:title>
 <dc:creator>Shen, Wenlong</dc:creator>
 <dc:creator>Yin, Bo</dc:creator>
 <dc:creator>Cao, Xianghui</dc:creator>
 <dc:creator>Cheng, Yu</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The emerging ad hoc clouds form a new cloud computing paradigm by leveraging
untapped local computation and storage resources. An important application
application over ad hoc clouds is outsourcing computationally intensive
problems to nearby cloud agents to solve in a distributed manner.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the authors due to incompleteness of
  the security analysis</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:date>2016-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01044</identifier>
 <datestamp>2015-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Concept Drift Detection for Streaming Data</dc:title>
 <dc:creator>Wang, Heng</dc:creator>
 <dc:creator>Abraham, Zubin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Common statistical prediction models often require and assume stationarity in
the data. However, in many practical applications, changes in the relationship
of the response and predictor variables are regularly observed over time,
resulting in the deterioration of the predictive performance of these models.
This paper presents Linear Four Rates (LFR), a framework for detecting these
concept drifts and subsequently identifying the data points that belong to the
new concept (for relearning the model). Unlike conventional concept drift
detection approaches, LFR can be applied to both batch and stream data; is not
limited by the distribution properties of the response variable (e.g., datasets
with imbalanced labels); is independent of the underlying statistical-model;
and uses user-specified parameters that are intuitively comprehensible. The
performance of LFR is compared to benchmark approaches using both simulated and
commonly used public datasets that span the gamut of concept drift types. The
results show LFR significantly outperforms benchmark approaches in terms of
recall, accuracy and delay in detection of concept drifts across datasets.
</dc:description>
 <dc:description>Comment: 9 pages, accepted in the International Joint Conference of Neural
  Networks 2015</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:date>2015-05-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01046</identifier>
 <datestamp>2016-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Connectivity in Noisy Sparse Subspace Clustering</dc:title>
 <dc:creator>Wang, Yining</dc:creator>
 <dc:creator>Wang, Yu-Xiang</dc:creator>
 <dc:creator>Singh, Aarti</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Subspace clustering is the problem of clustering data points into a union of
low-dimensional linear/affine subspaces. It is the mathematical abstraction of
many important problems in computer vision, image processing and machine
learning. A line of recent work (4, 19, 24, 20) provided strong theoretical
guarantee for sparse subspace clustering (4), the state-of-the-art algorithm
for subspace clustering, on both noiseless and noisy data sets. It was shown
that under mild conditions, with high probability no two points from different
subspaces are clustered together. Such guarantee, however, is not sufficient
for the clustering to be correct, due to the notorious &quot;graph connectivity
problem&quot; (15). In this paper, we investigate the graph connectivity problem for
noisy sparse subspace clustering and show that a simple post-processing
procedure is capable of delivering consistent clustering under certain &quot;general
position&quot; or &quot;restricted eigenvalue&quot; assumptions. We also show that our
condition is almost tight with adversarial noise perturbation by constructing a
counter-example. These results provide the first exact clustering guarantee of
noisy SSC for subspaces of dimension greater then 3.
</dc:description>
 <dc:description>Comment: 14 pages. To appear in The 19th International Conference on
  Artificial Intelligence and Statistics, held at Cadiz, Spain in 2016</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:date>2016-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01048</identifier>
 <datestamp>2015-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The End of Slow Networks: It's Time for a Redesign</dc:title>
 <dc:creator>Binnig, Carsten</dc:creator>
 <dc:creator>Crotty, Andrew</dc:creator>
 <dc:creator>Galakatos, Alex</dc:creator>
 <dc:creator>Kraska, Tim</dc:creator>
 <dc:creator>Zamanian, Erfan</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Next generation high-performance RDMA-capable networks will require a
fundamental rethinking of the design and architecture of modern distributed
DBMSs. These systems are commonly designed and optimized under the assumption
that the network is the bottleneck: the network is slow and &quot;thin&quot;, and thus
needs to be avoided as much as possible. Yet this assumption no longer holds
true. With InfiniBand FDR 4x, the bandwidth available to transfer data across
network is in the same ballpark as the bandwidth of one memory channel, and it
increases even further with the most recent EDR standard. Moreover, with the
increasing advances of RDMA, the latency improves similarly fast. In this
paper, we first argue that the &quot;old&quot; distributed database design is not capable
of taking full advantage of the network. Second, we propose architectural
redesigns for OLTP, OLAP and advanced analytical frameworks to take better
advantage of the improved bandwidth, latency and RDMA capabilities. Finally,
for each of the workload categories, we show that remarkable performance
improvements can be achieved.
</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:date>2015-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01049</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D visual analysis of seabed on smartphone</dc:title>
 <dc:creator>Lv, Zhihan</dc:creator>
 <dc:creator>Su, Tianyun</dc:creator>
 <dc:creator>Li, Xiaoming</dc:creator>
 <dc:creator>Feng, Shengzhong</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>I.3.7</dc:subject>
 <dc:description>  We create a 'virtual-seabed' platform to realize the 3D visual analysis of
seabed on smartphone. The 3D seabed platform is based on a 'section-drilling'
model, implementing visualization and analysis of the integrated data of seabed
on the 3D browser on smartphone. Some 3D visual analysis functions are
developed. This work presents a thorough and interesting way of presenting
seabed data on smartphone, which raises many application possibilities. This
platform is another practical proof based on our WebVRGIS platform.
</dc:description>
 <dc:description>Comment: 2015 IEEE Pacific Visualization Symposium (PacificVis)</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01050</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Online Approach to Dynamic Channel Access and Transmission Scheduling</dc:title>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:creator>Liu, Mingyan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  Making judicious channel access and transmission scheduling decisions is
essential for improving performance as well as energy and spectral efficiency
in multichannel wireless systems. This problem has been a subject of extensive
study in the past decade, and the resulting dynamic and opportunistic channel
access schemes can bring potentially significant improvement over traditional
schemes. However, a common and severe limitation of these dynamic schemes is
that they almost always require some form of a priori knowledge of the channel
statistics. A natural remedy is a learning framework, which has also been
extensively studied in the same context, but a typical learning algorithm in
this literature seeks only the best static policy, with performance measured by
weak regret, rather than learning a good dynamic channel access policy. There
is thus a clear disconnect between what an optimal channel access policy can
achieve with known channel statistics that actively exploits temporal, spatial
and spectral diversity, and what a typical existing learning algorithm aims
for, which is the static use of a single channel devoid of diversity gain. In
this paper we bridge this gap by designing learning algorithms that track known
optimal or sub-optimal dynamic channel access and transmission scheduling
policies, thereby yielding performance measured by a form of strong regret, the
accumulated difference between the reward returned by an optimal solution when
a priori information is available and that by our online algorithm. We do so in
the context of two specific algorithms that appeared in [1] and [2],
respectively, the former for a multiuser single-channel setting and the latter
for a single-user multichannel setting. In both cases we show that our
algorithms achieve sub-linear regret uniform in time and outperforms the
standard weak-regret learning algorithms.
</dc:description>
 <dc:description>Comment: 10 pages, to appear in MobiHoc 2015</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01051</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WebVRGIS Based City Bigdata 3D Visualization and Analysis</dc:title>
 <dc:creator>Li, Xiaoming</dc:creator>
 <dc:creator>Lv, Zhihan</dc:creator>
 <dc:creator>Zhang, Baoyun</dc:creator>
 <dc:creator>Wang, Weixi</dc:creator>
 <dc:creator>Feng, Shengzhong</dc:creator>
 <dc:creator>Hu, Jinxing</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>I.3.7</dc:subject>
 <dc:description>  This paper shows the WEBVRGIS platform overlying multiple types of data about
Shenzhen over a 3d globe. The amount of information that can be visualized with
this platform is overwhelming, and the GIS-based navigational scheme allows to
have great flexibility to access the different available data sources. For
example,visualising historical and forecasted passenger volume at stations
could be very helpful when overlaid with other social data.
</dc:description>
 <dc:description>Comment: 2015 IEEE Pacific Visualization Symposium (PacificVis)</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01052</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast algorithms for morphological operations using run-length encoded
  binary images</dc:title>
 <dc:creator>Ehrensperger, Gregor</dc:creator>
 <dc:creator>Ostermann, Alexander</dc:creator>
 <dc:creator>Schwitzer, Felix</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A08 (Primary) 65D18, 65D19, 68U10, 94A12 (Secondary)</dc:subject>
 <dc:subject>I.4.3</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:subject>I.4.10</dc:subject>
 <dc:description>  This paper presents innovative algorithms to efficiently compute erosions and
dilations of run-length encoded (RLE) binary images with arbitrary shaped
structuring elements. An RLE image is given by a set of runs, where a run is a
horizontal concatenation of foreground pixels. The proposed algorithms extract
the skeleton of the structuring element and build distance tables of the input
image, which are storing the distance to the next background pixel on the left
and right hand sides. This information is then used to speed up the
calculations of the erosion and dilation operator by enabling the use of
techniques which allow to skip the analysis of certain pixels whenever a hit or
miss occurs. Additionally the input image gets trimmed during the preprocessing
steps on the base of two primitive criteria. Experimental results show the
advantages over other algorithms. The source code of our algorithms is
available in C++.
</dc:description>
 <dc:description>Comment: 17 pages, 2 figures. Submitted to Elsevier (Pattern Recognition). For
  the associated source code, see
  https://numerical-analysis.uibk.ac.at/g.ehrensperger</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01057</identifier>
 <datestamp>2015-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preprint Virtual Geographic Environment Based Coach Passenger Flow
  Forecasting</dc:title>
 <dc:creator>Lv, Zhihan</dc:creator>
 <dc:creator>Li, Xiaoming</dc:creator>
 <dc:creator>Hu, Jinxing</dc:creator>
 <dc:creator>Yin, Ling</dc:creator>
 <dc:creator>Zhang, Baoyun</dc:creator>
 <dc:creator>Feng, Shengzhong</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>I.3.7</dc:subject>
 <dc:description>  This is the preprint version of our paper on 2015 IEEE Computational
Intelligence and Virtual Environments for Measurement Systems and Applications
(CIVEMSA). There are lacks of integrated analysis and visual display of
multiple real-time dynamic traffic information. This research proposed a deep
research and application examples on this basis which is conducted in virtual
geographic environment. Currently, there are many kinds of traffic passenger
flow forecasting models, and the common models include regression forecasting
model and time series prediction model. The coach passenger flow shows strong
regularity and stability without longterm change trend, so this research adopts
regression forecasting model to forecast the coach passenger flow
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the author due to a crucial sign
  error in section 3</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:date>2015-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01070</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sync-Rank: Robust Ranking, Constrained Ranking and Rank Aggregation via
  Eigenvector and Semidefinite Programming Synchronization</dc:title>
 <dc:creator>Cucuringu, Mihai</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the classic problem of establishing a statistical ranking of a
set of n items given a set of inconsistent and incomplete pairwise comparisons
between such items. Instantiations of this problem occur in numerous
applications in data analysis (e.g., ranking teams in sports data), computer
vision, and machine learning. We formulate the above problem of ranking with
incomplete noisy information as an instance of the group synchronization
problem over the group SO(2) of planar rotations, whose usefulness has been
demonstrated in numerous applications in recent years. Its least squares
solution can be approximated by either a spectral or a semidefinite programming
(SDP) relaxation, followed by a rounding procedure. We perform extensive
numerical simulations on both synthetic and real-world data sets, showing that
our proposed method compares favorably to other algorithms from the recent
literature. Existing theoretical guarantees on the group synchronization
problem imply lower bounds on the largest amount of noise permissible in the
ranking data while still achieving exact recovery. We propose a similar
synchronization-based algorithm for the rank-aggregation problem, which
integrates in a globally consistent ranking pairwise comparisons given by
different rating systems on the same set of items. We also discuss the problem
of semi-supervised ranking when there is available information on the ground
truth rank of a subset of players, and propose an algorithm based on SDP which
recovers the ranks of the remaining players. Finally, synchronization-based
ranking, combined with a spectral technique for the densest subgraph problem,
allows one to extract locally-consistent partial rankings, in other words, to
identify the rank of a small subset of players whose pairwise comparisons are
less noisy than the rest of the data, which other methods are not able to
identify.
</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01072</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EM-Based Channel Estimation from Crowd-Sourced RSSI Samples Corrupted by
  Noise and Interference</dc:title>
 <dc:creator>Kokalj-Filipovic, Silvija</dc:creator>
 <dc:creator>Greenstein, Larry</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a method for estimating channel parameters from RSSI measurements
and the lost packet count, which can work in the presence of losses due to both
interference and signal attenuation below the noise floor. This is especially
important in the wireless networks, such as vehicular, where propagation model
changes with the density of nodes. The method is based on Stochastic
Expectation Maximization, where the received data is modeled as a mixture of
distributions (no/low interference and strong interference), incomplete
(censored) due to packet losses. The PDFs in the mixture are Gamma, according
to the commonly accepted model for wireless signal and interference power. This
approach leverages the loss count as additional information, hence
outperforming maximum likelihood estimation, which does not use this
information (ML-), for a small number of received RSSI samples. Hence, it
allows inexpensive on-line channel estimation from ad-hoc collected data. The
method also outperforms ML- on uncensored data mixtures, as ML- assumes that
samples are from a single-mode PDF.
</dc:description>
 <dc:description>Comment: CISS 2015</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01076</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nearly-optimal bounds for sparse recovery in generic norms, with
  applications to $k$-median sketching</dc:title>
 <dc:creator>Backurs, Arturs</dc:creator>
 <dc:creator>Indyk, Piotr</dc:creator>
 <dc:creator>Price, Eric</dc:creator>
 <dc:creator>Razenshteyn, Ilya</dc:creator>
 <dc:creator>Woodruff, David P.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We initiate the study of trade-offs between sparsity and the number of
measurements in sparse recovery schemes for generic norms. Specifically, for a
norm $\|\cdot\|$, sparsity parameter $k$, approximation factor $K&gt;0$, and
probability of failure $P&gt;0$, we ask: what is the minimal value of $m$ so that
there is a distribution over $m \times n$ matrices $A$ with the property that
for any $x$, given $Ax$, we can recover a $k$-sparse approximation to $x$ in
the given norm with probability at least $1-P$? We give a partial answer to
this problem, by showing that for norms that admit efficient linear sketches,
the optimal number of measurements $m$ is closely related to the doubling
dimension of the metric induced by the norm $\|\cdot\|$ on the set of all
$k$-sparse vectors. By applying our result to specific norms, we cast known
measurement bounds in our general framework (for the $\ell_p$ norms, $p \in
[1,2]$) as well as provide new, measurement-efficient schemes (for the
Earth-Mover Distance norm). The latter result directly implies more succinct
linear sketches for the well-studied planar $k$-median clustering problem.
Finally, our lower bound for the doubling dimension of the EMD norm enables us
to address the open question of [Frahling-Sohler, STOC'05] about the space
complexity of clustering problems in the dynamic streaming model.
</dc:description>
 <dc:description>Comment: 29 pages</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01085</identifier>
 <datestamp>2016-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stable Signal Recovery from Phaseless Measurements</dc:title>
 <dc:creator>Gao, Bing</dc:creator>
 <dc:creator>Wang, Yang</dc:creator>
 <dc:creator>Xu, Zhiqiang</dc:creator>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The aim of this paper is to study the stability of the $\ell_1$ minimization
for the compressive phase retrieval and to extend the instance-optimality in
compressed sensing to the real phase retrieval setting. We first show that the
$m={\mathcal O}(k\log(N/k))$ measurements is enough to guarantee the $\ell_1$
minimization to recover $k$-sparse signals stably provided the measurement
matrix $A$ satisfies the strong RIP property. We second investigate the
phaseless instance-optimality with presenting a null space property of the
measurement matrix $A$ under which there exists a decoder $\Delta$ so that the
phaseless instance-optimality holds. We use the result to study the phaseless
instance-optimality for the $\ell_1$ norm. The results build a parallel for
compressive phase retrieval with the classical compressive sensing.
</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01085</dc:identifier>
 <dc:identifier>doi:10.1007/s00041-015-9434-x</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01090</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Source Coding in Networks with Covariance Distortion Constraints</dc:title>
 <dc:creator>Zahedi, Adel</dc:creator>
 <dc:creator>&#xd8;stergaard, Jan</dc:creator>
 <dc:creator>Jensen, S&#xf8;ren Holdt</dc:creator>
 <dc:creator>Naylor, Patrick A.</dc:creator>
 <dc:creator>Bech, S&#xf8;ren</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a source coding problem with a network scenario in mind, and
formulate it as a remote vector Gaussian Wyner-Ziv problem under covariance
matrix distortions. We define a notion of minimum for two positive-definite
matrices based on which we derive an explicit formula for the rate-distortion
function (RDF). We then study the special cases and applications of this
result. We show that two well-studied source coding problems, i.e. remote
vector Gaussian Wyner-Ziv problems with mean-squared error and mutual
information constraints are in fact special cases of our results. Finally, we
apply our results to a joint source coding and denoising problem. We consider a
network with a centralized topology and a given weighted sum-rate constraint,
where the received signals at the center are to be fused to maximize the output
SNR while enforcing no linear distortion. We show that one can design the
distortion matrices at the nodes in order to maximize the output SNR at the
fusion center. We thereby bridge between denoising and source coding within
this setup.
</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:date>2016-09-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01090</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2603973</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01092</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Technical Notes on Complexity of the Satisfiability Problem</dc:title>
 <dc:creator>Suchenek, Marek A.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  These notes contain, among others, a proof that the average running time of
an easy solution to the satisfiability problem for propositional calculus is,
under some reasonable assumptions, linear (with constant 2) in the size of the
input. Moreover, some suggestions are made about criteria for tractability of
complex algorithms. In particular, it is argued that the distribution of
probability on the whole input space of an algorithm constitutes an
non-negligible factor in estimating whether the algorithm is tractable or not.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01093</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pricing Online Decisions: Beyond Auctions</dc:title>
 <dc:creator>Cohen, Ilan Reuven</dc:creator>
 <dc:creator>Eden, Alon</dc:creator>
 <dc:creator>Fiat, Amos</dc:creator>
 <dc:creator>Je&#x17c;, &#x141;ukasz</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider dynamic pricing schemes in online settings where selfish agents
generate online events. Previous work on online mechanisms has dealt almost
entirely with the goal of maximizing social welfare or revenue in an auction
settings. This paper deals with quite general settings and minimizing social
costs. We show that appropriately computed posted prices allow one to achieve
essentially the same performance as the best online algorithm. This holds in a
wide variety of settings. Unlike online algorithms that learn about the event,
and then make enforceable decisions, prices are posted without knowing the
future events or even the current event, and are thus inherently dominant
strategy incentive compatible.
  In particular we show that one can give efficient posted price mechanisms for
metrical task systems, some instances of the $k$-server problem, and metrical
matching problems. We give both deterministic and randomized algorithms. Such
posted price mechanisms decrease the social cost dramatically over selfish
behavior where no decision incurs a charge. One alluring application of this is
reducing the social cost of free parking exponentially.
</dc:description>
 <dc:description>Comment: Appeared in the ACM-SIAM Symposium on Discrete Algorithms (SODA),
  2015</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01099</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CRT and Fixed Patterns in Combinatorial Sequences</dc:title>
 <dc:creator>Khan, Muhammad Asad</dc:creator>
 <dc:creator>Khan, Amir Ali</dc:creator>
 <dc:creator>Mirza, Fauzan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper, new context of Chinese Remainder Theorem (CRT) based analysis
of combinatorial sequence generators has been presented. CRT is exploited to
establish fixed patterns in LFSR sequences and underlying cyclic structures of
finite fields. New methodology of direct computations of DFT spectral points in
higher finite fields from known DFT spectra points of smaller constituent
fields is also introduced. Novel approach of CRT based structural analysis of
LFSR based combinatorial sequence is given both in time and frequency domain.
The proposed approach is demonstrated on some examples of combiner generators
and is scalable to general configuration of combiner generators.
</dc:description>
 <dc:description>Comment: New results on finite fields theory of combinatorial sequences and
  their CRT based analysis. arXiv admin note: substantial text overlap with
  arXiv:1503.00943</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01100</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Multiple Symbol Differential Detection and Channel Decoding for
  Noncoherent UWB Impulse Radio by Belief Propagation</dc:title>
 <dc:creator>Wang, Taotao</dc:creator>
 <dc:creator>Lv, Tiejun</dc:creator>
 <dc:creator>Gao, Hui</dc:creator>
 <dc:creator>Zhang, Shengli</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper proposes a belief propagation (BP) message passing algorithm based
joint multiple symbol differential detection (MSDD) and channel decoding scheme
for noncoherent differential ultra-wideband impulse radio (UWB-IR) systems.
MSDD is an effective means to improve the performance of noncoherent
differential UWB-IR systems. To optimize the overall detection and decoding
performance, in this paper, we propose a novel soft-in soft-out (SISO) MSDD
scheme and its integration with SISO channel decoding for noncoherent
differential UWB-IR. we first propose a new auto-correlation receiver (AcR)
architecture to sample the received UWB-IR signal. The proposed AcR can exploit
the dependencies (imposed by the differential modulation) among data symbols
throughout the whole packet. The signal probabilistic model has a hidden Markov
chain structure. We use a factor graph to represent this hidden Markov chain.
Then, we apply BP message passing algorithm on the factor graph to develop a
SISO MSDD scheme, which has better performance than the previous MSDD scheme
and is easy to be integrated with SISO channel decoding to form a joint MSDD
and channel decoding scheme. Simulation results indicate the performance
advantages of our MSDD scheme and joint MSDD and channel decoding scheme.
</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:date>2015-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01101</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Private Data Transfer over a Broadcast Channel</dc:title>
 <dc:creator>Mishra, Manoj</dc:creator>
 <dc:creator>Sharma, Tanmay</dc:creator>
 <dc:creator>Dey, Bikash K.</dc:creator>
 <dc:creator>Prabhakaran, Vinod M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We study the following private data transfer problem: Alice has a database of
files. Bob and Cathy want to access a file each from this database (which may
or may not be the same file), but each of them wants to ensure that their
choices of file do not get revealed even if Alice colludes with the other user.
Alice, on the other hand, wants to make sure that each of Bob and Cathy does
not learn any more information from the database than the files they demand
(the identities of which will be unknown to her). Moreover, they should not
learn any information about the other files even if they collude.
  It turns out that it is impossible to accomplish this if Alice, Bob, and
Cathy have access only to private randomness and noiseless communication links.
We consider this problem when a binary erasure broadcast channel with
independent erasures is available from Alice to Bob and Cathy in addition to a
noiseless public discussion channel. We study the
file-length-per-broadcast-channel-use rate in the honest-but-curious model. We
focus on the case when the database consists of two files, and obtain the
optimal rate. We then extend to the case of larger databases, and give upper
and lower bounds on the optimal rate.
</dc:description>
 <dc:description>Comment: To be presented at IEEE International Symposium on Information Theory
  (ISIT 2015), Hong Kong</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:date>2015-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01101</dc:identifier>
 <dc:identifier>doi:10.1109/ISIT.2015.7282676</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01106</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discriminative Neural Sentence Modeling by Tree-Based Convolution</dc:title>
 <dc:creator>Mou, Lili</dc:creator>
 <dc:creator>Peng, Hao</dc:creator>
 <dc:creator>Li, Ge</dc:creator>
 <dc:creator>Xu, Yan</dc:creator>
 <dc:creator>Zhang, Lu</dc:creator>
 <dc:creator>Jin, Zhi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  This paper proposes a tree-based convolutional neural network (TBCNN) for
discriminative sentence modeling. Our models leverage either constituency trees
or dependency trees of sentences. The tree-based convolution process extracts
sentences' structural features, and these features are aggregated by max
pooling. Such architecture allows short propagation paths between the output
layer and underlying feature detectors, which enables effective structural
feature learning and extraction. We evaluate our models on two tasks: sentiment
analysis and question classification. In both experiments, TBCNN outperforms
previous state-of-the-art results, including existing neural networks and
dedicated feature/rule engineering. We also make efforts to visualize the
tree-based convolution process, shedding light on how our models work.
</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:date>2015-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01112</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adoption Factors for e-Malls in the SME Sector in Saudi Arabia</dc:title>
 <dc:creator>Bahaddad, Adel A.</dc:creator>
 <dc:creator>AlGhamdi, Rayed</dc:creator>
 <dc:creator>Alkhalaf, Salem</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The small and medium-sized enterprise (SME) sector represents one of the
fundamental pillars in the trade field. It contributes significantly to raising
the economies of countries by providing significant numbers of job
opportunities, which are beneficial to directly supporting national economies.
One of the most important obstacles facing this sector in the information
technology era is the lack of online trading channels with consumers, which
require more financial support than the their capabilities. Therefore, e-Malls
might be one of the best low-cost solutions to overcome this obstacle. Also,
they provide electronic platforms that include most SME requirements for sales
via electronic channels as well as offer essential technical support. According
to a report published in 2013 by the Saudi Arabian Monetary Agency (SAMA), the
percentage of SMEs is equivalent to 90% of the total number of companies in
Saudi Arabia, which is numbered at 848,500. The e-Mall is a modern idea in
Saudi Arabia that requires the use of the Disunion Of Innovation (DOI) approach
to diffuse e-Malls through determining companies requirements and difficulties.
Therefore, this paper focuses on the factors that help SMEs to adopt e-Malls. A
quantitative questionnaire was conducted on 108 companies in Saudi Arabia to
find what obstacles and requirements they face to adopt an e-Mall and focus on
the factors affecting the implementation of this system, which are divided into
organizational, technical and cultural factors.
</dc:description>
 <dc:description>Comment: 22 pages, International Journal of Computer Science and Information
  Technologies, 2014</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01117</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An $\tilde{O}(\frac{1}{\sqrt{T}})$-error online algorithm for retrieving
  heavily perturbated statistical databases in the low-dimensional querying
  mode</dc:title>
 <dc:creator>Choromanski, Krzysztof</dc:creator>
 <dc:creator>Rostamizadeh, Afshin</dc:creator>
 <dc:creator>Syed, Umar</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We give the first $\tilde{O}(\frac{1}{\sqrt{T}})$-error online algorithm for
reconstructing noisy statistical databases, where $T$ is the number of (online)
sample queries received. The algorithm, which requires only $O(\log T)$ memory,
aims to learn a hidden database-vector $w^{*} \in \mathbb{R}^{D}$ in order to
accurately answer a stream of queries regarding the hidden database, which
arrive in an online fashion from some unknown distribution $\mathcal{D}$. We
assume the distribution $\mathcal{D}$ is defined on the neighborhood of a
low-dimensional manifold. The presented algorithm runs in $O(dD)$-time per
query, where $d$ is the dimensionality of the query-space. Contrary to the
classical setting, there is no separate training set that is used by the
algorithm to learn the database --- the stream on which the algorithm will be
evaluated must also be used to learn the database-vector. The algorithm only
has access to a binary oracle $\mathcal{O}$ that answers whether a particular
linear function of the database-vector plus random noise is larger than a
threshold, which is specified by the algorithm. We note that we allow for a
significant $O(D)$ amount of noise to be added while other works focused on the
low noise $o(\sqrt{D})$-setting. For a stream of $T$ queries our algorithm
achieves an average error $\tilde{O}(\frac{1}{\sqrt{T}})$ by filtering out
random noise, adapting threshold values given to the oracle based on its
previous answers and, as a consequence, recovering with high precision a
projection of a database-vector $w^{*}$ onto the manifold defining the
query-space.
</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01118</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning how to rank from heavily perturbed statistics - digraph
  clustering approach</dc:title>
 <dc:creator>Choromanski, Krzysztof</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Ranking is one of the most fundamental problems in machine learning with
applications in many branches of computer science such as: information
retrieval systems, recommendation systems, machine translation and
computational biology. Ranking objects based on possibly conflicting
preferences is a central problem in voting research and social choice theory.
In this paper we present a new simple combinatorial ranking algorithm adapted
to the preference-based setting. We apply this new algorithm to the well-known
scenario where the edges of the preference tournament are determined by the
majority-voting model. It outperforms existing methods when it cannot be
assumed that there exists global ranking of good enough quality and applies
combinatorial techniques that havent been used in the ranking context before.
Performed experiments show the superiority of the new algorithm over existing
methods, also over these that were designed to handle heavily perturbed
statistics. By combining our techniques with those presented in \cite{mohri},
we obtain a purely combinatorial algorithm that answers correctly most of the
queries in the heterogeneous scenario, where the preference tournament is only
locally of good quality but is not necessarily pseudotransitive. As a byproduct
of our methods, we obtain the algorithm solving clustering problem for the
directed planted partition model. To the best of our knowledge, it is the first
purely combinatorial algorithm tackling this problem.
</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01119</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coloring tournaments with forbidden substructures</dc:title>
 <dc:creator>Choromanski, Krzysztof</dc:creator>
 <dc:creator>Jebara, Tony</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Coloring graphs is an important algorithmic problem in combinatorics with
many applications in computer science. In this paper we study coloring
tournaments. A chromatic number of a random tournament is of order
$\Omega(\frac{n}{\log(n)})$. The question arises whether the chromatic number
can be proven to be smaller for more structured nontrivial classes of
tournaments. We analyze the class of tournaments defined by a forbidden
subtournament $H$. This paper gives a first quasi-polynomial algorithm running
in time $e^{O(\log(n)^{2})}$ that constructs colorings of $H$-free tournaments
using only $O(n^{1-\epsilon(H)}\log(n))$ colors, where $\epsilon(H) \geq
2^{-2^{50|H|^{2}+1}}$ for many forbidden tournaments $H$. To the best of our
knowledge all previously known related results required at least
sub-exponential time and relied on the regularity lemma. Since we do not use
the regularity lemma, we obtain the first known lower bounds on $\epsilon(H)$
that can be given by a closed-form expression. As a corollary, we give a
constructive proof of the celebrated open Erd\H{o}s-Hajnal conjecture with
explicitly given lower bounds on the EH coefficients for all classes of prime
tournaments for which the conjecture is known. Such a constractive proof was
not known before. Thus we significantly reduce the gap between best lower and
upper bounds on the EH coefficients from the conjecture for all known prime
tournaments that satisfy it. We also briefly explain how our methods may be
used for coloring $H$-free tournaments under the following conditions: $H$ is
any tournament with $\leq 5$ vertices or: $H$ is any but one tournament of six
vertices.
</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01123</identifier>
 <datestamp>2015-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coded Caching with Heterogenous Cache Sizes</dc:title>
 <dc:creator>Wang, Sinong</dc:creator>
 <dc:creator>Li, Wenxin</dc:creator>
 <dc:creator>Tian, Xiaohua</dc:creator>
 <dc:creator>Liu, Hui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We investigate the coded caching scheme under heterogenous cache sizes.
</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:date>2015-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01123</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01124</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discriminative and Efficient Label Propagation on Complementary Graphs
  for Multi-Object Tracking</dc:title>
 <dc:creator>C., Amit Kumar K.</dc:creator>
 <dc:creator>Jacques, Laurent</dc:creator>
 <dc:creator>De Vleeschouwer, Christophe</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Given a set of detections, detected at each time instant independently, we
investigate how to associate them across time. This is done by propagating
labels on a set of graphs, each graph capturing how either the spatio-temporal
or the appearance cues promote the assignment of identical or distinct labels
to a pair of detections. The graph construction is motivated by a locally
linear embedding of the detection features. Interestingly, the neighborhood of
a node in appearance graph is defined to include all the nodes for which the
appearance feature is available (even if they are temporally distant). This
gives our framework the uncommon ability to exploit the appearance features
that are available only sporadically. Once the graphs have been defined,
multi-object tracking is formulated as the problem of finding a label
assignment that is consistent with the constraints captured each graph, which
results into a difference of convex (DC) program. We propose to decompose the
global objective function into node-wise sub-problems. This not only allows a
computationally efficient solution, but also supports an incremental and
scalable construction of the graph, thereby making the framework applicable to
large graphs and practical tracking scenarios. Moreover, it opens the
possibility of parallel implementation.
</dc:description>
 <dc:description>Comment: 15 pages, 6 figures, submitted to PAMI</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:date>2015-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01124</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01130</identifier>
 <datestamp>2017-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proving the Herman-Protocol Conjecture</dc:title>
 <dc:creator>Bruna, Maria</dc:creator>
 <dc:creator>Grigore, Radu</dc:creator>
 <dc:creator>Kiefer, Stefan</dc:creator>
 <dc:creator>Ouaknine, Jo&#xeb;l</dc:creator>
 <dc:creator>Worrell, James</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Herman's self-stabilisation algorithm, introduced 25 years ago, is a
well-studied synchronous randomised protocol for enabling a ring of $N$
processes collectively holding any odd number of tokens to reach a stable state
in which a single token remains. Determining the worst-case expected time to
stabilisation is the central outstanding open problem about this protocol. It
is known that there is a constant $h$ such that any initial configuration has
expected stabilisation time at most $h N^2$. Ten years ago, McIver and Morgan
established a lower bound of $4/27 \approx 0.148$ for $h$, achieved with three
equally-spaced tokens, and conjectured this to be the optimal value of $h$. A
series of papers over the last decade gradually reduced the upper bound on $h$,
with the present record (achieved in 2014) standing at approximately $0.156$.
In this paper, we prove McIver and Morgan's conjecture and establish that $h =
4/27$ is indeed optimal.
</dc:description>
 <dc:description>Comment: ICALP 2016</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:date>2016-04-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01130</dc:identifier>
 <dc:identifier>doi:10.4230/LIPIcs.ICALP.2016.104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01139</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Challenges in transforming, engaging and improving m-learning in Higher
  Educational Institutions: Oman perspective</dc:title>
 <dc:creator>Lakshminarayanan, Ramkumar</dc:creator>
 <dc:creator>Ramalingam, Rajasekar</dc:creator>
 <dc:creator>Shaik, Shimaz Khan</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Nowadays, the student community is growing up with mobile devices and it has
becomes an integral part of their life. Devices such as smartphones, tablets,
and e-book readers connect users to access information and enabling instant
communication with others. The enormous growth and affordability of mobile
devices influenced their learning practices. Mobile technologies are playing a
significant role in students' academic activities. The factors like
convenience, flexibility, engagement, interactivity and easy-to-use enable
mobile learning more attractive to students. With these trends in mind, it is
important for the educators to inherit the mobile technologies in effective
teaching and learning. Our study explores the challenges that exist in
implementing the m-learning technologies in the teaching and learning practices
of higher educational institutions of Oman. Our study also addressed various
issue like adoption of technology, transition to new technology and issues
related to engaging students. Based on the outcomes of the study, a framework
has been formulated to address all the challenges that are identified for the
successful implementation of m-learning.
</dc:description>
 <dc:description>Comment: The Third International Conference of Educational Technology 24-26
  March 2015</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01140</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Frequency Spreading Equalization in Multicarrier Massive MIMO</dc:title>
 <dc:creator>Aminjavaheri, Amir</dc:creator>
 <dc:creator>Farhang, Arman</dc:creator>
 <dc:creator>Marchetti, Nicola</dc:creator>
 <dc:creator>Doyle, Linda E.</dc:creator>
 <dc:creator>Farhang-Boroujeny, Behrouz</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Application of filter bank multicarrier (FBMC) as an effective method for
signaling over massive MIMO channels has been recently proposed. This paper
further expands the application of FBMC to massive MIMO by applying frequency
spreading equalization (FSE) to these channels. FSE allows us to achieve a more
accurate equalization. Hence, higher number of bits per symbol can be
transmitted and the bandwidth of each subcarrier can be widened. Widening the
bandwidth of each subcarrier leads to (i) higher bandwidth efficiency; (ii)
lower complexity; (iii) lower sensitivity to carrier frequency offset (CFO);
(iv) reduced peak-to-average power ratio (PAPR); and (iv) reduced latency. All
these appealing advantages have a direct impact on the digital as well as
analog circuitry that is needed for the system implementation. In this paper,
we develop the mathematical formulation of the minimum mean square error (MMSE)
FSE for massive MIMO systems. This analysis guides us to decide on the number
of subcarriers that will be sufficient for practical channel models.
</dc:description>
 <dc:description>Comment: Accepted in IEEE ICC 2015 - Workshop on 5G &amp; Beyond - Enabling
  Technologies and Applications</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01140</dc:identifier>
 <dc:identifier>doi:10.1109/ICCW.2015.7247356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01142</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ultra-large alignments using Phylogeny-aware Profiles</dc:title>
 <dc:creator>Nguyen, Nam-phuong</dc:creator>
 <dc:creator>Mirarab, Siavash</dc:creator>
 <dc:creator>Kumar, Keerthana</dc:creator>
 <dc:creator>Warnow, Tandy</dc:creator>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Many biological questions, including the estimation of deep evolutionary
histories and the detection of remote homology between protein sequences, rely
upon multiple sequence alignments (MSAs) and phylogenetic trees of large
datasets. However, accurate large-scale multiple sequence alignment is very
difficult, especially when the dataset contains fragmentary sequences. We
present UPP, an MSA method that uses a new machine learning technique - the
Ensemble of Hidden Markov Models - that we propose here. UPP produces highly
accurate alignments for both nucleotide and amino acid sequences, even on
ultra-large datasets or datasets containing fragmentary sequences. UPP is
available at https://github.com/smirarab/sepp.
</dc:description>
 <dc:description>Comment: Online supplemental materials and data are available at
  http://www.cs.utexas.edu/users/phylo/software/upp/</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01142</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01145</identifier>
 <datestamp>2015-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dualization in Lattices Given by Ordered Sets of Irreducibles</dc:title>
 <dc:creator>Babin, Mikhail A.</dc:creator>
 <dc:creator>Kuznetsov, Sergei O.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Dualization of a monotone Boolean function on a finite lattice can be
represented by transforming the set of its minimal 1 to the set of its maximal
0 values. In this paper we consider finite lattices given by ordered sets of
their meet and join irreducibles (i.e., as a concept lattice of a formal
context). We show that in this case dualization is equivalent to the
enumeration of so-called minimal hypotheses. In contrast to usual dualization
setting, where a lattice is given by the ordered set of its elements,
dualization in this case is shown to be impossible in output polynomial time
unless P = NP. However, if the lattice is distributive, dualization is shown to
be possible in subexponential time.
</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:date>2015-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01145</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01151</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design method for an anthropomorphic hand able to gesture and grasp</dc:title>
 <dc:creator>Cerruti, Giulio</dc:creator>
 <dc:creator>Chablat, Damien</dc:creator>
 <dc:creator>Gouaillier, David</dc:creator>
 <dc:creator>Sakka, Sophie</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents a numerical method to conceive and design the kinematic
model of an anthropomorphic robotic hand used for gesturing and grasping. In
literature, there are few numerical methods for the finger placement of
human-inspired robotic hands. In particular, there are no numerical methods,
for the thumb placement, that aim to improve the hand dexterity and grasping
capabilities by keeping the hand design close to the human one. While existing
models are usually the result of successive parameter adjustments, the proposed
method determines the fingers placements by mean of empirical tests. Moreover,
a surgery test and the workspace analysis of the whole hand are used to find
the best thumb position and orientation according to the hand kinematics and
structure. The result is validated through simulation where it is checked that
the hand looks well balanced and that it meets our constraints and needs. The
presented method provides a numerical tool which allows the easy computation of
finger and thumb geometries and base placements for a human-like dexterous
robotic hand.
</dc:description>
 <dc:description>Comment: IEEE International Conference on Robotics and Automation, May 2015,
  Seattle, United States. IEEE, 2015, Proceeding IEEE International Conference
  on Robotics and Automation</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01158</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Iterative Concave Rank Approximation for Recovering Low-Rank Matrices</dc:title>
 <dc:creator>Malek-Mohammadi, Mohammadreza</dc:creator>
 <dc:creator>Babaie-Zadeh, Massoud</dc:creator>
 <dc:creator>Skoglund, Mikael</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a new algorithm for recovery of low-rank matrices
from compressed linear measurements. The underlying idea of this algorithm is
to closely approximate the rank function with a smooth function of singular
values, and then minimize the resulting approximation subject to the linear
constraints. The accuracy of the approximation is controlled via a scaling
parameter $\delta$, where a smaller $\delta$ corresponds to a more accurate
fitting. The consequent optimization problem for any finite $\delta$ is
nonconvex. Therefore, in order to decrease the risk of ending up in local
minima, a series of optimizations is performed, starting with optimizing a
rough approximation (a large $\delta$) and followed by successively optimizing
finer approximations of the rank with smaller $\delta$'s. To solve the
optimization problem for any $\delta &gt; 0$, it is converted to a new program in
which the cost is a function of two auxiliary positive semidefinete variables.
The paper shows that this new program is concave and applies a
majorize-minimize technique to solve it which, in turn, leads to a few convex
optimization iterations. This optimization scheme is also equivalent to a
reweighted Nuclear Norm Minimization (NNM), where weighting update depends on
the used approximating function. For any $\delta &gt; 0$, we derive a necessary
and sufficient condition for the exact recovery which are weaker than those
corresponding to NNM. On the numerical side, the proposed algorithm is compared
to NNM and a reweighted NNM in solving affine rank minimization and matrix
completion problems showing its considerable and consistent superiority in
terms of success rate, especially, when the number of measurements decreases
toward the lower-bound for the unique representation.
</dc:description>
 <dc:description>Comment: IEEE Trans. on Signal Processing, vol. 62, no. 20</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01158</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2014.2340820</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01161</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Python bindings for libcloudph++</dc:title>
 <dc:creator>Jarecka, Dorota</dc:creator>
 <dc:creator>Arabas, Sylwester</dc:creator>
 <dc:creator>Del Vento, Davide</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Physics - Atmospheric and Oceanic Physics</dc:subject>
 <dc:description>  This technical note introduces the Python bindings for libcloudph++. The
libcloudph++ is a C++ library of algorithms for representing atmospheric cloud
microphysics in numerical models. The bindings expose the complete
functionality of the library to the Python users. The bindings are implemented
using the Boost.Python C++ library and use NumPy arrays. This note includes
listings with Python scripts exemplifying the use of selected library
components. An example solution for using the Python bindings to access
libcloudph++ from Fortran is presented.
</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01163</identifier>
 <datestamp>2015-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AiiDA: Automated Interactive Infrastructure and Database for
  Computational Science</dc:title>
 <dc:creator>Pizzi, Giovanni</dc:creator>
 <dc:creator>Cepellotti, Andrea</dc:creator>
 <dc:creator>Sabatini, Riccardo</dc:creator>
 <dc:creator>Marzari, Nicola</dc:creator>
 <dc:creator>Kozinsky, Boris</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Computational science has seen in the last decades a spectacular rise in the
scope, breadth, and depth of its efforts. Notwithstanding this prevalence and
impact, it is often still performed using the renaissance model of individual
artisans gathered in a workshop, under the guidance of an established
practitioner. Great benefits could follow instead from adopting concepts and
tools coming from computer science to manage, preserve, and share these
computational efforts. We illustrate here our paradigm sustaining such vision,
based around the four pillars of Automation, Data, Environment, and Sharing. We
then discuss its implementation in the open-source AiiDA platform
(http://www.aiida.net), that has been tuned first to the demands of
computational materials science. AiiDA's design is based on directed acyclic
graphs to track the provenance of data and calculations, and ensure
preservation and searchability. Remote computational resources are managed
transparently, and automation is coupled with data storage to ensure
reproducibility. Last, complex sequences of calculations can be encoded into
scientific workflows. We believe that AiiDA's design and its sharing
capabilities will encourage the creation of social ecosystems to disseminate
codes, data, and scientific workflows.
</dc:description>
 <dc:description>Comment: 30 pages, 7 figures</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:date>2015-09-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01163</dc:identifier>
 <dc:identifier>G. Pizzi, A. Cepellotti, R. Sabatini, N. Marzari, and B. Kozinsky,
  Comp. Mat. Sci 111, 218-230 (2016)</dc:identifier>
 <dc:identifier>doi:10.1016/j.commatsci.2015.09.013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01166</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An extension of the Ky Fan inequality</dc:title>
 <dc:creator>Suhov, Yuri</dc:creator>
 <dc:creator>Sekeh, Salimeh Yasaei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>60A10, 60B05, 60C05</dc:subject>
 <dc:description>  The aim of this paper is to analyze the weighted KyFan inequality proposed in
[11]. A number of numerical simulations involving the exponential weighted
function is given. We show that in several cases and types of examples one can
imply an improvement of the standard KyFan inequality.
</dc:description>
 <dc:description>Comment: 12 pages, 7 figures</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01166</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01167</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Heuristic algorithms for obtaining Polynomial Threshold Functions with
  low densities</dc:title>
 <dc:creator>Sezener, Can Eren</dc:creator>
 <dc:creator>Oztop, Erhan</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper we present several heuristic algorithms, including a Genetic
Algorithm (GA), for obtaining polynomial threshold function (PTF)
representations of Boolean functions (BFs) with small number of monomials. We
compare these among each other and against the algorithm of Oztop via
computational experiments. The results indicate that our heuristic algorithms
find more parsimonious representations compared to the those of non-heuristic
and GA-based algorithms.
</dc:description>
 <dc:description>Comment: This paper will appear in the 13th Cologne-Twente Workshop on Graphs
  &amp; Combinatorial Optimization</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01169</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Dictionary Learning via Very Sparse Random Projections</dc:title>
 <dc:creator>Pourkamali-Anaraki, Farhad</dc:creator>
 <dc:creator>Becker, Stephen</dc:creator>
 <dc:creator>Hughes, Shannon M.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Performing signal processing tasks on compressive measurements of data has
received great attention in recent years. In this paper, we extend previous
work on compressive dictionary learning by showing that more general random
projections may be used, including sparse ones. More precisely, we examine
compressive K-means clustering as a special case of compressive dictionary
learning and give theoretical guarantees for its performance for a very general
class of random projections. We then propose a memory and computation efficient
dictionary learning algorithm, specifically designed for analyzing large
volumes of high-dimensional data, which learns the dictionary from very sparse
random projections. Experimental results demonstrate that our approach allows
for reduction of computational complexity and memory/data access, with
controllable loss in accuracy.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures, accepted in Sampling Theory and Applications
  (SampTA) 2015</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01173</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual Decomposition from the Perspective of Relax, Compensate and then
  Recover</dc:title>
 <dc:creator>Choi, Arthur</dc:creator>
 <dc:creator>Darwiche, Adnan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Relax, Compensate and then Recover (RCR) is a paradigm for approximate
inference in probabilistic graphical models that has previously provided
theoretical and practical insights on iterative belief propagation and some of
its generalizations. In this paper, we characterize the technique of dual
decomposition in the terms of RCR, viewing it as a specific way to compensate
for relaxed equivalence constraints. Among other insights gathered from this
perspective, we propose novel heuristics for recovering relaxed equivalence
constraints with the goal of incrementally tightening dual decomposition
approximations, all the way to reaching exact solutions. We also show
empirically that recovering equivalence constraints can sometimes tighten the
corresponding approximation (and obtaining exact results), without increasing
much the complexity of inference.
</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01173</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01175</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New algorithm for the discrete logarithm problem on elliptic curves</dc:title>
 <dc:creator>Semaev, Igor</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Commutative Algebra</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:description>  A new algorithms for computing discrete logarithms on elliptic curves defined
over finite fields is suggested. It is based on a new method to find zeroes of
summation polynomials. In binary elliptic curves one is to solve a cubic system
of Boolean equations. Under a first fall degree assumption the regularity
degree of the system is at most $4$. Extensive experimental data which supports
the assumption is provided. An heuristic analysis suggests a new asymptotical
complexity bound $2^{c\sqrt{n\ln n}}, c\approx 1.69$ for computing discrete
logarithms on an elliptic curve over a field of size $2^n$. For several binary
elliptic curves recommended by FIPS the new method performs better than
Pollard's.
</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01182</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bengali to Assamese Statistical Machine Translation using Moses (Corpus
  Based)</dc:title>
 <dc:creator>Kalita, Nayan Jyoti</dc:creator>
 <dc:creator>Islam, Baharul</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Machine dialect interpretation assumes a real part in encouraging man-machine
correspondence and in addition men-men correspondence in Natural Language
Processing (NLP). Machine Translation (MT) alludes to utilizing machine to
change one dialect to an alternate. Statistical Machine Translation is a type
of MT consisting of Language Model (LM), Translation Model (TM) and decoder. In
this paper, Bengali to Assamese Statistical Machine Translation Model has been
created by utilizing Moses. Other translation tools like IRSTLM for Language
Model and GIZA-PP-V1.0.7 for Translation model are utilized within this
framework which is accessible in Linux situations. The purpose of the LM is to
encourage fluent output and the purpose of TM is to encourage similarity
between input and output, the decoder increases the probability of translated
text in target language. A parallel corpus of 17100 sentences in Bengali and
Assamese has been utilized for preparing within this framework. Measurable MT
procedures have not so far been generally investigated for Indian dialects. It
might be intriguing to discover to what degree these models can help the
immense continuous MT deliberations in the nation.
</dc:description>
 <dc:description>Comment: 6 pages, International Conference on Cognitive Computing and
  Information Processing (CCIP-15), 3-4 March 2015, Noida (India)</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01182</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01183</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Document Clustering using K-Medoids</dc:title>
 <dc:creator>Jha, Monica</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  People are always in search of matters for which they are prone to use
internet, but again it has huge assemblage of data due to which it becomes
difficult for the reader to get the most accurate data. To make it easier for
people to gather accurate data, similar information has to be clustered at one
place. There are many algorithms used for clustering of relevant information in
one platform. In this paper, K-Medoids clustering algorithm has been employed
for formation of clusters which is further used for document summarization.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01183</dc:identifier>
 <dc:identifier>International Journal on Advanced Computer Theory and Engineering
  (IJACTE), ISSN (Print): 2319-2526, Volume-4, Issue-1, 2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01185</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Byzantine Attack and Defense in Cognitive Radio Networks: A Survey</dc:title>
 <dc:creator>Zhang, Linyuan</dc:creator>
 <dc:creator>Ding, Guoru</dc:creator>
 <dc:creator>Wu, Qihui</dc:creator>
 <dc:creator>Zou, Yulong</dc:creator>
 <dc:creator>Han, Zhu</dc:creator>
 <dc:creator>Wang, Jinlong</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The Byzantine attack in cooperative spectrum sensing (CSS), also known as the
spectrum sensing data falsification (SSDF) attack in the literature, is one of
the key adversaries to the success of cognitive radio networks (CRNs). In the
past couple of years, the research on the Byzantine attack and defense
strategies has gained worldwide increasing attention. In this paper, we provide
a comprehensive survey and tutorial on the recent advances in the Byzantine
attack and defense for CSS in CRNs. Specifically, we first briefly present the
preliminaries of CSS for general readers, including signal detection
techniques, hypothesis testing, and data fusion. Second, we analyze the spear
and shield relation between Byzantine attack and defense from three aspects:
the vulnerability of CSS to attack, the obstacles in CSS to defense, and the
games between attack and defense. Then, we propose a taxonomy of the existing
Byzantine attack behaviors and elaborate on the corresponding attack
parameters, which determine where, who, how, and when to launch attacks. Next,
from the perspectives of homogeneous or heterogeneous scenarios, we classify
the existing defense algorithms, and provide an in-depth tutorial on the
state-of-the-art Byzantine defense schemes, commonly known as robust or secure
CSS in the literature. Furthermore, we highlight the unsolved research
challenges and depict the future research directions.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Communications Surveys and Tutoirals</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01185</dc:identifier>
 <dc:identifier>doi:10.1109/COMST.2015.2422735</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01191</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the BMAP_1, BMAP_2/PH/g, c retrial queueing system</dc:title>
 <dc:creator>Wu, Jinbiao</dc:creator>
 <dc:creator>Peng, Yi</dc:creator>
 <dc:creator>Liu, Zaiming</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>60K25</dc:subject>
 <dc:subject>G.3.9</dc:subject>
 <dc:description>  In this paper, we analyze a retrial queueing system with Batch Markovian
Arrival Processes and two types of customers. The rate of individual repeated
attempts from the orbit is modulated according to a Markov Modulated Poisson
Process. Using the theory of multi-dimensional asymptotically quasi-Toeplitz
Markov chain, we obtain the stability condition and the algorithm for
calculating the stationary state distribution of the system. Main performance
measures are presented. Furthermore, we investigate some optimization problems.
The algorithm for determining the optimal number of guard servers and total
servers is elaborated. Finally, this queueing system is applied to the cellular
wireless network. Numerical results to illustrate the optimization problems and
the impact of retrial on performance measures are provided. We find that the
performance measures are mainly affected by the two types of customers'
arrivals and service patterns, but the retrial rate plays a less crucial role.
</dc:description>
 <dc:description>Comment: 28 pages with 3 figures</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01192</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multipath Reflections Analysis on Indoor Visible Light Positioning
  System</dc:title>
 <dc:creator>Gu, Wenjun</dc:creator>
 <dc:creator>Kashani, Mohammadreza A.</dc:creator>
 <dc:creator>Kavehrad, Mohsen</dc:creator>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Visible light communication (VLC) has become a promising research topic in
recent years, and finds its wide applications in indoor environments.
Particularly, for location based services (LBS), visible light also provides a
practical solution for indoor positioning. Multipath-induced dispersion is one
of the major concerns for complex indoor environments. It affects not only the
communication performance but also the positioning accuracy. In this paper, we
investigate the impact of multipath reflections on the positioning accuracy of
indoor VLC positioning systems. Combined Deterministic and Modified Monte Carlo
(CDMMC) approach is applied to estimate the channel impulse response
considering multipath reflections. Since the received signal strength (RSS)
information is used for the positioning algorithm, the power distribution from
one transmitter in a typical room configuration is first calculated. Then, the
positioning accuracy in terms of root mean square error is obtained and
analyzed.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Globecom 2015, 7 Pages, 13 Figures</dc:description>
 <dc:date>2015-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01192</dc:identifier>
 <dc:identifier>doi:10.1109/ICCE.2016.7430533</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01207</identifier>
 <datestamp>2017-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Localization in mobile networks via virtual convex hulls</dc:title>
 <dc:creator>Safavi, Sam</dc:creator>
 <dc:creator>Khan, Usman A.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we develop a \textit{distributed} algorithm to localize an
arbitrary number of agents moving in a bounded region of interest. We assume
that the network contains \textit{at least one} agent with known location
(hereinafter referred to as an anchor), and each agent measures a noisy version
of its motion and the distances to the nearby agents. We provide
a~\emph{geometric approach}, which allows each agent to: (i) continually update
the distances to the locations where it has exchanged information with the
other nodes in the past; and (ii) measure the distance between a neighbor and
any such locations. Based on this approach, we provide a \emph{linear update}
to find the locations of an arbitrary number of mobile agents when they follow
some convexity in their deployment and motion.
  Since the agents are mobile, they may not be able to find nearby nodes
(agents and/or anchors) to implement a distributed algorithm. To address this
issue, we introduce the notion of a \emph{virtual convex hull} with the help of
the aforementioned geometric approach. In particular, each agent keeps track of
a virtual convex hull of other nodes, which may not physically exist, and
updates its location with respect to its neighbors in the virtual hull. We show
that the corresponding localization algorithm, in the absence of noise, can be
abstracted as a Linear Time-Varying (LTV) system, with non-deterministic system
matrices, which asymptotically tracks the true locations of the agents. We
provide simulations to verify the analytical results and evaluate the
performance of the algorithm in the presence of noise on the motion as well as
on the distance measurements.
</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:date>2017-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01218</identifier>
 <datestamp>2016-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Instantly Decodable Network Coding for Real-Time Scalable Video
  Broadcast over Wireless Networks</dc:title>
 <dc:creator>Karim, Mohammad S.</dc:creator>
 <dc:creator>Sadeghi, Parastoo</dc:creator>
 <dc:creator>Sorour, Sameh</dc:creator>
 <dc:creator>Aboutorab, Neda</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study a real-time scalable video broadcast over wireless
networks in instantly decodable network coded (IDNC) systems. Such real-time
scalable video has a hard deadline and imposes a decoding order on the video
layers.We first derive the upper bound on the probability that the individual
completion times of all receivers meet the deadline. Using this probability, we
design two prioritized IDNC algorithms, namely the expanding window IDNC
(EW-IDNC) algorithm and the non-overlapping window IDNC (NOW-IDNC) algorithm.
These algorithms provide a high level of protection to the most important video
layer before considering additional video layers in coding decisions. Moreover,
in these algorithms, we select an appropriate packet combination over a given
number of video layers so that these video layers are decoded by the maximum
number of receivers before the deadline. We formulate this packet selection
problem as a two-stage maximal clique selection problem over an IDNC graph.
Simulation results over a real scalable video stream show that our proposed
EW-IDNC and NOW-IDNC algorithms improve the received video quality compared to
the existing IDNC algorithms.
</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01218</dc:identifier>
 <dc:identifier>doi:10.1186/s13634-015-0299-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01220</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matching-CNN Meets KNN: Quasi-Parametric Human Parsing</dc:title>
 <dc:creator>Liu, Si</dc:creator>
 <dc:creator>Liang, Xiaodan</dc:creator>
 <dc:creator>Liu, Luoqi</dc:creator>
 <dc:creator>Shen, Xiaohui</dc:creator>
 <dc:creator>Yang, Jianchao</dc:creator>
 <dc:creator>Xu, Changsheng</dc:creator>
 <dc:creator>Lin, Liang</dc:creator>
 <dc:creator>Cao, Xiaochun</dc:creator>
 <dc:creator>Yan, Shuicheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Both parametric and non-parametric approaches have demonstrated encouraging
performances in the human parsing task, namely segmenting a human image into
several semantic regions (e.g., hat, bag, left arm, face). In this work, we aim
to develop a new solution with the advantages of both methodologies, namely
supervision from annotated data and the flexibility to use newly annotated
(possibly uncommon) images, and present a quasi-parametric human parsing model.
Under the classic K Nearest Neighbor (KNN)-based nonparametric framework, the
parametric Matching Convolutional Neural Network (M-CNN) is proposed to predict
the matching confidence and displacements of the best matched region in the
testing image for a particular semantic region in one KNN image. Given a
testing image, we first retrieve its KNN images from the
annotated/manually-parsed human image corpus. Then each semantic region in each
KNN image is matched with confidence to the testing image using M-CNN, and the
matched regions from all KNN images are further fused, followed by a superpixel
smoothing procedure to obtain the ultimate human parsing result. The M-CNN
differs from the classic CNN in that the tailored cross image matching filters
are introduced to characterize the matching between the testing image and the
semantic region of a KNN image. The cross image matching filters are defined at
different convolutional layers, each aiming to capture a particular range of
displacements. Comprehensive evaluations over a large dataset with 7,700
annotated human images well demonstrate the significant performance gain from
the quasi-parametric model over the state-of-the-arts, for the human parsing
task.
</dc:description>
 <dc:description>Comment: This manuscript is the accepted version for CVPR 2015</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01220</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01252</identifier>
 <datestamp>2016-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence and Fluctuations of Regularized Tyler Estimators</dc:title>
 <dc:creator>Kammoun, Abla</dc:creator>
 <dc:creator>Couillet, Romain</dc:creator>
 <dc:creator>Pascal, Frederic</dc:creator>
 <dc:creator>Alouini, Mohamed-Slim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This article studies the behavior of regularized Tyler estimators (RTEs) of
scatter matrices. The key advantages of these estimators are twofold. First,
they guarantee by construction a good conditioning of the estimate and second,
being a derivative of robust Tyler estimators, they inherit their robustness
properties, notably their resilience to the presence of outliers. Nevertheless,
one major problem that poses the use of RTEs in practice is represented by the
question of setting the regularization parameter $\rho$. While a high value of
$\rho$ is likely to push all the eigenvalues away from zero, it comes at the
cost of a larger bias with respect to the population covariance matrix. A deep
understanding of the statistics of RTEs is essential to come up with
appropriate choices for the regularization parameter. This is not an easy task
and might be out of reach, unless one considers asymptotic regimes wherein the
number of observations $n$ and/or their size $N$ increase together. First
asymptotic results have recently been obtained under the assumption that $N$
and $n$ are large and commensurable. Interestingly, no results concerning the
regime of $n$ going to infinity with $N$ fixed exist, even though the
investigation of this assumption has usually predated the analysis of the most
difficult $N$ and $n$ large case. This motivates our work. In particular, we
prove in the present paper that the RTEs converge to a deterministic matrix
when $n\to\infty$ with $N$ fixed, which is expressed as a function of the
theoretical covariance matrix. We also derive the fluctuations of the RTEs
around this deterministic matrix and establish that these fluctuations converge
in distribution to a multivariate Gaussian distribution with zero mean and a
covariance depending on the population covariance and the parameter $\rho$.
</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01252</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2015.2494858</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01255</identifier>
 <datestamp>2015-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-supervised Convolutional Neural Networks for Text Categorization
  via Region Embedding</dc:title>
 <dc:creator>Johnson, Rie</dc:creator>
 <dc:creator>Zhang, Tong</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper presents a new semi-supervised framework with convolutional neural
networks (CNNs) for text categorization. Unlike the previous approaches that
rely on word embeddings, our method learns embeddings of small text regions
from unlabeled data for integration into a supervised CNN. The proposed scheme
for embedding learning is based on the idea of two-view semi-supervised
learning, which is intended to be useful for the task of interest even though
the training is done on unlabeled data. Our models achieve better results than
previous approaches on sentiment classification and topic classification tasks.
</dc:description>
 <dc:description>Comment: v1 has a different title, and the results there are obsolete. The
  current version is to appear in NIPS 2015</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:date>2015-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01257</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Usages of Composition Search Tree in Web Service Composition</dc:title>
 <dc:creator>N, Lakshmi H</dc:creator>
 <dc:creator>Mohanty, Hrushikesha</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The increasing availability of web services within an organization and on the
Web demands for efficient search and composition mechanisms to find services
satisfying user requirements. Often consumers may be unaware of exact service
names that is fixed by service providers. Rather consumers being well aware of
their requirements would like to search a service based on their commitments
(inputs) and expectations (outputs). Based on this concept we have explored the
feasibility of I/O based web service search and composition in our previous
work. The classical definition of service composition, i.e., one-to-one and
onto mapping between input and output sets of composing services, is extended
to give rise to three types of service match: Exact, Super and Partial match.
Based on matches of all three types, different kinds of compositions are
defined: Exact, Super and Collaborative Composition. Process of composition,
being a match between inputs and outputs of services, is hastened by making use
of information on service dependency that is made available in repository as an
one time preprocessed information obtained from services populating the
registry. Adopting three schemes for matching for a desired service outputs,
the possibility of having different kinds of compositions is demonstrated in
form of a Composition Search Tree. As an extension to our previous work, in
this paper, we propose the utility of Composition Search Tree for finding
compositions of interest like leanest and the shortest depth compositions.
</dc:description>
 <dc:description>Comment: 11 Pages ISSN : 0973-8215 IK International Publishing House Pvt.
  Ltd., New Delhi, India</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01257</dc:identifier>
 <dc:identifier>International Journal of Information Processing, 9(1), 28-37, 2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01258</identifier>
 <datestamp>2016-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modal Analysis Using Sparse and Co-prime Arrays</dc:title>
 <dc:creator>Pakrooh, Pooria</dc:creator>
 <dc:creator>Scharf, Louis L.</dc:creator>
 <dc:creator>Pezeshki, Ali</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Let a measurement consist of a linear combination of damped complex
exponential modes, plus noise. The problem is to estimate the parameters of
these modes, as in line spectrum estimation, vibration analysis, speech
processing, system identification, and direction of arrival estimation. Our
results differ from standard results of modal analysis to the extent that we
consider sparse and co-prime samplings in space, or equivalently sparse and
co-prime samplings in time. Our main result is a characterization of the
orthogonal subspace. This is the subspace that is orthogonal to the signal
subspace spanned by the columns of the generalized Vandermonde matrix of modes
in sparse or co-prime arrays. This characterization is derived in a form that
allows us to adapt modern methods of linear prediction and approximate least
squares, such as iterative quadratic maximum likelihood (IQML), for estimating
mode parameters. Several numerical examples are presented to demonstrate the
validity of the proposed modal estimation methods, and to compare the fidelity
of modal estimation with sparse and co-prime arrays, versus SNR. Our
calculations of Cram\'{e}r-Rao bounds allow us to analyze the loss in
performance sustained by sparse and co-prime arrays that are compressions of
uniform linear arrays.
</dc:description>
 <dc:description>Comment: 22 pages</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01258</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2521616</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01274</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Weight Hierarchy of Some Reducible Cyclic Codes</dc:title>
 <dc:creator>Xiong, Maosheng</dc:creator>
 <dc:creator>Li, Shuxing</dc:creator>
 <dc:creator>Ge, Gennian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  The generalized Hamming weights (GHWs) of linear codes are fundamental
parameters, the knowledge of which is of great interest in many applications.
However, to determine the GHWs of linear codes is difficult in general. In this
paper, we study the GHWs for a family of reducible cyclic codes and obtain the
complete weight hierarchy in several cases. This is achieved by extending the
idea of \cite{YLFL} into higher dimension and by employing some interesting
combinatorial arguments. It shall be noted that these cyclic codes may have
arbitrary number of nonzeroes.
</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01274</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01287</identifier>
 <datestamp>2016-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing on Masked Data to improve the Security of Big Data</dc:title>
 <dc:creator>Gadepally, Vijay</dc:creator>
 <dc:creator>Hancock, Braden</dc:creator>
 <dc:creator>Kaiser, Benjamin</dc:creator>
 <dc:creator>Kepner, Jeremy</dc:creator>
 <dc:creator>Michaleas, Pete</dc:creator>
 <dc:creator>Varia, Mayank</dc:creator>
 <dc:creator>Yerukhimovich, Arkady</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Organizations that make use of large quantities of information require the
ability to store and process data from central locations so that the product
can be shared or distributed across a heterogeneous group of users. However,
recent events underscore the need for improving the security of data stored in
such untrusted servers or databases. Advances in cryptographic techniques and
database technologies provide the necessary security functionality but rely on
a computational model in which the cloud is used solely for storage and
retrieval. Much of big data computation and analytics make use of signal
processing fundamentals for computation. As the trend of moving data storage
and computation to the cloud increases, homeland security missions should
understand the impact of security on key signal processing kernels such as
correlation or thresholding. In this article, we propose a tool called
Computing on Masked Data (CMD), which combines advances in database
technologies and cryptographic tools to provide a low overhead mechanism to
offload certain mathematical operations securely to the cloud. This article
describes the design and development of the CMD tool.
</dc:description>
 <dc:description>Comment: 6 pages, Accepted to IEEE HST Conference</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01287</dc:identifier>
 <dc:identifier>doi:10.1109/THS.2015.7225312</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01294</identifier>
 <datestamp>2016-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Probabilistic $\ell_1$ Method for Clustering High Dimensional Data</dc:title>
 <dc:creator>Asamov, Tsvetan</dc:creator>
 <dc:creator>Ben-Israel, Adi</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In general, the clustering problem is NP-hard, and global optimality cannot
be established for non-trivial instances. For high-dimensional data,
distance-based methods for clustering or classification face an additional
difficulty, the unreliability of distances in very high-dimensional spaces. We
propose a distance-based iterative method for clustering data in very
high-dimensional space, using the $\ell_1$-metric that is less sensitive to
high dimensionality than the Euclidean distance. For $K$ clusters in
$\mathbb{R}^n$, the problem decomposes to $K$ problems coupled by
probabilities, and an iteration reduces to finding $Kn$ weighted medians of
points on a line. The complexity of the algorithm is linear in the dimension of
the data space, and its performance was observed to improve significantly as
the dimension increases.
</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:date>2016-04-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01304</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Utilizing de Bruijn graph of metagenome assembly for metatranscriptome
  analysis</dc:title>
 <dc:creator>Ye, Yuzhen</dc:creator>
 <dc:creator>Tang, Haixu</dc:creator>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Metagenomics research has accelerated the studies of microbial organisms,
providing insights into the composition and potential functionality of various
microbial communities. Metatranscriptomics (studies of the transcripts from a
mixture of microbial species) and other meta-omics approaches hold even greater
promise for providing additional insights into functional and regulatory
characteristics of the microbial communities. Current metatranscriptomics
projects are often carried out without matched metagenomic datasets (of the
same microbial communities). For the projects that produce both
metatranscriptomic and metagenomic datasets, their analyses are often not
integrated. Metagenome assemblies are far from perfect, partially explaining
why metagenome assemblies are not used for the analysis of metatranscriptomic
datasets. Here we report a reads mapping algorithm for mapping of short reads
onto a de Bruijn graph of assemblies. A hash table of junction k-mers (k-mers
spanning branching structures in the de Bruijn graph) is used to facilitate
fast mapping of reads to the graph. We developed an application of this mapping
algorithm: a reference based approach to metatranscriptome assembly using
graphs of metagenome assembly as the reference. Our results show that this new
approach (called TAG) helps to assemble substantially more transcripts that
otherwise would have been missed or truncated because of the fragmented nature
of the reference metagenome. TAG was implemented in C++ and has been tested
extensively on the linux platform. It is available for download as open source
at http://omics.informatics.indiana.edu/TAG.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures, accepted in RECOMB-Seq 2015, under consideration
  in Bioinformatics (a special issue for RECOMB-Seq/CBB)</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01304</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01310</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reproducibility as a Technical Specification</dc:title>
 <dc:creator>Crick, Tom</dc:creator>
 <dc:creator>Hall, Benjamin A.</dc:creator>
 <dc:creator>Ishtiaq, Samin</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Reproducibility of computationally-derived scientific discoveries should be a
certainty. As the product of several person-years' worth of effort, results --
whether disseminated through academic journals, conferences or exploited
through commercial ventures -- should at some level be expected to be
repeatable by other researchers. While this stance may appear to be obvious and
trivial, a variety of factors often stand in the way of making it commonplace.
Whilst there has been detailed cross-disciplinary discussions of the various
social, cultural and ideological drivers and (potential) solutions, one factor
which has had less focus is the concept of reproducibility as a technical
challenge. Specifically, that the definition of an unambiguous and measurable
standard of reproducibility would offer a significant benefit to the wider
computational science community.
  In this paper, we propose a high-level technical specification for a service
for reproducibility, presenting cyberinfrastructure and associated workflow for
a service which would enable such a specification to be verified and validated.
In addition to addressing a pressing need for the scientific community, we
further speculate on the potential contribution to the wider software
development community of services which automate de novo compilation and
testing of code from source. We illustrate our proposed specification and
workflow by using the BioModelAnalyzer tool as a running example.
</dc:description>
 <dc:description>Comment: Submitted to the 18th IEEE International Conference on Computational
  Science and Engineering (CSE 2015); 6 pages, LaTeX. arXiv admin note:
  substantial text overlap with arXiv:1502.02448</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:date>2015-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01311</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PTAS for MAP Assignment on Pairwise Markov Random Fields in Planar
  Graphs</dc:title>
 <dc:creator>Fox-Epstein, Eli</dc:creator>
 <dc:creator>Levin, Roie</dc:creator>
 <dc:creator>Meierfrankenfeld, David</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We present a PTAS for computing the maximum a posteriori assignment on
Pairwise Markov Random Fields with non-negative weights in planar graphs. This
algorithm is practical and not far behind state-of-the-art techniques in image
processing. MAP on Pairwise Markov Random Fields with (possibly) negative
weights cannot be approximated unless P = NP, even on planar graphs. We also
show via reduction that this yields a PTAS for one scoring function of
Correlation Clustering in planar graphs.
</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01311</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01316</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Progmosis: Evaluating Risky Individual Behavior During Epidemics Using
  Mobile Network Data</dc:title>
 <dc:creator>Lima, Antonio</dc:creator>
 <dc:creator>Pejovic, Veljko</dc:creator>
 <dc:creator>Rossi, Luca</dc:creator>
 <dc:creator>Musolesi, Mirco</dc:creator>
 <dc:creator>Gonzalez, Marta</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The possibility to analyze, quantify and forecast epidemic outbreaks is
fundamental when devising effective disease containment strategies. Policy
makers are faced with the intricate task of drafting realistically
implementable policies that strike a balance between risk management and cost.
Two major techniques policy makers have at their disposal are: epidemic
modeling and contact tracing. Models are used to forecast the evolution of the
epidemic both globally and regionally, while contact tracing is used to
reconstruct the chain of people who have been potentially infected, so that
they can be tested, isolated and treated immediately. However, both techniques
might provide limited information, especially during an already advanced crisis
when the need for action is urgent.
  In this paper we propose an alternative approach that goes beyond epidemic
modeling and contact tracing, and leverages behavioral data generated by mobile
carrier networks to evaluate contagion risk on a per-user basis. The individual
risk represents the loss incurred by not isolating or treating a specific
person, both in terms of how likely it is for this person to spread the disease
as well as how many secondary infections it will cause. To this aim, we develop
a model, named Progmosis, which quantifies this risk based on movement and
regional aggregated statistics about infection rates. We develop and release an
open-source tool that calculates this risk based on cellular network events. We
simulate a realistic epidemic scenarios, based on an Ebola virus outbreak; we
find that gradually restricting the mobility of a subset of individuals reduces
the number of infected people after 30 days by 24%.
</dc:description>
 <dc:description>Comment: D4D Senegal - NetMob 2015</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01320</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Timing Synchronization for AC-OFDM Based Optical Wireless
  Communications</dc:title>
 <dc:creator>Ranjha, Bilal A.</dc:creator>
 <dc:creator>Kashani, Mohammadreza A.</dc:creator>
 <dc:creator>Kavehrad, Mohsen</dc:creator>
 <dc:creator>Deng, Peng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:description>  Visible light communications (VLC) have recently attracted a growing interest
and can be a potential solution to realize indoor wireless communication with
high bandwidth capacity for RF-restricted environments such as airplanes and
hospitals. Optical based orthogonal frequency division multiplexing (OFDM)
systems have been proposed in the literature to combat multipath distortion and
intersymbol interference (ISI) caused by multipath signal propagation. In this
paper, we present a robust timing synchronization scheme suitable for
asymmetrically clipped (AC) OFDM based optical intensity modulated direct
detection (IM/DD) wireless systems. Our proposed method works perfectly for
ACO-OFDM, Pulse amplitude modulated discrete multitone (PAM-DMT) and discrete
Hartley transform (DHT) based optical OFDM systems. In contrast to existing
OFDM timing synchronization methods which are either not suitable for AC OFDM
techniques due to unipolar nature of output signal or perform poorly, our
proposed method is suitable for AC OFDM schemes and outperforms all other
available techniques. Both numerical and experimental results confirm the
accuracy of the proposed method. Our technique is also computationally
efficient as it requires very few computations as compared to conventional
methods in order to achieve good accuracy.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE ICNS 2015, 10 Pages, 7 figs</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01320</dc:identifier>
 <dc:identifier>doi:10.1109/ICNSURV.2015.7121217</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01329</identifier>
 <datestamp>2017-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Achieving algorithmic resilience for temporal integration through
  spectral deferred corrections</dc:title>
 <dc:creator>Grout, R. W.</dc:creator>
 <dc:creator>Kolla, H.</dc:creator>
 <dc:creator>Minion, M. L.</dc:creator>
 <dc:creator>Bell, J. B.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Spectral deferred corrections (SDC) is an iterative approach for constructing
higher- order accurate numerical approximations of ordinary differential
equations. SDC starts with an initial approximation of the solution defined at
a set of Gaussian or spectral collocation nodes over a time interval and uses
an iterative application of lower-order time discretizations applied to a
correction equation to improve the solution at these nodes. Each deferred
correction sweep increases the formal order of accuracy of the method up to the
limit inherent in the accuracy defined by the collocation points. In this
paper, we demonstrate that SDC is well suited to recovering from soft
(transient) hardware faults in the data. A strategy where extra correction
iterations are used to recover from soft errors and provide algorithmic
resilience is proposed. Specifically, in this approach the iteration is
continued until the residual (a measure of the error in the approximation) is
small relative to the residual on the first correction iteration and changes
slowly between successive iterations. We demonstrate the effectiveness of this
strategy for both canonical test problems and a comprehen- sive situation
involving a mature scientific application code that solves the reacting
Navier-Stokes equations for combustion research.
</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01329</dc:identifier>
 <dc:identifier>Commun. Appl. Math. Comput. Sci. 12 (2017) 25-50</dc:identifier>
 <dc:identifier>doi:10.2140/camcos.2017.12.25</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01339</identifier>
 <datestamp>2016-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Separating decision tree complexity from subcube partition complexity</dc:title>
 <dc:creator>Kothari, Robin</dc:creator>
 <dc:creator>Racicot-Desloges, David</dc:creator>
 <dc:creator>Santha, Miklos</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The subcube partition model of computation is at least as powerful as
decision trees but no separation between these models was known. We show that
there exists a function whose deterministic subcube partition complexity is
asymptotically smaller than its randomized decision tree complexity, resolving
an open problem of Friedgut, Kahn, and Wigderson (2002). Our lower bound is
based on the information-theoretic techniques first introduced to lower bound
the randomized decision tree complexity of the recursive majority function.
  We also show that the public-coin partition bound, the best known lower bound
method for randomized decision tree complexity subsuming other general
techniques such as block sensitivity, approximate degree, randomized
certificate complexity, and the classical adversary bound, also lower bounds
randomized subcube partition complexity. This shows that all these lower bound
techniques cannot prove optimal lower bounds for randomized decision tree
complexity, which answers an open question of Jain and Klauck (2010) and Jain,
Lee, and Vishnoi (2014).
</dc:description>
 <dc:description>Comment: 16 pages, 1 figure</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01339</dc:identifier>
 <dc:identifier>Leibniz International Proceedings in Informatics (LIPIcs) 40, pp.
  915-930 (2015)</dc:identifier>
 <dc:identifier>doi:10.4230/LIPIcs.APPROX-RANDOM.2015.915</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01344</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Early Stopping is Nonparametric Variational Inference</dc:title>
 <dc:creator>Maclaurin, Dougal</dc:creator>
 <dc:creator>Duvenaud, David</dc:creator>
 <dc:creator>Adams, Ryan P.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We show that unconverged stochastic gradient descent can be interpreted as a
procedure that samples from a nonparametric variational approximate posterior
distribution. This distribution is implicitly defined as the transformation of
an initial distribution by a sequence of optimization updates. By tracking the
change in entropy over this sequence of transformations during optimization, we
form a scalable, unbiased estimate of the variational lower bound on the log
marginal likelihood. We can use this bound to optimize hyperparameters instead
of using cross-validation. This Bayesian interpretation of SGD suggests
improved, overfitting-resistant optimization procedures, and gives a
theoretical foundation for popular tricks such as early stopping and
ensembling. We investigate the properties of this marginal likelihood estimator
on neural network models.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01344</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01352</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Broadcasting under the SINR Model</dc:title>
 <dc:creator>Reddy, Sai Praneeth</dc:creator>
 <dc:creator>Kowalski, Dariusz R.</dc:creator>
 <dc:creator>Vaya, Shailesh</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We study the multi-broadcast problem in multi-hop wireless networks under the
SINR model deployed in the 2D Euclidean plane. In multi-broadcast, there are
$k$ initial rumours, potentially belonging to different nodes, that must be
forwarded to all $n$ nodes of the network. Furthermore, in each round a node
can only transmit a small message that could contain at most one initial rumor
and $O(\log n)$ control bits. In order to be successfully delivered to a node,
transmissions must satisfy the (Signal-to-Inference-and-Noise-Ratio) SINR
condition and have sufficiently strong signal at the receiver. We present
deterministic algorithms for multi-broadcast for different settings that
reflect the different types of knowledge about the topology of the network
available to the nodes: (i) the whole network topology (ii) their own
coordinates and coordinates of their neighbors (iii) only their own
coordinates, and (iv) only their own ids and the ids of their neighbors. For
the former two settings, we present solutions that are scalable with respect to
the diameter of the network and the polylogarithm of the network size, i.e.,
$\log^c n$ for some constant $c&gt; 0$, while the solutions for the latter two
have round complexity that is superlinear in the number of nodes. The last
result is of special significance, as it is the first result for the SINR model
that does not require nodes to know their coordinates in the plane (a very
specialized type of knowledge), but intricately exploits the understanding that
nodes are implanted in the 2D Euclidean plane.
</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01352</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01355</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MacWilliams Extension Theorem for MDS additive codes</dc:title>
 <dc:creator>Dyshko, Serhii</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  The MacWilliams Extension Theorem states that each linear isometry of a
linear code extends to a monomial map. Unlike the linear codes, in general,
additive codes do not have the extension property. In this paper, an analogue
of the extension theorem for additive codes in the case of additive MDS codes
is proved. More precisely, it is shown that for almost all additive MDS codes
their additive isometries extend to isometries of the ambient space.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2015-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01355</dc:identifier>
 <dc:identifier>doi:10.1007/s10623-016-0247-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01356</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards the fast and robust optimal design of Wireless Body Area
  Networks</dc:title>
 <dc:creator>D'Andreagiovanni, Fabio</dc:creator>
 <dc:creator>Nardin, Antonella</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Wireless body area networks are wireless sensor networks whose adoption has
recently emerged and spread in important healthcare applications, such as the
remote monitoring of health conditions of patients. A major issue associated
with the deployment of such networks is represented by energy consumption: in
general, the batteries of the sensors cannot be easily replaced and recharged,
so containing the usage of energy by a rational design of the network and of
the routing is crucial. Another issue is represented by traffic uncertainty:
body sensors may produce data at a variable rate that is not exactly known in
advance, for example because the generation of data is event-driven. Neglecting
traffic uncertainty may lead to wrong design and routing decisions, which may
compromise the functionality of the network and have very bad effects on the
health of the patients. In order to address these issues, in this work we
propose the first robust optimization model for jointly optimizing the topology
and the routing in body area networks under traffic uncertainty. Since the
problem may result challenging even for a state-of-the-art optimization solver,
we propose an original optimization algorithm that exploits suitable linear
relaxations to guide a randomized fixing of the variables, supported by an
exact large variable neighborhood search. Experiments on realistic instances
indicate that our algorithm performs better than a state-of-the-art solver,
fast producing solutions associated with improved optimality gaps.
</dc:description>
 <dc:description>Comment: Authors' manuscript version of the paper that was published in
  Applied Soft Computing</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:date>2015-06-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01356</dc:identifier>
 <dc:identifier>Applied Soft Computing 37 (2015) 971-982</dc:identifier>
 <dc:identifier>doi:10.1016/j.asoc.2015.04.037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01358</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of P2P Network Security</dc:title>
 <dc:creator>Washbourne, Logan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This paper presents a review of peer-to-peer network security. Popular for
sharing of multimedia files, these networks carry risks and vulnerabilities
relating to data integrity, spyware, adware, and unwanted files. Further
attacks include those of forgery, pollution, repudiation, membership and
Eclipse attacks, neighbor selection attacks, Sybil, DoS, and omission attacks.
We review some protection mechanisms that have been devised.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01359</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Group Violations of Inequalities in five Subgroups</dc:title>
 <dc:creator>Markin, Nadya</dc:creator>
 <dc:creator>Thomas, Eldho K.</dc:creator>
 <dc:creator>Oggier, Frederique</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider ten linear rank inequalities, which always hold for ranks of
vector subspaces, and look at them as group inequalities. We prove that groups
of order pq, for p,q two distinct primes, always satisfy these ten group
inequalities. We give partial results for groups of order $p^2q$, and find that
the symmetric group $S_4$ is the smallest group that yield violations, for two
among the ten group inequalities.
</dc:description>
 <dc:date>2015-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01365</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PASSCoDe: Parallel ASynchronous Stochastic dual Co-ordinate Descent</dc:title>
 <dc:creator>Hsieh, Cho-Jui</dc:creator>
 <dc:creator>Yu, Hsiang-Fu</dc:creator>
 <dc:creator>Dhillon, Inderjit S.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Stochastic Dual Coordinate Descent (SDCD) has become one of the most
efficient ways to solve the family of $\ell_2$-regularized empirical risk
minimization problems, including linear SVM, logistic regression, and many
others. The vanilla implementation of DCD is quite slow; however, by
maintaining primal variables while updating dual variables, the time complexity
of SDCD can be significantly reduced. Such a strategy forms the core algorithm
in the widely-used LIBLINEAR package. In this paper, we parallelize the SDCD
algorithms in LIBLINEAR. In recent research, several synchronized parallel SDCD
algorithms have been proposed, however, they fail to achieve good speedup in
the shared memory multi-core setting. In this paper, we propose a family of
asynchronous stochastic dual coordinate descent algorithms (ASDCD). Each thread
repeatedly selects a random dual variable and conducts coordinate updates using
the primal variables that are stored in the shared memory. We analyze the
convergence properties when different locking/atomic mechanisms are applied.
For implementation with atomic operations, we show linear convergence under
mild conditions. For implementation without any atomic operations or locking,
we present the first {\it backward error analysis} for ASDCD under the
multi-core environment, showing that the converged solution is the exact
solution for a primal problem with perturbed regularizer. Experimental results
show that our methods are much faster than previous parallel coordinate descent
solvers.
</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01368</identifier>
 <datestamp>2016-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Competition between global and local online social networks</dc:title>
 <dc:creator>Kleineberg, Kaj-Kolja</dc:creator>
 <dc:creator>Boguna, Marian</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The overwhelming success of online social networks, the key actors in the Web
2.0 cosmos, has reshaped human interactions globally. To help understand the
fundamental mechanisms which determine the fate of online social networks at
the system level, we describe the digital world as a complex ecosystem of
interacting networks. In this paper, we study the impact of heterogeneity in
network fitnesses on the competition between an international network, such as
Facebook, and local services. The higher fitness of international networks is
induced by their ability to attract users from all over the world, which can
then establish social interactions without the limitations of local networks.
In other words, inter-country social ties lead to increased fitness of the
international network. To study the competition between an international
network and local ones, we construct a 1:1000 scale model of the digital world,
consisting of the 80 countries with the most Internet users. Under certain
conditions, this leads to the extinction of local networks; whereas under
different conditions, local networks can persist and even dominate completely.
In particular, our model suggests that, with the parameters that best reproduce
the empirical overtake of Facebook, this overtake could have not taken place
with a significant probability.
</dc:description>
 <dc:description>Comment: Supplementary Material is available at:
  http://www.nature.com/article-assets/npg/srep/2016/160427/srep25116/extref/srep25116-s3.pdf
  See videos at https://www.youtube.com/watch?v=z3dP3PD7ueA and
  https://www.youtube.com/watch?v=XkZTxnJd-eI</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:date>2016-04-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01368</dc:identifier>
 <dc:identifier>Sci. Rep. 6, 25116 (2016)</dc:identifier>
 <dc:identifier>doi:10.1038/srep25116</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01369</identifier>
 <datestamp>2016-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Recovery from Pairwise Measurements</dc:title>
 <dc:creator>Chen, Yuxin</dc:creator>
 <dc:creator>Suh, Changho</dc:creator>
 <dc:creator>Goldsmith, Andrea J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper is concerned with jointly recovering $n$ node-variables $\left\{
x_{i}\right\}_{1\leq i\leq n}$ from a collection of pairwise difference
measurements. Imagine we acquire a few observations taking the form of
$x_{i}-x_{j}$; the observation pattern is represented by a measurement graph
$\mathcal{G}$ with an edge set $\mathcal{E}$ such that $x_{i}-x_{j}$ is
observed if and only if $(i,j)\in\mathcal{E}$. To account for noisy
measurements in a general manner, we model the data acquisition process by a
set of channels with given input/output transition measures. Employing
information-theoretic tools applied to channel decoding problems, we develop a
\emph{unified} framework to characterize the fundamental recovery criterion,
which accommodates general graph structures, alphabet sizes, and channel
transition measures. In particular, our results isolate a family of
\emph{minimum} \emph{channel divergence measures} to characterize the degree of
measurement corruption, which together with the size of the minimum cut of
$\mathcal{G}$ dictates the feasibility of exact information recovery. For
various homogeneous graphs, the recovery condition depends almost only on the
edge sparsity of the measurement graph irrespective of other graphical metrics;
alternatively, the minimum sample complexity required for these graphs scales
like \[ \text{minimum sample complexity }\asymp\frac{n\log
n}{\mathsf{Hel}_{1/2}^{\min}} \] for certain information metric
$\mathsf{Hel}_{1/2}^{\min}$ defined in the main text, as long as the alphabet
size is not super-polynomial in $n$. We apply our general theory to three
concrete applications, including the stochastic block model, the outlier model,
and the haplotype assembly problem. Our theory leads to order-wise tight
recovery conditions for all these scenarios.
</dc:description>
 <dc:description>Comment: This work has been presented in part in ISIT 2014
  (http://arxiv.org/abs/1404.7105) and ISIT 2015</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:date>2016-05-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01369</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01375</identifier>
 <datestamp>2015-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preprint Traffic Management and Forecasting System Based on 3D GIS</dc:title>
 <dc:creator>Li, Xiaoming</dc:creator>
 <dc:creator>Lv, Zhihan</dc:creator>
 <dc:creator>Hu, Jinxing</dc:creator>
 <dc:creator>Zhang, Baoyun</dc:creator>
 <dc:creator>Yin, Ling</dc:creator>
 <dc:creator>Zhong, Chen</dc:creator>
 <dc:creator>Wang, Weixi</dc:creator>
 <dc:creator>Feng, Shengzhong</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>I.3.7</dc:subject>
 <dc:description>  This is the preprint version of our paper on 2015 15th IEEE/ACM International
Symposium on Cluster, Cloud and Grid Computing (CCGrid). This paper takes
Shenzhen Futian comprehensive transportation junction as the case, and makes
use of continuous multiple real-time dynamic traffic information to carry out
monitoring and analysis on spatial and temporal distribution of passenger flow
under different means of transportation and service capacity of junction from
multi-dimensional space-time perspectives such as different period and special
period. Virtual reality geographic information system is employed to present
the forecasting result.
</dc:description>
 <dc:description>Comment: This is the preprint version of our paper on 2015 15th IEEE/ACM
  International Symposium on Cluster, Cloud and Grid Computing (CCGrid). arXiv
  admin note: text overlap with arXiv:1504.01057. arXiv admin note: substantial
  text overlap with arXiv:1504.01057</dc:description>
 <dc:date>2015-04-04</dc:date>
 <dc:date>2015-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01375</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01379</identifier>
 <datestamp>2015-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preprint Big City 3D Visual Analysis</dc:title>
 <dc:creator>Lv, Zhihan</dc:creator>
 <dc:creator>Li, Xiaoming</dc:creator>
 <dc:creator>Zhang, Baoyun</dc:creator>
 <dc:creator>Wang, Weixi</dc:creator>
 <dc:creator>Feng, Shengzhong</dc:creator>
 <dc:creator>Hu, Jinxing</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>I.3.7</dc:subject>
 <dc:description>  This is the preprint version of our paper on EUROGRAPHICS 2015. A big city
visual analysis platform based on Web Virtual Reality Geographical Information
System (WEBVRGIS) is presented. Extensive model editing functions and spatial
analysis functions are available, including terrain analysis, spatial analysis,
sunlight analysis, traffic analysis, population analysis and community
analysis.
</dc:description>
 <dc:description>Comment: This is the preprint version of our paper on EUROGRAPHICS 2015</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:date>2015-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01380</identifier>
 <datestamp>2015-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The swept rule for breaking the latency barrier in time advancing PDEs</dc:title>
 <dc:creator>Alhubail, Maitham Makki</dc:creator>
 <dc:creator>Wang, Qiqi</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  This article investigates the swept rule of space-time domain decomposition,
an idea to break the latency barrier via communicating less often when
explicitly solving time-dependent PDEs. The swept rule decomposes space and
time among computing nodes in ways that exploit the domains of influence and
the domain of dependency, making it possible to communicate once per many
timesteps without redundant computation. The article presents simple
theoretical analysis to the performance of the swept rule which then was shown
to be accurate by conducting numerical experiments.
</dc:description>
 <dc:description>Comment: 30 pages</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:date>2015-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01380</dc:identifier>
 <dc:identifier>Journal of Computational Physics (2016), pp. 110-121</dc:identifier>
 <dc:identifier>doi:10.1016/j.jcp.2015.11.026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01381</identifier>
 <datestamp>2015-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Soft Errors in Uncore Components</dc:title>
 <dc:creator>Cho, Hyungmin</dc:creator>
 <dc:creator>Cher, Chen-Yong</dc:creator>
 <dc:creator>Shepherd, Thomas</dc:creator>
 <dc:creator>Mitra, Subhasish</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>B.8.1</dc:subject>
 <dc:description>  The effects of soft errors in processor cores have been widely studied.
However, little has been published about soft errors in uncore components, such
as memory subsystem and I/O controllers, of a System-on-a-Chip (SoC). In this
work, we study how soft errors in uncore components affect system-level
behaviors. We have created a new mixed-mode simulation platform that combines
simulators at two different levels of abstraction, and achieves 20,000x speedup
over RTL-only simulation. Using this platform, we present the first study of
the system-level impact of soft errors inside various uncore components of a
large-scale, multi-core SoC using the industrial-grade, open-source OpenSPARC
T2 SoC design. Our results show that soft errors in uncore components can
significantly impact system-level reliability. We also demonstrate that uncore
soft errors can create major challenges for traditional system-level checkpoint
recovery techniques. To overcome such recovery challenges, we present a new
replay recovery technique for uncore components belonging to the memory
subsystem. For the L2 cache controller and the DRAM controller components of
OpenSPARC T2, our new technique reduces the probability that an application run
fails to produce correct results due to soft errors by more than 100x with
3.32% and 6.09% chip-level area and power impact, respectively.
</dc:description>
 <dc:description>Comment: to be published in Proceedings of the 52nd Annual Design Automation
  Conference</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:date>2015-05-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01381</dc:identifier>
 <dc:identifier>doi:10.1145/2744769.2744923</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01383</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QUOTUS: The Structure of Political Media Coverage as Revealed by Quoting
  Patterns</dc:title>
 <dc:creator>Niculae, Vlad</dc:creator>
 <dc:creator>Suen, Caroline</dc:creator>
 <dc:creator>Zhang, Justine</dc:creator>
 <dc:creator>Danescu-Niculescu-Mizil, Cristian</dc:creator>
 <dc:creator>Leskovec, Jure</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Given the extremely large pool of events and stories available, media outlets
need to focus on a subset of issues and aspects to convey to their audience.
Outlets are often accused of exhibiting a systematic bias in this selection
process, with different outlets portraying different versions of reality.
However, in the absence of objective measures and empirical evidence, the
direction and extent of systematicity remains widely disputed.
  In this paper we propose a framework based on quoting patterns for
quantifying and characterizing the degree to which media outlets exhibit
systematic bias. We apply this framework to a massive dataset of news articles
spanning the six years of Obama's presidency and all of his speeches, and
reveal that a systematic pattern does indeed emerge from the outlet's quoting
behavior. Moreover, we show that this pattern can be successfully exploited in
an unsupervised prediction setting, to determine which new quotes an outlet
will select to broadcast. By encoding bias patterns in a low-rank space we
provide an analysis of the structure of political media coverage. This reveals
a latent media bias space that aligns surprisingly well with political ideology
and outlet type. A linguistic analysis exposes striking differences across
these latent dimensions, showing how the different types of media outlets
portray different realities even when reporting on the same events. For
example, outlets mapped to the mainstream conservative side of the latent space
focus on quotes that portray a presidential persona disproportionately
characterized by negativity.
</dc:description>
 <dc:description>Comment: To appear in the Proceedings of WWW 2015. 11pp, 10 fig. Interactive
  visualization, data, and other info available at
  http://snap.stanford.edu/quotus/</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01407</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shannon's entropy revisited</dc:title>
 <dc:creator>Viznyuk, Sergei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  I consider the effect of a finite sample size on the entropy of a sample of
independent events. I propose formula for entropy which satisfies Shannon's
axioms, and which reduces to Shannon's entropy when sample size is infinite. I
discuss the physical meaning of the difference between two formulas, including
some practical implications, such as maximum achievable channel utilization,
and minimum achievable communication protocol overhead, for a given message
size.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure</dc:description>
 <dc:date>2015-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01407</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01420</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge driven Offline to Online Script Conversion</dc:title>
 <dc:creator>Kopparapu, Sunil</dc:creator>
 <dc:creator>Devanuj</dc:creator>
 <dc:creator>Srivastava, Akhilesh</dc:creator>
 <dc:creator>Rao, P. V. S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The problem of offline to online script conversion is a challenging and an
ill-posed problem. The interest in offline to online conversion exists because
there are a plethora of robust algorithms in online script literature which can
not be used on offline scripts. In this paper, we propose a method, based on
heuristics, to extract online script information from offline bitmap image. We
show the performance of the proposed method on a real sample signature offline
image, whose online information is known.
</dc:description>
 <dc:description>Comment: 4 pages, 5 figures, KBCS 2004</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01424</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improvement of the image quality of random phase--free holography using
  an iterative method</dc:title>
 <dc:creator>Shimobaba, Tomoyoshi</dc:creator>
 <dc:creator>Kakue, Takashi</dc:creator>
 <dc:creator>Endo, Yutaka</dc:creator>
 <dc:creator>Hirayama, Ryuji</dc:creator>
 <dc:creator>Hiyama, Daisuke</dc:creator>
 <dc:creator>Hasegawa, Satoki</dc:creator>
 <dc:creator>Nagahama, Yuki</dc:creator>
 <dc:creator>Sano, Marie</dc:creator>
 <dc:creator>Oikawa, Minoru</dc:creator>
 <dc:creator>Sugie, Takashige</dc:creator>
 <dc:creator>Ito, Tomoyoshi</dc:creator>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Our proposed method of random phase-free holography using virtual convergence
light can obtain large reconstructed images exceeding the size of the hologram,
without the assistance of random phase. The reconstructed images have
low-speckle noise in the amplitude and phase-only holograms (kinoforms);
however, in low-resolution holograms, we obtain a degraded image quality
compared to the original image. We propose an iterative random phase-free
method with virtual convergence light to address this problem.
</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01427</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Metric to Classify Style of Spoken Speech</dc:title>
 <dc:creator>Kopparapu, Sunil</dc:creator>
 <dc:creator>Bhatnagar, Saurabh</dc:creator>
 <dc:creator>Sahana, K.</dc:creator>
 <dc:creator>Sathyanarayana</dc:creator>
 <dc:creator>Srivastava, Akhilesh</dc:creator>
 <dc:creator>Rao, P. V. S.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The ability to classify spoken speech based on the style of speaking is an
important problem. With the advent of BPO's in recent times, specifically those
that cater to a population other than the local population, it has become
necessary for BPO's to identify people with certain style of speaking
(American, British etc). Today BPO's employ accent analysts to identify people
having the required style of speaking. This process while involving human bias,
it is becoming increasingly infeasible because of the high attrition rate in
the BPO industry. In this paper, we propose a new metric, which robustly and
accurately helps classify spoken speech based on the style of speaking. The
role of the proposed metric is substantiated by using it to classify real
speech data collected from over seventy different people working in a BPO. We
compare the performance of the metric against human experts who independently
carried out the classification process. Experimental results show that the
performance of the system using the novel metric performs better than two
different human expert.
</dc:description>
 <dc:description>Comment: 5 pages; OCOCOSDA 2010</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01427</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01431</identifier>
 <datestamp>2015-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>If the Current Clique Algorithms are Optimal, so is Valiant's Parser</dc:title>
 <dc:creator>Abboud, Amir</dc:creator>
 <dc:creator>Backurs, Arturs</dc:creator>
 <dc:creator>Williams, Virginia Vassilevska</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The CFG recognition problem is: given a context-free grammar $\mathcal{G}$
and a string $w$ of length $n$, decide if $w$ can be obtained from
$\mathcal{G}$. This is the most basic parsing question and is a core computer
science problem. Valiant's parser from 1975 solves the problem in
$O(n^{\omega})$ time, where $\omega&lt;2.373$ is the matrix multiplication
exponent. Dozens of parsing algorithms have been proposed over the years, yet
Valiant's upper bound remains unbeaten. The best combinatorial algorithms have
mildly subcubic $O(n^3/\log^3{n})$ complexity.
  Lee (JACM'01) provided evidence that fast matrix multiplication is needed for
CFG parsing, and that very efficient and practical algorithms might be hard or
even impossible to obtain. Lee showed that any algorithm for a more general
parsing problem with running time $O(|\mathcal{G}|\cdot n^{3-\varepsilon})$ can
be converted into a surprising subcubic algorithm for Boolean Matrix
Multiplication. Unfortunately, Lee's hardness result required that the grammar
size be $|\mathcal{G}|=\Omega(n^6)$. Nothing was known for the more relevant
case of constant size grammars.
  In this work, we prove that any improvement on Valiant's algorithm, even for
constant size grammars, either in terms of runtime or by avoiding the
inefficiencies of fast matrix multiplication, would imply a breakthrough
algorithm for the $k$-Clique problem: given a graph on $n$ nodes, decide if
there are $k$ that form a clique.
  Besides classifying the complexity of a fundamental problem, our reduction
has led us to similar lower bounds for more modern and well-studied cubic time
problems for which faster algorithms are highly desirable in practice: RNA
Folding, a central problem in computational biology, and Dyck Language Edit
Distance, answering an open question of Saha (FOCS'14).
</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:date>2015-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01433</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated System for Improving RSS Feeds Data Quality</dc:title>
 <dc:creator>Hurtado, Joan</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Nowadays, the majority of RSS feeds provide incomplete information about
their news items. The lack of information leads to engagement loss in users. We
present a new automated system for improving the RSS feeds' data quality. RSS
feeds provide a list of the latest news items ordered by date. Therefore, it
makes it easy for a web crawler to precisely locate the item and extract its
raw content. Then it identifies where the main content is located and extracts:
main text corpus, relevant keywords, bigrams, best image and predicts the
category of the item. The output of the system is an enhanced RSS feed. The
proposed system showed an average item data quality improvement from 39.98% to
95.62%.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01433</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01438</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence Time of Quantized Metropolis Consensus Over Time-Varying
  Networks</dc:title>
 <dc:creator>Basar, Tamer</dc:creator>
 <dc:creator>Etesami, Seyed Rasoul</dc:creator>
 <dc:creator>Olshevsky, Alex</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We consider the quantized consensus problem on undirected time-varying
connected graphs with n nodes, and devise a protocol with fast convergence time
to the set of consensus points. Specifically, we show that when the edges of
each network in a sequence of connected time-varying networks are activated
based on Poisson processes with Metropolis rates, the expected convergence time
to the set of consensus points is at most O(n^2 log^2 n), where each node
performs a constant number of updates per unit time.
</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01438</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01441</identifier>
 <datestamp>2015-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Locally Non-rigid Registration for Mobile HDR Photography</dc:title>
 <dc:creator>Gallo, Orazio</dc:creator>
 <dc:creator>Troccoli, Alejandro</dc:creator>
 <dc:creator>Hu, Jun</dc:creator>
 <dc:creator>Pulli, Kari</dc:creator>
 <dc:creator>Kautz, Jan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image registration for stack-based HDR photography is challenging. If not
properly accounted for, camera motion and scene changes result in artifacts in
the composite image. Unfortunately, existing methods to address this problem
are either accurate, but too slow for mobile devices, or fast, but prone to
failing. We propose a method that fills this void: our approach is extremely
fast---under 700ms on a commercial tablet for a pair of 5MP images---and
prevents the artifacts that arise from insufficient registration quality.
</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:date>2015-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01441</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01442</identifier>
 <datestamp>2015-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Effect of Recency to Human Mobility</dc:title>
 <dc:creator>Barbosa, Hugo</dc:creator>
 <dc:creator>Neto, Fernando Buarque de Lima</dc:creator>
 <dc:creator>Evsukoff, Alexandre</dc:creator>
 <dc:creator>Menezes, Ronaldo</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In recent years, we have seen scientists attempt to model and explain human
dynamics and, in particular, human movement. Many aspects of our complex life
are affected by human movements such as disease spread and epidemics modeling,
city planning, wireless network development, and disaster relief, to name a
few. Given the myriad of applications it is clear that a complete understanding
of how people move in space can lead to huge benefits to our society. In most
of the recent works, scientists have focused on the idea that people movements
are biased towards frequently-visited locations. According to them, human
movement is based on an exploration/exploitation dichotomy in which individuals
choose new locations (exploration) or return to frequently-visited locations
(exploitation). In this work, we focus on the concept of recency. We propose a
model in which exploitation in human movement also considers recently-visited
locations and not solely frequently-visited locations. We test our hypothesis
against different empirical data of human mobility and show that our proposed
model is able to better explain the human trajectories in these datasets.
</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:date>2015-06-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01442</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01446</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Totally Corrective Boosting with Cardinality Penalization</dc:title>
 <dc:creator>Denchev, Vasil S.</dc:creator>
 <dc:creator>Ding, Nan</dc:creator>
 <dc:creator>Matsushima, Shin</dc:creator>
 <dc:creator>Vishwanathan, S. V. N.</dc:creator>
 <dc:creator>Neven, Hartmut</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  We propose a totally corrective boosting algorithm with explicit cardinality
regularization. The resulting combinatorial optimization problems are not known
to be efficiently solvable with existing classical methods, but emerging
quantum optimization technology gives hope for achieving sparser models in
practice. In order to demonstrate the utility of our algorithm, we use a
distributed classical heuristic optimizer as a stand-in for quantum hardware.
Even though this evaluation methodology incurs large time and resource costs on
classical computing machinery, it allows us to gauge the potential gains in
generalization performance and sparsity of the resulting boosted ensembles. Our
experimental results on public data sets commonly used for benchmarking of
boosting algorithms decidedly demonstrate the existence of such advantages. If
actual quantum optimization were to be used with this algorithm in the future,
we would expect equivalent or superior results at much smaller time and energy
costs during training. Moreover, studying cardinality-penalized boosting also
sheds light on why unregularized boosting algorithms with early stopping often
yield better results than their counterparts with explicit convex
regularization: Early stopping performs suboptimal cardinality regularization.
The results that we present here indicate it is beneficial to explicitly solve
the combinatorial problem still left open at early termination.
</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01446</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01452</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Performance Analysis of Coded Cache in Wireless Fading Channel</dc:title>
 <dc:creator>Huang, Wei</dc:creator>
 <dc:creator>Wang, Sinong</dc:creator>
 <dc:creator>Ding, Lianghui</dc:creator>
 <dc:creator>Yang, Feng</dc:creator>
 <dc:creator>Zhang, Wenjun</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The rapid growth of data volume and the accompanying congestion problems over
the wireless networks have been critical issues to content providers. A novel
technique, termed as coded cache, is proposed to relieve the burden. Through
creating coded-multicasting opportunities, the coded-cache scheme can provide
extra performance gain over the conventional push technique that simply
pre-stores contents at local caches during the network idle period. But
existing works on the coded caching scheme assumed the availability of an
error-free shared channel accessible by each user. This paper considers the
more realistic scenario where each user may experience different link quality.
In this case, the system performance would be restricted by the user with the
worst channel condition. And the corresponding resource allocation schemes
aimed at breaking this obstacles are developed. Specifically, we employ the
coded caching scheme in time division and frequency division transmission mode
and formulate the sub-optimal problems. Power and bandwidth are allocated
respectively to maximum the system throughput. The simulation results show that
the throughput of the technique in wireless scenario will be limited and would
decrease as the number of users becomes sufficiently large.
</dc:description>
 <dc:description>Comment: submitted GC2015</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01452</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01456</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Measurement and Reconstruction for Noisy Graph Signals</dc:title>
 <dc:creator>Wang, Xiaohan</dc:creator>
 <dc:creator>Chen, Jiaxuan</dc:creator>
 <dc:creator>Gu, Yuantao</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The emerging field of signal processing on graph plays a more and more
important role in processing signals and information related to networks.
Existing works have shown that under certain conditions a smooth graph signal
can be uniquely reconstructed from its decimation, i.e., data associated with a
subset of vertices. However, in some potential applications (e.g., sensor
networks with clustering structure), the obtained data may be a combination of
signals associated with several vertices, rather than the decimation. In this
paper, we propose a new concept of local measurement, which is a generalization
of decimation. Using the local measurements, a local-set-based method named
iterative local measurement reconstruction (ILMR) is proposed to reconstruct
bandlimited graph signals. It is proved that ILMR can reconstruct the original
signal perfectly under certain conditions. The performance of ILMR against
noise is theoretically analyzed. The optimal choice of local weights and a
greedy algorithm of local set partition are given in the sense of minimizing
the expected reconstruction error. Compared with decimation, the proposed local
measurement sampling and reconstruction scheme is more robust in noise existing
scenarios.
</dc:description>
 <dc:description>Comment: 24 pages, 6 figures, 2 tables, journal manuscript</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01459</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Complete Worst-Case Analysis of Heapsort with Experimental
  Verification of Its Results, A manuscript (MS)</dc:title>
 <dc:creator>Suchenek, Marek A.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>68W40, 11A63</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  A rigorous proof is presented that the number of comparisons of keys
performed in the worst case by ${\tt Heapsort}$ on any array of size $N \geq 2$
is equal to: $ 2 (N-1)\, ( \, \lg \frac{N-1}{2} +\varepsilon \, ) - 2s_2(N) -
e_2(N) + \min (\lfloor \lg (N-1) \rfloor, 2) + 6 + c, $ where $ \varepsilon $,
given by: $\varepsilon = 1 + \lceil \lg \, (N-1) \rceil - \lg \, (N-1) -
2^{\lceil \lg \, (N-1) \rceil - \lg \, (N-1)} ,$ is a function of $ N $ with
the minimum value 0 and and the supremum value $\delta = 1 - \lg e + \lg \lg e
\approx 0.0860713320559342$, $s_2(N)$ is the sum of all digits of the binary
representation of $N$, $e_2(N)$ is the exponent of $2$ in the prime
factorization of $N$, and $ c $ is a binary function on the set of integers
defined by: $c = 1$, if $N \leq 2 ^{\lceil \lg N \rceil} - 4$, and $c = 0$,
otherwise. An algorithm that generates worst-case input arrays of any size $ N
\geq 2 $ for ${\tt Heapsort}$ is offered. The algorithm has been implemented in
Java, runs in $O( N \log N )$ time, and allows for precise experimental
verification of the above formula.
</dc:description>
 <dc:description>Comment: 115 pages 41 figures</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01467</identifier>
 <datestamp>2015-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uncertainty principle, Shannon-Nyquist sampling and beyond</dc:title>
 <dc:creator>Fujikawa, Kazuo</dc:creator>
 <dc:creator>Ge, Mo-Lin</dc:creator>
 <dc:creator>Liu, Yu-Long</dc:creator>
 <dc:creator>Zhao, Qing</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Donoho and Stark have shown that a precise deterministic recovery of missing
information contained in a time interval shorter than the time-frequency
uncertainty limit is possible. We analyze this signal recovery mechanism from a
physics point of view and show that the well-known Shannon-Nyquist sampling
theorem, which is fundamental in signal processing, also uses essentially the
same mechanism. The uncertainty relation in the context of information theory,
which is based on Fourier analysis, provides a criterion to distinguish
Shannon-Nyquist sampling from compressed sensing. A new signal recovery
formula, which is analogous to Donoho-Stark formula, is given using the idea of
Shannon-Nyquist sampling; in this formulation, the smearing of information
below the uncertainty limit as well as the recovery of information with
specified bandwidth take place. We also discuss the recovery of states from the
domain below the uncertainty limit of coordinate and momentum in quantum
mechanics and show that in principle the state recovery works by assuming ideal
measurement procedures. The recovery of the lost information in the
sub-uncertainty domain means that the loss of information in such a small
domain is not fatal, which is in accord with our common understanding of the
uncertainty principle, although its precise recovery is something we are not
used to in quantum mechanics. The uncertainty principle provides a universal
sampling criterion covering both the classical Shannon-Nyquist sampling theorem
and the quantum mechanical measurement.
</dc:description>
 <dc:description>Comment: 27 pages. Journal of Physical Society of Japan (in press)</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01467</dc:identifier>
 <dc:identifier>doi:10.7566/JPSJ.84.064801</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01472</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Lower Bounds for the Shannon Capacity of Odd Cycles</dc:title>
 <dc:creator>Mathew, K. Ashik</dc:creator>
 <dc:creator>&#xd6;sterg&#xe5;rd, Patric R. J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  The Shannon capacity of a graph $G$ is defined as $c(G)=\sup_{d\geq
1}(\alpha(G^d))^{\frac{1}{d}},$ where $\alpha(G)$ is the independence number of
$G$. The Shannon capacity of the cycle $C_5$ on $5$ vertices was determined by
Lov\'{a}sz in 1979, but the Shannon capacity of a cycle $C_p$ for general odd
$p$ remains one of the most notorious open problems in information theory. By
prescribing stabilizers for the independent sets in $C_p^d$ and using
stochastic search methods, we show that $\alpha(C_7^5)\geq 350$,
$\alpha(C_{11}^4)\geq 748$, $\alpha(C_{13}^4)\geq 1534$ and
$\alpha(C_{15}^3)\geq 381$. This leads to improved lower bounds on the Shannon
capacity of $C_7$ and $C_{15}$: $c(C_7)\geq 350^{\frac{1}{5}}&gt; 3.2271$ and
$c(C_{15})\geq 381^{\frac{1}{3}}&gt; 7.2495$.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01476</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mobile Phone Based Vehicle License Plate Recognition for Road Policing</dc:title>
 <dc:creator>L., Lajish V.</dc:creator>
 <dc:creator>Kopparapu, Sunil Kumar</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Identity of a vehicle is done through the vehicle license plate by traffic
police in general. Au- tomatic vehicle license plate recognition has several
applications in intelligent traffic management systems. The security situation
across the globe and particularly in India demands a need to equip the traffic
police with a system that enables them to get instant details of a vehicle. The
system should be easy to use, should be mobile, and work 24 x 7. In this paper,
we describe a mobile phone based, client-server architected, license plate
recognition system. While we use the state of the art image processing and
pattern recognition algorithms tuned for Indian conditions to automatically
recognize non-uniform license plates, the main contribution is in creating an
end to end usable solution. The client application runs on a mobile device and
a server application, with access to vehicle information database, is hosted
centrally. The solution enables capture of license plate image captured by the
phone camera and passes to the server; on the server the license plate number
is recognized; the data associated with the number plate is then sent back to
the mobile device, instantaneously. We describe the end to end system
architecture in detail. A working prototype of the proposed system has been
implemented in the lab environment.
</dc:description>
 <dc:description>Comment: 7 pages; PReMI Experiential Workshop, Delhi</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01479</identifier>
 <datestamp>2015-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From seconds to months: multi-scale dynamics of mobile telephone calls</dc:title>
 <dc:creator>Saramaki, Jari</dc:creator>
 <dc:creator>Moro, Esteban</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Big Data on electronic records of social interactions allow approaching human
behaviour and sociality from a quantitative point of view with unforeseen
statistical power. Mobile telephone Call Detail Records (CDRs), automatically
collected by telecom operators for billing purposes, have proven especially
fruitful for understanding one-to-one communication patterns as well as the
dynamics of social networks that are reflected in such patterns. We present an
overview of empirical results on the multi-scale dynamics of social dynamics
and networks inferred from mobile telephone calls. We begin with the shortest
timescales and fastest dynamics, such as burstiness of call sequences between
individuals, and &quot;zoom out&quot; towards longer temporal and larger structural
scales, from temporal motifs formed by correlated calls between multiple
individuals to long-term dynamics of social groups. We conclude this overview
with a future outlook.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01479</dc:identifier>
 <dc:identifier>Eur. Phys. J. B (2015) 88: 164</dc:identifier>
 <dc:identifier>doi:10.1140/epjb/e2015-60106-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01482</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Recurrent Neural Networks for Acoustic Modelling</dc:title>
 <dc:creator>Chan, William</dc:creator>
 <dc:creator>Lane, Ian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a novel deep Recurrent Neural Network (RNN) model for acoustic
modelling in Automatic Speech Recognition (ASR). We term our contribution as a
TC-DNN-BLSTM-DNN model, the model combines a Deep Neural Network (DNN) with
Time Convolution (TC), followed by a Bidirectional Long Short-Term Memory
(BLSTM), and a final DNN. The first DNN acts as a feature processor to our
model, the BLSTM then generates a context from the sequence acoustic signal,
and the final DNN takes the context and models the posterior probabilities of
the acoustic states. We achieve a 3.47 WER on the Wall Street Journal (WSJ)
eval92 task or more than 8% relative improvement over the baseline DNN models.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01483</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transferring Knowledge from a RNN to a DNN</dc:title>
 <dc:creator>Chan, William</dc:creator>
 <dc:creator>Ke, Nan Rosemary</dc:creator>
 <dc:creator>Lane, Ian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep Neural Network (DNN) acoustic models have yielded many state-of-the-art
results in Automatic Speech Recognition (ASR) tasks. More recently, Recurrent
Neural Network (RNN) models have been shown to outperform DNNs counterparts.
However, state-of-the-art DNN and RNN models tend to be impractical to deploy
on embedded systems with limited computational capacity. Traditionally, the
approach for embedded platforms is to either train a small DNN directly, or to
train a small DNN that learns the output distribution of a large DNN. In this
paper, we utilize a state-of-the-art RNN to transfer knowledge to small DNN. We
use the RNN model to generate soft alignments and minimize the Kullback-Leibler
divergence against the small DNN. The small DNN trained on the soft RNN
alignments achieved a 3.93 WER on the Wall Street Journal (WSJ) eval92 task
compared to a baseline 4.54 WER or more than 13% relative improvement.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01488</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On-line Handwritten Devanagari Character Recognition using Fuzzy
  Directional Features</dc:title>
 <dc:creator>Kopparapu, Sunil Kumar</dc:creator>
 <dc:creator>VL, Lajish</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper describes a new feature set for use in the recognition of on-line
handwritten Devanagari script based on Fuzzy Directional Features. Experiments
are conducted for the automatic recognition of isolated handwritten character
primitives (sub-character units). Initially we describe the proposed feature
set, called the Fuzzy Directional Features (FDF) and then show how these
features can be effectively utilized for writer independent character
recognition. Experimental results show that FDF set perform well for writer
independent data set at stroke level recognition. The main contribution of this
paper is the introduction of a novel feature set and establish experimentally
its ability in recognition of handwritten Devanagari script.
</dc:description>
 <dc:description>Comment: 6 pages; 2009</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01492</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient SDP Inference for Fully-connected CRFs Based on Low-rank
  Decomposition</dc:title>
 <dc:creator>Wang, Peng</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Hengel, Anton van den</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Conditional Random Fields (CRF) have been widely used in a variety of
computer vision tasks. Conventional CRFs typically define edges on neighboring
image pixels, resulting in a sparse graph such that efficient inference can be
performed. However, these CRFs fail to model long-range contextual
relationships. Fully-connected CRFs have thus been proposed. While there are
efficient approximate inference methods for such CRFs, usually they are
sensitive to initialization and make strong assumptions. In this work, we
develop an efficient, yet general algorithm for inference on fully-connected
CRFs. The algorithm is based on a scalable SDP algorithm and the low- rank
approximation of the similarity/kernel matrix. The core of the proposed
algorithm is a tailored quasi-Newton method that takes advantage of the
low-rank matrix approximation when solving the specialized SDP dual problem.
Experiments demonstrate that our method can be applied on fully-connected CRFs
that cannot be solved previously, such as pixel-level image co-segmentation.
</dc:description>
 <dc:description>Comment: 15 pages. A conference version of this work appears in Proc. IEEE
  Conference on Computer Vision and Pattern Recognition, 2015</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01492</dc:identifier>
 <dc:identifier>doi:10.1109/CVPR.2015.7298942</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01496</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Voice based self help System: User Experience Vs Accuracy</dc:title>
 <dc:creator>Kopparapu, Sunil Kumar</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In general, self help systems are being increasingly deployed by service
based industries because they are capable of delivering better customer service
and increasingly the switch is to voice based self help systems because they
provide a natural interface for a human to interact with a machine. A speech
based self help system ideally needs a speech recognition engine to convert
spoken speech to text and in addition a language processing engine to take care
of any misrecognitions by the speech recognition engine. Any off-the-shelf
speech recognition engine is generally a combination of acoustic processing and
speech grammar. While this is the norm, we believe that ideally a speech
recognition application should have in addition to a speech recognition engine
a separate language processing engine to give the system better performance. In
this paper, we discuss ways in which the speech recognition engine and the
language processing engine can be combined to give a better user experience.
</dc:description>
 <dc:description>Comment: 5 pages; 1 figure</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01496</dc:identifier>
 <dc:identifier>doi:10.1007/978-90-481-3658-2_18</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01497</identifier>
 <datestamp>2015-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ReHub. Extending Hub Labels for Reverse k-Nearest Neighbor Queries on
  Large-Scale networks</dc:title>
 <dc:creator>Efentakis, Alexandros</dc:creator>
 <dc:creator>Pfoser, Dieter</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Quite recently, the algorithmic community has focused on solving multiple
shortest-path query problems beyond simple vertex-to-vertex queries, especially
in the context of road networks. Unfortunately, this research cannot be
generalized for large-scale graphs, e.g., social or collaboration networks, or
to efficiently answer Reverse k-Nearest Neighbor (RkNN) queries, which are of
practical relevance to a wide range of applications. To remedy this, we propose
ReHub, a novel main-memory algorithm that extends the Hub Labeling technique to
efficiently answer RkNN queries on large-scale networks. Our experimentation
will show that ReHub is the best overall solution for this type of queries,
requiring only minimal preprocessing and providing very fast query times.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2015-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01502</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Separable time-causal and time-recursive spatio-temporal receptive
  fields</dc:title>
 <dc:creator>Lindeberg, Tony</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  We present an improved model and theory for time-causal and time-recursive
spatio-temporal receptive fields, obtained by a combination of Gaussian
receptive fields over the spatial domain and first-order integrators or
equivalently truncated exponential filters coupled in cascade over the temporal
domain. Compared to previous spatio-temporal scale-space formulations in terms
of non-enhancement of local extrema or scale invariance, these receptive fields
are based on different scale-space axiomatics over time by ensuring
non-creation of new local extrema or zero-crossings with increasing temporal
scale. Specifically, extensions are presented about parameterizing the
intermediate temporal scale levels, analysing the resulting temporal dynamics
and transferring the theory to a discrete implementation in terms of recursive
filters over time.
</dc:description>
 <dc:description>Comment: 12 pages, 2 figures, 2 tables. arXiv admin note: substantial text
  overlap with arXiv:1404.2037</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01502</dc:identifier>
 <dc:identifier>Proc SSVM 2015: Scale-Space and Variational Methods for Computer
  Vision, Springer LNCS vol 9087, pages 90-102, 2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01504</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Service Discovery and Trust in Mobile Social Network in Proximity</dc:title>
 <dc:creator>Chang, Chii</dc:creator>
 <dc:creator>Srirama, Satish</dc:creator>
 <dc:creator>Ling, Sea</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>H.4.m</dc:subject>
 <dc:description>  Service-oriented Mobile Social Network in Proximity (MSNP) lets participants
establish new social interactions with strangers in public proximity using
heterogeneous platforms and devices. Such characteristic faces challenges in
discovery latency and trustworthiness. In a public service-oriented MSNP
environment, which consists of a large number of participants, a content
requester who searches for a particular service provided by other MSNP
participants will need to retrieve and process a large number of Service
Description Metadata (SDM) files, associated semantic metadata files and
identifying the trustworthiness of the content providers. Performing such tasks
on a resource constraint mobile device can be time consuming, and the overall
discovery performance will be affected and will result in high latency. This
paper analyses the service discovery models of MSNP and presents corresponding
solutions to improve the service discovery performance of MSNP. We firstly
present and analyse the basic service discovery models of service-oriented
MSNP. To follow up, we apply a context-aware user preference prediction scheme
to enhance the speed of the semantic service discovery process. Later, we
address the trustworthiness issue in MSNP and propose a scheme to reduce the
latency of the trustworthy service discovery for MSNP. The proposed scheme has
been tested and evaluated on MSNP application prototype operating on real
mobile devices and MSNP simulation environments.
</dc:description>
 <dc:description>Comment: 40 pages, 14 figures, 3 tables</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01504</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01515</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simultaneously sparse and low-rank abundance matrix estimation for
  hyperspectral image unmixing</dc:title>
 <dc:creator>Giampouras, Paris</dc:creator>
 <dc:creator>Themelis, Konstantinos</dc:creator>
 <dc:creator>Rontogiannis, Athanasios</dc:creator>
 <dc:creator>Koutroumbas, Konstantinos</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In a plethora of applications dealing with inverse problems, e.g. in image
processing, social networks, compressive sensing, biological data processing
etc., the signal of interest is known to be structured in several ways at the
same time. This premise has recently guided the research to the innovative and
meaningful idea of imposing multiple constraints on the parameters involved in
the problem under study. For instance, when dealing with problems whose
parameters form sparse and low-rank matrices, the adoption of suitably combined
constraints imposing sparsity and low-rankness, is expected to yield
substantially enhanced estimation results. In this paper, we address the
spectral unmixing problem in hyperspectral images. Specifically, two novel
unmixing algorithms are introduced, in an attempt to exploit both spatial
correlation and sparse representation of pixels lying in homogeneous regions of
hyperspectral images. To this end, a novel convex mixed penalty term is first
defined consisting of the sum of the weighted $\ell_1$ and the weighted nuclear
norm of the abundance matrix corresponding to a small area of the image
determined by a sliding square window. This penalty term is then used to
regularize a conventional quadratic cost function and impose simultaneously
sparsity and row-rankness on the abundance matrix. The resulting regularized
cost function is minimized by a) an incremental proximal sparse and low-rank
unmixing algorithm and b) an algorithm based on the alternating minimization
method of multipliers (ADMM). The effectiveness of the proposed algorithms is
illustrated in experiments conducted both on simulated and real data.
</dc:description>
 <dc:description>Comment: 30 pages, 9 figures</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2015-10-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01515</dc:identifier>
 <dc:identifier>doi:10.1109/TGRS.2016.2551327</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01526</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy saving market for mobile operators</dc:title>
 <dc:creator>Hossain, M. M. Aftab</dc:creator>
 <dc:creator>J&#xe4;ntti, Riku</dc:creator>
 <dc:creator>Cavdar, Cicek</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Ensuring seamless coverage accounts for the lion's share of the energy
consumed in a mobile network. Overlapping coverage of three to five mobile
network operators (MNOs) results in enormous amount of energy waste which is
avoidable. The traffic demands of the mobile networks vary significantly
throughout the day. As the offered load for all networks are not same at a
given time and the differences in energy consumption at different loads are
significant, multi-MNO capacity/coverage sharing can dramatically reduce energy
consumption of mobile networks and provide the MNOs a cost effective means to
cope with the exponential growth of traffic. In this paper, we propose an
energy saving market for a multi-MNO network scenario. As the competing MNOs
are not comfortable with information sharing, we propose a double auction
clearinghouse market mechanism where MNOs sell and buy capacity in order to
minimize energy consumption. In our setting, each MNO proposes its bids and
asks simultaneously for buying and selling multi-unit capacities respectively
to an independent auctioneer, i.e., clearinghouse and ends up either as a buyer
or as a seller in each round. We show that the mechanism allows the MNOs to
save significant percentage of energy cost throughout a wide range of network
load. Different than other energy saving features such as cell sleep or antenna
muting which can not be enabled at heavy traffic load, dynamic capacity sharing
allows MNOs to handle traffic bursts with energy saving opportunity.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures, to be published in ICC 2015 workshop on Next
  Generation Green ICT</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01526</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01535</identifier>
 <datestamp>2015-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase transitions for scaling of structural correlations in directed
  networks</dc:title>
 <dc:creator>van der Hoorn, Pim</dc:creator>
 <dc:creator>Litvak, Nelly</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>62H20, 05C80</dc:subject>
 <dc:description>  Analysis of degree-degree dependencies in complex networks, and their impact
on processes on networks requires null models, i.e. models that generate
uncorrelated scale-free networks. Most models to date however show structural
negative dependencies, caused by finite size effects. We analyze the behavior
of these structural negative degree-degree dependencies, using rank based
correlation measures, in the directed Erased Configuration Model. We obtain
expressions for the scaling as a function of the exponents of the
distributions. Moreover, we show that this scaling undergoes a phase
transition, where one region exhibits scaling related to the natural cut-off of
the network while another region has scaling similar to the structural cut-off
for uncorrelated networks. By establishing the speed of convergence of these
structural dependencies we are able to asses statistical significance of
degree-degree dependencies on finite complex networks when compared to networks
generated by the directed Erased Configuration Model.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2015-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01535</dc:identifier>
 <dc:identifier>Phys. Rev. E 92, 022803 (2015)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.92.022803</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01552</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Scheduling/Signal-Level Coordination in the Downlink of
  Multi-Cloud Radio-Access Networks</dc:title>
 <dc:creator>Douik, Ahmed</dc:creator>
 <dc:creator>Dahrouj, Hayssam</dc:creator>
 <dc:creator>Al-Naffouri, Tareq Y.</dc:creator>
 <dc:creator>Alouini, Mohamed-Slim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In the context of resource allocation in cloud-radio access networks, recent
studies assume either signal-level or scheduling-level coordination. This
paper, instead, considers a hybrid level of coordination for the scheduling
problem in the downlink of a multi-cloud radio-access network, as a means to
benefit from both scheduling policies. Consider a multi-cloud radio access
network, where each cloud is connected to several base-stations (BSs) via high
capacity links, and therefore allows joint signal processing between them.
Across the multiple clouds, however, only scheduling-level coordination is
permitted, as it requires a lower level of backhaul communication. The frame
structure of every BS is composed of various time/frequency blocks, called
power-zones (PZs), and kept at fixed power level. The paper addresses the
problem of maximizing a network-wide utility by associating users to clouds and
scheduling them to the PZs, under the practical constraints that each user is
scheduled, at most, to a single cloud, but possibly to many BSs within the
cloud, and can be served by one or more distinct PZs within the BSs' frame. The
paper solves the problem using graph theory techniques by constructing the
conflict graph. The scheduling problem is, then, shown to be equivalent to a
maximum-weight independent set problem in the constructed graph, in which each
vertex symbolizes an association of cloud, user, BS and PZ, with a weight
representing the utility of that association. Simulation results suggest that
the proposed hybrid scheduling strategy provides appreciable gain as compared
to the scheduling-level coordinated networks, with a negligible degradation to
signal-level coordination.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01557</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weak Subgame Perfect Equilibria and their Application to Quantitative
  Reachability</dc:title>
 <dc:creator>Brihaye, Thomas</dc:creator>
 <dc:creator>Bruy&#xe8;re, V&#xe9;ronique</dc:creator>
 <dc:creator>Meunier, No&#xe9;mie</dc:creator>
 <dc:creator>Raskin, Jean-Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We study $n$-player turn-based games played on a finite directed graph. For
each play, the players have to pay a cost that they want to minimize. Instead
of the well-known notion of Nash equilibrium (NE), we focus on the notion of
subgame perfect equilibrium (SPE), a refinement of NE well-suited in the
framework of games played on graphs. We also study natural variants of SPE,
named weak (resp. very weak) SPE, where players who deviate cannot use the full
class of strategies but only a subclass with a finite number of (resp. a
unique) deviation step(s).
  Our results are threefold. Firstly, we characterize in the form of a Folk
theorem the set of all plays that are the outcome of a weak SPE. Secondly, for
the class of quantitative reachability games, we prove the existence of a
finite-memory SPE and provide an algorithm for computing it (only existence was
known with no information regarding the memory). Moreover, we show that the
existence of a constrained SPE, i.e. an SPE such that each player pays a cost
less than a given constant, can be decided. The proofs rely on our Folk theorem
for weak SPEs (which coincide with SPEs in the case of quantitative
reachability games) and on the decidability of MSO logic on infinite words.
Finally with similar techniques, we provide a second general class of games for
which the existence of a (constrained) weak SPE is decidable.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01561</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling Spatial-Temporal Clues in a Hybrid Deep Learning Framework for
  Video Classification</dc:title>
 <dc:creator>Wu, Zuxuan</dc:creator>
 <dc:creator>Wang, Xi</dc:creator>
 <dc:creator>Jiang, Yu-Gang</dc:creator>
 <dc:creator>Ye, Hao</dc:creator>
 <dc:creator>Xue, Xiangyang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Classifying videos according to content semantics is an important problem
with a wide range of applications. In this paper, we propose a hybrid deep
learning framework for video classification, which is able to model static
spatial information, short-term motion, as well as long-term temporal clues in
the videos. Specifically, the spatial and the short-term motion features are
extracted separately by two Convolutional Neural Networks (CNN). These two
types of CNN-based features are then combined in a regularized feature fusion
network for classification, which is able to learn and utilize feature
relationships for improved performance. In addition, Long Short Term Memory
(LSTM) networks are applied on top of the two features to further model
longer-term temporal clues. The main contribution of this work is the hybrid
learning framework that can model several important aspects of the video data.
We also show that (1) combining the spatial and the short-term motion features
in the regularized fusion network is better than direct classification and
fusion using the CNN with a softmax layer, and (2) the sequence-based LSTM is
highly complementary to the traditional classification strategy without
considering the temporal frame orders. Extensive experiments are conducted on
two popular and challenging benchmarks, the UCF-101 Human Actions and the
Columbia Consumer Videos (CCV). On both benchmarks, our framework achieves
to-date the best reported performance: $91.3\%$ on the UCF-101 and $83.5\%$ on
the CCV.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01563</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;How much?&quot; Is Not Enough - An Analysis of Open Budget Initiatives</dc:title>
 <dc:creator>Tygel, Alan Freihof</dc:creator>
 <dc:creator>Attard, Judie</dc:creator>
 <dc:creator>Orlandi, Fabrizio</dc:creator>
 <dc:creator>Campos, Maria Luiza Machado</dc:creator>
 <dc:creator>Auer, S&#xf6;ren</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>J.1</dc:subject>
 <dc:subject>E.m</dc:subject>
 <dc:description>  A worldwide movement towards the publication of Open Government Data is
taking place, and budget data is one of the key elements pushing this trend.
Its importance is mostly related to transparency, but publishing budget data,
combined with other actions, can also improve democratic participation, allow
comparative analysis of governments and boost data-driven business. However,
the lack of standards and common evaluation criteria still hinders the
development of appropriate tools and the materialization of the appointed
benefits. In this paper, we present a model to analyse government initiatives
to publish budget data. We identify the main features of these initiatives with
a double objective: (i) to drive a structured analysis, relating some
dimensions to their possible impacts, and (ii) to derive characterization
attributes to compare initiatives based on each dimension. We define use
perspectives and analyse some initiatives using this model. We conclude that,
in order to favour use perspectives, special attention must be given to user
feedback, semantics standards and linking possibilities.
</dc:description>
 <dc:description>Comment: 10 pages. Submited as a full paper to WebSci2015 conference on 20th
  March 2015</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01575</identifier>
 <datestamp>2015-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bidirectional Recurrent Neural Networks as Generative Models -
  Reconstructing Gaps in Time Series</dc:title>
 <dc:creator>Berglund, Mathias</dc:creator>
 <dc:creator>Raiko, Tapani</dc:creator>
 <dc:creator>Honkala, Mikko</dc:creator>
 <dc:creator>K&#xe4;rkk&#xe4;inen, Leo</dc:creator>
 <dc:creator>Vetek, Akos</dc:creator>
 <dc:creator>Karhunen, Juha</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Bidirectional recurrent neural networks (RNN) are trained to predict both in
the positive and negative time directions simultaneously. They have not been
used commonly in unsupervised tasks, because a probabilistic interpretation of
the model has been difficult. Recently, two different frameworks, GSN and NADE,
provide a connection between reconstruction and probabilistic modeling, which
makes the interpretation possible. As far as we know, neither GSN or NADE have
been studied in the context of time series before. As an example of an
unsupervised task, we study the problem of filling in gaps in high-dimensional
time series with complex dynamics. Although unidirectional RNNs have recently
been trained successfully to model such time series, inference in the negative
time direction is non-trivial. We propose two probabilistic interpretations of
bidirectional RNNs that can be used to reconstruct missing gaps efficiently.
Our experiments on text data show that both proposed methods are much more
accurate than unidirectional reconstructions, although a bit less accurate than
a computationally complex bidirectional Bayesian inference on the
unidirectional RNN. We also provide results on music data for which the
Bayesian inference is computationally infeasible, demonstrating the scalability
of the proposed methods.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2015-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01575</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01584</identifier>
 <datestamp>2015-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random Projections for k-Means: Maintaining Coresets Beyond Merge &amp;
  Reduce</dc:title>
 <dc:creator>Bury, Marc</dc:creator>
 <dc:creator>Schwiegelshohn, Chris</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We give a new construction for a small space summary satisfying the coreset
guarantee of a data set with respect to the $k$-means objective function. The
number of points required in an offline construction is in $\tilde{O}(k
\epsilon^{-2}\min(d,k\epsilon^{-2}))$ which is minimal among all available
constructions.
  Aside from two constructions with exponential dependence on the dimension,
all known coresets are maintained in data streams via the merge and reduce
framework, which incurs are large space dependency on $\log n$. Instead, our
construction crucially relies on Johnson-Lindenstrauss type embeddings which
combined with results from online algorithms give us a new technique for
efficiently maintaining coresets in data streams without relying on merge and
reduce. The final number of points stored by our algorithm in a data stream is
in $\tilde{O}(k^2 \epsilon^{-2} \log^2 n \min(d,k\epsilon^{-2}))$.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn due to an error in Theorem 1</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2015-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01584</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01612</identifier>
 <datestamp>2015-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotic behaviour of weighted differential entropies in a Bayesian
  problem</dc:title>
 <dc:creator>Kelbert, Mark</dc:creator>
 <dc:creator>Mozgunov, Pavel</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>94A17(Primary), 62B10, 62C10 (Secondary)</dc:subject>
 <dc:subject>H.1.1</dc:subject>
 <dc:description>  We consider a Bayesian problem of estimating of probability of success in a
series of conditionally independent trials with binary outcomes. We study the
asymptotic behaviour of differential entropy for posterior probability density
function conditional on $x$ successes after $n$ conditionally independent
trials, when $n \to \infty$. It is shown that after an appropriate
normalization in cases $x \sim n$ and $x$ $\sim n^\beta$ ($0&lt;\beta&lt;1$) limiting
distribution is Gaussian and the differential entropy of standardized RV
converges to differential entropy of standard Gaussian random variable. When
$x$ or $n-x$ is a constant the limiting distribution in not Gaussian, but still
the asymptotic of differential entropy can be found explicitly.
  Then suppose that one is interested to know whether the coin is fair or not
and for large $n$ is interested in the true frequency. To do so the concept of
weighted differential entropy introduced in \cite{Belis1968} is used when the
frequency $\gamma$ is necessary to emphasize. It was found that the weight in
suggested form does not change the asymptotic form of Shannon, Renyi, Tsallis
and Fisher entropies, but change the constants. The main term in weighted
Fisher Information is changed by some constant which depend on distance between
the true frequency and the value we want to emphasize.
  In third part we derived the weighted versions of Rao-Cram\'er, Bhattacharyya
and Kullback inequalities. This result is applied to the Bayesian problem
described above. The asymptotic forms of these inequalities are obtained for a
particular class of weight functions.
</dc:description>
 <dc:description>Comment: 33 pages</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2015-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01612</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01614</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secret key-based Authentication with a Privacy Constraint</dc:title>
 <dc:creator>Kittichokechai, Kittipong</dc:creator>
 <dc:creator>Caire, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider problems of authentication using secret key generation under a
privacy constraint on the enrolled source data. An adversary who has access to
the stored description and correlated side information tries to deceive the
authentication as well as learn about the source. We characterize the optimal
tradeoff between the compression rate of the stored description, the leakage
rate of the source data, and the exponent of the adversary's maximum false
acceptance probability. The related problem of secret key generation with a
privacy constraint is also studied where the optimal tradeoff between the
compression rate, leakage rate, and secret key rate is characterized. It
reveals a connection between the optimal secret key rate and security of the
authentication system.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures, to be presented at ISIT 2015</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01614</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01617</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low Complexity V-BLAST MIMO-OFDM Detector by Successive Iterations
  Reduction</dc:title>
 <dc:creator>Ahmed, Karam</dc:creator>
 <dc:creator>Abuelenin, Sherif</dc:creator>
 <dc:creator>Soliman, Heba</dc:creator>
 <dc:creator>Al-Barbary, Khairy</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  V-BLAST detection method suffers large computational complexity due to its
successive detection of symbols. In this paper, we propose a modified V-BLAST
algorithm to decrease the computational complexity by reducing the number of
detection iterations required in MIMO communication systems. We begin by
showing the existence of a maximum number of iterations, beyond which, no
significant improvement is obtained. We establish a criterion for the number of
maximum effective iterations. We propose a modified algorithm that uses the
measured SNR to dynamically set the number of iterations to achieve an
acceptable bit-error rate. Then, we replace the feedback algorithm with an
approximate linear function to reduce the complexity. Simulations show that
significant reduction in computational complexity is achieved compared to the
ordinary V-BLAST, while maintaining a good BER performance.
</dc:description>
 <dc:description>Comment: 6 pages, 7 figures, 2 tables. The final publication is available at
  www.aece.ro</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01617</dc:identifier>
 <dc:identifier>Advances in Electrical and Computer Engineering, vol. 15, no. 1,
  pp. 77-82, 2015</dc:identifier>
 <dc:identifier>doi:10.4316/AECE.2015.01011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01623</identifier>
 <datestamp>2015-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Byzantine Gathering in Networks</dc:title>
 <dc:creator>Bouchard, S&#xe9;bastien</dc:creator>
 <dc:creator>Dieudonn&#xe9;, Yoann</dc:creator>
 <dc:creator>Ducourthial, Bertrand</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  This paper investigates an open problem introduced in [14]. Two or more
mobile agents start from different nodes of a network and have to accomplish
the task of gathering which consists in getting all together at the same node
at the same time. An adversary chooses the initial nodes of the agents and
assigns a different positive integer (called label) to each of them. Initially,
each agent knows its label but does not know the labels of the other agents or
their positions relative to its own. Agents move in synchronous rounds and can
communicate with each other only when located at the same node. Up to f of the
agents are Byzantine. A Byzantine agent can choose an arbitrary port when it
moves, can convey arbitrary information to other agents and can change its
label in every round, in particular by forging the label of another agent or by
creating a completely new one.
  What is the minimum number M of good agents that guarantees deterministic
gathering of all of them, with termination?
  We provide exact answers to this open problem by considering the case when
the agents initially know the size of the network and the case when they do
not. In the former case, we prove M=f+1 while in the latter, we prove M=f+2.
More precisely, for networks of known size, we design a deterministic algorithm
gathering all good agents in any network provided that the number of good
agents is at least f+1. For networks of unknown size, we also design a
deterministic algorithm ensuring the gathering of all good agents in any
network but provided that the number of good agents is at least f+2. Both of
our algorithms are optimal in terms of required number of good agents, as each
of them perfectly matches the respective lower bound on M shown in [14], which
is of f+1 when the size of the network is known and of f+2 when it is unknown.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2015-04-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01628</identifier>
 <datestamp>2015-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quickest Eigenvalue-Based Spectrum Sensing using Random Matrix Theory</dc:title>
 <dc:creator>Arts, Martijn</dc:creator>
 <dc:creator>Bollig, Andreas</dc:creator>
 <dc:creator>Mathar, Rudolf</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We investigate the potential of quickest detection based on the eigenvalues
of the sample covariance matrix for spectrum sensing applications. A simple
phase shift keying (PSK) model with additive white Gaussian noise (AWGN), with
$1$ primary user (PU) and $K$ secondary users (SUs) is considered. Under both
detection hypotheses $\mathcal{H}_0$ (noise only) and $\mathcal{H}_1$ (signal +
noise) the eigenvalues of the sample covariance matrix follow Wishart
distributions. For the case of $K = 2$ SUs, we derive an analytical formulation
of the probability density function (PDF) of the maximum-minimum eigenvalue
(MME) detector under $\mathcal{H}_1$. Utilizing results from the literature
under $\mathcal{H}_0$, we investigate two detection schemes. First, we
calculate the receiver operator characteristic (ROC) for MME block detector
based on analytical results. Second, we introduce two eigenvalue-based quickest
detection algorithms: a cumulative sum (CUSUM) algorithm, when the
signal-to-noise ratio (SNR) of the PU signal is known and an algorithm using
the generalized likelihood ratio, in case the SNR is unknown. Bounds on the
mean time to false-alarm $\tau_\text{fa}$ and the mean time to detection
$\tau_\text{d}$ are given for the CUSUM algorithm. Numerical simulations
illustrate the potential advantages of the quickest detection approach over the
block detection scheme.
</dc:description>
 <dc:description>Comment: updated copyright information; corrected error in definition of the
  non-centrality matrix</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2015-10-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01628</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01637</identifier>
 <datestamp>2015-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Variation of Collective Attention in Hashtag Spike Trains</dc:title>
 <dc:creator>Sanli, Ceyda</dc:creator>
 <dc:creator>Lambiotte, Renaud</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In this paper, we propose a methodology quantifying temporal patterns of
nonlinear hashtag time series. Our approach is based on an analogy between
neuron spikes and hashtag diffusion. We adopt the local variation, originally
developed to analyze local time delays in neuron spike trains. We show that the
local variation successfully characterizes nonlinear features of hashtag spike
trains such as burstiness and regularity. We apply this understanding in an
extreme social event and are able to observe temporal evaluation of online
collective attention of Twitter users to that event.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures. Technical Report of the International AAAI
  Conference on Weblogs and Social Media (ICWSM-15) Workshop 3: Modeling and
  Mining Temporal Interactions</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01637</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01639</identifier>
 <datestamp>2015-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ego-Object Discovery</dc:title>
 <dc:creator>Bola&#xf1;os, Marc</dc:creator>
 <dc:creator>Radeva, Petia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Lifelogging devices are spreading faster everyday. This growth can represent
great benefits to develop methods for extraction of meaningful information
about the user wearing the device and his/her environment. In this paper, we
propose a semi-supervised strategy for easily discovering objects relevant to
the person wearing a first-person camera. Given an egocentric video/images
sequence acquired by the camera, our algorithm uses both the appearance
extracted by means of a convolutional neural network and an object refill
methodology that allows to discover objects even in case of small amount of
object appearance in the collection of images. An SVM filtering strategy is
applied to deal with the great part of the False Positive object candidates
found by most of the state of the art object detectors. We validate our method
on a new egocentric dataset of 4912 daily images acquired by 4 persons as well
as on both PASCAL 2012 and MSRC datasets. We obtain for all of them results
that largely outperform the state of the art approach. We make public both the
EDUB dataset and the algorithm code.
</dc:description>
 <dc:description>Comment: 9 pages, 13 figures, Submitted to: Image and Vision Computing</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2015-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01647</identifier>
 <datestamp>2016-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scheduling wireless links by graph multicoloring in the physical
  interference model</dc:title>
 <dc:creator>Vieira, Fabio R. J.</dc:creator>
 <dc:creator>de Rezende, Jos&#xe9; F.</dc:creator>
 <dc:creator>Barbosa, Valmir C.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Scheduling wireless links for simultaneous activation in such a way that all
transmissions are successfully decoded at the receivers and moreover network
capacity is maximized is a computationally hard problem. Usually it is tackled
by heuristics whose output is a sequence of time slots in which every link
appears in exactly one time slot. Such approaches can be interpreted as the
coloring of a graph's vertices so that every vertex gets exactly one color.
Here we introduce a new approach that can be viewed as assigning multiple
colors to each vertex, so that, in the resulting schedule, every link may
appear more than once (though the same number of times for all links). We
report on extensive computational experiments, under the physical interference
model, revealing substantial gains for a variety of randomly generated
networks.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01647</dc:identifier>
 <dc:identifier>Computer Networks 99 (2016), 125-133</dc:identifier>
 <dc:identifier>doi:10.1016/j.comnet.2016.02.008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01649</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The List-Decoding Size of Fourier-Sparse Boolean Functions</dc:title>
 <dc:creator>Haviv, Ishay</dc:creator>
 <dc:creator>Regev, Oded</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  A function defined on the Boolean hypercube is $k$-Fourier-sparse if it has
at most $k$ nonzero Fourier coefficients. For a function $f: \mathbb{F}_2^n
\rightarrow \mathbb{R}$ and parameters $k$ and $d$, we prove a strong upper
bound on the number of $k$-Fourier-sparse Boolean functions that disagree with
$f$ on at most $d$ inputs. Our bound implies that the number of uniform and
independent random samples needed for learning the class of $k$-Fourier-sparse
Boolean functions on $n$ variables exactly is at most $O(n \cdot k \log k)$.
  As an application, we prove an upper bound on the query complexity of testing
Booleanity of Fourier-sparse functions. Our bound is tight up to a logarithmic
factor and quadratically improves on a result due to Gur and Tamuz (Chicago J.
Theor. Comput. Sci., 2013).
</dc:description>
 <dc:description>Comment: 16 pages, CCC 2015</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01649</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01650</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Benchmarking the cost of thread divergence in CUDA</dc:title>
 <dc:creator>Bialas, Piotr</dc:creator>
 <dc:creator>Strzelecki, Adam</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  All modern processors include a set of vector instructions. While this gives
a tremendous boost to the performance, it requires a vectorized code that can
take advantage of such instructions. As an ideal vectorization is hard to
achieve in practice, one has to decide when different instructions may be
applied to different elements of the vector operand. This is especially
important in implicit vectorization as in NVIDIA CUDA Single Instruction
Multiple Threads (SIMT) model, where the vectorization details are hidden from
the programmer. In order to assess the costs incurred by incompletely
vectorized code, we have developed a micro-benchmark that measures the
characteristics of the CUDA thread divergence model on different architectures
focusing on the loops performance.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01650</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01656</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tight Size-Degree Bounds for Sums-of-Squares Proofs</dc:title>
 <dc:creator>Lauria, Massimo</dc:creator>
 <dc:creator>Nordstr&#xf6;m, Jakob</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.2.3</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  We exhibit families of $4$-CNF formulas over $n$ variables that have
sums-of-squares (SOS) proofs of unsatisfiability of degree (a.k.a. rank) $d$
but require SOS proofs of size $n^{\Omega(d)}$ for values of $d = d(n)$ from
constant all the way up to $n^{\delta}$ for some universal constant$\delta$.
This shows that the $n^{O(d)}$ running time obtained by using the Lasserre
semidefinite programming relaxations to find degree-$d$ SOS proofs is optimal
up to constant factors in the exponent. We establish this result by combining
$\mathsf{NP}$-reductions expressible as low-degree SOS derivations with the
idea of relativizing CNF formulas in [Kraj\'i\v{c}ek '04] and [Dantchev and
Riis'03], and then applying a restriction argument as in [Atserias, M\&quot;uller,
and Oliva '13] and [Atserias, Lauria, and Nordstr\&quot;om '14]. This yields a
generic method of amplifying SOS degree lower bounds to size lower bounds, and
also generalizes the approach in [ALN14] to obtain size lower bounds for the
proof systems resolution, polynomial calculus, and Sherali-Adams from lower
bounds on width, degree, and rank, respectively.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01656</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01661</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An original Propagator for large array</dc:title>
 <dc:creator>Khmou, Youssef</dc:creator>
 <dc:creator>Safi, Said</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  In this paper, we demonstrate that when the ratio $n$ of the number of
antenna elements $N$ to the number $P$ of radiating sources is superior or
equal to $2$, then it is possible to choose a propagator from a set of
$n(n+1)/2-1$ operators to compute the Angles of Arrival (AoA) of the narrowband
incoming waves. This new non eigenbased approach is efficient when the Signal
to Noise Ratio (SNR) is moderate, and gives multitude of possibilities, that
are dependent of the random data, to construct the complex sets whose columns
are orthogonal to the signal subspace generated by the radiating sources.
Elementary examples are given for $n=3$, $n=4$ and $n=6$. The simulation
results are presented to illustrate the performance of the proposed
computational methods.
</dc:description>
 <dc:description>Comment: Fourteen pages and four figures</dc:description>
 <dc:date>2015-03-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01662</identifier>
 <datestamp>2017-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grid-free compressive beamforming</dc:title>
 <dc:creator>Xenaki, Angeliki</dc:creator>
 <dc:creator>Gerstoft, Peter</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The direction-of-arrival (DOA) estimation problem involves the localization
of a few sources from a limited number of observations on an array of sensors,
thus it can be formulated as a sparse signal reconstruction problem and solved
efficiently with compressive sensing (CS) to achieve high-resolution imaging.
On a discrete angular grid, the CS reconstruction degrades due to basis
mismatch when the DOAs do not coincide with the angular directions on the grid.
To overcome this limitation, a continuous formulation of the DOA problem is
employed and an optimization procedure is introduced, which promotes sparsity
on a continuous optimization variable. The DOA estimation problem with
infinitely many unknowns, i.e., source locations and amplitudes, is solved over
a few optimization variables with semidefinite programming. The grid-free CS
reconstruction provides high-resolution imaging even with non-uniform arrays,
single-snapshot data and under noisy conditions as demonstrated on experimental
towed array data.
</dc:description>
 <dc:description>Comment: 14 pages, 8 figures, journal paper</dc:description>
 <dc:date>2015-03-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01662</dc:identifier>
 <dc:identifier>doi:10.1121/1.4916269</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01665</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Does Gaming Help Improve Cognitive Skills?</dc:title>
 <dc:creator>Chakravarti, Mohnish</dc:creator>
 <dc:creator>Chakravarti, Arati</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  A nationally representative study of video game play among adolescents in the
United States showed that 97% of adolescents aged 12 to 17 years play computer,
web, and portable (or console) video games (Lenhart et al., 2008). We
hypothesized that if people play games as a regular exercise regime, gaming
will correlate with an improvement in their cognitive skills. For this
experiment, a few games that tested the logical reasoning and critical analysis
skills under a given time constraint were coded in Python using Pygame and were
played by a group of 7th grade students. In order to test whether there is a
relationship between gaming and test performance, we divided the students into
two groups and gave them tests before and after the experimentation period in
order to measure their improvement. One group played the games while the other
did not. In the group of students that played the games, an average improvement
of 62.19% was seen (p &lt; 0.0001). The group that did not play the games only
improved their performance by an average of 18.51% (p = 0.0882).
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01665</dc:identifier>
 <dc:identifier>Journal of Emerging Investigators, January 2015 (5), 4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01666</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Garbage Collection Techniques for Flash-Resident Page-Mapping FTLs</dc:title>
 <dc:creator>Dayan, Niv</dc:creator>
 <dc:creator>Bonnet, Philippe</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  Storage devices based on flash memory have replaced hard disk drives (HDDs)
due to their superior performance, increasing density, and lower power
consumption. Unfortunately, flash memory is subject to challenging
idiosyncrasies like erase-before-write and limited block lifetime. These
constraints are handled by a flash translation layer (FTL), which performs
out-of-place updates, wear-leveling and garbage-collection behind the scene,
while offering the application a virtualization of the physical address space.
  A class of relevant FTLs employ a flash-resident page-associative mapping
table from logical to physical addresses, with a smaller RAM-resident cache for
frequently mapped entries. In this paper, we address the problem of performing
garbage-collection under such FTLs. We observe two problems. Firstly,
maintaining the metadata needed to perform garbage-collection under these
schemes is problematic, because at write-time we do not necessarily know the
physical address of the before-image. Secondly, the size of this metadata must
remain small, because it makes RAM unavailable for caching frequently accessed
entries. We propose two complementary techniques, called Lazy Gecko and
Logarithmic Gecko, which address these issues. Lazy Gecko works well when RAM
is plentiful enough to store the GC metadata. Logarithmic Gecko works well when
RAM isn't plentiful and efficiently stores the GC metadata in flash. Thus,
these techniques are applicable to a wide range of flash devices with varying
amounts of embedded RAM.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01683</identifier>
 <datestamp>2015-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Jointly Embedding Relations and Mentions for Knowledge Population</dc:title>
 <dc:creator>Fan, Miao</dc:creator>
 <dc:creator>Cao, Kai</dc:creator>
 <dc:creator>He, Yifan</dc:creator>
 <dc:creator>Grishman, Ralph</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper contributes a joint embedding model for predicting relations
between a pair of entities in the scenario of relation inference. It differs
from most stand-alone approaches which separately operate on either knowledge
bases or free texts. The proposed model simultaneously learns low-dimensional
vector representations for both triplets in knowledge repositories and the
mentions of relations in free texts, so that we can leverage the evidence both
resources to make more accurate predictions. We use NELL to evaluate the
performance of our approach, compared with cutting-edge methods. Results of
extensive experiments show that our model achieves significant improvement on
relation extraction.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2015-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01684</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large Margin Nearest Neighbor Embedding for Knowledge Representation</dc:title>
 <dc:creator>Fan, Miao</dc:creator>
 <dc:creator>Zhou, Qiang</dc:creator>
 <dc:creator>Zheng, Thomas Fang</dc:creator>
 <dc:creator>Grishman, Ralph</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Traditional way of storing facts in triplets ({\it head\_entity, relation,
tail\_entity}), abbreviated as ({\it h, r, t}), makes the knowledge intuitively
displayed and easily acquired by mankind, but hardly computed or even reasoned
by AI machines. Inspired by the success in applying {\it Distributed
Representations} to AI-related fields, recent studies expect to represent each
entity and relation with a unique low-dimensional embedding, which is different
from the symbolic and atomic framework of displaying knowledge in triplets. In
this way, the knowledge computing and reasoning can be essentially facilitated
by means of a simple {\it vector calculation}, i.e. ${\bf h} + {\bf r} \approx
{\bf t}$. We thus contribute an effective model to learn better embeddings
satisfying the formula by pulling the positive tail entities ${\bf t^{+}}$ to
get together and close to {\bf h} + {\bf r} ({\it Nearest Neighbor}), and
simultaneously pushing the negatives ${\bf t^{-}}$ away from the positives
${\bf t^{+}}$ via keeping a {\it Large Margin}. We also design a corresponding
learning algorithm to efficiently find the optimal solution based on {\it
Stochastic Gradient Descent} in iterative fashion. Quantitative experiments
illustrate that our approach can achieve the state-of-the-art performance,
compared with several latest methods on some benchmark datasets for two
classical applications, i.e. {\it Link prediction} and {\it Triplet
classification}. Moreover, we analyze the parameter complexities among all the
evaluated models, and analytical results indicate that our model needs fewer
computational resources on outperforming the other methods.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1503.08155</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01690</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Expanding the Compute-and-Forward Framework: Unequal Powers, Signal
  Levels, and Multiple Linear Combinations</dc:title>
 <dc:creator>Nazer, Bobak</dc:creator>
 <dc:creator>Cadambe, Viveck</dc:creator>
 <dc:creator>Ntranos, Vasilis</dc:creator>
 <dc:creator>Caire, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The compute-and-forward framework permits each receiver in a Gaussian network
to directly decode a linear combination of the transmitted messages. The
resulting linear combinations can then be employed as an end-to-end
communication strategy for relaying, interference alignment, and other
applications. Recent efforts have demonstrated the advantages of employing
unequal powers at the transmitters and decoding more than one linear
combination at each receiver. However, neither of these techniques fit
naturally within the original formulation of compute-and-forward. This paper
proposes an expanded compute-and-forward framework that incorporates both of
these possibilities and permits an intuitive interpretation in terms of signal
levels. Within this framework, recent achievability and optimality results are
unified and generalized.
</dc:description>
 <dc:description>Comment: 30 pages, 10 figures, to appear in IEEE Transactions on Information
  Theory</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2016-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01690</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2016.2593633</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01693</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Security Toolbox for Detecting Novel and Sophisticated Android Malware</dc:title>
 <dc:creator>Holland, Benjamin</dc:creator>
 <dc:creator>Deering, Tom</dc:creator>
 <dc:creator>Kothari, Suresh</dc:creator>
 <dc:creator>Mathews, Jon</dc:creator>
 <dc:creator>Ranade, Nikhil</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  This paper presents a demo of our Security Toolbox to detect novel malware in
Android apps. This Toolbox is developed through our recent research project
funded by the DARPA Automated Program Analysis for Cybersecurity (APAC)
project. The adversarial challenge (&quot;Red&quot;) teams in the DARPA APAC program are
tasked with designing sophisticated malware to test the bounds of malware
detection technology being developed by the research and development (&quot;Blue&quot;)
teams. Our research group, a Blue team in the DARPA APAC program, proposed a
&quot;human-in-the-loop program analysis&quot; approach to detect malware given the
source or Java bytecode for an Android app. Our malware detection apparatus
consists of two components: a general-purpose program analysis platform called
Atlas, and a Security Toolbox built on the Atlas platform. This paper describes
the major design goals, the Toolbox components to achieve the goals, and the
workflow for auditing Android apps. The accompanying video
(http://youtu.be/WhcoAX3HiNU) illustrates features of the Toolbox through a
live audit.
</dc:description>
 <dc:description>Comment: 4 pages, 1 listing, 2 figures</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01693</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01697</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tensor machines for learning target-specific polynomial features</dc:title>
 <dc:creator>Yang, Jiyan</dc:creator>
 <dc:creator>Gittens, Alex</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recent years have demonstrated that using random feature maps can
significantly decrease the training and testing times of kernel-based
algorithms without significantly lowering their accuracy. Regrettably, because
random features are target-agnostic, typically thousands of such features are
necessary to achieve acceptable accuracies. In this work, we consider the
problem of learning a small number of explicit polynomial features. Our
approach, named Tensor Machines, finds a parsimonious set of features by
optimizing over the hypothesis class introduced by Kar and Karnick for random
feature maps in a target-specific manner. Exploiting a natural connection
between polynomials and tensors, we provide bounds on the generalization error
of Tensor Machines. Empirically, Tensor Machines behave favorably on several
real-world datasets compared to other state-of-the-art techniques for learning
polynomial features, and deliver significantly more parsimonious models.
</dc:description>
 <dc:description>Comment: 19 pages, 4 color figures, 2 tables. Submitted to ECML 2015</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01697</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01705</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fusion of Sparse Reconstruction Algorithms for Multiple Measurement
  Vectors</dc:title>
 <dc:creator>G., Deepa K.</dc:creator>
 <dc:creator>Ambat, Sooraj K.</dc:creator>
 <dc:creator>Hari, K. V. S.</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the recovery of sparse signals that share a common support from
multiple measurement vectors. The performance of several algorithms developed
for this task depends on parameters like dimension of the sparse signal,
dimension of measurement vector, sparsity level, measurement noise. We propose
a fusion framework, where several multiple measurement vector reconstruction
algorithms participate and the final signal estimate is obtained by combining
the signal estimates of the participating algorithms. We present the conditions
for achieving a better reconstruction performance than the participating
algorithms. Numerical simulations demonstrate that the proposed fusion
algorithm often performs better than the participating algorithms.
</dc:description>
 <dc:date>2015-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01708</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reactive Synthesis Without Regret</dc:title>
 <dc:creator>Hunter, Paul</dc:creator>
 <dc:creator>P&#xe9;rez, Guillermo A.</dc:creator>
 <dc:creator>Raskin, Jean-Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:description>  Two-player zero-sum games of infinite duration and their quantitative
versions are used in verification to model the interaction between a controller
(Eve) and its environment (Adam). The question usually addressed is that of the
existence (and computability) of a strategy for Eve that can maximize her
payoff against any strategy of Adam. In this work, we are interested in
strategies of Eve that minimize her regret, i.e. strategies that minimize the
difference between her actual payoff and the payoff she could have achieved if
she had known the strategy of Adam in advance. We give algorithms to compute
the strategies of Eve that ensure minimal regret against an adversary whose
choice of strategy is (i) unrestricted, (ii) limited to positional strategies,
or (iii) limited to word strategies. We also establish relations between the
latter version and other problems studied in the literature.
</dc:description>
 <dc:description>Comment: Fixes some typos and mistakes in the values of some proofs</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2017-10-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01708</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01709</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the expressibility of copyless cost register automata</dc:title>
 <dc:creator>Mazowiecki, Filip</dc:creator>
 <dc:creator>Riveros, Cristian</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Cost register automata (CRA) were proposed by Alur et all as an alternative
model for weighted automata. In hope of finding decidable subclasses of CRA,
they proposed to restrict their model with the copyless restriction but nothing
is really know about the structure or properties of this new computational
model called copyless CRA.
  In this paper we study the properties and expressiveness of copyless CRA. We
propose a normal form for copyless CRA and we study the properties of a special
group of registers (called stable registers). Furthermore, we find that
copyless CRA do not have good closure properties since we show that they are
not closed under reverse operation. Finally, we propose a subclass of copyless
CRA and we show that this subclass is closed under regular-lookahead.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01716</identifier>
 <datestamp>2015-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Evaluation of Deep Learning on Highway Driving</dc:title>
 <dc:creator>Huval, Brody</dc:creator>
 <dc:creator>Wang, Tao</dc:creator>
 <dc:creator>Tandon, Sameep</dc:creator>
 <dc:creator>Kiske, Jeff</dc:creator>
 <dc:creator>Song, Will</dc:creator>
 <dc:creator>Pazhayampallil, Joel</dc:creator>
 <dc:creator>Andriluka, Mykhaylo</dc:creator>
 <dc:creator>Rajpurkar, Pranav</dc:creator>
 <dc:creator>Migimatsu, Toki</dc:creator>
 <dc:creator>Cheng-Yue, Royce</dc:creator>
 <dc:creator>Mujica, Fernando</dc:creator>
 <dc:creator>Coates, Adam</dc:creator>
 <dc:creator>Ng, Andrew Y.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Numerous groups have applied a variety of deep learning techniques to
computer vision problems in highway perception scenarios. In this paper, we
presented a number of empirical evaluations of recent deep learning advances.
Computer vision, combined with deep learning, has the potential to bring about
a relatively inexpensive, robust solution to autonomous driving. To prepare
deep learning for industry uptake and practical applications, neural networks
will require large data sets that represent all possible driving environments
and scenarios. We collect a large data set of highway data and apply deep
learning and computer vision algorithms to problems such as car and lane
detection. We show how existing convolutional neural networks (CNNs) can be
used to perform lane and vehicle detection while running at frame rates
required for a real-time system. Our results lend credence to the hypothesis
that deep learning holds promise for autonomous driving.
</dc:description>
 <dc:description>Comment: Added a video for lane detection</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2015-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01718</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modular Acquisition and Stimulation System for Timestamp-Driven
  Neuroscience Experiments</dc:title>
 <dc:creator>Matias, Paulo</dc:creator>
 <dc:creator>Guariento, Rafael Tuma</dc:creator>
 <dc:creator>de Almeida, Lirio Onofre Baptista</dc:creator>
 <dc:creator>Slaets, Jan Frans Willem</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Dedicated systems are fundamental for neuroscience experimental protocols
that require timing determinism and synchronous stimuli generation. We
developed a data acquisition and stimuli generator system for neuroscience
research, optimized for recording timestamps from up to 6 spiking neurons and
entirely specified in a high-level Hardware Description Language (HDL). Despite
the logic complexity penalty of synthesizing from such a language, it was
possible to implement our design in a low-cost small reconfigurable device.
Under a modular framework, we explored two different memory arbitration schemes
for our system, evaluating both their logic element usage and resilience to
input activity bursts. One of them was designed with a decoupled and latency
insensitive approach, allowing for easier code reuse, while the other adopted a
centralized scheme, constructed specifically for our application. The usage of
a high-level HDL allowed straightforward and stepwise code modifications to
transform one architecture into the other. The achieved modularity is very
useful for rapidly prototyping novel electronic instrumentation systems
tailored to scientific research.
</dc:description>
 <dc:description>Comment: Preprint submitted to ARC 2015. Extended: 16 pages, 10 figures. The
  final publication is available at link.springer.com</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01718</dc:identifier>
 <dc:identifier>Lecture Notes in Computer Science Volume 9040, 2015, pp 339-348</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-16214-0_29</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01747</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SCMA for Open-Loop Joint Transmission CoMP</dc:title>
 <dc:creator>Vilaipornsawai, Usa</dc:creator>
 <dc:creator>Nikopour, Hosein</dc:creator>
 <dc:creator>Bayesteh, Alireza</dc:creator>
 <dc:creator>Ma, Jianglie</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Sparse Code Multiple Access (SCMA), a non-orthogonal multiple access scheme,
has been introduced as a key 5G technology to improve spectral efficiency. In
this work, we propose SCMA to enable open-loop coordinated multipoint (CoMP)
joint transmission (JT). The scheme combines CoMP techniques with multi-user
SCMA (MU-SCMA) in downlink. This scheme provides open-loop user multiplexing
and JT in power and code domains, with robustness to mobility and low overhead
of channel state information (CSI) acquisition. The combined scheme is called
MU-SCMA-CoMP, in which SCMA layers and transmit power of multiple transmit
points (TPs) are shared among multiple users while a user may receive multiple
SCMA layers from multiple TPs within a CoMP cluster. The benefits of the
proposed scheme includes: i) drastic overhead reduction of CSI acquisition, ii)
significant increase in throughput and coverage, and iii) robustness to channel
aging. Various algorithms of MU-SCMA-CoMP are presented, including the
detection strategy, power sharing optimization, and scheduling. System level
evaluation shows that the proposed schemes provide significant throughput and
coverage gains over OFDMA for both pedestrian and vehicular users.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01753</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Implementation of a 3D Undersea Camera System</dc:title>
 <dc:creator>Chen, Xida</dc:creator>
 <dc:creator>Sutphen, Steve</dc:creator>
 <dc:creator>Macoun, Paul</dc:creator>
 <dc:creator>Yang, Yee-Hong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we present the design and development of an undersea camera
system. The goal of our system is to provide a 3D model of the undersea habitat
in a long-term continuous manner. The most important feature of our system is
the use of multiple cameras and multiple projectors, which is able to provide
accurate 3D models with an accuracy of a millimeter. By introducing projectors
in our system, we can use many different structured light methods for different
tasks. There are two main advantages comparing our system with using ROVs or
AUVs. First, our system can provide continuous monitoring of the undersea
habitat. Second, our system has a low hardware cost. Comparing to existing
deployed camera systems, the advantage of our system is that it can provide
accurate 3D models and provides opportunities for future development of
innovative algorithms for undersea research.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01753</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01760</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User Effort and Network Structure Mediate Access to Information in
  Networks</dc:title>
 <dc:creator>Kang, Jeon-Hyung</dc:creator>
 <dc:creator>Lerman, Kristina</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Individuals' access to information in a social network depends on its
distributed and where in the network individuals position themselves. However,
individuals have limited capacity to manage their social connections and
process information. In this work, we study how this limited capacity and
network structure interact to affect the diversity of information social media
users receive. Previous studies of the role of networks in information access
were limited in their ability to measure the diversity of information. We
address this problem by learning the topics of interest to social media users
by observing messages they share online with their followers. We present a
probabilistic model that incorporates human cognitive constraints in a
generative model of information sharing. We then use the topics learned by the
model to measure the diversity of information users receive from their social
media contacts. We confirm that users in structurally diverse network
positions, which bridge otherwise disconnected regions of the follower graph,
are exposed to more diverse information. In addition, we identify user effort
as an important variable that mediates access to diverse information in social
media. Users who invest more effort into their activity on the site not only
place themselves in more structurally diverse positions within the network than
the less engaged users, but they also receive more diverse information when
located in similar network positions. These findings indicate that the
relationship between network structure and access to information in networks is
more nuanced than previously thought.
</dc:description>
 <dc:description>Comment: The 9TH International AAAI Conference on Web and Social Media</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01760</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01771</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Routing in SDN-enabled Networks with Consolidated Middleboxes</dc:title>
 <dc:creator>Gushchin, Andrey</dc:creator>
 <dc:creator>Walid, Anwar</dc:creator>
 <dc:creator>Tang, Ao</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Middleboxes are special network devices that perform various functions such
as enabling security and efficiency. SDN-based routing approaches in networks
with middleboxes need to address resource constraints, such as memory in the
switches and processing power of middleboxes, and traversal constraint where a
flow must visit the required middleboxes in a specific order. In this work we
propose a solution based on MultiPoint-To-Point Trees (MPTPT) for routing
traffic in SDN-enabled networks with consolidated middleboxes. We show both
theoretically and via simulations that our solution significantly reduces the
number of routing rules in the switches, while guaranteeing optimum throughput
and meeting processing requirements. Additionally, the underlying algorithm has
low complexity making it suitable in dynamic network environment.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01771</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01777</identifier>
 <datestamp>2015-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Heterogeneous Tensor Decomposition for Clustering via Manifold
  Optimization</dc:title>
 <dc:creator>Sun, Yanfeng</dc:creator>
 <dc:creator>Gao, Junbin</dc:creator>
 <dc:creator>Hong, Xia</dc:creator>
 <dc:creator>Mishra, Bamdev</dc:creator>
 <dc:creator>Yin, Baocai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Tensors or multiarray data are generalizations of matrices. Tensor clustering
has become a very important research topic due to the intrinsically rich
structures in real-world multiarray datasets. Subspace clustering based on
vectorizing multiarray data has been extensively researched. However,
vectorization of tensorial data does not exploit complete structure
information. In this paper, we propose a subspace clustering algorithm without
adopting any vectorization process. Our approach is based on a novel
heterogeneous Tucker decomposition model. In contrast to existing techniques,
we propose a new clustering algorithm that alternates between different modes
of the proposed heterogeneous tensor model. All but the last mode have
closed-form updates. Updating the last mode reduces to optimizing over the
so-called multinomial manifold, for which we investigate second order
Riemannian geometry and propose a trust-region algorithm. Numerical experiments
show that our proposed algorithm compete effectively with state-of-the-art
clustering algorithms that are based on tensor factorization.
</dc:description>
 <dc:description>Comment: 12 pages, 2 figures</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2015-04-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01777</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01780</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Welfare Maximization with Limited Interaction</dc:title>
 <dc:creator>Alon, Noga</dc:creator>
 <dc:creator>Nisan, Noam</dc:creator>
 <dc:creator>Raz, Ran</dc:creator>
 <dc:creator>Weinstein, Omri</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>F.2.3</dc:subject>
 <dc:subject>H.1.1</dc:subject>
 <dc:description>  We continue the study of welfare maximization in unit-demand (matching)
markets, in a distributed information model where agent's valuations are
unknown to the central planner, and therefore communication is required to
determine an efficient allocation. Dobzinski, Nisan and Oren (STOC'14) showed
that if the market size is $n$, then $r$ rounds of interaction (with
logarithmic bandwidth) suffice to obtain an $n^{1/(r+1)}$-approximation to the
optimal social welfare. In particular, this implies that such markets converge
to a stable state (constant approximation) in time logarithmic in the market
size.
  We obtain the first multi-round lower bound for this setup. We show that even
if the allowable per-round bandwidth of each agent is $n^{\epsilon(r)}$, the
approximation ratio of any $r$-round (randomized) protocol is no better than
$\Omega(n^{1/5^{r+1}})$, implying an $\Omega(\log \log n)$ lower bound on the
rate of convergence of the market to equilibrium.
  Our construction and technique may be of interest to round-communication
tradeoffs in the more general setting of combinatorial auctions, for which the
only known lower bound is for simultaneous ($r=1$) protocols [DNO14].
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01780</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01781</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Profiling user activities with minimal traffic traces</dc:title>
 <dc:creator>Mai, Tiep</dc:creator>
 <dc:creator>Ajwani, Deepak</dc:creator>
 <dc:creator>Sala, Alessandra</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Understanding user behavior is essential to personalize and enrich a user's
online experience. While there are significant benefits to be accrued from the
pursuit of personalized services based on a fine-grained behavioral analysis,
care must be taken to address user privacy concerns. In this paper, we consider
the use of web traces with truncated URLs - each URL is trimmed to only contain
the web domain - for this purpose. While such truncation removes the
fine-grained sensitive information, it also strips the data of many features
that are crucial to the profiling of user activity. We show how to overcome the
severe handicap of lack of crucial features for the purpose of filtering out
the URLs representing a user activity from the noisy network traffic trace
(including advertisement, spam, analytics, webscripts) with high accuracy. This
activity profiling with truncated URLs enables the network operators to provide
personalized services while mitigating privacy concerns by storing and sharing
only truncated traffic traces.
  In order to offset the accuracy loss due to truncation, our statistical
methodology leverages specialized features extracted from a group of
consecutive URLs that represent a micro user action like web click, chat reply,
etc., which we call bursts. These bursts, in turn, are detected by a novel
algorithm which is based on our observed characteristics of the inter-arrival
time of HTTP records. We present an extensive experimental evaluation on a real
dataset of mobile web traces, consisting of more than 130 million records,
representing the browsing activities of 10,000 users over a period of 30 days.
Our results show that the proposed methodology achieves around 90% accuracy in
segregating URLs representing user activities from non-representative URLs.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01781</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01782</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Profit Maximization for Geographical Dispersed Green Data Centers</dc:title>
 <dc:creator>Kiani, Abbas</dc:creator>
 <dc:creator>Ansari, Nirwan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper aims at maximizing the profit associated with running
geographically dispersed green data centers, which offer multiple classes of
service. To this end, we formulate an optimization framework which relies on
the accuracy of the G/D/1 queue in characterizing the workload distribution,
and taps on the merits of the workload decomposition into green and brown
workload served by green and brown energy resources. Moreover, we take into
account of not only the Service Level Agreements (SLAs) between the data
centers and clients but also different deregulated electricity markets of data
centers located at different regions. We prove the convexity of our
optimization problem and the performance of the proposed workload distribution
strategy is evaluated via simulations.
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01782</dc:identifier>
 <dc:identifier>doi:10.1109/TSG.2016.2562565</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01783</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proximal operators for multi-agent path planning</dc:title>
 <dc:creator>Bento, Jos&#xe9;</dc:creator>
 <dc:creator>Derbinsky, Nate</dc:creator>
 <dc:creator>Mathy, Charles</dc:creator>
 <dc:creator>Yedidia, Jonathan S.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We address the problem of planning collision-free paths for multiple agents
using optimization methods known as proximal algorithms. Recently this approach
was explored in Bento et al. 2013, which demonstrated its ease of
parallelization and decentralization, the speed with which the algorithms
generate good quality solutions, and its ability to incorporate different
proximal operators, each ensuring that paths satisfy a desired property.
Unfortunately, the operators derived only apply to paths in 2D and require that
any intermediate waypoints we might want agents to follow be preassigned to
specific agents, limiting their range of applicability. In this paper we
resolve these limitations. We introduce new operators to deal with agents
moving in arbitrary dimensions that are faster to compute than their 2D
predecessors and we introduce landmarks, space-time positions that are
automatically assigned to the set of agents under different optimality
criteria. Finally, we report the performance of the new operators in several
numerical experiments.
</dc:description>
 <dc:description>Comment: See movie at http://youtu.be/gRnsjd_ocxs</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01786</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ADM-CLE approach for detecting slow variables in continuous time Markov
  chains and dynamic data</dc:title>
 <dc:creator>Cucuringu, Mihai</dc:creator>
 <dc:creator>Erban, Radek</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  A method for detecting intrinsic slow variables in high-dimensional
stochastic chemical reaction networks is developed and analyzed. It combines
anisotropic diffusion maps (ADM) with approximations based on the chemical
Langevin equation (CLE). The resulting approach, called ADM-CLE, has the
potential of being more efficient than the ADM method for a large class of
chemical reaction systems, because it replaces the computationally most
expensive step of ADM (running local short bursts of simulations) by using an
approximation based on the CLE. The ADM-CLE approach can be used to estimate
the stationary distribution of the detected slow variable, without any a-priori
knowledge of it. If the conditional distribution of the fast variables can be
obtained analytically, then the resulting ADM-CLE approach does not make any
use of Monte Carlo simulations to estimate the distributions of both slow and
fast variables.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01786</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01789</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Lattice of Congruences of a Finite Line Frame</dc:title>
 <dc:creator>Areces, Carlos</dc:creator>
 <dc:creator>Campercholi, Miguel</dc:creator>
 <dc:creator>Penazzi, Daniel</dc:creator>
 <dc:creator>Terraf, Pedro S&#xe1;nchez</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03B45 (Primary), 06B10, 06E25, 03B70 (Secondary)</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:description>  Let $\mathbf{F}=\left\langle F,R\right\rangle $ be a finite Kripke frame. A
congruence of $\mathbf{F}$ is a bisimulation of $\mathbf{F}$ that is also an
equivalence relation on F. The set of all congruences of $\mathbf{F}$ is a
lattice under the inclusion ordering. In this article we investigate this
lattice in the case that $\mathbf{F}$ is a finite line frame. We give concrete
descriptions of the join and meet of two congruences with a nontrivial upper
bound. Through these descriptions we show that for every nontrivial congruence
$\rho$, the interval $[\mathrm{Id_{F},\rho]}$ embeds into the lattice of
divisors of a suitable positive integer. We also prove that any two congruences
with a nontrivial upper bound permute.
</dc:description>
 <dc:description>Comment: 31 pages, 11 figures. Expanded intro, conclusions rewritten. New,
  less geometrical, proofs of Lemma 19 and (former) Lemma 34</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01789</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01799</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral Graph Theoretic Analysis of Tsallis Entropy-based Dissimilarity
  Measure</dc:title>
 <dc:creator>Hamza, A. Ben</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we introduce a nonextensive quantum information theoretic
measure which may be defined between any arbitrary number of density matrices,
and we analyze its fundamental properties in the spectral graph-theoretic
framework. Unlike other entropic measures, the proposed quantum divergence is
symmetric, matrix-convex, theoretically upper-bounded, and has the advantage of
being generalizable to any arbitrary number of density matrices, with a
possibility of assigning weights to these densities.
</dc:description>
 <dc:description>Comment: 12 pages, 2 figures</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01800</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multicomponent Approach to Nonrigid Registration of Diffusion Tensor
  Images</dc:title>
 <dc:creator>Khader, Mohammed</dc:creator>
 <dc:creator>Hamza, A. Ben</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a nonrigid registration approach for diffusion tensor images using
a multicomponent information-theoretic measure. Explicit orientation
optimization is enabled by incorporating tensor reorientation, which is
necessary for wrapping diffusion tensor images. Experimental results on
diffusion tensor images indicate the feasibility of the proposed approach and a
much better performance compared to the affine registration method based on
mutual information in terms of registration accuracy in the presence of
geometric distortion.
</dc:description>
 <dc:description>Comment: 19 pages, 9 figures</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01802</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fountain Codes with Nonuniform Selection Distributions through Feedback</dc:title>
 <dc:creator>Hashemi, Morteza</dc:creator>
 <dc:creator>Cassuto, Yuval</dc:creator>
 <dc:creator>Trachtenberg, Ari</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  One key requirement for fountain (rateless) coding schemes is to achieve a
high intermediate symbol recovery rate. Recent coding schemes have incorporated
the use of a feedback channel to improve intermediate performance of
traditional rateless codes; however, these codes with feedback are designed
based on uniformly at random selection of input symbols. In this paper, on the
other hand, we develop feedback-based fountain codes with dynamically-adjusted
nonuniform symbol selection distributions, and show that this characteristic
can enhance the intermediate decoding rate. We provide an analysis of our
codes, including bounds on computational complexity and failure probability for
a maximum likelihood decoder; the latter are tighter than bounds known for
classical rateless codes. Through numerical simulations, we also show that
feedback information paired with a nonuniform selection distribution can highly
improve the symbol recovery rate, and that the amount of feedback sent can be
tuned to the specific transmission properties of a given feedback channel.
</dc:description>
 <dc:description>Comment: Submitted to the IEEE Transactions on Information Theory</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01802</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2016.2570232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01806</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kernelized Low Rank Representation on Grassmann Manifolds</dc:title>
 <dc:creator>Wang, Boyue</dc:creator>
 <dc:creator>Hu, Yongli</dc:creator>
 <dc:creator>Gao, Junbin</dc:creator>
 <dc:creator>Sun, Yanfeng</dc:creator>
 <dc:creator>Yin, Baocai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Low rank representation (LRR) has recently attracted great interest due to
its pleasing efficacy in exploring low-dimensional subspace structures embedded
in data. One of its successful applications is subspace clustering which means
data are clustered according to the subspaces they belong to. In this paper, at
a higher level, we intend to cluster subspaces into classes of subspaces. This
is naturally described as a clustering problem on Grassmann manifold. The
novelty of this paper is to generalize LRR on Euclidean space onto an LRR model
on Grassmann manifold in a uniform kernelized framework. The new methods have
many applications in computer vision tasks. Several clustering experiments are
conducted on handwritten digit images, dynamic textures, human face clips and
traffic scene sequences. The experimental results show that the proposed
methods outperform a number of state-of-the-art subspace clustering methods.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01806</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01807</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low Rank Representation on Grassmann Manifolds: An Extrinsic Perspective</dc:title>
 <dc:creator>Wang, Boyue</dc:creator>
 <dc:creator>Hu, Yongli</dc:creator>
 <dc:creator>Gao, Junbin</dc:creator>
 <dc:creator>Sun, Yanfeng</dc:creator>
 <dc:creator>Yin, Baocai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Many computer vision algorithms employ subspace models to represent data. The
Low-rank representation (LRR) has been successfully applied in subspace
clustering for which data are clustered according to their subspace structures.
The possibility of extending LRR on Grassmann manifold is explored in this
paper. Rather than directly embedding Grassmann manifold into a symmetric
matrix space, an extrinsic view is taken by building the self-representation of
LRR over the tangent space of each Grassmannian point. A new algorithm for
solving the proposed Grassmannian LRR model is designed and implemented.
Several clustering experiments are conducted on handwritten digits dataset,
dynamic texture video clips and YouTube celebrity face video data. The
experimental results show our method outperforms a number of existing methods.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01809</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Block ADMM for Big Data Optimization in Modern Communication
  Networks</dc:title>
 <dc:creator>Liu, Lanchao</dc:creator>
 <dc:creator>Han, Zhu</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, we review the parallel and distributed optimization algorithms
based on the alternating direction method of multipliers (ADMM) for solving
&quot;big data&quot; optimization problems in modern communication networks. We first
introduce the canonical formulation of the large-scale optimization problem.
Next, we describe the general form of ADMM and then focus on several direct
extensions and sophisticated modifications of ADMM from $2$-block to $N$-block
settings to deal with the optimization problem. The iterative schemes and
convergence properties of each extension/modification are given, and the
implementation on large-scale computing facilities is also illustrated.
Finally, we numerate several applications in communication networks, such as
the security constrained optimal power flow problem in smart grid networks and
mobile data offloading problem in software defined networks (SDNs).
</dc:description>
 <dc:date>2015-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01826</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Power Control for Delay-Aware Device-to-Device Communications</dc:title>
 <dc:creator>Wang, Wei</dc:creator>
 <dc:creator>Zhang, Fan</dc:creator>
 <dc:creator>Lau, Vincent K. N.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider the dynamic power control for delay-aware D2D
communications. The stochastic optimization problem is formulated as an
infinite horizon average cost Markov decision process. To deal with the curse
of dimensionality, we utilize the interference filtering property of the
CSMA-like MAC protocol and derive a closed-form approximate priority function
and the associated error bound using perturbation analysis. Based on the
closed-form approximate priority function, we propose a low-complexity power
control algorithm solving the per-stage optimization problem. The proposed
solution is further shown to be asymptotically optimal for a sufficiently large
carrier sensing distance. Finally, the proposed power control scheme is
compared with various baselines through simulations, and it is shown that
significant performance gain can be achieved.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1502.07966</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01826</dc:identifier>
 <dc:identifier>IEEE Journal of Selected Areas in Communications, vol. 33, no. 1,
  pp. 14 - 27, Jan. 2015</dc:identifier>
 <dc:identifier>doi:10.1109/JSAC.2014.2369614</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01828</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Cloud Infrastructure Service Recommendation System for Optimizing
  Real-time QoS Provisioning Constraints</dc:title>
 <dc:creator>Zhang, Miranda</dc:creator>
 <dc:creator>Ranjan, Rajiv</dc:creator>
 <dc:creator>Menzel, Michael</dc:creator>
 <dc:creator>Nepal, Surya</dc:creator>
 <dc:creator>Strazdins, Peter</dc:creator>
 <dc:creator>Wang, Lizhe</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Proliferation of cloud computing has revolutionized hosting and delivery of
Internet-based application services. However, with the constant launch of new
cloud services and capabilities almost every month by both big (e.g., Amazon
Web Service, Microsoft Azure) and small companies (e.g. Rackspace, Ninefold),
decision makers (e.g. application developers, CIOs) are likely to be
overwhelmed by choices available. The decision making problem is further
complicated due to heterogeneous service configurations and application
provisioning Quality of Service (QoS) constraints. To address this hard
challenge, in our previous work we developed a semi-automated, extensible, and
ontology-based approach to infrastructure service discovery and selection based
on only design time constraints (e.g., renting cost, datacentre location,
service feature, etc.). In this paper, we extend our approach to include the
real-time (run-time) QoS (endto- end message latency, end-to-end message
throughput) in the decision making process. Hosting of next generation
applications in domain of on-line interactive gaming, large scale sensor
analytics, and real-time mobile applications on cloud services necessitates
optimization of such real-time QoS constraints for meeting Service Level
Agreements (SLAs). To this end, we present a real-time QoS aware multi-criteria
decision making technique that builds over well known Analytics Hierarchy
Process (AHP) method. The proposed technique is applicable to selecting
Infrastructure as a Service (IaaS) cloud offers, and it allows users to define
multiple design-time and real-time QoS constraints or requirements. These
requirements are then matched against our knowledge base to compute possible
best fit combinations of cloud services at IaaS layer. We conducted extensive
experiments to prove the feasibility of our approach.
</dc:description>
 <dc:description>Comment: IEEE Systems Journal</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01836</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Unconditional Hardness Results for Dynamic and Online Problems</dc:title>
 <dc:creator>Clifford, Raphael</dc:creator>
 <dc:creator>Gr&#xf8;nlund, Allan</dc:creator>
 <dc:creator>Larsen, Kasper Green</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  There has been a resurgence of interest in lower bounds whose truth rests on
the conjectured hardness of well known computational problems. These
conditional lower bounds have become important and popular due to the painfully
slow progress on proving strong unconditional lower bounds. Nevertheless, the
long term goal is to replace these conditional bounds with unconditional ones.
In this paper we make progress in this direction by studying the cell probe
complexity of two conjectured to be hard problems of particular importance:
matrix-vector multiplication and a version of dynamic set disjointness known as
Patrascu's Multiphase Problem. We give improved unconditional lower bounds for
these problems as well as introducing new proof techniques of independent
interest. These include a technique capable of proving strong threshold lower
bounds of the following form: If we insist on having a very fast query time,
then the update time has to be slow enough to compute a lookup table with the
answer to every possible query. This is the first time a lower bound of this
type has been proven.
</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01836</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01840</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Autonomous CRM Control via CLV Approximation with Deep Reinforcement
  Learning in Discrete and Continuous Action Space</dc:title>
 <dc:creator>Tkachenko, Yegor</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The paper outlines a framework for autonomous control of a CRM (customer
relationship management) system. First, it explores how a modified version of
the widely accepted Recency-Frequency-Monetary Value system of metrics can be
used to define the state space of clients or donors. Second, it describes a
procedure to determine the optimal direct marketing action in discrete and
continuous action space for the given individual, based on his position in the
state space. The procedure involves the use of model-free Q-learning to train a
deep neural network that relates a client's position in the state space to
rewards associated with possible marketing actions. The estimated value
function over the client state space can be interpreted as customer lifetime
value, and thus allows for a quick plug-in estimation of CLV for a given
client. Experimental results are presented, based on KDD Cup 1998 mailing
dataset of donation solicitations.
</dc:description>
 <dc:description>Comment: 13 pages, 8 figures</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01840</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01842</identifier>
 <datestamp>2016-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal Certification of Android Bytecode</dc:title>
 <dc:creator>Gunadi, Hendra</dc:creator>
 <dc:creator>Tiu, Alwen</dc:creator>
 <dc:creator>Gore, Rajeev</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Android is an operating system that has been used in a majority of mobile
devices. Each application in Android runs in an instance of the Dalvik virtual
machine, which is a register-based virtual machine (VM). Most applications for
Android are developed using Java, compiled to Java bytecode and then translated
to DEX bytecode using the dx tool in the Android SDK. In this work, we aim to
develop a type-based method for certifying non-interference properties of DEX
bytecode, following a methodology that has been developed for Java bytecode
certification by Barthe et al. To this end, we develop a formal operational
semantics of the Dalvik VM, a type system for DEX bytecode, and prove the
soundness of the type system with respect to a notion of non-interference. We
then study the translation process from Java bytecode to DEX bytecode, as
implemented in the dx tool in the Android SDK. We show that an abstracted
version of the translation from Java bytecode to DEX bytecode preserves the
non-interference property. More precisely, we show that if the Java bytecode is
typable in Barthe et al's type system (which guarantees non-interference) then
its translation is typable in our type system. This result opens up the
possibility to leverage existing bytecode verifiers for Java to certify
non-interference properties of Android bytecode.
</dc:description>
 <dc:description>Comment: 12 pages content, 43 pages total including Appendices, double-column
  IEEE</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:date>2016-10-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01855</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Math Marvel with M-Learning</dc:title>
 <dc:creator>Balaji, R. D.</dc:creator>
 <dc:creator>Veeramani, V.</dc:creator>
 <dc:creator>Balaji, Malathi</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Math is the backbone of any field. Still its a night mare for many. Recent
survey proves that many students become dropouts from their higher education
due to math courses. ICT is an enchanted word in the contemporary educational
environment. It made the learning process more entertaining and almost made the
knowledge loss negligible. Adopting the ICT in math courses are still in the
infant level. Hence its a challenge placed in front of the IT and academic
professionals teaching math to make a suitable ICT tools for math courses to
make the learning an amusing experience. In this paper we have highlighted
three main concepts which make the math classes in a fascinating way. The first
method is introducing revolutionary hybrid ebooks which make the reading with
both audio and video facilities. The second method is facilitating the flip
class room so that student may have anywhere-anytime learning experience.
Finally the recent trends in m-learning are using apps for math courses. We
have highlighted the improvement showed by the students based on the survey
conducted with two groups of students with m-learning tools and without
m-learning tools. Even though there are good improvements showed by the
students, we the researchers feel that few more improvements are required in
these methodologies. The suggestions for the same are made in the
recommendations and conclusion section.
</dc:description>
 <dc:description>Comment: 7 pages, ROMIST 2015, Oman</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01861</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social Impact of MOOC's in Oman Higher Education</dc:title>
 <dc:creator>Balaji, R. D.</dc:creator>
 <dc:creator>Al-Mahri, Fatma</dc:creator>
 <dc:creator>Al-Fatnaasi, Tarek</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The word E transformed everything is this world, as well as the whole globe
itself. To a great extend this helps for eco friendly green world. In
educational field, electronic medium has played a major role. It influenced and
changed almost every component of it to electronic medium like e-book, online
courses, etc. Throughout the world, leading universities are offering online
courses voluntarily. Generally we refer to it as Massive Online Open Courses
(MOOCs). There are many debates going on related to success and consequences of
MOOCs. Many are highlighting that these courses are self-paced, economical, and
provide quality training to all irrespective of geographical constraints. But
many other academic people go against these points and keep listing many other
disadvantages of MOOCs. This paper explores the basics of MOOCs at the initial
section. Following section will deal with advantages and disadvantages of MOOCs
in general. We the researchers collected the details about the awareness of
MOOCs among teachers and students in a higher education institution in Oman. We
have also collected the details about MOOCs implementation and usage within
Oman educational society. Based on the collected information, we have evaluated
and presented the findings about MOOCs impact in Oman higher education. We have
felt that doing appropriate improvements in MOOCs may become an imperative
medium in Oman educational institutions. The suggestions are listed in the
discussion and recommendation section.
</dc:description>
 <dc:description>Comment: ICOET 2015, Oman</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01873</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Location, location, location: Border effects in interference limited ad
  hoc networks</dc:title>
 <dc:creator>Georgiou, Orestis</dc:creator>
 <dc:creator>Wang, Shanshan</dc:creator>
 <dc:creator>Bocus, Mohammud Z.</dc:creator>
 <dc:creator>Dettmann, Carl P.</dc:creator>
 <dc:creator>Coon, Justin P.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Wireless networks are fundamentally limited by the intensity of the received
signals and by their inherent interference. It is shown here that in finite ad
hoc networks where node placement is modelled according to a Poisson point
process and no carrier sensing is employed for medium access, the SINR received
by nodes located at the border of the network deployment/operation region is on
average greater than the rest. This is primarily due to the uneven interference
landscape of such networks which is particularly kind to border nodes giving
rise to all sorts of performance inhomogeneities and access unfairness. Using
tools from stochastic geometry we quantify these spatial variations and provide
closed form communication-theoretic results showing why the receiver's location
is so important.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, conference proceedings of SPASWIN'2015</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01873</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01877</identifier>
 <datestamp>2015-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social media in scholarly communication</dc:title>
 <dc:creator>Haustein, Stefanie</dc:creator>
 <dc:creator>Sugimoto, Cassidy R.</dc:creator>
 <dc:creator>Larivi&#xe8;re, Vincent</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Social media metrics - commonly coined as &quot;altmetrics&quot; - have been heralded
as great democratizers of science, providing broader and timelier indicators of
impact than citations. These metrics come from a range of sources, including
Twitter, blogs, social reference managers, post-publication peer review, and
other social media platforms. Social media metrics have begun to be used as
indicators of scientific impact, yet the theoretical foundation, empirical
validity, and extent of use of platforms underlying these metrics lack thorough
treatment in the literature. This editorial provides an overview of terminology
and definitions of altmetrics and summarizes current research regarding social
media use in academia, social media metrics as well as data reliability and
validity. The papers of the special issue are introduced.
</dc:description>
 <dc:description>Comment: Guest Editorial to the special issue &quot;Social Media Metrics in
  Scholarly Communication: Exploring Tweets, Blogs, Likes and other Altmetrics&quot;
  in Aslib Journal of Information Management 67(3)</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:date>2015-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01877</dc:identifier>
 <dc:identifier>Aslib Journal of Information Management 67(3) (2015)</dc:identifier>
 <dc:identifier>doi:10.1108/AJIM-03-2015-0047</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01879</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multihop connectivity of ad hoc networks with randomly oriented
  directional antennas</dc:title>
 <dc:creator>Georgiou, Orestis</dc:creator>
 <dc:creator>Nguyen, Camly</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Directional antennas and beamforming can significantly improve point-to-point
wireless links when perfectly aligned. In this letter we investigate the
extreme opposite where antenna orientations and positions are chosen at random
in the presence of Rayleigh fading. We show that while the 1-hop network
connectivity is deteriorated, the multihop routes improve, especially in the
dense regime. We derive closed form expressions for the expectation of the
$1$-hop and $2$-hop degree which are verified through computer simulations. We
conclude that node density does not greatly affect the number of hops required
between stations whilst simple random beamforming schemes do, thus returning
substantial network performance benefits due to the existence of shorter
multi-hop paths.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures, Letter</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01883</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust real time face recognition and tracking on gpu using fusion of
  rgb and depth image</dc:title>
 <dc:creator>Naik, Narmada</dc:creator>
 <dc:creator>Rathna, G. N</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a real-time face recognition system using kinect sensor.
The algorithm is implemented on GPU using opencl and significant speed
improvements are observed. We use kinect depth image to increase the robustness
and reduce computational cost of conventional LBP based face recognition. The
main objective of this paper was to perform robust, high speed fusion based
face recognition and tracking. The algorithm is mainly composed of three steps.
First step is to detect all faces in the video using viola jones algorithm. The
second step is online database generation using a tracking window on the face.
A modified LBP feature vector is calculated using fusion information from depth
and greyscale image on GPU. This feature vector is used to train a svm
classifier. Third step involves recognition of multiple faces based on our
modified feature vector.
</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01883</dc:identifier>
 <dc:identifier>doi:10.5121/csit.2015.50601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01887</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Evaluation of Distributed Networked Control for a
  Dual-Machine Power System</dc:title>
 <dc:creator>Tavassoli, Babak</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Oscillations between swing modes of electric machines is an important
limitation in achieving a high level of transient performance and reliability
in power grids. Based on the new advances in measurement and transmission of
wide-area information, this work proposes a distributed networked control
scheme by considering the communication delays. The results are applied to
reduce the inter-area swing oscillations in a power grid. In comparison with
the previous works, we provide a more realistic modeling of the resulting
networked control system with data sampling and delays. The exactness of the
proposed modeling allows for precise evaluation and comparison between the
distributed and decentralized schema. A symmetric a dual machine power system
is highly oscillatory and we focus on this case to evaluate the ability of the
proposed control design in dampening of the oscillations. The design can be
done either based on optimization of a quadratic cost function or a disturbance
attenuation level
</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01891</identifier>
 <datestamp>2016-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Query Language for Multi-version Data Web Archives</dc:title>
 <dc:creator>Meimaris, Marios</dc:creator>
 <dc:creator>Papastefanatos, George</dc:creator>
 <dc:creator>Viglas, Stratis</dc:creator>
 <dc:creator>Stavrakas, Yannis</dc:creator>
 <dc:creator>Pateritsas, Christos</dc:creator>
 <dc:creator>Anagnostopoulos, Ioannis</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The Data Web refers to the vast and rapidly increasing quantity of
scientific, corporate, government and crowd-sourced data published in the form
of Linked Open Data, which encourages the uniform representation of
heterogeneous data items on the web and the creation of links between them. The
growing availability of open linked datasets has brought forth significant new
challenges regarding their proper preservation and the management of evolving
information within them. In this paper, we focus on the evolution and
preservation challenges related to publishing and preserving evolving linked
data across time. We discuss the main problems regarding their proper modelling
and querying and provide a conceptual model and a query language for modelling
and retrieving evolving data along with changes affecting them. We present in
details the syntax of the query language and demonstrate its functionality over
a real-world use case of evolving linked dataset from the biological domain.
</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:date>2016-05-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01891</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01920</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating Two-Stream CNN for Video Classification</dc:title>
 <dc:creator>Ye, Hao</dc:creator>
 <dc:creator>Wu, Zuxuan</dc:creator>
 <dc:creator>Zhao, Rui-Wei</dc:creator>
 <dc:creator>Wang, Xi</dc:creator>
 <dc:creator>Jiang, Yu-Gang</dc:creator>
 <dc:creator>Xue, Xiangyang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Videos contain very rich semantic information. Traditional hand-crafted
features are known to be inadequate in analyzing complex video semantics.
Inspired by the huge success of the deep learning methods in analyzing image,
audio and text data, significant efforts are recently being devoted to the
design of deep nets for video analytics. Among the many practical needs,
classifying videos (or video clips) based on their major semantic categories
(e.g., &quot;skiing&quot;) is useful in many applications. In this paper, we conduct an
in-depth study to investigate important implementation options that may affect
the performance of deep nets on video classification. Our evaluations are
conducted on top of a recent two-stream convolutional neural network (CNN)
pipeline, which uses both static frames and motion optical flows, and has
demonstrated competitive performance against the state-of-the-art methods. In
order to gain insights and to arrive at a practical guideline, many important
options are studied, including network architectures, model fusion, learning
parameters and the final prediction methods. Based on the evaluations, very
competitive results are attained on two popular video classification
benchmarks. We hope that the discussions and conclusions from this work can
help researchers in related fields to quickly set up a good basis for further
investigations along this very promising direction.
</dc:description>
 <dc:description>Comment: ACM ICMR'15</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01920</dc:identifier>
 <dc:identifier>doi:10.1145/2671188.2749406</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01927</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings Tenth International Workshop on Developments in
  Computational Models</dc:title>
 <dc:creator>Lago, Ugo Dal</dc:creator>
 <dc:creator>Harmer, Russ</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  This volume contains the papers presented at the Tenth International Workshop
on Developments in Computational Models (DCM) held in Vienna, Austria on 13th
July 2014, as part of the Vienna Summer of Logic.
  Several new models of computation have emerged in the last years, and many
developments of traditional computational models have been proposed with the
aim of taking into account the new demands of computer systems users and the
new capabilities of computation engines. A new computational model, or a new
feature in a traditional one, usually is reflected in a new family of
programming languages, and new paradigms of software development.
  The aim of this workshop is to bring together researchers who are currently
developing new computational models or new features for traditional
computational models, in order to foster their interaction, to provide a forum
for presenting new ideas and work in progress, and to enable newcomers to learn
about current activities in this area. Topics of interest include all abstract
models of computation and their applications to the development of programming
languages and systems.
</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01927</dc:identifier>
 <dc:identifier>EPTCS 179, 2015</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01928</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings Tenth Workshop on Model Based Testing</dc:title>
 <dc:creator>Pakulin, Nikolay</dc:creator>
 <dc:creator>Petrenko, Alexander K.</dc:creator>
 <dc:creator>Schlingloff, Bernd-Holger</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The workshop is devoted to model-based testing of both software and hardware.
Model-based testing uses models describing the required behavior of the system
under consideration to guide such efforts as test selection and test results
evaluation. Testing validates the real system behavior against models and
checks that the implementation conforms to them, but is capable also to find
errors in the models themselves.
  The intent of this workshop is to bring together researchers and users of
model-based testing techniques and tools to discuss the state of the art in
theory, applications, tools, and industrialization of model-based testing and
related domains.
</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01928</dc:identifier>
 <dc:identifier>EPTCS 180, 2015</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.180</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01934</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Mining for Prediction of Human Performance Capability in the
  Software-Industry</dc:title>
 <dc:creator>Thakur, Gaurav Singh</dc:creator>
 <dc:creator>Gupta, Anubhav</dc:creator>
 <dc:creator>Gupta, Sangita</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The recruitment of new personnel is one of the most essential business
processes which affect the quality of human capital within any company. It is
highly essential for the companies to ensure the recruitment of right talent to
maintain a competitive edge over the others in the market. However IT companies
often face a problem while recruiting new people for their ongoing projects due
to lack of a proper framework that defines a criteria for the selection
process. In this paper we aim to develop a framework that would allow any
project manager to take the right decision for selecting new talent by
correlating performance parameters with the other domain-specific attributes of
the candidates. Also, another important motivation behind this project is to
check the validity of the selection procedure often followed by various big
companies in both public and private sectors which focus only on academic
scores, GPA/grades of students from colleges and other academic backgrounds. We
test if such a decision will produce optimal results in the industry or is
there a need for change that offers a more holistic approach to recruitment of
new talent in the software companies. The scope of this work extends beyond the
IT domain and a similar procedure can be adopted to develop a recruitment
framework in other fields as well. Data-mining techniques provide useful
information from the historical projects depending on which the hiring-manager
can make decisions for recruiting high-quality workforce. This study aims to
bridge this hiatus by developing a data-mining framework based on an
ensemble-learning technique to refocus on the criteria for personnel selection.
The results from this research clearly demonstrated that there is a need to
refocus on the selection-criteria for quality objectives.
</dc:description>
 <dc:description>Comment: Data Mining for Prediction of Human Performance Capability in the
  Software-Industry, International Journal of Data-Mining and Knowledge
  Management Process (IJDKP) - March 2015 Issue</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01942</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking</dc:title>
 <dc:creator>Leal-Taix&#xe9;, Laura</dc:creator>
 <dc:creator>Milan, Anton</dc:creator>
 <dc:creator>Reid, Ian</dc:creator>
 <dc:creator>Roth, Stefan</dc:creator>
 <dc:creator>Schindler, Konrad</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In the recent past, the computer vision community has developed centralized
benchmarks for the performance evaluation of a variety of tasks, including
generic object and pedestrian detection, 3D reconstruction, optical flow,
single-object short-term tracking, and stereo estimation. Despite potential
pitfalls of such benchmarks, they have proved to be extremely helpful to
advance the state of the art in the respective area. Interestingly, there has
been rather limited work on the standardization of quantitative benchmarks for
multiple target tracking. One of the few exceptions is the well-known PETS
dataset, targeted primarily at surveillance applications. Despite being widely
used, it is often applied inconsistently, for example involving using different
subsets of the available data, different ways of training the models, or
differing evaluation scripts. This paper describes our work toward a novel
multiple object tracking benchmark aimed to address such issues. We discuss the
challenges of creating such a framework, collecting existing and new data,
gathering state-of-the-art methods to be tested on the datasets, and finally
creating a unified evaluation system. With MOTChallenge we aim to pave the way
toward a unified evaluation framework for a more meaningful quantification of
multi-target tracking.
</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01942</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01949</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A lower bound on the order of the largest induced forest in planar
  graphs with high girth</dc:title>
 <dc:creator>Dross, Fran&#xe7;ois</dc:creator>
 <dc:creator>Montassier, Mickael</dc:creator>
 <dc:creator>Pinlou, Alexandre</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We give here new upper bounds on the size of a smallest feedback vertex set
in planar graphs with high girth. In particular, we prove that a planar graph
with girth $g$ and size $m$ has a feedback vertex set of size at most
$\frac{4m}{3g}$, improving the trivial bound of $\frac{2m}{g}$. We also prove
that every $2$-connected graph with maximum degree $3$ and order $n$ has a
feedback vertex set of size at most $\frac{n+2}{3}$.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures. arXiv admin note: text overlap with
  arXiv:1409.1348</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01949</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01954</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Subset Selection Using Gabor Filters and Neural Networks</dc:title>
 <dc:creator>Ali, Heider K.</dc:creator>
 <dc:creator>Whitehead, Anthony</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  An automatic method for the selection of subsets of images, both modern and
historic, out of a set of landmark large images collected from the Internet is
presented in this paper. This selection depends on the extraction of dominant
features using Gabor filtering. Features are selected carefully from a
preliminary image set and fed into a neural network as a training data. The
method collects a large set of raw landmark images containing modern and
historic landmark images and non-landmark images. The method then processes
these images to classify them as landmark and non-landmark images. The
classification performance highly depends on the number of candidate features
of the landmark.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01954</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01957</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video Contents Prior Storing Server for Optical Access Network</dc:title>
 <dc:creator>Tsang, Tony</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  One of the most important multimedia applications is Internet protocol TV
(IPTV) for next-generation networks. IPTV provides triple-play services that
require high-speed access networks with the functions of multicasting and
quality of service (QoS) guarantees. Among optical access networks, Ethernet
passive optical networks (EPONs) are regarded as among the best solutions to
meet higher bandwidth demands. In this paper, we propose a new architecture for
multicasting live IPTV traffic in optical access network. The proposed
mechanism involves assigning a unique logical link identifier to each IPTV
channel. To manage multicasting, a prior storing server in the optical line
terminal (OLT) and in each optical network unit (ONU) is constructed. In this
work, we propose a partial prior storing strategy that considers the changes in
the popularity of the video content segments over time and the access patterns
of the users to compute the utility of the objects in the prior storage. We
also propose to partition the prior storage to avoid the eviction of the
popular objects (those not accessed frequently) by the unpopular ones which are
accessed with higher frequency. The popularity distribution and ageing of
popularity are measured from two online datasets and use the parameters in
simulations. Simulation results show that our proposed architecture can improve
the system performance and QoS parameters in terms of packet delay, jitter and
packet loss.
</dc:description>
 <dc:description>Comment: 10 pages. in March 2015, Volume 7. Number 1 International Journal of
  Computer Networks &amp; Communications (IJCNC) March 2015, Volume 7</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01957</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01974</identifier>
 <datestamp>2016-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure two-party quantum computation for non-rational and rational
  settings</dc:title>
 <dc:creator>Maitra, Arpita</dc:creator>
 <dc:creator>Paul, Goutam</dc:creator>
 <dc:creator>Pal, Asim K.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  Since the negative result of Lo (Physical Review A, 1997), it has been left
open whether there exist some functions that can be securely computed in
two-party setting in quantum domain when one of the parties is malicious. In
this paper, we for the first time, show that there are some functions for which
secure two-party quantum computation is indeed possible for non-simultaneous
channel model. This is in sharp contrast with the impossibility result of Ben
-Or et al. (FOCS, 2006) in broadcast channel model. The functions we study are
of two types - one is any function without an embedded XOR, and the other one
is a particular function containing an embedded XOR. Contrary to classical
solutions, security against adversaries with unbounded power of computation is
achieved by the quantum protocols due to entanglement. Further, in the context
of secure multi-party quantum computation, for the first time we introduce
rational parties, each of whom tries to maximize its utility by obtaining the
function output alone. We adapt our quantum protocols for both the above types
of functions in rational setting to achieve fairness and strict Nash
equilibrium.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:date>2016-05-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01974</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01982</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Diffusion Schemes for Heterogeneous Networks</dc:title>
 <dc:creator>Fernandez-Bes, Jesus</dc:creator>
 <dc:creator>Arenas-Garc&#xed;a, Jer&#xf3;nimo</dc:creator>
 <dc:creator>Silva, Magno T. M.</dc:creator>
 <dc:creator>Azpicueta-Ruiz, Luis A.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we deal with distributed estimation problems in diffusion
networks with heterogeneous nodes, i.e., nodes that either implement different
adaptive rules or differ in some other aspect such as the filter structure or
length, or step size. Although such heterogeneous networks have been considered
from the first works on diffusion networks, obtaining practical and robust
schemes to adaptively adjust the combiners in different scenarios is still an
open problem. In this paper, we study a diffusion strategy specially designed
and suited to heterogeneous networks. Our approach is based on two key
ingredients: 1) the adaptation and combination phases are completely decoupled,
so that network nodes keep purely local estimations at all times; and 2)
combiners are adapted to minimize estimates of the network mean-square-error.
Our scheme is compared with the standard Adapt-then-Combine scheme and
theoretically analyzed using energy conservation arguments. Several experiments
involving networks with heterogeneous nodes show that the proposed decoupled
Adapt-then-Combine approach with adaptive combiners outperforms other
state-of-the-art techniques, becoming a competitive approach in these
scenarios.
</dc:description>
 <dc:description>Comment: To appear in in IEEE Transactions on Signal Processing. URL:
  http://ieeexplore.ieee.org/document/8010454/</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01982</dc:identifier>
 <dc:identifier>IEEE Transactions on Signal Processing ( Volume: 65, Issue: 21,
  Nov.1, 1 2017 )</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2740199</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01987</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing a Linked Data Migrational Framework for Singapore Government
  Datasets</dc:title>
 <dc:creator>Raamkumar, Aravind Sesagiri</dc:creator>
 <dc:creator>Thangavelu, Muthu Kumaar</dc:creator>
 <dc:creator>Khoo, Sudarsan Kaleeswaran amd Christopher S. G.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>H.3.5</dc:subject>
 <dc:description>  The subject area of this report is Linked Data and its application to the
Government domain. Linked Data is an alternative method of data representation
that aims to interlink data from varied sources through relationships.
Governments around the world have started publishing their data in this format
to assist citizens in making better use of public services. This report
provides an eight step migrational framework for converting Singapore
Government data from legacy systems to Linked Data format. The framework
formulation is based on a study of the Singapore data ecosystem with help from
Infocomm Development Authority (iDA) of Singapore. Each step in the migrational
framework has been constructed with objectives, recommendations, best practices
and issues with entry and exit points. This work builds on the existing Linked
Data literature, implementations in other countries and cookbooks provided by
Linked Data researchers. iDA can use this report to gain an understanding of
the effort and work involved in the implementation of Linked Data system on top
of their legacy systems. The framework can be evaluated by building a Proof of
Concept (POC) application.
</dc:description>
 <dc:description>Comment: 23 pages, 5 figures</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01987</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01989</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pixel-wise Deep Learning for Contour Detection</dc:title>
 <dc:creator>Hwang, Jyh-Jing</dc:creator>
 <dc:creator>Liu, Tyng-Luh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We address the problem of contour detection via per-pixel classifications of
edge point. To facilitate the process, the proposed approach leverages with
DenseNet, an efficient implementation of multiscale convolutional neural
networks (CNNs), to extract an informative feature vector for each pixel and
uses an SVM classifier to accomplish contour detection. In the experiment of
contour detection, we look into the effectiveness of combining per-pixel
features from different CNN layers and verify their performance on BSDS500.
</dc:description>
 <dc:description>Comment: 2 pages. arXiv admin note: substantial text overlap with
  arXiv:1412.6857</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.01995</identifier>
 <datestamp>2015-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving the Closest Vector Problem in $2^n$ Time--- The Discrete
  Gaussian Strikes Again!</dc:title>
 <dc:creator>Aggarwal, Divesh</dc:creator>
 <dc:creator>Dadush, Daniel</dc:creator>
 <dc:creator>Stephens-Davidowitz, Noah</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We give a $2^{n+o(n)}$-time and space randomized algorithm for solving the
exact Closest Vector Problem (CVP) on $n$-dimensional Euclidean lattices. This
improves on the previous fastest algorithm, the deterministic
$\widetilde{O}(4^{n})$-time and $\widetilde{O}(2^{n})$-space algorithm of
Micciancio and Voulgaris.
  We achieve our main result in three steps. First, we show how to modify the
sampling algorithm from [ADRS15] to solve the problem of discrete Gaussian
sampling over lattice shifts, $L- t$, with very low parameters. While the
actual algorithm is a natural generalization of [ADRS15], the analysis uses
substantial new ideas. This yields a $2^{n+o(n)}$-time algorithm for
approximate CVP for any approximation factor $\gamma = 1+2^{-o(n/\log n)}$.
Second, we show that the approximate closest vectors to a target vector $t$ can
be grouped into &quot;lower-dimensional clusters,&quot; and we use this to obtain a
recursive reduction from exact CVP to a variant of approximate CVP that
&quot;behaves well with these clusters.&quot; Third, we show that our discrete Gaussian
sampling algorithm can be used to solve this variant of approximate CVP.
  The analysis depends crucially on some new properties of the discrete
Gaussian distribution and approximate closest vectors, which might be of
independent interest.
</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:date>2015-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.01995</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02001</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constraining application behaviour by generating languages</dc:title>
 <dc:creator>van der Walt, Paul</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Writing a platform for reactive applications which enforces operational
constraints is difficult, and has been approached in various ways. In this
experience report, we detail an approach using an embedded DSL which can be
used to specify the structure and permissions of a program in a given
application domain. Once the developer has specified which components an
application will consist of, and which permissions each one needs, the
specification itself evaluates to a new, tailored, language. The final
implementation of the application is then written in this specialised
environment where precisely the API calls associated with the permissions which
have been granted, are made available.
  Our prototype platform targets the domain of mobile computing, and is
implemented using Racket. It demonstrates resource access control (e.g.,
camera, address book, etc.) and tries to prevent leaking of private data.
Racket is shown to be an extremely effective platform for designing new
programming languages and their run-time libraries. We demonstrate that this
approach allows reuse of an inter-component communication layer, is convenient
for the application developer because it provides high-level building blocks to
structure the application, and provides increased control to the platform
owner, preventing certain classes of errors by the developer.
</dc:description>
 <dc:description>Comment: 8 pages, 8th European Lisp Symposium</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02010</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Chaotic Dynamical System that Paints</dc:title>
 <dc:creator>Sahai, Tuhin</dc:creator>
 <dc:creator>Mathew, George</dc:creator>
 <dc:creator>Surana, Amit</dc:creator>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Can a dynamical system paint masterpieces such as Da Vinci's Mona Lisa or
Monet's Water Lilies? Moreover, can this dynamical system be chaotic in the
sense that although the trajectories are sensitive to initial conditions, the
same painting is created every time? Setting aside the creative aspect of
painting a picture, in this work, we develop a novel algorithm to reproduce
paintings and photographs. Combining ideas from ergodic theory and control
theory, we construct a chaotic dynamical system with predetermined statistical
properties. If one makes the spatial distribution of colors in the picture the
target distribution, akin to a human, the algorithm first captures large scale
features and then goes on to refine small scale features. Beyond reproducing
paintings, this approach is expected to have a wide variety of applications
such as uncertainty quantification, sampling for efficient inference in
scalable machine learning for big data, and developing effective strategies for
search and rescue. In particular, our preliminary studies demonstrate that this
algorithm provides significant acceleration and higher accuracy than competing
methods for Markov Chain Monte Carlo (MCMC).
</dc:description>
 <dc:description>Comment: Four movies have been uploaded in the ancillary folder. They display
  the evolution of the dynamical system based reconstruction of paintings and
  pictures</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02017</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Software Development Industry In East Africa: Knowledge Management
  Perspective And Value Proposition</dc:title>
 <dc:creator>Mwangi, Karanja Evanson</dc:creator>
 <dc:creator>Thuku, Lawrence Xavier</dc:creator>
 <dc:creator>Kangethe, John Patrick</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Increased usage of the internet has contributed immensely to the growth of
software development practice in East Africa. This paper investigates the
existence of formal KM (Knowledge Management) initiatives in the Software
industry such as creation of virtual communities (Communities of practice and
communities of interest); expert localization and establishment of knowledge
taxonomies in these communities; the knowledge transfer and sharing processes;
incubation and Mentorship; collaborative software development and their role in
creating entrepreneurship initiatives and providing a building block towards
the knowledge economies. We propose a hybrid framework for use in KM initiative
focusing on Software Development in East Africa.
</dc:description>
 <dc:description>Comment: 16 pages and five figures,Africa Casebook - Synergies in African
  Business and Management Practices,ISBN 978-9966-1570-0-3. from 1st African
  International Business and Management Conference (AIBUMA) on Knowledge and
  Innovation Leadership for Competitiveness Nairobi, Kenya 25-27th August 2010</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02018</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Data Mining Approach to Predict Prospective Business Sectors for
  Lending in Retail Banking Using Decision Tree</dc:title>
 <dc:creator>Islam, Md. Rafiqul</dc:creator>
 <dc:creator>Habib, Md. Ahsan</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  A potential objective of every financial organization is to retain existing
customers and attain new prospective customers for long-term. The economic
behaviour of customer and the nature of the organization are controlled by a
prescribed form called Know Your Customer (KYC) in manual banking. Depositor
customers in some sectors (business of Jewellery/Gold, Arms, Money exchanger
etc) are with high risk; whereas in some sectors (Transport Operators,
Auto-delear, religious) are with medium risk; and in remaining sectors (Retail,
Corporate, Service, Farmer etc) belongs to low risk. Presently, credit risk for
counterparty can be broadly categorized under quantitative and qualitative
factors. Although there are many existing systems on customer retention as well
as customer attrition systems in bank, these rigorous methods suffers clear and
defined approach to disburse loan in business sector. In the paper, we have
used records of business customers of a retail commercial bank in the city
including rural and urban area of (Tangail city) Bangladesh to analyse the
major transactional determinants of customers and predicting of a model for
prospective sectors in retail bank. To achieve this, data mining approach is
adopted for analysing the challenging issues, where pruned decision tree
classification technique has been used to develop the model and finally tested
its performance with Weka result. Moreover, this paper attempts to build up a
model to predict prospective business sectors in retail banking.
</dc:description>
 <dc:description>Comment: This paper contains 10 pages, 7 figures, 1 table and 1 algorithm. See
  more from here, http://airccse.org/journal/ijdkp/papers/5215ijdkp02.pdf and
  journal information see here http://airccse.org/journal/ijdkp/ijdkp.html
  http://www.airccse.org http://www.airccj.org</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02018</dc:identifier>
 <dc:identifier>International Journal of Data Mining &amp; Knowledge Management
  Process (IJDKP), vol. 5(2), pp. 13-22, 2015</dc:identifier>
 <dc:identifier>doi:10.5121/ijdkp.2015.5202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02026</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Efficient Service Delivery: The Role Of Workflow Systems In
  Public Sector In Kenya</dc:title>
 <dc:creator>Thuku, Lawrence Xavier Waweru</dc:creator>
 <dc:creator>Mwangi, Karanja Evanson</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Current challenges in Electronic Government initiatives include performance
management, effective and efficient means of sharing information between
different stakeholders e.g. government departments in order to improve the
quality of service delivery to the citizens. To address these challenges, this
paper addresses an application domain of workflow systems in public
institutions and proposes a framework that can be effectively used in
implementing workflow systems in public institutions
</dc:description>
 <dc:description>Comment: Strathmore University ICT conference 19 pages, the 11th Strathmore
  University ICT Conference , 3rd -4th September 2010, Strathmore University
  Nairobi</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02027</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Neutrosophic Entropy and its Five Components</dc:title>
 <dc:creator>Patrascu, Vasile</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper presents two variants of penta-valued representation for
neutrosophic entropy. The first is an extension of Kaufmann's formula and the
second is an extension of Kosko's formula.
  Based on the primary three-valued information represented by the degree of
truth, degree of falsity and degree of neutrality there are built some
penta-valued representations that better highlights some specific features of
neutrosophic entropy. Thus, we highlight five features of neutrosophic
uncertainty such as ambiguity, ignorance, contradiction, neutrality and
saturation. These five features are supplemented until a seven partition of
unity by adding two features of neutrosophic certainty such as truth and
falsity.
  The paper also presents the particular forms of neutrosophic entropy obtained
in the case of bifuzzy representations, intuitionistic fuzzy representations,
paraconsistent fuzzy representations and finally the case of fuzzy
representations.
</dc:description>
 <dc:date>2015-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02027</dc:identifier>
 <dc:identifier>Neutrosophic Sets and Systems, Vol.7, 2015,pp. 40-46</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02035</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Set Membership with a Few Bit Probes</dc:title>
 <dc:creator>Garg, Mohit</dc:creator>
 <dc:creator>Radhakrishnan, Jaikumar</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68P05, 68P20, 68P30</dc:subject>
 <dc:description>  We consider the bit-probe complexity of the set membership problem, where a
set S of size at most n from a universe of size m is to be represented as a
short bit vector in order to answer membership queries of the form &quot;Is x in S?&quot;
by adaptively probing the bit vector at t places. Let s(m,n,t) be the minimum
number of bits of storage needed for such a scheme. Several recent works
investigate s(m,n,t) for various ranges of the parameter; we obtain
improvements over some of the bounds shown by Buhrman, Miltersen,
Radhakrishnan, and Srinivasan (2002) and Alon and Feige (2009).
</dc:description>
 <dc:description>Comment: 19 pages, expanded version of 'Set membership with a few bit probes.
  SODA 2015: 776-784' (with additional results)</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02044</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Algorithmic Proof of the Lovasz Local Lemma via Resampling Oracles</dc:title>
 <dc:creator>Harvey, Nicholas</dc:creator>
 <dc:creator>Vondrak, Jan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  The Lovasz Local Lemma is a seminal result in probabilistic combinatorics. It
gives a sufficient condition on a probability space and a collection of events
for the existence of an outcome that simultaneously avoids all of those events.
Finding such an outcome by an efficient algorithm has been an active research
topic for decades. Breakthrough work of Moser and Tardos (2009) presented an
efficient algorithm for a general setting primarily characterized by a product
structure on the probability space.
  In this work we present an efficient algorithm for a much more general
setting. Our main assumption is that there exist certain functions, called
resampling oracles, that can be invoked to address the undesired occurrence of
the events. We show that, in all scenarios to which the original Lovasz Local
Lemma applies, there exist resampling oracles, although they are not
necessarily efficient. Nevertheless, for essentially all known applications of
the Lovasz Local Lemma and its generalizations, we have designed efficient
resampling oracles. As applications of these techniques, we present new results
for packings of Latin transversals, rainbow matchings and rainbow spanning
trees.
</dc:description>
 <dc:description>Comment: 47 pages</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02052</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exchange of Services in Networks: Competition, Cooperation, and Fairness</dc:title>
 <dc:creator>Georgiadis, Leonidas</dc:creator>
 <dc:creator>Iosifidis, George</dc:creator>
 <dc:creator>Tassiulas, Leandros</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Exchange of services and resources in, or over, networks is attracting
nowadays renewed interest. However, despite the broad applicability and the
extensive study of such models, e.g., in the context of P2P networks, many
fundamental questions regarding their properties and efficiency remain
unanswered. We consider such a service exchange model and analyze the users'
interactions under three different approaches. First, we study a centrally
designed service allocation policy that yields the fair total service each user
should receive based on the service it others to the others. Accordingly, we
consider a competitive market where each user determines selfishly its
allocation policy so as to maximize the service it receives in return, and a
coalitional game model where users are allowed to coordinate their policies. We
prove that there is a unique equilibrium exchange allocation for both game
theoretic formulations, which also coincides with the central fair service
allocation. Furthermore, we characterize its properties in terms of the
coalitions that emerge and the equilibrium allocations, and analyze its
dependency on the underlying network graph. That servicing policy is the
natural reference point to the various mechanisms that are currently proposed
to incentivize user participation and improve the efficiency of such networked
service (or, resource) exchange markets.
</dc:description>
 <dc:description>Comment: to appear in ACM Sigmetrics 2015</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02059</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supporting Language Learners with the Meanings Of Closed Class Items</dc:title>
 <dc:creator>Alrefaie, Hayat</dc:creator>
 <dc:creator>Ramsay, Allan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The process of language learning involves the mastery of countless tasks:
making the constituent sounds of the language being learned, learning the
grammatical patterns, and acquiring the requisite vocabulary for reception and
production. While a plethora of computational tools exist to facilitate the
first and second of these tasks, a number of challenges arise with respect to
enabling the third. This paper describes a tool that has been designed to
support language learners with the challenge of understanding the use of
closed-class lexical items. The process of learning the Arabic for office is
(mktb) is relatively simple and should be possible by means of simple
repetition of the word. However, it is much more difficult to learn and
correctly use the Arabic equivalent of the word on. The current paper describes
a mechanism for the delivery of diagnostic information regarding specific
lexical examples, with the aim of clearly demonstrating why a particular
translation of a given closed-class item may be appropriate in certain
situations but not others, thereby helping learners to understand and use the
term correctly.
</dc:description>
 <dc:description>Comment: 12 pages include references, 5 figures and AIAPP 2015 conference in
  Geneva</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02063</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressing Sparse Sequences under Local Decodability Constraints</dc:title>
 <dc:creator>Pananjady, Ashwin</dc:creator>
 <dc:creator>Courtade, Thomas A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider a variable-length source coding problem subject to local
decodability constraints. In particular, we investigate the blocklength scaling
behavior attainable by encodings of $r$-sparse binary sequences, under the
constraint that any source bit can be correctly decoded upon probing at most
$d$ codeword bits. We consider both adaptive and non-adaptive access models,
and derive upper and lower bounds that often coincide up to constant factors.
Notably, such a characterization for the fixed-blocklength analog of our
problem remains unknown, despite considerable research over the last three
decades. Connections to communication complexity are also briefly discussed.
</dc:description>
 <dc:description>Comment: 8 pages, 1 figure. First five pages to appear in 2015 International
  Symposium on Information Theory. This version contains supplementary material</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02072</identifier>
 <datestamp>2015-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intractability of Optimal Multi-Robot Path Planning on Planar Graphs</dc:title>
 <dc:creator>Yu, Jingjin</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We study the computational complexity of optimally solving multi-robot path
planning problems on planar graphs. For four common time- and distance-based
objectives, we show that the associated path optimization problems for multiple
robots are all NP-complete, even when the underlying graph is planar.
Establishing the computational intractability of optimal multi-robot path
planning problems on planar graphs has important practical implications. In
particular, our result suggests the preferred approach toward solving such
problems, when the number of robots is large, is to augment the planar
environment to reduce the sharing of paths among robots traveling in opposite
directions on those paths. Indeed, such efficiency boosting structures, such as
highways and elevated intersections, are ubiquitous in robotics and
transportation applications.
</dc:description>
 <dc:description>Comment: Updated draft</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:date>2015-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02081</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Block Diagonalization for Massive Multiuser MIMO Systems</dc:title>
 <dc:creator>Ni, Weiheng</dc:creator>
 <dc:creator>Dong, Xiaodai</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  For a massive multiple-input multiple-output (MIMO) system, restricting the
number of RF chains to far less than the number of antenna elements can
significantly reduce the implementation cost compared to the full complexity RF
chain configuration. In this paper, we consider the downlink communication of a
massive multiuser MIMO (MU-MIMO) system and propose a low-complexity hybrid
block diagonalization (Hy-BD) scheme to approach the capacity performance of
the traditional BD processing method. We aim to harvest the large array gain
through the phase-only RF precoding and combining and then digital BD
processing is performed on the equivalent baseband channel. The proposed Hy-BD
scheme is examined in both the large Rayleigh fading channels and millimeter
wave (mmWave) channels. A performance analysis is further conducted for
single-path channels and large number of transmit and receive antennas.
Finally, simulation results demonstrate that our Hy-BD scheme, with a lower
implementation and computational complexity, achieves a capacity performance
that is close to (sometimes even higher than) that of the traditional
high-dimensional BD processing.
</dc:description>
 <dc:description>Comment: 11 pages, 12 figures, double column, journal</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02089</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Computational Power of Optimization in Online Learning</dc:title>
 <dc:creator>Hazan, Elad</dc:creator>
 <dc:creator>Koren, Tomer</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider the fundamental problem of prediction with expert advice where
the experts are &quot;optimizable&quot;: there is a black-box optimization oracle that
can be used to compute, in constant time, the leading expert in retrospect at
any point in time. In this setting, we give a novel online algorithm that
attains vanishing regret with respect to $N$ experts in total
$\widetilde{O}(\sqrt{N})$ computation time. We also give a lower bound showing
that this running time cannot be improved (up to log factors) in the oracle
model, thereby exhibiting a quadratic speedup as compared to the standard,
oracle-free setting where the required time for vanishing regret is
$\widetilde{\Theta}(N)$. These results demonstrate an exponential gap between
the power of optimization in online learning and its power in statistical
learning: in the latter, an optimization oracle---i.e., an efficient empirical
risk minimizer---allows to learn a finite hypothesis class of size $N$ in time
$O(\log{N})$. We also study the implications of our results to learning in
repeated zero-sum games, in a setting where the players have access to oracles
that compute, in constant time, their best-response to any mixed strategy of
their opponent. We show that the runtime required for approximating the minimax
value of the game in this setting is $\widetilde{\Theta}(\sqrt{N})$, yielding
again a quadratic improvement upon the oracle-free setting, where
$\widetilde{\Theta}(N)$ is known to be tight.
</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02092</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revolutionary Hybrid E-Books for Enhanced Higher Learning</dc:title>
 <dc:creator>Balaji, R. D.</dc:creator>
 <dc:creator>Lakshminarayan, Ramkumar</dc:creator>
 <dc:creator>Balaji, Er. Malathi</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Books are the best friends of human beings and make them a rational animal.
In this E-world our traditional books are losing their values. Recent surveys
are proving that the younger generations are not much interested in visiting
libraries and reading books due to their addiction towards the electronic
gadgets. Many publishers are now changed their strategy by publishing and
promoting ebooks. Academicians are also badly affected by this trend and they
are forced to motivate the students to improve their reading habits for their
better performance in the institutions and to be responsible citizens of a
country.
  There are many difficulties faced by the ebook readers and it discourages the
people to read an ebook for long time like a normal printed book. The main
objective of this paper is to introduce a hybrid Ebook which is capable of
having audio and video files also in it. This makes the people to read the
e-book with modern electronic formats. This multimedia facility makes the
people to read or listen or watch the ebooks for long time. We have quoted the
survey results which prove that the students prefer to read hybrid books than
normal ebooks or the printed handouts in College of Applied Sciences, Oman.
Still we feel these books should have few more facilities, so that people who
like traditional books will also adopt these ebooks, without losing the
satisfaction of reading printed books. These things are listed in the
recommendations and conclusion section.
</dc:description>
 <dc:description>Comment: 8 pages, ICOET 2015, Oman. arXiv admin note: substantial text overlap
  with arXiv:1504.01855</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02093</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing the Understanding of Computer Networking Courses through
  Software Tools</dc:title>
 <dc:creator>Dafalla, Z. I.</dc:creator>
 <dc:creator>Balaji, R. D.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Computer networking is an important specialization in Information and
Communication Technologies. However imparting the right knowledge to students
can be a challenging task due to the fact that there is not enough time to
deliver lengthy labs during normal lecture hours. Augmenting the use of
physical machines with software tools help the students to learn beyond the
limited lab sessions within the environment of higher Institutions of learning
throughout the world. The Institutions focus mostly on effective use of
available resources i.e. a lab may have few lab sessions scheduled within a day
for different courses. Hence a particular lab session must begin and end on
time. A slow student who did not complete his/her lab exercise must vacate the
lab because another class is about to commence. Hence using free software tools
such as OPNET IT guru, Packet trace and NS2 will help the student to learn
beyond the College time. A Student will gain an insight into Computer
networking field by repeatedly doing the same labs at the comfort of his laptop
or PC at home, hence increasing deeper understanding into the subject. The main
objective of this paper is to explore the software tools which will enhance the
networks practical skills among higher education students at College of Applied
Sciences Salalah. The paper also discusses the methodologies of implementing
and executing lab sessions after the normal college hours. The limitations and
suggestions for the improvements are also specified at the end of this paper.
</dc:description>
 <dc:description>Comment: 4 pages, ICOET 2015, Oman. arXiv admin note: substantial text overlap
  with arXiv:1504.01855</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02115</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Review of Man-in-the-Middle Attacks</dc:title>
 <dc:creator>Gangan, Subodh</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This paper presents a survey of man-in-the-middle (MIM) attacks in
communication networks and methods of protection against them. In real time
communication, the attack can in many situations be discovered by the use of
timing information. The most common attacks occur due to Address Resolution
Protocol (ARP) cache poisoning, DNS spoofing, session hijacking, and SSL
hijacking.
</dc:description>
 <dc:description>Comment: 12 pages, 10 figures</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02125</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Residential Demand Response Applications Using Batch Reinforcement
  Learning</dc:title>
 <dc:creator>Ruelens, Frederik</dc:creator>
 <dc:creator>Claessens, Bert</dc:creator>
 <dc:creator>Vandael, Stijn</dc:creator>
 <dc:creator>De Schutter, Bart</dc:creator>
 <dc:creator>Babuska, Robert</dc:creator>
 <dc:creator>Belmans, Ronnie</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Driven by recent advances in batch Reinforcement Learning (RL), this paper
contributes to the application of batch RL to demand response. In contrast to
conventional model-based approaches, batch RL techniques do not require a
system identification step, which makes them more suitable for a large-scale
implementation. This paper extends fitted Q-iteration, a standard batch RL
technique, to the situation where a forecast of the exogenous data is provided.
In general, batch RL techniques do not rely on expert knowledge on the system
dynamics or the solution. However, if some expert knowledge is provided, it can
be incorporated by using our novel policy adjustment method. Finally, we tackle
the challenge of finding an open-loop schedule required to participate in the
day-ahead market. We propose a model-free Monte-Carlo estimator method that
uses a metric to construct artificial trajectories and we illustrate this
method by finding the day-ahead schedule of a heat-pump thermostat. Our
experiments show that batch RL techniques provide a valuable alternative to
model-based controllers and that they can be used to construct both closed-loop
and open-loop policies.
</dc:description>
 <dc:description>Comment: Submitted to Trans. on Smart Grid</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02128</identifier>
 <datestamp>2016-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communication channel prioritization in a publish-subscribe architecture</dc:title>
 <dc:creator>Paikan, Ali</dc:creator>
 <dc:creator>Domenichelli, Daniele</dc:creator>
 <dc:creator>Natale, Lorenzo</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Real-Time communication are important in all those distributed applications
where timing constraints on data proccessing and task executation play a
fundamental role. Standards-base software engineering does not yet specify how
real-time properties should be integrated into a publish/subscribe middleware.
This article describes an approach for integration of priority quality of
service in a publish/subscribe middleware. The approach simply leverages the
operating system functionalities to provide a framework where specific
communication channels can be prioritized at run-time. The quality of service
is implemented in YARP (Yet Another Robot Platform) framework and the primarily
results of performance tests are presented.
</dc:description>
 <dc:description>Comment: In 8th Workshop on Software Engineering and Architectures for
  Realtime Interactive Systems (SEARIS)</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:date>2016-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02134</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hand Posture's Effect on Touch Screen Text Input Behaviors: A Touch Area
  Based Study</dc:title>
 <dc:creator>Thomas, Christopher</dc:creator>
 <dc:creator>Jennings, Brandon</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Mobile devices with touch keyboards have become ubiquitous, but text entry on
these devices remains slow and errorprone. Understanding touch patterns during
text entry could be useful in designing robust error-correction algorithms for
soft keyboards. In this paper, we present an analysis of text input behaviors
on a soft QWERTY keyboard in three different text entry postures: index finger
only, one thumb, and two thumb. Our work expands on the work of [1] by
considering the entire surface area of digit contact with the smartphone
keyboard, rather than interpreting each touch as a single point. To do this, we
captured touch areas for every key in a lab study with 8 participants and
calculated offsets, error rates, and size measurements. We then repeated the
original experiment described in [1] and showed that significant differences
exist when basing offset calculations on touch area compared to touch points
for two postures.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02141</identifier>
 <datestamp>2017-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Falls with X-Factor Hidden Markov Models</dc:title>
 <dc:creator>Khan, Shehroz S.</dc:creator>
 <dc:creator>Karg, Michelle E.</dc:creator>
 <dc:creator>Kulic, Dana</dc:creator>
 <dc:creator>Hoey, Jesse</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Identification of falls while performing normal activities of daily living
(ADL) is important to ensure personal safety and well-being. However, falling
is a short term activity that occurs infrequently. This poses a challenge to
traditional classification algorithms, because there may be very little
training data for falls (or none at all). This paper proposes an approach for
the identification of falls using a wearable device in the absence of training
data for falls but with plentiful data for normal ADL. We propose three
`X-Factor' Hidden Markov Model (XHMMs) approaches. The XHMMs model unseen falls
using &quot;inflated&quot; output covariances (observation models). To estimate the
inflated covariances, we propose a novel cross validation method to remove
&quot;outliers&quot; from the normal ADL that serve as proxies for the unseen falls and
allow learning the XHMMs using only normal activities. We tested the proposed
XHMM approaches on two activity recognition datasets and show high detection
rates for falls in the absence of fall-specific training data. We show that the
traditional method of choosing a threshold based on maximum of negative of
log-likelihood to identify unseen falls is ill-posed for this problem. We also
show that supervised classification methods perform poorly when very limited
fall data are available during the training phase.
</dc:description>
 <dc:description>Comment: 27 pages, 4 figures, 3 tables, Applied Soft Computing, 2017</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:date>2017-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02141</dc:identifier>
 <dc:identifier>doi:10.1016/j.asoc.2017.01.034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02146</identifier>
 <datestamp>2015-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discrete Stochastic Submodular Maximization: Adaptive vs. Non-Adaptive
  vs. Offline</dc:title>
 <dc:creator>Hellerstein, Lisa</dc:creator>
 <dc:creator>Kletenik, Devorah</dc:creator>
 <dc:creator>Lin, Patrick</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We consider the problem of stochastic monotone submodular function
maximization, subject to constraints. We give results on adaptivity gaps, and
on the gap between the optimal offline and online solutions. We present a
procedure that transforms a decision tree (adaptive algorithm) into a
non-adaptive chain. We prove that this chain achieves at least ${\tau}$ times
the utility of the decision tree, over a product distribution and binary state
space, where ${\tau} = \min_{i,j} \Pr[x_i=j]$. This proves an adaptivity gap of
$1/{\tau}$ (which is $2$ in the case of a uniform distribution) for the problem
of stochastic monotone submodular maximization subject to state-independent
constraints. For a cardinality constraint, we prove that a simple adaptive
greedy algorithm achieves an approximation factor of $(1-1/e^{\tau})$ with
respect to the optimal offline solution; previously, it has been proven that
the algorithm achieves an approximation factor of $(1-1/e)$ with respect to the
optimal adaptive online solution. Finally, we show that there exists a
non-adaptive solution for the stochastic max coverage problem that is within a
factor $(1-1/e)$ of the optimal adaptive solution and within a factor of
${\tau}(1-1/e)$ of the optimal offline solution.
</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:date>2015-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02147</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unwrapping ADMM: Efficient Distributed Computing via Transpose Reduction</dc:title>
 <dc:creator>Goldstein, Tom</dc:creator>
 <dc:creator>Taylor, Gavin</dc:creator>
 <dc:creator>Barabin, Kawika</dc:creator>
 <dc:creator>Sayre, Kent</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recent approaches to distributed model fitting rely heavily on consensus
ADMM, where each node solves small sub-problems using only local data. We
propose iterative methods that solve {\em global} sub-problems over an entire
distributed dataset. This is possible using transpose reduction strategies that
allow a single node to solve least-squares over massive datasets without
putting all the data in one place. This results in simple iterative methods
that avoid the expensive inner loops required for consensus methods. To
demonstrate the efficiency of this approach, we fit linear classifiers and
sparse linear models to datasets over 5 Tb in size using a distributed
implementation with over 7000 cores in far less time than previous approaches.
</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02148</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mining and discovering biographical information in Difangzhi with a
  language-model-based approach</dc:title>
 <dc:creator>Bol, Peter K.</dc:creator>
 <dc:creator>Liu, Chao-Lin</dc:creator>
 <dc:creator>Wang, Hongsu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We present results of expanding the contents of the China Biographical
Database by text mining historical local gazetteers, difangzhi. The goal of the
database is to see how people are connected together, through kinship, social
connections, and the places and offices in which they served. The gazetteers
are the single most important collection of names and offices covering the Song
through Qing periods. Although we begin with local officials we shall
eventually include lists of local examination candidates, people from the
locality who served in government, and notable local figures with biographies.
The more data we collect the more connections emerge. The value of doing
systematic text mining work is that we can identify relevant connections that
are either directly informative or can become useful without deep historical
research. Academia Sinica is developing a name database for officials in the
central governments of the Ming and Qing dynasties.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, 1 table, 2015 International Conference on Digital
  Humanities. in Proceedings of the 2015 International Conference on Digital
  Humanities (DH 2015). July 2015</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02150</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Lexical, Syntactic, and Semantic Features for Chinese Textual
  Entailment in NTCIR RITE Evaluation Tasks</dc:title>
 <dc:creator>Huang, Wei-Jie</dc:creator>
 <dc:creator>Liu, Chao-Lin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We computed linguistic information at the lexical, syntactic, and semantic
levels for Recognizing Inference in Text (RITE) tasks for both traditional and
simplified Chinese in NTCIR-9 and NTCIR-10. Techniques for syntactic parsing,
named-entity recognition, and near synonym recognition were employed, and
features like counts of common words, statement lengths, negation words, and
antonyms were considered to judge the entailment relationships of two
statements, while we explored both heuristics-based functions and
machine-learning approaches. The reported systems showed robustness by
simultaneously achieving second positions in the binary-classification subtasks
for both simplified and traditional Chinese in NTCIR-10 RITE-2. We conducted
more experiments with the test data of NTCIR-9 RITE, with good results. We also
extended our work to search for better configurations of our classifiers and
investigated contributions of individual features. This extended work showed
interesting results and should encourage further discussion.
</dc:description>
 <dc:description>Comment: 20 pages, 1 figure, 26 tables, Journal article in Soft Computing
  (Spinger). Soft Computing, online. Springer, Germany, 2015</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02150</dc:identifier>
 <dc:identifier>doi:10.1007/s00500-015-1629-1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02151</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Linear Time Algorithm for the $3$-neighbour Traveling Salesman Problem
  on Halin graphs and extensions</dc:title>
 <dc:creator>Woods, Brad</dc:creator>
 <dc:creator>Punnen, Abraham</dc:creator>
 <dc:creator>Stephen, Tamon</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The Quadratic Travelling Salesman Problem (QTSP) is to find a least cost
Hamilton cycle in an edge-weighted graph, where costs are defined on all pairs
of edges contained in the Hamilton cycle. This is a more general version than
the commonly studied QTSP which only considers pairs of adjacent edges. We
define a restricted version of QTSP, the $k$-neighbour TSP (TSP($k$)), and give
a linear time algorithm to solve TSP($k$) on a Halin graph for $k\leq 3$. This
algorithm can be extended to solve TSP($k$) on any fully reducible class of
graphs for any fixed $k$ in polynomial time. This result generalizes
corresponding results for the standard TSP. TSP($k$) can be used to model
various machine scheduling problems as well as an optimal routing problem for
unmanned aerial vehicles (UAVs).
</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:date>2017-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02162</identifier>
 <datestamp>2015-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Concentric network symmetry grasps authors' styles in word adjacency
  networks</dc:title>
 <dc:creator>Amancio, Diego R.</dc:creator>
 <dc:creator>Silva, Filipi N.</dc:creator>
 <dc:creator>Costa, Luciano da F.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Several characteristics of written texts have been inferred from statistical
analysis derived from networked models. Even though many network measurements
have been adapted to study textual properties at several levels of complexity,
some textual aspects have been disregarded. In this paper, we study the
symmetry of word adjacency networks, a well-known representation of text as a
graph. A statistical analysis of the symmetry distribution performed in several
novels showed that most of the words do not display symmetric patterns of
connectivity. More specifically, the merged symmetry displayed a distribution
similar to the ubiquitous power-law distribution. Our experiments also revealed
that the studied metrics do not correlate with other traditional network
measurements, such as the degree or betweenness centrality. The effectiveness
of the symmetry measurements was verified in the authorship attribution task.
Interestingly, we found that specific authors prefer particular types of
symmetric motifs. As a consequence, the authorship of books could be accurately
identified in 82.5% of the cases, in a dataset comprising books written by 8
authors. Because the proposed measurements for text analysis are complementary
to the traditional approach, they can be used to improve the characterization
of text networks, which might be useful for related applications, such as those
relying on the identification of topical words and information retrieval.
</dc:description>
 <dc:description>Comment: Accepted for publication in Europhys. Lett. (EPL). The supplementary
  information is available from
  https://dl.dropboxusercontent.com/u/2740286/symmetry.pdf</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:date>2015-06-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02162</dc:identifier>
 <dc:identifier>Europhys. Lett. 110 68001 (2015)</dc:identifier>
 <dc:identifier>doi:10.1209/0295-5075/110/68001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02164</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linearly Supporting Feature Extraction For Automated Estimation Of
  Stellar Atmospheric Parameters</dc:title>
 <dc:creator>Li, Xiangru</dc:creator>
 <dc:creator>Lu, Yu</dc:creator>
 <dc:creator>Comte, Georges</dc:creator>
 <dc:creator>Luo, Ali</dc:creator>
 <dc:creator>Zhao, Yongheng</dc:creator>
 <dc:creator>Wang, Yongjun</dc:creator>
 <dc:subject>Astrophysics - Solar and Stellar Astrophysics</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We describe a scheme to extract linearly supporting (LSU) features from
stellar spectra to automatically estimate the atmospheric parameters $T_{eff}$,
log$~g$, and [Fe/H]. &quot;Linearly supporting&quot; means that the atmospheric
parameters can be accurately estimated from the extracted features through a
linear model. The successive steps of the process are as follow: first,
decompose the spectrum using a wavelet packet (WP) and represent it by the
derived decomposition coefficients; second, detect representative spectral
features from the decomposition coefficients using the proposed method Least
Absolute Shrinkage and Selection Operator (LARS)$_{bs}$; third, estimate the
atmospheric parameters $T_{eff}$, log$~g$, and [Fe/H] from the detected
features using a linear regression method. One prominent characteristic of this
scheme is its ability to evaluate quantitatively the contribution of each
detected feature to the atmospheric parameter estimate and also to trace back
the physical significance of that feature. This work also shows that the
usefulness of a component depends on both wavelength and frequency. The
proposed scheme has been evaluated on both real spectra from the Sloan Digital
Sky Survey (SDSS)/SEGUE and synthetic spectra calculated from Kurucz's NEWODF
models. On real spectra, we extracted 23 features to estimate $T_{eff}$, 62
features for log$~g$, and 68 features for [Fe/H]. Test consistencies between
our estimates and those provided by the Spectroscopic Sarameter Pipeline of
SDSS show that the mean absolute errors (MAEs) are 0.0062 dex for log$~T_{eff}$
(83 K for $T_{eff}$), 0.2345 dex for log$~g$, and 0.1564 dex for [Fe/H]. For
the synthetic spectra, the MAE test accuracies are 0.0022 dex for log$~T_{eff}$
(32 K for $T_{eff}$), 0.0337 dex for log$~g$, and 0.0268 dex for [Fe/H].
</dc:description>
 <dc:description>Comment: 21 pages, 7 figures, 8 tables, The Astrophysical Journal Supplement
  Series (accepted for publication)</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02168</identifier>
 <datestamp>2017-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Index Coding Scheme Exploiting Interlinked Cycles</dc:title>
 <dc:creator>Thapa, Chandra</dc:creator>
 <dc:creator>Ong, Lawrence</dc:creator>
 <dc:creator>Johnson, Sarah J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the index coding problem in the unicast message setting, i.e., where
each message is requested by one unique receiver. This problem can be modeled
by a directed graph. We propose a new scheme called interlinked cycle cover,
which exploits interlinked cycles in the directed graph, for designing index
codes. This new scheme generalizes the existing clique cover and cycle cover
schemes. We prove that for a class of infinitely many digraphs with messages of
any length, interlinked cycle cover provides an optimal index code.
Furthermore, the index code is linear with linear time encoding complexity.
</dc:description>
 <dc:description>Comment: To be presented at the 2015 IEEE International Symposium on
  Information Theory (ISIT 2015), Hong Kong</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02168</dc:identifier>
 <dc:identifier>doi:10.1109/ISIT.2015.7282610</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02174</identifier>
 <datestamp>2015-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Connectivity Preserving Multivalued Functions in Digital Topology</dc:title>
 <dc:creator>Boxer, Laurence</dc:creator>
 <dc:creator>Staecker, P. Christopher</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - General Topology</dc:subject>
 <dc:subject>I.4.m</dc:subject>
 <dc:description>  We study connectivity preserving multivalued functions between digital
images. This notion generalizes that of continuous multivalued functions
studied mostly in the setting of the digital plane $Z^2$. We show that
connectivity preserving multivalued functions, like continuous multivalued
functions, are appropriate models for digital morpholological operations.
Connectivity preservation, unlike continuity, is preserved by compositions, and
generalizes easily to higher dimensions and arbitrary adjacency relations.
</dc:description>
 <dc:description>Comment: small changes</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:date>2015-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02202</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fackbook Implementation in Developing English Writing for Thai Students</dc:title>
 <dc:creator>Endoo, Pisutpong</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The objectives of this research were to study FB implementation and attitudes
in developing English writing skills of Thai students studying in the first
year students program in EIC academic year 1/2014 at RMUTI, Surin Campus. The
Purposive sampling was designed for data collecting. The instruments for this
research were questionnaires and in-depth questions. The data analysis was
analyzed by the Descriptive statistics to find out the value of the frequency
and percentage.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02205</identifier>
 <datestamp>2015-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BigDataBench-MT: A Benchmark Tool for Generating Realistic Mixed Data
  Center Workloads</dc:title>
 <dc:creator>Han, Rui</dc:creator>
 <dc:creator>Zhan, Shulin</dc:creator>
 <dc:creator>Shao, Chenrong</dc:creator>
 <dc:creator>Wang, Junwei</dc:creator>
 <dc:creator>John, Lizy K.</dc:creator>
 <dc:creator>Xu, Jiangtao</dc:creator>
 <dc:creator>Lu, Gang</dc:creator>
 <dc:creator>Wang, Lei</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Long-running service workloads (e.g. web search engine) and short-term data
analysis workloads (e.g. Hadoop MapReduce jobs) co-locate in today's data
centers. Developing realistic benchmarks to reflect such practical scenario of
mixed workload is a key problem to produce trustworthy results when evaluating
and comparing data center systems. This requires using actual workloads as well
as guaranteeing their submissions to follow patterns hidden in real-world
traces. However, existing benchmarks either generate actual workloads based on
probability models, or replay real-world workload traces using basic I/O
operations. To fill this gap, we propose a benchmark tool that is a first step
towards generating a mix of actual service and data analysis workloads on the
basis of real workload traces. Our tool includes a combiner that enables the
replaying of actual workloads according to the workload traces, and a
multi-tenant generator that flexibly scales the workloads up and down according
to users' requirements. Based on this, our demo illustrates the workload
customization and generation process using a visual interface. The proposed
tool, called BigDataBench-MT, is a multi-tenant version of our comprehensive
benchmark suite BigDataBench and it is publicly available from
http://prof.ict.ac.cn/BigDataBench/multi-tenancyversion/.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2015-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02206</identifier>
 <datestamp>2016-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multiphase Image Segmentation Based on Fuzzy Membership Functions and
  L1-norm Fidelity</dc:title>
 <dc:creator>Li, Fang</dc:creator>
 <dc:creator>Osher, Stanley</dc:creator>
 <dc:creator>Qin, Jing</dc:creator>
 <dc:creator>Yan, Ming</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a variational multiphase image segmentation model
based on fuzzy membership functions and L1-norm fidelity. Then we apply the
alternating direction method of multipliers to solve an equivalent problem. All
the subproblems can be solved efficiently. Specifically, we propose a fast
method to calculate the fuzzy median. Experimental results and comparisons show
that the L1-norm based method is more robust to outliers such as impulse noise
and keeps better contrast than its L2-norm counterpart. Theoretically, we prove
the existence of the minimizer and analyze the convergence of the algorithm.
</dc:description>
 <dc:description>Comment: 28 pages, 8 figures, 3 tables</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2016-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02206</dc:identifier>
 <dc:identifier>Journal of Scientific Computing, 69 (2016), 82-106</dc:identifier>
 <dc:identifier>doi:10.1007/s10915-016-0183-z</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02209</identifier>
 <datestamp>2015-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy Efficient Policy for Cloud Radio Access Network</dc:title>
 <dc:creator>Zhang, Di</dc:creator>
 <dc:creator>Zhou, Zhenyu</dc:creator>
 <dc:creator>Yu, Keping</dc:creator>
 <dc:creator>Sato, Takuro</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Energy Efficiency (EE) is a big issue in 5th Generation Wireless
Communications (5G) on condition that the number of access User Equipments
(UEs) are exploding and more antennas should be equipped in one Base Station
(BS). In EE studies, prior literatures focus on the energy consumption of
single separated BS coverage area or through scheduling mechanism or network
coding method. But some other elements are ignored in those literatures, such
as the energy consumption of machine room, circuit, etc. In this paper, to be
more closer to the reality, based on the Cloud Radio Access Network (C-RAN), we
modify its traditional structure for easier layout of sleeping mechanism in the
real world, study the EE issue within a comprehensive view while taking more
elements into consideration. We modified the traditional C-RAN structure with
the purpose of much easily adopting the sleeping mechanism with on-off
selection method. Afterwards, the EE issue is modeled into a mathematical
optimizing problem and its solution is given by a tractable method. The
analysis of sum capacity in one cluster of this modified structure is addressed
first. Then based on the analysis, the EE issue is studied with a comprehensive
view while taking more elements into consideration. In the next step, we
convert it into an optimization problem and give its solution with the sleeping
techniques. Comparing with prior works, this proposal is of better performance
for the merit of comprehensive vision and easier layout characteristic.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the author due to a crucial sign
  error</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2015-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02209</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02212</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards SE and EE in 5G with NOMA and Massive MIMO Technologies</dc:title>
 <dc:creator>Zhang, Di</dc:creator>
 <dc:creator>Zhou, Zhenyu</dc:creator>
 <dc:creator>Sato, Takuro</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Non-Orthogonal Multiple Access (NOMA) has been proposed to enhance the
Spectrum Efficiency (SE) and cell-edge capacity. This paper considers the
massive Multi-Input Multi-Output (MIMO) with Non-Orthogonal Multiple Access
(NOMA) encoding. The close-form expression of capacity of the massive MIMO with
NOMA is given here. Apart from the previous Successive Interference
Cancellation (SIC) method, the Power Hard Limiter (PHD) is introduced here for
better reality implement.
</dc:description>
 <dc:description>Comment: in IEICE General Conference, Mar. 13, 2015</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02214</identifier>
 <datestamp>2016-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A deterministic sparse FFT algorithm for vectors with small support</dc:title>
 <dc:creator>Plonka, Gerlind</dc:creator>
 <dc:creator>Wannenwetsch, Katrin</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>65T50, 42A38</dc:subject>
 <dc:description>  In this paper we consider the special case where a discrete signal ${\bf x}$
of length N is known to vanish outside a support interval of length $m &lt; N$. If
the support length $m$ of ${\bf x}$ or a good bound of it is a-priori known we
derive a sublinear deterministic algorithm to compute ${\bf x}$ from its
discrete Fourier transform. In case of exact Fourier measurements we require
only ${\cal O}(m \log m)$ arithmetical operations. For noisy measurements, we
propose a stable ${\cal O}(m \log N)$ algorithm.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02214</dc:identifier>
 <dc:identifier>Numerical Algorithms, 71(4) (2016), 889-905</dc:identifier>
 <dc:identifier>doi:10.1007/s11075-015-0028-0</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02218</identifier>
 <datestamp>2017-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating Cartogram Effectiveness</dc:title>
 <dc:creator>Nusrat, Sabrina</dc:creator>
 <dc:creator>Alam, Md. Jawaherul</dc:creator>
 <dc:creator>Kobourov, Stephen G.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Cartograms are maps in which areas of geographic regions (countries, states)
appear in proportion to some variable of interest (population, income).
Cartograms are popular visualizations for geo-referenced data that have been
used for over a century and that make it possible to gain insight into patterns
and trends in the world around us. Despite the popularity of cartograms and the
large number of cartogram types, there are few studies evaluating the
effectiveness of cartograms in conveying information. Based on a recent task
taxonomy for cartograms, we evaluate four major different types of cartograms:
contiguous, non-contiguous, rectangular, and Dorling cartograms. Specifically,
we evaluate the effectiveness of these cartograms by quantitative performance
analysis, as well as by subjective preferences. We analyze the results of our
study in the context of some prevailing assumptions in the literature of
cartography and cognitive science. Finally, we make recommendations for the use
of different types of cartograms for different tasks and settings.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2017-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02222</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully bordered words</dc:title>
 <dc:creator>Holub, &#x160;t&#x11b;p&#xe1;n</dc:creator>
 <dc:creator>M&#xfc;ller, Mike</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>68R15</dc:subject>
 <dc:description>  We characterize binary words that have exactly two unbordered conjugates and
show that they can be expressed as a product of two palindromes.
</dc:description>
 <dc:description>Comment: A significantly expanded version</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2016-06-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02222</dc:identifier>
 <dc:identifier>doi:10.1016/j.tcs.2016.10.020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02235</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extraction of Protein Sequence Motif Information using PSO K-Means</dc:title>
 <dc:creator>Gowri, R.</dc:creator>
 <dc:creator>Rathipriya, R.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The main objective of the paper is to find the motif information.The
functionalities of the proteins are ideally found from their motif information
which is extracted using various techniques like clustering with k-means,
hybrid k-means, self-organising maps, etc., in the literature. In this work
protein sequence information is extracted using optimised k-means algorithm.
The particle swarm optimisation technique is one of the frequently used
optimisation method. In the current work the PSO k-means is used for motif
information extraction. This paper also deals with the comparison between the
motif information obtained from clusters and biclustersusing PSO k-means
algorithm. The motif information acquired is based on the structure homogeneity
of the protein sequence.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02242</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Achievable Rates for the Fading Half-Duplex Single Relay Selection
  Network Using Buffer-Aided Relaying</dc:title>
 <dc:creator>Zlatanov, Nikola</dc:creator>
 <dc:creator>Jamali, Vahid</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In the half-duplex single relay selection network, comprised of a source, $M$
half-duplex relays, and a destination, only one relay is active at any given
time, i.e., only one relay receives or transmits, and the other relays are
inactive, i.e., they do not receive nor transmit. The capacity of this network,
when all links are affected by independent slow time-continuous fading and
additive white Gaussian noise (AWGN), is still unknown, and only achievable
average rates have been reported in the literature so far. In this paper, we
present new achievable average rates for this network which are larger than the
best known average rates. These new average rates are achieved with a
buffer-aided relaying protocol. Since the developed buffer-aided protocol
introduces unbounded delay, we also devise a buffer-aided protocol which limits
the delay at the expense of a decrease in rate. Moreover, we discuss the
practical implementation of the proposed buffer-aided relaying protocols and
show that they do not require more resources for channel state information
acquisition than the existing relay selection protocols.
</dc:description>
 <dc:description>Comment: Published in IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02242</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2015.2421912</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02247</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Projective simulation with generalization</dc:title>
 <dc:creator>Melnikov, Alexey A.</dc:creator>
 <dc:creator>Makmal, Adi</dc:creator>
 <dc:creator>Dunjko, Vedran</dc:creator>
 <dc:creator>Briegel, Hans J.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The ability to generalize is an important feature of any intelligent agent.
Not only because it may allow the agent to cope with large amounts of data, but
also because in some environments, an agent with no generalization capabilities
cannot learn. In this work we outline several criteria for generalization, and
present a dynamic and autonomous machinery that enables projective simulation
agents to meaningfully generalize. Projective simulation, a novel, physical
approach to artificial intelligence, was recently shown to perform well in
standard reinforcement learning problems, with applications in advanced
robotics as well as quantum experiments. Both the basic projective simulation
model and the presented generalization machinery are based on very simple
principles. This allows us to provide a full analytical analysis of the agent's
performance and to illustrate the benefit the agent gains by generalizing.
Specifically, we show that already in basic (but extreme) environments,
learning without generalization may be impossible, and demonstrate how the
presented generalization machinery enables the projective simulation agent to
learn.
</dc:description>
 <dc:description>Comment: 14 pages, 9 figures</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02247</dc:identifier>
 <dc:identifier>Sci. Rep. 7, 14430 (2017)</dc:identifier>
 <dc:identifier>doi:10.1038/s41598-017-14740-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02255</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On mining complex sequential data by means of FCA and pattern structures</dc:title>
 <dc:creator>Buzmakov, Aleksey</dc:creator>
 <dc:creator>Egho, Elias</dc:creator>
 <dc:creator>Jay, Nicolas</dc:creator>
 <dc:creator>Kuznetsov, Sergei O.</dc:creator>
 <dc:creator>Napoli, Amedeo</dc:creator>
 <dc:creator>Ra&#xef;ssi, Chedy</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  Nowadays data sets are available in very complex and heterogeneous ways.
Mining of such data collections is essential to support many real-world
applications ranging from healthcare to marketing. In this work, we focus on
the analysis of &quot;complex&quot; sequential data by means of interesting sequential
patterns. We approach the problem using the elegant mathematical framework of
Formal Concept Analysis (FCA) and its extension based on &quot;pattern structures&quot;.
Pattern structures are used for mining complex data (such as sequences or
graphs) and are based on a subsumption operation, which in our case is defined
with respect to the partial order on sequences. We show how pattern structures
along with projections (i.e., a data reduction of sequential structures), are
able to enumerate more meaningful patterns and increase the computing
efficiency of the approach. Finally, we show the applicability of the presented
method for discovering and analyzing interesting patient patterns from a French
healthcare data set on cancer. The quantitative and qualitative results (with
annotations and analysis from a physician) are reported in this use case which
is the main motivation for this work.
  Keywords: data mining; formal concept analysis; pattern structures;
projections; sequences; sequential data.
</dc:description>
 <dc:description>Comment: An accepted publication in International Journal of General Systems.
  The paper is created in the wake of the conference on Concept Lattice and
  their Applications (CLA'2013). 27 pages, 9 figures, 3 tables</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02261</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Open Access Policy: Numbers, Analysis, Effectiveness</dc:title>
 <dc:creator>Swan, A.</dc:creator>
 <dc:creator>Gargouri, Y.</dc:creator>
 <dc:creator>Hunt, M.</dc:creator>
 <dc:creator>Harnad, S.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  The PASTEUR4OA project analyses what makes an Open Access (OA) policy
effective. The total number of institutional or funder OA policies worldwide is
now 663 (March 2015), over half of them mandatory. ROARMAP, the policy
registry, has been rebuilt to record more policy detail and provide more
extensive search functionality. Deposit rates were measured for articles in
institutions' repositories and compared to the total number of WoS-indexed
articles published from those institutions. Average deposit rate was over four
times as high for institutions with a mandatory policy. Six positive
correlations were found between deposit rates and (1) Must-Deposit; (2)
Cannot-Waive-Deposit; (3) Deposit-Linked-to-Research-Evaluation; (4)
Cannot-Waive-Rights-Retention; (5) Must-Make-Deposit-OA (after allowable
embargo) and (6) Can-Waive-OA. For deposit latency, there is a positive
correlation between earlier deposit and (7) Must-Deposit-Immediately as well as
with (4) Cannot-Waive-Rights-Retention and with mandate age. There are not yet
enough OA policies to test whether still further policy conditions would
contribute to mandate effectiveness but the present findings already suggest
that it would be useful for current and future OA policies to adopt the seven
positive conditions so as to accelerate and maximise the growth of OA.
</dc:description>
 <dc:description>Comment: 49 pages, 21 figures, 15 tables. Pasteur4OA Work Package 3 report:
  Open Access policies 2015</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02264</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model Coupling between the Weather Research and Forecasting Model and
  the DPRI Large Eddy Simulator for Urban Flows on GPU-accelerated Multicore
  Systems</dc:title>
 <dc:creator>Vanderbauwhede, Wim</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this report we present a novel approach to model coupling for
shared-memory multicore systems hosting OpenCL-compliant accelerators, which we
call The Glasgow Model Coupling Framework (GMCF). We discuss the implementation
of a prototype of GMCF and its application to coupling the Weather Research and
Forecasting Model and an OpenCL-accelerated version of the Large Eddy Simulator
for Urban Flows (LES) developed at DPRI.
  The first stage of this work concerned the OpenCL port of the LES. The
methodology used for the OpenCL port is a combination of automated analysis and
code generation and rule-based manual parallelization. For the evaluation, the
non-OpenCL LES code was compiled using gfortran, fort and pgfortran}, in each
case with auto-parallelization and auto-vectorization. The OpenCL-accelerated
version of the LES achieves a 7 times speed-up on a NVIDIA GeForce GTX 480
GPGPU, compared to the fastest possible compilation of the original code
running on a 12-core Intel Xeon E5-2640.
  In the second stage of this work, we built the Glasgow Model Coupling
Framework and successfully used it to couple an OpenMP-parallelized WRF
instance with an OpenCL LES instance which runs the LES code on the GPGPI. The
system requires only very minimal changes to the original code. The report
discusses the rationale, aims, approach and implementation details of this
work.
</dc:description>
 <dc:description>Comment: This work was conducted during a research visit at the Disaster
  Prevention Research Institute of Kyoto University, supported by an EPSRC
  Overseas Travel Grant, EP/L026201/1</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02268</identifier>
 <datestamp>2015-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space- and Time-Efficient Algorithm for Maintaining Dense Subgraphs on
  One-Pass Dynamic Streams</dc:title>
 <dc:creator>Bhattacharya, Sayan</dc:creator>
 <dc:creator>Henzinger, Monika</dc:creator>
 <dc:creator>Nanongkai, Danupon</dc:creator>
 <dc:creator>Tsourakakis, Charalampos E.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  While in many graph mining applications it is crucial to handle a stream of
updates efficiently in terms of {\em both} time and space, not much was known
about achieving such type of algorithm. In this paper we study this issue for a
problem which lies at the core of many graph mining applications called {\em
densest subgraph problem}. We develop an algorithm that achieves time- and
space-efficiency for this problem simultaneously. It is one of the first of its
kind for graph problems to the best of our knowledge.
  In a graph $G = (V, E)$, the &quot;density&quot; of a subgraph induced by a subset of
nodes $S \subseteq V$ is defined as $|E(S)|/|S|$, where $E(S)$ is the set of
edges in $E$ with both endpoints in $S$. In the densest subgraph problem, the
goal is to find a subset of nodes that maximizes the density of the
corresponding induced subgraph. For any $\epsilon&gt;0$, we present a dynamic
algorithm that, with high probability, maintains a $(4+\epsilon)$-approximation
to the densest subgraph problem under a sequence of edge insertions and
deletions in a graph with $n$ nodes. It uses $\tilde O(n)$ space, and has an
amortized update time of $\tilde O(1)$ and a query time of $\tilde O(1)$. Here,
$\tilde O$ hides a $O(\poly\log_{1+\epsilon} n)$ term. The approximation ratio
can be improved to $(2+\epsilon)$ at the cost of increasing the query time to
$\tilde O(n)$. It can be extended to a $(2+\epsilon)$-approximation
sublinear-time algorithm and a distributed-streaming algorithm. Our algorithm
is the first streaming algorithm that can maintain the densest subgraph in {\em
one pass}. The previously best algorithm in this setting required $O(\log n)$
passes [Bahmani, Kumar and Vassilvitskii, VLDB'12]. The space required by our
algorithm is tight up to a polylogarithmic factor.
</dc:description>
 <dc:description>Comment: A preliminary version of this paper appeared in STOC 2015</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2015-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02268</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02281</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Optimized Hybrid Approach for Path Finding</dc:title>
 <dc:creator>Ansari, Ahlam</dc:creator>
 <dc:creator>Sayyed, Mohd Amin</dc:creator>
 <dc:creator>Ratlamwala, Khatija</dc:creator>
 <dc:creator>Shaikh, Parvin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Path finding algorithm addresses problem of finding shortest path from source
to destination avoiding obstacles. There exist various search algorithms namely
A*, Dijkstra's and ant colony optimization. Unlike most path finding algorithms
which require destination co-ordinates to compute path, the proposed algorithm
comprises of a new method which finds path using backtracking without requiring
destination co-ordinates. Moreover, in existing path finding algorithm, the
number of iterations required to find path is large. Hence, to overcome this,
an algorithm is proposed which reduces number of iterations required to
traverse the path. The proposed algorithm is hybrid of backtracking and a new
technique(modified 8- neighbor approach). The proposed algorithm can become
essential part in location based, network, gaming applications. grid traversal,
navigation, gaming applications, mobile robot and Artificial Intelligence.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02281</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02288</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ROPocop - Dynamic Mitigation of Code-Reuse Attacks</dc:title>
 <dc:creator>Follner, Andreas</dc:creator>
 <dc:creator>Bodden, Eric</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Control-flow attacks, usually achieved by exploiting a buffer-overflow
vulnerability, have been a serious threat to system security for over fifteen
years. Researchers have answered the threat with various mitigation techniques,
but nevertheless, new exploits that successfully bypass these technologies
still appear on a regular basis.
  In this paper, we propose ROPocop, a novel approach for detecting and
preventing the execution of injected code and for mitigating code-reuse attacks
such as return-oriented programming (RoP). ROPocop uses dynamic binary
instrumentation, requiring neither access to source code nor debug symbols or
changes to the operating system. It mitigates attacks by both monitoring the
program counter at potentially dangerous points and by detecting suspicious
program flows.
  We have implemented ROPocop for Windows x86 using PIN, a dynamic program
instrumentation framework from Intel. Benchmarks using the SPEC CPU2006 suite
show an average overhead of 2.4x, which is comparable to similar approaches,
which give weaker guarantees. Real-world applications show only an initially
noticeable input lag and no stutter. In our evaluation our tool successfully
detected all 11 of the latest real-world code-reuse exploits, with no false
alarms. Therefore, despite the overhead, it is a viable, temporary solution to
secure critical systems against exploits if a vendor patch is not yet
available.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02288</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02290</identifier>
 <datestamp>2015-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computer simulation of Poisson's ratio of soft polydisperse discs at
  zero temperature</dc:title>
 <dc:creator>Narojczyk, Jakub</dc:creator>
 <dc:creator>Wojciechowski, Krzysztof W.</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Condensed Matter - Soft Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  A simple algorithm is proposed for studies of structural and elastic
properties in the presence of structural disorder at zero temperature. The
algorithm is used to determine the properties of the polydisperse soft disc
system. It is shown that the Poisson's ratio of the system essentially depends
on the size polydispersity parameter - larger polydispersity implies larger
Poisson's ratio. In the presence of any size polidispersity the Poisson's ratio
increases also when the interactions between the particles tend to the hard
potential.
</dc:description>
 <dc:description>Comment: 8th International Conference on Intermolecular and Magnetic
  Interactions in Matter, Naleczow, POLAND, SEP 08-10, 2005</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02290</dc:identifier>
 <dc:identifier>Materials Science-Poland Volume: 24 Issue: 4 pp.921-927 Published:
  2006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02293</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial Domain Simultaneous Information and Power Transfer for MIMO
  Channels</dc:title>
 <dc:creator>Timotheou, Stelios</dc:creator>
 <dc:creator>Krikidis, Ioannis</dc:creator>
 <dc:creator>Karachontzitis, Sotiris</dc:creator>
 <dc:creator>Berberidis, Kostas</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we theoretically investigate a new technique for simultaneous
information and power transfer (SWIPT) in multiple-input multiple-output (MIMO)
point-to-point with radio frequency energy harvesting capabilities. The
proposed technique exploits the spatial decomposition of the MIMO channel and
uses the eigenchannels either to convey information or to transfer energy. In
order to generalize our study, we consider channel estimation error in the
decomposition process and the interference between the eigenchannels. An
optimization problem that minimizes the total transmitted power subject to
maximum power per eigenchannel, information and energy constraints is
formulated as a mixed-integer nonlinear program and solved to optimality using
mixed-integer second-order cone programming. A near-optimal mixed-integer
linear programming solution is also developed with robust computational
performance. A polynomial complexity algorithm is further proposed for the
optimal solution of the problem when no maximum power per eigenchannel
constraints are imposed. In addition, a low polynomial complexity algorithm is
developed for the power allocation problem with a given eigenchannel
assignment, as well as a low-complexity heuristic for solving the eigenchannel
assignment problem.
</dc:description>
 <dc:description>Comment: 14 pages, 5 figures, Accepted for publication in IEEE Trans. on
  Wireless Communications</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02293</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2015.2416721</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02297</identifier>
 <datestamp>2015-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formalizing parity complexes</dc:title>
 <dc:creator>Buckley, Mitchell</dc:creator>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We formalise, in Coq, the opening sections of Parity Complexes [Street1991]
up to and including the all important excision of extremals algorithm. Parity
complexes describe the essential combinatorial structure exhibited by
simplexes, cubes and globes, that enable the construction of free
$\omega$-categories on such objects. The excision of extremals is a recursive
algorithm that presents every cell in such a category as a (unique) composite
of atomic cells. This is the sense in which the $\omega$-category is (freely)
generated from its atoms. Due to the complicated multi-dimensional nature of
this work, the detail of definitions and proofs can be hard to follow and
verify. Indeed, some corrections were required some years following the
original publication~\cite{Street1994}. Our formalisation verifies that all
cases of each result operate as stated. In particular, we indicate which
portions of the theory can be proved directly from definitions, and which
require more subtle and complex arguments. By identifying results that require
the most complicated proofs, we are able to investigate where this theory might
benefit from further study and which results need to be considered most
carefully in future work.
</dc:description>
 <dc:description>Comment: Second version following revision for publication, 27 pages</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2015-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02298</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A closed equation in time domain for band-limited extensions of
  one-sided sequences</dc:title>
 <dc:creator>Dokuchaev, Nikolai</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The paper suggests a method of optimal extension of one-sided semi-infinite
sequences of a general type by traces of band-limited sequences in
deterministic setting, i.e. without probabilistic assumptions. The method
requires to solve a closed linear equation in the time domain connecting the
past observations of the underlying process with the future values of the
band-limited process.
  Robustness of the solution with respect to the input errors and data
truncation is established in the framework of Tikhonov regularization.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1208.3278</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2017-09-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02298</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02300</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fairness for Non-Orthogonal Multiple Access in 5G Systems</dc:title>
 <dc:creator>Timotheou, Stelios</dc:creator>
 <dc:creator>Krikidis, Ioannis</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In non-orthogonal multiple access (NOMA) downlink, multiple data flows are
superimposed in the power domain and user decoding is based on successive
interference cancellation. NOMA's performance highly depends on the power split
among the data flows and the associated power allocation (PA) problem. In this
letter, we study NOMA from a fairness standpoint and we investigate PA
techniques that ensure fairness for the downlink users under i) instantaneous
channel state information (CSI) at the transmitter, and ii) average CSI.
Although the formulated problems are non-convex, we have developed
low-complexity polynomial algorithms that yield the optimal solution in both
cases considered.
</dc:description>
 <dc:description>Comment: 5 pages, 3 Figures, accepted in IEEE Signal Processing Letters</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02300</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2015.2417119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02305</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Cyberbullying and Other Toxic Behavior in Team Competition
  Online Games</dc:title>
 <dc:creator>Kwak, Haewoon</dc:creator>
 <dc:creator>Blackburn, Jeremy</dc:creator>
 <dc:creator>Han, Seungyeop</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:subject>K.4.2</dc:subject>
 <dc:description>  In this work we explore cyberbullying and other toxic behavior in team
competition online games. Using a dataset of over 10 million player reports on
1.46 million toxic players along with corresponding crowdsourced decisions, we
test several hypotheses drawn from theories explaining toxic behavior. Besides
providing large-scale, empirical based understanding of toxic behavior, our
work can be used as a basis for building systems to detect, prevent, and
counter-act toxic behavior.
</dc:description>
 <dc:description>Comment: CHI'15</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02306</identifier>
 <datestamp>2016-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal induced universal graphs and adjacency labeling for trees</dc:title>
 <dc:creator>Alstrup, Stephen</dc:creator>
 <dc:creator>Dahlgaard, S&#xf8;ren</dc:creator>
 <dc:creator>Knudsen, Mathias B&#xe6;k Tejs</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We show that there exists a graph $G$ with $O(n)$ nodes, where any forest of
$n$ nodes is a node-induced subgraph of $G$. Furthermore, for constant
arboricity $k$, the result implies the existence of a graph with $O(n^k)$ nodes
that contains all $n$-node graphs as node-induced subgraphs, matching a
$\Omega(n^k)$ lower bound. The lower bound and previously best upper bounds
were presented in Alstrup and Rauhe (FOCS'02). Our upper bounds are obtained
through a $\log_2 n +O(1)$ labeling scheme for adjacency queries in forests.
  We hereby solve an open problem being raised repeatedly over decades, e.g. in
Kannan, Naor, Rudich (STOC 1988), Chung (J. of Graph Theory 1990), Fraigniaud
and Korman (SODA 2010).
</dc:description>
 <dc:description>Comment: A preliminary version of this paper appeared at FOCS'15</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2016-02-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02307</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Detection in Training Assisted SIMO Systems with Phase Noise
  Impairments</dc:title>
 <dc:creator>Pitarokoilis, Antonios</dc:creator>
 <dc:creator>Bj&#xf6;rnson, Emil</dc:creator>
 <dc:creator>Larsson, Erik G.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, the problem of optimal maximum likelihood detection in a
single user single-input multiple-output (SIMO) channel with phase noise at the
receiver is considered. The optimal detection rules under training are derived
for two operation modes, namely when the phase increments are fully correlated
among the $M$ receiver antennas (synchronous operation) and when they are
independent (non-synchronous operation). The phase noise increments are
parameterized by a very general distribution, which includes the Wiener phase
noise model as a special case. It is proven that phase noise creates a
symbol-error-rate (SER) floor for both operation modes. In the synchronous
operation this error floor is independent of $M$, while it goes to zero
exponentially with $M$ in the non-synchronous operation.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, IEEE ICC 2015, London, UK, to appear</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02307</dc:identifier>
 <dc:identifier>doi:10.1109/ICC.2015.7248716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02317</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantization Design for Distributed Optimization</dc:title>
 <dc:creator>Pu, Ye</dc:creator>
 <dc:creator>Zeilinger, Melanie N.</dc:creator>
 <dc:creator>Jones, Colin N.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We consider the problem of solving a distributed optimization problem using a
distributed computing platform, where the communication in the network is
limited: each node can only communicate with its neighbours and the channel has
a limited data-rate. A common technique to address the latter limitation is to
apply quantization to the exchanged information. We propose two distributed
optimization algorithms with an iteratively refining quantization design based
on the inexact proximal gradient method and its accelerated variant. We show
that if the parameters of the quantizers, i.e. the number of bits and the
initial quantization intervals, satisfy certain conditions, then the
quantization error is bounded by a linearly decreasing function and the
convergence of the distributed algorithms is guaranteed. Furthermore, we prove
that after imposing the quantization scheme, the distributed algorithms still
exhibit a linear convergence rate, and show complexity upper-bounds on the
number of iterations to achieve a given accuracy. Finally, we demonstrate the
performance of the proposed algorithms and the theoretical findings for solving
a distributed optimal control problem.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02324</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing Installations for Verification of the Model of Active Queue
  Management Discipline RED in the GNS3</dc:title>
 <dc:creator>Velieva, T. R.</dc:creator>
 <dc:creator>Korolkova, A. V.</dc:creator>
 <dc:creator>Kulyabov, D. S.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  The problem of RED-module mathematical model results verification, based on
GNS3 experimental stand, is discussed in this article. The experimental stand
consists of virtual Cisco router, traffic generator D-ITG and traffic receiver.
The process of construction of such stand is presented. Also, the interaction
between experimental stand and a computer of investigation in order to obtain
and analyze data from stand is revised. A stochastic model of the traffic
management RED type module was built. Verification of the model was carried out
on the NS-2 basis. However, we would like to conduct verification on a real
router. As a result was the task of designing an experimental stand. It was
decided to verify the clean RED algorithm based on Cisco router. For the
construction of the stand software package GNS3 (Graphical Network Simulator)
was chosen. Thus, the purpose of the study is to build on the GNS3 basis a
virtual stand consisting of a Cisco router, a traffic generator and a receiver.
A traffic generator D-ITG (Distributed Internet Traffic Generator) is used as.
</dc:description>
 <dc:description>Comment: in Russian; in English</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02324</dc:identifier>
 <dc:identifier>6th ICUMT, IEEE, 2014, pp. 570--577</dc:identifier>
 <dc:identifier>doi:10.1109/ICUMT.2014.7002164</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02333</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lower bounds on $q$-wise independence tails and applications to
  min-entropy condensers</dc:title>
 <dc:creator>Skorski, Maciej</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We present novel and sharp lower bounds for higher load moments in the
classical problem of mapping $M$ balls into $N$ bins by $q$-universal hashing,
specialized to the case when $M=N$. As a corollary we prove a tight counterpart
for the result about min-entropy condensers due to Dodis, Pietrzak and Wichs
(CRYPTO'14), which has found important applications in key derivation. It
states that condensing $k$ bits of min-entropy into a $k$-bit string
$\epsilon$-close to almost full min-entropy (precisely $
k-\log\log(1/\epsilon)$ bits of entropy) can be achieved by the use of
$q$-independent hashing with $q= \log(1/\epsilon)$. We prove that when given a
source of min-entropy $k$ and aiming at entropy loss $\ell = \log\log
(1/\epsilon) - 3$, the independence level $q=(1-o(1))\log(1/\epsilon)$ is
necessary (for small values of $\epsilon$), which almost matches the positive
result. Besides these asymptotic bounds, we provide clear hard bounds in terms
of Bell numbers and some numerical examples. Our technique is based on an
explicit representation of the load moments in terms of Stirling numbers, some
asymptotic estimates on Stirling numbers and a tricky application of the
Paley-Zygmund inequality. \keywords{ min-entropy condensers, key derivation,
balls and bins hashing, anti-concentration inequalities }
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02333</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02335</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Early Bird Catches The Term: Combining Twitter and News Data For
  Event Detection and Situational Awareness</dc:title>
 <dc:creator>Thapen, Nicholas</dc:creator>
 <dc:creator>Simmie, Donal</dc:creator>
 <dc:creator>Hankin, Chris</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Twitter updates now represent an enormous stream of information originating
from a wide variety of formal and informal sources, much of which is relevant
to real-world events. In this paper we adapt existing bio-surveillance
algorithms to detect localised spikes in Twitter activity corresponding to real
events with a high level of confidence. We then develop a methodology to
automatically summarise these events, both by providing the tweets which fully
describe the event and by linking to highly relevant news articles. We apply
our methods to outbreaks of illness and events strongly affecting sentiment. In
both case studies we are able to detect events verifiable by third party
sources and produce high quality summaries.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02338</identifier>
 <datestamp>2016-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kernel Manifold Alignment</dc:title>
 <dc:creator>Tuia, Devis</dc:creator>
 <dc:creator>Camps-Valls, Gustau</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce a kernel method for manifold alignment (KEMA) and domain
adaptation that can match an arbitrary number of data sources without needing
corresponding pairs, just few labeled examples in all domains. KEMA has
interesting properties: 1) it generalizes other manifold alignment methods, 2)
it can align manifolds of very different complexities, performing a sort of
manifold unfolding plus alignment, 3) it can define a domain-specific metric to
cope with multimodal specificities, 4) it can align data spaces of different
dimensionality, 5) it is robust to strong nonlinear feature deformations, and
6) it is closed-form invertible which allows transfer across-domains and data
synthesis. We also present a reduced-rank version for computational efficiency
and discuss the generalization performance of KEMA under Rademacher principles
of stability. KEMA exhibits very good performance over competing methods in
synthetic examples, visual object recognition and recognition of facial
expressions tasks.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2015-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02338</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0148655</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02340</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-Online Multi-target Tracking with Aggregated Local Flow Descriptor</dc:title>
 <dc:creator>Choi, Wongun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we focus on the two key aspects of multiple target tracking
problem: 1) designing an accurate affinity measure to associate detections and
2) implementing an efficient and accurate (near) online multiple target
tracking algorithm. As the first contribution, we introduce a novel Aggregated
Local Flow Descriptor (ALFD) that encodes the relative motion pattern between a
pair of temporally distant detections using long term interest point
trajectories (IPTs). Leveraging on the IPTs, the ALFD provides a robust
affinity measure for estimating the likelihood of matching detections
regardless of the application scenarios. As another contribution, we present a
Near-Online Multi-target Tracking (NOMT) algorithm. The tracking problem is
formulated as a data-association between targets and detections in a temporal
window, that is performed repeatedly at every frame. While being efficient,
NOMT achieves robustness via integrating multiple cues including ALFD metric,
target dynamics, appearance similarity, and long term trajectory regularization
into the model. Our ablative analysis verifies the superiority of the ALFD
metric over the other conventional affinity metrics. We run a comprehensive
experimental evaluation on two challenging tracking datasets, KITTI and MOT
datasets. The NOMT method combined with ALFD metric achieves the best accuracy
in both datasets with significant margins (about 10% higher MOTA) over the
state-of-the-arts.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02346</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal User Association for Massive MIMO Empowered Ultra-Dense Wireless
  Networks</dc:title>
 <dc:creator>Gotsis, Antonis G.</dc:creator>
 <dc:creator>Stefanatos, Stelios</dc:creator>
 <dc:creator>Alexiou, Angeliki</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Ultra network densification and Massive MIMO are considered major 5G enablers
since they promise huge capacity gains by exploiting proximity, spectral and
spatial reuse benefits. Both approaches rely on increasing the number of access
elements per user, either through deploying more access nodes over an area or
increasing the number of antenna elements per access node. At the
network-level, optimal user-association for a densely and randomly deployed
network of Massive MIMO empowered access nodes must account for both channel
and load conditions. In this paper we formulate this complex problem, report
its computationally intractability and reformulate it to a plausible form,
amenable to acquire a global optimal solution with reasonable complexity. We
apply the proposed optimization model to typical ultra-dense outdoor small-cell
setups and demonstrate: (i) the significant impact of optimal user-association
to the achieved rate levels compared to a baseline strategy, and (ii) the
optimality of alternative network access element deployment strategies.
</dc:description>
 <dc:description>Comment: to be presented in IEEE ICC 2015 - Workshop on Advanced PHY and MAC
  Techniques for Super Dense Wireless Networks (ICC'15 - Workshops 13)</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02347</identifier>
 <datestamp>2015-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Point Decomposition Problem in Binary Elliptic Curves</dc:title>
 <dc:creator>Karabina, Koray</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:description>  We analyze the point decomposition problem (PDP) in binary elliptic curves.
It is known that PDP in an elliptic curve group can be reduced to solving a
particular system of multivariate non-linear system of equations derived from
the so called Semaev summation polynomials. We modify the underlying system of
equations by introducing some auxiliary variables. We argue that the trade-off
between lowering the degree of Semaev polynomials and increasing the number of
variables is worth.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2015-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02351</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When Face Recognition Meets with Deep Learning: an Evaluation of
  Convolutional Neural Networks for Face Recognition</dc:title>
 <dc:creator>Hu, Guosheng</dc:creator>
 <dc:creator>Yang, Yongxin</dc:creator>
 <dc:creator>Yi, Dong</dc:creator>
 <dc:creator>Kittler, Josef</dc:creator>
 <dc:creator>Christmas, William</dc:creator>
 <dc:creator>Li, Stan Z.</dc:creator>
 <dc:creator>Hospedales, Timothy</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deep learning, in particular Convolutional Neural Network (CNN), has achieved
promising results in face recognition recently. However, it remains an open
question: why CNNs work well and how to design a 'good' architecture. The
existing works tend to focus on reporting CNN architectures that work well for
face recognition rather than investigate the reason. In this work, we conduct
an extensive evaluation of CNN-based face recognition systems (CNN-FRS) on a
common ground to make our work easily reproducible. Specifically, we use public
database LFW (Labeled Faces in the Wild) to train CNNs, unlike most existing
CNNs trained on private databases. We propose three CNN architectures which are
the first reported architectures trained using LFW data. This paper
quantitatively compares the architectures of CNNs and evaluate the effect of
different implementation choices. We identify several useful properties of
CNN-FRS. For instance, the dimensionality of the learned features can be
significantly reduced without adverse effect on face recognition accuracy. In
addition, traditional metric learning method exploiting CNN-learned features is
evaluated. Experiments show two crucial factors to good CNN-FRS performance are
the fusion of multiple CNNs and metric learning. To make our work reproducible,
source code and models will be made publicly available.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures, 7 tables</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02351</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02356</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring EEG for Object Detection and Retrieval</dc:title>
 <dc:creator>Mohedano, Eva</dc:creator>
 <dc:creator>Salvador, Amaia</dc:creator>
 <dc:creator>Porta, Sergi</dc:creator>
 <dc:creator>Gir&#xf3;-i-Nieto, Xavier</dc:creator>
 <dc:creator>Healy, Graham</dc:creator>
 <dc:creator>McGuinness, Kevin</dc:creator>
 <dc:creator>O'Connor, Noel</dc:creator>
 <dc:creator>Smeaton, Alan F.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.1.2</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  This paper explores the potential for using Brain Computer Interfaces (BCI)
as a relevance feedback mechanism in content-based image retrieval. We
investigate if it is possible to capture useful EEG signals to detect if
relevant objects are present in a dataset of realistic and complex images. We
perform several experiments using a rapid serial visual presentation (RSVP) of
images at different rates (5Hz and 10Hz) on 8 users with different degrees of
familiarization with BCI and the dataset. We then use the feedback from the BCI
and mouse-based interfaces to retrieve localized objects in a subset of TRECVid
images. We show that it is indeed possible to detect such objects in complex
images and, also, that users with previous knowledge on the dataset or
experience with the RSVP outperform others. When the users have limited time to
annotate the images (100 seconds in our experiments) both interfaces are
comparable in performance. Comparing our best users in a retrieval task, we
found that EEG-based relevance feedback outperforms mouse-based feedback. The
realistic and complex image dataset differentiates our work from previous
studies on EEG for image retrieval.
</dc:description>
 <dc:description>Comment: This preprint is the full version of a short paper accepted in the
  ACM International Conference on Multimedia Retrieval (ICMR) 2015 (Shanghai,
  China)</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02357</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the covering dimension of a linear code</dc:title>
 <dc:creator>Britz, Thomas</dc:creator>
 <dc:creator>Shiromoto, Keisuke</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>05B35, 06A07, 94B05</dc:subject>
 <dc:description>  The critical exponent of a matroid is one of the important parameters in
matroid theory and is related to the Rota and Crapo's Critical Problem. This
paper introduces the covering dimension of a linear code over a finite field,
which is analogous to the critical exponent of a representable matroid. An
upper bound on the covering dimension is conjectured and nearly proven,
improving a classical bound for the critical exponent. Finally, a construction
is given of linear codes that attain equality in the covering dimension bound.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02358</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RDF annotation of Second Life objects: Knowledge Representation meets
  Social Virtual reality</dc:title>
 <dc:creator>Bernava, Carlo</dc:creator>
 <dc:creator>Fiumara, Giacomo</dc:creator>
 <dc:creator>Maggiorini, Dario</dc:creator>
 <dc:creator>Provetti, Alessandro</dc:creator>
 <dc:creator>Ripamonti, Laura</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.1</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  We have designed and implemented an application running inside Second Life
that supports user annotation of graphical objects and graphical visualization
of concept ontologies, thus providing a formal, machine-accessible description
of objects. As a result, we offer a platform that combines the graphical
knowledge representation that is expected from a MUVE artifact with the
semantic structure given by the Resource Framework Description (RDF)
representation of information.
</dc:description>
 <dc:description>Comment: The final publication is available at link.springer.com</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02358</dc:identifier>
 <dc:identifier>Computational and Mathematical Organization Theory (2014) Vol. 20,
  pages 20-35. ISSN 1381-298X</dc:identifier>
 <dc:identifier>doi:10.1007/s10588-012-9148-4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02360</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Objective Power Allocation for Energy Efficient Wireless
  Information and Power Transfer Systems</dc:title>
 <dc:creator>Leng, Shiyang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Simultaneous wireless information and power transfer (SWIPT) provides a
promising solution for enabling perpetual wireless networks. As energy
efficiency (EE) is an im- portant evaluation of system performance, this thesis
studies energy-efficient resource allocation algorithm designs in SWIPT
systems. We first investigate the trade-off between the EE for information
transmission, the EE for power transfer, and the total transmit power in a
basic SWIPT system with separated receivers. A multi-objective optimization
problem is formulated under the constraint of maximum transmit power. We
propose an algorithm which achieves flexible resource allocation for energy
efficiencies maxi- mization and transmit power minimization. The trade-off
region of the system design objectives is shown in simulation results. Further,
we consider secure communication in a SWIPT system with power splitting
receivers. Artificial noise is injected to the com- munication channel to
combat the eavesdropping capability of potential eavesdroppers. A
power-efficient resource allocation algorithm is developed when multiple
legitimate information receivers and multi-antenna potential eavesdroppers
co-exist in the system. Simulation results demonstrate a significant
performance gain by the proposed optimal algorithm compared to suboptimal
baseline schemes.
</dc:description>
 <dc:description>Comment: Master thesis,Institute for Digital Communications, Germany,
  http://www.idc.lnt.de/en/forschung/energy-harvesting/</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02360</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02362</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approaches to the Intelligent Subject Search</dc:title>
 <dc:creator>Ivanov, V. K.</dc:creator>
 <dc:creator>Palyukh, B. V.</dc:creator>
 <dc:creator>Sotnikov, A. N.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  This article presents main results of the pilot study of approaches to the
subject information search based on automated semantic processing of mass
scientific and technical data. The authors focus on technology of building and
qualification of search queries with the following filtering and ranking of
search data. Software architecture, specific features of subject search and
research results application are considered.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02362</dc:identifier>
 <dc:identifier>FedCSIS'2014 3 (2014) 13-20</dc:identifier>
 <dc:identifier>doi:10.15439/2014F70</dc:identifier>
 <dc:identifier>doi:10.15439/978-83-60810-57-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02363</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analyzing and Modeling Special Offer Campaigns in Location-based Social
  Networks</dc:title>
 <dc:creator>Zhang, Ke</dc:creator>
 <dc:creator>Pelechrinis, Konstantinos</dc:creator>
 <dc:creator>Lappas, Theodoros</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The proliferation of mobile handheld devices in combination with the
technological advancements in mobile computing has led to a number of
innovative services that make use of the location information available on such
devices. Traditional yellow pages websites have now moved to mobile platforms,
giving the opportunity to local businesses and potential, near-by, customers to
connect. These platforms can offer an affordable advertisement channel to local
businesses. One of the mechanisms offered by location-based social networks
(LBSNs) allows businesses to provide special offers to their customers that
connect through the platform. We collect a large time-series dataset from
approximately 14 million venues on Foursquare and analyze the performance of
such campaigns using randomization techniques and (non-parametric) hypothesis
testing with statistical bootstrapping. Our main finding indicates that this
type of promotions are not as effective as anecdote success stories might
suggest. Finally, we design classifiers by extracting three different types of
features that are able to provide an educated decision on whether a special
offer campaign for a local business will succeed or not both in short and long
term.
</dc:description>
 <dc:description>Comment: in The 9th International AAAI Conference on Web and Social Media
  (ICWSM 2015)</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02366</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Collection of Challenging Optimization Problems in Science,
  Engineering and Economics</dc:title>
 <dc:creator>Mehta, Dhagash</dc:creator>
 <dc:creator>Grosan, Crina</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  Function optimization and finding simultaneous solutions of a system of
nonlinear equations (SNE) are two closely related and important optimization
problems. However, unlike in the case of function optimization in which one is
required to find the global minimum and sometimes local minima, a database of
challenging SNEs where one is required to find stationary points (extrama and
saddle points) is not readily available. In this article, we initiate building
such a database of important SNE (which also includes related function
optimization problems), arising from Science, Engineering and Economics. After
providing a short review of the most commonly used mathematical and
computational approaches to find solutions of such systems, we provide a
preliminary list of challenging problems by writing the Mathematical
formulation down, briefly explaning the origin and importance of the problem
and giving a short account on the currently known results, for each of the
problems. We anticipate that this database will not only help benchmarking
novel numerical methods for solving SNEs and function optimization problems but
also will help advancing the corresponding research areas.
</dc:description>
 <dc:description>Comment: Accepted as an invited contribution to the special session on
  Evolutionary Computation for Nonlinear Equation Systems at the 2015 IEEE
  Congress on Evolutionary Computation (at Sendai International Center, Sendai,
  Japan, from 25th to 28th May, 2015.)</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02366</dc:identifier>
 <dc:identifier>doi:10.1109/CEC.2015.7257223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02367</identifier>
 <datestamp>2016-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Periodic power spectrum with applications in detection of latent
  periodicities in DNA sequences</dc:title>
 <dc:creator>Yin, Changchuan</dc:creator>
 <dc:creator>Wang, Jiasong</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>65T50</dc:subject>
 <dc:description>  Latent periodic elements in genomes play important roles in genomic
functions. Many complex periodic elements in genomes are difficult to be
detected by commonly used digital signal processing (DSP). We present a novel
method to compute the periodic power spectrum of a DNA sequence based on the
nucleotide distributions on periodic positions of the sequence. The method
directly calculates full periodic spectrum of a DNA sequence rather than
frequency spectrum by Fourier transform. The magnitude of the periodic power
spectrum reflects the strength of the periodicity signals, thus, the algorithm
can capture all the latent periodicities in DNA sequences. We apply this method
on detection of latent periodicities in different genome elements, including
exons and microsatellite DNA sequences. The results show that the method
minimizes the impact of spectral leakage, captures a much broader latent
periodicities in genomes, and outperforms the conventional Fourier transform.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2015-04-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02367</dc:identifier>
 <dc:identifier>doi:10.1007/s00285-016-0982-8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02374</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uplink Performance of Conventional and Massive MIMO Cellular Systems
  with Delayed CSIT</dc:title>
 <dc:creator>Papazafeiropoulos, Anastasios K.</dc:creator>
 <dc:creator>Ngo, Hien Quoc</dc:creator>
 <dc:creator>Ratnarajah, Tharm</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Massive multiple-input multiple-output (MIMO) networks, where the base
stations (BSs) are equipped with large number of antennas and serve a number of
users simultaneously, are very promising, but suffer from pilot contamination.
Despite its importance, delayed channel state information (CSI) due to user
mobility, being another degrading factor, lacks investigation in the
literature. Hence, we consider an uplink model, where each BS applies
zero-forcing decoder, accounting for both effects, but with the focal point on
the relative users' movement with regard to the BS antennas. In this setting,
analytical closed-form expressions for the sum-rate with finite number of BS
antennas, and the asymptotic limits with infinite number of BS antennas
epitomize the main contributions. In particular, the probability density
function of the signal-to-interference-plus-noise ratio and the ergodic
sum-rate are derived for any finite number of antennas. Insights of the impact
of the arising Doppler shift due to user mobility into the low signal-to-noise
ratio regime as well as the outage probability are obtained. Moreover,
asymptotic analysis performance results in terms of infinitely increasing
number of antennas, power, and both numbers of antennas and users (while their
ratio is fixed) are provided. The numerical results demonstrate the performance
loss in various Doppler shifts. An interesting observation is that massive MIMO
is favorable even in time-varying channel conditions.
</dc:description>
 <dc:description>Comment: 5 figures</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02382</identifier>
 <datestamp>2016-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust, scalable and fast bootstrap method for analyzing large scale
  data</dc:title>
 <dc:creator>Basiri, Shahab</dc:creator>
 <dc:creator>Ollila, Esa</dc:creator>
 <dc:creator>Koivunen, Visa</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper we address the problem of performing statistical inference for
large scale data sets i.e., Big Data. The volume and dimensionality of the data
may be so high that it cannot be processed or stored in a single computing
node. We propose a scalable, statistically robust and computationally efficient
bootstrap method, compatible with distributed processing and storage systems.
Bootstrap resamples are constructed with smaller number of distinct data points
on multiple disjoint subsets of data, similarly to the bag of little bootstrap
method (BLB) [1]. Then significant savings in computation is achieved by
avoiding the re-computation of the estimator for each bootstrap sample.
Instead, a computationally efficient fixed-point estimation equation is
analytically solved via a smart approximation following the Fast and Robust
Bootstrap method (FRB) [2]. Our proposed bootstrap method facilitates the use
of highly robust statistical methods in analyzing large scale data sets. The
favorable statistical properties of the method are established analytically.
Numerical examples demonstrate scalability, low complexity and robust
statistical performance of the method in analyzing large data sets.
</dc:description>
 <dc:description>Comment: This paper is submitted for publication in IEEE Transactions On
  Signal Processing, 8 pages, 8 figures</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2015-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02382</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2015.2498121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02395</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bridging the gap between general probabilistic theories and the
  device-independent framework for nonlocality and contextuality</dc:title>
 <dc:creator>Chiribella, Giulio</dc:creator>
 <dc:creator>Yuan, Xiao</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:description>  Characterizing quantum correlations in terms of information-theoretic
principles is a popular chapter of quantum foundations. Traditionally, the
principles adopted for this scope have been expressed in terms of conditional
probability distributions, specifying the probability that a black box produces
a certain output upon receiving a certain input. This framework is known as
&quot;device-independent&quot;. Another major chapter of quantum foundations is the
information-theoretic characterization of quantum theory, with its sets of
states and measurements, and with its allowed dynamics. The different
frameworks adopted for this scope are known under the umbrella term &quot;general
probabilistic theories&quot;. With only a few exceptions, the two programmes on
characterizing quantum correlations and characterizing quantum theory have so
far proceeded on separate tracks, each one developing its own methods and its
own agenda. This paper aims at bridging the gap, by comparing the two
frameworks and illustrating how the two programmes can benefit each other.
</dc:description>
 <dc:description>Comment: 61 pages, no figures, published version</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2016-03-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02395</dc:identifier>
 <dc:identifier>Information and Computation, 250, 15-49 (2016)</dc:identifier>
 <dc:identifier>doi:10.1016/j.ic.2016.02.006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02398</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-time Monocular Object SLAM</dc:title>
 <dc:creator>G&#xe1;lvez-L&#xf3;pez, Dorian</dc:creator>
 <dc:creator>Salas, Marta</dc:creator>
 <dc:creator>Tard&#xf3;s, Juan D.</dc:creator>
 <dc:creator>Montiel, J. M. M.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a real-time object-based SLAM system that leverages the largest
object database to date. Our approach comprises two main components: 1) a
monocular SLAM algorithm that exploits object rigidity constraints to improve
the map and find its real scale, and 2) a novel object recognition algorithm
based on bags of binary words, which provides live detections with a database
of 500 3D objects. The two components work together and benefit each other: the
SLAM algorithm accumulates information from the observations of the objects,
anchors object features to especial map landmarks and sets constrains on the
optimization. At the same time, objects partially or fully located within the
map are used as a prior to guide the recognition algorithm, achieving higher
recall. We evaluate our proposal on five real environments showing improvements
on the accuracy of the map and efficiency with respect to other
state-of-the-art techniques.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02398</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02406</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deciding when to stop: Efficient stopping of active learning guided
  drug-target prediction</dc:title>
 <dc:creator>Temerinac-Ott, Maja</dc:creator>
 <dc:creator>Naik, Armaghan W.</dc:creator>
 <dc:creator>Murphy, Robert F.</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Active learning has shown to reduce the number of experiments needed to
obtain high-confidence drug-target predictions. However, in order to actually
save experiments using active learning, it is crucial to have a method to
evaluate the quality of the current prediction and decide when to stop the
experimentation process. Only by applying reliable stoping criteria to active
learning, time and costs in the experimental process can be actually saved. We
compute active learning traces on simulated drug-target matrices in order to
learn a regression model for the accuracy of the active learner. By analyzing
the performance of the regression model on simulated data, we design stopping
criteria for previously unseen experimental matrices. We demonstrate on four
previously characterized drug effect data sets that applying the stopping
criteria can result in upto 40% savings of the total experiments for highly
accurate predictions.
</dc:description>
 <dc:description>Comment: This paper was selected for oral presentation at RECOMB 2015 and an
  abstract is published in the conference proceedings</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02406</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02408</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Observations of service identification from two enterprises</dc:title>
 <dc:creator>Alkkiom&#xe4;ki, Ville</dc:creator>
 <dc:creator>Smolander, Kari</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Service-oriented computing has created new requirements for information
systems development processes and methods. The adoption of service-oriented
development requires service identification methods matching the challenge in
enterprises. A wide variety of service identification methods (SIM) have been
proposed, but less attention has been paid to the actual requirements of the
methods. This paper provides an ethnographical look at challenges in service
identification based on data from 14 service identification sessions, providing
insight into the practice of service identification. The findings identified
two types of service identification sessions and the results can be used for
selecting the appropriate SIM based on the type of the session.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02408</dc:identifier>
 <dc:identifier>International Journal of Software Engineering &amp; Applications
  (IJSEA), Vol.6, No.2, March 2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02411</identifier>
 <datestamp>2015-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can Almost Everybody be Almost Happy? PCP for PPAD and the
  Inapproximability of Nash</dc:title>
 <dc:creator>Babichenko, Yakov</dc:creator>
 <dc:creator>Papadimitriou, Christos</dc:creator>
 <dc:creator>Rubinstein, Aviad</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We conjecture that PPAD has a PCP-like complete problem, seeking a near
equilibrium in which all but very few players have very little incentive to
deviate. We show that, if one assumes that this problem requires exponential
time, several open problems in this area are settled. The most important
implication, proved via a &quot;birthday repetition&quot; reduction, is that the n^O(log
n) approximation scheme of [LMM03] for the Nash equilibrium of two-player games
is essentially optimum. Two other open problems in the area are resolved once
one assumes this conjecture, establishing that certain approximate equilibria
are PPAD-complete: Finding a relative approximation of two-player Nash
equilibria (without the well-supported restriction of [Das13]), and an
approximate competitive equilibrium with equal incomes [Bud11] with small
clearing error and near-optimal Gini coefficient.
</dc:description>
 <dc:description>Comment: Revision 2 derandomizes the main reduction</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2015-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02412</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase Transitions in Spectral Community Detection of Large Noisy
  Networks</dc:title>
 <dc:creator>Chen, Pin-Yu</dc:creator>
 <dc:creator>Hero III, Alfred O.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we study the sensitivity of the spectral clustering based
community detection algorithm subject to a Erdos-Renyi type random noise model.
We prove phase transitions in community detectability as a function of the
external edge connection probability and the noisy edge presence probability
under a general network model where two arbitrarily connected communities are
interconnected by random external edges. Specifically, the community detection
performance transitions from almost perfect detectability to low detectability
as the inter-community edge connection probability exceeds some critical value.
We derive upper and lower bounds on the critical value and show that the bounds
are identical when the two communities have the same size. The phase transition
results are validated using network simulations. Using the derived expressions
for the phase transition threshold we propose a method for estimating this
threshold from observed data.
</dc:description>
 <dc:description>Comment: conference paper at IEEE ICASSP 2015</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02420</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms for the workflow satisfiability problem engineered for
  counting constraints</dc:title>
 <dc:creator>Cohen, D.</dc:creator>
 <dc:creator>Crampton, J.</dc:creator>
 <dc:creator>Gagarin, A.</dc:creator>
 <dc:creator>Gutin, G.</dc:creator>
 <dc:creator>Jones, M.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The workflow satisfiability problem (WSP) asks whether there exists an
assignment of authorized users to the steps in a workflow specification that
satisfies the constraints in the specification. The problem is NP-hard in
general, but several subclasses of the problem are known to be fixed-parameter
tractable (FPT) when parameterized by the number of steps in the specification.
In this paper, we consider the WSP with user-independent counting constraints,
a large class of constraints for which the WSP is known to be FPT. We describe
an efficient implementation of an FPT algorithm for solving this subclass of
the WSP and an experimental evaluation of this algorithm. The algorithm
iteratively generates all equivalence classes of possible partial solutions
until, whenever possible, it finds a complete solution to the problem. We also
provide a reduction from a WSP instance to a pseudo-Boolean SAT instance. We
apply this reduction to the instances used in our experiments and solve the
resulting PB SAT problems using SAT4J, a PB SAT solver. We compare the
performance of our algorithm with that of SAT4J and discuss which of the two
approaches would be more effective in practice.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02420</dc:identifier>
 <dc:identifier>doi:10.1007/s10878-015-9877-7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02424</identifier>
 <datestamp>2015-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Big Data Analytics for Dynamic Energy Management in Smart Grids</dc:title>
 <dc:creator>Diamantoulakis, Panagiotis D.</dc:creator>
 <dc:creator>Kapinas, Vasileios M.</dc:creator>
 <dc:creator>Karagiannidis, George K.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The smart electricity grid enables a two-way flow of power and data between
suppliers and consumers in order to facilitate the power flow optimization in
terms of economic efficiency, reliability and sustainability. This
infrastructure permits the consumers and the micro-energy producers to take a
more active role in the electricity market and the dynamic energy management
(DEM). The most important challenge in a smart grid (SG) is how to take
advantage of the users' participation in order to reduce the cost of power.
However, effective DEM depends critically on load and renewable production
forecasting. This calls for intelligent methods and solutions for the real-time
exploitation of the large volumes of data generated by a vast amount of smart
meters. Hence, robust data analytics, high performance computing, efficient
data network management, and cloud computing techniques are critical towards
the optimized operation of SGs. This research aims to highlight the big data
issues and challenges faced by the DEM employed in SG networks. It also
provides a brief description of the most commonly used data processing methods
in the literature, and proposes a promising direction for future research in
the field.
</dc:description>
 <dc:description>Comment: Published in ELSEVIER Big Data Research</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2015-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02424</dc:identifier>
 <dc:identifier>Big Data Research, vol. 2, no. 3, pp. 94-101, Sep. 2015</dc:identifier>
 <dc:identifier>doi:10.1016/j.bdr.2015.03.003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02437</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Complete 3D Models of Indoor Scenes</dc:title>
 <dc:creator>Guo, Ruiqi</dc:creator>
 <dc:creator>Zou, Chuhang</dc:creator>
 <dc:creator>Hoiem, Derek</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  One major goal of vision is to infer physical models of objects, surfaces,
and their layout from sensors. In this paper, we aim to interpret indoor scenes
from one RGBD image. Our representation encodes the layout of walls, which must
conform to a Manhattan structure but is otherwise flexible, and the layout and
extent of objects, modeled with CAD-like 3D shapes. We represent both the
visible and occluded portions of the scene, producing a complete 3D parse. Such
a scene interpretation is useful for robotics and visual reasoning, but
difficult to produce due to the well-known challenge of segmentation, the high
degree of occlusion, and the diversity of objects in indoor scene. We take a
data-driven approach, generating sets of potential object regions, matching to
regions in training images, and transferring and aligning associated 3D models
while encouraging fit to observations and overall consistency. We demonstrate
encouraging results on the NYU v2 dataset and highlight a variety of
interesting directions for future work.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02440</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Model Checking to Generate Test Cases for Android Applications</dc:title>
 <dc:creator>Espada, Ana Rosario</dc:creator>
 <dc:creator>Gallardo, Mar&#xed;a del Mar</dc:creator>
 <dc:creator>Salmer&#xf3;n, Alberto</dc:creator>
 <dc:creator>Merino, Pedro</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The behavior of mobile devices is highly non deterministic and barely
predictable due to the interaction of the user with its applications. In
consequence, analyzing the correctness of applications running on a smartphone
involves dealing with the complexity of its environment. In this paper, we
propose the use of model-based testing to describe the potential behaviors of
users interacting with mobile applications. These behaviors are modeled by
composing specially-designed state machines. These composed state machines can
be exhaustively explored using a model checking tool to automatically generate
all possible user interactions. Each generated trace model checker can be
interpreted as a test case to drive a runtime analysis of actual applications.
We have implemented a tool that follows the proposed methodology to analyze
Android devices using the model checker Spin as the exhaustive generator of
test cases.
</dc:description>
 <dc:description>Comment: In Proceedings MBT 2015, arXiv:1504.01928</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02440</dc:identifier>
 <dc:identifier>EPTCS 180, 2015, pp. 7-21</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.180.1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02441</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ioco Theory for Probabilistic Automata</dc:title>
 <dc:creator>Gerhold, Marcus</dc:creator>
 <dc:creator>Stoelinga, Mari&#xeb;lle</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Model-based testing (MBT) is a well-known technology, which allows for
automatic test case generation, execution and evaluation. To test
non-functional properties, a number of test MBT frameworks have been developed
to test systems with real-time, continuous behaviour, symbolic data and
quantitative system aspects. Notably, a lot of these frameworks are based on
Tretmans' classical input/output conformance (ioco) framework. However, a
model-based test theory handling probabilistic behaviour does not exist yet.
Probability plays a role in many different systems: unreliable communication
channels, randomized algorithms and communication protocols, service level
agreements pinning down up-time percentages, etc. Therefore, a probabilistic
test theory is of great practical importance. We present the ingredients for a
probabilistic variant of ioco and define the {\pi}oco relation, show that it
conservatively extends ioco and define the concepts of test case, execution and
evaluation.
</dc:description>
 <dc:description>Comment: In Proceedings MBT 2015, arXiv:1504.01928</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02441</dc:identifier>
 <dc:identifier>EPTCS 180, 2015, pp. 23-40</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.180.2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02442</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Visual Formalism for Interacting Systems</dc:title>
 <dc:creator>Jorgensen, Paul C.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Interacting systems are increasingly common. Many examples pervade our
everyday lives: automobiles, aircraft, defense systems, telephone switching
systems, financial systems, national governments, and so on. Closer to computer
science, embedded systems and Systems of Systems are further examples of
interacting systems. Common to all of these is that some &quot;whole&quot; is made up of
constituent parts, and these parts interact with each other. By design, these
interactions are intentional, but it is the unintended interactions that are
problematic. The Systems of Systems literature uses the terms &quot;constituent
systems&quot; and &quot;constituents&quot; to refer to systems that interact with each other.
That practice is followed here. This paper presents a visual formalism, Swim
Lane Event-Driven Petri Nets, that is proposed as a basis for Model-Based
Testing (MBT) of interacting systems. In the absence of available tools, this
model can only support the offline form of Model-Based Testing.
</dc:description>
 <dc:description>Comment: In Proceedings MBT 2015, arXiv:1504.01928</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02442</dc:identifier>
 <dc:identifier>EPTCS 180, 2015, pp. 41-55</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.180.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02443</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Potential Errors and Test Assessment in Software Product Line
  Engineering</dc:title>
 <dc:creator>Lackner, Hartmut</dc:creator>
 <dc:creator>Schmidt, Martin</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Software product lines (SPL) are a method for the development of variant-rich
software systems. Compared to non-variable systems, testing SPLs is extensive
due to an increasingly amount of possible products. Different approaches exist
for testing SPLs, but there is less research for assessing the quality of these
tests by means of error detection capability. Such test assessment is based on
error injection into correct version of the system under test. However to our
knowledge, potential errors in SPL engineering have never been systematically
identified before. This article presents an overview over existing paradigms
for specifying software product lines and the errors that can occur during the
respective specification processes. For assessment of test quality, we leverage
mutation testing techniques to SPL engineering and implement the identified
errors as mutation operators. This allows us to run existing tests against
defective products for the purpose of test assessment. From the results, we
draw conclusions about the error-proneness of the surveyed SPL design paradigms
and how quality of SPL tests can be improved.
</dc:description>
 <dc:description>Comment: In Proceedings MBT 2015, arXiv:1504.01928</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02443</dc:identifier>
 <dc:identifier>EPTCS 180, 2015, pp. 57-72</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.180.4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02444</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Homing is in P</dc:title>
 <dc:creator>Kushik, Natalia</dc:creator>
 <dc:creator>Yevtushenko, Nina</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Homing preset and adaptive experiments with Finite State Machines (FSMs) are
widely used when a non-initialized discrete event system is given for testing
and thus, has to be set to the known state at the first step. The length of a
shortest homing sequence is known to be exponential with respect to the number
of states for a complete observable nondeterministic FSM while the problem of
checking the existence of such sequence (Homing problem) is PSPACE-complete. In
order to decrease the complexity of related problems, one can consider adaptive
experiments when a next input to be applied to a system under experiment
depends on the output responses to the previous inputs. In this paper, we study
the problem of the existence of an adaptive homing experiment for complete
observable nondeterministic machines. We show that if such experiment exists
then it can be constructed with the use of a polynomial-time algorithm with
respect to the number of FSM states.
</dc:description>
 <dc:description>Comment: In Proceedings MBT 2015, arXiv:1504.01928</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02444</dc:identifier>
 <dc:identifier>EPTCS 180, 2015, pp. 73-78</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.180.5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02448</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings Graphs as Models</dc:title>
 <dc:creator>Rensink, Arend</dc:creator>
 <dc:creator>Zambon, Eduardo</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  This volume contains the proceedings of the (first) Graphs as Models (GaM)
2015 workshop, held on 10-11 April 2015 in London, U.K., as a satellite
workshop of ETAPS 2015, the European Joint Conferences on Theory and Practice
of Software. This new workshop combines the strengths of two pre-existing
workshop series: GT-VMT (Graph Transformation and Visual Modelling Techniques)
and GRAPHITE (Graph Inspection and Traversal Engineering).
  Graphs are used as models in all areas of computer science: examples are
state space graphs, control flow graphs, syntax graphs, UML-type models of all
kinds, network layouts, social networks, dependency graphs, and so forth. Used
to model a particular phenomenon or process, graphs are then typically analysed
to find out properties of the modelled subject, or transformed to construct
other types of models.
  The workshop aimed at attracting and stimulating research on the techniques
for graph analysis, inspection and transformation, on a general level rather
than in any specific domain. In total, we received 15 submissions covering
several different areas. Of these 15 submissions, nine were eventually accepted
and appear in this volume.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02448</dc:identifier>
 <dc:identifier>EPTCS 181, 2015</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.181</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02462</identifier>
 <datestamp>2015-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Group Theoretic Perspective on Unsupervised Deep Learning</dc:title>
 <dc:creator>Paul, Arnab</dc:creator>
 <dc:creator>Venkatasubramanian, Suresh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Why does Deep Learning work? What representations does it capture? How do
higher-order representations emerge? We study these questions from the
perspective of group theory, thereby opening a new approach towards a theory of
Deep learning.
  One factor behind the recent resurgence of the subject is a key algorithmic
step called {\em pretraining}: first search for a good generative model for the
input samples, and repeat the process one layer at a time. We show deeper
implications of this simple principle, by establishing a connection with the
interplay of orbits and stabilizers of group actions. Although the neural
networks themselves may not form groups, we show the existence of {\em shadow}
groups whose elements serve as close approximations.
  Over the shadow groups, the pre-training step, originally introduced as a
mechanism to better initialize a network, becomes equivalent to a search for
features with minimal orbits. Intuitively, these features are in a way the {\em
simplest}. Which explains why a deep learning network learns simple features
first. Next, we show how the same principle, when repeated in the deeper
layers, can capture higher order representations, and why representation
complexity increases as the layers get deeper.
</dc:description>
 <dc:description>Comment: 2-page version of arXiv:1412.6621 prepared for presentation at ICLR
  2015 workshop as required by ICLR PC). This version has some minor formatting
  changes as required by the conference</dc:description>
 <dc:date>2015-04-08</dc:date>
 <dc:date>2015-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02463</identifier>
 <datestamp>2015-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Earthquakes, Hurricanes, and Mobile Communication Patterns in the New
  York Metro Area: Collective Behavior during Extreme Events</dc:title>
 <dc:creator>Small, Christopher</dc:creator>
 <dc:creator>Becker, Richard</dc:creator>
 <dc:creator>C&#xe1;ceres, Ram&#xf3;n</dc:creator>
 <dc:creator>Urbanek, Simon</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  We use wireless voice-call and text-message volumes to quantify
spatiotemporal communication patterns in the New York Metro area before,
during, and after the Virginia earthquake and Hurricane Irene in 2011. The
earthquake produces an instantaneous and pervasive increase in volume and a
~90-minute temporal disruption to both call and text volume patterns, but call
volume anomalies are much larger. The magnitude of call volume anomaly
diminishes with distance from earthquake epicenter, with multiple clusters of
high response in Manhattan. The hurricane produces a two-day, spatially varying
disruption to normal call and text volume patterns. In most coastal areas, call
volumes dropped anomalously in the afternoon before the hurricane's arrival,
but text volumes showed a much less consistent pattern. These spatial patterns
suggest partial, but not full, compliance with evacuation orders for low-lying
areas. By helping us understand how people behave in actual emergencies,
wireless data patterns may assist network operators and emergency planners who
want to provide the best possible services to the community. We have been
careful to preserve privacy throughout this work by using only anonymous and
aggregate data.
</dc:description>
 <dc:description>Comment: 24 pages, 10 figures, added 1 sentence to abstract, corrected font
  issues</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2015-06-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02463</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02485</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Do Deep CNNs Learn About Objects?</dc:title>
 <dc:creator>Peng, Xingchao</dc:creator>
 <dc:creator>Sun, Baochen</dc:creator>
 <dc:creator>Ali, Karim</dc:creator>
 <dc:creator>Saenko, Kate</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep convolutional neural networks learn extremely powerful image
representations, yet most of that power is hidden in the millions of deep-layer
parameters. What exactly do these parameters represent? Recent work has started
to analyse CNN representations, finding that, e.g., they are invariant to some
2D transformations Fischer et al. (2014), but are confused by particular types
of image noise Nguyen et al. (2014). In this work, we delve deeper and ask: how
invariant are CNNs to object-class variations caused by 3D shape, pose, and
photorealism?
</dc:description>
 <dc:description>Comment: 2 pages workshop paper. arXiv admin note: substantial text overlap
  with arXiv:1412.7122</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02485</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02490</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Twitter for Low-Resource Conversational Speech Language
  Modeling</dc:title>
 <dc:creator>Jaech, Aaron</dc:creator>
 <dc:creator>Ostendorf, Mari</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In applications involving conversational speech, data sparsity is a limiting
factor in building a better language model. We propose a simple,
language-independent method to quickly harvest large amounts of data from
Twitter to supplement a smaller training set that is more closely matched to
the domain. The techniques lead to a significant reduction in perplexity on
four low-resource languages even though the presence on Twitter of these
languages is relatively small. We also find that the Twitter text is more
useful for learning word classes than the in-domain text and that use of these
word classes leads to further reductions in perplexity. Additionally, we
introduce a method of using social and textual information to prioritize the
download queue during the Twitter crawling. This maximizes the amount of useful
data that can be collected, impacting both perplexity and vocabulary coverage.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02491</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Line-Broadcasting in Complete k-Trees</dc:title>
 <dc:creator>Shabtai, Revital Hollander</dc:creator>
 <dc:creator>Roditty, Yehuda</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A line-broadcasting model in a connected graph $G=(V,E)$, $|V|=n$, is a model
in which one vertex, called the {\it originator} of the broadcast holds a
message that has to be transmitted to all vertices of the graph through
placement of a series of calls over the graph. In this model, an informed
vertex can transmit a message through a path of any length in a single time
unit, as long as two transmissions do not use the same edge at the same time.
Farley \cite{f} has shown that the process is completed within at most $\lceil
\log_{2}n \rceil$ time units from any originator in a tree (and thus in any
connected undirected graph). and that the cost of broadcasting one message from
any vertex is at most $(n-1) \lceil \log_{2}n \rceil$.
  In this paper, we present lower and upper bounds for the cost to broadcast
one message in a complete $k-$tree, from any vertex using the line-broadcasting
model. We prove that if $B(u)$ is the minimum cost to broadcast in a graph
$G=(V,E)$ from a vertex $u \in V$ using the line-broadcasting model, then
$(1+o(1))n \le B(u) \le (2+o(1))n$, where $u$ is any vertex in a complete
$k$-tree. Furthermore, for certain conditions, $B(u) \le (2-o(1))n$.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02502</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Overview of Integral Quadratic Constraints for Delayed Nonlinear and
  Parameter-Varying Systems</dc:title>
 <dc:creator>Pfifer, Harald</dc:creator>
 <dc:creator>Seiler, Peter</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  A general framework is presented for analyzing the stability and performance
of nonlinear and linear parameter varying (LPV) time delayed systems. First,
the input/output behavior of the time delay operator is bounded in the
frequency domain by integral quadratic constraints (IQCs). A constant delay is
a linear, time-invariant system and this leads to a simple, intuitive
interpretation for these frequency domain constraints. This simple
interpretation is used to derive new IQCs for both constant and varying delays.
Second, the performance of nonlinear and LPV delayed systems is bounded using
dissipation inequalities that incorporate IQCs. This step makes use of recent
results that show, under mild technical conditions, that an IQC has an
equivalent representation as a finite-horizon time-domain constraint. Numerical
examples are provided to demonstrate the effectiveness of the method for both
class of systems.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02502</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02504</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Spectral Radius Ratio for Node Degree to Analyze the Evolution of
  Scale Free Networks and Small World Networks</dc:title>
 <dc:creator>Meghanathan, Natarajan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In this paper, we show the evaluation of the spectral radius for node degree
as the basis to analyze the variation in the node degrees during the evolution
of scale-free networks and small-world networks. Spectral radius is the
principal eigenvalue of the adjacency matrix of a network graph and spectral
radius ratio for node degree is the ratio of the spectral radius and the
average node degree. We observe a very high positive correlation between the
spectral radius ratio for node degree and the coefficient of variation of node
degree (ratio of the standard deviation of node degree and average node
degree). We show how the spectral radius ratio for node degree can be used as
the basis to tune the operating parameters of the evolution models for
scale-free networks and small-world networks as well as evaluate the impact of
the number of links added per node introduced during the evolution of a
scale-free network and evaluate the impact of the probability of rewiring
during the evolution of a small-world network from a regular network.
</dc:description>
 <dc:description>Comment: 8 pages, 8 figures, Second International Conference on Computer
  Science and Information Technology, (COSIT-2015), Geneva, Switzerland, March
  21-22, 2015</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02504</dc:identifier>
 <dc:identifier>doi:10.5121/csit.2015.50603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02511</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application of the war of attrition game to the analysis of intellectual
  property disputes</dc:title>
 <dc:creator>Ch&#xe1;vez-Angeles, Manuel G.</dc:creator>
 <dc:creator>S&#xe1;nchez-Medina, Patricia S.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Quantitative Finance - General Finance</dc:subject>
 <dc:description>  In many developing countries intellectual property infringement and the
commerce of pirate goods is an entrepreneurial activity. Digital piracy is very
often the only media for having access to music, cinema, books and software. At
the same time, bio-prospecting and infringement of indigenous knowledge rights
by international consortiums is usual in places with high biodiversity. In
these arenas transnational actors interact with local communities. Accusations
of piracy often go both ways. This article analyzes the case of southeast
Mexico. Using a war of attrition game theory model it explains different
situations of intellectual property rights piracy and protection. It analyzes
different levels of interaction and institutional settings from the global to
the very local. The article proposes free IP zones as a solution of IP
disputes. The formation of technological local clusters through Free
Intellectual Property Zones (FIPZ) would allow firms to copy and share de facto
public domain content for developing new products inside the FIPZ. Enforcement
of intellectual property could be pursuit outside of the FIPZ. FIPZ are
envisioned as a new type of a sui generis intellectual property regime.
</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02511</dc:identifier>
 <dc:identifier>International Journal of Game Theory and Technology (IJGTT),
  Vol.3, No.1, March 2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02514</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stronger Impossibility Results for Strategy-Proof Voting with i.i.d.
  Beliefs</dc:title>
 <dc:creator>Leung, Samantha</dc:creator>
 <dc:creator>Lui, Edward</dc:creator>
 <dc:creator>Pass, Rafael</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The classic Gibbard-Satterthwaite theorem says that every strategy-proof
voting rule with at least three possible candidates must be dictatorial. In
\cite{McL11}, McLennan showed that a similar impossibility result holds even if
we consider a weaker notion of strategy-proofness where voters believe that the
other voters' preferences are i.i.d.~(independent and identically distributed):
If an anonymous voting rule (with at least three candidates) is strategy-proof
w.r.t.~all i.i.d.~beliefs and is also Pareto efficient, then the voting rule
must be a random dictatorship. In this paper, we strengthen McLennan's result
by relaxing Pareto efficiency to $\epsilon$-Pareto efficiency where Pareto
efficiency can be violated with probability $\epsilon$, and we further relax
$\epsilon$-Pareto efficiency to a very weak notion of efficiency which we call
$\epsilon$-super-weak unanimity. We then show the following: If an anonymous
voting rule (with at least three candidates) is strategy-proof w.r.t.~all
i.i.d.~beliefs and also satisfies $\epsilon$-super-weak unanimity, then the
voting rule must be $O(\epsilon)$-close to random dictatorship.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1405.5827</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02514</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02517</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Survey of Operating Systems for the IoT Environment</dc:title>
 <dc:creator>Borgohain, Tuhin</dc:creator>
 <dc:creator>Kumar, Uday</dc:creator>
 <dc:creator>Sanyal, Sugata</dc:creator>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  This paper is a comprehensive survey of the various operating systems
available for the Internet of Things environment. At first the paper introduces
the various aspects of the operating systems designed for the IoT environment
where resource constraint poses a huge problem for the operation of the general
OS designed for the various computing devices. The latter part of the paper
describes the various OS available for the resource constraint IoT environment
along with the various platforms each OS supports, the software development
kits available for the development of applications in the respective OS along
with the various protocols implemented in these OS for the purpose of
communication and networking.
</dc:description>
 <dc:description>Comment: 5 pages, 7 tables</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02517</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02518</identifier>
 <datestamp>2015-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Feature Learning from Temporal Data</dc:title>
 <dc:creator>Goroshin, Ross</dc:creator>
 <dc:creator>Bruna, Joan</dc:creator>
 <dc:creator>Tompson, Jonathan</dc:creator>
 <dc:creator>Eigen, David</dc:creator>
 <dc:creator>LeCun, Yann</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Current state-of-the-art classification and detection algorithms rely on
supervised training. In this work we study unsupervised feature learning in the
context of temporally coherent video data. We focus on feature learning from
unlabeled video data, using the assumption that adjacent video frames contain
semantically similar information. This assumption is exploited to train a
convolutional pooling auto-encoder regularized by slowness and sparsity. We
establish a connection between slow feature learning to metric learning and
show that the trained encoder can be used to define a more temporally and
semantically coherent metric.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1412.6056</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2015-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02518</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02523</identifier>
 <datestamp>2015-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Clustering RDF Databases Using Tunable-LSH</dc:title>
 <dc:creator>Alu&#xe7;, G&#xfc;ne&#x15f;</dc:creator>
 <dc:creator>&#xd6;zsu, M. Tamer</dc:creator>
 <dc:creator>Daudjee, Khuzaima</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  The Resource Description Framework (RDF) is a W3C standard for representing
graph-structured data, and SPARQL is the standard query language for RDF.
Recent advances in Information Extraction, Linked Data Management and the
Semantic Web have led to a rapid increase in both the volume and the variety of
RDF data that are publicly available. As businesses start to capitalize on RDF
data, RDF data management systems are being exposed to workloads that are far
more diverse and dynamic than what they were designed to handle. Consequently,
there is a growing need for developing workload-adaptive and self-tuning RDF
data management systems. To realize this vision, we introduce a fast and
efficient method for dynamically clustering records in an RDF data management
system. Specifically, we assume nothing about the workload upfront, but as
SPARQL queries are executed, we keep track of records that are co-accessed by
the queries in the workload and physically cluster them. To decide dynamically
(hence, in constant-time) where a record needs to be placed in the storage
system, we develop a new locality-sensitive hashing (LSH) scheme, Tunable-LSH.
Using Tunable-LSH, records that are co-accessed across similar sets of queries
can be hashed to the same or nearby physical pages in the storage system. What
sets Tunable-LSH apart from existing LSH schemes is that it can auto-tune to
achieve the aforementioned clustering objective with high accuracy even when
the workloads change. Experimental evaluation of Tunable-LSH in our prototype
RDF data management system, chameleon-db, as well as in a standalone hashtable
shows significant end-to-end improvements over existing solutions.
</dc:description>
 <dc:description>Comment: Fixed typos, updated related work section</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2015-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02526</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Arbitrary Statistical Mixtures of Discrete Distributions</dc:title>
 <dc:creator>Li, Jian</dc:creator>
 <dc:creator>Rabani, Yuval</dc:creator>
 <dc:creator>Schulman, Leonard J.</dc:creator>
 <dc:creator>Swamy, Chaitanya</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the problem of learning from unlabeled samples very general
statistical mixture models on large finite sets. Specifically, the model to be
learned, $\vartheta$, is a probability distribution over probability
distributions $p$, where each such $p$ is a probability distribution over $[n]
= \{1,2,\dots,n\}$. When we sample from $\vartheta$, we do not observe $p$
directly, but only indirectly and in very noisy fashion, by sampling from $[n]$
repeatedly, independently $K$ times from the distribution $p$. The problem is
to infer $\vartheta$ to high accuracy in transportation (earthmover) distance.
  We give the first efficient algorithms for learning this mixture model
without making any restricting assumptions on the structure of the distribution
$\vartheta$. We bound the quality of the solution as a function of the size of
the samples $K$ and the number of samples used. Our model and results have
applications to a variety of unsupervised learning scenarios, including
learning topic models and collaborative filtering.
</dc:description>
 <dc:description>Comment: 23 pages. Preliminary version in the Proceeding of the 47th ACM
  Symposium on the Theory of Computing (STOC15)</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02526</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02530</identifier>
 <datestamp>2016-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classifying Unrooted Gaussian Trees under Privacy Constraints</dc:title>
 <dc:creator>Moharrer, A.</dc:creator>
 <dc:creator>Wei, S.</dc:creator>
 <dc:creator>Amariucai, G. T.</dc:creator>
 <dc:creator>Deng, J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, our objective is to find out how topological and algebraic
properties of unrooted Gaussian tree models determine their security
robustness, which is measured by our proposed max-min information (MaMI)
metric. Such metric quantifies the amount of common randomness extractable
through public discussion between two legitimate nodes under an eavesdropper
attack. We show some general topological properties that the desired max-min
solutions shall satisfy. Under such properties, we develop conditions under
which comparable trees are put together to form partially ordered sets
(posets). Each poset contains the most favorable structure as the poset leader,
and the least favorable structure. Then, we compute the Tutte-like polynomial
for each tree in a poset in order to assign a polynomial to any tree in a
poset. Moreover, we propose a novel method, based on restricted integer
partitions, to effectively enumerate all poset leaders. The results not only
help us understand the security strength of different Gaussian trees, which is
critical when we evaluate the information leakage issues for various jointly
Gaussian distributed measurements in networks, but also provide us both an
algebraic and a topological perspective in grasping some fundamental properties
of such models.
</dc:description>
 <dc:description>Comment: 12 pages, 7 figures, part of this work is submitted to IEEE Globecom
  2015, San Diego, CA, USA</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2016-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02531</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HEp-2 Cell Image Classification with Deep Convolutional Neural Networks</dc:title>
 <dc:creator>Gao, Zhimin</dc:creator>
 <dc:creator>Wang, Lei</dc:creator>
 <dc:creator>Zhou, Luping</dc:creator>
 <dc:creator>Zhang, Jianjia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Efficient Human Epithelial-2 (HEp-2) cell image classification can facilitate
the diagnosis of many autoimmune diseases. This paper presents an automatic
framework for this classification task, by utilizing the deep convolutional
neural networks (CNNs) which have recently attracted intensive attention in
visual recognition. This paper elaborates the important components of this
framework, discusses multiple key factors that impact the efficiency of
training a deep CNN, and systematically compares this framework with the
well-established image classification models in the literature. Experiments on
benchmark datasets show that i) the proposed framework can effectively
outperform existing models by properly applying data augmentation; ii) our
CNN-based framework demonstrates excellent adaptability across different
datasets, which is highly desirable for classification under varying laboratory
settings. Our system is ranked high in the cell image classification
competition hosted by ICPR 2014.
</dc:description>
 <dc:description>Comment: 32 pages</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2015-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02531</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02532</identifier>
 <datestamp>2015-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Design of Switched Networks of Positive Linear Systems via
  Geometric Programming</dc:title>
 <dc:creator>Ogura, Masaki</dc:creator>
 <dc:creator>Preciado, Victor M.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this paper, we propose an optimization framework to design a network of
positive linear systems whose structure switches according to a Markov process.
The optimization framework herein proposed allows the network designer to
optimize the coupling elements of a directed network, as well as the dynamics
of the nodes in order to maximize the stabilization rate of the network and/or
the disturbance rejection against an exogenous input. The cost of implementing
a particular network is modeled using posynomial cost functions, which allow
for a wide variety of modeling options. In this context, we show that the
cost-optimal network design can be efficiently found using geometric
programming in polynomial time. We illustrate our results with a practical
problem in network epidemiology, namely, the cost-optimal stabilization of the
spread of a disease over a time-varying contact network.
</dc:description>
 <dc:description>Comment: Accepted for publications in IEEE Transactions on Control of Network
  Systems</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2015-09-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02532</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02536</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Equivocations, Exponents and Second-Order Coding Rates under Various
  R\'enyi Information Measures</dc:title>
 <dc:creator>Hayashi, Masahito</dc:creator>
 <dc:creator>Tan, Vincent Y. F.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We evaluate the asymptotics of equivocations, their exponents as well as
their second-order coding rates under various R\'{e}nyi information measures.
Specifically, we consider the effect of applying a hash function on a source
and we quantify the level of non-uniformity and dependence of the compressed
source from another correlated source when the number of copies of the sources
is large. Unlike previous works that use Shannon information measures to
quantify randomness, information or uniformity, we define our security measures
in terms of a more general class of information measures--the R\'{e}nyi
information measures and their Gallager-type counterparts. A special case of
these R\'{e}nyi information measure is the class of Shannon information
measures. We prove tight asymptotic results for the security measures and their
exponential rates of decay. We also prove bounds on the second-order
asymptotics and show that these bounds match when the magnitudes of the
second-order coding rates are large. We do so by establishing new classes
non-asymptotic bounds on the equivocation and evaluating these bounds using
various probabilistic limit theorems asymptotically.
</dc:description>
 <dc:description>Comment: 47 pages, 9 figures; Presented at the 2015 International Symposium on
  Information Theory (Hong Kong); Submitted to the IEEE Transactions on
  Information Theory; v3: fixed typos and added some clarifications to the
  proofs</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02547</identifier>
 <datestamp>2015-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Byzantine Agreement with Optimal Early Stopping, Optimal Resilience and
  Polynomial Complexity</dc:title>
 <dc:creator>Abraham, Ittai</dc:creator>
 <dc:creator>Dolev, Danny</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We provide the first protocol that solves Byzantine agreement with optimal
early stopping ($\min\{f+2,t+1\}$ rounds) and optimal resilience ($n&gt;3t$) using
polynomial message size and computation.
  All previous approaches obtained sub-optimal results and used resolve rules
that looked only at the immediate children in the EIG (\emph{Exponential
Information Gathering}) tree. At the heart of our solution are new resolve
rules that look at multiple layers of the EIG tree.
</dc:description>
 <dc:description>Comment: full version of STOC 2015 abstract</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02549</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A dynamical systems approach to the discrimination of the modes of
  operation of cryptographic systems</dc:title>
 <dc:creator>Machicao, Jeaneth</dc:creator>
 <dc:creator>Baetens, Jan M.</dc:creator>
 <dc:creator>Marco, Anderson G.</dc:creator>
 <dc:creator>De Baets, Bernard</dc:creator>
 <dc:creator>Bruno, Odemir M.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  Evidence of signatures associated with cryptographic modes of operation is
established. Motivated by some analogies between cryptographic and dynamical
systems, in particular with chaos theory, we propose an algorithm based on
Lyapunov exponents of discrete dynamical systems to estimate the divergence
among ciphertexts as the encryption algorithm is applied iteratively. The
results allow to distinguish among six modes of operation, namely ECB, CBC,
OFB, CFB, CTR and PCBC using DES, IDEA, TEA and XTEA block ciphers of 64 bits,
as well as AES, RC6, Twofish, Seed, Serpent and Camellia block ciphers of 128
bits. Furthermore, the proposed methodology enables a classification of modes
of operation of cryptographic systems according to their strength.
</dc:description>
 <dc:description>Comment: 14 pages, 10 figures</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02555</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time Critical Multitasking for Multicore Microcontroller using XMOS Kit</dc:title>
 <dc:creator>Saini, Prerna</dc:creator>
 <dc:creator>Bansal, Ankit</dc:creator>
 <dc:creator>Sharma, Abhishek</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This paper presents the research work on multicore microcontrollers using
parallel, and time critical programming for the embedded systems. Due to the
high complexity and limitations, it is very hard to work on the application
development phase on such architectures. The experimental results mentioned in
the paper are based on xCORE multicore microcontroller form XMOS. The paper
also imitates multi-tasking and parallel programming for the same platform. The
tasks assigned to multiple cores are executed simultaneously, which saves the
time and energy. The relative study for multicore processor and multicore
controller concludes that micro architecture based controller having multiple
cores illustrates better performance in time critical multi-tasking
environment. The research work mentioned here not only illustrates the
functionality of multicore microcontroller, but also express the novel
technique of programming, profiling and optimization on such platforms in real
time environments.
</dc:description>
 <dc:description>Comment: 18 pages, 18 figure, 9 tables,</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02555</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02564</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster Algorithms for the Constrained k-means Problem</dc:title>
 <dc:creator>Bhattacharya, Anup</dc:creator>
 <dc:creator>Jaiswal, Ragesh</dc:creator>
 <dc:creator>Kumar, Amit</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The classical center based clustering problems such as
$k$-means/median/center assume that the optimal clusters satisfy the locality
property that the points in the same cluster are close to each other. A number
of clustering problems arise in machine learning where the optimal clusters do
not follow such a locality property. Consider a variant of the $k$-means
problem that may be regarded as a general version of such problems. Here, the
optimal clusters $O_1, ..., O_k$ are an arbitrary partition of the dataset and
the goal is to output $k$-centers $c_1, ..., c_k$ such that the objective
function $\sum_{i=1}^{k} \sum_{x \in O_{i}} ||x - c_{i}||^2$ is minimized. It
is not difficult to argue that any algorithm (without knowing the optimal
clusters) that outputs a single set of $k$ centers, will not behave well as far
as optimizing the above objective function is concerned. However, this does not
rule out the existence of algorithms that output a list of such $k$ centers
such that at least one of these $k$ centers behaves well. Given an error
parameter $\varepsilon &gt; 0$, let $\ell$ denote the size of the smallest list of
$k$-centers such that at least one of the $k$-centers gives a $(1+\varepsilon)$
approximation w.r.t. the objective function above. In this paper, we show an
upper bound on $\ell$ by giving a randomized algorithm that outputs a list of
$2^{\tilde{O}(k/\varepsilon)}$ $k$-centers. We also give a closely matching
lower bound of $2^{\tilde{\Omega}(k/\sqrt{\varepsilon})}$. Moreover, our
algorithm runs in time $O \left(n d \cdot 2^{\tilde{O}(k/\varepsilon)}
\right)$. This is a significant improvement over the previous result of Ding
and Xu who gave an algorithm with running time $O \left(n d \cdot (\log{n})^{k}
\cdot 2^{poly(k/\varepsilon)} \right)$ and output a list of size $O
\left((\log{n})^k \cdot 2^{poly(k/\varepsilon)} \right)$.
</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02576</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Highly-cited papers in Library and Information Science (LIS): Authors,
  institutions, and network structures</dc:title>
 <dc:creator>Bauer, Johann</dc:creator>
 <dc:creator>Leydesdorff, Loet</dc:creator>
 <dc:creator>Bornmann, Lutz</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  As a follow-up to the highly-cited authors list published by Thomson Reuters
in June 2014, we analyze the top-1% most frequently cited papers published
between 2002 and 2012 included in the Web of Science (WoS) subject category
&quot;Information Science &amp; Library Science.&quot; 798 authors contributed to 305 top-1%
publications; these authors were employed at 275 institutions. The authors at
Harvard University contributed the largest number of papers, when the addresses
are whole-number counted. However, Leiden University leads the ranking, if
fractional counting is used.
  Twenty-three of the 798 authors were also listed as most highly-cited authors
by Thomson Reuters in June 2014 (http://highlycited.com/). Twelve of these 23
authors were involved in publishing four or more of the 305 papers under study.
Analysis of co-authorship relations among the 798 highly-cited scientists shows
that co-authorships are based on common interests in a specific topic. Three
topics were important between 2002 and 2012: (1) collection and exploitation of
information in clinical practices, (2) the use of internet in public
communication and commerce, and (3) scientometrics.
</dc:description>
 <dc:description>Comment: accepted for publication in the Journal of the Association for
  Information Science and Technology (JASIST)</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02577</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Panther: Fast Top-k Similarity Search in Large Networks</dc:title>
 <dc:creator>Zhang, Jing</dc:creator>
 <dc:creator>Tang, Jie</dc:creator>
 <dc:creator>Ma, Cong</dc:creator>
 <dc:creator>Tong, Hanghang</dc:creator>
 <dc:creator>Jing, Yu</dc:creator>
 <dc:creator>Li, Juanzi</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Estimating similarity between vertices is a fundamental issue in network
analysis across various domains, such as social networks and biological
networks. Methods based on common neighbors and structural contexts have
received much attention. However, both categories of methods are difficult to
scale up to handle large networks (with billions of nodes). In this paper, we
propose a sampling method that provably and accurately estimates the similarity
between vertices. The algorithm is based on a novel idea of random path, and an
extended method is also presented, to enhance the structural similarity when
two vertices are completely disconnected. We provide theoretical proofs for the
error-bound and confidence of the proposed algorithm. We perform extensive
empirical study and show that our algorithm can obtain top-k similar vertices
for any vertex in a network approximately 300x faster than state-of-the-art
methods. We also use identity resolution and structural hole spanner finding,
two important applications in social networks, to evaluate the accuracy of the
estimated similarities. Our experimental results demonstrate that the proposed
algorithm achieves clearly better performance than several alternative methods.
</dc:description>
 <dc:description>Comment: 10 pages, 10 figures</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02578</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blade: A Data Center Garbage Collector</dc:title>
 <dc:creator>Terei, David</dc:creator>
 <dc:creator>Levy, Amit</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:subject>D.4.2</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:description>  An increasing number of high-performance distributed systems are written in
garbage collected languages. This removes a large class of harmful bugs from
these systems. However, it also introduces high tail-latency do to garbage
collection pause times. We address this problem through a new technique of
garbage collection avoidance which we call Blade. Blade is an API between the
collector and application developer that allows developers to leverage existing
failure recovery mechanisms in distributed systems to coordinate collection and
bound the latency impact. We describe Blade and implement it for the Go
programming language. We also investigate two different systems that utilize
Blade, a HTTP load-balancer and the Raft consensus algorithm. For the
load-balancer, we eliminate any latency introduced by the garbage collector,
for Raft, we bound the latency impact to a single network round-trip, (48
{\mu}s in our setup). In both cases, latency at the tail using Blade is up to
three orders of magnitude better.
</dc:description>
 <dc:description>Comment: 14 pages, 9 figures</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02583</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A stronger bound for the strong chromatic index</dc:title>
 <dc:creator>Bruhn, Henning</dc:creator>
 <dc:creator>Joos, Felix</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We prove $\chi_s'(G)\leq 1.93 \Delta(G)^2$ for graphs of sufficiently large
maximum degree where $\chi_s'(G)$ is the strong chromatic index of $G$. This
improves an old bound of Molloy and Reed. As a by-product, we present a
Talagrand-type inequality where it is allowed to exclude unlikely bad outcomes
that would otherwise render the inequality unusable.
</dc:description>
 <dc:description>Comment: 22 pages</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02587</identifier>
 <datestamp>2016-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stop It, and Be Stubborn!</dc:title>
 <dc:creator>Valmari, Antti</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>68Q60, 68Q85, 68N30</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:description>  A system is AG EF terminating, if and only if from every reachable state, a
terminal state is reachable. This publication argues that it is beneficial for
both catching non-progress errors and stubborn set state space reduction to try
to make verification models AG EF terminating. An incorrect mutual exclusion
algorithm is used as an example. The error does not manifest itself, unless the
first action of the customers is modelled differently from other actions. An
appropriate method is to add an alternative first action that models the
customer stopping for good. This method typically makes the model AG EF
terminating. If the model is AG EF terminating, then the basic strong stubborn
set method preserves safety and some progress properties without any additional
condition for solving the ignoring problem. Furthermore, whether the model is
AG EF terminating can be checked efficiently from the reduced state space.
</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02587</dc:identifier>
 <dc:identifier>ACSD 2015, 15th IEEE International Conference on Application of
  Concurrency to System Design, pp. 10-19</dc:identifier>
 <dc:identifier>doi:10.1109/ACSD.2015.14</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02590</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Study of Some Recent Crossovers Effects on Speed and Accuracy of Genetic
  Algorithm, Using Symmetric Travelling Salesman Problem</dc:title>
 <dc:creator>Ismkhan, Hassan</dc:creator>
 <dc:creator>Zamanifar, Kamran</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The Travelling Salesman Problem (TSP) is one of the most famous optimization
problems. The Genetic Algorithm (GA) is one of metaheuristics that have been
applied to TSP. The Crossover and mutation operators are two important elements
of GA. There are many TSP solver crossover operators. In this paper, we state
implementation of some recent TSP solver crossovers at first and then we use
each of them in GA to solve some Symmetric TSP (STSP) instances and finally
compare their effects on speed and accuracy of presented GA.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1209.5339</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02590</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02597</identifier>
 <datestamp>2016-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A State Space Tool for Models Expressed In C++ (tool paper)</dc:title>
 <dc:creator>Valmari, Antti</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>68Q60, 68Q85, 68N30</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:description>  This publication introduces A State Space Exploration Tool that is based on
representing the model under verification as a piece of C++ code that obeys
certain conventions. Its name is ASSET. Model checking takes place by compiling
the model and the tool together, and executing the result. This approach
facilitates very fast execution of the transitions of the model. On the other
hand, the use of stubborn sets and symmetries requires that either the modeller
or a preprocessor tool analyses the model at a syntactic level and expresses
stubborn set obligation rules and the symmetry mapping as suitable C++
functions. The tool supports the detection of illegal deadlocks, safety errors,
and may progress errors. It also partially supports the detection of must
progress errors.
</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02597</dc:identifier>
 <dc:identifier>CEUR Workshop Proceedings Vol-1525 2015, pp. 91-105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02602</identifier>
 <datestamp>2017-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algebraic solution of tropical optimization problems via matrix
  sparsification with application to scheduling</dc:title>
 <dc:creator>Krivulin, Nikolai</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>65K10 (Primary), 15A80, 65F50, 90B35, 90C48 (Secondary)</dc:subject>
 <dc:description>  Optimization problems are considered in the framework of tropical algebra to
minimize and maximize a nonlinear objective function defined on vectors over an
idempotent semifield, and calculated using multiplicative conjugate
transposition. To find the minimum of the function, we first obtain a partial
solution, which explicitly represents a subset of solution vectors. We
characterize all solutions by a system of simultaneous equation and inequality,
and show that the solution set is closed under vector addition and scalar
multiplication. A matrix sparsification technique is proposed to extend the
partial solution, and then to obtain a complete solution described as a family
of subsets. We offer a backtracking procedure that generates all members of the
family, and derive an explicit representation for the complete solution. As
another result, we deduce a complete solution of the maximization problem,
given in a compact vector form by the use of sparsified matrices. The results
obtained are illustrated with illuminating examples and graphical
representations. We apply the results to solve real-world problems drawn from
project (machine) scheduling, and give numerical examples.
</dc:description>
 <dc:description>Comment: 36 pages, 4 figures, solution to maximization problem added</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:date>2017-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02602</dc:identifier>
 <dc:identifier>Journal of Logical and Algebraic Methods in Programming, Vol.89,
  P.150-170 (2017)</dc:identifier>
 <dc:identifier>doi:10.1016/j.jlamp.2017.03.004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02603</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple Parallel Implementation of Interaction Nets in Haskell</dc:title>
 <dc:creator>Kahl, Wolfram</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Due to their &quot;inherent parallelism&quot;, interaction nets have since their
introduction been considered as an attractive implementation mechanism for
functional programming. We show that a simple highly-concurrent implementation
in Haskell can achieve promising speed-ups on multiple cores.
</dc:description>
 <dc:description>Comment: In Proceedings DCM 2014, arXiv:1504.01927</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02603</dc:identifier>
 <dc:identifier>EPTCS 179, 2015, pp. 33-47</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.179.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02605</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lempel Ziv Computation In Small Space (LZ-CISS)</dc:title>
 <dc:creator>Fischer, Johannes</dc:creator>
 <dc:creator>I, Tomohiro</dc:creator>
 <dc:creator>K&#xf6;ppl, Dominik</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  For both the Lempel Ziv 77- and 78-factorization we propose algorithms
generating the respective factorization using $(1+\epsilon) n \lg n + O(n)$
bits (for any positive constant $\epsilon \le 1$) working space (including the
space for the output) for any text of size \$n\$ over an integer alphabet in
$O(n / \epsilon^{2})$ time.
</dc:description>
 <dc:description>Comment: Full Version of CPM 2015 paper</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02605</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02608</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotic Estimates in Information Theory with Non-Vanishing Error
  Probabilities</dc:title>
 <dc:creator>Tan, Vincent Y. F.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This monograph presents a unified treatment of single- and multi-user
problems in Shannon's information theory where we depart from the requirement
that the error probability decays asymptotically in the blocklength. Instead,
the error probabilities for various problems are bounded above by a
non-vanishing constant and the spotlight is shone on achievable coding rates as
functions of the growing blocklengths. This represents the study of asymptotic
estimates with non-vanishing error probabilities.
  In Part I, after reviewing the fundamentals of information theory, we discuss
Strassen's seminal result for binary hypothesis testing where the type-I error
probability is non-vanishing and the rate of decay of the type-II error
probability with growing number of independent observations is characterized.
In Part II, we use this basic hypothesis testing result to develop second- and
sometimes, even third-order asymptotic expansions for point-to-point
communication. Finally in Part III, we consider network information theory
problems for which the second-order asymptotics are known. These problems
include some classes of channels with random state, the multiple-encoder
distributed lossless source coding (Slepian-Wolf) problem and special cases of
the Gaussian interference and multiple-access channels. Finally, we discuss
avenues for further research.
</dc:description>
 <dc:description>Comment: Further comments welcome</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02608</dc:identifier>
 <dc:identifier>Foundations and Trends in Communications and Information Theory,
  Vol. 11, Nos. 1-2, 2014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02609</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LazyCtrl: Scalable Network Control for Cloud Data Centers</dc:title>
 <dc:creator>Zheng, Kai</dc:creator>
 <dc:creator>Wang, Lin</dc:creator>
 <dc:creator>Yang, Baohua</dc:creator>
 <dc:creator>Sun, Yi</dc:creator>
 <dc:creator>Zhang, Yue</dc:creator>
 <dc:creator>Uhlig, Steve</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The advent of software defined networking enables flexible, reliable and
feature-rich control planes for data center networks. However, the tight
coupling of centralized control and complete visibility leads to a wide range
of issues among which scalability has risen to prominence. To address this, we
present LazyCtrl, a novel hybrid control plane design for data center networks
where network control is carried out by distributed control mechanisms inside
independent groups of switches while complemented with a global controller. Our
design is motivated by the observation that data center traffic is usually
highly skewed and thus edge switches can be grouped according to traffic
locality. LazyCtrl aims at bringing laziness to the global controller by
dynamically devolving most of the control tasks to independent switch groups to
process frequent intra-group events near datapaths while handling rare
inter-group or other specified events by the controller. We implement LazyCtrl
and build a prototype based on Open vSwich and Floodlight. Trace-driven
experiments on our prototype show that an effective switch grouping is easy to
maintain in multi-tenant clouds and the central controller can be significantly
shielded by staying lazy, with its workload reduced by up to 82%.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02609</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02610</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Confluence Detection for Transformations of Labelled Transition Systems</dc:title>
 <dc:creator>Wijs, Anton</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  The development of complex component software systems can be made more
manageable by first creating an abstract model and then incrementally adding
details. Model transformation is an approach to add such details in a
controlled way. In order for model transformation systems to be useful, it is
crucial that they are confluent, i.e. that when applied on a given model, they
will always produce a unique output model, independent of the order in which
rules of the system are applied on the input. In this work, we consider
Labelled Transition Systems (LTSs) to reason about the semantics of models, and
LTS transformation systems to reason about model transformations. In related
work, the problem of confluence detection has been investigated for general
graph structures. We observe, however, that confluence can be detected more
efficiently in special cases where the graphs have particular structural
properties. In this paper, we present a number of observations to detect
confluence of LTS transformation systems, and propose both a new confluence
detection algorithm and a conflict resolution algorithm based on them.
</dc:description>
 <dc:description>Comment: In Proceedings GaM 2015, arXiv:1504.02448</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02610</dc:identifier>
 <dc:identifier>EPTCS 181, 2015, pp. 1-15</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.181.1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02611</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Practical Graph-Based Verification for an Object-Oriented
  Concurrency Model</dc:title>
 <dc:creator>Heu&#xdf;ner, Alexander</dc:creator>
 <dc:creator>Poskitt, Christopher M.</dc:creator>
 <dc:creator>Corrodi, Claudio</dc:creator>
 <dc:creator>Morandi, Benjamin</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  To harness the power of multi-core and distributed platforms, and to make the
development of concurrent software more accessible to software engineers,
different object-oriented concurrency models such as SCOOP have been proposed.
Despite the practical importance of analysing SCOOP programs, there are
currently no general verification approaches that operate directly on program
code without additional annotations. One reason for this is the multitude of
partially conflicting semantic formalisations for SCOOP (either in theory or
by-implementation). Here, we propose a simple graph transformation system (GTS)
based run-time semantics for SCOOP that grasps the most common features of all
known semantics of the language. This run-time model is implemented in the
state-of-the-art GTS tool GROOVE, which allows us to simulate, analyse, and
verify a subset of SCOOP programs with respect to deadlocks and other
behavioural properties. Besides proposing the first approach to verify SCOOP
programs by automatic translation to GTS, we also highlight our experiences of
applying GTS (and especially GROOVE) for specifying semantics in the form of a
run-time model, which should be transferable to GTS models for other concurrent
languages and libraries.
</dc:description>
 <dc:description>Comment: In Proceedings GaM 2015, arXiv:1504.02448</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02611</dc:identifier>
 <dc:identifier>EPTCS 181, 2015, pp. 32-47</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.181.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02612</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Visual Analytics Approach to Compare Propagation Models in Social
  Networks</dc:title>
 <dc:creator>Vallet, Jason</dc:creator>
 <dc:creator>Kirchner, H&#xe9;l&#xe8;ne</dc:creator>
 <dc:creator>Pinaud, Bruno</dc:creator>
 <dc:creator>Melan&#xe7;on, Guy</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Numerous propagation models describing social influence in social networks
can be found in the literature. This makes the choice of an appropriate model
in a given situation difficult. Selecting the most relevant model requires the
ability to objectively compare them. This comparison can only be made at the
cost of describing models based on a common formalism and yet independent from
them. We propose to use graph rewriting to formally describe propagation
mechanisms as local transformation rules applied according to a strategy. This
approach makes sense when it is supported by a visual analytics framework
dedicated to graph rewriting. The paper first presents our methodology to
describe some propagation models as a graph rewriting problem. Then, we
illustrate how our visual analytics framework allows to interactively
manipulate models, and underline their differences based on measures computed
on simulation traces.
</dc:description>
 <dc:description>Comment: In Proceedings GaM 2015, arXiv:1504.02448</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02612</dc:identifier>
 <dc:identifier>EPTCS 181, 2015, pp. 65-79</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.181.5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02613</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Programming on Nominal Graphs</dc:title>
 <dc:creator>Hoch, Nicklas</dc:creator>
 <dc:creator>Montanari, Ugo</dc:creator>
 <dc:creator>Sammartino, Matteo</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Many optimization problems can be naturally represented as (hyper) graphs,
where vertices correspond to variables and edges to tasks, whose cost depends
on the values of the adjacent variables. Capitalizing on the structure of the
graph, suitable dynamic programming strategies can select certain orders of
evaluation of the variables which guarantee to reach both an optimal solution
and a minimal size of the tables computed in the optimization process. In this
paper we introduce a simple algebraic specification with parallel composition
and restriction whose terms up to structural axioms are the graphs mentioned
above. In addition, free (unrestricted) vertices are labelled with variables,
and the specification includes operations of name permutation with finite
support. We show a correspondence between the well-known tree decompositions of
graphs and our terms. If an axiom of scope extension is dropped, several
(hierarchical) terms actually correspond to the same graph. A suitable
graphical structure can be found, corresponding to every hierarchical term.
Evaluating such a graphical structure in some target algebra yields a dynamic
programming strategy. If the target algebra satisfies the scope extension
axiom, then the result does not depend on the particular structure, but only on
the original graph. We apply our approach to the parking optimization problem
developed in the ASCENS e-mobility case study, in collaboration with
Volkswagen. Dynamic programming evaluations are particularly interesting for
autonomic systems, where actual behavior often consists of propagating local
knowledge to obtain global knowledge and getting it back for local decisions.
</dc:description>
 <dc:description>Comment: In Proceedings GaM 2015, arXiv:1504.02448</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02613</dc:identifier>
 <dc:identifier>EPTCS 181, 2015, pp. 80-96</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.181.6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02614</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Conflict Detection for Graph Transformation with Attributes</dc:title>
 <dc:creator>Kulcs&#xe1;r, G&#xe9;za</dc:creator>
 <dc:creator>Deckwerth, Frederik</dc:creator>
 <dc:creator>Lochau, Malte</dc:creator>
 <dc:creator>Varr&#xf3;, Gergely</dc:creator>
 <dc:creator>Sch&#xfc;rr, Andy</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In graph transformation, a conflict describes a situation where two
alternative transformations cannot be arbitrarily serialized. When enriching
graphs with attributes, existing conflict detection techniques typically report
a conflict whenever at least one of two transformations manipulates a shared
attribute. In this paper, we propose an improved, less conservative condition
for static conflict detection of graph transformation with attributes by
explicitly taking the semantics of the attribute operations into account. The
proposed technique is based on symbolic graphs, which extend the traditional
notion of graphs by logic formulas used for attribute handling. The approach is
proven complete, i.e., any potential conflict is guaranteed to be detected.
</dc:description>
 <dc:description>Comment: In Proceedings GaM 2015, arXiv:1504.02448</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02614</dc:identifier>
 <dc:identifier>EPTCS 181, 2015, pp. 97-112</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.181.7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02615</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting and Refactoring Operational Smells within the Domain Name
  System</dc:title>
 <dc:creator>Radwan, Marwan</dc:creator>
 <dc:creator>Heckel, Reiko</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The Domain Name System (DNS) is one of the most important components of the
Internet infrastructure. DNS relies on a delegation-based architecture, where
resolution of names to their IP addresses requires resolving the names of the
servers responsible for those names. The recursive structures of the inter
dependencies that exist between name servers associated with each zone are
called dependency graphs. System administrators' operational decisions have far
reaching effects on the DNSs qualities. They need to be soundly made to create
a balance between the availability, security and resilience of the system. We
utilize dependency graphs to identify, detect and catalogue operational bad
smells. Our method deals with smells on a high-level of abstraction using a
consistent taxonomy and reusable vocabulary, defined by a DNS Operational
Model. The method will be used to build a diagnostic advisory tool that will
detect configuration changes that might decrease the robustness or security
posture of domain names before they become into production.
</dc:description>
 <dc:description>Comment: In Proceedings GaM 2015, arXiv:1504.02448</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02615</dc:identifier>
 <dc:identifier>EPTCS 181, 2015, pp. 113-128</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.181.8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02616</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aggregation by Provenance Types: A Technique for Summarising Provenance
  Graphs</dc:title>
 <dc:creator>Moreau, Luc</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  As users become confronted with a deluge of provenance data, dedicated
techniques are required to make sense of this kind of information. We present
Aggregation by Provenance Types, a provenance graph analysis that is capable of
generating provenance graph summaries. It proceeds by converting provenance
paths up to some length k to attributes, referred to as provenance types, and
by grouping nodes that have the same provenance types. The summary also
includes numeric values representing the frequency of nodes and edges in the
original graph. A quantitative evaluation and a complexity analysis show that
this technique is tractable; with small values of k, it can produce useful
summaries and can help detect outliers. We illustrate how the generated
summaries can further be used for conformance checking and visualization.
</dc:description>
 <dc:description>Comment: In Proceedings GaM 2015, arXiv:1504.02448</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02616</dc:identifier>
 <dc:identifier>EPTCS 181, 2015, pp. 129-144</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.181.9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02621</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Reference Interpreter for the Graph Programming Language GP 2</dc:title>
 <dc:creator>Bak, Christopher</dc:creator>
 <dc:creator>Faulkner, Glyn</dc:creator>
 <dc:creator>Plump, Detlef</dc:creator>
 <dc:creator>Runciman, Colin</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  GP 2 is an experimental programming language for computing by graph
transformation. An initial interpreter for GP 2, written in the functional
language Haskell, provides a concise and simply structured reference
implementation. Despite its simplicity, the performance of the interpreter is
sufficient for the comparative investigation of a range of test programs. It
also provides a platform for the development of more sophisticated
implementations.
</dc:description>
 <dc:description>Comment: In Proceedings GaM 2015, arXiv:1504.02448</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02621</dc:identifier>
 <dc:identifier>EPTCS 181, 2015, pp. 48-64</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.181.4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02622</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximum Entropy Linear Manifold for Learning Discriminative
  Low-dimensional Representation</dc:title>
 <dc:creator>Czarnecki, Wojciech Marian</dc:creator>
 <dc:creator>J&#xf3;zefowicz, Rafa&#x142;</dc:creator>
 <dc:creator>Tabor, Jacek</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Representation learning is currently a very hot topic in modern machine
learning, mostly due to the great success of the deep learning methods. In
particular low-dimensional representation which discriminates classes can not
only enhance the classification procedure, but also make it faster, while
contrary to the high-dimensional embeddings can be efficiently used for visual
based exploratory data analysis.
  In this paper we propose Maximum Entropy Linear Manifold (MELM), a
multidimensional generalization of Multithreshold Entropy Linear Classifier
model which is able to find a low-dimensional linear data projection maximizing
discriminativeness of projected classes. As a result we obtain a linear
embedding which can be used for classification, class aware dimensionality
reduction and data visualization. MELM provides highly discriminative 2D
projections of the data which can be used as a method for constructing robust
classifiers.
  We provide both empirical evaluation as well as some interesting theoretical
properties of our objective function such us scale and affine transformation
invariance, connections with PCA and bounding of the expected balanced accuracy
error.
</dc:description>
 <dc:description>Comment: submitted to ECMLPKDD 2015</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02622</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02627</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What are Strategies in Delay Games? Borel Determinacy for Games with
  Lookahead</dc:title>
 <dc:creator>Klein, Felix</dc:creator>
 <dc:creator>Zimmermann, Martin</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We investigate determinacy of delay games with Borel winning conditions,
infinite-duration two-player games in which one player may delay her moves to
obtain a lookahead on her opponent's moves.
  First, we prove determinacy of such games with respect to a fixed evolution
of the lookahead. However, strategies in such games may depend on information
about the evolution. Thus, we introduce different notions of universal
strategies for both players, which are evolution-independent, and determine the
exact amount of information a universal strategy needs about the history of a
play and the evolution of the lookahead to be winning. In particular, we show
that delay games with Borel winning conditions are determined with respect to
universal strategies. Finally, we consider decidability problems, e.g., &quot;Does a
player have a universal winning strategy for delay games with a given winning
condition?&quot;, for omega-regular and omega-context-free winning conditions.
</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02644</identifier>
 <datestamp>2015-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OneMax in Black-Box Models with Several Restrictions</dc:title>
 <dc:creator>Doerr, Carola</dc:creator>
 <dc:creator>Lengler, Johannes</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Black-box complexity studies lower bounds for the efficiency of
general-purpose black-box optimization algorithms such as evolutionary
algorithms and other search heuristics. Different models exist, each one being
designed to analyze a different aspect of typical heuristics such as the memory
size or the variation operators in use. While most of the previous works focus
on one particular such aspect, we consider in this work how the combination of
several algorithmic restrictions influence the black-box complexity. Our
testbed are so-called OneMax functions, a classical set of test functions that
is intimately related to classic coin-weighing problems and to the board game
Mastermind.
  We analyze in particular the combined memory-restricted ranking-based
black-box complexity of OneMax for different memory sizes. While its isolated
memory-restricted as well as its ranking-based black-box complexity for bit
strings of length $n$ is only of order $n/\log n$, the combined model does not
allow for algorithms being faster than linear in $n$, as can be seen by
standard information-theoretic considerations. We show that this linear bound
is indeed asymptotically tight. Similar results are obtained for other memory-
and offspring-sizes. Our results also apply to the (Monte Carlo) complexity of
OneMax in the recently introduced elitist model, in which only the best-so-far
solution can be kept in the memory. Finally, we also provide improved lower
bounds for the complexity of OneMax in the regarded models.
  Our result enlivens the quest for natural evolutionary algorithms optimizing
OneMax in $o(n \log n)$ iterations.
</dc:description>
 <dc:description>Comment: This is the full version of a paper accepted to GECCO 2015</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:date>2015-09-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02644</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02648</identifier>
 <datestamp>2016-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time-causal and time-recursive spatio-temporal receptive fields</dc:title>
 <dc:creator>Lindeberg, Tony</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  We present an improved model and theory for time-causal and time-recursive
spatio-temporal receptive fields, based on a combination of Gaussian receptive
fields over the spatial domain and first-order integrators or equivalently
truncated exponential filters coupled in cascade over the temporal domain.
  Compared to previous spatio-temporal scale-space formulations in terms of
non-enhancement of local extrema or scale invariance, these receptive fields
are based on different scale-space axiomatics over time by ensuring
non-creation of new local extrema or zero-crossings with increasing temporal
scale. Specifically, extensions are presented about (i) parameterizing the
intermediate temporal scale levels, (ii) analysing the resulting temporal
dynamics, (iii) transferring the theory to a discrete implementation, (iv)
computing scale-normalized spatio-temporal derivative expressions for
spatio-temporal feature detection and (v) computational modelling of receptive
fields in the lateral geniculate nucleus (LGN) and the primary visual cortex
(V1) in biological vision.
  We show that by distributing the intermediate temporal scale levels according
to a logarithmic distribution, we obtain much faster temporal response
properties (shorter temporal delays) compared to a uniform distribution.
Specifically, these kernels converge very rapidly to a limit kernel possessing
true self-similar scale-invariant properties over temporal scales, thereby
allowing for true scale invariance over variations in the temporal scale,
although the underlying temporal scale-space representation is based on a
discretized temporal scale parameter.
  We show how scale-normalized temporal derivatives can be defined for these
time-causal scale-space kernels and how the composed theory can be used for
computing basic types of scale-normalized spatio-temporal derivative
expressions in a computationally efficient manner.
</dc:description>
 <dc:description>Comment: 39 pages, 12 figures, 5 tables in Journal of Mathematical Imaging and
  Vision, published online Dec 2015</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:date>2015-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02648</dc:identifier>
 <dc:identifier>Journal of Mathematical Imaging and Vision, 55(1): 50-88, 2016</dc:identifier>
 <dc:identifier>doi:10.1007/s10851-015-0613-9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02651</identifier>
 <datestamp>2015-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reachability analysis of first-order definable pushdown systems</dc:title>
 <dc:creator>Clemente, Lorenzo</dc:creator>
 <dc:creator>Lasota, S&#x142;awomir</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  We study pushdown systems where control states, stack alphabet, and
transition relation, instead of being finite, are first-order definable in a
fixed countably-infinite structure. We show that the reachability analysis can
be addressed with the well-known saturation technique for the wide class of
oligomorphic structures. Moreover, for the more restrictive homogeneous
structures, we are able to give concrete complexity upper bounds. We show ample
applicability of our technique by presenting several concrete examples of
homogeneous structures, subsuming, with optimal complexity, known results from
the literature. We show that infinitely many such examples of homogeneous
structures can be obtained with the classical wreath product construction.
</dc:description>
 <dc:description>Comment: to appear in CSL'15</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:date>2015-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02656</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A complex network approach to cloud computing</dc:title>
 <dc:creator>Travieso, Gonzalo</dc:creator>
 <dc:creator>Ruggiero, Carlos Antonio</dc:creator>
 <dc:creator>Bruno, Odemir Martinez</dc:creator>
 <dc:creator>Costa, Luciano da Fontoura</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Cloud computing has become an important means to speed up computing. One
problem influencing heavily the performance of such systems is the choice of
nodes as servers responsible for executing the users' tasks. In this article we
report how complex networks can be used to model such a problem. More
specifically, we investigate the performance of the processing respectively to
cloud systems underlain by Erdos-Renyi and Barabasi-Albert topology containing
two servers. Cloud networks involving two communities not necessarily of the
same size are also considered in our analysis. The performance of each
configuration is quantified in terms of two indices: the cost of communication
between the user and the nearest server, and the balance of the distribution of
tasks between the two servers. Regarding the latter index, the ER topology
provides better performance than the BA case for smaller average degrees and
opposite behavior for larger average degrees. With respect to the cost, smaller
values are found in the BA topology irrespective of the average degree. In
addition, we also verified that it is easier to find good servers in the ER
than in BA. Surprisingly, balance and cost are not too much affected by the
presence of communities. However, for a well-defined community network, we
found that it is important to assign each server to a different community so as
to achieve better performance.
</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02656</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02671</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Longest Common Extensions in Sublinear Space</dc:title>
 <dc:creator>Bille, Philip</dc:creator>
 <dc:creator>G&#xf8;rtz, Inge Li</dc:creator>
 <dc:creator>Knudsen, Mathias B&#xe6;k Tejs</dc:creator>
 <dc:creator>Lewenstein, Moshe</dc:creator>
 <dc:creator>Vildh&#xf8;j, Hjalte Wedel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The longest common extension problem (LCE problem) is to construct a data
structure for an input string $T$ of length $n$ that supports LCE$(i,j)$
queries. Such a query returns the length of the longest common prefix of the
suffixes starting at positions $i$ and $j$ in $T$. This classic problem has a
well-known solution that uses $O(n)$ space and $O(1)$ query time. In this paper
we show that for any trade-off parameter $1 \leq \tau \leq n$, the problem can
be solved in $O(\frac{n}{\tau})$ space and $O(\tau)$ query time. This
significantly improves the previously best known time-space trade-offs, and
almost matches the best known time-space product lower bound.
</dc:description>
 <dc:description>Comment: An extended abstract of this paper has been accepted to CPM 2015</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02671</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02687</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Density Histograms for Criteria-driven Edge Bundling</dc:title>
 <dc:creator>Moura, Daniel C.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>68U05</dc:subject>
 <dc:subject>I.3.3</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:description>  This paper presents a graph bundling algorithm that agglomerates edges taking
into account both spatial proximity as well as user-defined criteria in order
to reveal patterns that were not perceivable with previous bundling techniques.
Each edge belongs to a group that may either be an input of the problem or
found by clustering one or more edge properties such as origin, destination,
orientation, length or domain-specific properties. Bundling is driven by a
stack of density maps, with each map capturing both the edge density of a given
group as well as interactions with edges from other groups. Density maps are
efficiently calculated by smoothing 2D histograms of edge occurrence using
repeated averaging filters based on integral images.
  A CPU implementation of the algorithm is tested on several graphs, and
different grouping criteria are used to illustrate how the proposed technique
can render different visualizations of the same data. Bundling performance is
much higher than on previous approaches, being particularly noticeable on large
graphs, with millions of edges being bundled in seconds.
</dc:description>
 <dc:description>Comment: Submitted to a conference (under review)</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02687</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02692</identifier>
 <datestamp>2015-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Fibrational Approach to Automata Theory</dc:title>
 <dc:creator>Chen, Liang-Ting</dc:creator>
 <dc:creator>Urbat, Henning</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:description>  For predual categories C and D we establish isomorphisms between opfibrations
representing local varieties of languages in C, local pseudovarieties of
D-monoids, and finitely generated profinite D-monoids. The global sections of
these opfibrations are shown to correspond to varieties of languages in C,
pseudovarieties of D-monoids, and profinite equational theories of D-monoids,
respectively. As an application, we obtain a new proof of Eilenberg's variety
theorem along with several related results, covering varieties of languages and
their coalgebraic modifications, Straubing's C-varieties, fully invariant local
varieties, etc., within a single framework.
</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02692</dc:identifier>
 <dc:identifier>CALCO (2015) 50-65</dc:identifier>
 <dc:identifier>doi:10.4230/LIPIcs.CALCO.2015.50</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02694</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Syntactic Monoids in a Category</dc:title>
 <dc:creator>Adamek, Jiri</dc:creator>
 <dc:creator>Milius, Stefan</dc:creator>
 <dc:creator>Urbat, Henning</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:description>  The syntactic monoid of a language is generalized to the level of a symmetric
monoidal closed category D. This allows for a uniform treatment of several
notions of syntactic algebras known in the literature, including the syntactic
monoids of Rabin and Scott (D = sets), the syntactic semirings of Polak (D =
semilattices), and the syntactic associative algebras of Reutenauer (D = vector
spaces). Assuming that D is an entropic variety of algebras, we prove that the
syntactic D-monoid of a language L can be constructed as a quotient of a free
D-monoid modulo the syntactic congruence of L, and that it is isomorphic to the
transition D-monoid of the minimal automaton for L in D. Furthermore, in case
the variety D is locally finite, we characterize the regular languages as
precisely the languages with finite syntactic D-monoids.
</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:date>2015-06-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02696</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental Sparse GP Regression for Continuous-time Trajectory
  Estimation &amp; Mapping</dc:title>
 <dc:creator>Yan, Xinyan</dc:creator>
 <dc:creator>Indelman, Vadim</dc:creator>
 <dc:creator>Boots, Byron</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Recent work on simultaneous trajectory estimation and mapping (STEAM) for
mobile robots has found success by representing the trajectory as a Gaussian
process. Gaussian processes can represent a continuous-time trajectory,
elegantly handle asynchronous and sparse measurements, and allow the robot to
query the trajectory to recover its estimated position at any time of interest.
A major drawback of this approach is that STEAM is formulated as a batch
estimation problem. In this paper we provide the critical extensions necessary
to transform the existing batch algorithm into an extremely efficient
incremental algorithm. In particular, we are able to vastly speed up the
solution time through efficient variable reordering and incremental sparse
updates, which we believe will greatly increase the practicality of Gaussian
process methods for robot mapping and localization. Finally, we demonstrate the
approach and its advantages on both synthetic and real datasets.
</dc:description>
 <dc:description>Comment: 10 pages, 10 figures</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02712</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gradient of Probability Density Functions based Contrasts for Blind
  Source Separation (BSS)</dc:title>
 <dc:creator>C, Dharmani Bhaveshkumar</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>94A17</dc:subject>
 <dc:description>  The article derives some novel independence measures and contrast functions
for Blind Source Separation (BSS) application. For the $k^{th}$ order
differentiable multivariate functions with equal hyper-volumes (region bounded
by hyper-surfaces) and with a constraint of bounded support for $k&gt;1$, it
proves that equality of any $k^{th}$ order derivatives implies equality of the
functions. The difference between product of marginal Probability Density
Functions (PDFs) and joint PDF of a random vector is defined as Function
Difference (FD) of a random vector. Assuming the PDFs are $k^{th}$ order
differentiable, the results on generalized functions are applied to the
independence condition. This brings new sets of independence measures and BSS
contrasts based on the $L^p$-Norm, $ p \geq 1$ of - FD, gradient of FD (GFD)
and Hessian of FD (HFD). Instead of a conventional two stage indirect
estimation method for joint PDF based BSS contrast estimation, a single stage
direct estimation of the contrasts is desired. The article targets both the
efficient estimation of the proposed contrasts and extension of the potential
theory for an information field. The potential theory has a concept of
reference potential and it is used to derive closed form expression for the
relative analysis of potential field. Analogous to it, there are introduced
concepts of Reference Information Potential (RIP) and Cross Reference
Information Potential (CRIP) based on the potential due to kernel functions
placed at selected sample points as basis in kernel methods. The quantities are
used to derive closed form expressions for information field analysis using
least squares. The expressions are used to estimate $L^2$-Norm of FD and
$L^2$-Norm of GFD based contrasts.
</dc:description>
 <dc:description>Comment: 47 pages</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02716</identifier>
 <datestamp>2015-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Equational reasoning with context-free families of string diagrams</dc:title>
 <dc:creator>Kissinger, Aleks</dc:creator>
 <dc:creator>Zamdzhiev, Vladimir</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:description>  String diagrams provide an intuitive language for expressing networks of
interacting processes graphically. A discrete representation of string
diagrams, called string graphs, allows for mechanised equational reasoning by
double-pushout rewriting. However, one often wishes to express not just single
equations, but entire families of equations between diagrams of arbitrary size.
To do this we define a class of context-free grammars, called B-ESG grammars,
that are suitable for defining entire families of string graphs, and crucially,
of string graph rewrite rules. We show that the language-membership and
match-enumeration problems are decidable for these grammars, and hence that
there is an algorithm for rewriting string graphs according to B-ESG rewrite
patterns. We also show that it is possible to reason at the level of grammars
by providing a simple method for transforming a grammar by string graph
rewriting, and showing admissibility of the induced B-ESG rewrite pattern.
</dc:description>
 <dc:description>Comment: International Conference on Graph Transformation, ICGT 2015. The
  final publication is available at Springer via
  http://dx.doi.org/10.1007/978-3-319-21145-9_9</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:date>2015-10-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02716</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-21145-9_9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02719</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diffusion Component Analysis: Unraveling Functional Topology in
  Biological Networks</dc:title>
 <dc:creator>Cho, Hyunghoon</dc:creator>
 <dc:creator>Berger, Bonnie</dc:creator>
 <dc:creator>Peng, Jian</dc:creator>
 <dc:subject>Quantitative Biology - Molecular Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Complex biological systems have been successfully modeled by biochemical and
genetic interaction networks, typically gathered from high-throughput (HTP)
data. These networks can be used to infer functional relationships between
genes or proteins. Using the intuition that the topological role of a gene in a
network relates to its biological function, local or diffusion based
&quot;guilt-by-association&quot; and graph-theoretic methods have had success in
inferring gene functions. Here we seek to improve function prediction by
integrating diffusion-based methods with a novel dimensionality reduction
technique to overcome the incomplete and noisy nature of network data. In this
paper, we introduce diffusion component analysis (DCA), a framework that plugs
in a diffusion model and learns a low-dimensional vector representation of each
node to encode the topological properties of a network. As a proof of concept,
we demonstrate DCA's substantial improvement over state-of-the-art
diffusion-based approaches in predicting protein function from molecular
interaction networks. Moreover, our DCA framework can integrate multiple
networks from heterogeneous sources, consisting of genomic information,
biochemical experiments and other resources, to even further improve function
prediction. Yet another layer of performance gain is achieved by integrating
the DCA framework with support vector machines that take our node vector
representations as features. Overall, our DCA framework provides a novel
representation of nodes in a network that can be used as a plug-in architecture
to other machine learning algorithms to decipher topological properties of and
obtain novel insights into interactomes.
</dc:description>
 <dc:description>Comment: RECOMB 2015</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02719</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02730</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Domains of commutative C*-subalgebras</dc:title>
 <dc:creator>Heunen, Chris</dc:creator>
 <dc:creator>Lindenhovius, Bert</dc:creator>
 <dc:subject>Mathematics - Operator Algebras</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  A C*-algebra is determined to a great extent by the partial order of its
commutative C*-algebras. We study order-theoretic properties of this dcpo. Many
properties coincide: the dcpo is, equivalently, algebraic, continuous,
meet-continuous, atomistic, quasi-algebraic, or quasi-continuous, if and only
if the C*-algebra is scattered. For C*-algebras with enough projections, these
properties are equivalent to finite-dimensionality. Approximately
finite-dimensional elements of the dcpo correspond to Boolean subalgebras of
the projections of the C*-algebra, which determine the projections up to
isomorphism. Scattered C*-algebras are finite-dimensional if and only if their
dcpo is Lawson-scattered. General C*-algebras are finite-dimensional if and
only if their dcpo is order-scattered.
</dc:description>
 <dc:description>Comment: 34 pages</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02744</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-time Tool for Affine Transformations of Two Dimensional IFS
  Fractals</dc:title>
 <dc:creator>Hadzieva, Elena</dc:creator>
 <dc:creator>Shuminoska, Marija</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>28A80, 65D17</dc:subject>
 <dc:description>  This work introduces a novel tool for interactive, real-time transformations
of two dimensional IFS fractals. We assign barycentric coordinates (relative to
an arbitrary affine basis of $\mathbb{R}^2$) to the points that constitute the
image of a fractal. The tool uses some of the nice properties of the
barycentric coordinates, enabling any affine transformation of the basis, done
by click-and-drag, to be immediately followed by the same affine transformation
of the IFS fractal attractor. In order to have a better control over the
fractal, as affine basis we use a kind of minimal simplex that contains the
attractor. We give theoretical grounds of the tool and then the software
application.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02744</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02756</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discrimination and characterization of Parkinsonian rest tremors by
  analyzing long-term correlations and multifractal signatures</dc:title>
 <dc:creator>Livi, Lorenzo</dc:creator>
 <dc:creator>Sadeghian, Alireza</dc:creator>
 <dc:creator>Sadeghian, Hamid</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  In this paper, we analyze 48 signals of rest tremor velocity related to 12
distinct subjects affected by Parkinson's disease. The subjects belong to two
different groups, formed by four and eight subjects with, respectively, high-
and low-amplitude rest tremors. Each subject is tested in four settings, given
by combining the use of deep brain stimulation and L-DOPA medication. We
develop two main feature-based representations of such signals, which are
obtained by considering (i) the long-term correlations and multifractal
properties, and (ii) the power spectra. The feature-based representations are
initially utilized for the purpose of characterizing the subjects under
different settings. In agreement with previous studies, we show that deep brain
stimulation does not significantly characterize neither of the two groups,
regardless of the adopted representation. On the other hand, the medication
effect yields statistically significant differences in both high- and
low-amplitude tremor groups. We successively test several different instances
of the two feature-based representations of the signals in the setting of
supervised classification and (nonlinear) feature transformation. We consider
three different classification problems, involving the recognition of (i) the
presence of medication, (ii) the use of deep brain stimulation, and (iii) the
membership to the high- and low-amplitude tremor groups. Classification results
show that the use of medication can be discriminated with higher accuracy,
considering many of the feature-based representations. Notably, we show that
the best results are obtained with a parsimonious, two-dimensional
representation encoding the long-term correlations and multifractal character
of the signals.
</dc:description>
 <dc:description>Comment: 10 pages, 41 references</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:date>2015-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02756</dc:identifier>
 <dc:identifier>doi:10.1109/TBME.2016.2515760</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02762</identifier>
 <datestamp>2016-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image patch analysis of sunspots and active regions. II. Clustering via
  matrix factorization</dc:title>
 <dc:creator>Moon, Kevin R.</dc:creator>
 <dc:creator>Delouille, Veronique</dc:creator>
 <dc:creator>Li, Jimmy J.</dc:creator>
 <dc:creator>De Visscher, Ruben</dc:creator>
 <dc:creator>Watson, Fraser</dc:creator>
 <dc:creator>Hero III, Alfred O.</dc:creator>
 <dc:subject>Astrophysics - Solar and Stellar Astrophysics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Separating active regions that are quiet from potentially eruptive ones is a
key issue in Space Weather applications. Traditional classification schemes
such as Mount Wilson and McIntosh have been effective in relating an active
region large scale magnetic configuration to its ability to produce eruptive
events. However, their qualitative nature prevents systematic studies of an
active region's evolution for example. We introduce a new clustering of active
regions that is based on the local geometry observed in Line of Sight
magnetogram and continuum images. We use a reduced-dimension representation of
an active region that is obtained by factoring the corresponding data matrix
comprised of local image patches. Two factorizations can be compared via the
definition of appropriate metrics on the resulting factors. The distances
obtained from these metrics are then used to cluster the active regions. We
find that these metrics result in natural clusterings of active regions. The
clusterings are related to large scale descriptors of an active region such as
its size, its local magnetic field distribution, and its complexity as measured
by the Mount Wilson classification scheme. We also find that including data
focused on the neutral line of an active region can result in an increased
correspondence between our clustering results and other active region
descriptors such as the Mount Wilson classifications and the $R$ value. We
provide some recommendations for which metrics, matrix factorization
techniques, and regions of interest to use to study active regions.
</dc:description>
 <dc:description>Comment: Accepted for publication in the Journal of Space Weather and Space
  Climate (SWSC). 33 pages, 12 figures</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:date>2015-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02762</dc:identifier>
 <dc:identifier>Journal of Space Weather and Space Climate, Vol. 6, A3 (2016)</dc:identifier>
 <dc:identifier>doi:10.1051/swsc/2015043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02763</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance measures for classification systems with rejection</dc:title>
 <dc:creator>Condessa, Filipe</dc:creator>
 <dc:creator>Kovacevic, Jelena</dc:creator>
 <dc:creator>Bioucas-Dias, Jose</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>68-04</dc:subject>
 <dc:description>  Classifiers with rejection are essential in real-world applications where
misclassifications and their effects are critical. However, if no problem
specific cost function is defined, there are no established measures to assess
the performance of such classifiers. We introduce a set of desired properties
for performance measures for classifiers with rejection, based on which we
propose a set of three performance measures for the evaluation of the
performance of classifiers with rejection that satisfy the desired properties.
The nonrejected accuracy measures the ability of the classifier to accurately
classify nonrejected samples; the classification quality measures the correct
decision making of the classifier with rejector; and the rejection quality
measures the ability to concentrate all misclassified samples onto the set of
rejected samples. From the measures, we derive the concept of relative
optimality that allows us to connect the measures to a family of cost functions
that take into account the trade-off between rejection and misclassification.
We illustrate the use of the proposed performance measures on classifiers with
rejection applied to synthetic and real-world data.
</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02763</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02764</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Coarse-to-Fine Model for 3D Pose Estimation and Sub-category
  Recognition</dc:title>
 <dc:creator>Mottaghi, Roozbeh</dc:creator>
 <dc:creator>Xiang, Yu</dc:creator>
 <dc:creator>Savarese, Silvio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Despite the fact that object detection, 3D pose estimation, and sub-category
recognition are highly correlated tasks, they are usually addressed
independently from each other because of the huge space of parameters. To
jointly model all of these tasks, we propose a coarse-to-fine hierarchical
representation, where each level of the hierarchy represents objects at a
different level of granularity. The hierarchical representation prevents
performance loss, which is often caused by the increase in the number of
parameters (as we consider more tasks to model), and the joint modelling
enables resolving ambiguities that exist in independent modelling of these
tasks. We augment PASCAL3D+ dataset with annotations for these tasks and show
that our hierarchical model is effective in joint modelling of object
detection, 3D pose estimation, and sub-category recognition.
</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02789</identifier>
 <datestamp>2015-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Car that Knows Before You Do: Anticipating Maneuvers via Learning
  Temporal Driving Models</dc:title>
 <dc:creator>Jain, Ashesh</dc:creator>
 <dc:creator>Koppula, Hema S.</dc:creator>
 <dc:creator>Raghavan, Bharad</dc:creator>
 <dc:creator>Soh, Shane</dc:creator>
 <dc:creator>Saxena, Ashutosh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Advanced Driver Assistance Systems (ADAS) have made driving safer over the
last decade. They prepare vehicles for unsafe road conditions and alert drivers
if they perform a dangerous maneuver. However, many accidents are unavoidable
because by the time drivers are alerted, it is already too late. Anticipating
maneuvers beforehand can alert drivers before they perform the maneuver and
also give ADAS more time to avoid or prepare for the danger.
  In this work we anticipate driving maneuvers a few seconds before they occur.
For this purpose we equip a car with cameras and a computing device to capture
the driving context from both inside and outside of the car. We propose an
Autoregressive Input-Output HMM to model the contextual information alongwith
the maneuvers. We evaluate our approach on a diverse data set with 1180 miles
of natural freeway and city driving and show that we can anticipate maneuvers
3.5 seconds before they occur with over 80\% F1-score in real-time.
</dc:description>
 <dc:description>Comment: ICCV 2015, http://brain4cars.com</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:date>2015-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02789</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02790</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sharpening Skills in Using Presentation Tools: Students' Experiences</dc:title>
 <dc:creator>Dano-Hinosolango, Maria Angeles</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Making use of Information and Communication Technology resources is deemed
necessary for students. With this, they need to demonstrate their competence in
using various technologies such as Prezi and PowerPoint to communicate
effectively and efficiently. Hence, their experiences in using these
presentation tools is important to assist them in their needs. In this study,
all the fourth year Bachelor of Science in Technology Communication Management
students who have used the PowerPoint and Prezi were the respondents. Survey
instruments were given to determine the experiences of students of these
technologies based on their familiarity, skills, and effectiveness in
delivering the reports and presentations. It was found out that students were
generally good in using these tools. On the other hand, following the basic
rules to use these presentation tools effectively has to be reinforced in the
classroom to enhance and enrich their learning in sharpening their skills on
presentation tools.
</dc:description>
 <dc:description>Comment: It has 10 pages and 4 tables to illustrate the results of the data
  gathered</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02790</dc:identifier>
 <dc:identifier>This has been published in International Journal on Integrating
  Technology in Education (IJITE) Vol 4, No 1, 2015 with the ISSN 2320-1886
  (Online); 2320-3935 (Print)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02796</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model Counting Modulo Theories</dc:title>
 <dc:creator>Phan, Quoc-Sang</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>H.1.1</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  This thesis is concerned with the quantitative assessment of security in
software. More specifically, it tackles the problem of efficient computation of
channel capacity, the maximum amount of confidential information leaked by
software, measured in Shannon entropy or R\'{e}nyi's min-entropy.
  Most approaches to computing channel capacity are either efficient and return
only (possibly very loose) upper bounds, or alternatively are inefficient but
precise; few target realistic programs. In this thesis, we present a novel
approach to the problem by reducing it to a model counting problem on
first-order logic, which we name Model Counting Modulo Theories or #SMT for
brevity.
  For quantitative security, our contribution is twofold. First, on the
theoretical side we establish the connections between measuring confidentiality
leaks and fundamental verification algorithms like Symbolic Execution, SMT
solvers and DPLL. Second, exploiting these connections, we develop novel
#SMT-based techniques to compute channel capacity, which achieve both accuracy
and efficiency. These techniques are scalable to real-world programs, and
illustrative case studies include C programs from Linux kernel, a Java program
from a European project and anonymity protocols.
  For formal verification, our contribution is also twofold. First, we
introduce and study a new research problem, namely #SMT, which has other
potential applications beyond computing channel capacity, such as returning
multiple-counterexamples for Bounded Model Checking or automated test
generation. Second, we propose an alternative approach for Bounded Model
Checking using classical Symbolic Execution, which can be parallelised to
leverage modern multi-core and distributed architecture.
</dc:description>
 <dc:description>Comment: PhD thesis (2015); Queen Mary University of London
  (http://theory.eecs.qmul.ac.uk/)</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02796</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02799</identifier>
 <datestamp>2015-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discrete All-Pay Bidding Games</dc:title>
 <dc:creator>Menz, Michael</dc:creator>
 <dc:creator>Wang, Justin</dc:creator>
 <dc:creator>Xie, Jiyang</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In an all-pay auction, only one bidder wins but all bidders must pay the
auctioneer. All-pay bidding games arise from attaching a similar bidding
structure to traditional combinatorial games to determine which player moves
next. In contrast to the established theory of single-pay bidding games,
optimal play involves choosing bids from some probability distribution that
will guarantee a minimum probability of winning. In this manner, all-pay
bidding games wed the underlying concepts of economic and combinatorial games.
We present several results on the structures of optimal strategies in these
games. We then give a fast algorithm for computing such strategies for a large
class of all-pay bidding games. The methods presented provide a framework for
further development of the theory of all-pay bidding games.
</dc:description>
 <dc:date>2015-04-02</dc:date>
 <dc:date>2015-05-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02817</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards A Theory Of Quantum Computability</dc:title>
 <dc:creator>Guerrini, Stefano</dc:creator>
 <dc:creator>Martini, Simone</dc:creator>
 <dc:creator>Masini, Andrea</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We propose a definition of quantum computable functions as mappings between
superpositions of natural numbers to probability distributions of natural
numbers. Each function is obtained as a limit of an infinite computation of a
quantum Turing machine. The class of quantum computable functions is
recursively enumerable, thus opening the door to a quantum computability theory
which may follow some of the classical developments.
</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02824</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Deep Embedding Model for Co-occurrence Learning</dc:title>
 <dc:creator>Shen, Yelong</dc:creator>
 <dc:creator>Jin, Ruoming</dc:creator>
 <dc:creator>Chen, Jianshu</dc:creator>
 <dc:creator>He, Xiaodong</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:creator>Deng, Li</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Co-occurrence Data is a common and important information source in many
areas, such as the word co-occurrence in the sentences, friends co-occurrence
in social networks and products co-occurrence in commercial transaction data,
etc, which contains rich correlation and clustering information about the
items. In this paper, we study co-occurrence data using a general energy-based
probabilistic model, and we analyze three different categories of energy-based
model, namely, the $L_1$, $L_2$ and $L_k$ models, which are able to capture
different levels of dependency in the co-occurrence data. We also discuss how
several typical existing models are related to these three types of energy
models, including the Fully Visible Boltzmann Machine (FVBM) ($L_2$), Matrix
Factorization ($L_2$), Log-BiLinear (LBL) models ($L_2$), and the Restricted
Boltzmann Machine (RBM) model ($L_k$). Then, we propose a Deep Embedding Model
(DEM) (an $L_k$ model) from the energy model in a \emph{principled} manner.
Furthermore, motivated by the observation that the partition function in the
energy model is intractable and the fact that the major objective of modeling
the co-occurrence data is to predict using the conditional probability, we
apply the \emph{maximum pseudo-likelihood} method to learn DEM. In consequence,
the developed model and its learning method naturally avoid the above
difficulties and can be easily used to compute the conditional probability in
prediction. Interestingly, our method is equivalent to learning a special
structured deep neural network using back-propagation and a special sampling
strategy, which makes it scalable on large-scale datasets. Finally, in the
experiments, we show that the DEM can achieve comparable or better results than
state-of-the-art methods on datasets across several application domains.
</dc:description>
 <dc:date>2015-04-10</dc:date>
 <dc:date>2015-06-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02824</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02830</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The inverse $p$-maxian problem on trees with variable edge lengths</dc:title>
 <dc:creator>Nguyen, Kien Trung</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>90B10, 90B80, 90C27</dc:subject>
 <dc:description>  We concern the problem of modifying the edge lengths of a tree in minimum
total cost so that the prespecified $p$ vertices become the $p$-maxian with
respect to the new edge lengths. This problem is called the inverse $p$-maxian
problem on trees. \textbf{Gassner} proposed efficient combinatorial alogrithm
to solve the the inverse 1-maxian problem on trees in 2008. For the problem
with $p \geq 2$, we claim that the problem can be reduced to finitely many
inverse $2$-maxian problem. We then develop algorithms to solve the inverse
$2$-maxian problem for various objective functions. The problem under
$l_1$-norm can be formulated as a linear program and thus can be solved in
polynomial time. Particularly, if the underlying tree is a star, then the
problem can be solved in linear time. We also devised $O(n\log n)$ algorithms
to solve the problems under Chebyshev norm and bottleneck Hamming distance,
where $n$ is the number of vertices of the tree. Finally, the problem under
weighted sum Hamming distance is $NP$-hard.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:date>2015-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02833</identifier>
 <datestamp>2015-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Composition of Memristive Networks for Real-Time Computing</dc:title>
 <dc:creator>B&#xfc;rger, Jens</dc:creator>
 <dc:creator>Goudarzi, Alireza</dc:creator>
 <dc:creator>Stefanovic, Darko</dc:creator>
 <dc:creator>Teuscher, Christof</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Advances in materials science have led to physical instantiations of
self-assembled networks of memristive devices and demonstrations of their
computational capability through reservoir computing. Reservoir computing is an
approach that takes advantage of collective system dynamics for real-time
computing. A dynamical system, called a reservoir, is excited with a
time-varying signal and observations of its states are used to reconstruct a
desired output signal. However, such a monolithic assembly limits the
computational power due to signal interdependency and the resulting correlated
readouts. Here, we introduce an approach that hierarchically composes a set of
interconnected memristive networks into a larger reservoir. We use signal
amplification and restoration to reduce reservoir state correlation, which
improves the feature extraction from the input signals. Using the same number
of output signals, such a hierarchical composition of heterogeneous small
networks outperforms monolithic memristive networks by at least 20% on waveform
generation tasks. On the NARMA-10 task, we reduce the error by up to a factor
of 2 compared to homogeneous reservoirs with sigmoidal neurons, whereas single
memristive networks are unable to produce the correct result. Hierarchical
composition is key for solving more complex tasks with such novel nano-scale
hardware.
</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:date>2015-04-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02833</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02840</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>siftservice.com - Turning a Computer Vision algorithm into a World Wide
  Web Service</dc:title>
 <dc:creator>Tafti, Ahmad Pahlavan</dc:creator>
 <dc:creator>Hassannia, Hamid</dc:creator>
 <dc:creator>Yu, Zeyun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image features detection and description is a longstanding topic in computer
vision and pattern recognition areas. The Scale Invariant Feature Transform
(SIFT) is probably the most popular and widely demanded feature descriptor
which facilitates a variety of computer vision applications such as image
registration, object tracking, image forgery detection, and 3D surface
reconstruction. This work introduces a Software as a Service (SaaS) based
implementation of the SIFT algorithm which is freely available at
http://siftservice.com for any academic, educational and research purposes. The
service provides application-to-application interaction and aims Rapid
Application Development (RAD) and also fast prototyping for computer vision
students and researchers all around the world. An Internet connection is all
they need!
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02840</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02842</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Definition and Research of Internet Neurology</dc:title>
 <dc:creator>Liu, Feng</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  More and more scientific research shows that there is a close correlation
between the Internet and brain science. This paper presents the idea of
establishing the Internet neurology, which means to make a cross-contrast
between the two in terms of physiology and psychology, so that a complete
infrastructure system of the Internet is established, predicting the
development trend of the Internet in the future as well as the brain structure
and operation mechanism, and providing theoretical support for the generation
principle of intelligence, cognition and emotion. It also proposes the
viewpoint that the Internet can be divided into Internet neurophysiology,
Internet neuropsychology, Brain Internet physiology, Brain Internet psychology
and the Internet in cognitive science.
</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02843</identifier>
 <datestamp>2016-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A benchmark for data-based office modeling: challenges related to CO$_2$
  dynamics</dc:title>
 <dc:creator>Risuleo, Riccardo Sven</dc:creator>
 <dc:creator>Molinari, Marco</dc:creator>
 <dc:creator>Bottegal, Giulio</dc:creator>
 <dc:creator>Hjalmarsson, H&#xe5;kan</dc:creator>
 <dc:creator>Johansson, Karl H.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper describes a benchmark consisting of a set of synthetic
measurements relative to an office environment simulated with the software
IDA-ICE. The simulated environment reproduces a laboratory at the KTH-EES Smart
Building, equipped with a building management system. The data set contains
records collected over a period of several days. The signals to CO$_2$
concentration, mechanical ventilation airflows, air infiltrations and
occupancy. Information on door and window opening is also available. This
benchmark is intended for testing data-based modeling techniques. The ultimate
goal is the development of models to improve the forecast and control of
environmental variables. Among the numerous challenges related to this
framework, we point out the problem of occupancy estimation using information
on CO$_2$ concentration. This can be seen as a blind identification problem.
For benchmarking purposes, we present two different identification approaches:
a baseline overparametrization method and a kernel-based method.
</dc:description>
 <dc:description>Comment: 14 pages, accepted for publication to IFAC SysId 2015</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:date>2016-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02843</dc:identifier>
 <dc:identifier>doi:10.1016/j.ifacol.2015.12.304</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02856</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High Density Noise Removal by Cascading Algorithms</dc:title>
 <dc:creator>Dash, Arabinda</dc:creator>
 <dc:creator>Sathua, Sujaya Kumar</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  An advanced non-linear cascading filter algorithm for the removal of high
density salt and pepper noise from the digital images is proposed. The proposed
method consists of two stages. The first stage Decision base Median Filter
(DMF) acts as the preliminary noise removal algorithm. The second stage is
either Modified Decision Base Partial Trimmed Global Mean Filter (MDBPTGMF) or
Modified Decision Based Unsymmetric Trimmed Median Filter (MDBUTMF) which is
used to remove the remaining noise and enhance the image quality. The DMF
algorithm performs well at low noise density but it fails to remove the noise
at medium and high level. The MDBPTGMF and MDUTMF have excellent performance at
low, medium and high noise density but these reduce the image quality and blur
the image at high noise level. So the basic idea behind this paper is to
combine the advantages of the filters used in both the stages to remove the
Salt and Pepper noise and enhance the image quality at all the noise density
level. The proposed method is tested against different gray scale images and it
gives better Mean Absolute Error (MAE), Peak Signal to Noise Ratio (PSNR) and
Image Enhancement Factor (IEF) than the Adaptive Median Filter (AMF), Decision
Base Unsymmetric Trimmed Median Filter (DBUTMF), Modified Decision Base
Unsymmetric Trimmed Median Filter (MDBUTMF) and Decision Base Partial Trimmed
Global Mean Filter (DBPTGMF).
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02856</dc:identifier>
 <dc:identifier>doi:10.1109/ACCT.2015.100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02861</identifier>
 <datestamp>2016-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Explicit Model Checking of Very Large MDP using Partitioning and
  Secondary Storage</dc:title>
 <dc:creator>Hartmanns, Arnd</dc:creator>
 <dc:creator>Hermanns, Holger</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  The applicability of model checking is hindered by the state space explosion
problem in combination with limited amounts of main memory. To extend its
reach, the large available capacities of secondary storage such as hard disks
can be exploited. Due to the specific performance characteristics of secondary
storage technologies, specialised algorithms are required. In this paper, we
present a technique to use secondary storage for probabilistic model checking
of Markov decision processes. It combines state space exploration based on
partitioning with a block-iterative variant of value iteration over the same
partitions for the analysis of probabilistic reachability and expected-reward
properties. A sparse matrix-like representation is used to store partitions on
secondary storage in a compact format. All file accesses are sequential, and
compression can be used without affecting runtime. The technique has been
implemented within the Modest Toolset. We evaluate its performance on several
benchmark models of up to 3.5 billion states. In the analysis of time-bounded
properties on real-time models, our method neutralises the state space
explosion induced by the time bound in its entirety.
</dc:description>
 <dc:description>Comment: The final publication is available at Springer via
  http://dx.doi.org/10.1007/978-3-319-24953-7_10</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:date>2016-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02861</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-24953-7_10</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02863</identifier>
 <datestamp>2017-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Appearance-Based Gaze Estimation in the Wild</dc:title>
 <dc:creator>Zhang, Xucong</dc:creator>
 <dc:creator>Sugano, Yusuke</dc:creator>
 <dc:creator>Fritz, Mario</dc:creator>
 <dc:creator>Bulling, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Appearance-based gaze estimation is believed to work well in real-world
settings, but existing datasets have been collected under controlled laboratory
conditions and methods have been not evaluated across multiple datasets. In
this work we study appearance-based gaze estimation in the wild. We present the
MPIIGaze dataset that contains 213,659 images we collected from 15 participants
during natural everyday laptop use over more than three months. Our dataset is
significantly more variable than existing ones with respect to appearance and
illumination. We also present a method for in-the-wild appearance-based gaze
estimation using multimodal convolutional neural networks that significantly
outperforms state-of-the art methods in the most challenging cross-dataset
evaluation. We present an extensive evaluation of several state-of-the-art
image-based gaze estimation algorithms on three current datasets, including our
own. This evaluation provides clear insights and allows us to identify key
research challenges of gaze estimation in the wild.
</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02863</dc:identifier>
 <dc:identifier>doi:10.1109/CVPR.2015.7299081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02866</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Delay Aware Routing Protocol for Wireless Sensor Networks</dc:title>
 <dc:creator>Bhuyan, Bhaskar</dc:creator>
 <dc:creator>Sarma, Nityananda</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Wireless Sensor Networks (WSNs) consist of sensor nodes which can be deployed
for various operations such as agriculture and environmental sensing, wild life
monitoring, health care, military surveillance, industrial control, home
automation, security etc. Quality of Service (QoS) is an important issue in
wireless sensor networks (WSNs) and providing QoS support in WSNs is an
emerging area of research. Due to resource constraints nature of sensor
networks like processing power, memory, bandwidth, energy etc. providing QoS
support in WSNs is a challenging task. Delay is an important QoS parameter for
forwarding data in a time constraint WSNs environment. In this paper we propose
a delay aware routing protocol for transmission of time critical event
information to the Sink of WSNs. The performance of the proposed protocol is
evaluated by NS2 simulations under different scenarios.
</dc:description>
 <dc:description>Comment: 6 Pages, 8 Figures, journal</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02866</dc:identifier>
 <dc:identifier>IJCSI International Journal of Computer Science Issues, Volume 11,
  Issue 6, No 2, November 2014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02870</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quick sensitivity analysis for incremental data modification and its
  application to leave-one-out CV in linear classification problems</dc:title>
 <dc:creator>Okumura, Shota</dc:creator>
 <dc:creator>Suzuki, Yoshiki</dc:creator>
 <dc:creator>Takeuchi, Ichiro</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce a novel sensitivity analysis framework for large scale
classification problems that can be used when a small number of instances are
incrementally added or removed. For quickly updating the classifier in such a
situation, incremental learning algorithms have been intensively studied in the
literature. Although they are much more efficient than solving the optimization
problem from scratch, their computational complexity yet depends on the entire
training set size. It means that, if the original training set is large,
completely solving an incremental learning problem might be still rather
expensive. To circumvent this computational issue, we propose a novel framework
that allows us to make an inference about the updated classifier without
actually re-optimizing it. Specifically, the proposed framework can quickly
provide a lower and an upper bounds of a quantity on the unknown updated
classifier. The main advantage of the proposed framework is that the
computational cost of computing these bounds depends only on the number of
updated instances. This property is quite advantageous in a typical sensitivity
analysis task where only a small number of instances are updated. In this paper
we demonstrate that the proposed framework is applicable to various practical
sensitivity analysis tasks, and the bounds provided by the framework are often
sufficiently tight for making desired inferences.
</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02870</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02872</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regularized system identification using orthonormal basis functions</dc:title>
 <dc:creator>Chen, Tianshi</dc:creator>
 <dc:creator>Ljung, Lennart</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Most of existing results on regularized system identification focus on
regularized impulse response estimation. Since the impulse response model is a
special case of orthonormal basis functions, it is interesting to consider if
it is possible to tackle the regularized system identification using more
compact orthonormal basis functions. In this paper, we explore two
possibilities. First, we construct reproducing kernel Hilbert space of impulse
responses by orthonormal basis functions and then use the induced reproducing
kernel for the regularized impulse response estimation. Second, we extend the
regularization method from impulse response estimation to the more general
orthonormal basis functions estimation. For both cases, the poles of the basis
functions are treated as hyperparameters and estimated by empirical Bayes
method. Then we further show that the former is a special case of the latter,
and more specifically, the former is equivalent to ridge regression of the
coefficients of the orthonormal basis functions.
</dc:description>
 <dc:description>Comment: 6 pages, final submission of an contribution for European Control
  Conference 2015, uploaded on March 20, 2015</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02875</identifier>
 <datestamp>2017-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovery of the $D$-basis in binary tables based on hypergraph
  dualization</dc:title>
 <dc:creator>Adaricheva, Kira</dc:creator>
 <dc:creator>Nation, J. B.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Discovery of (strong) association rules, or implications, is an important
task in data management, and it finds application in artificial intelligence,
data mining and the semantic web. We introduce a novel approach for the
discovery of a specific set of implications, called the $D$-basis, that
provides a representation for a reduced binary table, based on the structure of
its Galois lattice. At the core of the method are the $D$-relation defined in
the lattice theory framework, and the hypergraph dualization algorithm that
allows us to effectively produce the set of transversals for a given Sperner
hypergraph. The latter algorithm, first developed by specialists from Rutgers
Center for Operations Research, has already found numerous applications in
solving optimization problems in data base theory, artificial intelligence and
game theory. One application of the method is for analysis of gene expression
data related to a particular phenotypic variable, and some initial testing is
done for the data provided by the University of Hawaii Cancer Center.
</dc:description>
 <dc:description>Comment: 14 pages, one table and one figure</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02875</dc:identifier>
 <dc:identifier>Theoretical Computer Science, v.658 Part B, 307-315 (2017)</dc:identifier>
 <dc:identifier>doi:10.1016/j.tcs.2015.11.031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02876</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Hardness of Subgraph Isomorphism</dc:title>
 <dc:creator>Cygan, Marek</dc:creator>
 <dc:creator>Pachocki, Jakub</dc:creator>
 <dc:creator>Soca&#x142;a, Arkadiusz</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Subgraph Isomorphism is a very basic graph problem, where given two graphs
$G$ and $H$ one is to check whether $G$ is a subgraph of $H$. Despite its
simple definition, the Subgraph Isomorphism problem turns out to be very broad,
as it generalizes problems such as Clique, $r$-Coloring, Hamiltonicity, Set
Packing and Bandwidth. However, for all of the mentioned problems
$2^{\mathcal{O}(n)}$ time algorithms exist, so a natural and frequently asked
question in the past was whether there exists a $2^{\mathcal{O}(n)}$ time
algorithm for Subgraph Isomorphism. In the monograph of Fomin and Kratsch
[Springer'10] this question is highlighted as an open problem, among few
others.
  Our main result is a reduction from 3-SAT, producing a subexponential number
of sublinear instances of the Subgraph Isomorphism problem. In particular, our
reduction implies a $2^{\Omega(n \sqrt{\log n})}$ lower bound for Subgraph
Isomorphism under the Exponential Time Hypothesis. This shows that there exist
classes of graphs that are strictly harder to embed than cliques or Hamiltonian
cycles.
  The core of our reduction consists of two steps. First, we preprocess and
pack variables and clauses of a 3-SAT formula into groups of logarithmic size.
However, the grouping is not arbitrary, since as a result we obtain only a
limited interaction between the groups. In the second step, we overcome the
technical hardness of encoding evaluations as permutations by a simple, yet
fruitful scheme of guessing the sizes of preimages of an arbitrary mapping,
reducing the case of arbitrary mapping to bijections. In fact, when applying
this step to a recent independent result of Fomin et al.[arXiv:1502.05447
(2015)], who showed hardness of Graph Homomorphism, we can transfer their
hardness result to Subgraph Isomorphism, implying a nearly tight lower bound of
$2^{\Omega(n \log n / \log \log n)}$.
</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02876</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02878</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Science and Ebola</dc:title>
 <dc:creator>Plaat, Aske</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Data Science---Today, everybody and everything produces data. People produce
large amounts of data in social networks and in commercial transactions.
Medical, corporate, and government databases continue to grow. Sensors continue
to get cheaper and are increasingly connected, creating an Internet of Things,
and generating even more data. In every discipline, large, diverse, and rich
data sets are emerging, from astrophysics, to the life sciences, to the
behavioral sciences, to finance and commerce, to the humanities and to the
arts. In every discipline people want to organize, analyze, optimize and
understand their data to answer questions and to deepen insights. The science
that is transforming this ocean of data into a sea of knowledge is called data
science. This lecture will discuss how data science has changed the way in
which one of the most visible challenges to public health is handled, the 2014
Ebola outbreak in West Africa.
</dc:description>
 <dc:description>Comment: Inaugural lecture Leiden University</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02878</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02882</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantitative Analysis of Whether Machine Intelligence Can Surpass Human
  Intelligence</dc:title>
 <dc:creator>Liu, Feng</dc:creator>
 <dc:creator>Shi, Yong</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Whether the machine intelligence can surpass the human intelligence is a
controversial issue. On the basis of traditional IQ, this article presents the
Universal IQ test method suitable for both the machine intelligence and the
human intelligence. With the method, machine and human intelligences were
divided into 4 major categories and 15 subcategories. A total of 50 search
engines across the world and 150 persons at different ages were subject to the
relevant test. And then, the Universal IQ ranking list of 2014 for the test
objects was obtained.
</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02886</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fundamental Relations Between Reactive and Proactive Relay-Selection
  Strategies</dc:title>
 <dc:creator>Xia, Minghua</dc:creator>
 <dc:creator>A&#xef;ssa, Sonia</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Two major relay-selection strategies widely applied in cooperative
decode-and-forward (DF) relaying networks, namely, reactive relay selection
(RRS) and proactive relay selection (PRS), are generally looked upon as
independent and studied separately. In this paper, RRS and PRS are proven to be
equivalent with respect to the end-to-end outage probability from the first
principle, i.e. their respective relay-selection criteria. On the other hand,
RRS is shown to be superior to PRS with respect to the end-to-end symbol error
rate. Afterwards, a case study of a general DF relaying system, subject to
co-channel interferences and additive white Gaussian noise at both the relaying
nodes and the destination, is performed to explicitly illustrate the
aforementioned outage equivalence. These fundamental relations provide
intuitive yet insightful performance benchmarks for comparing various
applications of these two relay-selection strategies.
</dc:description>
 <dc:description>Comment: 4 pages, to appear in IEEE Communications Letters</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02899</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On absorption in semigroups and $n$-ary semigroups</dc:title>
 <dc:creator>Ba&#x161;i&#x107;, Bojan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The notion of absorption was developed a few years ago by Barto and Kozik and
immediately found many applications, particularly in topics related to the
constraint satisfaction problem. We investigate the behavior of absorption in
semigroups and n-ary semigroups (that is, algebras with one n-ary associative
operation). In the case of semigroups, we give a simple necessary and
sufficient condition for a semigroup to be absorbed by its subsemigroup. We
then proceed to n-ary semigroups, where we conjecture an analogue of this
necessary and sufficient condition, and prove that the conjectured condition is
indeed necessary and sufficient for B to absorb A (where A is an n-ary
semigroup and B is its n-ary subsemigroup) in the following three cases: when A
is commutative, when |A-B|=1 and when A is an idempotent ternary semigroup.
</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:date>2015-06-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02899</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 11, Issue 2 (June 25,
  2015) lmcs:1575</dc:identifier>
 <dc:identifier>doi:10.2168/LMCS-11(2:15)2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02902</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gradual Training Method for Denoising Auto Encoders</dc:title>
 <dc:creator>Kalmanovich, Alexander</dc:creator>
 <dc:creator>Chechik, Gal</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Stacked denoising auto encoders (DAEs) are well known to learn useful deep
representations, which can be used to improve supervised training by
initializing a deep network. We investigate a training scheme of a deep DAE,
where DAE layers are gradually added and keep adapting as additional layers are
added. We show that in the regime of mid-sized datasets, this gradual training
provides a small but consistent improvement over stacked training in both
reconstruction quality and classification error over stacked training on MNIST
and CIFAR datasets.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1412.6257</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02902</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02914</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representing numeric data in 32 bits while preserving 64-bit precision</dc:title>
 <dc:creator>Neal, Radford M.</dc:creator>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Data files often consist of numbers having only a few significant decimal
digits, whose information content would allow storage in only 32 bits. However,
we may require that arithmetic operations involving these numbers be done with
64-bit floating-point precision, which precludes simply representing the data
as 32-bit floating-point values. Decimal floating point gives a compact and
exact representation, but requires conversion with a slow division operation
before it can be used. Here, I show that interesting subsets of 64-bit
floating-point values can be compactly and exactly represented by the 32 bits
consisting of the sign, exponent, and high-order part of the mantissa, with the
lower-order 32 bits of the mantissa filled in by table lookup, indexed by bits
from the part of the mantissa retained, and possibly from the exponent. For
example, decimal data with 4 or fewer digits to the left of the decimal point
and 2 or fewer digits to the right of the decimal point can be represented in
this way using the lower-order 5 bits of the retained part of the mantissa as
the index. Data consisting of 6 decimal digits with the decimal point in any of
the 7 positions before or after one of the digits can also be represented this
way, and decoded using 19 bits from the mantissa and exponent as the index.
Encoding with such a scheme is a simple copy of half the 64-bit value, followed
if necessary by verification that the value can be represented, by checking
that it decodes correctly. Decoding requires only extraction of index bits and
a table lookup. Lookup in a small table will usually reference cache; even with
larger tables, decoding is still faster than conversion from decimal floating
point with a division operation. I discuss how such schemes perform on recent
computer systems, and how they might be used to automatically compress large
arrays in interpretive languages such as R.
</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02914</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02921</identifier>
 <datestamp>2016-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Antenna Array Signal Processing for Quaternion-Valued Wireless
  Communication Systems</dc:title>
 <dc:creator>Liu, Wei</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Quaternion-valued wireless communication systems have been studied in the
past. Although progress has been made in this promising area, a crucial missing
link is lack of effective and efficient quaternion-valued signal processing
algorithms for channel equalisation and beamforming. With most recent
developments in quaternion-valued signal processing, in this work, we fill the
gap to solve the problem and further derive the quaternion-valued Wiener
solution for block-based calculation.
</dc:description>
 <dc:description>Comment: 3 pages, 5 figures, published in Proc. of the IEEE Benjamin Franklin
  Symposium on Microwave and Antenna Sub-systems (BenMAS), Philadelphia, US,
  September 2014</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02921</dc:identifier>
 <dc:identifier>doi:10.1109/BenMAS.2014.7529462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02923</identifier>
 <datestamp>2016-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressed Sensing Recovery via Nonconvex Shrinkage Penalties</dc:title>
 <dc:creator>Woodworth, Joseph</dc:creator>
 <dc:creator>Chartrand, Rick</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The $\ell^0$ minimization of compressed sensing is often relaxed to $\ell^1$,
which yields easy computation using the shrinkage mapping known as soft
thresholding, and can be shown to recover the original solution under certain
hypotheses. Recent work has derived a general class of shrinkages and
associated nonconvex penalties that better approximate the original $\ell^0$
penalty and empirically can recover the original solution from fewer
measurements. We specifically examine p-shrinkage and firm thresholding. In
this work, we prove that given data and a measurement matrix from a broad class
of matrices, one can choose parameters for these classes of shrinkages to
guarantee exact recovery of the sparsest solution. We further prove convergence
of the algorithm iterative p-shrinkage (IPS) for solving one such relaxed
problem.
</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02923</dc:identifier>
 <dc:identifier>doi:10.1088/0266-5611/32/7/075004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02926</identifier>
 <datestamp>2016-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strategic Interaction Among Different Entities in Internet of Things</dc:title>
 <dc:creator>Ghosh, Arnob</dc:creator>
 <dc:creator>Sarkar, Saswati</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The economic model of the Internet of Things (IoT) consists of end users,
advertisers and three different kinds of providers--IoT service provider
(IoTSP), Wireless service provider (WSP) and cloud service provider (CSP). We
investigate three different kinds of interactions among the providers. First,
we consider that the IoTSP prices a bundled service to the end-users, and the
WSP and CSP pay the IoTSP (push model). Next, we consider the model where the
end-users independently pay the each provider (pull model). Finally, we
consider a hybrid model of the above two where the IoTSP and WSP quote their
prices to the end-users, but the CSP quotes its price to the IoTSP.
  We characterize and quantify the impact of the advertisement revenue on the
equilibrium pricing strategy and payoff of providers, and corresponding demands
of end users in each of the above interaction models. Our analysis reveals that
the demand of end-users, and the payoffs of the providers are non decreasing
functions of the advertisement revenue. For sufficiently high advertisement
revenue, the IoTSP will offer its service free of cost in each interaction
model. However, the payoffs of the providers, and the demand of end-users vary
across different interaction models. Our analysis shows that the demand of
end-users, and the payoff of the WSP are the highest in the pull (push, resp.)
model in the low (high, resp.) advertisement revenue regime. The payoff of the
IoTSP is always higher in the pull model irrespective of the advertisement
revenue. The payoff of the CSP is the highest in the hybrid model in the low
advertisement revenue regime. However, in the high advertisement revenue regime
the payoff of the CSP in the hybrid model or in the push model can be higher
depending on the equilibrium chosen in the push model.
</dc:description>
 <dc:description>Comment: Submitted in IEEE Transactions on Automatic Control</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:date>2016-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02926</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02930</identifier>
 <datestamp>2016-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge reduction of dynamic covering decision information systems
  with varying attribute values</dc:title>
 <dc:creator>Cai, Mingjie</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Knowledge reduction of dynamic covering information systems involves with the
time in practical situations. In this paper, we provide incremental approaches
to computing the type-1 and type-2 characteristic matrices of dynamic coverings
because of varying attribute values. Then we present incremental algorithms of
constructing the second and sixth approximations of sets by using
characteristic matrices. We employ experimental results to illustrate that the
incremental approaches are effective to calculate approximations of sets in
dynamic covering information systems. Finally, we perform knowledge reduction
of dynamic covering information systems with the incremental approaches.
</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02930</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02931</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Correntropy for Robust Adaptive Filtering</dc:title>
 <dc:creator>Chen, Badong</dc:creator>
 <dc:creator>Xing, Lei</dc:creator>
 <dc:creator>Zhao, Haiquan</dc:creator>
 <dc:creator>Zheng, Nanning</dc:creator>
 <dc:creator>Pr&#xed;ncipe, Jos&#xe9; C.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  As a robust nonlinear similarity measure in kernel space, correntropy has
received increasing attention in domains of machine learning and signal
processing. In particular, the maximum correntropy criterion (MCC) has recently
been successfully applied in robust regression and filtering. The default
kernel function in correntropy is the Gaussian kernel, which is, of course, not
always the best choice. In this work, we propose a generalized correntropy that
adopts the generalized Gaussian density (GGD) function as the kernel (not
necessarily a Mercer kernel), and present some important properties. We further
propose the generalized maximum correntropy criterion (GMCC), and apply it to
adaptive filtering. An adaptive algorithm, called the GMCC algorithm, is
derived, and the mean square convergence performance is studied. We show that
the proposed algorithm is very stable and can achieve zero probability of
divergence (POD). Simulation results confirm the theoretical expectations and
demonstrate the desirable performance of the new algorithm.
</dc:description>
 <dc:description>Comment: 34 pages, 9 figures, submitted to IEEE Transactions on Signal
  Processing</dc:description>
 <dc:date>2015-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02931</dc:identifier>
 <dc:identifier>IEEE Trans. on Signal Processing, vol. 64, no. 13, pp. 3376-3387,
  2016</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2539127</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02944</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Efficiency of Far-Field Wireless Power Transfer</dc:title>
 <dc:creator>Xia, Minghua</dc:creator>
 <dc:creator>A&#xef;ssa, Sonia</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Far-field wireless power transfer (WPT) is a promising technique to resolve
the painstaking power-charging problem inherent in various wireless terminals.
This paper investigates the power transfer efficiency of the WPT segment in
future communication systems in support of simultaneous power and data
transfer, by means of analytically computing the time-average output direct
current (DC) power at user equipments (UEs). In order to investigate the effect
of channel variety among UEs on the average output DC power, different policies
for the scheduling of the power transfer among the users are implemented and
compared in two scenarios: homogeneous, whereby users are symmetric and
experience similar path loss, and heterogeneous, whereby users are asymmetric
and exhibit different path losses. Specifically, if opportunistic scheduling is
performed among $N$ symmetric/asymmetric UEs, the power scaling laws are
attained by using extreme value theory, and reveal that the gain in power
transfer efficiency is $\ln{N}$ if UEs are symmetric whereas the gain is $N$ if
UEs are asymmetric, compared with that of conventional round-robin scheduling.
Thus, the channel variety among UEs inherent to the wireless environment can be
exploited by opportunistic scheduling to significantly improve the power
transfer efficiency when designing future wireless communication systems in
support of simultaneous power and data transfer.
</dc:description>
 <dc:description>Comment: 13 pages, to appear in IEEE Transactions on Signal Processing</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02944</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2015.2417497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02945</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Transform: Cocktail Party Source Separation via Complex Convolution
  in a Deep Neural Network</dc:title>
 <dc:creator>Simpson, Andrew J. R.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>68Txx</dc:subject>
 <dc:description>  Convolutional deep neural networks (DNN) are state of the art in many
engineering problems but have not yet addressed the issue of how to deal with
complex spectrograms. Here, we use circular statistics to provide a convenient
probabilistic estimate of spectrogram phase in a complex convolutional DNN. In
a typical cocktail party source separation scenario, we trained a convolutional
DNN to re-synthesize the complex spectrograms of two source speech signals
given a complex spectrogram of the monaural mixture - a discriminative deep
transform (DT). We then used this complex convolutional DT to obtain
probabilistic estimates of the magnitude and phase components of the source
spectrograms. Our separation results are on a par with equivalent binary-mask
based non-complex separation approaches.
</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02947</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Looking at Mean-Payoff through Foggy Windows</dc:title>
 <dc:creator>Hunter, Paul</dc:creator>
 <dc:creator>P&#xe9;rez, Guillermo A.</dc:creator>
 <dc:creator>Raskin, Jean-Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Mean-payoff games (MPGs) are infinite duration two-player zero-sum games
played on weighted graphs. Under the hypothesis of perfect information, they
admit memoryless optimal strategies for both players and can be solved in
NP-intersect-coNP. MPGs are suitable quantitative models for open reactive
systems. However, in this context the assumption of perfect information is not
always realistic. For the partial-observation case, the problem that asks if
the first player has an observation-based winning strategy that enforces a
given threshold on the mean-payoff, is undecidable. In this paper, we study the
window mean-payoff objectives that were introduced recently as an alternative
to the classical mean-payoff objectives. We show that, in sharp contrast to the
classical mean-payoff objectives, some of the window mean-payoff objectives are
decidable in games with partial-observation.
</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02949</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-wellfounded trees in Homotopy Type Theory</dc:title>
 <dc:creator>Ahrens, Benedikt</dc:creator>
 <dc:creator>Capriotti, Paolo</dc:creator>
 <dc:creator>Spadotti, R&#xe9;gis</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  We prove a conjecture about the constructibility of coinductive types - in
the principled form of indexed M-types - in Homotopy Type Theory. The
conjecture says that in the presence of inductive types, coinductive types are
derivable. Indeed, in this work, we construct coinductive types in a subsystem
of Homotopy Type Theory; this subsystem is given by Intensional Martin-L\&quot;of
type theory with natural numbers and Voevodsky's Univalence Axiom. Our results
are mechanized in the computer proof assistant Agda.
</dc:description>
 <dc:description>Comment: 14 pages, to be published in proceedings of TLCA 2015; ancillary
  files contain Agda files with formalized proofs</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02949</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02954</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-scale Antenna Operation in Heterogeneous Cloud Radio Access
  Networks: A Partial Centralization Approach</dc:title>
 <dc:creator>Park, Sangkyu</dc:creator>
 <dc:creator>Chae, Chan-Byoung</dc:creator>
 <dc:creator>Bahk, Saewoong</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  To satisfy the ever-increasing capacity demand and quality of service (QoS)
requirements of users, 5G cellular systems will take the form of heterogeneous
networks (HetNets) that consist of macro cells and small cells. To build and
operate such systems, mobile operators have given significant attention to
cloud radio access networks (C-RANs) due to their beneficial features of
performance optimization and cost effectiveness. Along with the architectural
enhancement of C-RAN, large-scale antennas (a.k.a. massive MIMO) at cell sites
contribute greatly to increased network capacity either with higher spectral
efficiency or through permitting many users at once. In this article, we
discuss the challenging issues of C-RAN based HetNets (H-CRAN), especially with
respect to large-scale antenna operation. We provide an overview of existing
C-RAN architectures in terms of large-scale antenna operation and promote a
partially centralized approach. This approach reduces, remarkably, fronthaul
overheads in CRANs with large-scale antennas. We also provide some insights
into its potential and applicability in the fronthaul bandwidthlimited H-CRAN
with large-scale antennas.
</dc:description>
 <dc:description>Comment: To appear in IEEE Wireless Communications Magazine June 2015</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:date>2015-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02954</dc:identifier>
 <dc:identifier>doi:10.1109/MWC.2015.7143324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02957</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intelligent Implementation Processor Design for Oracle Distributed
  Databases System</dc:title>
 <dc:creator>Hassen, Fadoua</dc:creator>
 <dc:creator>Touzi, Amel Grissa</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Despite the increasing need for modeling and implementing Distributed
Databases (DDB), distributed database management systems are still quite far
from helping the designer to directly implement its BDD. Indeed, the
fundamental principle of implementation of a DDB is to make the database appear
as a centralized database, providing series of transparencies, something that
is not provided directly by the current DDBMS. We focus in this work on Oracle
DBMS which, despite its market dominance, offers only a few logical mechanisms
to implement distribution. To remedy this problem, we propose a new
architecture of DDBMS Oracle. The idea is based on extending it by an
intelligent layer that provides: 1) creation of different types of
fragmentation through a GUI for defining different sites geographically
dispersed 2) allocation and replication of DB. The system must automatically
generate SQL scripts for each site of the original configuration.
</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02957</dc:identifier>
 <dc:identifier>International Conference on Control, Engineering &amp; Information
  Technology (CEIT 2014), pp. 278-296, Tunisie, 2014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02967</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotic Compatibility between LOCC Conversion and Recovery</dc:title>
 <dc:creator>Ito, Kosuke</dc:creator>
 <dc:creator>Kumagai, Wataru</dc:creator>
 <dc:creator>Hayashi, Masahito</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Recently, entanglement concentration was explicitly shown to be irreversible.
However, it is still not clear what kind of states can be reversibly converted
in the asymptotic setting by LOCC when neither the initial nor the target state
is maximally entangled. We derive the necessary and sufficient condition for
the reversibility of LOCC conversions between two bipartite pure entangled
states in the asymptotic setting. In addition, we show that conversion can be
achieved perfectly with only local unitary operation under such condition
except for special cases. Interestingly, our result implies that an error-free
reversible conversion is asymptotically possible even between states whose
copies can never be locally unitarily equivalent with any finite numbers of
copies, although such a conversion is impossible in the finite setting. In
fact, we show such an example. Moreover, we establish how to overcome the
irreversibility of LOCC conversion in two ways. As for the first method, we
evaluate how many copies of the initial state is to be lost to overcome the
irreversibility of LOCC conversion. The second method is to add a supplementary
state appropriately, which also works for LU conversion unlike the first
method. Especially, for the qubit system, any non-maximally pure entangled
state can be a universal resource for the asymptotic reversibility when copies
of the state is sufficiently many. More interestingly, our analysis implies
that far-from-maximally entangled states can be better than nearly maximally
entangled states as this type of resource. This fact brings new insight to the
resource theory of state conversion.
</dc:description>
 <dc:description>Comment: 16 pages, 6 figures</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:date>2015-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02967</dc:identifier>
 <dc:identifier>Phys. Rev. A 92, 052308 (2015)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevA.92.052308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02972</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing trading strategies based on financial sentiment data using
  evolutionary optimization</dc:title>
 <dc:creator>Hochreiter, Ronald</dc:creator>
 <dc:subject>Quantitative Finance - Portfolio Management</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper we apply evolutionary optimization techniques to compute
optimal rule-based trading strategies based on financial sentiment data. The
sentiment data was extracted from the social media service StockTwits to
accommodate the level of bullishness or bearishness of the online trading
community towards certain stocks. Numerical results for all stocks from the Dow
Jones Industrial Average (DJIA) index are presented and a comparison to
classical risk-return portfolio selection is provided.
</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02975</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classification with Extreme Learning Machine and Ensemble Algorithms
  Over Randomly Partitioned Data</dc:title>
 <dc:creator>&#xc7;atak, Ferhat &#xd6;zg&#xfc;r</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this age of Big Data, machine learning based data mining methods are
extensively used to inspect large scale data sets. Deriving applicable
predictive modeling from these type of data sets is a challenging obstacle
because of their high complexity. Opportunity with high data availability
levels, automated classification of data sets has become a critical and
complicated function. In this paper, the power of applying MapReduce based
Distributed AdaBoosting of Extreme Learning Machine (ELM) are explored to build
reliable predictive bag of classification models. Thus, (i) dataset ensembles
are build; (ii) ELM algorithm is used to build weak classification models; and
(iii) build a strong classification model from a set of weak classification
models. This training model is applied to the publicly available knowledge
discovery and data mining datasets.
</dc:description>
 <dc:description>Comment: In Turkish, SIU</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02975</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02978</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of Block Markov Superposition Transmission of Short
  Codes</dc:title>
 <dc:creator>Huang, Kechao</dc:creator>
 <dc:creator>Ma, Xiao</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider the asymptotic and finite-length performance of
block Markov superposition transmission~(BMST) of short codes, which can be
viewed as a new class of spatially coupled~(SC) codes with the generator
matrices of short codes~(referred to as {\em basic codes}) coupled. A modified
extrinsic information transfer~(EXIT) chart analysis that takes into account
the relation between mutual information~(MI) and bit-error-rate~(BER) is
presented to study the convergence behavior of BMST codes. Using the modified
EXIT chart analysis, we investigate the impact of various parameters on BMST
code performance, thereby providing theoretical guidance for designing and
implementing practical BMST codes suitable for sliding window decoding. Then,
we present a performance comparison of BMST codes and SC low-density
parity-check (SC-LDPC) codes on the basis of equal decoding latency. Also
presented is a comparison of computational complexity. Simulation results show
that, under the equal decoding latency constraint, BMST codes using the
repetition code as the basic code can outperform $(3,6)$-regular SC-LDPC codes
in the waterfall region but have a higher computational complexity.
</dc:description>
 <dc:description>Comment: Submitted to the IEEE Journal on Selected Areas in Communications</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02978</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02980</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Antenna Relay Aided Wireless Physical Layer Security</dc:title>
 <dc:creator>Chen, Xiaoming</dc:creator>
 <dc:creator>Zhong, Caijun</dc:creator>
 <dc:creator>Yuen, Chau</dc:creator>
 <dc:creator>Chen, Hsiao-Hwa</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  With growing popularity of mobile Internet, providing secure wireless
services has become a critical issue. Physical layer security (PHY-security)
has been recognized as an effective means to enhance wireless security by
exploiting wireless medium characteristics, e.g., fading, noise, and
interference. A particularly interesting PHY-security technology is cooperative
relay due to the fact that it helps to provide distributed diversity and
shorten access distance. This article offers a tutorial on various
multi-antenna relaying technologies to improve security at physical layer. The
state of the art research results on multi-antenna relay aided PHY-security as
well as some secrecy performance optimization schemes are presented. In
particular, we focus on large-scale MIMO (LS-MIMO) relaying technology, which
is effective to tackle various challenging issues for implementing wireless
PHY-security, such as short-distance interception without eavesdropper channel
state information (CSI) and with imperfect legitimate CSI. Moreover, the future
directions are identified for further enhancement of secrecy performance.
</dc:description>
 <dc:description>Comment: 17 pages, 4 figures, IEEE Communications Magazine, 2015</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02980</dc:identifier>
 <dc:identifier>doi:10.1109/MCOM.2015.7355564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.02990</identifier>
 <datestamp>2015-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Complexity Downlink User Selection for Massive MIMO Systems</dc:title>
 <dc:creator>Liu, Haijing</dc:creator>
 <dc:creator>Gao, Hui</dc:creator>
 <dc:creator>Yang, Shaoshi</dc:creator>
 <dc:creator>Lv, Tiejun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we propose a pair of low-complexity user selection schemes with
zero-forcing precoding for multiuser massive MIMO downlink systems, in which
the base station is equipped with a large-scale antenna array. First, we derive
approximations of the ergodic sum rates of the systems invoking the
conventional random user selection (RUS) and the location-dependant user
selection (LUS). Then, the optimal number of simultaneously served user
equipments (UEs), $K^*$, is investigated to maximize the sum rate
approximations. Upon exploiting $K^*$, we develop two user selection schemes,
namely $K^*$-RUS and $K^*$-LUS, where $K^*$ UEs are selected either randomly or
based on their locations. Both of the proposed schemes are independent of the
instantaneous channel state information of small-scale fading, therefore
enjoying the same extremely-low computational complexity as that of the
conventional RUS scheme. Moreover, both of our proposed schemes achieve
significant sum rate improvement over the conventional RUS. In addition, it is
worth noting that like the conventional RUS, the $K^*$-RUS achieves good
fairness among UEs.
</dc:description>
 <dc:description>Comment: 11 pages, 27 figures, Accepted to publish on IEEE Systems Journal --
  Special Issue on 5G Wireless Systems with Massive MIMO, Apr. 2015</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.02990</dc:identifier>
 <dc:identifier>doi:10.1109/JSYST.2015.2422475</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03004</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Scalability of LISP Mappings Caches</dc:title>
 <dc:creator>Coras, Florin</dc:creator>
 <dc:creator>Domingo-Pascual, Jordi</dc:creator>
 <dc:creator>Cabellos-Aparicio, Albert</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The Locator/ID Separation Protocol (LISP) limits the growth of the
Default-Free Zone routing tables by creating a highly aggregatable and
quasi-static Internet core. However, LISP pushes the forwarding state to edge
routers whose timely operation relies on caching of location to identity
bindings. In this paper we develop an analytical model to study the asymptotic
scalability of the LISP cache. Under the assumptions that (i) long-term
popularity can be modeled as a constant Generalized Zipf distribution and (ii)
temporal locality is predominantly determined by long-term popularity, we find
that the scalability of the LISP cache is O(1) with respect to the amount of
prefixes (Internet growth) and users (growth of the LISP site). We validate the
model and discuss the accuracy of our assumptions using several one-day-long
packet traces.
</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03013</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cellular Automata are Generic</dc:title>
 <dc:creator>Dershowitz, Nachum</dc:creator>
 <dc:creator>Falkovich, Evgenia</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Any algorithm (in the sense of Gurevich's abstract-state-machine
axiomatization of classical algorithms) operating over any arbitrary unordered
domain can be simulated by a dynamic cellular automaton, that is, by a
pattern-directed cellular automaton with unconstrained topology and with the
power to create new cells. The advantage is that the latter is closer to
physical reality. The overhead of our simulation is quadratic.
</dc:description>
 <dc:description>Comment: In Proceedings DCM 2014, arXiv:1504.01927</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03013</dc:identifier>
 <dc:identifier>EPTCS 179, 2015, pp. 17-32</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.179.2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03014</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings 6th Workshop on Formal Methods and Analysis in SPL
  Engineering</dc:title>
 <dc:creator>Atlee, Joanne M.</dc:creator>
 <dc:creator>Gnesi, Stefania</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The workshop aims at reviewing the state of the art and the state of the
practice in which formal methods and analysis approaches are currently applied
in SPLE. This leads to a discussion of a research agenda for the extension of
existing formal approaches and the development of new formal techniques for
dealing with the particular needs of SPLE. To achieve the above objectives, the
workshop is intended as a highly interactive event fostering discussion and
initiating collaborations between the participants from both communities.
</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03014</dc:identifier>
 <dc:identifier>EPTCS 182, 2015</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.182</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03016</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Power Talk: How to Modulate Data over a DC Micro Grid Bus using Power
  Electronics</dc:title>
 <dc:creator>Angjelichinoski, Marko</dc:creator>
 <dc:creator>Stefanovic, Cedomir</dc:creator>
 <dc:creator>Popovski, Petar</dc:creator>
 <dc:creator>Liu, Hongpeng</dc:creator>
 <dc:creator>Loh, Poh Chiang</dc:creator>
 <dc:creator>Blaabjerg, Frede</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We introduce a novel communication strategy for DC Micro Grids (MGs), termed
power talk, in which the devices communicate by modulating the power levels in
the DC bus. The information is transmitted by varying the parameters that the
MG units use to control the level of the common bus voltage, while it is
received by processing the bus measurements that units perform. This
communication is challenged by the fact that the voltage level is subject to
random disturbances, as the state of the MG changes with random load
variations. We develop a corresponding communication model and address the
random voltage fluctuations by using coding strategies that transform the MG
into some well-known communication channels. The performance analysis shows
that it is possible to mitigate the random voltage level variations and
communicate reliably over the MG bus.
</dc:description>
 <dc:description>Comment: IEEE GLOBECOM 2015</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03021</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Elastic properties of the degenerate f.c.c. crystal of polydisperse soft
  dimers at zero temperature</dc:title>
 <dc:creator>Narojczyk, J. W.</dc:creator>
 <dc:creator>Wojciechowski, K. W.</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Condensed Matter - Soft Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Elastic properties of soft, three-dimensional dimers, interacting through
site-site n-inverse-power potential, are determined by computer simulations at
zero temperature. The degenerate crystal of dimers exhibiting (Gaussian) size
distribution of atomic diameters - i.e. size polydispersity - is studied at the
molecular number density $1/\sqrt{2}$; the distance between centers of atoms
forming dimers is considered as a length unit. It is shown that, at the fixed
number density of the dimers, increasing polydispersity causes, typically, an
increase of pressure, elastic constants and Poisson's ratio; the latter is
positive in most direction. A direction is found, however, in which the size
polydispersity causes substantial decrease of Poisson's ratio, down to negative
values for large $n$. Thus, the system is partially auxetic for large
polydispersity and large n.
</dc:description>
 <dc:description>Comment: Conference: International Workshop on Functional and Nanostructured
  Materials (FNMA)/International Conference on Intermolecular and Magnetic
  Interactions in Matter (IMIM) Location: L'Aquila, ITALY Date: SEP 27-30,2009</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03021</dc:identifier>
 <dc:identifier>Journal of Non Crystalline Solids. 356 pp. 2026-2032 (2010)</dc:identifier>
 <dc:identifier>doi:10.1016/j.jnoncrysol.2010.05.080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03024</identifier>
 <datestamp>2015-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Almost Lossless Analog Compression without Phase Information</dc:title>
 <dc:creator>Riegler, Erwin</dc:creator>
 <dc:creator>Taub&#xf6;ck, Georg</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose an information-theoretic framework for phase retrieval.
Specifically, we consider the problem of recovering an unknown n-dimensional
vector x up to an overall sign factor from m=Rn phaseless measurements with
compression rate R and derive a general achievability bound for R.
Surprisingly, it turns out that this bound on the compression rate is the same
as the one for almost lossless analog compression obtained by Wu and Verd\'u
(2010): Phaseless linear measurements are as good as linear measurements with
full phase information in the sense that ignoring the sign of m measurements
only leaves us with an ambiguity with respect to an overall sign factor of x.
</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:date>2015-04-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03026</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of a Classical Matrix Preconditioning Algorithm</dc:title>
 <dc:creator>Schulman, Leonard J.</dc:creator>
 <dc:creator>Sinclair, Alistair</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65F08</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>G.1.3</dc:subject>
 <dc:description>  We study a classical iterative algorithm for balancing matrices in the
$L_\infty$ norm via a scaling transformation. This algorithm, which goes back
to Osborne and Parlett \&amp; Reinsch in the 1960s, is implemented as a standard
preconditioner in many numerical linear algebra packages. Surprisingly, despite
its widespread use over several decades, no bounds were known on its rate of
convergence. In this paper we prove that, for any irreducible $n\times n$ (real
or complex) input matrix~$A$, a natural variant of the algorithm converges in
$O(n^3\log(n\rho/\varepsilon))$ elementary balancing operations, where $\rho$
measures the initial imbalance of~$A$ and $\varepsilon$ is the target imbalance
of the output matrix. (The imbalance of~$A$ is $\max_i
|\log(a_i^{\text{out}}/a_i^{\text{in}})|$, where
$a_i^{\text{out}},a_i^{\text{in}}$ are the maximum entries in magnitude in the
$i$th row and column respectively.) This bound is tight up to the $\log n$
factor. A balancing operation scales the $i$th row and column so that their
maximum entries are equal, and requires $O(m/n)$ arithmetic operations on
average, where $m$ is the number of non-zero elements in~$A$. Thus the running
time of the iterative algorithm is $\tilde{O}(n^2m)$. This is the first time
bound of any kind on any variant of the Osborne-Parlett-Reinsch algorithm. We
also prove a conjecture of Chen that characterizes those matrices for which the
limit of the balancing process is independent of the order in which balancing
operations are performed.
</dc:description>
 <dc:description>Comment: The previous version (1) (see also STOC'15) handled UB (&quot;unique
  balance&quot;) input matrices. In this version (2) we extend the work to handle
  all input matrices</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:date>2015-06-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03033</identifier>
 <datestamp>2015-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the stability of the PWP method</dc:title>
 <dc:creator>Diaz, Rafael</dc:creator>
 <dc:creator>Vargas, Angelica</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The PWP method was introduced by Diaz in 2009 as a technique for measuring
indirect influences in complex networks. It depends on a matrix D, provided by
the user, called the matrix of direct influences, and on a positive real
parameter which is part of the method itself. We study changes in the method's
predictions as D and the parameter vary.
</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:date>2015-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03048</identifier>
 <datestamp>2017-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The weight distributions of two classes of p ary cyclic codes with few
  weights</dc:title>
 <dc:creator>Yang, Shudi</dc:creator>
 <dc:creator>Yao, Zheng-An</dc:creator>
 <dc:creator>Zhao, Chang-An</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>11T71 94B15</dc:subject>
 <dc:description>  Cyclic codes have attracted a lot of research interest for decades as they
have efficient encoding and decoding algorithms.
  In this paper, for an odd prime $p$, the weight distributions of two classes
of $p$-ary cyclic codes are completely determined. We show that both codes have
at most five nonzero weights.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2015-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03048</dc:identifier>
 <dc:identifier>doi:10.1016/j.ffa.2016.11.004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03068</identifier>
 <datestamp>2015-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Review Mining for Feature Based Opinion Summarization and Visualization</dc:title>
 <dc:creator>Kamal, Ahmad</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The application and usage of opinion mining, especially for business
intelligence, product recommendation, targeted marketing etc. have fascinated
many research attentions around the globe. Various research efforts attempted
to mine opinions from customer reviews at different levels of granularity,
including word-, sentence-, and document-level. However, development of a fully
automatic opinion mining and sentiment analysis system is still elusive. Though
the development of opinion mining and sentiment analysis systems are getting
momentum, most of them attempt to perform document-level sentiment analysis,
classifying a review document as positive, negative, or neutral. Such
document-level opinion mining approaches fail to provide insight about users
sentiment on individual features of a product or service. Therefore, it seems
to be a great help for both customers and manufacturers, if the reviews could
be processed at a finer-grained level and presented in a summarized form
through some visual means, highlighting individual features of a product and
users sentiment expressed over them. In this paper, the design of a unified
opinion mining and sentiment analysis framework is presented at the
intersection of both machine learning and natural language processing
approaches. Also, design of a novel feature-level review summarization scheme
is proposed to visualize mined features, opinions and their polarity values in
a comprehendible way.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, 2 tables</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:date>2015-04-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03068</dc:identifier>
 <dc:identifier>International Journal of Computer Applications, 119(17), 2015, pp.
  6-13</dc:identifier>
 <dc:identifier>doi:10.5120/21157-4183</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03071</identifier>
 <datestamp>2015-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robobarista: Object Part based Transfer of Manipulation Trajectories
  from Crowd-sourcing in 3D Pointclouds</dc:title>
 <dc:creator>Sung, Jaeyong</dc:creator>
 <dc:creator>Jin, Seok Hyun</dc:creator>
 <dc:creator>Saxena, Ashutosh</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  There is a large variety of objects and appliances in human environments,
such as stoves, coffee dispensers, juice extractors, and so on. It is
challenging for a roboticist to program a robot for each of these object types
and for each of their instantiations. In this work, we present a novel approach
to manipulation planning based on the idea that many household objects share
similarly-operated object parts. We formulate the manipulation planning as a
structured prediction problem and design a deep learning model that can handle
large noise in the manipulation demonstrations and learns features from three
different modalities: point-clouds, language and trajectory. In order to
collect a large number of manipulation demonstrations for different objects, we
developed a new crowd-sourcing platform called Robobarista. We test our model
on our dataset consisting of 116 objects with 249 parts along with 250 language
instructions, for which there are 1225 crowd-sourced manipulation
demonstrations. We further show that our robot can even manipulate objects it
has never seen before.
</dc:description>
 <dc:description>Comment: In International Symposium on Robotics Research (ISRR) 2015</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:date>2015-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03071</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03076</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A High Reliability Asymptotic Approach for Packet Inter-Delivery Time
  Optimization in Cyber-Physical Systems</dc:title>
 <dc:creator>Guo, Xueying</dc:creator>
 <dc:creator>Singh, Rahul</dc:creator>
 <dc:creator>Kumar, P. R.</dc:creator>
 <dc:creator>Niu, Zhisheng</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:description>  In cyber-physical systems such as automobiles, measurement data from sensor
nodes should be delivered to other consumer nodes such as actuators in a
regular fashion. But, in practical systems over unreliable media such as
wireless, it is a significant challenge to guarantee small enough
inter-delivery times for different clients with heterogeneous channel
conditions and inter-delivery requirements. In this paper, we design scheduling
policies aiming at satisfying the inter-delivery requirements of such clients.
We formulate the problem as a risk-sensitive Markov Decision Process (MDP).
Although the resulting problem involves an infinite state space, we first prove
that there is an equivalent MDP involving only a finite number of states. Then
we prove the existence of a stationary optimal policy and establish an
algorithm to compute it in a finite number of steps.
  However, the bane of this and many similar problems is the resulting
complexity, and, in an attempt to make fundamental progress, we further propose
a new high reliability asymptotic approach. In essence, this approach considers
the scenario when the channel failure probabilities for different clients are
of the same order, and asymptotically approach zero. We thus proceed to
determine the asymptotically optimal policy: in a two-client scenario, we show
that the asymptotically optimal policy is a &quot;modified least time-to-go&quot; policy,
which is intuitively appealing and easily implementable; in the general
multi-client scenario, we are led to an SN policy, and we develop an algorithm
of low computational complexity to obtain it. Simulation results show that the
resulting policies perform well even in the pre-asymptotic regime with moderate
failure probabilities.
</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03076</dc:identifier>
 <dc:identifier>ACM Mobihoc 2015</dc:identifier>
 <dc:identifier>doi:10.1145/2746285.2746305.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03077</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Iterative-Promoting Variable Step-size Least Mean Square Algorithm For
  Adaptive Sparse Channel Estimation</dc:title>
 <dc:creator>Liu, Beiyi</dc:creator>
 <dc:creator>Gui, Guan</dc:creator>
 <dc:creator>Xu, Li</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Least mean square (LMS) type adaptive algorithms have attracted much
attention due to their low computational complexity. In the scenarios of sparse
channel estimation, zero-attracting LMS (ZA-LMS), reweighted ZA-LMS (RZA-LMS)
and reweighted -norm LMS (RL1-LMS) have been proposed to exploit channel
sparsity. However, these proposed algorithms may hard to make tradeoff between
convergence speed and estimation performance with only one step-size. To solve
this problem, we propose three sparse iterative-promoting variable step-size
LMS (IP-VSS-LMS) algorithms with sparse constraints, i.e. ZA, RZA and RL1.
These proposed algorithms are termed as ZA-IPVSS-LMS, RZA-IPVSS-LMS and
RL1-IPVSS-LMS respectively. Simulation results are provided to confirm
effectiveness of the proposed sparse channel estimation algorithms.
</dc:description>
 <dc:description>Comment: 6 pages, 10 figures, submitted for APCC2015</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03077</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03080</identifier>
 <datestamp>2015-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Inference of Genome Structure and Content in Heterogeneous Tumour
  Samples</dc:title>
 <dc:creator>McPherson, Andrew</dc:creator>
 <dc:creator>Roth, Andrew</dc:creator>
 <dc:creator>Ha, Gavin</dc:creator>
 <dc:creator>Shah, Sohrab P.</dc:creator>
 <dc:creator>Chauve, Cedric</dc:creator>
 <dc:creator>Sahinalp, S. Cenk</dc:creator>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  For a genomically unstable cancer, a single tumour biopsy will often contain
a mixture of competing tumour clones. These tumour clones frequently differ
with respect to their genomic content (copy number of each gene) and structure
(order of genes on each chromosome). Modern bulk genome sequencing mixes the
signals of tumour clones and contaminating normal cells, complicating inference
of genomic content and structure. We propose a method to unmix tumour and
contaminating normal signals and jointly predict genomic structure and content
of each tumour clone. We use genome graphs to represent tumour clones, and
model the likelihood of the observed reads given clones and mixing proportions.
Our use of haplotype blocks allows us to accurately measure allele specific
read counts, and infer allele specific copy number for each clone. The proposed
method is a heuristic local search based on applying incremental, locally
optimal modifications of the genome graphs. Using simulated data, we show that
our method predicts copy counts and gene adjacencies with reasonable accuracy.
</dc:description>
 <dc:description>Comment: Presented at RECOMB 2015</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:date>2015-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03083</identifier>
 <datestamp>2015-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Learning of Distributed Representations for Images and Texts</dc:title>
 <dc:creator>He, Xiaodong</dc:creator>
 <dc:creator>Srivastava, Rupesh</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:creator>Deng, Li</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This technical report provides extra details of the deep multimodal
similarity model (DMSM) which was proposed in (Fang et al. 2015,
arXiv:1411.4952). The model is trained via maximizing global semantic
similarity between images and their captions in natural language using the
public Microsoft COCO database, which consists of a large set of images and
their corresponding captions. The learned representations attempt to capture
the combination of various visual concepts and cues.
</dc:description>
 <dc:description>Comment: This is a previous tech report of a part of the work of
  arXiv:1411.4952. In order to avoid confusion, we'd like to withdraw this
  report from arXiv</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:date>2015-04-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03095</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Inference Attack Model for Flow Table Capacity and Usage: Exploiting
  the Vulnerability of Flow Table Overflow in Software-Defined Network</dc:title>
 <dc:creator>Leng, Junyuan</dc:creator>
 <dc:creator>Zhou, Yadong</dc:creator>
 <dc:creator>Zhang, Junjie</dc:creator>
 <dc:creator>Hu, Chengchen</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  As the most competitive solution for next-generation network,
software-defined network (SDN) and its dominant implementation OpenFlow, are
attracting more and more interests. But besides convenience and flexibility,
SDN/OpenFlow also introduces new kinds of limitations and security issues. Of
these limitations, the most obvious and maybe the most neglected one, is the
flow table capacity of SDN/OpenFlow switches.
  In this paper, we proposed a novel inference attack targeting at SDN/OpenFlow
network, which is motivated by the limited flow table capacities of
SDN/OpenFlow switches and the following measurable network performance decrease
resulting from frequent interactions between data plane and control plane when
the flow table is full. To our best knowledge, this is the first proposed
inference attack model of this kind for SDN/OpenFlow. We also implemented an
inference attack framework according to our model and examined its efficiency
and accuracy. The simulation results demonstrate that our framework can infer
the network parameters(flow table capacity and flow table usage) with an
accuracy of 80% or higher. These findings give us a deeper understanding of
SDN/OpenFlow limitations and serve as guidelines to future improvements of
SDN/OpenFlow.
</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03097</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sampling promotes community structure in social and information networks</dc:title>
 <dc:creator>Blagus, Neli</dc:creator>
 <dc:creator>&#x160;ubelj, Lovro</dc:creator>
 <dc:creator>Weiss, Gregor</dc:creator>
 <dc:creator>Bajec, Marko</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Any network studied in the literature is inevitably just a sampled
representative of its real-world analogue. Additionally, network sampling is
lately often applied to large networks to allow for their faster and more
efficient analysis. Nevertheless, the changes in network structure introduced
by sampling are still far from understood. In this paper, we study the presence
of characteristic groups of nodes in sampled social and information networks.
We consider different network sampling techniques including random node and
link selection, network exploration and expansion. We first observe that the
structure of social networks reveals densely linked groups like communities,
while the structure of information networks is better described by modules of
structurally equivalent nodes. However, despite these notable differences, the
structure of sampled networks exhibits stronger characterization by
community-like groups than the original networks, irrespective of their type
and consistently across various sampling techniques. Hence, rich community
structure commonly observed in social and information networks is to some
extent merely an artifact of sampling.
</dc:description>
 <dc:description>Comment: 15 pages, 6 figures, 5 tables</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03097</dc:identifier>
 <dc:identifier>Physica A 432, 206-215 (2015)</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2015.03.048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03101</identifier>
 <datestamp>2015-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convex Learning of Multiple Tasks and their Structure</dc:title>
 <dc:creator>Ciliberto, Carlo</dc:creator>
 <dc:creator>Mroueh, Youssef</dc:creator>
 <dc:creator>Poggio, Tomaso</dc:creator>
 <dc:creator>Rosasco, Lorenzo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Reducing the amount of human supervision is a key problem in machine learning
and a natural approach is that of exploiting the relations (structure) among
different tasks. This is the idea at the core of multi-task learning. In this
context a fundamental question is how to incorporate the tasks structure in the
learning problem.We tackle this question by studying a general computational
framework that allows to encode a-priori knowledge of the tasks structure in
the form of a convex penalty; in this setting a variety of previously proposed
methods can be recovered as special cases, including linear and non-linear
approaches. Within this framework, we show that tasks and their structure can
be efficiently learned considering a convex optimization problem that can be
approached by means of block coordinate methods such as alternating
minimization and for which we prove convergence to the global minimum.
</dc:description>
 <dc:description>Comment: 26 pages, 1 figure, 2 tables</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:date>2015-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03106</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Multiple Visual Tasks while Discovering their Structure</dc:title>
 <dc:creator>Ciliberto, Carlo</dc:creator>
 <dc:creator>Rosasco, Lorenzo</dc:creator>
 <dc:creator>Villa, Silvia</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Multi-task learning is a natural approach for computer vision applications
that require the simultaneous solution of several distinct but related
problems, e.g. object detection, classification, tracking of multiple agents,
or denoising, to name a few. The key idea is that exploring task relatedness
(structure) can lead to improved performances.
  In this paper, we propose and study a novel sparse, non-parametric approach
exploiting the theory of Reproducing Kernel Hilbert Spaces for vector-valued
functions. We develop a suitable regularization framework which can be
formulated as a convex optimization problem, and is provably solvable using an
alternating minimization approach. Empirical tests show that the proposed
method compares favorably to state of the art techniques and further allows to
recover interpretable structures, a problem of interest in its own right.
</dc:description>
 <dc:description>Comment: 19 pages, 3 figures, 3 tables</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03109</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DVB-S2x Enabled Precoding for High Throughput Satellite Systems</dc:title>
 <dc:creator>Arapoglou, Pantelis-Daniel</dc:creator>
 <dc:creator>Ginesi, Alberto</dc:creator>
 <dc:creator>Cioni, Stefano</dc:creator>
 <dc:creator>Erl, Stefan</dc:creator>
 <dc:creator>Clazzer, Federico</dc:creator>
 <dc:creator>Andrenacci, Stefano</dc:creator>
 <dc:creator>Vanelli-Coralli, Alessandro</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Multi-user Multiple-Input Multiple-Output (MU-MIMO) has allowed recent
releases of terrestrial LTE standards to achieve significant improvements in
terms of offered system capacity. The publications of the DVB-S2x standard and
particularly of its novel superframe structure is a key enabler for applying
similar interference management techniques -such as precoding- to multibeam
High Throughput Satellite (HTS) systems. This paper presents results resulting
from European Space Agency (ESA) funded R&amp;D activities concerning the practical
issues that arise when precoding is applied over an aggressive frequency re-use
HTS network. In addressing these issues, the paper also proposes pragmatic
solutions that have been developed in order to overcome these limitations.
Through the application of a comprehensive system simulator, it is demonstrated
that important capacity gains (beyond 40%) are to be expected from applying
precoding even after introducing a number of significant practical impairments.
</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03115</identifier>
 <datestamp>2017-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bibliometric author evaluation through linear regression on the coauthor
  network</dc:title>
 <dc:creator>Persson, Rasmus A. X.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  The rising trend of coauthored academic works obscures the credit assignment
that is the basis for decisions of funding and career advancements. In this
paper, a simple model based on the assumption of an unvarying &quot;author ability&quot;
is introduced. With this assumption, the weight of author contributions to a
body of coauthored work can be statistically estimated. The method is tested on
a set of some more than five-hundred authors in a coauthor network from the
CiteSeerX database. The ranking obtained agrees fairly well with that given by
total fractional citation counts for an author, but noticeable differences
exist.
</dc:description>
 <dc:description>Comment: 13 pages, 2 figures</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:date>2017-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03115</dc:identifier>
 <dc:identifier>Journal of Informetrics 11 (2017) pp. 299-306</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2017.01.003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03128</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Absolute Geometry Calibration of Distributed Microphone Arrays in an
  Audio-Visual Sensor Network</dc:title>
 <dc:creator>Jacob, Florian</dc:creator>
 <dc:creator>Haeb-Umbach, Reinhold</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Joint audio-visual speaker tracking requires that the locations of
microphones and cameras are known and that they are given in a common
coordinate system. Sensor self-localization algorithms, however, are usually
separately developed for either the acoustic or the visual modality and return
their positions in a modality specific coordinate system, often with an unknown
rotation, scaling and translation between the two. In this paper we propose two
techniques to determine the positions of acoustic sensors in a common
coordinate system, based on audio-visual correlates, i.e., events that are
localized by both, microphones and cameras separately. The first approach maps
the output of an acoustic self-calibration algorithm by estimating rotation,
scale and translation to the visual coordinate system, while the second solves
a joint system of equations with acoustic and visual directions of arrival as
input. The evaluation of the two strategies reveals that joint calibration
outperforms the mapping approach and achieves an overall calibration error of
0.20m even in reverberant environments.
</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03149</identifier>
 <datestamp>2015-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Transmission in Amplify-and-Forward Diamond Networks with a
  Single Eavesdropper</dc:title>
 <dc:creator>Sarma, Siddhartha</dc:creator>
 <dc:creator>Agnihotri, Samar</dc:creator>
 <dc:creator>Kuri, Joy</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Unicast communication over a network of $M$-parallel relays in the presence
of an eavesdropper is considered. The relay nodes, operating under individual
power constraints, amplify and forward the signals received at their inputs.
The problem of the maximum secrecy rate achievable with AF relaying is
addressed. Previous work on this problem provides iterative algorithms based on
semidefinite relaxation. However, those algorithms result in suboptimal
performance without any performance and convergence guarantees. We address this
problem for three specific network models, with real-valued channel gains. We
propose a novel transformation that leads to convex optimization problems. Our
analysis leads to (i)a polynomial-time algorithm to compute the optimal secure
AF rate for two of the models and (ii) a closed-form expression for the optimal
secure rate for the other.
</dc:description>
 <dc:description>Comment: 12pt font, 18 pages, 1 figure, conference</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:date>2015-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03151</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Massively Parallel Ray Tracing Algorithm Using GPU</dc:title>
 <dc:creator>Qin, Yutong</dc:creator>
 <dc:creator>Lin, Jianbiao</dc:creator>
 <dc:creator>Huang, Xiang</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Ray tracing is a technique for generating an image by tracing the path of
light through pixels in an image plane and simulating the effects of
high-quality global illumination at a heavy computational cost. Because of the
high computation complexity, it can't reach the requirement of real-time
rendering. The emergence of many-core architectures, makes it possible to
reduce significantly the running time of ray tracing algorithm by employing the
powerful ability of floating point computation. In this paper, a new GPU
implementation and optimization of the ray tracing to accelerate the rendering
process is presented.
</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03154</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-world Object Recognition with Off-the-shelf Deep Conv Nets: How
  Many Objects can iCub Learn?</dc:title>
 <dc:creator>Pasquale, Giulia</dc:creator>
 <dc:creator>Ciliberto, Carlo</dc:creator>
 <dc:creator>Odone, Francesca</dc:creator>
 <dc:creator>Rosasco, Lorenzo</dc:creator>
 <dc:creator>Natale, Lorenzo</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The ability to visually recognize objects is a fundamental skill for robotics
systems. Indeed, a large variety of tasks involving manipulation, navigation or
interaction with other agents, deeply depends on the accurate understanding of
the visual scene. Yet, at the time being, robots are lacking good visual
perceptual systems, which often become the main bottleneck preventing the use
of autonomous agents for real-world applications.
  Lately in computer vision, systems that learn suitable visual representations
and based on multi-layer deep convolutional networks are showing remarkable
performance in tasks such as large-scale visual recognition and image
retrieval. To this regard, it is natural to ask whether such remarkable
performance would generalize also to the robotic setting.
  In this paper we investigate such possibility, while taking further steps in
developing a computational vision system to be embedded on a robotic platform,
the iCub humanoid robot. In particular, we release a new dataset ({\sc
iCubWorld28}) that we use as a benchmark to address the question: {\it how many
objects can iCub recognize?} Our study is developed in a learning framework
which reflects the typical visual experience of a humanoid robot like the iCub.
Experiments shed interesting insights on the strength and weaknesses of current
computer vision approaches applied in real robotic settings.
</dc:description>
 <dc:description>Comment: 18 pages, 9 figures, 3 tables</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03161</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random intersection graphs and their applications in security, wireless
  communication, and social networks</dc:title>
 <dc:creator>Zhao, Jun</dc:creator>
 <dc:creator>Ya&#x11f;an, Osman</dc:creator>
 <dc:creator>Gligor, Virgil</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Random intersection graphs have received much interest and been used in
diverse applications. They are naturally induced in modeling secure sensor
networks under random key predistribution schemes, as well as in modeling the
topologies of social networks including common-interest networks, collaboration
networks, and actor networks. Simply put, a random intersection graph is
constructed by assigning each node a set of items in some random manner and
then putting an edge between any two nodes that share a certain number of
items.
  Broadly speaking, our work is about analyzing random intersection graphs, and
models generated by composing it with other random graph models including
random geometric graphs and Erd\H{o}s-R\'enyi graphs. These compositional
models are introduced to capture the characteristics of various complex natural
or man-made networks more accurately than the existing models in the
literature. For random intersection graphs and their compositions with other
random graphs, we study properties such as ($k$-)connectivity,
($k$-)robustness, and containment of perfect matchings and Hamilton cycles. Our
results are typically given in the form of asymptotically exact probabilities
or zero-one laws specifying critical scalings, and provide key insights into
the design and analysis of various real-world networks.
</dc:description>
 <dc:description>Comment: This is an invited paper in Information Theory and Applications
  Workshop (ITA) 2015</dc:description>
 <dc:date>2015-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03170</identifier>
 <datestamp>2016-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Search algorithms for efficient logistics chains</dc:title>
 <dc:creator>Lawrencenko, Serge</dc:creator>
 <dc:creator>Duborkina, Irina A.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>90C27 (Primary), 90B06, 90B10, 05C85, 90B18, 68R10, 94C15
  (Secondary)</dc:subject>
 <dc:description>  Logistics networks arise whenever there is a transfer of material substance
or objects (such as checked baggage on international flights) as well as
energy, information, or finance through links (channels). A general concept of
logistics network is suggested and motivated for modeling a service of any kind
supplied through links between the nodes of the network. The efficiency of a
single link is defined to be the ratio of the volume of useful service at the
output node to the volume of expended service at the input node of the link
(for a specific period of time). Similarly, the efficiency of a chain is the
ratio of the volume of service at the output to the volume of service at the
input of the chain. The overall efficiency of the chain is calculated as the
product of the efficiencies of its links; the more efficiency of the chain, the
less are the losses in the chain. This paper introduces the notion of
inadequacy of service in such a way that the overall inadequacy of a chain is
equal to the sum of the inadequacies of its links. So the efficiencies are
being multiplied, whereas the inadequacies are being added. Thus, the
antagonistic pair (efficiency, inadequacy) appears to be analogous to the pair
(reliability, entropy) in communication theory. Various possible
interpretations of the proposed logistic model are presented: energy, material,
information and financial networks. Four algorithms are provided for logistics
chain search: two algorithms for finding the most effective chain from a
specified origin to a specified destination, and two algorithms for finding the
guaranteed minimum level of service between any pair of unspecified nodes in a
given network. An example is shown as to how one of the algorithms finds the
most efficient energy chain from the electrical substation to a specified user
in a concrete energy network.
</dc:description>
 <dc:description>Comment: 10 pages, 1 figure, in Russian</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03170</dc:identifier>
 <dc:identifier>Service in Russia and Abroad, Vol. 9 (2015), No. 2 (58), 37-48</dc:identifier>
 <dc:identifier>doi:10.12737/11889</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03182</identifier>
 <datestamp>2015-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Low-Complexity Message Recovery Method for Compute-and-Forward
  Relaying</dc:title>
 <dc:creator>Barreal, Amaro</dc:creator>
 <dc:creator>P&#xe4;&#xe4;kk&#xf6;nen, Joonas</dc:creator>
 <dc:creator>Karpuk, David</dc:creator>
 <dc:creator>Hollanti, Camilla</dc:creator>
 <dc:creator>Tirkkonen, Olav</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The Compute-and-Forward relaying strategy achieves high computation rates by
decoding linear combinations of transmitted messages at intermediate relays.
However, if the involved relays independently choose which combinations of the
messages to decode, there is no guarantee that the overall system of linear
equations is solvable at the destination. In this article it is shown that, for
a Gaussian fading channel model with two transmitters and two relays, always
choosing the combination that maximizes the computation rate often leads to a
case where the original messages cannot be recovered. It is further shown that
by limiting the relays to select from carefully designed sets of equations, a
solvable system can be guaranteed while maintaining high computation rates. The
proposed method has a constant computational complexity and requires no
information exchange between the relays.
</dc:description>
 <dc:description>Comment: 5 figures, 5 pages, submitted</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:date>2015-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03182</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03184</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probability Density Functions from the Fisher Information Metric</dc:title>
 <dc:creator>Clingman, T.</dc:creator>
 <dc:creator>Murugan, Jeff</dc:creator>
 <dc:creator>Shock, Jonathan P.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Differential Geometry</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  We show a general relation between the spatially disjoint product of
probability density functions and the sum of their Fisher information metric
tensors. We then utilise this result to give a method for constructing the
probability density functions for an arbitrary Riemannian Fisher information
metric tensor. We note further that this construction is extremely
unconstrained, depending only on certain continuity properties of the
probability density functions and a select symmetry of their domains.
</dc:description>
 <dc:description>Comment: 16 pages, no figures</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03184</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03195</identifier>
 <datestamp>2015-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Upper Bounds on the Error of Sparse Vector and Low-Rank Matrix Recovery</dc:title>
 <dc:creator>Malek-Mohammadi, Mohammadreza</dc:creator>
 <dc:creator>Rojas, Cristian R.</dc:creator>
 <dc:creator>Jansson, Magnus</dc:creator>
 <dc:creator>Babaie-Zadeh, Massoud</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Suppose that a solution $\widetilde{\mathbf{x}}$ to an underdetermined linear
system $\mathbf{b} = \mathbf{A} \mathbf{x}$ is given. $\widetilde{\mathbf{x}}$
is approximately sparse meaning that it has a few large components compared to
other small entries. However, the total number of nonzero components of
$\widetilde{\mathbf{x}}$ is large enough to violate any condition for the
uniqueness of the sparsest solution. On the other hand, if only the dominant
components are considered, then it will satisfy the uniqueness conditions. One
intuitively expects that $\widetilde{\mathbf{x}}$ should not be far from the
true sparse solution $\mathbf{x}_0$. We show that this intuition is the case by
providing an upper bound on $\| \widetilde{\mathbf{x}} - \mathbf{x}_0\|$ which
is a function of the magnitudes of small components of $\widetilde{\mathbf{x}}$
but independent from $\mathbf{x}_0$. This result is extended to the case that
$\mathbf{b}$ is perturbed by noise. Additionally, we generalize the upper
bounds to the low-rank matrix recovery problem.
</dc:description>
 <dc:description>Comment: Submitted to Elsevier Signal Processing</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:date>2015-06-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03195</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03212</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Parameter Choices Through Self-Adjustment: Applying the 1/5-th
  Rule in Discrete Settings</dc:title>
 <dc:creator>Doerr, Benjamin</dc:creator>
 <dc:creator>Doerr, Carola</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  While evolutionary algorithms are known to be very successful for a broad
range of applications, the algorithm designer is often left with many
algorithmic choices, for example, the size of the population, the mutation
rates, and the crossover rates of the algorithm. These parameters are known to
have a crucial influence on the optimization time, and thus need to be chosen
carefully, a task that often requires substantial efforts. Moreover, the
optimal parameters can change during the optimization process. It is therefore
of great interest to design mechanisms that dynamically choose best-possible
parameters. An example for such an update mechanism is the one-fifth success
rule for step-size adaption in evolutionary strategies. While in continuous
domains this principle is well understood also from a mathematical point of
view, no comparable theory is available for problems in discrete domains.
  In this work we show that the one-fifth success rule can be effective also in
discrete settings. We regard the $(1+(\lambda,\lambda))$~GA proposed in
[Doerr/Doerr/Ebel: From black-box complexity to designing new genetic
algorithms, TCS 2015]. We prove that if its population size is chosen according
to the one-fifth success rule then the expected optimization time on
\textsc{OneMax} is linear. This is better than what \emph{any} static
population size $\lambda$ can achieve and is asymptotically optimal also among
all adaptive parameter choices.
</dc:description>
 <dc:description>Comment: This is the full version of a paper that is to appear at GECCO 2015</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03213</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Sharing- and Competition-Aware Framework for Cellular Network
  Evolution Planning</dc:title>
 <dc:creator>Di Francesco, Paolo</dc:creator>
 <dc:creator>Malandrino, Francesco</dc:creator>
 <dc:creator>Forde, Tim K.</dc:creator>
 <dc:creator>DaSilva, Luiz A.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Mobile network operators are facing the difficult task of significantly
increasing capacity to meet projected demand while keeping CAPEX and OPEX down.
We argue that infrastructure sharing is a key consideration in operators'
planning of the evolution of their networks, and that such planning can be
viewed as a stage in the cognitive cycle. In this paper, we present a framework
to model this planning process while taking into account both the ability to
share resources and the constraints imposed by competition regulation (the
latter quantified using the Herfindahl index). Using real-world demand and
deployment data, we find that the ability to share infrastructure essentially
moves capacity from rural, sparsely populated areas (where some of the current
infrastructure can be decommissioned) to urban ones (where most of the
next-generation base stations would be deployed), with significant increases in
resource efficiency. Tight competition regulation somewhat limits the ability
to share but does not entirely jeopardize those gains, while having the
secondary effect of encouraging the wider deployment of next-generation
technologies.
</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03217</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Variable Fixing Heuristic with Local Branching for the Fixed Charge
  Uncapacitated Network Design Problem with User-optimal Flow</dc:title>
 <dc:creator>Gonz&#xe1;lez, Pedro Henrique</dc:creator>
 <dc:creator>Simonetti, Luidi</dc:creator>
 <dc:creator>Michelon, Philippe</dc:creator>
 <dc:creator>Martinhon, Carlos</dc:creator>
 <dc:creator>Santos, Edcarllos</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  This paper presents an iterated local search for the fixed-charge
uncapacitated network design problem with user-optimal flow (FCNDP-UOF), which
concerns routing multiple commodities from its origin to its destination by
signing a network through selecting arcs, with an objective of minimizing the
sum of the fixed costs of the selected arcs plus the sum of variable costs
associated to the flows on each arc. Besides that, since the FCNDP-UOF is a
bi-level problem, each commodity has to be transported through a shortest path,
concerning the edges length, in the built network. The proposed algorithm
generate a initial solution using a variable fixing heuristic. Then a local
branching strategy is applied to improve the quality of the solution. At last,
an efficient perturbation strategy is presented to perform cycle-based moves to
explore different parts of the solution space. Computational experiments shows
that the proposed solution method consistently produces high-quality solutions
in reasonable computational times.
</dc:description>
 <dc:description>Comment: 32 pages, 10 figures, submitted to Computers and Operations Research</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03217</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03218</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flexible Allocation of Heterogeneous Resources to Services on an IoT
  Device</dc:title>
 <dc:creator>Angelakis, Vangelis</dc:creator>
 <dc:creator>Avgouleas, Ioannis</dc:creator>
 <dc:creator>Pappas, Nikolaos</dc:creator>
 <dc:creator>Yuan, Di</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In the Internet of Things (IoT), devices and gateways may be equipped with
multiple, heterogeneous network interfaces which should be utilized by a large
number of services. In this work, we model the problem of assigning services'
resource demands to a device's heterogeneous interfaces and give a Mixed
Integer Linear Program (MILP) formulation for it. For meaningful instance sizes
the MILP model gives optimal solutions to the presented computationally-hard
problem. We provide insightful results discussing the properties of the derived
solutions with respect to the splitting of services to different interfaces.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03239</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global Value Numbering: A Precise and Efficient Algorithm</dc:title>
 <dc:creator>Pai, Rekha R</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Global Value Numbering (GVN) is an important static analysis to detect
equivalent expressions in a program. We present an iterative data-flow analysis
GVN algorithm in SSA for the purpose of detecting total redundancies. The
central challenge is defining a join operation to detect equivalences at a join
point in polynomial time such that later occurrences of redundant expressions
could be detected. For this purpose, we introduce the novel concept of value
$\phi$-function. We claim the algorithm is precise and takes only polynomial
time.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, an extended version to be submitted to journal</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03239</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03240</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase-Noise Mitigation in OFDM by Best Match Trajectories</dc:title>
 <dc:creator>Negusse, Senay</dc:creator>
 <dc:creator>Zetterberg, Per</dc:creator>
 <dc:creator>H&#xe4;ndel, Peter</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper proposes a novel approach to phase-noise compensation. The basic
idea is to approximate the phase-noise statistics by a finite number of
realizations, i.e., a phase-noise codebook. The receiver then uses an augmented
received signal model, where the codebook index is estimated along with other
parameters. The realization of the basic idea depends on the details of the air
interface, the phase-noise statistics, the propagation scenario and the
computational constraints. In this paper, we will focus on a MQAM-OFDM system
with pilot sub-carriers within each OFDM symbol. The channel is frequency
selective, fading and unknown. A decision-feedback method is employed to
further enhance performance of the system. Simulation results are shown for
uncoded and coded systems to illustrate the performance of the algorithm, which
is also compared with previously employed methods. Our simulations show that
for a 16-QAM coded OFDM system over a frequency selective Rayleigh fading
channel affected by phase noise with root-mean-square (RMS) of 14.4 degrees per
OFDM symbol, the proposed algorithm is 1.5dB from the ideal phase-noise free
case at a BER of $10^{-4}$. The performance of the best reference scheme is
2.5dB from the ideal case at BER of $10^{-4}$. The proposed scheme is also
computationally attractive.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Transactions on Communications, 2015</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03240</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2015.2422829</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03242</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wide-area Wireless Communication Challenges for the Internet of Things</dc:title>
 <dc:creator>Dhillon, Harpreet S.</dc:creator>
 <dc:creator>Huang, Howard</dc:creator>
 <dc:creator>Viswanathan, Harish</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Aided by the ubiquitous wireless connectivity, declining communication costs,
and the emergence of cloud platforms, the deployment of Internet of Things
(IoT) devices and services is accelerating. Most major mobile network operators
view machine-to-machine (M2M) communication networks for supporting IoT as a
significant source of new revenue. In this paper, we motivate the need for
wide-area M2M wireless networks, especially for short data packet communication
to support a very large number of IoT devices. We first present a brief
overview of current and emerging technologies for supporting wide area M2M, and
then using communication theory principles, discuss the fundamental challenges
and potential solutions for these networks, highlighting tradeoffs and
strategies for random and scheduled access. We conclude with recommendations
for how future 5G networks should be designed for efficient wide-area M2M
communications.
</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03246</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Scaling of Interference Alignment Under Delay and Power
  Constraints</dc:title>
 <dc:creator>Krishnasamy, Subhashini</dc:creator>
 <dc:creator>Niesen, Urs</dc:creator>
 <dc:creator>Gupta, Piyush</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Future wireless standards such as 5G envision dense wireless networks with
large number of simultaneously connected devices. In this context, interference
management becomes critical in achieving high spectral efficiency. Orthogonal
signaling, which limits the number of users utilizing the resource
simultaneously, gives a sum-rate that remains constant with increasing number
of users. An alternative approach called interference alignment promises a
throughput that scales linearly with the number of users. However, this
approach requires very high SNR or long time duration for sufficient channel
variation, and therefore may not be feasible in real wireless systems. We
explore ways to manage interference in large networks with delay and power
constraints. Specifically, we devise an interference phase alignment strategy
that combines precoding and scheduling without using power control to exploit
the diversity inherent in a system with large number of users. We show that
this scheme achieves a sum-rate that scales almost logarithmically with the
number of users. We also show that no scheme using single symbol phase
alignment, which is asymmetric complex signaling restricted to a single complex
symbol, can achieve better than logarithmic scaling of the sum-rate.
</dc:description>
 <dc:description>Comment: Shorter version to appear in ISIT 2015</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03246</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03247</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Handling Skew in Multiway Joins in Parallel Processing</dc:title>
 <dc:creator>Afrati, Foto N.</dc:creator>
 <dc:creator>Ullman, Jeffrey D.</dc:creator>
 <dc:creator>Vasilakopoulos, Angelos</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Handling skew is one of the major challenges in query processing. In
distributed computational environments such as MapReduce, uneven distribution
of the data to the servers is not desired. One of the dominant measures that we
want to optimize in distributed environments is communication cost. In a
MapReduce job this is the amount of data that is transferred from the mappers
to the reducers. In this paper we will introduce a novel technique for handling
skew when we want to compute a multiway join in one MapReduce round with
minimum communication cost. This technique is actually an adaptation of the
Shares algorithm [Afrati et. al, TKDE 2011].
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03249</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Embedding AC Power Flow with Voltage Control in the Complex Plane : The
  Case of Analytic Continuation via Pad\'e Approximants</dc:title>
 <dc:creator>Baghsorkhi, Sina S.</dc:creator>
 <dc:creator>Suetin, Sergey P.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Complex Variables</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  This paper proposes a method to embed the AC power flow problem with voltage
magnitude constraints in the complex plane. Modeling the action of network
controllers that regulate the magnitude of voltage phasors is a challenging
task in the complex plane as it has to preserve the framework of holomorphicity
for obtention of these complex variables with fixed magnitude. Hence this paper
presents a significant step in the development of the idea of Holomorphic
Embedding Load Flow Method (HELM), introduced in 2012, that exploits the theory
of analytic continuation, especially the monodromy theorem for resolving issues
that have plagued conventional numerical methods for decades. This paper also
illustrates the indispensable role of Pad\'e approximants for analytic
continuation of complex functions, expressed as power series, beyond the
boundary of convergence of the series. Later the paper demonstrates the
superiority of the proposed method over the well-established Newton-Raphson as
well as the recently developed semidefinite and moment relaxation of power flow
problems.
</dc:description>
 <dc:description>Comment: 9 pages, 10 figures, 7 tables</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03253</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximum entropy properties of discrete-time first-order stable spline
  kernel</dc:title>
 <dc:creator>Chen, Tianshi</dc:creator>
 <dc:creator>Ardeshiri, Tohid</dc:creator>
 <dc:creator>Carli, Francesca P.</dc:creator>
 <dc:creator>Chiuso, Alessandro</dc:creator>
 <dc:creator>Ljung, Lennart</dc:creator>
 <dc:creator>Pillonetto, Gianluigi</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The first order stable spline (SS-1) kernel is used extensively in
regularized system identification. In particular, the stable spline estimator
models the impulse response as a zero-mean Gaussian process whose covariance is
given by the SS-1 kernel. In this paper, we discuss the maximum entropy
properties of this prior. In particular, we formulate the exact maximum entropy
problem solved by the SS-1 kernel without Gaussian and uniform sampling
assumptions. Under general sampling schemes, we also explicitly derive the
special structure underlying the SS-1 kernel (e.g. characterizing the
tridiagonal nature of its inverse), also giving to it a maximum entropy
covariance completion interpretation. Along the way similar maximum entropy
properties of the Wiener kernel are also given.
</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03253</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03256</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Linguistic Structures for Application-level Fault-Tolerance</dc:title>
 <dc:creator>De Florio, Vincenzo</dc:creator>
 <dc:creator>Blondia, Chris</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The structures for the expression of fault-tolerance provisions into the
application software are the central topic of this paper. Structuring
techniques answer the questions &quot;How to incorporate fault-tolerance in the
application layer of a computer program&quot; and &quot;How to manage the fault-tolerant
code&quot;. As such, they provide means to control complexity, the latter being a
relevant factor for the introduction of design faults. This fact and the ever
increasing complexity of today's distributed software justify the need for
simple, coherent, and effective structures for the expression of
fault-tolerance in the application software. In this text we first define a
&quot;base&quot; of structural attributes with which application-level fault-tolerance
structures can be qualitatively assessed and compared with each other and with
respect to the above mentioned needs. This result is then used to provide an
elaborated survey of the state-of-the-art of application-level fault-tolerance
structures.
</dc:description>
 <dc:description>Comment: Paper appeared in ACM Computing Surveys, Vol. 40, No. 2 (April 2008)</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03256</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03257</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The (Non)-Existence of Stable Mechanisms in Incomplete Information
  Environments</dc:title>
 <dc:creator>Arnosti, Nick</dc:creator>
 <dc:creator>Immorlica, Nicole</dc:creator>
 <dc:creator>Lucier, Brendan</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider two-sided matching markets, and study the incentives of agents to
circumvent a centralized clearing house by signing binding contracts with one
another. It is well-known that if the clearing house implements a stable match
and preferences are known, then no group of agents can profitably deviate in
this manner.
  We ask whether this property holds even when agents have incomplete
information about their own preferences or the preferences of others. We find
that it does not. In particular, when agents are uncertain about the
preferences of others, every mechanism is susceptible to deviations by groups
of agents. When, in addition, agents are uncertain about their own preferences,
every mechanism is susceptible to deviations in which a single pair of agents
agrees in advance to match to each other.
</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03257</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03268</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Localization of Control Synthesis Problem for Large-Scale Interconnected
  System Using IQC and Dissipativity Theories</dc:title>
 <dc:creator>Anubi, Olugbenga Moses</dc:creator>
 <dc:creator>Clemen, Layne</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The synthesis problem for the compositional performance certification of
interconnected systems is considered. A fairly unified description of control
synthesis problem is given using integral quadratic constraints (IQC) and
dissipativity. Starting with a given large-scale interconnected system and a
global performance objective, an optimization problem is formulated to search
for admissible dissipativity properties of each subsystems. Local control laws
are then synthesized to certify the relevant dissipativity properties.
Moreover, the term localization is introduced to describe a finite collection
of syntheses problems, for the local subsystems, which are a feasibility
certificate for the global synthesis problem. Consequently, the problem of
localizing the global problem to a smaller collection of disjointed sets of
subsystems, called groups, is considered. This works looks promising as another
way of looking at decentralized control and also as a way of doing performance
specifications for components in a large-scale system.
</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03268</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03274</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Stochastic Market Clearing with High-Penetration Wind Power</dc:title>
 <dc:creator>Zhang, Yu</dc:creator>
 <dc:creator>Giannakis, Georgios B.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Integrating renewable energy into the modern power grid requires
risk-cognizant dispatch of resources to account for the stochastic availability
of renewables. Toward this goal, day-ahead stochastic market clearing with
high-penetration wind energy is pursued in this paper based on the DC optimal
power flow (OPF). The objective is to minimize the social cost which consists
of conventional generation costs, end-user disutility, as well as a risk
measure of the system re-dispatching cost. Capitalizing on the conditional
value-at-risk (CVaR), the novel model is able to mitigate the potentially high
risk of the recourse actions to compensate wind forecast errors. The resulting
convex optimization task is tackled via a distribution-free sample average
based approximation to bypass the prohibitively complex high-dimensional
integration. Furthermore, to cope with possibly large-scale dispatchable loads,
a fast distributed solver is developed with guaranteed convergence using the
alternating direction method of multipliers (ADMM). Numerical results tested on
a modified benchmark system are reported to corroborate the merits of the novel
framework and proposed approaches.
</dc:description>
 <dc:description>Comment: To appear in IEEE Transactions on Power Systems; 12 pages and 9
  figures</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03274</dc:identifier>
 <dc:identifier>doi:10.1109/TPWRS.2015.2423151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03275</identifier>
 <datestamp>2015-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wiggins: Detecting Valuable Information in Dynamic Networks Using
  Limited Resources</dc:title>
 <dc:creator>Mahmoody, Ahmad</dc:creator>
 <dc:creator>Riondato, Matteo</dc:creator>
 <dc:creator>Upfal, Eli</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Detecting new information and events in a dynamic network by probing
individual nodes has many practical applications: discovering new webpages,
analyzing influence properties in network, and detecting failure propagation in
electronic circuits or infections in public drinkable water systems. In
practice, it is infeasible for anyone but the owner of the network (if
existent) to monitor all nodes at all times. In this work we study the
constrained setting when the observer can only probe a small set of nodes at
each time step to check whether new pieces of information (items) have reached
those nodes.
  We formally define the problem through an infinite time generating process
that places new items in subsets of nodes according to an unknown probability
distribution. Items have an exponentially decaying novelty, modeling their
decreasing value. The observer uses a probing schedule (i.e., a probability
distribution over the set of nodes) to choose, at each time step, a small set
of nodes to check for new items. The goal is to compute a schedule that
minimizes the average novelty of undetected items. We present an algorithm,
WIGGINS, to compute the optimal schedule through convex optimization, and then
show how it can be adapted when the parameters of the problem must be learned
or change over time. We also present a scalable variant of WIGGINS for the
MapReduce framework. The results of our experimental evaluation on real social
networks demonstrate the practicality of our approach.
</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:date>2015-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03277</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Algorithm of Pipelined Gossiping</dc:title>
 <dc:creator>De Florio, Vincenzo</dc:creator>
 <dc:creator>Blondia, Chris</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  A family of gossiping algorithms depending on a parameter permutation is
introduced, formalized, and discussed. Several of its members are analyzed and
their asymptotic behaviour is revealed, including a member whose model and
performance closely follows the one of hardware pipelined processors. This
similarity is exposed. An optimizing algorithm is finally proposed and
discussed as a general strategy to increase the performance of the base
algorithms.
</dc:description>
 <dc:description>Comment: Paper published in the Journal of Systems Architecture, Vol. 52
  (2006). Elsevier</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03277</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03285</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple Measurements and Joint Dimensionality Reduction for Large Scale
  Image Search with Short Vectors - Extended Version</dc:title>
 <dc:creator>Radenovic, Filip</dc:creator>
 <dc:creator>Jegou, Herve</dc:creator>
 <dc:creator>Chum, Ondrej</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper addresses the construction of a short-vector (128D) image
representation for large-scale image and particular object retrieval. In
particular, the method of joint dimensionality reduction of multiple
vocabularies is considered. We study a variety of vocabulary generation
techniques: different k-means initializations, different descriptor
transformations, different measurement regions for descriptor extraction. Our
extensive evaluation shows that different combinations of vocabularies, each
partitioning the descriptor space in a different yet complementary manner,
results in a significant performance improvement, which exceeds the
state-of-the-art.
</dc:description>
 <dc:description>Comment: Extended version of the ICMR 2015 paper</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03285</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03287</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Air Interface User Privacy in Mobile Telephony</dc:title>
 <dc:creator>Khan, Mohammed Shafiul Alam</dc:creator>
 <dc:creator>Mitchell, Chris J</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Although the security properties of 3G and 4G mobile networks have
significantly improved by comparison with 2G (GSM), significant shortcomings
remain with respect to user privacy. A number of possible modifications to 2G,
3G and 4G protocols have been proposed designed to provide greater user
privacy; however, they all require significant modifications to existing
deployed infrastructures, which are almost certainly impractical to achieve in
practice. In this article we propose an approach which does not require any
changes to the existing deployed network infrastructures or mobile devices, but
offers improved user identity protection over the air interface. The proposed
scheme makes use of multiple IMSIs for an individual USIM to offer a degree of
pseudonymity for a user. The only changes required are to the operation of the
authentication centre in the home network and to the USIM, and the scheme could
be deployed immediately since it is completely transparent to the existing
mobile telephony infrastructure. We present two different approaches to the use
and management of multiple IMSIs.
</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03287</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03293</identifier>
 <datestamp>2016-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Object Detection with Deep Convolutional Networks via Bayesian
  Optimization and Structured Prediction</dc:title>
 <dc:creator>Zhang, Yuting</dc:creator>
 <dc:creator>Sohn, Kihyuk</dc:creator>
 <dc:creator>Villegas, Ruben</dc:creator>
 <dc:creator>Pan, Gang</dc:creator>
 <dc:creator>Lee, Honglak</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Object detection systems based on the deep convolutional neural network (CNN)
have recently made ground- breaking advances on several object detection
benchmarks. While the features learned by these high-capacity neural networks
are discriminative for categorization, inaccurate localization is still a major
source of error for detection. Building upon high-capacity CNN architectures,
we address the localization problem by 1) using a search algorithm based on
Bayesian optimization that sequentially proposes candidate regions for an
object bounding box, and 2) training the CNN with a structured loss that
explicitly penalizes the localization inaccuracy. In experiments, we
demonstrated that each of the proposed methods improves the detection
performance over the baseline method on PASCAL VOC 2007 and 2012 datasets.
Furthermore, two methods are complementary and significantly outperform the
previous state-of-the-art when combined.
</dc:description>
 <dc:description>Comment: CVPR 2015</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:date>2016-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03293</dc:identifier>
 <dc:identifier>doi:10.1109/CVPR.2015.7298621</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03294</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Testing Cluster Structure of Graphs</dc:title>
 <dc:creator>Czumaj, Artur</dc:creator>
 <dc:creator>Peng, Pan</dc:creator>
 <dc:creator>Sohler, Christian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the problem of recognizing the cluster structure of a graph in the
framework of property testing in the bounded degree model. Given a parameter
$\varepsilon$, a $d$-bounded degree graph is defined to be $(k,
\phi)$-clusterable, if it can be partitioned into no more than $k$ parts, such
that the (inner) conductance of the induced subgraph on each part is at least
$\phi$ and the (outer) conductance of each part is at most
$c_{d,k}\varepsilon^4\phi^2$, where $c_{d,k}$ depends only on $d,k$. Our main
result is a sublinear algorithm with the running time
$\widetilde{O}(\sqrt{n}\cdot\mathrm{poly}(\phi,k,1/\varepsilon))$ that takes as
input a graph with maximum degree bounded by $d$, parameters $k$, $\phi$,
$\varepsilon$, and with probability at least $\frac23$, accepts the graph if it
is $(k,\phi)$-clusterable and rejects the graph if it is $\varepsilon$-far from
$(k, \phi^*)$-clusterable for $\phi^* = c'_{d,k}\frac{\phi^2
\varepsilon^4}{\log n}$, where $c'_{d,k}$ depends only on $d,k$. By the lower
bound of $\Omega(\sqrt{n})$ on the number of queries needed for testing graph
expansion, which corresponds to $k=1$ in our problem, our algorithm is
asymptotically optimal up to polylogarithmic factors.
</dc:description>
 <dc:description>Comment: Full version of STOC 2015</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03303</identifier>
 <datestamp>2016-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ultimate Intelligence Part II: Physical Measure and Complexity of
  Intelligence</dc:title>
 <dc:creator>&#xd6;zkural, Eray</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We continue our analysis of volume and energy measures that are appropriate
for quantifying inductive inference systems. We extend logical depth and
conceptual jump size measures in AIT to stochastic problems, and physical
measures that involve volume and energy. We introduce a graphical model of
computational complexity that we believe to be appropriate for intelligent
machines. We show several asymptotic relations between energy, logical depth
and volume of computation for inductive inference. In particular, we arrive at
a &quot;black-hole equation&quot; of inductive inference, which relates energy, volume,
space, and algorithmic information for an optimal inductive inference solution.
We introduce energy-bounded algorithmic entropy. We briefly apply our ideas to
the physical limits of intelligent computation in our universe.
</dc:description>
 <dc:description>Comment: This paper was initially submitted to ALT-2014. We are taking the
  valuable opinions of the anonymous reviewers into account. Many thanks to
  Laurent Orseau for his constructive comments on the draft, which inspired
  this revision. arXiv admin note: substantial text overlap with
  arXiv:1501.00601 This is a major revision over the last version edited</dc:description>
 <dc:date>2015-04-09</dc:date>
 <dc:date>2016-05-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03306</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Virus Propagation in Multiple Profile Networks</dc:title>
 <dc:creator>Rapti, Angeliki</dc:creator>
 <dc:creator>Tsichlas, Kostas</dc:creator>
 <dc:creator>Sioutas, Spiros</dc:creator>
 <dc:creator>Tzimas, Giannis</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Suppose we have a virus or one competing idea/product that propagates over a
multiple profile (e.g., social) network. Can we predict what proportion of the
network will actually get &quot;infected&quot; (e.g., spread the idea or buy the
competing product), when the nodes of the network appear to have different
sensitivity based on their profile? For example, if there are two profiles
$\mathcal{A}$ and $\mathcal{B}$ in a network and the nodes of profile
$\mathcal{A}$ and profile $\mathcal{B}$ are susceptible to a highly spreading
virus with probabilities $\beta_{\mathcal{A}}$ and $\beta_{\mathcal{B}}$
respectively, what percentage of both profiles will actually get infected from
the virus at the end? To reverse the question, what are the necessary
conditions so that a predefined percentage of the network is infected? We
assume that nodes of different profiles can infect one another and we prove
that under realistic conditions, apart from the weak profile (great
sensitivity), the stronger profile (low sensitivity) will get infected as well.
First, we focus on cliques with the goal to provide exact theoretical results
as well as to get some intuition as to how a virus affects such a multiple
profile network. Then, we move to the theoretical analysis of arbitrary
networks. We provide bounds on certain properties of the network based on the
probabilities of infection of each node in it when it reaches the steady state.
Finally, we provide extensive experimental results that verify our theoretical
results and at the same time provide more insight on the problem.
</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03315</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Approach to Develop a New Hybrid Technique for Trademark Image
  Retrieval</dc:title>
 <dc:creator>Agarwal, Saurabh</dc:creator>
 <dc:creator>Johari, Punit Kumar</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Trademark Image Retrieval is playing a vital role as a part of CBIR System.
Trademark is of great significance because it carries the status value of any
company. To retrieve such a fake or copied trademark we design a retrieval
system which is based on hybrid techniques. It contains a mixture of two
different feature vector which combined together to give a suitable retrieval
system. In the proposed system we extract the corner feature which is applied
on an edge pixel image. This feature is used to extract the relevant image and
to more purify the result we apply other feature which is the invariant moment
feature. From the experimental result we conclude that the system is 85 percent
efficient.
</dc:description>
 <dc:description>Comment: 12 Pages, International Journal on Information Theory (IJIT),Vol.3,
  No.4, October 2014</dc:description>
 <dc:date>2014-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03315</dc:identifier>
 <dc:identifier>doi:10.5121/ijit.2014.3403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03340</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Model for Integration of Information Security Management against
  Replication Attack Based on Biological Structures of the Body</dc:title>
 <dc:creator>Bodaghi, Amir Hosein</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  By developing communications and increase of access points, computer networks
have been vulnerable considerably against wide range of information attacks,
specially new and complicated attacks. Every day, replication attacks attack
millions of network and mobile users. Increase in amount of replication attack
may be a potential danger for income of SMS or network and causes losing
customers of these services provider. Humans or software can be used to
encounter these replication attacks. It is obvious that lonely absolute use of
each method will not result in a proper answer to encounter replication
attack`s problem. Since replication attack is one of the important problems of
information protection and security in organizations for computer and mobile
phone users, while reviewing types of replication attacks and methods of
encountering, this paper uses similarities between pathologies in body and
invader factors in replication attacks, a model is provided based on biological
simulation methods existing in body`s adapted immune system to encounter these
threats.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2014-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03342</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Privacy and Security in Online Social Networks</dc:title>
 <dc:creator>Kayes, Imrul</dc:creator>
 <dc:creator>Iamnitchi, Adriana</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Online Social Networks (OSN) are a permanent presence in today's personal and
professional lives of a huge segment of the population, with direct
consequences to offline activities. Built on a foundation of trust-users
connect to other users with common interests or overlapping personal
trajectories-online social networks and the associated applications extract an
unprecedented volume of personal information. Unsurprisingly, serious privacy
and security risks emerged, positioning themselves along two main types of
attacks: attacks that exploit the implicit trust embedded in declared social
relationships; and attacks that harvest user's personal information for
ill-intended use. This article provides an overview of the privacy and security
issues that emerged so far in OSNs. We introduce a taxonomy of privacy and
security attacks in OSNs, we overview existing solutions to mitigate those
attacks, and outline challenges still to overcome.
</dc:description>
 <dc:date>2015-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03363</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Outage Probability for Multi-Hop Full-Duplex Decode and Forward MIMO
  Relay</dc:title>
 <dc:creator>Pivaro, G. F.</dc:creator>
 <dc:creator>Fraindenraich, G.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, a multi-hop (MH) decode-and-forward (DF) multiple-input
multiple-output (MIMO) relay network has been studied. To consider a more
realistic scenario, Full-Duplex (FD) operation with Relay Self-Interference
(RSI) is employed.
  Assuming that the MIMO channels are subject to Rayleigh fading, a simple and
compact closed-form outage probability expression has been derived. The key
assumption to derive this result is that the mutual information of each channel
could be well approximated by a Gaussian random variable. In order to obtain
the resultant outage probability, a new excellent accurate approximation has
been obtained for the sum of Wishart distributed complex random matrices.
  Numerical Monte Carlo simulations have been performed to validate our result.
These simulations have shown that, for low and medium interference regime, FD
mode performs better than Half-Duplex (HD) mode. On the other hand, when RSI
increases, HD mode can outperforms FD mode.
</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03370</identifier>
 <datestamp>2015-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preprint Serious Game Based Dysphonic Rehabilitation Tool</dc:title>
 <dc:creator>Lv, Zhihan</dc:creator>
 <dc:creator>Esteve, Chantal</dc:creator>
 <dc:creator>Chirivella, Javier</dc:creator>
 <dc:creator>Gagliardo, Pablo</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.1</dc:subject>
 <dc:description>  This is the preprint version of our paper on 2015 International Conference on
Virtual Rehabilitation (ICVR2015). The purpose of this work is designing and
implementing a rehabilitation software for dysphonic patients. Constant
training is a key factor for this type of therapy. The patient can play the
game as well as conduct the voice training simultaneously guided by therapists
at clinic or exercise independently at home. The voice information can be
recorded and extracted for evaluating the long-time rehabilitation progress.
</dc:description>
 <dc:description>Comment: This is the preprint version of our paper on 2015 International
  Conference on Virtual Rehabilitation (ICVR2015)</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:date>2015-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03371</identifier>
 <datestamp>2015-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preprint Imagining In-Air Interaction for Hemiplegia Sufferer</dc:title>
 <dc:creator>Lv, Zhihan</dc:creator>
 <dc:creator>Li, Haibo</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.5.1</dc:subject>
 <dc:description>  This is the preprint version of our paper on 2015 International Conference on
Virtual Rehabilitation (ICVR2015). In this paper, we described the imagination
scenarios of a touch-less interaction technology for hemiplegia, which can
support either hand or foot interaction with the smartphone or head mounted
device (HMD). The computer vision interaction technology is implemented in our
previous work, which provides a core support for gesture interaction by
accurately detecting and tracking the hand or foot gesture. The patients
interact with the application using hand/foot gesture motion in the camera
view.
</dc:description>
 <dc:description>Comment: This is the preprint version of our paper on 2015 International
  Conference on Virtual Rehabilitation (ICVR2015)</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:date>2015-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03371</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03374</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Language, Twitter and Academic Conferences</dc:title>
 <dc:creator>Garc&#xed;a, Ruth</dc:creator>
 <dc:creator>G&#xf3;mez, Diego</dc:creator>
 <dc:creator>Parra, Denis</dc:creator>
 <dc:creator>Trattner, Christoph</dc:creator>
 <dc:creator>Kaltenbrunner, Andreas</dc:creator>
 <dc:creator>Graells-Garrido, Eduardo</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  Using Twitter during academic conferences is a way of engaging and connecting
an audience inherently multicultural by the nature of scientific collaboration.
English is expected to be the lingua franca bridging the communication and
integration between native speakers of different mother tongues. However,
little research has been done to support this assumption. In this paper we
analyzed how integrated language communities are by analyzing the scholars'
tweets used in 26 Computer Science conferences over a time span of five years.
We found that although English is the most popular language used to tweet
during conferences, a significant proportion of people also tweet in other
languages. In addition, people who tweet solely in English interact mostly
within the same group (English monolinguals), while people who speak other
languages tend to show a more diverse interaction with other lingua groups.
Finally, we also found that the people who interact with other Twitter users
show a more diverse language distribution, while people who do not interact
mostly post tweets in a single language. These results suggest a relation
between the number of languages a user speaks, which can affect the interaction
dynamics of online communities.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures, 4 tables, submitted to ACM Hypertext and Social
  Media 2015</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03376</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Any non-affine one-to-one binary gate suffices for computation</dc:title>
 <dc:creator>Lloyd, Seth</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Any non-affine one-to-one binary gate can be wired together with suitable
inputs to give AND, OR, NOT and fan-out gates, and so suffices to construct a
general-purpose computer.
</dc:description>
 <dc:description>Comment: 7 pages, plain TeX, 1992 Los Alamos Alamos preprint number
  LA-UR-92-996. Shows that any non-affine reversible binary logic gate is
  universal</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03385</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Content Creation and Protection Scheme for Medical Images</dc:title>
 <dc:creator>Lee, Chen-Yu</dc:creator>
 <dc:creator>Chen, Deng-Jyi</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Medical images contain metadata information on where, when, and how an image
was acquired, and the majority of this information is stored as pixel data.
Image feature descriptions are often captured only as free text stored in the
image file or in the hospital information system. Correlations between the free
text and the location of the feature are often inaccurate, making it difficult
to link image observations to their corresponding image locations. This limits
the interpretation of image data from a clinical, research, and academic
standpoint. An efficient medical image protection design should allow for
compatibility, usability, and privacy. This paper proposes a medical-content
creation and protection scheme that contains a) a DICOM-compatible multimedia
annotation scheme for medical content creation; b) a DICOM-compatible partial
DRM scheme for medical record transmission under this scheme, authorized users
can view only information to which they have been granted to access.
</dc:description>
 <dc:description>Comment: 15 pages, submitted</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03386</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tractable Query Answering and Optimization for Extensions of
  Weakly-Sticky Datalog+-</dc:title>
 <dc:creator>Milani, Mostafa</dc:creator>
 <dc:creator>Bertossi, Leopoldo</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We consider a semantic class, weakly-chase-sticky (WChS), and a syntactic
subclass, jointly-weakly-sticky (JWS), of Datalog+- programs. Both extend that
of weakly-sticky (WS) programs, which appear in our applications to data
quality. For WChS programs we propose a practical, polynomial-time query
answering algorithm (QAA). We establish that the two classes are closed under
magic-sets rewritings. As a consequence, QAA can be applied to the optimized
programs. QAA takes as inputs the program (including the query) and semantic
information about the &quot;finiteness&quot; of predicate positions. For the syntactic
subclasses JWS and WS of WChS, this additional information is computable.
</dc:description>
 <dc:description>Comment: To appear in Proc. Alberto Mendelzon WS on Foundations of Data
  Management (AMW15)</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03391</identifier>
 <datestamp>2015-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tight Bounds on Low-degree Spectral Concentration of Submodular and XOS
  functions</dc:title>
 <dc:creator>Feldman, Vitaly</dc:creator>
 <dc:creator>Vondrak, Jan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Submodular and fractionally subadditive (or equivalently XOS) functions play
a fundamental role in combinatorial optimization, algorithmic game theory and
machine learning. Motivated by learnability of these classes of functions from
random examples, we consider the question of how well such functions can be
approximated by low-degree polynomials in $\ell_2$ norm over the uniform
distribution. This question is equivalent to understanding of the concentration
of Fourier weight on low-degree coefficients, a central concept in Fourier
analysis. We show that
  1. For any submodular function $f:\{0,1\}^n \rightarrow [0,1]$, there is a
polynomial of degree $O(\log (1/\epsilon) / \epsilon^{4/5})$ approximating $f$
within $\epsilon$ in $\ell_2$, and there is a submodular function that requires
degree $\Omega(1/\epsilon^{4/5})$.
  2. For any XOS function $f:\{0,1\}^n \rightarrow [0,1]$, there is a
polynomial of degree $O(1/\epsilon)$ and there exists an XOS function that
requires degree $\Omega(1/\epsilon)$.
  This improves on previous approaches that all showed an upper bound of
$O(1/\epsilon^2)$ for submodular and XOS functions. The best previous lower
bound was $\Omega(1/\epsilon^{2/3})$ for monotone submodular functions. Our
techniques reveal new structural properties of submodular and XOS functions and
the upper bounds lead to nearly optimal PAC learning algorithms for these
classes of functions.
</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:date>2015-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03398</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An average-case depth hierarchy theorem for Boolean circuits</dc:title>
 <dc:creator>Rossman, Benjamin</dc:creator>
 <dc:creator>Servedio, Rocco A.</dc:creator>
 <dc:creator>Tan, Li-Yang</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We prove an average-case depth hierarchy theorem for Boolean circuits over
the standard basis of $\mathsf{AND}$, $\mathsf{OR}$, and $\mathsf{NOT}$ gates.
Our hierarchy theorem says that for every $d \geq 2$, there is an explicit
$n$-variable Boolean function $f$, computed by a linear-size depth-$d$ formula,
which is such that any depth-$(d-1)$ circuit that agrees with $f$ on $(1/2 +
o_n(1))$ fraction of all inputs must have size $\exp({n^{\Omega(1/d)}}).$ This
answers an open question posed by H{\aa}stad in his Ph.D. thesis.
  Our average-case depth hierarchy theorem implies that the polynomial
hierarchy is infinite relative to a random oracle with probability 1,
confirming a conjecture of H{\aa}stad, Cai, and Babai. We also use our result
to show that there is no &quot;approximate converse&quot; to the results of Linial,
Mansour, Nisan and Boppana on the total influence of small-depth circuits, thus
answering a question posed by O'Donnell, Kalai, and Hatami.
  A key ingredient in our proof is a notion of \emph{random projections} which
generalize random restrictions.
</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03398</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03406</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Innovative Method for enhancing Key generation and management in the
  AES-algorithm</dc:title>
 <dc:creator>Mohammad, Omer K. Jasim</dc:creator>
 <dc:creator>Abbas, Safia</dc:creator>
 <dc:creator>El-Horbaty, El-Sayed M.</dc:creator>
 <dc:creator>Salem, Abdel-Badeeh M.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  With the extraordinary maturity of data exchange in network environments and
increasing the attackers capabilities, information security has become the most
important process for data storage and communication. In order to provide such
information security the confidentiality, data integrity, and data origin
authentication must be verified based on cryptographic encryption algorithms.
This paper presents a development of the advanced encryption standard (AES)
algorithm, which is considered as the most eminent symmetric encryption
algorithm. The development focuses on the generation of the integration between
the developed AES based S-Boxes, and the specific selected secret key generated
from the quantum key distribution.
</dc:description>
 <dc:description>Comment: 7 pages, 10 figures. arXiv admin note: text overlap with
  arXiv:1503.04796</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03406</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03409</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Clustering Assisted Fundamental Matrix Estimation</dc:title>
 <dc:creator>Wu, Hao</dc:creator>
 <dc:creator>Wan, Yi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In computer vision, the estimation of the fundamental matrix is a basic
problem that has been extensively studied. The accuracy of the estimation
imposes a significant influence on subsequent tasks such as the camera
trajectory determination and 3D reconstruction. In this paper we propose a new
method for fundamental matrix estimation that makes use of clustering a group
of 4D vectors. The key insight is the observation that among the 4D vectors
constructed from matching pairs of points obtained from the SIFT algorithm,
well-defined cluster points tend to be reliable inliers suitable for
fundamental matrix estimation. Based on this, we utilizes a recently proposed
efficient clustering method through density peaks seeking and propose a new
clustering assisted method. Experimental results show that the proposed
algorithm is faster and more accurate than currently commonly used methods.
</dc:description>
 <dc:description>Comment: 12 pages, 8 figures, 3 tables, Second International Conference on
  Computer Science and Information Technology (COSIT 2015) March 21~22, 2015,
  Geneva, Switzerland</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03409</dc:identifier>
 <dc:identifier>doi:10.5121/csit.2015.50604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03410</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simultaneous Feature Learning and Hash Coding with Deep Neural Networks</dc:title>
 <dc:creator>Lai, Hanjiang</dc:creator>
 <dc:creator>Pan, Yan</dc:creator>
 <dc:creator>Liu, Ye</dc:creator>
 <dc:creator>Yan, Shuicheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Similarity-preserving hashing is a widely-used method for nearest neighbour
search in large-scale image retrieval tasks. For most existing hashing methods,
an image is first encoded as a vector of hand-engineering visual features,
followed by another separate projection or quantization step that generates
binary codes. However, such visual feature vectors may not be optimally
compatible with the coding process, thus producing sub-optimal hashing codes.
In this paper, we propose a deep architecture for supervised hashing, in which
images are mapped into binary codes via carefully designed deep neural
networks. The pipeline of the proposed deep architecture consists of three
building blocks: 1) a sub-network with a stack of convolution layers to produce
the effective intermediate image features; 2) a divide-and-encode module to
divide the intermediate image features into multiple branches, each encoded
into one hash bit; and 3) a triplet ranking loss designed to characterize that
one image is more similar to the second image than to the third one. Extensive
evaluations on several benchmark image datasets show that the proposed
simultaneous feature learning and hash coding pipeline brings substantial
improvements over other state-of-the-art supervised or unsupervised hashing
methods.
</dc:description>
 <dc:description>Comment: This paper has been accepted to IEEE International Conference on
  Pattern Recognition and Computer Vision (CVPR), 2015</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03410</dc:identifier>
 <dc:identifier>doi:10.1109/CVPR.2015.7298947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03411</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Private Key Capacity of a Cooperative Pairwise-Independent Network</dc:title>
 <dc:creator>Xu, Peng</dc:creator>
 <dc:creator>Ding, Zhiguo</dc:creator>
 <dc:creator>Dai, Xuchu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies the private key generation of a cooperative
pairwise-independent network (PIN) with M+2 terminals (Alice, Bob and M
relays), M &gt;= 2. In this PIN, the correlated sources observed by every pair of
terminals are independent of those sources observed by any other pair of
terminal. All the terminals can communicate with each other over a public
channel which is also observed by Eve noiselessly. The objective is to generate
a private key between Alice and Bob under the help of the M relays; such a
private key needs to be protected not only from Eve but also from individual
relays simultaneously. The private key capacity of this PIN model is
established, whose lower bound is obtained by proposing a novel random binning
(RB) based key generation algorithm, and the upper bound is obtained based on
the construction of M enhanced source models. The two bounds are shown to be
exactly the same. Then, we consider a cooperative wireless network and use the
estimates of fading channels to generate private keys. It has been shown that
the proposed RB-based algorithm can achieve a multiplexing gain M-1, an
improvement in comparison with the existing XOR- based algorithm whose
achievable multiplexing gain is about [M]/2.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, IEEE ISIT 2015 (to appear)</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03413</identifier>
 <datestamp>2017-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consensus based Detection in the Presence of Data Falsification Attacks</dc:title>
 <dc:creator>Kailkhura, Bhavya</dc:creator>
 <dc:creator>Brahma, Swastik</dc:creator>
 <dc:creator>Varshney, Pramod K.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper considers the problem of detection in distributed networks in the
presence of data falsification (Byzantine) attacks. Detection approaches
considered in the paper are based on fully distributed consensus algorithms,
where all of the nodes exchange information only with their neighbors in the
absence of a fusion center. In such networks, we characterize the negative
effect of Byzantines on the steady-state and transient detection performance of
the conventional consensus based detection algorithms. To address this issue,
we study the problem from the network designer's perspective. More
specifically, we first propose a distributed weighted average consensus
algorithm that is robust to Byzantine attacks. We show that, under reasonable
assumptions, the global test statistic for detection can be computed locally at
each node using our proposed consensus algorithm. We exploit the statistical
distribution of the nodes' data to devise techniques for mitigating the
influence of data falsifying Byzantines on the distributed detection system.
Since some parameters of the statistical distribution of the nodes' data might
not be known a priori, we propose learning based techniques to enable an
adaptive design of the local fusion or update rules.
</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03413</dc:identifier>
 <dc:identifier>doi:10.1109/TSIPN.2016.2607119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03415</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HHCART: An Oblique Decision Tree</dc:title>
 <dc:creator>Wickramarachchi, D. C.</dc:creator>
 <dc:creator>Robertson, B. L.</dc:creator>
 <dc:creator>Reale, M.</dc:creator>
 <dc:creator>Price, C. J.</dc:creator>
 <dc:creator>Brown, J.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Decision trees are a popular technique in statistical data classification.
They recursively partition the feature space into disjoint sub-regions until
each sub-region becomes homogeneous with respect to a particular class. The
basic Classification and Regression Tree (CART) algorithm partitions the
feature space using axis parallel splits. When the true decision boundaries are
not aligned with the feature axes, this approach can produce a complicated
boundary structure. Oblique decision trees use oblique decision boundaries to
potentially simplify the boundary structure. The major limitation of this
approach is that the tree induction algorithm is computationally expensive. In
this article we present a new decision tree algorithm, called HHCART. The
method utilizes a series of Householder matrices to reflect the training data
at each node during the tree construction. Each reflection is based on the
directions of the eigenvectors from each classes' covariance matrix.
Considering axis parallel splits in the reflected training data provides an
efficient way of finding oblique splits in the unreflected training data.
Experimental results show that the accuracy and size of the HHCART trees are
comparable with some benchmark methods in the literature. The appealing feature
of HHCART is that it can handle both qualitative and quantitative features in
the same oblique split.
</dc:description>
 <dc:description>Comment: 13 Pages, 1 Figure, 4 Tables, 1 Algorithm</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03415</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03425</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Analysis and Prediction of Job Interview Performance</dc:title>
 <dc:creator>Naim, Iftekhar</dc:creator>
 <dc:creator>Tanveer, M. Iftekhar</dc:creator>
 <dc:creator>Gildea, Daniel</dc:creator>
 <dc:creator>Mohammed</dc:creator>
 <dc:creator>Hoque</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a computational framework for automatically quantifying verbal and
nonverbal behaviors in the context of job interviews. The proposed framework is
trained by analyzing the videos of 138 interview sessions with 69
internship-seeking undergraduates at the Massachusetts Institute of Technology
(MIT). Our automated analysis includes facial expressions (e.g., smiles, head
gestures, facial tracking points), language (e.g., word counts, topic
modeling), and prosodic information (e.g., pitch, intonation, and pauses) of
the interviewees. The ground truth labels are derived by taking a weighted
average over the ratings of 9 independent judges. Our framework can
automatically predict the ratings for interview traits such as excitement,
friendliness, and engagement with correlation coefficients of 0.75 or higher,
and can quantify the relative importance of prosody, language, and facial
expressions. By analyzing the relative feature weights learned by the
regression models, our framework recommends to speak more fluently, use less
filler words, speak as &quot;we&quot; (vs. &quot;I&quot;), use more unique words, and smile more.
We also find that the students who were rated highly while answering the first
interview question were also rated highly overall (i.e., first impression
matters). Finally, our MIT Interview dataset will be made available to other
researchers to further validate and expand our findings.
</dc:description>
 <dc:description>Comment: 14 pages, 8 figures, 6 tables</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03426</identifier>
 <datestamp>2016-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network-Coded Multiple Access with High-order Modulations</dc:title>
 <dc:creator>Pan, Haoyuan</dc:creator>
 <dc:creator>Lu, Lu</dc:creator>
 <dc:creator>Liew, Soung Chang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents the first network-coded multiple access (NCMA) system
prototype operated on high-order modulations up to 16-QAM. NCMA jointly
exploits physical-layer network coding (PNC) and multiuser decoding (MUD) to
boost throughput of multipacket reception systems. Direct generalization of the
existing NCMA decoding algorithm, originally designed for BPSK, to high-order
modulations, will lead to huge performance degradation. The throughput
degradation is caused by the relative phase offset between received signals
from different nodes. To circumvent the phase offset problem, this paper
investigates an NCMA system with multiple receive antennas at the access point
(AP), referred to as MIMO-NCMA. We put forth a low-complexity symbol-level NCMA
decoder that, together with MIMO, can substantially alleviate the performance
degradation induced by relative phase offset. To demonstrate the feasibility
and advantage of MIMO-NCMA for high-order modulations, we implemented our
designs on software-defined radio. Our experimental results show that the
throughput of QPSK MIMO-NCMA is double that of both BPSK NCMA and QPSK MUD at
SNR=10dB. For higher SNRs at which 16-QAM can be supported, the throughput of
MIMO-NCMA can be as high as 3.5 times that of BPSK NCMA. Overall, this paper
provides an implementable framework for high-order modulated NCMA.
</dc:description>
 <dc:description>Comment: Full-length Version</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:date>2016-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03426</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03437</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-latency List Decoding Of Polar Codes With Double Thresholding</dc:title>
 <dc:creator>Fan, YouZhe</dc:creator>
 <dc:creator>Chen, Ji</dc:creator>
 <dc:creator>Xia, ChenYang</dc:creator>
 <dc:creator>Tsui, Chi-ying</dc:creator>
 <dc:creator>Jin, Jie</dc:creator>
 <dc:creator>Shen, Hui</dc:creator>
 <dc:creator>Li, Bin</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  For polar codes with short-to-medium code length, list successive
cancellation decoding is used to achieve a good error-correcting performance.
However, list pruning in the current list decoding is based on the sorting
strategy and its timing complexity is high. This results in a long decoding
latency for large list size. In this work, aiming at a low-latency list
decoding implementation, a double thresholding algorithm is proposed for a fast
list pruning. As a result, with a negligible performance degradation, the list
pruning delay is greatly reduced. Based on the double thresholding, a
low-latency list decoding architecture is proposed and implemented using a UMC
90nm CMOS technology. Synthesis results show that, even for a large list size
of 16, the proposed low-latency architecture achieves a decoding throughput of
220 Mbps at a frequency of 641 MHz.
</dc:description>
 <dc:description>Comment: 5 pages, 7 figures, 1 table, to be presented in the 40th IEEE
  International Conference on Acoustics, Speech and Signal Processing (ICASSP)
  2015</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03437</dc:identifier>
 <dc:identifier>doi:10.1109/ICASSP.2015.7178128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03439</identifier>
 <datestamp>2015-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Denoising Using Low Rank Minimization With Modified Noise
  Estimation</dc:title>
 <dc:creator>Shamsi, Zahid Hussain</dc:creator>
 <dc:creator>Oh, Hyun Sook</dc:creator>
 <dc:creator>Kim, Dai-Gyoung</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, the application of low rank minimization to image denoising has
shown remarkable denoising results which are equivalent or better than those of
the existing state-of-the-art algorithms. However, due to iterative nature of
low rank optimization, estimation of residual noise is an essential requirement
after each iteration. Currently, this noise is estimated by using the filtered
noise in the previous iteration without considering the geometric structure of
the given image. This estimate may be affected in the presence of moderate and
severe levels of noise. To obtain a more reliable estimate of residual noise,
we propose a modified algorithm (GWNNM) which includes the contribution of the
geometric structure of an image to the existing noise estimation. Furthermore,
the proposed algorithm exploits the difference of large and small singular
values to enhance the edges and textures during the denoising process.
Consequently, the proposed modifications achieve significant improvements in
the denoising results of the existing low rank optimization algorithms.
</dc:description>
 <dc:description>Comment: 4 pages, 8 figures</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:date>2015-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03440</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Engineering Methods for Differentially Private Histograms: Efficiency
  Beyond Utility</dc:title>
 <dc:creator>Kellaris, Georgios</dc:creator>
 <dc:creator>Papadopoulos, Stavros</dc:creator>
 <dc:creator>Papadias, Dimitris</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Publishing histograms with $\epsilon$-differential privacy has been studied
extensively in the literature. Existing schemes aim at maximizing the utility
of the published data, while previous experimental evaluations analyze the
privacy/utility trade-off. In this paper we provide the first experimental
evaluation of differentially private methods that goes beyond utility,
emphasizing also on another important aspect, namely efficiency. Towards this
end, we first observe that all existing schemes are comprised of a small set of
common blocks. We then optimize and choose the best implementation for each
block, determine the combinations of blocks that capture the entire literature,
and propose novel block combinations. We qualitatively assess the quality of
the schemes based on the skyline of efficiency and utility, i.e., based on
whether a method is dominated on both aspects or not. Using exhaustive
experiments on four real datasets with different characteristics, we conclude
that there are always trade-offs in terms of utility and efficiency. We
demonstrate that the schemes derived from our novel block combinations provide
the best trade-offs for time critical applications. Our work can serve as a
guide to help practitioners engineer a differentially private histogram scheme
depending on their application requirements.
</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03440</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03445</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$(1+2u)$-constacyclic codes over $\mathbb{Z}_4+u\mathbb{Z}_4$</dc:title>
 <dc:creator>Ashraf, Mohammad</dc:creator>
 <dc:creator>Mohammad, Ghulam</dc:creator>
 <dc:subject>Mathematics - Rings and Algebras</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B05, 94B15</dc:subject>
 <dc:description>  Let $R=\mathbb{Z}_4+u\mathbb{Z}_4,$ where $\mathbb{Z}_4$ denotes the ring of
integers modulo $4$ and $u^2=0$. In the present paper, we introduce a new Gray
map from $R^n$ to $\mathbb{Z}_{4}^{2n}.$ We study $(1+2u)$-constacyclic codes
over $R$ of odd lengths with the help of cyclic codes over $R$. It is proved
that the Gray image of $(1+2u)$-constacyclic codes of length $n$ over $R$ are
cyclic codes of length $2n$ over $\mathbb{Z}_4$. Further, a number of linear
codes over $\mathbb{Z}_4$ as the images of $(1+2u)$-constacyclic codes over $R$
are obtained.
</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03445</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03449</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design Tool To Express Failure Detection Protocols</dc:title>
 <dc:creator>De Florio, Vincenzo</dc:creator>
 <dc:creator>Blondia, Chris</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Failure detection protocols---a fundamental building block for crafting
fault-tolerant distributed systems---are in many cases described by their
authors making use of informal pseudo-codes of their conception. Often these
pseudo-codes use syntactical constructs that are not available in COTS
programming languages such as C or C++. This translates into informal
descriptions that call for ad hoc interpretations and implementations. Being
informal, these descriptions cannot be tested by their authors, which may
translate into insufficiently detailed or even faulty specifications. This
paper tackles this problem introducing a formal syntax for those constructs and
a C library that implements them---a tool-set to express and reason about
failure detection protocols. The resulting specifications are longer but non
ambiguous, and eligible for becoming a standard form.
</dc:description>
 <dc:description>Comment: Published in IET Software, Vol. 4, No. 2, April 2010. Institution of
  Engineering and Technology (IET). 14 pages</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03449</dc:identifier>
 <dc:identifier>doi:10.1049/iet-sen.2009.0043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03451</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Harnessing Natural Fluctuations: Analogue Computer for Efficient
  Socially Maximal Decision Making</dc:title>
 <dc:creator>Kim, Song-Ju</dc:creator>
 <dc:creator>Naruse, Makoto</dc:creator>
 <dc:creator>Aono, Masashi</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Each individual handles many tasks of finding the most profitable option from
a set of options that stochastically provide rewards. Our society comprises a
collection of such individuals, and the society is expected to maximise the
total rewards, while the individuals compete for common rewards. Such
collective decision making is formulated as the `competitive multi-armed bandit
problem (CBP)', requiring a huge computational cost. Herein, we demonstrate a
prototype of an analog computer that efficiently solves CBPs by exploiting the
physical dynamics of numerous fluids in coupled cylinders. This device enables
the maximisation of the total rewards for the society without paying the
conventionally required computational cost; this is because the fluids estimate
the reward probabilities of the options for the exploitation of past knowledge
and generate random fluctuations for the exploration of new knowledge. Our
results suggest that to optimise the social rewards, the utilisation of
fluid-derived natural fluctuations is more advantageous than applying
artificial external fluctuations. Our analog computing scheme is expected to
trigger further studies for harnessing the huge computational power of natural
phenomena for resolving a wide variety of complex problems in modern
information society.
</dc:description>
 <dc:description>Comment: 30 pages, 3 figures</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03451</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03473</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards an I/O Conformance Testing Theory for Software Product Lines
  based on Modal Interface Automata</dc:title>
 <dc:creator>Luthmann, Lars</dc:creator>
 <dc:creator>Mennicke, Stephan</dc:creator>
 <dc:creator>Lochau, Malte</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We present an adaptation of input/output conformance (ioco) testing
principles to families of similar implementation variants as appearing in
product line engineering. Our proposed product line testing theory relies on
Modal Interface Automata (MIA) as behavioral specification formalism. MIA
enrich I/O-labeled transition systems with may/must modalities to distinguish
mandatory from optional behavior, thus providing a semantic notion of intrinsic
behavioral variability. In particular, MIA constitute a restricted, yet fully
expressive subclass of I/O-labeled modal transition systems, guaranteeing
desirable refinement and compositionality properties. The resulting modal-ioco
relation defined on MIA is preserved under MIA refinement, which serves as
variant derivation mechanism in our product line testing theory. As a result,
modal-ioco is proven correct in the sense that it coincides with traditional
ioco to hold for every derivable implementation variant. Based on this result,
a family-based product line conformance testing framework can be established.
</dc:description>
 <dc:description>Comment: In Proceedings FMSPLE 2015, arXiv:1504.03014</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03473</dc:identifier>
 <dc:identifier>EPTCS 182, 2015, pp. 1-13</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.182.1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03474</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coherent branching feature bisimulation</dc:title>
 <dc:creator>Belder, Tessa</dc:creator>
 <dc:creator>ter Beek, Maurice H.</dc:creator>
 <dc:creator>de Vink, Erik P.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  Progress in the behavioral analysis of software product lines at the family
level benefits from further development of the underlying semantical theory.
Here, we propose a behavioral equivalence for feature transition systems (FTS)
generalizing branching bisimulation for labeled transition systems (LTS). We
prove that branching feature bisimulation for an FTS of a family of products
coincides with branching bisimulation for the LTS projection of each the
individual products. For a restricted notion of coherent branching feature
bisimulation we furthermore present a minimization algorithm and show its
correctness. Although the minimization problem for coherent branching feature
bisimulation is shown to be intractable, application of the algorithm in the
setting of a small case study results in a significant speed-up of model
checking of behavioral properties.
</dc:description>
 <dc:description>Comment: In Proceedings FMSPLE 2015, arXiv:1504.03014</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03474</dc:identifier>
 <dc:identifier>EPTCS 182, 2015, pp. 14-30</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.182.2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03475</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards correct-by-construction product variants of a software product
  line: GFML, a formal language for feature modules</dc:title>
 <dc:creator>Pham, Thi-Kim-Zung</dc:creator>
 <dc:creator>Dubois, Catherine</dc:creator>
 <dc:creator>Levy, Nicole</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Software Product Line Engineering (SPLE) is a software engineering paradigm
that focuses on reuse and variability. Although feature-oriented programming
(FOP) can implement software product line efficiently, we still need a method
to generate and prove correctness of all product variants more efficiently and
automatically. In this context, we propose to manipulate feature modules which
contain three kinds of artifacts: specification, code and correctness proof. We
depict a methodology and a platform that help the user to automatically produce
correct-by-construction product variants from the related feature modules. As a
first step of this project, we begin by proposing a language, GFML, allowing
the developer to write such feature modules. This language is designed so that
the artifacts can be easily reused and composed. GFML files contain the
different artifacts mentioned above.The idea is to compile them into FoCaLiZe,
a language for specification, implementation and formal proof with some
object-oriented flavor. In this paper, we define and illustrate this language.
We also introduce a way to compose the feature modules on some examples.
</dc:description>
 <dc:description>Comment: In Proceedings FMSPLE 2015, arXiv:1504.03014</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03475</dc:identifier>
 <dc:identifier>EPTCS 182, 2015, pp. 44-55</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.182.4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03476</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantitative Analysis of Probabilistic Models of Software Product Lines
  with Statistical Model Checking</dc:title>
 <dc:creator>ter Beek, Maurice H.</dc:creator>
 <dc:creator>Legay, Axel</dc:creator>
 <dc:creator>Lafuente, Alberto Lluch</dc:creator>
 <dc:creator>Vandin, Andrea</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  We investigate the suitability of statistical model checking techniques for
analysing quantitative properties of software product line models with
probabilistic aspects. For this purpose, we enrich the feature-oriented
language FLan with action rates, which specify the likelihood of exhibiting
particular behaviour or of installing features at a specific moment or in a
specific order. The enriched language (called PFLan) allows us to specify
models of software product lines with probabilistic configurations and
behaviour, e.g. by considering a PFLan semantics based on discrete-time Markov
chains. The Maude implementation of PFLan is combined with the distributed
statistical model checker MultiVeStA to perform quantitative analyses of a
simple product line case study. The presented analyses include the likelihood
of certain behaviour of interest (e.g. product malfunctioning) and the expected
average cost of products.
</dc:description>
 <dc:description>Comment: In Proceedings FMSPLE 2015, arXiv:1504.03014</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03476</dc:identifier>
 <dc:identifier>EPTCS 182, 2015, pp. 56-70</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.182.5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03477</identifier>
 <datestamp>2016-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Software Binaries for Reengineering-Driven Product Line
  Architecture\^aAn Industrial Case Study</dc:title>
 <dc:creator>Peake, Ian D.</dc:creator>
 <dc:creator>Blech, Jan Olaf</dc:creator>
 <dc:creator>Fernando, Lasith</dc:creator>
 <dc:creator>Sharma, Divyasheel</dc:creator>
 <dc:creator>Ramaswamy, Srini</dc:creator>
 <dc:creator>Kande, Mallikarjun</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:subject>D.2.m</dc:subject>
 <dc:description>  This paper describes a method for the recovering of software architectures
from a set of similar (but unrelated) software products in binary form. One
intention is to drive refactoring into software product lines and combine
architecture recovery with run time binary analysis and existing clustering
methods. Using our runtime binary analysis, we create graphs that capture the
dependencies between different software parts. These are clustered into smaller
component graphs, that group software parts with high interactions into larger
entities. The component graphs serve as a basis for further software product
line work. In this paper, we concentrate on the analysis part of the method and
the graph clustering. We apply the graph clustering method to a real
application in the context of automation / robot configuration software tools.
</dc:description>
 <dc:description>Comment: In Proceedings FMSPLE 2015, arXiv:1504.03014</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03477</dc:identifier>
 <dc:identifier>EPTCS 182, 2015, pp. 71-82</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.182.6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03483</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting and Explaining Conflicts in Attributed Feature Models</dc:title>
 <dc:creator>Lesta, Uwe</dc:creator>
 <dc:creator>Schaefer, Ina</dc:creator>
 <dc:creator>Winkelmann, Tim</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.2</dc:subject>
 <dc:subject>D.2.13</dc:subject>
 <dc:description>  Product configuration systems are often based on a variability model. The
development of a variability model is a time consuming and error-prone process.
Considering the ongoing development of products, the variability model has to
be adapted frequently. These changes often lead to mistakes, such that some
products cannot be derived from the model anymore, that undesired products are
derivable or that there are contradictions in the variability model. In this
paper, we propose an approach to discover and to explain contradictions in
attributed feature models efficiently in order to assist the developer with the
correction of mistakes. We use extended feature models with attributes and
arithmetic constraints, translate them into a constraint satisfaction problem
and explore those for contradictions. When a contradiction is found, the
constraints are searched for a set of contradicting relations by the
QuickXplain algorithm.
</dc:description>
 <dc:description>Comment: In Proceedings FMSPLE 2015, arXiv:1504.03014</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03483</dc:identifier>
 <dc:identifier>EPTCS 182, 2015, pp. 31-43</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.182.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03490</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Modeling of an MRI Guided Drug Delivery System Based on
  Magnetic Nanoparticle Aggregations for the Navigation of Paramagnetic
  Nanocapsules</dc:title>
 <dc:creator>Lampropoulos, N. K.</dc:creator>
 <dc:creator>Karvelas, E. G.</dc:creator>
 <dc:creator>Sarris, I. E.</dc:creator>
 <dc:subject>Condensed Matter - Soft Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  A computational method for magnetically guided drug delivery is presented and
the results are compared for the aggregation process of magnetic particles
within a fluid environment. The model is developed for the simulation of the
aggregation patterns of magnetic nanoparticles under the influence of MRI
magnetic coils. A novel approach for the calculation of the drag coefficient of
aggregates is presented. The comparison against experimental and numerical
results from the literature is showed that the proposed method predicts well
the aggregations in respect to their size and pattern dependance, on the
concentration and the strength of the magnetic field, as well as their velocity
when particles are driven through the fluid by magnetic gradients.
</dc:description>
 <dc:description>Comment: 14 pages, 14 figures</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03494</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Nonlinear MPC of Multi-Agent Systems with Data Compression
  and Random Delays - Extended Version</dc:title>
 <dc:creator>El-Ferik, Sami</dc:creator>
 <dc:creator>Siddiqui, Bilal A.</dc:creator>
 <dc:creator>Lewis, Frank L.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This is an extended version of a technical note accepted for publication in
IEEE Transactions on Automatic Control. The note proposes an Input to State
practically Stable (ISpS) formulation of distributed nonlinear model predictive
controller (NMPC) for formation control of constrained autonomous vehicles in
presence of communication bandwidth limitation and transmission delays. Planned
trajectories are compressed using neural networks resulting in considerable
reduction of data packet size, while being robust to propagation delays and
uncertainty in neighbors' trajectories. Collision avoidance is achieved by
means of spatially filtered potential field. Analytical results proving ISpS
and generalized small gain conditions are presented for both strongly- and
weakly-connected networks, and illustrated by simulations.
</dc:description>
 <dc:description>Comment: 19 pages, 3 Figures, accepted for publication, IEEE Transactions on
  Automatic Control, 2015, Technical Note</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03494</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03498</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EMF-REST: Generation of RESTful APIs from Models</dc:title>
 <dc:creator>Ed-Douibi, Hamza</dc:creator>
 <dc:creator>Izquierdo, Javier Luis C&#xe1;novas</dc:creator>
 <dc:creator>G&#xf3;mez, Abel</dc:creator>
 <dc:creator>Tisi, Massimo</dc:creator>
 <dc:creator>Cabot, Jordi</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In the last years, RESTful Web services have become more and more popular as
a lightweight solution to connect remote systems in distributed and Cloud-based
architectures. However, being an architectural style rather than a
specification or standard, the proper design of RESTful Web services is not
trivial since developers have to deal with a plethora of recommendations and
best practices. Model-Driven Engineering (MDE) emphasizes the use of models and
model transformations to raise the level of abstraction and semi-automate the
development of software. In this paper we present an approach that leverages on
MDE techniques to generate RESTful services. The approach, called EMF-REST,
takes EMF data models as input and generates Web APIs following the REST
principles and relying on well-known libraries and standards, thus facilitating
its comprehension and maintainability. Additionally, EMF-REST integrates model
and Web-specific features to provide model validation and security
capabilities, respectively, to the generated API. For Web developers, our
approach brings more agility to the Web development process by providing
ready-to-run-and-test Web APIs out of data models. Also, our approach provides
MDE practitioners the basis to develop Cloud-based modeling solutions as well
as enhanced collaborative support.
</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03503</identifier>
 <datestamp>2016-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Backhaul-Aware User Association and Resource Allocation for
  Energy-Constrained HetNets</dc:title>
 <dc:creator>Han, Qiaoni</dc:creator>
 <dc:creator>Yang, Bo</dc:creator>
 <dc:creator>Miao, Guowang</dc:creator>
 <dc:creator>Chen, Cailian</dc:creator>
 <dc:creator>Wang, Xiaocheng</dc:creator>
 <dc:creator>Guan, Xinping</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Growing attentions have been paid to renewable energy or hybrid energy
powered heterogeneous networks (HetNets). In this paper, focusing on
backhaul-aware joint user association and resource allocation for this type of
HetNets, we formulate an online optimization problem to maximize the network
utility reflecting proportional fairness. Since user association and resource
allocation are tightly coupled not only on resource consumption of the base
stations (BSs), but also in the constraints of their available energy and
backhaul, the closed-form solution is quite difficult to obtain. Thus, we solve
the problem distributively via employing some decomposition methods.
Specifically, at first, by adopting primal decomposition method, we decompose
the original problem into a lower-level resource allocation problem for each
BS, and a higher-level user association problem. For the optimal resource
allocation, we prove that a BS either assigns equal normalized resources or
provides equal long-term service rate to its served users. Then, the user
association problem is solved by Lagrange dual decomposition method, and a
completely distributed algorithm is developed. Moreover, applying results of
the subgradient method, we demonstrate the convergence of the proposed
distributed algorithm. Furthermore, in order to efficiently and reliably apply
the proposed algorithm to the future wireless networks with an extremely dense
BS deployment, we design a virtual user association and resource allocation
scheme based on the software-defined networking architecture. Lastly, numerical
results validate the convergence of the proposed algorithm and the significant
improvement on network utility, load balancing and user fairness.
</dc:description>
 <dc:description>Comment: 35 pages, 12 figures</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:date>2016-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03503</dc:identifier>
 <dc:identifier>doi:10.1109/TVT.2016.2533559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03504</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sketch-based 3D Shape Retrieval using Convolutional Neural Networks</dc:title>
 <dc:creator>Wang, Fang</dc:creator>
 <dc:creator>Kang, Le</dc:creator>
 <dc:creator>Li, Yi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Retrieving 3D models from 2D human sketches has received considerable
attention in the areas of graphics, image retrieval, and computer vision.
Almost always in state of the art approaches a large amount of &quot;best views&quot; are
computed for 3D models, with the hope that the query sketch matches one of
these 2D projections of 3D models using predefined features.
  We argue that this two stage approach (view selection -- matching) is
pragmatic but also problematic because the &quot;best views&quot; are subjective and
ambiguous, which makes the matching inputs obscure. This imprecise nature of
matching further makes it challenging to choose features manually. Instead of
relying on the elusive concept of &quot;best views&quot; and the hand-crafted features,
we propose to define our views using a minimalism approach and learn features
for both sketches and views. Specifically, we drastically reduce the number of
views to only two predefined directions for the whole dataset. Then, we learn
two Siamese Convolutional Neural Networks (CNNs), one for the views and one for
the sketches. The loss function is defined on the within-domain as well as the
cross-domain similarities. Our experiments on three benchmark datasets
demonstrate that our method is significantly better than state of the art
approaches, and outperforms them in all conventional metrics.
</dc:description>
 <dc:description>Comment: CVPR 2015</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03504</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03509</identifier>
 <datestamp>2015-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regret vs. Communication: Distributed Stochastic Multi-Armed Bandits and
  Beyond</dc:title>
 <dc:creator>Liu, Shuang</dc:creator>
 <dc:creator>Chen, Cheng</dc:creator>
 <dc:creator>Zhang, Zhihua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we consider the distributed stochastic multi-armed bandit
problem, where a global arm set can be accessed by multiple players
independently. The players are allowed to exchange their history of
observations with each other at specific points in time. We study the
relationship between regret and communication. When the time horizon is known,
we propose the Over-Exploration strategy, which only requires one-round
communication and whose regret does not scale with the number of players. When
the time horizon is unknown, we measure the frequency of communication through
a new notion called the density of the communication set, and give an exact
characterization of the interplay between regret and communication.
Specifically, a lower bound is established and stable strategies that match the
lower bound are developed. The results and analyses in this paper are specific
but can be translated into more general settings.
</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:date>2015-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03516</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mixed-ADC Massive MIMO</dc:title>
 <dc:creator>Liang, Ning</dc:creator>
 <dc:creator>Zhang, Wenyi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Motivated by the demand for energy-efficient communication solutions in the
next generation cellular network, a mixed-ADC architecture for massive multiple
input multiple output (MIMO) systems is proposed, which differs from previous
works in that herein one-bit analog-to-digital converters (ADCs) partially
replace the conventionally assumed high-resolution ADCs. The
information-theoretic tool of generalized mutual information (GMI) is exploited
to analyze the achievable data rates of the proposed system architecture and an
array of analytical results of engineering interest are obtained. For fixed
single input multiple output (SIMO) channels, a closed-form expression of the
GMI is derived, based on which the linear combiner is optimized. The analysis
is then extended to ergodic fading channels, for which tight lower and upper
bounds of the GMI are obtained. Impacts of dithering and imperfect channel
state information (CSI) are also investigated, and it is shown that dithering
can remarkably improve the system performance while imperfect CSI only
introduces a marginal rate loss. Finally, the analytical framework is applied
to the multi-user access scenario. Numerical results demonstrate that the
mixed-ADC architecture with a relatively small number of high-resolution ADCs
is able to achieve a large fraction of the channel capacity of conventional
architecture, while reduce the energy consumption considerably even compared
with antenna selection, for both single-user and multi-user scenarios.
</dc:description>
 <dc:description>Comment: double column, 15 pages, 11 figures, accepted for publication in IEEE
  Journal on Selected Areas in Communications Special Issue on Energy-Efficient
  Techniques for 5G Wireless Communication Systems</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:date>2015-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03516</dc:identifier>
 <dc:identifier>doi:10.1109/JSAC.2016.2544604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03517</identifier>
 <datestamp>2015-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bearing-Based Formation Maneuvering</dc:title>
 <dc:creator>Zhao, Shiyu</dc:creator>
 <dc:creator>Zelazo, Daniel</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper studies the problem of multi-agent formation maneuver control
where both of the centroid and scale of a formation are required to track given
velocity references while maintaining the formation shape. Unlike the
conventional approaches where the target formation is defined by inter-neighbor
relative positions or distances, we propose a bearing-based approach where the
target formation is defined by inter-neighbor bearings. Due to the invariance
of the bearings, the bearing-based approach provides a natural solution to
formation scale control. We assume the dynamics of each agent as a single
integrator and propose a globally stable proportional-integral formation
maneuver control law. It is shown that at least two leaders are required to
collaborate in order to control the centroid and scale of the formation whereas
the followers are not required to have access to any global information, such
as the velocities of the leaders.
</dc:description>
 <dc:description>Comment: To appear in the 2015 IEEE Multi-Conference on Systems and Control
  (MSC2015); this is the final version</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:date>2015-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03517</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03522</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Scene Text Localization and Recognition with Local Character
  Refinement</dc:title>
 <dc:creator>Neumann, Luk&#xe1;&#x161;</dc:creator>
 <dc:creator>Matas, Ji&#x159;&#xed;</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  An unconstrained end-to-end text localization and recognition method is
presented. The method detects initial text hypothesis in a single pass by an
efficient region-based method and subsequently refines the text hypothesis
using a more robust local text model, which deviates from the common assumption
of region-based methods that all characters are detected as connected
components.
  Additionally, a novel feature based on character stroke area estimation is
introduced. The feature is efficiently computed from a region distance map, it
is invariant to scaling and rotations and allows to efficiently detect text
regions regardless of what portion of text they capture.
  The method runs in real time and achieves state-of-the-art text localization
and recognition results on the ICDAR 2013 Robust Reading dataset.
</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03524</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Achieving Economic Operation and Secondary Frequency Regulation
  Simultaneously Through Feedback Control</dc:title>
 <dc:creator>Miao, Zhixin</dc:creator>
 <dc:creator>Fan, Lingling</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This article presents an exciting finding for the power industry: the
parameters of secondary frequency control based on integral or proportional
integral control can be tuned to achieve economic operation and frequency
regulation simultaneously. We show that if the power imbalance is represented
by frequency deviation, an iterative dual decomposition based economic dispatch
solving is equivalent to integral control. An iterative method of multipliers
based economic dispatch is equivalent to proportional integral control.
Similarly, if the controller parameters of the secondary frequency controls are
chosen based on generator cost functions, these secondary frequency controllers
achieve both economic operation and frequency regulation simultaneously.
</dc:description>
 <dc:description>Comment: submitted to IEEE PES letters</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03536</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ISP-friendly Peer-assisted On-demand Streaming of Long Duration Content
  in BBC iPlayer</dc:title>
 <dc:creator>Karamshuk, Dmytro</dc:creator>
 <dc:creator>Sastry, Nishanth</dc:creator>
 <dc:creator>Secker, Andrew</dc:creator>
 <dc:creator>Chandaria, Jigna</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In search of scalable solutions, CDNs are exploring P2P support. However, the
benefits of peer assistance can be limited by various obstacle factors such as
ISP friendliness - requiring peers to be within the same ISP, bitrate
stratification - the need to match peers with others needing similar bitrate,
and partial participation - some peers choosing not to redistribute content.
  This work relates potential gains from peer assistance to the average number
of users in a swarm, its capacity, and empirically studies the effects of these
obstacle factors at scale, using a month-long trace of over 2 million users in
London accessing BBC shows online. Results indicate that even when P2P swarms
are localised within ISPs, up to 88% of traffic can be saved. Surprisingly,
bitrate stratification results in 2 large sub-swarms and does not significantly
affect savings. However, partial participation, and the need for a minimum
swarm size do affect gains. We investigate improvements to gain from increasing
content availability through two well-studied techniques: content bundling -
combining multiple items to increase availability, and historical caching of
previously watched items. Bundling proves ineffective as increased server
traffic from larger bundles outweighs benefits of availability, but simple
caching can considerably boost traffic gains from peer assistance.
</dc:description>
 <dc:description>Comment: In Proceedings of IEEE INFOCOM 2015</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03536</dc:identifier>
 <dc:identifier>doi:10.1109/INFOCOM.2015.7218393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03539</identifier>
 <datestamp>2015-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection of Information leakage in cloud</dc:title>
 <dc:creator>Alam, Mansaf</dc:creator>
 <dc:creator>Sethi, Shuchi</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Recent research shows that colluded malware in different VMs sharing a single
physical host may use a resource as a channel to leak critical information.
Covert channels employ time or storage characteristics to transmit confidential
information to attackers leaving no trail.These channels were not meant for
communication and hence control mechanisms do not exist. This means these
remain undetected by traditional security measures employed in firewalls etc in
a network. The comprehensive survey to address the issue highlights that
accurate methods for fast detection in cloud are very expensive in terms of
storage and processing. The proposed framework builds signature by extracting
features which accurately classify the regular from covert traffic in cloud and
estimates difference in distribution of data under analysis by means of scores.
It then adds context to the signature and finally using machine learning
(Support Vector Machines),a model is built and trained for deploying in cloud.
The results show that the framework proposed is high in accuracy while being
low cost and robust as it is tested after adding noise which is likely to exist
in public cloud environments.
</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:date>2015-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03539</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03542</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Factors Affecting the Usage and Adoption of a Nation-wide TV
  Streaming Service</dc:title>
 <dc:creator>Karamshuk, Dmytro</dc:creator>
 <dc:creator>Sastry, Nishanth</dc:creator>
 <dc:creator>Secker, Andrew</dc:creator>
 <dc:creator>Chandaria, Jigna</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Using nine months of access logs comprising 1.9 Billion sessions to BBC
iPlayer, we survey the UK ISP ecosystem to understand the factors affecting
adoption and usage of a high bandwidth TV streaming application across
different providers. We find evidence that connection speeds are important and
that external events can have a huge impact for live TV usage. Then, through a
temporal analysis of the access logs, we demonstrate that data usage caps
imposed by mobile ISPs significantly affect usage patterns, and look for
solutions. We show that product bundle discounts with a related fixed-line ISP,
a strategy already employed by some mobile providers, can better support user
needs and capture a bigger share of accesses. We observe that users regularly
split their sessions between mobile and fixed-line connections, suggesting a
straightforward strategy for offloading by speculatively pre-fetching content
from a fixed-line ISP before access on mobile devices.
</dc:description>
 <dc:description>Comment: In Proceedings of IEEE INFOCOM 2015</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03542</dc:identifier>
 <dc:identifier>doi:10.1109/INFOCOM.2015.7218454</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03543</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Definability Dichotomy for Finite Valued CSPs</dc:title>
 <dc:creator>Dawar, Anuj</dc:creator>
 <dc:creator>Wang, Pengming</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>68Q19</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:description>  Finite valued constraint satisfaction problems are a formalism for describing
many natural optimization problems, where constraints on the values that
variables can take come with rational weights and the aim is to find an
assignment of minimal cost. Thapper and Zivny have recently established a
complexity dichotomy for finite valued constraint languages. They show that
each such language either gives rise to a polynomial-time solvable optimization
problem, or to an NP-hard one, and establish a criterion to distinguish the two
cases. We refine the dichotomy by showing that all optimization problems in the
first class are definable in fixed-point language with counting, while all
languages in the second class are not definable, even in infinitary logic with
counting. Our definability dichotomy is not conditional on any
complexity-theoretic assumption.
</dc:description>
 <dc:description>Comment: 23 pages</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03543</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03547</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SDP-based State Estimation of Multi-phase Active Distribution Networks
  using micro-PMUs</dc:title>
 <dc:creator>Disfani, Vahid Rasouli</dc:creator>
 <dc:creator>Bozchalui, Mohammad Chehreghani</dc:creator>
 <dc:creator>Sharma, Ratnesh</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Distribution system state estimation (DSSE) is an essential tool for
operation of distribution networks, the results of which enables the operator
to have a thorough observation of the system. Thus, most distribution
management systems (DMS) include a single-phase state estimator. Due to
non-convexity of the SE problem, heuristic and Newton methods do not guarantee
the global solution. In contrast, SDP based SE is more promising to guarantee
the globally optimal solution since it represents and solves the problem in a
convex format. However, the observability of the power system is highly
vulnerable to the set of measurements while employing the SDP-based SE, which
is addressed in this report. An algorithm is proposed to generate additional
measurements using the measurement data already gathered. The SDP-based SE is
very sensitive to the level of noise in large power networks. Also, bad data
detection algorithms proposed for Newton methods do not work for the SDP-based
SE method due to larger number of state variables in SDP representation of
power network. In this report, an algorithm is proposed to generate additional
measurements using the measurement data already gathered in order to solve the
observability issue. A network separation algorithm is developed to solve the
entire problem for smaller sub-networks which include micro-PMUs to mitigate
the adverse effects of noise for huge networks. An algorithm based on
redundancy test is also developed for bad data detection. The algorithms are
tested on single phase and multiphase test systems. The algorithms are applied
EPRI Circuit 5 (2998-bus) test feeder to demonstrate the flexibility of the
algorithms developed.
</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03553</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Handshaking Protocol for Distributed Implementation of Reo</dc:title>
 <dc:creator>Kokash, Natallia</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Reo, an exogenous channel-based coordination language, is a model for service
coordination wherein services communicate through connectors formed by joining
binary communication channels. In order to establish transactional
communication among services as prescribed by connector semantics, distributed
ports exchange handshaking messages signalling which parties are ready to
provide or consume data. In this paper, we present a formal implementation
model for distributed Reo with communication delays and outline ideas for its
proof of correctness. To reason about Reo implementation formally, we introduce
Timed Action Constraint Automata (TACA) and explain how to compare TACA with
existing automata-based semantics for Reo. We use TACA to describe handshaking
behavior of Reo modeling primitives and argue that in any distributed circuit
remote Reo nodes and channels exposing such behavior commit to perform
transitions envisaged by the network semantics.
</dc:description>
 <dc:description>Comment: In Proceedings FOCLASA 2014, arXiv:1502.03157</dc:description>
 <dc:date>2015-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03553</dc:identifier>
 <dc:identifier>EPTCS 175, 2015, pp. 1-17</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.175.1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03558</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fuzzy approaches to context variable in fuzzy geographically weighted
  clustering</dc:title>
 <dc:creator>Van Minh, Nguyen</dc:creator>
 <dc:creator>Son, Le Hoang</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>62H30</dc:subject>
 <dc:subject>I.5.3</dc:subject>
 <dc:description>  Fuzzy Geographically Weighted Clustering (FGWC) is considered as a suitable
tool for the analysis of geo-demographic data that assists the provision and
planning of products and services to local people. Context variables were
attached to FGWC in order to accelerate the computing speed of the algorithm
and to focus the results on the domain of interests. Nonetheless, the
determination of exact, crisp values of the context variable is a hard task. In
this paper, we propose two novel methods using fuzzy approaches for that
determination. A numerical example is given to illustrate the uses of the
proposed methods.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2015-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03558</dc:identifier>
 <dc:identifier>doi:10.5121/csit.2015.50503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03561</identifier>
 <datestamp>2015-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Workflow Satisfiability Problem with Class-Independent
  Constraints</dc:title>
 <dc:creator>Crampton, Jason</dc:creator>
 <dc:creator>Gagarin, Andrei</dc:creator>
 <dc:creator>Gutin, Gregory</dc:creator>
 <dc:creator>Jones, Mark</dc:creator>
 <dc:creator>Wahlstrom, Magnus</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A workflow specification defines sets of steps and users. An authorization
policy determines for each user a subset of steps the user is allowed to
perform. Other security requirements, such as separation-of-duty, impose
constraints on which subsets of users may perform certain subsets of steps. The
\emph{workflow satisfiability problem} (WSP) is the problem of determining
whether there exists an assignment of users to workflow steps that satisfies
all such authorizations and constraints. An algorithm for solving WSP is
important, both as a static analysis tool for workflow specifications, and for
the construction of run-time reference monitors for workflow management
systems. Given the computational difficulty of WSP, it is important,
particularly for the second application, that such algorithms are as efficient
as possible.
  We introduce class-independent constraints, enabling us to model scenarios
where the set of users is partitioned into groups, and the identities of the
user groups are irrelevant to the satisfaction of the constraint. We prove that
solving WSP is fixed-parameter tractable (FPT) for this class of constraints
and develop an FPT algorithm that is useful in practice. We compare the
performance of the FPT algorithm with that of SAT4J (a pseudo-Boolean SAT
solver) in computational experiments, which show that our algorithm
significantly outperforms SAT4J for many instances of WSP. User-independent
constraints, a large class of constraints including many practical ones, are a
special case of class-independent constraints for which WSP was proved to be
FPT (Cohen {\em et al.}, J. Artif. Intel. Res. 2014). Thus our results
considerably extend our knowledge of the fixed-parameter tractability of WSP.
</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:date>2015-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03564</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Android based security and home automation system</dc:title>
 <dc:creator>Khan, Sadeque Reza</dc:creator>
 <dc:creator>Dristy, Farzana Sultana</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  The smart mobile terminal operator platform Android is getting popular all
over the world with its wide variety of applications and enormous use in
numerous spheres of our daily life. Considering the fact of increasing demand
of home security and automation, an Android based control system is presented
in this paper where the proposed system can maintain the security of home main
entrance and also the car door lock. Another important feature of the designed
system is that it can control the overall appliances in a room. The mobile to
security system or home automation system interface is established through
Bluetooth. The hardware part is designed with the PIC microcontroller.
</dc:description>
 <dc:description>Comment: 10 pages,17 figures, Journal, International Journal of Ambient
  Systems and Applications, Volume 3, 2015</dc:description>
 <dc:date>2015-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03564</dc:identifier>
 <dc:identifier>doi:10.5121/ijasa.2014.3102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03573</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building Proteins in a Day: Efficient 3D Molecular Reconstruction</dc:title>
 <dc:creator>Brubaker, Marcus A.</dc:creator>
 <dc:creator>Punjani, Ali</dc:creator>
 <dc:creator>Fleet, David J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  Discovering the 3D atomic structure of molecules such as proteins and viruses
is a fundamental research problem in biology and medicine. Electron
Cryomicroscopy (Cryo-EM) is a promising vision-based technique for structure
estimation which attempts to reconstruct 3D structures from 2D images. This
paper addresses the challenging problem of 3D reconstruction from 2D Cryo-EM
images. A new framework for estimation is introduced which relies on modern
stochastic optimization techniques to scale to large datasets. We also
introduce a novel technique which reduces the cost of evaluating the objective
function during optimization by over five orders or magnitude. The net result
is an approach capable of estimating 3D molecular structure from large scale
datasets in about a day on a single workstation.
</dc:description>
 <dc:description>Comment: To be presented at IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR) 2015</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03573</dc:identifier>
 <dc:identifier>doi:10.1109/CVPR.2015.7298929</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1504.03580</identifier>
 <datestamp>2015-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An New Type Of Artificial Brain Using Controlled Neurons</dc:title>
 <dc:creator>Burger, John Robert</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Plans for a new type of artificial brain are possible because of realistic
neurons in logically structured arrays of controlled toggles, one toggle per
neuron. Controlled toggles can be made to compute, in parallel, parameters of
critical importance for each of several complex images recalled from
associative long term memory. Controlled toggles are shown below to amount to a
new type of neural network that supports autonomous behavior and action.
</dc:description>
 <dc:description>Comment: 10 pages; 6 figures</dc:description>
 <dc:date>2015-04-14</dc:date>
 <dc:date>2015-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1504.03580</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="75000" completeListSize="155308">2369777|76001</resumptionToken>
</ListRecords>
</OAI-PMH>
